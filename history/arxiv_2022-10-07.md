# Your interest papers
---
## cs.CV
---
### CIR-Net: Cross-modality Interaction and Refinement for RGB-D Salient Object Detection. (arXiv:2210.02843v1 [cs.CV])
- Authors : Runmin Cong, Qinwei Lin, Chen Zhang, **Chongyi Li**, Xiaochun Cao, Qingming Huang, Yao Zhao
- Link : [http://arxiv.org/abs/2210.02843](http://arxiv.org/abs/2210.02843)
> ABSTRACT  :  Focusing on the issue of how to effectively capture and utilize cross-modality information in RGB-D salient object detection (SOD) task, we present a convolutional neural network (CNN) model, named CIR-Net, based on the novel cross-modality interaction and refinement. For the cross-modality interaction, 1) a progressive attention guided integration unit is proposed to sufficiently integrate RGB-D feature representations in the encoder stage, and 2) a convergence aggregation structure is proposed, which flows the RGB and depth decoding features into the corresponding RGB-D decoding streams via an importance gated fusion unit in the decoder stage. For the cross-modality refinement, we insert a refinement middleware structure between the encoder and the decoder, in which the RGB, depth, and RGB-D encoder features are further refined by successively using a self-modality attention refinement unit and a cross-modality weighting refinement unit. At last, with the gradually refined features, we predict the saliency map in the decoder stage. Extensive experiments on six popular RGB-D SOD benchmarks demonstrate that our network outperforms the state-of-the-art saliency detectors both qualitatively and quantitatively.  
### Rolling Shutter Inversion: Bring Rolling Shutter Images to High Framerate Global Shutter Video. (arXiv:2210.03040v1 [cs.CV])
- Authors : Bin Fan, Yuchao Dai, Hongdong Li
- Link : [http://arxiv.org/abs/2210.03040](http://arxiv.org/abs/2210.03040)
> ABSTRACT  :  A single rolling-shutter (RS) image may be viewed as a row-wise combination of a sequence of global-shutter (GS) images captured by a (virtual) moving GS camera within the **exposure** duration. Although RS cameras are widely used, the RS effect causes obvious image distortion especially in the presence of fast camera motion, hindering downstream computer vision tasks. In this paper, we propose to invert the RS image capture mechanism, i.e., recovering a continuous high framerate GS video from two time-consecutive RS frames. We call this task the RS temporal super-resolution (RSSR) problem. The RSSR is a very challenging task, and to our knowledge, no practical solution exists to date. This paper presents a novel deep-learning based solution. By leveraging the multi-view geometry relationship of the RS imaging process, our learning-based framework successfully achieves high framerate GS generation. Specifically, three novel contributions can be identified: (i) novel formulations for bidirectional RS undistortion flows under constant velocity as well as constant acceleration motion model. (ii) a simple linear scaling operation, which bridges the RS undistortion flow and regular optical flow. (iii) a new mutual conversion scheme between varying RS undistortion flows that correspond to different scanlines. Our method also exploits the underlying spatial-temporal geometric relationships within a deep learning framework, where no additional supervision is required beyond the necessary middle-scanline GS image. Building upon these contributions, we represent the very first rolling-shutter temporal super-resolution deep-network that is able to recover high framerate GS videos from just two RS frames. Extensive experimental results on both synthetic and real data show that our proposed method can produce high-quality GS image sequences with rich details, outperforming the state-of-the-art methods.  
### Structure Representation Network and Uncertainty Feedback Learning for Dense Non-Uniform Fog Removal. (arXiv:2210.03061v1 [cs.CV])
- Authors : Yeying Jin, Wending Yan, **Wenhan Yang**
- Link : [http://arxiv.org/abs/2210.03061](http://arxiv.org/abs/2210.03061)
> ABSTRACT  :  Few existing image defogging or dehazing methods consider dense and non-uniform particle distributions, which usually happen in smoke, dust and fog. Dealing with these dense and/or non-uniform distributions can be intractable, since fog's attenuation and airlight (or veiling effect) significantly weaken the background scene information in the input image. To address this problem, we introduce a structure-representation network with uncertainty feedback learning. Specifically, we extract the feature representations from a pre-trained Vision Transformer (DINO-ViT) module to recover the background information. To guide our network to focus on non-uniform fog areas, and then remove the fog accordingly, we introduce the uncertainty feedback learning, which produces the uncertainty maps, that have higher uncertainty in denser fog regions, and can be regarded as an attention map that represents fog's density and uneven distribution. Based on the uncertainty map, our feedback network refines our defogged output iteratively. Moreover, to handle the intractability of estimating the atmospheric light colors, we exploit the grayscale version of our input image, since it is less affected by varying light colors that are possibly present in the input image. The experimental results demonstrate the effectiveness of our method both quantitatively and qualitatively compared to the state-of-the-art methods in handling dense and non-uniform fog or smoke.  
### Unsupervised Image Transformation Learning via Generative Adversarial Networks. (arXiv:2103.07751v2 [cs.CV] UPDATED)
- Authors : Kaiwen Zha, Yujun Shen, Bolei Zhou
- Link : [http://arxiv.org/abs/2103.07751](http://arxiv.org/abs/2103.07751)
> ABSTRACT  :  In this work, we study the image transformation problem, which targets at learning the underlying transformations (e.g., the transition of seasons) from a collection of unlabeled images. However, there could be countless of transformations in the real world, making such a task incredibly challenging, especially under the unsupervised setting. To tackle this obstacle, we propose a novel learning framework built on generative adversarial networks (GANs), where the discriminator and the generator share a transformation space. After the model gets fully optimized, any two points within the shared space are expected to define a valid transformation. In this way, at the inference stage, we manage to adequately extract the variation factor between a customizable image pair by projecting both images onto the transformation space. The resulting transformation vector can further guide the image synthesis, facilitating image editing with continuous semantic change (e.g., altering summer to winter with fall as the intermediate step). Noticeably, the learned transformation space supports not only transferring image styles (e.g., changing day to **night**), but also manipulating image contents (e.g., adding clouds in the sky). In addition, we make in-depth analysis on the properties of the transformation space to help understand how various transformations are organized. Project page is at https://genforce.github.io/trgan/.  
### Cosmic-CoNN: A Cosmic Ray Detection Deep-Learning Framework, Dataset, and Toolkit. (arXiv:2106.14922v3 [astro-ph.IM] UPDATED)
- Authors : Chengyuan Xu, Curtis McCully, Boning Dong, Andrew Howell, Pradeep Sen
- Link : [http://arxiv.org/abs/2106.14922](http://arxiv.org/abs/2106.14922)
> ABSTRACT  :  Rejecting cosmic rays (CRs) is essential for the scientific interpretation of CCD-captured data, but detecting CRs in single-**exposure** images has remained challenging. Conventional CR detectors require experimental parameter tuning for different instruments, and recent deep learning methods only produce instrument-specific models that suffer from performance loss on telescopes not included in the training data. We present Cosmic-CoNN, a generic CR detector deployed for 24 telescopes at the Las Cumbres Observatory, which is made possible by the three contributions in this work: 1) We build a large and diverse ground-based CR dataset leveraging thousands of images from a global telescope network. 2) We propose a novel loss function and a neural network optimized for telescope imaging data to train generic CR detection models. At 95% recall, our model achieves a precision of 93.70% on Las Cumbres imaging data and maintains a consistent performance on new ground-based instruments never used for training. Specifically, the Cosmic-CoNN model trained on the Las Cumbres CR dataset maintains high precisions of 92.03% and 96.69% on Gemini GMOS-N/S 1x1 and 2x2 binning images, respectively. 3) We build a suite of tools including an interactive CR mask visualization and editing interface, console commands, and Python APIs to make automatic, robust CR detection widely accessible by the community of astronomers. Our dataset, open-source codebase, and trained models are available at https://github.com/cy-xu/cosmic-conn.  
### Graph-Based Depth Denoising & Dequantization for Point Cloud **Enhancement**. (arXiv:2111.04946v2 [cs.CV] UPDATED)
- Authors : Xue Zhang, Gene Cheung, Jiahao Pang, Yash Sanghvi, Abhiram Gnanasambandam
- Link : [http://arxiv.org/abs/2111.04946](http://arxiv.org/abs/2111.04946)
> ABSTRACT  :  A 3D point cloud is typically constructed from depth measurements acquired by sensors at one or more viewpoints. The measurements suffer from both quantization and noise corruption. To improve quality, previous works denoise a point cloud \textit{a posteriori} after projecting the imperfect depth data onto 3D space. Instead, we enhance depth measurements directly on the sensed images \textit{a priori}, before synthesizing a 3D point cloud. By enhancing near the physical sensing process, we tailor our optimization to our depth formation model before subsequent processing steps that obscure measurement errors.    Specifically, we model depth formation as a combined process of signal-dependent noise addition and non-uniform log-based quantization. The designed model is validated (with parameters fitted) using collected empirical data from a representative depth sensor. To enhance each pixel row in a depth image, we first encode intra-view similarities between available row pixels as edge weights via feature graph learning. We next establish inter-view similarities with another rectified depth image via viewpoint mapping and sparse linear interpolation. This leads to a maximum a posteriori (MAP) graph filtering objective that is convex and differentiable. We minimize the objective efficiently using accelerated gradient descent (AGD), where the optimal step size is approximated via Gershgorin circle theorem (GCT). Experiments show that our method significantly outperformed recent point cloud denoising schemes and state-of-the-art image denoising schemes in two established point cloud quality metrics.  
### Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
- Authors : Gerard Snaauw, Michele Sasdelli, Gabriel Maicas, Stephan Lau, Johan Verjans, Mark Jenkinson, Gustavo Carneiro, Australian Institute, for Machine, University of, South Australian, Health and, Medical Research
- Link : [http://arxiv.org/abs/2201.10305](http://arxiv.org/abs/2201.10305)
> ABSTRACT  :  Many applications in image-guided surgery and therapy require fast and reliable non-linear, multi-modal image registration. Recently proposed unsupervised deep learning-based registration methods have demonstrated superior performance compared to iterative methods in just a fraction of the time. Most of the learning-based methods have focused on mono-modal image registration. The extension to multi-modal registration depends on the use of an appropriate similarity function, such as the mutual information (MI). We propose guiding the training of a deep learning-based registration method with MI estimation between an image-pair in an end-to-end trainable network. Our results show that a small, 2-layer network produces competitive results in both mono- and multi-modal registration, with sub-second run-times. Comparisons to both iterative and deep learning-based methods show that our MI-based method produces topologically and qualitatively superior results with an extremely low rate of non-diffeomorphic transformations. **Real-time** clinical application will benefit from a better visual matching of anatomical structures and less registration failures/outliers.  
### MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v2 [cs.CV] UPDATED)
- Authors : Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen
- Link : [http://arxiv.org/abs/2203.17272](http://arxiv.org/abs/2203.17272)
> ABSTRACT  :  We introduce MyStyle, a personalized deep generative prior trained with a few shots of an individual. MyStyle allows to reconstruct, enhance and edit images of a specific person, such that the output is faithful to the person's key facial characteristics. Given a small reference set of portrait images of a person (~100), we tune the weights of a pretrained StyleGAN face generator to form a local, low-dimensional, personalized manifold in the latent space. We show that this manifold constitutes a personalized region that spans latent codes associated with diverse portrait images of the individual. Moreover, we demonstrate that we obtain a personalized generative prior, and propose a unified approach to apply it to various ill-posed image **enhancement** problems, such as inpainting and super-resolution, as well as semantic editing. Using the personalized generative prior we obtain outputs that exhibit high-fidelity to the input images and are also faithful to the key facial characteristics of the individual in the reference set. We demonstrate our method with fair-use images of numerous widely recognizable individuals for whom we have the prior knowledge for a qualitative evaluation of the expected outcome. We evaluate our approach against few-shots baselines and show that our personalized prior, quantitatively and qualitatively, outperforms state-of-the-art alternatives.  
### Pik-Fix: Restoring and Colorizing Old Photos. (arXiv:2205.01902v3 [cs.CV] UPDATED)
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Alan Bovik, Hongkai Yu
- Link : [http://arxiv.org/abs/2205.01902](http://arxiv.org/abs/2205.01902)
> ABSTRACT  :  Restoring and inpainting the visual memories that are present, but often impaired, in old photos remains an intriguing but unsolved research topic. Decades-old photos often suffer from severe and commingled degradation such as cracks, defocus, and color-fading, which are difficult to treat individually and harder to repair when they interact. Deep learning presents a plausible avenue, but the lack of large-scale datasets of old photos makes addressing this **restoration** task very challenging. Here we present a novel reference-based end-to-end learning framework that is able to both repair and colorize old, degraded pictures. Our proposed framework consists of three modules: a **restoration** sub-network that conducts **restoration** from degradations, a similarity network that performs color histogram matching and color transfer, and a colorization subnet that learns to predict the chroma elements of images conditioned on chromatic reference signals. The overall system makes uses of color histogram priors from reference images, which greatly reduces the need for large-scale training data. We have also created a first-of-a-kind public dataset of real old photos that are paired with ground truth ''pristine'' photos that have been manually restored by PhotoShop experts. We conducted extensive experiments on this dataset and synthetic datasets, and found that our method significantly outperforms previous state-of-the-art models using both qualitative comparisons and quantitative measurements. The code is available at https://github.com/DerrickXuNu/Pik-Fix.  
## eess.IV
---
### Graph-Based Depth Denoising & Dequantization for Point Cloud **Enhancement**. (arXiv:2111.04946v2 [cs.CV] UPDATED)
- Authors : Xue Zhang, Gene Cheung, Jiahao Pang, Yash Sanghvi, Abhiram Gnanasambandam
- Link : [http://arxiv.org/abs/2111.04946](http://arxiv.org/abs/2111.04946)
> ABSTRACT  :  A 3D point cloud is typically constructed from depth measurements acquired by sensors at one or more viewpoints. The measurements suffer from both quantization and noise corruption. To improve quality, previous works denoise a point cloud \textit{a posteriori} after projecting the imperfect depth data onto 3D space. Instead, we enhance depth measurements directly on the sensed images \textit{a priori}, before synthesizing a 3D point cloud. By enhancing near the physical sensing process, we tailor our optimization to our depth formation model before subsequent processing steps that obscure measurement errors.    Specifically, we model depth formation as a combined process of signal-dependent noise addition and non-uniform log-based quantization. The designed model is validated (with parameters fitted) using collected empirical data from a representative depth sensor. To enhance each pixel row in a depth image, we first encode intra-view similarities between available row pixels as edge weights via feature graph learning. We next establish inter-view similarities with another rectified depth image via viewpoint mapping and sparse linear interpolation. This leads to a maximum a posteriori (MAP) graph filtering objective that is convex and differentiable. We minimize the objective efficiently using accelerated gradient descent (AGD), where the optimal step size is approximated via Gershgorin circle theorem (GCT). Experiments show that our method significantly outperformed recent point cloud denoising schemes and state-of-the-art image denoising schemes in two established point cloud quality metrics.  
### Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
- Authors : Gerard Snaauw, Michele Sasdelli, Gabriel Maicas, Stephan Lau, Johan Verjans, Mark Jenkinson, Gustavo Carneiro, Australian Institute, for Machine, University of, South Australian, Health and, Medical Research
- Link : [http://arxiv.org/abs/2201.10305](http://arxiv.org/abs/2201.10305)
> ABSTRACT  :  Many applications in image-guided surgery and therapy require fast and reliable non-linear, multi-modal image registration. Recently proposed unsupervised deep learning-based registration methods have demonstrated superior performance compared to iterative methods in just a fraction of the time. Most of the learning-based methods have focused on mono-modal image registration. The extension to multi-modal registration depends on the use of an appropriate similarity function, such as the mutual information (MI). We propose guiding the training of a deep learning-based registration method with MI estimation between an image-pair in an end-to-end trainable network. Our results show that a small, 2-layer network produces competitive results in both mono- and multi-modal registration, with sub-second run-times. Comparisons to both iterative and deep learning-based methods show that our MI-based method produces topologically and qualitatively superior results with an extremely low rate of non-diffeomorphic transformations. **Real-time** clinical application will benefit from a better visual matching of anatomical structures and less registration failures/outliers.  
## cs.LG
---
### Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v1 [eess.SY])
- Authors : Chaolun Ma, Bruce Wang, Zihao Li, Ahmadreza Mahmoudzadeh, Yunlong Zhang
- Link : [http://arxiv.org/abs/2210.02612](http://arxiv.org/abs/2210.02612)
> ABSTRACT  :  This research studies the network traffic signal control problem. It uses the Lyapunov control function to derive the back pressure method, which is equal to differential queue lengths weighted by intersection lane flows. Lyapunov control theory is a platform that unifies several current theories for intersection signal control. We further use the theorem to derive the flow-based and other pressure-based signal control algorithms. For example, the Dynamic, Optimal, **Real-time** Algorithm for Signals (DORAS) algorithm may be derived by defining the Lyapunov function as the sum of queue length. The study then utilizes the back pressure as a reward in the reinforcement learning (RL) based network signal control, whose agent is trained with double Deep Q-Network (Double-DQN). The proposed algorithm is compared with several traditional and RL-based methods under passenger traffic flow and mixed flow with freight traffic, respectively. The numerical tests are conducted on a single corridor and on a local grid network under three traffic demand scenarios of low, medium, and heavy traffic, respectively. The numerical simulation demonstrates that the proposed algorithm outperforms the others in terms of the average vehicle waiting time on the network.  
### PSVRF: Learning to restore Pitch-Shifted Voice without reference. (arXiv:2210.02731v1 [cs.SD])
- Authors : Yangfu Li, Xiaodan Lin, Jiaxin Yang
- Link : [http://arxiv.org/abs/2210.02731](http://arxiv.org/abs/2210.02731)
> ABSTRACT  :  Pitch scaling algorithms have a significant impact on the security of Automatic Speaker Verification (ASV) systems. Although numerous anti-spoofing algorithms have been proposed to identify the pitch-shifted voice and even restore it to the original version, they either have poor performance or require the original voice as a reference, limiting the prospects of applications. In this paper, we propose a no-reference approach termed PSVRF$^1$ for high-quality **restoration** of pitch-shifted voice. Experiments on AISHELL-1 and AISHELL-3 demonstrate that PSVRF can restore the voice disguised by various pitch-scaling techniques, which obviously enhances the robustness of ASV systems to pitch-scaling attacks. Furthermore, the performance of PSVRF even surpasses that of the state-of-the-art reference-based approach.  
### CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning. (arXiv:2210.02912v1 [cs.LG])
- Authors : Samuel Maddock, Alexandre Sablayrolles, Pierre Stock
- Link : [http://arxiv.org/abs/2210.02912](http://arxiv.org/abs/2210.02912)
> ABSTRACT  :  Federated Learning (FL) is a setting for training machine learning models in distributed environments where the clients do not share their raw data but instead send model updates to a server. However, model updates can be subject to attacks and leak private information. Differential Privacy (DP) is a leading mitigation strategy which involves adding noise to clipped model updates, trading off performance for strong theoretical privacy guarantees. Previous work has shown that the threat model of DP is conservative and that the obtained guarantees may be vacuous or may not directly translate to information leakage in practice. In this paper, we aim to achieve a tighter measurement of the model **exposure** by considering a realistic threat model. We propose a novel method, CANIFE, that uses canaries - carefully crafted samples by a strong adversary to evaluate the empirical privacy of a training round. We apply this attack to vision models trained on CIFAR-10 and CelebA and to language models trained on Sent140 and Shakespeare. In particular, in realistic FL scenarios, we demonstrate that the empirical epsilon obtained with CANIFE is 2-7x lower than the theoretical bound.  
### Real-Time Detection of Anomalies in Large-Scale Transient Surveys. (arXiv:2111.00036v2 [astro-ph.IM] UPDATED)
- Authors : Daniel Muthukrishna, Michelle Lochner, Sara Webb, Gautham Narayan
- Link : [http://arxiv.org/abs/2111.00036](http://arxiv.org/abs/2111.00036)
> ABSTRACT  :  New time-domain surveys, such as the Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST), will observe millions of transient alerts each **night**, making standard approaches of visually identifying new and interesting transients infeasible. We present two novel methods of automatically detecting anomalous transient light curves in real-time. Both methods are based on the simple idea that if the light curves from a known population of transients can be accurately modelled, any deviations from model predictions are likely anomalies. The first modelling approach is a probabilistic neural network built using Temporal Convolutional Networks (TCNs) and the second is an interpretable Bayesian parametric model of a transient. We demonstrate our methods' ability to provide anomaly scores as a function of time on light curves from the Zwicky Transient Facility. We show that the flexibility of neural networks, the attribute that makes them such a powerful tool for many regression tasks, is what makes them less suitable for anomaly detection when compared with our parametric model. The parametric model is able to identify anomalies with respect to common supernova classes with high precision and recall scores, achieving area under the precision-recall curves (AUCPR) above 0.79 for most rare classes such as kilonovae, tidal disruption events, intermediate luminosity transients, and pair-instability supernovae. Our ability to identify anomalies improves over the lifetime of the light curves. Our framework, used in conjunction with transient classifiers, will enable fast and prioritised followup of unusual transients from new large-scale surveys.  
### Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
- Authors : Gerard Snaauw, Michele Sasdelli, Gabriel Maicas, Stephan Lau, Johan Verjans, Mark Jenkinson, Gustavo Carneiro, Australian Institute, for Machine, University of, South Australian, Health and, Medical Research
- Link : [http://arxiv.org/abs/2201.10305](http://arxiv.org/abs/2201.10305)
> ABSTRACT  :  Many applications in image-guided surgery and therapy require fast and reliable non-linear, multi-modal image registration. Recently proposed unsupervised deep learning-based registration methods have demonstrated superior performance compared to iterative methods in just a fraction of the time. Most of the learning-based methods have focused on mono-modal image registration. The extension to multi-modal registration depends on the use of an appropriate similarity function, such as the mutual information (MI). We propose guiding the training of a deep learning-based registration method with MI estimation between an image-pair in an end-to-end trainable network. Our results show that a small, 2-layer network produces competitive results in both mono- and multi-modal registration, with sub-second run-times. Comparisons to both iterative and deep learning-based methods show that our MI-based method produces topologically and qualitatively superior results with an extremely low rate of non-diffeomorphic transformations. **Real-time** clinical application will benefit from a better visual matching of anatomical structures and less registration failures/outliers.  
### MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v2 [cs.CV] UPDATED)
- Authors : Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen
- Link : [http://arxiv.org/abs/2203.17272](http://arxiv.org/abs/2203.17272)
> ABSTRACT  :  We introduce MyStyle, a personalized deep generative prior trained with a few shots of an individual. MyStyle allows to reconstruct, enhance and edit images of a specific person, such that the output is faithful to the person's key facial characteristics. Given a small reference set of portrait images of a person (~100), we tune the weights of a pretrained StyleGAN face generator to form a local, low-dimensional, personalized manifold in the latent space. We show that this manifold constitutes a personalized region that spans latent codes associated with diverse portrait images of the individual. Moreover, we demonstrate that we obtain a personalized generative prior, and propose a unified approach to apply it to various ill-posed image **enhancement** problems, such as inpainting and super-resolution, as well as semantic editing. Using the personalized generative prior we obtain outputs that exhibit high-fidelity to the input images and are also faithful to the key facial characteristics of the individual in the reference set. We demonstrate our method with fair-use images of numerous widely recognizable individuals for whom we have the prior knowledge for a qualitative evaluation of the expected outcome. We evaluate our approach against few-shots baselines and show that our personalized prior, quantitatively and qualitatively, outperforms state-of-the-art alternatives.  
## cs.AI
---
### Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v1 [eess.SY])
- Authors : Chaolun Ma, Bruce Wang, Zihao Li, Ahmadreza Mahmoudzadeh, Yunlong Zhang
- Link : [http://arxiv.org/abs/2210.02612](http://arxiv.org/abs/2210.02612)
> ABSTRACT  :  This research studies the network traffic signal control problem. It uses the Lyapunov control function to derive the back pressure method, which is equal to differential queue lengths weighted by intersection lane flows. Lyapunov control theory is a platform that unifies several current theories for intersection signal control. We further use the theorem to derive the flow-based and other pressure-based signal control algorithms. For example, the Dynamic, Optimal, **Real-time** Algorithm for Signals (DORAS) algorithm may be derived by defining the Lyapunov function as the sum of queue length. The study then utilizes the back pressure as a reward in the reinforcement learning (RL) based network signal control, whose agent is trained with double Deep Q-Network (Double-DQN). The proposed algorithm is compared with several traditional and RL-based methods under passenger traffic flow and mixed flow with freight traffic, respectively. The numerical tests are conducted on a single corridor and on a local grid network under three traffic demand scenarios of low, medium, and heavy traffic, respectively. The numerical simulation demonstrates that the proposed algorithm outperforms the others in terms of the average vehicle waiting time on the network.  
### Morality, Machines and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents. (arXiv:2103.02728v3 [cs.AI] UPDATED)
- Authors : Cosmin Badea, Gregory Artus
- Link : [http://arxiv.org/abs/2103.02728](http://arxiv.org/abs/2103.02728)
> ABSTRACT  :  We present what we call the Interpretation Problem, whereby any rule in symbolic form is open to infinite interpretation in ways that we might disapprove of and argue that any attempt to build morality into machines is subject to it. We show how the Interpretation Problem in Artificial Intelligence is an illustration of Wittgenstein's general claim that no rule can contain the criteria for its own application, and that the risks created by this problem escalate in proportion to the degree to which to machine is causally connected to the world, in what we call the Law of Interpretative **Exposure**. Using game theory, we attempt to define the structure of normative spaces and argue that any rule-following within a normative space is guided by values that are external to that space and which cannot themselves be represented as rules. In light of this, we categorise the types of mistakes an artificial moral agent could make into Mistakes of Intention and Instrumental Mistakes, and we propose ways of building morality into machines by getting them to interpret the rules we give in accordance with these external values, through explicit moral reasoning, the Show, not Tell paradigm, the adjustment of causal power and structure of the agent, and relational values, with the ultimate aim that the machine develop a virtuous character and that the impact of the Interpretation Problem is minimised.  
### Pik-Fix: Restoring and Colorizing Old Photos. (arXiv:2205.01902v3 [cs.CV] UPDATED)
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Alan Bovik, Hongkai Yu
- Link : [http://arxiv.org/abs/2205.01902](http://arxiv.org/abs/2205.01902)
> ABSTRACT  :  Restoring and inpainting the visual memories that are present, but often impaired, in old photos remains an intriguing but unsolved research topic. Decades-old photos often suffer from severe and commingled degradation such as cracks, defocus, and color-fading, which are difficult to treat individually and harder to repair when they interact. Deep learning presents a plausible avenue, but the lack of large-scale datasets of old photos makes addressing this **restoration** task very challenging. Here we present a novel reference-based end-to-end learning framework that is able to both repair and colorize old, degraded pictures. Our proposed framework consists of three modules: a **restoration** sub-network that conducts **restoration** from degradations, a similarity network that performs color histogram matching and color transfer, and a colorization subnet that learns to predict the chroma elements of images conditioned on chromatic reference signals. The overall system makes uses of color histogram priors from reference images, which greatly reduces the need for large-scale training data. We have also created a first-of-a-kind public dataset of real old photos that are paired with ground truth ''pristine'' photos that have been manually restored by PhotoShop experts. We conducted extensive experiments on this dataset and synthetic datasets, and found that our method significantly outperforms previous state-of-the-art models using both qualitative comparisons and quantitative measurements. The code is available at https://github.com/DerrickXuNu/Pik-Fix.  
# Paper List
---
## cs.CV
---
**120** new papers in cs.CV:-) 
1. Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive Networks. (arXiv:2210.02445v1 [eess.IV])
2. BaseTransformers: Attention over base data-points for One Shot Learning. (arXiv:2210.02476v1 [cs.CV])
3. Depth Is All You Need for Monocular 3D Detection. (arXiv:2210.02493v1 [cs.CV])
4. On Adversarial Robustness of Deep Image Deblurring. (arXiv:2210.02502v1 [cs.CV])
5. TartanCalib: Iterative Wide-Angle Lens Calibration using Adaptive SubPixel Refinement of AprilTags. (arXiv:2210.02511v1 [cs.CV])
6. Dual-Domain Cross-Iteration Squeeze-Excitation Network for Sparse Reconstruction of Brain MRI. (arXiv:2210.02523v1 [cs.CV])
7. Towards Semi-automatic Detection and Localization of Indoor Accessibility Issues using Mobile Depth Scanning and Computer Vision. (arXiv:2210.02533v1 [cs.HC])
8. Water Simulation and Rendering from a Still Photograph. (arXiv:2210.02553v1 [cs.GR])
9. Reading Chinese in Natural Scenes with a Bag-of-Radicals Prior. (arXiv:2210.02576v1 [cs.CV])
10. AOE-Net: Entities Interactions Modeling with Adaptive Attention Mechanism for Temporal Action Proposals Generation. (arXiv:2210.02578v1 [cs.CV])
11. DigiFace-1M: 1 Million Digital Face Images for Face Recognition. (arXiv:2210.02579v1 [cs.CV])
12. Transferring dense object detection models to event-based data. (arXiv:2210.02607v1 [cs.CV])
13. Dynamic Stochastic Ensemble with Adversarial Robust Lottery Ticket Subnetworks. (arXiv:2210.02618v1 [cs.CV])
14. Research on the quantity and brightness evolution characteristics of Photospheric Bright Points groups. (arXiv:2210.02635v1 [astro-ph.SR])
15. IR2Net: Information Restriction and Information Recovery for Accurate Binary Neural Networks. (arXiv:2210.02637v1 [cs.CV])
16. Domain Generalization via Contrastive Causal Learning. (arXiv:2210.02655v1 [cs.CV])
17. Towards Better Semantic Understanding of Mobile Interfaces. (arXiv:2210.02663v1 [cs.HC])
18. Vision-Based Defect Classification and Weight Estimation of Rice Kernels. (arXiv:2210.02665v1 [cs.CV])
19. Neural Matching Fields: Implicit Representation of Matching Fields for Visual Correspondence. (arXiv:2210.02689v1 [cs.CV])
20. Focal and Global Spatial-Temporal Transformer for Skeleton-based Action Recognition. (arXiv:2210.02693v1 [cs.CV])
21. DexGraspNet: A Large-Scale Robotic Dexterous Grasp Dataset for General Objects Based on Simulation. (arXiv:2210.02697v1 [cs.RO])
22. FedGraph: an Aggregation Method from Graph Perspective. (arXiv:2210.02733v1 [cs.CV])
23. MuS2: A Benchmark for Sentinel-2 Multi-Image Super-Resolution. (arXiv:2210.02745v1 [eess.IV])
24. CLAD: A Contrastive Learning based Approach for Background Debiasing. (arXiv:2210.02748v1 [cs.CV])
25. Audio-Visual Face Reenactment. (arXiv:2210.02755v1 [cs.CV])
26. Learning Consistency-Aware Unsigned Distance Functions Progressively from Raw Point Clouds. (arXiv:2210.02757v1 [cs.CV])
27. Vision Transformer Based Model for Describing a Set of Images as a Story. (arXiv:2210.02762v1 [cs.CV])
28. FloatingFusion: Depth from ToF and Image-stabilized Stereo Cameras. (arXiv:2210.02785v1 [cs.CV])
29. Data Augmentation-free Unsupervised Learning for 3D Point Cloud Understanding. (arXiv:2210.02798v1 [cs.CV])
30. Effective Self-supervised Pre-training on Low-compute networks without Distillation. (arXiv:2210.02808v1 [cs.CV])
31. Robust Double-Encoder Network for RGB-D Panoptic Segmentation. (arXiv:2210.02834v1 [cs.CV])
32. CIR-Net: Cross-modality Interaction and Refinement for RGB-D Salient Object Detection. (arXiv:2210.02843v1 [cs.CV])
33. Smooth Non-Rigid Shape Matching via Effective Dirichlet Energy Optimization. (arXiv:2210.02870v1 [cs.CV])
34. Self-Distillation for Further Pre-training of Transformers. (arXiv:2210.02871v1 [cs.CV])
35. Text-driven Video Prediction. (arXiv:2210.02872v1 [cs.CV])
36. Vision+X: A Survey on Multimodal Learning in the Light of Data. (arXiv:2210.02884v1 [cs.CV])
37. RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank. (arXiv:2210.02885v1 [cs.LG])
38. MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text. (arXiv:2210.02928v1 [cs.CL])
39. A Review of Uncertainty Calibration in Pretrained Object Detectors. (arXiv:2210.02935v1 [cs.CV])
40. Video Referring Expression Comprehension via Transformer with Content-aware Query. (arXiv:2210.02953v1 [cs.CV])
41. The Lie Derivative for Measuring Learned Equivariance. (arXiv:2210.02984v1 [cs.LG])
42. Cross-Modality Domain Adaptation for Freespace Detection: A Simple yet Effective Baseline. (arXiv:2210.02991v1 [cs.CV])
43. COVID-19 Detection Using Segmentation, Region Extraction and Classification Pipeline. (arXiv:2210.02992v1 [eess.IV])
44. Compressed Vision for Efficient Video Understanding. (arXiv:2210.02995v1 [cs.CV])
45. A Novel Attention Mechanism Using Anatomical Prior Probability Maps for Thoracic Disease Classification from X-Ray Images. (arXiv:2210.02998v1 [eess.IV])
46. XDGAN: Multi-Modal 3D Shape Generation in 2D Space. (arXiv:2210.03007v1 [cs.CV])
47. Rolling Shutter Inversion: Bring Rolling Shutter Images to High Framerate Global Shutter Video. (arXiv:2210.03040v1 [cs.CV])
48. Feature-Realistic Neural Fusion for Real-Time, Open Set Scene Understanding. (arXiv:2210.03043v1 [cs.CV])
49. Structure Representation Network and Uncertainty Feedback Learning for Dense Non-Uniform Fog Removal. (arXiv:2210.03061v1 [cs.CV])
50. IJCB 2022 Mobile Behavioral Biometrics Competition (MobileB2C). (arXiv:2210.03072v1 [cs.CV])
51. Iterative Vision-and-Language Navigation. (arXiv:2210.03087v1 [cs.CV])
52. Ambiguous Images With Human Judgments for Robust Visual Event Classification. (arXiv:2210.03102v1 [cs.CV])
53. Env-Aware Anomaly Detection: Ignore Style Changes, Stay True to Content!. (arXiv:2210.03103v1 [cs.CV])
54. Mask3D for 3D Semantic Instance Segmentation. (arXiv:2210.03105v1 [cs.CV])
55. Real-World Robot Learning with Masked Visual Pre-training. (arXiv:2210.03109v1 [cs.RO])
56. A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. (arXiv:2210.03112v1 [cs.LG])
57. CLIP model is an Efficient Continual Learner. (arXiv:2210.03114v1 [cs.CV])
58. SimPer: Simple Self-Supervised Learning of Periodic Targets. (arXiv:2210.03115v1 [cs.LG])
59. Content-Based Search for Deep Generative Models. (arXiv:2210.03116v1 [cs.CV])
60. MaPLe: Multi-modal Prompt Learning. (arXiv:2210.03117v1 [cs.CV])
61. Unsupervised confidence for LiDAR depth maps and applications. (arXiv:2210.03118v1 [cs.CV])
62. Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation. (arXiv:2002.01048v2 [cs.CV] UPDATED)
63. Denoising Diffusion Implicit Models. (arXiv:2010.02502v4 [cs.LG] UPDATED)
64. Sill-Net: Feature Augmentation with Separated Illumination Representation. (arXiv:2102.03539v3 [cs.CV] UPDATED)
65. Unsupervised Image Transformation Learning via Generative Adversarial Networks. (arXiv:2103.07751v2 [cs.CV] UPDATED)
66. Initialization and Regularization of Factorized Neural Layers. (arXiv:2105.01029v2 [stat.ML] UPDATED)
67. Cosmic-CoNN: A Cosmic Ray Detection Deep-Learning Framework, Dataset, and Toolkit. (arXiv:2106.14922v3 [astro-ph.IM] UPDATED)
68. A data-centric approach for improving ambiguous labels with combined semi-supervised classification and clustering. (arXiv:2106.16209v4 [cs.CV] UPDATED)
69. Reservoir Computing Approach for Gray Images Segmentation. (arXiv:2107.11077v3 [cs.CV] UPDATED)
70. Bayesian Embeddings for Few-Shot Open World Recognition. (arXiv:2107.13682v2 [cs.CV] UPDATED)
71. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v6 [cs.CV] UPDATED)
72. Cross-Region Domain Adaptation for Class-level Alignment. (arXiv:2109.06422v2 [cs.CV] UPDATED)
73. Graph-Based Depth Denoising & Dequantization for Point Cloud **Enhancement**. (arXiv:2111.04946v2 [cs.CV] UPDATED)
74. OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images. (arXiv:2111.14341v4 [cs.CV] UPDATED)
75. EM-driven unsupervised learning for efficient motion segmentation. (arXiv:2201.02074v3 [cs.CV] UPDATED)
76. Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
77. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v4 [cs.CV] UPDATED)
78. Finding Directions in GAN's Latent Space for Neural Face Reenactment. (arXiv:2202.00046v2 [cs.CV] UPDATED)
79. LayoutEnhancer: Generating Good Indoor Layouts from Imperfect Data. (arXiv:2202.00185v2 [cs.GR] UPDATED)
80. Conditional Motion In-betweening. (arXiv:2202.04307v2 [cs.CV] UPDATED)
81. A Principled Design of Image Representation: Towards Forensic Tasks. (arXiv:2203.00913v4 [cs.CV] UPDATED)
82. KPE: Keypoint Pose Encoding for Transformer-based Image Generation. (arXiv:2203.04907v2 [cs.CV] UPDATED)
83. Conditional Prompt Learning for Vision-Language Models. (arXiv:2203.05557v2 [cs.CV] UPDATED)
84. Data Efficient 3D Learner via Knowledge Transferred from 2D Model. (arXiv:2203.08479v3 [cs.CV] UPDATED)
85. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v4 [cs.LG] UPDATED)
86. FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks. (arXiv:2203.13371v2 [cs.CV] UPDATED)
87. MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v2 [cs.CV] UPDATED)
88. Pik-Fix: Restoring and Colorizing Old Photos. (arXiv:2205.01902v3 [cs.CV] UPDATED)
89. TextMatcher: Cross-Attentional Neural Network to Compare Image and Text. (arXiv:2205.05507v2 [cs.CV] UPDATED)
90. Visual Attention-based Self-supervised Absolute Depth Estimation using Geometric Priors in Autonomous Driving. (arXiv:2205.08780v3 [cs.CV] UPDATED)
91. Learning What and Where -- Unsupervised Disentangling Location and Identity Tracking. (arXiv:2205.13349v2 [cs.CV] UPDATED)
92. Circumventing Backdoor Defenses That Are Based on Latent Separability. (arXiv:2205.13613v2 [cs.LG] UPDATED)
93. V4D: Voxel for 4D Novel View Synthesis. (arXiv:2205.14332v2 [cs.CV] UPDATED)
94. Supernet Training for Federated Image Classification under System Heterogeneity. (arXiv:2206.01366v5 [cs.LG] UPDATED)
95. Satellite-based high-resolution maps of cocoa for C\^ote d'Ivoire and Ghana. (arXiv:2206.06119v3 [cs.CV] UPDATED)
96. Back to MLP: A Simple Baseline for Human Motion Prediction. (arXiv:2207.01567v3 [cs.CV] UPDATED)
97. The Power of Transfer Learning in Agricultural Applications: AgriNet. (arXiv:2207.03881v3 [cs.CV] UPDATED)
98. Beyond Hard Labels: Investigating data label distributions. (arXiv:2207.06224v2 [cs.CV] UPDATED)
99. Implicit Neural Representations for Generative Modeling of Living Cell Shapes. (arXiv:2207.06283v2 [cs.CV] UPDATED)
100. Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams). (arXiv:2207.10960v2 [cs.GR] UPDATED)
101. Opportunistic hip fracture risk prediction in Men from X-ray: Findings from the Osteoporosis in Men (MrOS) Study. (arXiv:2207.10970v2 [cs.CV] UPDATED)
102. Joint Attention-Driven Domain Fusion and Noise-Tolerant Learning for Multi-Source Domain Adaptation. (arXiv:2208.02947v2 [cs.CV] UPDATED)
103. Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale. (arXiv:2208.09796v2 [cs.CV] UPDATED)
104. The Value of Out-of-Distribution Data. (arXiv:2208.10967v2 [cs.LG] UPDATED)
105. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v2 [cs.CV] UPDATED)
106. On the Surprising Effectiveness of Transformers in Low-Labeled Video Recognition. (arXiv:2209.07474v2 [cs.CV] UPDATED)
107. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v2 [cs.CV] UPDATED)
108. MGTR: End-to-End Mutual Gaze Detection with Transformer. (arXiv:2209.10930v2 [cs.CV] UPDATED)
109. A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective. (arXiv:2209.13232v2 [cs.CV] UPDATED)
110. Motion and Appearance Adaptation for Cross-Domain Motion Transfer. (arXiv:2209.14529v2 [cs.CV] UPDATED)
111. Bounded Future MS-TCN++ for surgical gesture recognition. (arXiv:2209.14647v2 [cs.CV] UPDATED)
112. MobileViTv3: Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features. (arXiv:2209.15159v2 [cs.CV] UPDATED)
113. Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain Supervision for Domain-adaptive Action Detection. (arXiv:2209.15439v2 [cs.CV] UPDATED)
114. Where Should I Spend My FLOPS? Efficiency Evaluations of Visual Pre-training Methods. (arXiv:2209.15589v3 [cs.CV] UPDATED)
115. Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language. (arXiv:2210.00482v2 [cs.LG] UPDATED)
116. BVI-VFI: A Video Quality Database for Video Frame Interpolation. (arXiv:2210.00823v2 [eess.IV] UPDATED)
117. Collecting The Puzzle Pieces: Disentangled Self-Driven Human Pose Transfer by Permuting Textures. (arXiv:2210.01887v2 [cs.CV] UPDATED)
118. When and why vision-language models behave like bags-of-words, and what to do about it?. (arXiv:2210.01936v2 [cs.CV] UPDATED)
119. The Calibration Generalization Gap. (arXiv:2210.01964v2 [cs.LG] UPDATED)
120. Advanced Deep Learning Architectures for Accurate Detection of Subsurface Tile Drainage Pipes from Remote Sensing Images. (arXiv:2210.02071v2 [cs.CV] UPDATED)
## eess.IV
---
**17** new papers in eess.IV:-) 
1. Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive Networks. (arXiv:2210.02445v1 [eess.IV])
2. On Adversarial Robustness of Deep Image Deblurring. (arXiv:2210.02502v1 [cs.CV])
3. SPICE: Self-Supervised Learning for MRI with Automatic Coil Sensitivity Estimation. (arXiv:2210.02584v1 [eess.IV])
4. Lung2Lung: Volumetric Style Transfer with Self-Ensembling for High-Resolution Cross-Volume Computed Tomography. (arXiv:2210.02625v1 [eess.IV])
5. MuS2: A Benchmark for Sentinel-2 Multi-Image Super-Resolution. (arXiv:2210.02745v1 [eess.IV])
6. CLAD: A Contrastive Learning based Approach for Background Debiasing. (arXiv:2210.02748v1 [cs.CV])
7. COVID-19 Detection Using Segmentation, Region Extraction and Classification Pipeline. (arXiv:2210.02992v1 [eess.IV])
8. A Novel Attention Mechanism Using Anatomical Prior Probability Maps for Thoracic Disease Classification from X-Ray Images. (arXiv:2210.02998v1 [eess.IV])
9. Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation. (arXiv:2002.01048v2 [cs.CV] UPDATED)
10. Reservoir Computing Approach for Gray Images Segmentation. (arXiv:2107.11077v3 [cs.CV] UPDATED)
11. Graph-Based Depth Denoising & Dequantization for Point Cloud **Enhancement**. (arXiv:2111.04946v2 [cs.CV] UPDATED)
12. Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
13. Learning Nonlocal Sparse and Low-Rank Models for Image Compressive Sensing. (arXiv:2203.09656v5 [eess.IV] UPDATED)
14. Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review. (arXiv:2206.11233v3 [q-bio.NC] UPDATED)
15. A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathological Images. (arXiv:2208.07655v3 [eess.IV] UPDATED)
16. BVI-VFI: A Video Quality Database for Video Frame Interpolation. (arXiv:2210.00823v2 [eess.IV] UPDATED)
17. Advanced Deep Learning Architectures for Accurate Detection of Subsurface Tile Drainage Pipes from Remote Sensing Images. (arXiv:2210.02071v2 [cs.CV] UPDATED)
## cs.LG
---
**218** new papers in cs.LG:-) 
1. Localizing Anatomical Landmarks in Ocular Images using Zoom-In Attentive Networks. (arXiv:2210.02445v1 [eess.IV])
2. Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models. (arXiv:2210.02447v1 [cs.LG])
3. TgDLF2.0: Theory-guided deep-learning for electrical load forecasting via Transformer and transfer learning. (arXiv:2210.02448v1 [cs.LG])
4. DEGAN: Time Series Anomaly Detection using Generative Adversarial Network Discriminators and Density Estimation. (arXiv:2210.02449v1 [cs.LG])
5. Learning from aggregated data with a maximum entropy model. (arXiv:2210.02450v1 [cs.LG])
6. BaseTransformers: Attention over base data-points for One Shot Learning. (arXiv:2210.02476v1 [cs.CV])
7. Fisher information lower bounds for sampling. (arXiv:2210.02482v1 [stat.ML])
8. Analyzing historical diagnosis code data from NIH N3C and RECOVER Programs using deep learning to determine risk factors for Long Covid. (arXiv:2210.02490v1 [cs.LG])
9. Honest Students from Untrusted Teachers: Learning an Interpretable Question-Answering Pipeline from a Pretrained Language Model. (arXiv:2210.02498v1 [cs.CL])
10. A novel non-linear transformation based multi-user identification algorithm for fixed text keystroke behavioral dynamics. (arXiv:2210.02505v1 [eess.SP])
11. Learning with Limited Samples -- Meta-Learning and Applications to Communication Systems. (arXiv:2210.02515v1 [cs.LG])
12. Equalizing Credit Opportunity in Algorithms: Aligning Algorithmic Fairness Research with U.S. Fair Lending Regulation. (arXiv:2210.02516v1 [cs.LG])
13. Toward Knowledge-Driven Speech-Based Models of Depression: Leveraging Spectrotemporal Variations in Speech Vowels. (arXiv:2210.02527v1 [cs.LG])
14. Deep learning for ECoG brain-computer interface: end-to-end vs. hand-crafted features. (arXiv:2210.02544v1 [eess.SP])
15. Benchmarking Learning Efficiency in Deep Reservoir Computing. (arXiv:2210.02549v1 [cs.LG])
16. Towards Safe Mechanical Ventilation Treatment Using Deep Offline Reinforcement Learning. (arXiv:2210.02552v1 [cs.LG])
17. Improved Anomaly Detection by Using the Attention-Based Isolation Forest. (arXiv:2210.02558v1 [cs.LG])
18. Dueling Convex Optimization with General Preferences. (arXiv:2210.02562v1 [math.OC])
19. Revisiting Structured Dropout. (arXiv:2210.02570v1 [cs.LG])
20. Bi-Stride Multi-Scale Graph Neural Network for Mesh-Based Physical Simulation. (arXiv:2210.02573v1 [cs.LG])
21. A Closer Look at Robustness to L-infinity and Spatial Perturbations and their Composition. (arXiv:2210.02577v1 [cs.LG])
22. Functional Labeled Optimal Partitioning. (arXiv:2210.02580v1 [cs.LG])
23. Query The Agent: Improving sample efficiency through epistemic uncertainty estimation. (arXiv:2210.02585v1 [cs.LG])
24. Star-Graph Multimodal Matching Component Analysis for Data Fusion and Transfer Learning. (arXiv:2210.02590v1 [cs.LG])
25. Reward-Mixing MDPs with a Few Latent Contexts are Learnable. (arXiv:2210.02594v1 [cs.LG])
26. From Threat Reports to Continuous Threat Intelligence: A Comparison of Attack Technique Extraction Methods from Textual Artifacts. (arXiv:2210.02601v1 [cs.CR])
27. Spectral Regularization Allows Data-frugal Learning over Combinatorial Spaces. (arXiv:2210.02604v1 [stat.ML])
28. Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v1 [eess.SY])
29. Federated Learning with Server Learning: Enhancing Performance for Non-IID Data. (arXiv:2210.02614v1 [cs.LG])
30. Learning to Reason With Relational Abstractions. (arXiv:2210.02615v1 [cs.LG])
31. Digital Twin-Empowered Network Planning for Multi-Tier Computing. (arXiv:2210.02616v1 [cs.NI])
32. Generalization Properties of Retrieval-based Models. (arXiv:2210.02617v1 [cs.LG])
33. Inference Latency Prediction at the Edge. (arXiv:2210.02620v1 [cs.PF])
34. Training Diverse High-Dimensional Controllers by Scaling Covariance Matrix Adaptation MAP-Annealing. (arXiv:2210.02622v1 [cs.RO])
35. TensorAnalyzer: Identification of Urban Patterns in Big Cities using Non-Negative Tensor Factorization. (arXiv:2210.02623v1 [cs.LG])
36. MechRetro is a chemical-mechanism-driven graph learning framework for interpretable retrosynthesis prediction and pathway planning. (arXiv:2210.02630v1 [cs.LG])
37. Data-driven Approaches to Surrogate Machine Learning Model Development. (arXiv:2210.02631v1 [cs.LG])
38. Geodesic Graph Neural Network for Efficient Graph Representation Learning. (arXiv:2210.02636v1 [cs.LG])
39. Learning Algorithms for Intelligent Agents and Mechanisms. (arXiv:2210.02654v1 [cs.LG])
40. Trust in Motion: Capturing Trust Ascendancy in Open-Source Projects using Hybrid AI. (arXiv:2210.02656v1 [cs.SE])
41. Predictive Edge Caching through Deep Mining of Sequential Patterns in User Content Retrievals. (arXiv:2210.02657v1 [cs.NI])
42. Topological Continual Learning with Wasserstein Distance and Barycenter. (arXiv:2210.02661v1 [cs.LG])
43. Towards Better Semantic Understanding of Mobile Interfaces. (arXiv:2210.02663v1 [cs.HC])
44. When not to use machine learning: a perspective on potential and limitations. (arXiv:2210.02666v1 [cs.LG])
45. Transformers Implement First-Order Logic with Majority Quantifiers. (arXiv:2210.02671v1 [cs.LG])
46. Orthogonal Non-negative Matrix Factorization: a Maximum-Entropy-Principle Approach. (arXiv:2210.02672v1 [cs.DS])
47. Uncertainty Estimation for Multi-view Data: The Power of Seeing the Whole Picture. (arXiv:2210.02676v1 [cs.LG])
48. Effective Metaheuristic Based Classifiers for Multiclass Intrusion Detection. (arXiv:2210.02678v1 [cs.CR])
49. DReS-FL: Dropout-Resilient Secure Federated Learning for Non-IID Clients via Secret Data Sharing. (arXiv:2210.02680v1 [cs.LG])
50. Conformal Isometry of Lie Group Representation in Recurrent Network of Grid Cells. (arXiv:2210.02684v1 [q-bio.NC])
51. Probabilistic partition of unity networks for high-dimensional regression problems. (arXiv:2210.02694v1 [cs.LG])
52. Block-Structured Optimization for Subgraph Detection in Interdependent Networks. (arXiv:2210.02702v1 [cs.LG])
53. hyperbox-brain: A Toolbox for Hyperbox-based Machine Learning Algorithms. (arXiv:2210.02704v1 [cs.LG])
54. On Optimal Learning Under Targeted Data Poisoning. (arXiv:2210.02713v1 [cs.LG])
55. Continuous Diagnosis and Prognosis by Controlling the Update Process of Deep Neural Networks. (arXiv:2210.02719v1 [cs.LG])
56. Understanding Gradient Regularization in Deep Learning: Efficient Finite-Difference Computation and Implicit Bias. (arXiv:2210.02720v1 [cs.LG])
57. Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision. (arXiv:2210.02724v1 [cs.LG])
58. Join-Chain Network: A Logical Reasoning View of the Multi-head Attention in Transformer. (arXiv:2210.02729v1 [cs.CL])
59. PSVRF: Learning to restore Pitch-Shifted Voice without reference. (arXiv:2210.02731v1 [cs.SD])
60. Spatial-Temporal Graph Convolutional Gated Recurrent Network for Traffic Forecasting. (arXiv:2210.02737v1 [cs.LG])
61. The Sound of Silence: Efficiency of First Digit Features in Synthetic Audio Detection. (arXiv:2210.02746v1 [cs.SD])
62. Flow Matching for Generative Modeling. (arXiv:2210.02747v1 [cs.LG])
63. CLAD: A Contrastive Learning based Approach for Background Debiasing. (arXiv:2210.02748v1 [cs.CV])
64. AutoQC: Automated Synthesis of Quantum Circuits Using Neural Network. (arXiv:2210.02766v1 [cs.SE])
65. Modelling Commonsense Properties using Pre-Trained Bi-Encoders. (arXiv:2210.02771v1 [cs.CL])
66. Paging with Succinct Predictions. (arXiv:2210.02775v1 [cs.LG])
67. Why Should I Choose You? AutoXAI: A Framework for Selecting and Tuning eXplainable AI Solutions. (arXiv:2210.02795v1 [cs.LG])
68. Hypernetwork approach to Bayesian MAML. (arXiv:2210.02796v1 [cs.LG])
69. Melody Infilling with User-Provided Structural Context. (arXiv:2210.02829v1 [cs.SD])
70. Matching Text and Audio Embeddings: Exploring Transfer-learning Strategies for Language-based Audio Retrieval. (arXiv:2210.02833v1 [cs.IR])
71. Detecting Irregular Network Activity with Adversarial Learning and Expert Feedback. (arXiv:2210.02841v1 [cs.CR])
72. Anomaly detection using data depth: multivariate case. (arXiv:2210.02851v1 [stat.ML])
73. NeuDep: Neural Binary Memory Dependence Analysis. (arXiv:2210.02853v1 [cs.CR])
74. Causal Inference for Chatting Handoff. (arXiv:2210.02862v1 [cs.AI])
75. Self-Distillation for Further Pre-training of Transformers. (arXiv:2210.02871v1 [cs.CV])
76. Blockchain-based Monitoring for Poison Attack Detection in Decentralized Federated Learning. (arXiv:2210.02873v1 [cs.CR])
77. Antibody Representation Learning for Drug Discovery. (arXiv:2210.02881v1 [q-bio.QM])
78. Scaling up Stochastic Gradient Descent for Non-convex Optimisation. (arXiv:2210.02882v1 [stat.ML])
79. RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank. (arXiv:2210.02885v1 [cs.LG])
80. Transferring Knowledge for Reinforcement Learning in Contact-Rich Manipulation. (arXiv:2210.02891v1 [cs.RO])
81. Embedding-Assisted Attentional Deep Learning for Real-World RF Fingerprinting of Bluetooth. (arXiv:2210.02897v1 [cs.NI])
82. Self-supervised Learning for Clustering of Wireless Spectrum Activity. (arXiv:2210.02899v1 [cs.NI])
83. Joint Entropy Search for Multi-objective Bayesian Optimization. (arXiv:2210.02905v1 [cs.LG])
84. Federated Boosted Decision Trees with Differential Privacy. (arXiv:2210.02910v1 [cs.CR])
85. CANIFE: Crafting Canaries for Empirical Privacy Measurement in Federated Learning. (arXiv:2210.02912v1 [cs.LG])
86. Communication-Efficient and Drift-Robust Federated Learning via Elastic Net. (arXiv:2210.02940v1 [cs.LG])
87. VLSNR:Vision-Linguistics Coordination Time Sequence-aware News Recommendation. (arXiv:2210.02946v1 [cs.IR])
88. POPNASv2: An Efficient Multi-Objective Neural Architecture Search Technique. (arXiv:2210.02959v1 [cs.LG])
89. Designing a Robust Low-Level Agnostic Controller for a Quadrotor with Actor-Critic Reinforcement Learning. (arXiv:2210.02964v1 [cs.RO])
90. Few-shot Generation of Personalized Neural Surrogates for Cardiac Simulation via Bayesian Meta-Learning. (arXiv:2210.02967v1 [cs.LG])
91. Fault Diagnosis using eXplainable AI: a Transfer Learning-based Approach for Rotating Machinery exploiting Augmented Synthetic Data. (arXiv:2210.02974v1 [cs.AI])
92. The Lie Derivative for Measuring Learned Equivariance. (arXiv:2210.02984v1 [cs.LG])
93. SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data. (arXiv:2210.02989v1 [cs.LG])
94. COVID-19 Detection Using Segmentation, Region Extraction and Classification Pipeline. (arXiv:2210.02992v1 [eess.IV])
95. Expander Graph Propagation. (arXiv:2210.02997v1 [cs.LG])
96. A Novel Attention Mechanism Using Anatomical Prior Probability Maps for Thoracic Disease Classification from X-Ray Images. (arXiv:2210.02998v1 [eess.IV])
97. To Softmax, or not to Softmax: that is the question when applying Active Learning for Transformer Models. (arXiv:2210.03005v1 [cs.LG])
98. XDGAN: Multi-Modal 3D Shape Generation in 2D Space. (arXiv:2210.03007v1 [cs.CV])
99. Residual-based error correction for neural operator accelerated infinite-dimensional Bayesian inverse problems. (arXiv:2210.03008v1 [math.NA])
100. Uncovering the Structural Fairness in Graph Contrastive Learning. (arXiv:2210.03011v1 [cs.LG])
101. Stateful active facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2210.03022v1 [cs.AI])
102. Learning many-body Hamiltonians with Heisenberg-limited scaling. (arXiv:2210.03030v1 [quant-ph])
103. Feature-Realistic Neural Fusion for Real-Time, Open Set Scene Understanding. (arXiv:2210.03043v1 [cs.CV])
104. Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?. (arXiv:2210.03044v1 [cs.LG])
105. Conditional Feature Importance for Mixed Data. (arXiv:2210.03047v1 [stat.ML])
106. ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs. (arXiv:2210.03052v1 [cs.LG])
107. Reinforcement Learning with Large Action Spaces for Neural Machine Translation. (arXiv:2210.03053v1 [cs.CL])
108. Language Models are Multilingual Chain-of-Thought Reasoners. (arXiv:2210.03057v1 [cs.CL])
109. Few-Shot Calibration of Set Predictors via Meta-Learned Cross-Validation-Based Conformal Prediction. (arXiv:2210.03067v1 [stat.ML])
110. InferES : A Natural Language Inference Corpus for Spanish Featuring Negation-Based Contrastive and Adversarial Examples. (arXiv:2210.03068v1 [cs.CL])
111. A Better Way to Decay: Proximal Gradient Training Algorithms for Neural Nets. (arXiv:2210.03069v1 [cs.LG])
112. Edge-Varying Fourier Graph Networks for Multivariate Time Series Forecasting. (arXiv:2210.03093v1 [cs.LG])
113. VIMA: General Robot Manipulation with Multimodal Prompts. (arXiv:2210.03094v1 [cs.RO])
114. Accelerated Single-Call Methods for Constrained Min-Max Optimization. (arXiv:2210.03096v1 [math.OC])
115. Distributionally Adaptive Meta Reinforcement Learning. (arXiv:2210.03104v1 [cs.LG])
116. Real-World Robot Learning with Masked Visual Pre-training. (arXiv:2210.03109v1 [cs.RO])
117. A New Path: Scaling Vision-and-Language Navigation with Synthetic Instructions and Imitation Learning. (arXiv:2210.03112v1 [cs.LG])
118. IR-MCL: Implicit Representation-Based Online Global Localization. (arXiv:2210.03113v1 [cs.RO])
119. SimPer: Simple Self-Supervised Learning of Periodic Targets. (arXiv:2210.03115v1 [cs.LG])
120. Content-Based Search for Deep Generative Models. (arXiv:2210.03116v1 [cs.CV])
121. Minimum Stein Discrepancy Estimators. (arXiv:1906.08283v3 [math.ST] UPDATED)
122. Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation. (arXiv:2002.01048v2 [cs.CV] UPDATED)
123. FedCVT: Semi-supervised Vertical Federated Learning with Cross-view Training. (arXiv:2008.10838v2 [cs.LG] UPDATED)
124. Denoising Diffusion Implicit Models. (arXiv:2010.02502v4 [cs.LG] UPDATED)
125. Spectral clustering via adaptive layer aggregation for multi-layer networks. (arXiv:2012.04646v2 [stat.ML] UPDATED)
126. Learning Setup Policies: Reliable Transition Between Locomotion Behaviours. (arXiv:2101.09391v2 [cs.RO] UPDATED)
127. Fair and Optimal Cohort Selection for Linear Utilities. (arXiv:2102.07684v3 [cs.DS] UPDATED)
128. Who's Afraid of Adversarial Transferability?. (arXiv:2105.00433v3 [cs.LG] UPDATED)
129. Initialization and Regularization of Factorized Neural Layers. (arXiv:2105.01029v2 [stat.ML] UPDATED)
130. Efficient Sequence Packing without Cross-contamination: Accelerating Large Language Models without Impacting Performance. (arXiv:2107.02027v2 [cs.CL] UPDATED)
131. Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage. (arXiv:2107.06226v3 [cs.LG] UPDATED)
132. Epistemic Neural Networks. (arXiv:2107.08924v6 [cs.LG] UPDATED)
133. Reservoir Computing Approach for Gray Images Segmentation. (arXiv:2107.11077v3 [cs.CV] UPDATED)
134. Staged trees and asymmetry-labeled DAGs. (arXiv:2108.01994v2 [stat.ML] UPDATED)
135. Neural Operator: Learning Maps Between Function Spaces. (arXiv:2108.08481v4 [cs.LG] UPDATED)
136. Accelerating Federated Learning with a Global Biased Optimiser. (arXiv:2108.09134v3 [cs.LG] UPDATED)
137. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v6 [cs.CV] UPDATED)
138. An Apparatus for the Simulation of Breathing Disorders: Physically Meaningful Generation of Surrogate Data. (arXiv:2109.06699v2 [physics.med-ph] UPDATED)
139. HPOBench: A Collection of Reproducible Multi-Fidelity Benchmark Problems for HPO. (arXiv:2109.06716v3 [cs.LG] UPDATED)
140. Exoplanet atmosphere evolution: emulation with neural networks. (arXiv:2110.15162v2 [astro-ph.EP] UPDATED)
141. Real-Time Detection of Anomalies in Large-Scale Transient Surveys. (arXiv:2111.00036v2 [astro-ph.IM] UPDATED)
142. OCR-free Document Understanding Transformer. (arXiv:2111.15664v5 [cs.LG] UPDATED)
143. Mutual information neural estimation for unsupervised multi-modal registration of brain images. (arXiv:2201.10305v2 [eess.IV] UPDATED)
144. Deep Generative Model for Periodic Graphs. (arXiv:2201.11932v4 [cs.LG] UPDATED)
145. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v4 [cs.CV] UPDATED)
146. Differentially Private Speaker Anonymization. (arXiv:2202.11823v2 [cs.SD] UPDATED)
147. Structured Multi-task Learning for Molecular Property Prediction. (arXiv:2203.04695v2 [q-bio.BM] UPDATED)
148. Conditional Prompt Learning for Vision-Language Models. (arXiv:2203.05557v2 [cs.CV] UPDATED)
149. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v4 [cs.LG] UPDATED)
150. Transfer Learning Framework for Low-Resource Text-to-Speech using a Large-Scale Unlabeled Speech Corpus. (arXiv:2203.15447v2 [eess.AS] UPDATED)
151. Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback for Unbiased Learning to Rank. (arXiv:2203.17118v3 [cs.LG] UPDATED)
152. MyStyle: A Personalized Generative Prior. (arXiv:2203.17272v2 [cs.CV] UPDATED)
153. Truth Serum: Poisoning Machine Learning Models to Reveal Their Secrets. (arXiv:2204.00032v2 [cs.CR] UPDATED)
154. Uncoupled Learning Dynamics with $O(\log T)$ Swap Regret in Multiplayer Games. (arXiv:2204.11417v2 [cs.GT] UPDATED)
155. VICE: Variational Interpretable Concept Embeddings. (arXiv:2205.00756v8 [cs.LG] UPDATED)
156. DeeptDCS: Deep Learning-Based Estimation of Currents Induced During Transcranial Direct Current Stimulation. (arXiv:2205.01858v2 [q-bio.QM] UPDATED)
157. Toward a Geometrical Understanding of Self-supervised Contrastive Learning. (arXiv:2205.06926v2 [cs.LG] UPDATED)
158. RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning. (arXiv:2205.12548v2 [cs.CL] UPDATED)
159. Towards a Fair Comparison and Realistic Evaluation Framework of Android Malware Detectors based on Static Analysis and Machine Learning. (arXiv:2205.12569v2 [cs.CR] UPDATED)
160. Circumventing Backdoor Defenses That Are Based on Latent Separability. (arXiv:2205.13613v2 [cs.LG] UPDATED)
161. So3krates: Equivariant attention for interactions on arbitrary length-scales in molecular systems. (arXiv:2205.14276v2 [cs.LG] UPDATED)
162. Go Beyond Multiple Instance Neural Networks: Deep-learning Models based on Local Pattern Aggregation. (arXiv:2205.14428v2 [cs.LG] UPDATED)
163. Provable General Function Class Representation Learning in Multitask Bandits and MDPs. (arXiv:2205.15701v2 [cs.LG] UPDATED)
164. Supernet Training for Federated Image Classification under System Heterogeneity. (arXiv:2206.01366v5 [cs.LG] UPDATED)
165. Optimal Weak to Strong Learning. (arXiv:2206.01563v3 [cs.LG] UPDATED)
166. Pursuit of a Discriminative Representation for Multiple Subspaces via Sequential Games. (arXiv:2206.09120v2 [stat.ML] UPDATED)
167. General Univariate Estimation-of-Distribution Algorithms. (arXiv:2206.11198v3 [cs.NE] UPDATED)
168. Automatic autism spectrum disorder detection using artificial intelligence methods with MRI neuroimaging: A review. (arXiv:2206.11233v3 [q-bio.NC] UPDATED)
169. Constrained Stochastic Nonconvex Optimization with State-dependent Markov Data. (arXiv:2206.11346v3 [math.OC] UPDATED)
170. Non-Determinism and the Lawlessness of Machine Learning Code. (arXiv:2206.11834v3 [cs.CY] UPDATED)
171. Conditionally Elicitable Dynamic Risk Measures for Deep Reinforcement Learning. (arXiv:2206.14666v2 [cs.LG] UPDATED)
172. Populating Memory in Continual Learning with Consistency Aware Sampling. (arXiv:2207.01145v2 [cs.LG] UPDATED)
173. Neural Networks and the Chomsky Hierarchy. (arXiv:2207.02098v2 [cs.LG] UPDATED)
174. The Power of Transfer Learning in Agricultural Applications: AgriNet. (arXiv:2207.03881v3 [cs.CV] UPDATED)
175. Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning. (arXiv:2207.05480v2 [cs.LG] UPDATED)
176. Beyond Hard Labels: Investigating data label distributions. (arXiv:2207.06224v2 [cs.CV] UPDATED)
177. Implicit Neural Representations for Generative Modeling of Living Cell Shapes. (arXiv:2207.06283v2 [cs.CV] UPDATED)
178. Multimodal hierarchical Variational AutoEncoders with Factor Analysis latent space. (arXiv:2207.09185v2 [cs.LG] UPDATED)
179. Controllable Data Generation by Deep Learning: A Review. (arXiv:2207.09542v5 [cs.LG] UPDATED)
180. Principal Geodesic Analysis of Merge Trees (and Persistence Diagrams). (arXiv:2207.10960v2 [cs.GR] UPDATED)
181. INTERACT: Achieving Low Sample and Communication Complexities in Decentralized Bilevel Learning over Networks. (arXiv:2207.13283v3 [cs.LG] UPDATED)
182. Best-of-Both-Worlds Algorithms for Partial Monitoring. (arXiv:2207.14550v2 [cs.LG] UPDATED)
183. A Game-Theoretic Perspective of Generalization in Reinforcement Learning. (arXiv:2208.03650v2 [cs.LG] UPDATED)
184. Simplified State Space Layers for Sequence Modeling. (arXiv:2208.04933v2 [cs.LG] UPDATED)
185. Bias amplification in experimental social networks is reduced by resampling. (arXiv:2208.07261v2 [cs.SI] UPDATED)
186. The Value of Out-of-Distribution Data. (arXiv:2208.10967v2 [cs.LG] UPDATED)
187. Estimation of Correlation Matrices from Limited time series Data using Machine Learning. (arXiv:2209.01198v2 [cs.LG] UPDATED)
188. Efficient search of active inference policy spaces using k-means. (arXiv:2209.02550v3 [cs.LG] UPDATED)
189. Applying Transformer-based Text Summarization for Keyphrase Generation. (arXiv:2209.03791v2 [cs.CL] UPDATED)
190. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v2 [cs.CV] UPDATED)
191. Rethink Decision Tree Traversal. (arXiv:2209.04825v2 [cs.LG] UPDATED)
192. Pre-training Transformers on Indian Legal Text. (arXiv:2209.06049v2 [cs.CL] UPDATED)
193. Classical Sequence Match is a Competitive Few-Shot One-Class Learner. (arXiv:2209.06394v2 [cs.LG] UPDATED)
194. On the detrimental effect of invariances in the likelihood for variational inference. (arXiv:2209.07157v2 [cs.LG] UPDATED)
195. On the Surprising Effectiveness of Transformers in Low-Labeled Video Recognition. (arXiv:2209.07474v2 [cs.CV] UPDATED)
196. Hub-aware Random Walk Graph Embedding Methods for Classification. (arXiv:2209.07603v2 [cs.LG] UPDATED)
197. Is Stochastic Gradient Descent Near Optimal?. (arXiv:2209.08627v2 [cs.LG] UPDATED)
198. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v2 [cs.CV] UPDATED)
199. Optimization of Annealed Importance Sampling Hyperparameters. (arXiv:2209.13226v2 [stat.ML] UPDATED)
200. A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective. (arXiv:2209.13232v2 [cs.CV] UPDATED)
201. Biological connectomes as a representation for the architecture of artificial neural networks. (arXiv:2209.14406v2 [cs.NE] UPDATED)
202. Stop Wasting My Time! Saving Days of ImageNet and BERT Training with Latest Weight Averaging. (arXiv:2209.14981v2 [cs.LG] UPDATED)
203. MobileViTv3: Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features. (arXiv:2209.15159v2 [cs.CV] UPDATED)
204. Where Should I Spend My FLOPS? Efficiency Evaluations of Visual Pre-training Methods. (arXiv:2209.15589v3 [cs.CV] UPDATED)
205. Grouped self-attention mechanism for a memory-efficient Transformer. (arXiv:2210.00440v2 [cs.LG] UPDATED)
206. Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language. (arXiv:2210.00482v2 [cs.LG] UPDATED)
207. Efficient acoustic feature transformation in mismatched environments using a Guided-GAN. (arXiv:2210.00721v3 [cs.SD] UPDATED)
208. Limitations of neural network training due to numerical instability of backpropagation. (arXiv:2210.00805v2 [cs.LG] UPDATED)
209. On Stability and Generalization of Bilevel Optimization Problem. (arXiv:2210.01063v2 [cs.LG] UPDATED)
210. Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications. (arXiv:2210.01162v2 [cs.RO] UPDATED)
211. Multi-objective Deep Data Generation with Correlated Property Control. (arXiv:2210.01796v2 [cs.LG] UPDATED)
212. When and why vision-language models behave like bags-of-words, and what to do about it?. (arXiv:2210.01936v2 [cs.CV] UPDATED)
213. A Framework for Large Scale Synthetic Graph Dataset Generation. (arXiv:2210.01944v2 [cs.LG] UPDATED)
214. The Calibration Generalization Gap. (arXiv:2210.01964v2 [cs.LG] UPDATED)
215. Evaluate & Evaluation on the Hub: Better Best Practices for Data and Model Measurements. (arXiv:2210.01970v2 [cs.LG] UPDATED)
216. Advanced Deep Learning Architectures for Accurate Detection of Subsurface Tile Drainage Pipes from Remote Sensing Images. (arXiv:2210.02071v2 [cs.CV] UPDATED)
217. A Fourier Approach to Mixture Learning. (arXiv:2210.02415v2 [cs.LG] UPDATED)
218. Convex and Nonconvex Sublinear Regression with Application to Data-driven Learning of Reach Sets. (arXiv:2210.01919v1 [eess.SY] CROSS LISTED)
## cs.AI
---
**124** new papers in cs.AI:-) 
1. Practical Adversarial Attacks on Spatiotemporal Traffic Forecasting Models. (arXiv:2210.02447v1 [cs.LG])
2. DEGAN: Time Series Anomaly Detection using Generative Adversarial Network Discriminators and Density Estimation. (arXiv:2210.02449v1 [cs.LG])
3. Learning from aggregated data with a maximum entropy model. (arXiv:2210.02450v1 [cs.LG])
4. BaseTransformers: Attention over base data-points for One Shot Learning. (arXiv:2210.02476v1 [cs.CV])
5. Token Classification for Disambiguating Medical Abbreviations. (arXiv:2210.02487v1 [cs.CL])
6. Analyzing historical diagnosis code data from NIH N3C and RECOVER Programs using deep learning to determine risk factors for Long Covid. (arXiv:2210.02490v1 [cs.LG])
7. Dual-Domain Cross-Iteration Squeeze-Excitation Network for Sparse Reconstruction of Brain MRI. (arXiv:2210.02523v1 [cs.CV])
8. Revisiting Structured Dropout. (arXiv:2210.02570v1 [cs.LG])
9. Reading Chinese in Natural Scenes with a Bag-of-Radicals Prior. (arXiv:2210.02576v1 [cs.CV])
10. Query The Agent: Improving sample efficiency through epistemic uncertainty estimation. (arXiv:2210.02585v1 [cs.LG])
11. Lyapunov Function Consistent Adaptive Network Signal Control with Back Pressure and Reinforcement Learning. (arXiv:2210.02612v1 [eess.SY])
12. Learning to Reason With Relational Abstractions. (arXiv:2210.02615v1 [cs.LG])
13. TensorAnalyzer: Identification of Urban Patterns in Big Cities using Non-Negative Tensor Factorization. (arXiv:2210.02623v1 [cs.LG])
14. Feasibility on Detecting Door Slamming towards Monitoring Early Signs of Domestic Violence. (arXiv:2210.02642v1 [cs.SD])
15. Automatic Scene-based Topic Channel Construction System for E-Commerce. (arXiv:2210.02643v1 [cs.CL])
16. Learning Algorithms for Intelligent Agents and Mechanisms. (arXiv:2210.02654v1 [cs.LG])
17. Vision-Based Defect Classification and Weight Estimation of Rice Kernels. (arXiv:2210.02665v1 [cs.CV])
18. A Human Rights-Based Approach to Responsible AI. (arXiv:2210.02667v1 [cs.AI])
19. Block-Structured Optimization for Subgraph Detection in Interdependent Networks. (arXiv:2210.02702v1 [cs.LG])
20. Flow Matching for Generative Modeling. (arXiv:2210.02747v1 [cs.LG])
21. CLAD: A Contrastive Learning based Approach for Background Debiasing. (arXiv:2210.02748v1 [cs.CV])
22. Meta Reinforcement Learning for Optimal Design of Legged Robots. (arXiv:2210.02750v1 [cs.RO])
23. Vision Transformer Based Model for Describing a Set of Images as a Story. (arXiv:2210.02762v1 [cs.CV])
24. Artificial virtuous agents in a multiagent tragedy of the commons. (arXiv:2210.02769v1 [cs.AI])
25. Modelling Commonsense Properties using Pre-Trained Bi-Encoders. (arXiv:2210.02771v1 [cs.CL])
26. Hypernetwork approach to Bayesian MAML. (arXiv:2210.02796v1 [cs.LG])
27. Just ClozE! A Fast and Simple Method for Evaluating the Factual Consistency in Abstractive Summarization. (arXiv:2210.02804v1 [cs.CL])
28. A Review of Multilingualism in and for Ontologies. (arXiv:2210.02807v1 [cs.AI])
29. KnowledgeShovel: An AI-in-the-Loop Document Annotation System for Scientific Knowledge Base Construction. (arXiv:2210.02830v1 [cs.DL])
30. Deep Reinforcement Learning based Evasion Generative Adversarial Network for Botnet Detection. (arXiv:2210.02840v1 [cs.CR])
31. Causal Inference for Chatting Handoff. (arXiv:2210.02862v1 [cs.AI])
32. Blockchain-based Monitoring for Poison Attack Detection in Decentralized Federated Learning. (arXiv:2210.02873v1 [cs.CR])
33. RankMe: Assessing the downstream performance of pretrained self-supervised representations by their rank. (arXiv:2210.02885v1 [cs.LG])
34. Transferring Knowledge for Reinforcement Learning in Contact-Rich Manipulation. (arXiv:2210.02891v1 [cs.RO])
35. Embedding-Assisted Attentional Deep Learning for Real-World RF Fingerprinting of Bluetooth. (arXiv:2210.02897v1 [cs.NI])
36. Learning Disentangled Representations for Natural Language Definitions. (arXiv:2210.02898v1 [cs.CL])
37. Self-supervised Learning for Clustering of Wireless Spectrum Activity. (arXiv:2210.02899v1 [cs.NI])
38. Generative Entity Typing with Curriculum Learning. (arXiv:2210.02914v1 [cs.CL])
39. MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text. (arXiv:2210.02928v1 [cs.CL])
40. Data-Driven Meets Navigation: Concepts, Models, and Experimental Validation. (arXiv:2210.02930v1 [cs.RO])
41. Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question Answering. (arXiv:2210.02933v1 [cs.CL])
42. Communication-Efficient and Drift-Robust Federated Learning via Elastic Net. (arXiv:2210.02940v1 [cs.LG])
43. VLSNR:Vision-Linguistics Coordination Time Sequence-aware News Recommendation. (arXiv:2210.02946v1 [cs.IR])
44. POPNASv2: An Efficient Multi-Objective Neural Architecture Search Technique. (arXiv:2210.02959v1 [cs.LG])
45. Fault Diagnosis using eXplainable AI: a Transfer Learning-based Approach for Rotating Machinery exploiting Augmented Synthetic Data. (arXiv:2210.02974v1 [cs.AI])
46. The Lie Derivative for Measuring Learned Equivariance. (arXiv:2210.02984v1 [cs.LG])
47. Cross-Modality Domain Adaptation for Freespace Detection: A Simple yet Effective Baseline. (arXiv:2210.02991v1 [cs.CV])
48. Synergistic information supports modality integration and flexible learning in neural networks solving multiple tasks. (arXiv:2210.02996v1 [q-bio.NC])
49. Expander Graph Propagation. (arXiv:2210.02997v1 [cs.LG])
50. Enhancing Code Classification by Mixup-Based Data Augmentation. (arXiv:2210.03003v1 [cs.SE])
51. To Softmax, or not to Softmax: that is the question when applying Active Learning for Transformer Models. (arXiv:2210.03005v1 [cs.LG])
52. Explanations as Programs in Probabilistic Logic Programming. (arXiv:2210.03021v1 [cs.AI])
53. Stateful active facilitator: Coordination and Environmental Heterogeneity in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2210.03022v1 [cs.AI])
54. Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization. (arXiv:2210.03029v1 [cs.CL])
55. Conversational Semantic Role Labeling with Predicate-Oriented Latent Graph. (arXiv:2210.03037v1 [cs.CL])
56. Unmasking the Lottery Ticket Hypothesis: What's Encoded in a Winning Ticket's Mask?. (arXiv:2210.03044v1 [cs.LG])
57. State-of-the-art generalisation research in NLP: a taxonomy and review. (arXiv:2210.03050v1 [cs.CL])
58. Reinforcement Learning with Large Action Spaces for Neural Machine Translation. (arXiv:2210.03053v1 [cs.CL])
59. Language Models are Multilingual Chain-of-Thought Reasoners. (arXiv:2210.03057v1 [cs.CL])
60. InferES : A Natural Language Inference Corpus for Spanish Featuring Negation-Based Contrastive and Adversarial Examples. (arXiv:2210.03068v1 [cs.CL])
61. Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering. (arXiv:2210.03078v1 [cs.CL])
62. Edge-Varying Fourier Graph Networks for Multivariate Time Series Forecasting. (arXiv:2210.03093v1 [cs.LG])
63. VIMA: General Robot Manipulation with Multimodal Prompts. (arXiv:2210.03094v1 [cs.RO])
64. Ambiguous Images With Human Judgments for Robust Visual Event Classification. (arXiv:2210.03102v1 [cs.CV])
65. Distributionally Adaptive Meta Reinforcement Learning. (arXiv:2210.03104v1 [cs.LG])
66. IR-MCL: Implicit Representation-Based Online Global Localization. (arXiv:2210.03113v1 [cs.RO])
67. SimPer: Simple Self-Supervised Learning of Periodic Targets. (arXiv:2210.03115v1 [cs.LG])
68. Adversarial Attack and Defense on Graph Data: A Survey. (arXiv:1812.10528v4 [cs.CR] UPDATED)
69. Learning Setup Policies: Reliable Transition Between Locomotion Behaviours. (arXiv:2101.09391v2 [cs.RO] UPDATED)
70. Morality, Machines and the Interpretation Problem: A Value-based, Wittgensteinian Approach to Building Moral Agents. (arXiv:2103.02728v3 [cs.AI] UPDATED)
71. Initialization and Regularization of Factorized Neural Layers. (arXiv:2105.01029v2 [stat.ML] UPDATED)
72. Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage. (arXiv:2107.06226v3 [cs.LG] UPDATED)
73. Epistemic Neural Networks. (arXiv:2107.08924v6 [cs.LG] UPDATED)
74. Staged trees and asymmetry-labeled DAGs. (arXiv:2108.01994v2 [stat.ML] UPDATED)
75. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v6 [cs.CV] UPDATED)
76. Cross-Region Domain Adaptation for Class-level Alignment. (arXiv:2109.06422v2 [cs.CV] UPDATED)
77. An Apparatus for the Simulation of Breathing Disorders: Physically Meaningful Generation of Surrogate Data. (arXiv:2109.06699v2 [physics.med-ph] UPDATED)
78. OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images. (arXiv:2111.14341v4 [cs.CV] UPDATED)
79. OCR-free Document Understanding Transformer. (arXiv:2111.15664v5 [cs.LG] UPDATED)
80. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v4 [cs.CV] UPDATED)
81. Finding Directions in GAN's Latent Space for Neural Face Reenactment. (arXiv:2202.00046v2 [cs.CV] UPDATED)
82. LayoutEnhancer: Generating Good Indoor Layouts from Imperfect Data. (arXiv:2202.00185v2 [cs.GR] UPDATED)
83. Conditional Motion In-betweening. (arXiv:2202.04307v2 [cs.CV] UPDATED)
84. KPE: Keypoint Pose Encoding for Transformer-based Image Generation. (arXiv:2203.04907v2 [cs.CV] UPDATED)
85. Conditional Prompt Learning for Vision-Language Models. (arXiv:2203.05557v2 [cs.CV] UPDATED)
86. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v4 [cs.LG] UPDATED)
87. Towards a Stronger Theory for Permutation-based Evolutionary Algorithms. (arXiv:2204.07637v2 [cs.NE] UPDATED)
88. Pik-Fix: Restoring and Colorizing Old Photos. (arXiv:2205.01902v3 [cs.CV] UPDATED)
89. Machine Learning Diffusion Monte Carlo Energies. (arXiv:2205.04547v2 [cond-mat.mes-hall] UPDATED)
90. Toward a Geometrical Understanding of Self-supervised Contrastive Learning. (arXiv:2205.06926v2 [cs.LG] UPDATED)
91. Least-to-Most Prompting Enables Complex Reasoning in Large Language Models. (arXiv:2205.10625v2 [cs.AI] UPDATED)
92. Provable General Function Class Representation Learning in Multitask Bandits and MDPs. (arXiv:2205.15701v2 [cs.LG] UPDATED)
93. Satellite-based high-resolution maps of cocoa for C\^ote d'Ivoire and Ghana. (arXiv:2206.06119v3 [cs.CV] UPDATED)
94. Definition drives design: Disability models and mechanisms of bias in AI technologies. (arXiv:2206.08287v2 [cs.AI] UPDATED)
95. General Univariate Estimation-of-Distribution Algorithms. (arXiv:2206.11198v3 [cs.NE] UPDATED)
96. Back to MLP: A Simple Baseline for Human Motion Prediction. (arXiv:2207.01567v3 [cs.CV] UPDATED)
97. Neural Networks and the Chomsky Hierarchy. (arXiv:2207.02098v2 [cs.LG] UPDATED)
98. DocPrompting: Generating Code by Retrieving the Docs. (arXiv:2207.05987v2 [cs.CL] UPDATED)
99. Multimodal hierarchical Variational AutoEncoders with Factor Analysis latent space. (arXiv:2207.09185v2 [cs.LG] UPDATED)
100. Controllable Data Generation by Deep Learning: A Review. (arXiv:2207.09542v5 [cs.LG] UPDATED)
101. A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathological Images. (arXiv:2208.07655v3 [eess.IV] UPDATED)
102. The Value of Out-of-Distribution Data. (arXiv:2208.10967v2 [cs.LG] UPDATED)
103. Efficient search of active inference policy spaces using k-means. (arXiv:2209.02550v3 [cs.LG] UPDATED)
104. Applying Transformer-based Text Summarization for Keyphrase Generation. (arXiv:2209.03791v2 [cs.CL] UPDATED)
105. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v2 [cs.CV] UPDATED)
106. Pre-training Transformers on Indian Legal Text. (arXiv:2209.06049v2 [cs.CL] UPDATED)
107. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v2 [cs.CV] UPDATED)
108. A Survey on Graph Neural Networks and Graph Transformers in Computer Vision: A Task-Oriented Perspective. (arXiv:2209.13232v2 [cs.CV] UPDATED)
109. Programmable and Customized Intelligence for Traffic Steering in 5G Networks Using Open RAN Architectures. (arXiv:2209.14171v2 [cs.NI] UPDATED)
110. Biological connectomes as a representation for the architecture of artificial neural networks. (arXiv:2209.14406v2 [cs.NE] UPDATED)
111. Motion and Appearance Adaptation for Cross-Domain Motion Transfer. (arXiv:2209.14529v2 [cs.CV] UPDATED)
112. Bounded Future MS-TCN++ for surgical gesture recognition. (arXiv:2209.14647v2 [cs.CV] UPDATED)
113. Stop Wasting My Time! Saving Days of ImageNet and BERT Training with Latest Weight Averaging. (arXiv:2209.14981v2 [cs.LG] UPDATED)
114. Quantifying Harm. (arXiv:2209.15111v2 [cs.AI] UPDATED)
115. MobileViTv3: Mobile-Friendly Vision Transformer with Simple and Effective Fusion of Local, Global and Input Features. (arXiv:2209.15159v2 [cs.CV] UPDATED)
116. Grouped self-attention mechanism for a memory-efficient Transformer. (arXiv:2210.00440v2 [cs.LG] UPDATED)
117. Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language. (arXiv:2210.00482v2 [cs.LG] UPDATED)
118. RISC-V Toolchain and Agile Development based Open-source Neuromorphic Processor. (arXiv:2210.00562v2 [cs.AR] UPDATED)
119. Learning Minimally-Violating Continuous Control for Infeasible Linear Temporal Logic Specifications. (arXiv:2210.01162v2 [cs.RO] UPDATED)
120. Multi-objective Deep Data Generation with Correlated Property Control. (arXiv:2210.01796v2 [cs.LG] UPDATED)
121. When and why vision-language models behave like bags-of-words, and what to do about it?. (arXiv:2210.01936v2 [cs.CV] UPDATED)
122. COMPS: Conceptual Minimal Pair Sentences for testing Property Knowledge and Inheritance in Pre-trained Language Models. (arXiv:2210.01963v2 [cs.CL] UPDATED)
123. The Calibration Generalization Gap. (arXiv:2210.01964v2 [cs.LG] UPDATED)
124. Convex and Nonconvex Sublinear Regression with Application to Data-driven Learning of Reach Sets. (arXiv:2210.01919v1 [eess.SY] CROSS LISTED)

