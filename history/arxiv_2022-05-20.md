# Your interest papers
---
## cs.CV
---
### **Dark** Solitons in Bose-Einstein Condensates: A Dataset for Many-body Physics Research. (arXiv:2205.09114v1 [cond-mat.quant-gas])
- Authors : Shangjie Guo
- Link : [http://arxiv.org/abs/2205.09114](http://arxiv.org/abs/2205.09114)
> ABSTRACT  :  We establish a dataset of over $1.6\times10^4$ experimental images of Bose-Einstein condensates containing solitonic excitations to enable machine learning (ML) for many-body physics research. About 33 % of this dataset has manually assigned and carefully curated labels. The remainder is automatically labeled using SolDet -- an implementation of a physics-informed ML data analysis framework -- consisting of a convolutional-neural-network-based classifier and object detector as well as a statistically motivated physics-informed classifier and a quality metric. This technical note constitutes the definitive reference of the dataset, providing an opportunity for the data science community to develop more sophisticated analysis tools, to further understand nonlinear many-body physics, and even advance cold atom experiments.  
### Support-set based Multi-modal Representation **Enhancement** for Video Captioning. (arXiv:2205.09307v1 [cs.CV])
- Authors : Xiaoya Chen, Jingkuan Song, Pengpeng Zeng, Lianli Gao, Heng Tao
- Link : [http://arxiv.org/abs/2205.09307](http://arxiv.org/abs/2205.09307)
> ABSTRACT  :  Video captioning is a challenging task that necessitates a thorough comprehension of visual scenes. Existing methods follow a typical one-to-one mapping, which concentrates on a limited sample space while ignoring the intrinsic semantic associations between samples, resulting in rigid and uninformative expressions. To address this issue, we propose a novel and flexible framework, namely Support-set based Multi-modal Representation **Enhancement** (SMRE) model, to mine rich information in a semantic subspace shared between samples. Specifically, we propose a Support-set Construction (SC) module to construct a support-set to learn underlying connections between samples and obtain semantic-related visual elements. During this process, we design a Semantic Space Transformation (SST) module to constrain relative distance and administrate multi-modal interactions in a self-supervised way. Extensive experiments on MSVD and MSR-VTT datasets demonstrate that our SMRE achieves state-of-the-art performance.  
### Physically-Based Editing of Indoor Scene Lighting from a Single Image. (arXiv:2205.09343v1 [cs.CV])
- Authors : Zhengqin Li, Jia Shi, Sai Bi, Rui Zhu, Kalyan Sunkavalli, Zexiang Xu, Ravi Ramamoorthi, Manmohan Chandraker
- Link : [http://arxiv.org/abs/2205.09343](http://arxiv.org/abs/2205.09343)
> ABSTRACT  :  We present a method to edit complex indoor lighting from a single image with its predicted depth and light source segmentation masks. This is an extremely challenging problem that requires modeling complex light transport, and disentangling **HDR** lighting from material and geometry with only a partial LDR observation of the scene. We tackle this problem using two novel components: 1) a holistic scene reconstruction method that estimates scene reflectance and parametric 3D lighting, and 2) a neural rendering framework that re-renders the scene from our predictions. We use physically-based indoor light representations that allow for intuitive editing, and infer both visible and invisible light sources. Our neural rendering framework combines physically-based direct illumination and shadow rendering with deep networks to approximate global illumination. It can capture challenging lighting effects, such as soft shadows, directional lighting, specular materials, and interreflections. Previous single image inverse rendering methods usually entangle scene lighting and geometry and only support applications like object insertion. Instead, by combining parametric 3D lighting estimation with neural scene rendering, we demonstrate the first automatic method to achieve full scene relighting, including light source insertion, removal, and replacement, from a single image. All source code and data will be publicly released.  
### Mip-**NeRF** RGB-D: Depth Assisted Fast Neural Radiance Fields. (arXiv:2205.09351v1 [cs.CV])
- Authors : Arnab Dey, Yassine Ahmine
- Link : [http://arxiv.org/abs/2205.09351](http://arxiv.org/abs/2205.09351)
> ABSTRACT  :  Neural scene representations, such as neural radiance fields (**NeRF**), are based on training a multilayer perceptron (MLP) using a set of color images with known poses. An increasing number of devices now produce RGB-D information, which has been shown to be very important for a wide range of tasks. Therefore, the aim of this paper is to investigate what improvements can be made to these promising implicit representations by incorporating depth information with the color images. In particular, the recently proposed Mip-**NeRF** approach, which uses conical frustums instead of rays for volume rendering, allows one to account for the varying area of a pixel with distance from the camera center. The proposed method additionally models depth uncertainty. This allows to address major limitations of **NeRF**-based approaches including improving the accuracy of geometry, reduced artifacts, faster training time, and shortened prediction time. Experiments are performed on well-known benchmark scenes, and comparisons show improved accuracy in scene geometry and photometric reconstruction, while reducing the training time by 3 - 5 times.  
### UIF: An Objective Quality Assessment for Underwater Image **Enhancement**. (arXiv:2205.09392v1 [cs.CV])
- Authors : Yannan Zheng, Weiling Chen, Rongfu Lin, Tiesong Zhao
- Link : [http://arxiv.org/abs/2205.09392](http://arxiv.org/abs/2205.09392)
> ABSTRACT  :  Due to complex and volatile lighting environment, underwater imaging can be readily impaired by light scattering, warping, and noises. To improve the visual quality, Underwater Image **Enhancement** (UIE) techniques have been widely studied. Recent efforts have also been contributed to evaluate and compare the UIE performances with subjective and objective methods. However, the subjective evaluation is time-consuming and uneconomic for all images, while existing objective methods have limited capabilities for the newly-developed UIE approaches based on deep learning. To fill this gap, we propose an Underwater Image Fidelity (UIF) metric for objective evaluation of enhanced underwater images. By exploiting the statistical features of these images, we present to extract naturalness-related, sharpness-related, and structure-related features. Among them, the naturalness-related and sharpness-related features evaluate visual improvement of enhanced images; the structure-related feature indicates structural similarity between images before and after UIE. Then, we employ support vector regression to fuse the above three features into a final UIF metric. In addition, we have also established a large-scale UIE database with subjective scores, namely Underwater Image **Enhancement** Database (UIED), which is utilized as a benchmark to compare all objective metrics. Experimental results confirm that the proposed UIF outperforms a variety of underwater and general-purpose image quality metrics.  
### Cross-**Enhancement** Transformer for Action Segmentation. (arXiv:2205.09445v1 [cs.CV])
- Authors : Jiahui Wang, Zhenyou Wang, Shanna Zhuang, Hui Wang
- Link : [http://arxiv.org/abs/2205.09445](http://arxiv.org/abs/2205.09445)
> ABSTRACT  :  Temporal convolutions have been the paradigm of choice in action segmentation, which enhances long-term receptive fields by increasing convolution layers. However, high layers cause the loss of local information necessary for frame recognition. To solve the above problem, a novel encoder-decoder structure is proposed in this paper, called Cross-**Enhancement** Transformer. Our approach can be effective learning of temporal structure representation with interactive self-attention mechanism. Concatenated each layer convolutional feature maps in encoder with a set of features in decoder produced via self-attention. Therefore, local and global information are used in a series of frame actions simultaneously. In addition, a new loss function is proposed to enhance the training process that penalizes over-segmentation errors. Experiments show that our framework performs state-of-the-art on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities and the Breakfast dataset.  
### Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning. (arXiv:2205.09542v1 [cs.CV])
- Authors : Yuxin Zhang, Fan Tang, Weiming Dong, Haibin Huang, Chongyang Ma, Yee Lee, Changsheng Xu
- Link : [http://arxiv.org/abs/2205.09542](http://arxiv.org/abs/2205.09542)
> ABSTRACT  :  In this work, we tackle the challenging problem of arbitrary image style transfer using a novel style feature representation learning method. A suitable style representation, as a key component in image stylization tasks, is essential to achieve satisfactory results. Existing deep neural network based approaches achieve reasonable results with the guidance from second-order statistics such as Gram matrix of content features. However, they do not leverage sufficient style information, which results in artifacts such as local distortions and style inconsistency. To address these issues, we propose to learn style representation directly from image features instead of their second-order statistics, by analyzing the similarities and differences between multiple styles and considering the style distribution. Specifically, we present Contrastive Arbitrary Style Transfer (CAST), which is a new style representation learning and style transfer method via contrastive learning. Our framework consists of three key components, i.e., a multi-layer style projector for style code encoding, a domain **enhancement** module for effective learning of style distribution, and a generative network for image style transfer. We conduct qualitative and quantitative evaluations comprehensively to demonstrate that our approach achieves significantly better results compared to those obtained via state-of-the-art methods. Code and models are available at https://github.com/zyxElsa/CAST_pytorch  
### On Trace of PGD-Like Adversarial Attacks. (arXiv:2205.09586v1 [cs.CV])
- Authors : Mo Zhou
- Link : [http://arxiv.org/abs/2205.09586](http://arxiv.org/abs/2205.09586)
> ABSTRACT  :  Adversarial attacks pose safety and security concerns for deep learning applications. Yet largely imperceptible, a strong PGD-like attack may leave strong trace in the adversarial example. Since attack triggers the local linearity of a network, we speculate network behaves in different extents of linearity for benign examples and adversarial examples. Thus, we construct Adversarial Response Characteristics (ARC) features to reflect the model's gradient consistency around the input to indicate the extent of linearity. Under certain conditions, it shows a gradually varying pattern from benign example to adversarial example, as the later leads to Sequel Attack Effect (SAE). ARC feature can be used for informed attack detection (perturbation magnitude is known) with binary classifier, or uninformed attack detection (perturbation magnitude is unknown) with ordinal regression. Due to the uniqueness of SAE to PGD-like attacks, ARC is also capable of inferring other attack details such as loss function, or the ground-truth label as a post-processing defense. Qualitative and quantitative evaluations manifest the effectiveness of ARC feature on CIFAR-10 w/ ResNet-18 and ImageNet w/ ResNet-152 and **Swin**T-B-IN1K with considerable generalization among PGD-like attacks despite domain shift. Our method is intuitive, light-weighted, non-intrusive, and data-undemanding.  
### CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning. (arXiv:2112.04564v3 [cs.CV] UPDATED)
- Authors : Yue Fan, Dengxin Dai, Anna Kukleva, Bernt Schiele
- Link : [http://arxiv.org/abs/2112.04564](http://arxiv.org/abs/2112.04564)
> ABSTRACT  :  In this paper, we propose a novel co-learning framework (CoSSL) with decoupled representation learning and classifier learning for imbalanced SSL. To handle the data imbalance, we devise Tail-class Feature **Enhancement** (TFE) for classifier learning. Furthermore, the current evaluation protocol for imbalanced SSL focuses only on balanced test sets, which has limited practicality in real-world scenarios. Therefore, we further conduct a comprehensive evaluation under various shifted test distributions. In experiments, we show that our approach outperforms other methods over a large range of shifted distributions, achieving state-of-the-art performance on benchmark datasets ranging from CIFAR-10, CIFAR-100, ImageNet, to Food-101. Our code will be made publicly available.  
### On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v2 [physics.med-ph] UPDATED)
- Authors : Nicholas Hindley, Neha Koonjoo, Christopher Chiu, Tess Reynolds, Bo Zhu, Danyal Bhutto, Chiara Paganelli
- Link : [http://arxiv.org/abs/2202.05267](http://arxiv.org/abs/2202.05267)
> ABSTRACT  :  MRI-guidance techniques that dynamically adapt radiation beams to follow tumor motion in real-time will lead to more accurate cancer treatments and reduced collateral healthy tissue damage. The gold-standard for reconstruction of undersampled MR data is compressed sensing (CS) which is computationally slow and limits the rate that images can be available for real-time adaptation. Here, we demonstrate the use of automated transform by manifold approximation (AUTOMAP), a generalized framework that maps raw MR signal to the target image domain, to rapidly reconstruct images from undersampled radial k-space data. The AUTOMAP neural network was trained to reconstruct images from a golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on lung cancer patient data and generic images from ImageNet. Model training was subsequently augmented with motion-encoded k-space data derived from videos in the YouTube-8M dataset to encourage motion robust reconstruction. We find that AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with much shorter processing times after initial fine-tuning on retrospectively acquired lung cancer patient data. Validation of motion-trained models with a virtual dynamic lung tumor phantom showed that the generalized motion properties learned from YouTube lead to improved target tracking accuracy. Our work shows that AUTOMAP can achieve real-time, accurate reconstruction of radial data. These findings imply that neural-network-based reconstruction is potentially superior to existing approaches for real-time image guidance applications.  
### Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection. (arXiv:2204.02964v2 [cs.CV] UPDATED)
- Authors : Yuxin Fang, Shusheng Yang, Shijie Wang, Yixiao Ge, Ying Shan, Xinggang Wang
- Link : [http://arxiv.org/abs/2204.02964](http://arxiv.org/abs/2204.02964)
> ABSTRACT  :  We present an approach to efficiently and effectively adapt a masked image modeling (MIM) pre-trained vanilla Vision Transformer (ViT) for object detection, which is based on our two novel observations: (i) A MIM pre-trained vanilla ViT encoder can work surprisingly well in the challenging object-level recognition scenario even with randomly sampled partial observations, e.g., only 25% $\sim$ 50% of the input embeddings. (ii) In order to construct multi-scale representations for object detection from single-scale ViT, a randomly initialized compact convolutional stem supplants the pre-trained large kernel patchify stem, and its intermediate features can naturally serve as the higher resolution inputs of a feature pyramid network without further upsampling or other manipulations. While the pre-trained ViT is only regarded as the 3$^{rd}$-stage of our detector's backbone instead of the whole feature extractor. This results in a ConvNet-ViT hybrid feature extractor. The proposed detector, named MIMDet, enables a MIM pre-trained vanilla ViT to outperform hierarchical **Swin** Transformer by 2.5 box AP and 2.6 mask AP on COCO, and achieves better results compared with the previous best adapted vanilla ViT detector using a more modest fine-tuning recipe while converging 2.8$\times$ faster. Code and pre-trained models are available at https://github.com/hustvl/MIMDet.  
### PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection. (arXiv:2205.07403v2 [cs.CV] UPDATED)
- Authors : Guangsheng Shi, Ruifeng Li, Chao Ma
- Link : [http://arxiv.org/abs/2205.07403](http://arxiv.org/abs/2205.07403)
> ABSTRACT  :  **Real-time** and high-performance 3D object detection is of critical importance for autonomous driving. Recent top-performing 3D object detectors mainly rely on point-based or 3D voxel-based convolutions, which are both computationally inefficient for onboard deployment. While recent researches focus on point-based or 3D voxel-based convolutions for higher performance, these methods fail to meet latency and power efficiency requirements especially for deployment on embedded devices. In contrast, pillar-based methods use merely 2D convolutions, which consume less computation resources, but they lag far behind their voxel-based counterparts in detection accuracy. However, the superiority of such 3D voxel-based methods over pillar-based methods is still broadly attributed to the effectiveness of 3D convolution neural network (CNN). In this paper, by examining the primary performance gap between pillar- and voxel-based detectors, we develop a real-time and high-performance pillar-based detector, dubbed PillarNet. The proposed PillarNet consists of a powerful encoder network for effective pillar feature learning, a neck network for spatial-semantic feature fusion and the commonly used detect head. Using only 2D convolutions, PillarNet is flexible to an optional pillar size and compatible with classical 2D CNN backbones, such as VGGNet and ResNet. Additionally, PillarNet benefits from our designed orientation-decoupled IoU regression loss along with the IoU-aware prediction branch. Extensive experimental results on large-scale nuScenes Dataset and Waymo Open Dataset demonstrate that the proposed PillarNet performs well over the state-of-the-art 3D detectors in terms of effectiveness and efficiency. Code will be made publicly available.  
## eess.IV
---
### Leveraging high-resolution spatial features in mid-infrared spectroscopic imaging to classify tissue subtypes in ovarian cancer. (arXiv:2205.09285v1 [q-bio.TO])
- Authors : Chalapathi Charan, Matthew Brun, Rupali Mankar, Noah Kennedy, Sara Corvigno, Yanping Zhong, Jinsong Liu, David Mayerich, Sebastian Berisha, Rohith Reddy
- Link : [http://arxiv.org/abs/2205.09285](http://arxiv.org/abs/2205.09285)
> ABSTRACT  :  Mid-infrared spectroscopic imaging (MIRSI) is an emerging class of label-free techniques being leveraged for digital histopathology. Optical photothermal infrared (O-PTIR) is based on vibrational absorbance imaging using a pump-probe architecture capable of a 10x **enhancement** in spatial resolution relative to FTIR imaging. This allows truly sub-cellular spectroscopic investigation of tissue at biochemically important fingerprint wavelengths. Modern histopathologic identification of ovarian cancer involves tissue staining followed by morphological pattern recognition. This process is time-consuming, subjective, and requires extensive expertise. In this paper, we present the first label-free automated histological classification of ovarian tissue sub-types using MIRSI. We demonstrate that enhanced resolution of sub-cellular features, combined with spectroscopic information, enables reliable classification (0.98 AUC) of ovarian cell sub-types. Moreover, we present statistically robust validation from 74 patient samples with over 60 million data points. This demonstrates that sub-cellular resolution from five wavenumbers is sufficient to outperform state-of-the-art diffraction-limited techniques from up to 374 different wavenumbers. O-PTIR also performs measurements in back-reflection geometry, opening the door to future in vivo studies on glass slides.  
### UIF: An Objective Quality Assessment for Underwater Image **Enhancement**. (arXiv:2205.09392v1 [cs.CV])
- Authors : Yannan Zheng, Weiling Chen, Rongfu Lin, Tiesong Zhao
- Link : [http://arxiv.org/abs/2205.09392](http://arxiv.org/abs/2205.09392)
> ABSTRACT  :  Due to complex and volatile lighting environment, underwater imaging can be readily impaired by light scattering, warping, and noises. To improve the visual quality, Underwater Image **Enhancement** (UIE) techniques have been widely studied. Recent efforts have also been contributed to evaluate and compare the UIE performances with subjective and objective methods. However, the subjective evaluation is time-consuming and uneconomic for all images, while existing objective methods have limited capabilities for the newly-developed UIE approaches based on deep learning. To fill this gap, we propose an Underwater Image Fidelity (UIF) metric for objective evaluation of enhanced underwater images. By exploiting the statistical features of these images, we present to extract naturalness-related, sharpness-related, and structure-related features. Among them, the naturalness-related and sharpness-related features evaluate visual improvement of enhanced images; the structure-related feature indicates structural similarity between images before and after UIE. Then, we employ support vector regression to fuse the above three features into a final UIF metric. In addition, we have also established a large-scale UIE database with subjective scores, namely Underwater Image **Enhancement** Database (UIED), which is utilized as a benchmark to compare all objective metrics. Experimental results confirm that the proposed UIF outperforms a variety of underwater and general-purpose image quality metrics.  
### On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v2 [physics.med-ph] UPDATED)
- Authors : Nicholas Hindley, Neha Koonjoo, Christopher Chiu, Tess Reynolds, Bo Zhu, Danyal Bhutto, Chiara Paganelli
- Link : [http://arxiv.org/abs/2202.05267](http://arxiv.org/abs/2202.05267)
> ABSTRACT  :  MRI-guidance techniques that dynamically adapt radiation beams to follow tumor motion in real-time will lead to more accurate cancer treatments and reduced collateral healthy tissue damage. The gold-standard for reconstruction of undersampled MR data is compressed sensing (CS) which is computationally slow and limits the rate that images can be available for real-time adaptation. Here, we demonstrate the use of automated transform by manifold approximation (AUTOMAP), a generalized framework that maps raw MR signal to the target image domain, to rapidly reconstruct images from undersampled radial k-space data. The AUTOMAP neural network was trained to reconstruct images from a golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on lung cancer patient data and generic images from ImageNet. Model training was subsequently augmented with motion-encoded k-space data derived from videos in the YouTube-8M dataset to encourage motion robust reconstruction. We find that AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with much shorter processing times after initial fine-tuning on retrospectively acquired lung cancer patient data. Validation of motion-trained models with a virtual dynamic lung tumor phantom showed that the generalized motion properties learned from YouTube lead to improved target tracking accuracy. Our work shows that AUTOMAP can achieve real-time, accurate reconstruction of radial data. These findings imply that neural-network-based reconstruction is potentially superior to existing approaches for real-time image guidance applications.  
## cs.LG
---
### **Dark** Solitons in Bose-Einstein Condensates: A Dataset for Many-body Physics Research. (arXiv:2205.09114v1 [cond-mat.quant-gas])
- Authors : Shangjie Guo
- Link : [http://arxiv.org/abs/2205.09114](http://arxiv.org/abs/2205.09114)
> ABSTRACT  :  We establish a dataset of over $1.6\times10^4$ experimental images of Bose-Einstein condensates containing solitonic excitations to enable machine learning (ML) for many-body physics research. About 33 % of this dataset has manually assigned and carefully curated labels. The remainder is automatically labeled using SolDet -- an implementation of a physics-informed ML data analysis framework -- consisting of a convolutional-neural-network-based classifier and object detector as well as a statistically motivated physics-informed classifier and a quality metric. This technical note constitutes the definitive reference of the dataset, providing an opportunity for the data science community to develop more sophisticated analysis tools, to further understand nonlinear many-body physics, and even advance cold atom experiments.  
### Towards Applicable Reinforcement Learning: Improving the Generalization and Sample Efficiency with Policy Ensemble. (arXiv:2205.09284v1 [cs.LG])
- Authors : Zhengyu Yang, Kan Ren, Xufang Luo, Minghuan Liu, Weiqing Liu, Jiang Bian, Weinan Zhang, Dongsheng Li
- Link : [http://arxiv.org/abs/2205.09284](http://arxiv.org/abs/2205.09284)
> ABSTRACT  :  It is challenging for reinforcement learning (RL) algorithms to succeed in real-world applications like financial trading and logistic system due to the noisy observation and environment shifting between training and evaluation. Thus, it requires both high sample efficiency and generalization for resolving real-world tasks. However, directly applying typical RL algorithms can lead to poor performance in such scenarios. Considering the great performance of ensemble methods on both accuracy and generalization in supervised learning (SL), we design a robust and applicable method named Ensemble Proximal Policy Optimization (EPPO), which learns ensemble policies in an end-to-end manner. Notably, EPPO combines each policy and the policy ensemble organically and optimizes both simultaneously. In addition, EPPO adopts a diversity **enhancement** regularization over the policy space which helps to generalize to unseen states and promotes exploration. We theoretically prove EPPO increases exploration efficacy, and through comprehensive experimental evaluations on various tasks, we demonstrate that EPPO achieves higher efficiency and is robust for real-world applications compared with vanilla policy optimization algorithms and other ensemble methods. Code and supplemental materials are available at https://seqml.github.io/eppo.  
### What killed the Convex Booster ?. (arXiv:2205.09628v1 [cs.LG])
- Authors : Yishay Mansour, Richard Nock
- Link : [http://arxiv.org/abs/2205.09628](http://arxiv.org/abs/2205.09628)
> ABSTRACT  :  A landmark negative result of Long and Servedio established a worst-case spectacular failure of a supervised learning trio (loss, algorithm, model) otherwise praised for its high precision machinery. Hundreds of papers followed up on the two suspected culprits: the loss (for being convex) and/or the algorithm (for fitting a classical boosting blueprint). Here, we call to the half-century+ founding theory of losses for class probability estimation (properness), an extension of Long and Servedio's results and a new general boosting algorithm to demonstrate that the real culprit in their specific context was in fact the (linear) model class. We advocate for a more general stanpoint on the problem as we argue that the source of the negative result lies in the **dark** side of a pervasive -- and otherwise prized -- aspect of ML: \textit{parameterisation}.  
### CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning. (arXiv:2112.04564v3 [cs.CV] UPDATED)
- Authors : Yue Fan, Dengxin Dai, Anna Kukleva, Bernt Schiele
- Link : [http://arxiv.org/abs/2112.04564](http://arxiv.org/abs/2112.04564)
> ABSTRACT  :  In this paper, we propose a novel co-learning framework (CoSSL) with decoupled representation learning and classifier learning for imbalanced SSL. To handle the data imbalance, we devise Tail-class Feature **Enhancement** (TFE) for classifier learning. Furthermore, the current evaluation protocol for imbalanced SSL focuses only on balanced test sets, which has limited practicality in real-world scenarios. Therefore, we further conduct a comprehensive evaluation under various shifted test distributions. In experiments, we show that our approach outperforms other methods over a large range of shifted distributions, achieving state-of-the-art performance on benchmark datasets ranging from CIFAR-10, CIFAR-100, ImageNet, to Food-101. Our code will be made publicly available.  
## cs.AI
---
### Towards Applicable Reinforcement Learning: Improving the Generalization and Sample Efficiency with Policy Ensemble. (arXiv:2205.09284v1 [cs.LG])
- Authors : Zhengyu Yang, Kan Ren, Xufang Luo, Minghuan Liu, Weiqing Liu, Jiang Bian, Weinan Zhang, Dongsheng Li
- Link : [http://arxiv.org/abs/2205.09284](http://arxiv.org/abs/2205.09284)
> ABSTRACT  :  It is challenging for reinforcement learning (RL) algorithms to succeed in real-world applications like financial trading and logistic system due to the noisy observation and environment shifting between training and evaluation. Thus, it requires both high sample efficiency and generalization for resolving real-world tasks. However, directly applying typical RL algorithms can lead to poor performance in such scenarios. Considering the great performance of ensemble methods on both accuracy and generalization in supervised learning (SL), we design a robust and applicable method named Ensemble Proximal Policy Optimization (EPPO), which learns ensemble policies in an end-to-end manner. Notably, EPPO combines each policy and the policy ensemble organically and optimizes both simultaneously. In addition, EPPO adopts a diversity **enhancement** regularization over the policy space which helps to generalize to unseen states and promotes exploration. We theoretically prove EPPO increases exploration efficacy, and through comprehensive experimental evaluations on various tasks, we demonstrate that EPPO achieves higher efficiency and is robust for real-world applications compared with vanilla policy optimization algorithms and other ensemble methods. Code and supplemental materials are available at https://seqml.github.io/eppo.  
### NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition. (arXiv:2205.05832v2 [cs.CL] UPDATED)
- Authors : Shuang Wu, Xiaoning Song, Zhenhua Feng, Jun Wu
- Link : [http://arxiv.org/abs/2205.05832](http://arxiv.org/abs/2205.05832)
> ABSTRACT  :  Recently, Flat-LAttice Transformer (FLAT) has achieved great success in Chinese Named Entity Recognition (NER). FLAT performs lexical **enhancement** by constructing flat lattices, which mitigates the difficulties posed by blurred word boundaries and the lack of word semantics. In FLAT, the positions of starting and ending characters are used to connect a matching word. However, this method is likely to match more words when dealing with long texts, resulting in long input sequences. Therefore, it significantly increases the memory and computational costs of the self-attention module. To deal with this issue, we advocate a novel lexical **enhancement** method, InterFormer, that effectively reduces the amount of computational and memory costs by constructing non-flat lattices. Furthermore, with InterFormer as the backbone, we implement NFLAT for Chinese NER. NFLAT decouples lexicon fusion and context feature encoding. Compared with FLAT, it reduces unnecessary attention calculations in "word-character" and "word-word". This reduces the memory usage by about 50% and can use more extensive lexicons or higher batches for network training. The experimental results obtained on several well-known benchmarks demonstrate the superiority of the proposed method over the state-of-the-art hybrid (character-word) models.  
# Paper List
---
## cs.CV
---
**92** new papers in cs.CV:-) 
1. **Dark** Solitons in Bose-Einstein Condensates: A Dataset for Many-body Physics Research. (arXiv:2205.09114v1 [cond-mat.quant-gas])
2. Exploring the Adjugate Matrix Approach to Quaternion Pose Extraction. (arXiv:2205.09116v1 [eess.IV])
3. LeRaC: Learning Rate Curriculum. (arXiv:2205.09180v1 [cs.LG])
4. Computing the ensemble spread from deterministic weather predictions using conditional generative adversarial networks. (arXiv:2205.09182v1 [cs.LG])
5. Scalable Multi-view Clustering with Graph Filtering. (arXiv:2205.09228v1 [cs.LG])
6. MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes. (arXiv:2205.09248v1 [cs.SD])
7. On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets. (arXiv:2205.09249v1 [cs.CL])
8. Bayesian Convolutional Neural Networks for Limited Data Hyperspectral Remote Sensing Image Classification. (arXiv:2205.09250v1 [cs.CV])
9. Training Vision-Language Transformers from Captions Alone. (arXiv:2205.09256v1 [cs.CV])
10. Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions. (arXiv:2205.09292v1 [cs.CV])
11. 3DConvCaps: 3DUnet with Convolutional Capsule Encoder for Medical Image Segmentation. (arXiv:2205.09299v1 [cs.CV])
12. Support-set based Multi-modal Representation **Enhancement** for Video Captioning. (arXiv:2205.09307v1 [cs.CV])
13. A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis. (arXiv:2205.09315v1 [eess.IV])
14. On Demographic Bias in Fingerprint Recognition. (arXiv:2205.09318v1 [cs.CV])
15. Let's Talk! Striking Up Conversations via Conversational Visual Question Generation. (arXiv:2205.09327v1 [cs.AI])
16. Physically-Based Editing of Indoor Scene Lighting from a Single Image. (arXiv:2205.09343v1 [cs.CV])
17. Mip-**NeRF** RGB-D: Depth Assisted Fast Neural Radiance Fields. (arXiv:2205.09351v1 [cs.CV])
18. Plane Geometry Diagram Parsing. (arXiv:2205.09363v1 [cs.CV])
19. Diversity Matters: Fully Exploiting Depth Clues for Reliable Monocular 3D Object Detection. (arXiv:2205.09373v1 [cs.CV])
20. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v1 [eess.IV])
21. Unconventional Visual Sensors for Autonomous Vehicles. (arXiv:2205.09383v1 [cs.CV])
22. UIF: An Objective Quality Assessment for Underwater Image **Enhancement**. (arXiv:2205.09392v1 [cs.CV])
23. Oracle-MNIST: a Realistic Image Dataset for Benchmarking Machine Learning Algorithms. (arXiv:2205.09442v1 [cs.CV])
24. PYSKL: Towards Good Practices for Skeleton Action Recognition. (arXiv:2205.09443v1 [cs.CV])
25. Cross-**Enhancement** Transformer for Action Segmentation. (arXiv:2205.09445v1 [cs.CV])
26. Image Augmentation Based Momentum Memory Intrinsic Reward for Sparse Reward Visual Scenes. (arXiv:2205.09448v1 [cs.AI])
27. Learning Feature Fusion for Unsupervised Domain Adaptive Person Re-identification. (arXiv:2205.09495v1 [cs.CV])
28. Enhancing the Transferability of Adversarial Examples via a Few Queries. (arXiv:2205.09518v1 [cs.CV])
29. Estimating the ultrasound attenuation coefficient using convolutional neural networks -- a feasibility study. (arXiv:2205.09533v1 [physics.med-ph])
30. Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning. (arXiv:2205.09542v1 [cs.CV])
31. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v1 [cs.CV])
32. TRT-ViT: TensorRT-oriented Vision Transformer. (arXiv:2205.09579v1 [cs.CV])
33. On Trace of PGD-Like Adversarial Attacks. (arXiv:2205.09586v1 [cs.CV])
34. Transferable Physical Attack against Object Detection with Separable Attention. (arXiv:2205.09592v1 [cs.CV])
35. A Comparative Study of Feature Expansion Unit for 3D Point Cloud Upsampling. (arXiv:2205.09594v1 [cs.CV])
36. CORPS: Cost-free Rigorous Pseudo-labeling based on Similarity-ranking for Brain MRI Segmentation. (arXiv:2205.09601v1 [cs.CV])
37. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v1 [cs.LG])
38. Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection. (arXiv:2205.09613v1 [cs.CV])
39. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v1 [cs.LG])
40. Masked Image Modeling with Denoising Contrast. (arXiv:2205.09616v1 [cs.CV])
41. A Topological Approach for Semi-Supervised Learning. (arXiv:2205.09617v1 [cs.CV])
42. Focused Adversarial Attacks. (arXiv:2205.09624v1 [cs.LG])
43. A graph-transformer for whole slide image classification. (arXiv:2205.09671v1 [cs.CV])
44. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v1 [cs.CV])
45. Semi-Supervised Learning for Image Classification using Compact Networks in the BioMedical Context. (arXiv:2205.09678v1 [cs.CV])
46. VNT-Net: Rotational Invariant Vector Neuron Transformers. (arXiv:2205.09690v1 [cs.CV])
47. k-strip: A novel segmentation algorithm in k-space for the application of skull stripping. (arXiv:2205.09706v1 [eess.IV])
48. Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization. (arXiv:2205.09709v1 [eess.AS])
49. Voxel-informed Language Grounding. (arXiv:2205.09710v1 [cs.CL])
50. Light In The Black: An Evaluation of Data Augmentation Techniques for COVID-19 CT's Semantic Segmentation. (arXiv:2205.09722v1 [cs.CV])
51. Robust and Efficient Medical Imaging with Self-Supervision. (arXiv:2205.09723v1 [cs.CV])
52. Towards Unified Keyframe Propagation Models. (arXiv:2205.09731v1 [cs.CV])
53. Diverse Weight Averaging for Out-of-Distribution Generalization. (arXiv:2205.09739v1 [cs.CV])
54. BEVerse: Unified Perception and Prediction in Birds-Eye-View for Vision-Centric Autonomous Driving. (arXiv:2205.09743v1 [cs.CV])
55. HandoverSim: A Simulation Framework and Benchmark for Human-to-Robot Object Handovers. (arXiv:2205.09747v1 [cs.RO])
56. A Review of Generalized Zero-Shot Learning Methods. (arXiv:2011.08641v4 [cs.CV] UPDATED)
57. Learning Multiscale Convolutional Dictionaries for Image Reconstruction. (arXiv:2011.12815v3 [cs.CV] UPDATED)
58. D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and Localization. (arXiv:2012.01821v2 [cs.CV] UPDATED)
59. Achieving Domain Generalization in Underwater Object Detection by Domain Mixup and Contrastive Learning. (arXiv:2104.02230v3 [cs.CV] UPDATED)
60. Denoising Noisy Neural Networks: A Bayesian Approach with Compensation. (arXiv:2105.10699v3 [cs.LG] UPDATED)
61. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v4 [cs.CV] UPDATED)
62. NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration. (arXiv:2108.03443v5 [cs.CV] UPDATED)
63. COVID-19 Monitoring System using Social Distancing and Face Mask Detection on Surveillance video datasets. (arXiv:2110.03905v2 [cs.CV] UPDATED)
64. Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion. (arXiv:2110.05706v3 [cs.CV] UPDATED)
65. DBSegment: Fast and robust segmentation of deep brain structures -- Evaluation of transportability across acquisition domains. (arXiv:2110.09473v3 [eess.IV] UPDATED)
66. Transparent Human Evaluation for Image Captioning. (arXiv:2111.08940v2 [cs.CL] UPDATED)
67. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v3 [eess.IV] UPDATED)
68. CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning. (arXiv:2112.04564v3 [cs.CV] UPDATED)
69. A Novel Skeleton-Based Human Activity Discovery Using Particle Swarm Optimization with Gaussian Mutation. (arXiv:2201.05314v2 [cs.CV] UPDATED)
70. Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v3 [cs.CV] UPDATED)
71. NIMBLE: A Non-rigid Hand Model with Bones and Muscles. (arXiv:2202.04533v3 [cs.CV] UPDATED)
72. On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v2 [physics.med-ph] UPDATED)
73. GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v2 [cs.CV] UPDATED)
74. SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v2 [cs.CV] UPDATED)
75. Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v2 [eess.SP] UPDATED)
76. Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection. (arXiv:2204.02964v2 [cs.CV] UPDATED)
77. Learning with Signatures. (arXiv:2204.07953v3 [cs.CV] UPDATED)
78. Evolutionary latent space search for driving human portrait generation. (arXiv:2204.11887v2 [cs.CV] UPDATED)
79. Cracking White-box DNN Watermarks via Invariant Neuron Transforms. (arXiv:2205.00199v2 [cs.CR] UPDATED)
80. Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial View Object Classification. (arXiv:2205.01920v4 [cs.CV] UPDATED)
81. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v3 [eess.IV] UPDATED)
82. UnrealNAS: Can We Search Neural Architectures with Unreal Data?. (arXiv:2205.02162v3 [cs.CV] UPDATED)
83. CLIP-CLOP: CLIP-Guided Collage and Photomontage. (arXiv:2205.03146v2 [cs.CV] UPDATED)
84. ConvMAE: Masked Convolution Meets Masked Autoencoders. (arXiv:2205.03892v2 [cs.CV] UPDATED)
85. Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning. (arXiv:2205.04042v2 [cs.CV] UPDATED)
86. Attracting and Dispersing: A Simple Approach for Source-free Domain Adaptation. (arXiv:2205.04183v2 [cs.CV] UPDATED)
87. Distinction Maximization Loss: Efficiently Improving Classification Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v2 [cs.LG] UPDATED)
88. Test-time Fourier Style Calibration for Domain Generalization. (arXiv:2205.06427v2 [cs.CV] UPDATED)
89. PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection. (arXiv:2205.07403v2 [cs.CV] UPDATED)
90. Text Detection & Recognition in the Wild for Robot Localization. (arXiv:2205.08565v2 [cs.CV] UPDATED)
91. SemiCurv: Semi-Supervised Curvilinear Structure Segmentation. (arXiv:2205.08706v2 [cs.CV] UPDATED)
92. Financial Time Series Data Augmentation with Generative Adversarial Networks and Extended Intertemporal Return Plots. (arXiv:2205.08924v2 [cs.CV] UPDATED)
## eess.IV
---
**18** new papers in eess.IV:-) 
1. Exploring the Adjugate Matrix Approach to Quaternion Pose Extraction. (arXiv:2205.09116v1 [eess.IV])
2. Leveraging high-resolution spatial features in mid-infrared spectroscopic imaging to classify tissue subtypes in ovarian cancer. (arXiv:2205.09285v1 [q-bio.TO])
3. A Sub-pixel Accurate Quantification of Joint Space Narrowing Progression in Rheumatoid Arthritis. (arXiv:2205.09315v1 [eess.IV])
4. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v1 [eess.IV])
5. UIF: An Objective Quality Assessment for Underwater Image **Enhancement**. (arXiv:2205.09392v1 [cs.CV])
6. Enhancing VVC with Deep Learning based Multi-Frame Post-Processing. (arXiv:2205.09458v1 [eess.IV])
7. Federated Learning: Applications, Challenges and Future Scopes. (arXiv:2205.09513v1 [cs.LG])
8. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v1 [cs.CV])
9. Combining Deep Learning and Adaptive Sparse Modeling for Low-dose CT Reconstruction. (arXiv:2205.09587v1 [eess.IV])
10. Reconstructing complex field through opaque scattering layer with structured light illumination. (arXiv:2205.09677v1 [physics.optics])
11. k-strip: A novel segmentation algorithm in k-space for the application of skull stripping. (arXiv:2205.09706v1 [eess.IV])
12. Learning Multiscale Convolutional Dictionaries for Image Reconstruction. (arXiv:2011.12815v3 [cs.CV] UPDATED)
13. Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion. (arXiv:2110.05706v3 [cs.CV] UPDATED)
14. DBSegment: Fast and robust segmentation of deep brain structures -- Evaluation of transportability across acquisition domains. (arXiv:2110.09473v3 [eess.IV] UPDATED)
15. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v3 [eess.IV] UPDATED)
16. Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v3 [cs.CV] UPDATED)
17. On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v2 [physics.med-ph] UPDATED)
18. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v3 [eess.IV] UPDATED)
## cs.LG
---
**195** new papers in cs.LG:-) 
1. **Dark** Solitons in Bose-Einstein Condensates: A Dataset for Many-body Physics Research. (arXiv:2205.09114v1 [cond-mat.quant-gas])
2. AutoQML: Automated Quantum Machine Learning for Wi-Fi Integrated Sensing and Communications. (arXiv:2205.09115v1 [cs.LG])
3. Neighborhood Mixup Experience Replay: Local Convex Interpolation for Improved Sample Efficiency in Continuous Control Tasks. (arXiv:2205.09117v1 [cs.LG])
4. Fast matrix multiplication for binary and ternary CNNs on ARM CPU. (arXiv:2205.09120v1 [cs.LG])
5. On the efficiency of Stochastic Quasi-Newton Methods for Deep Learning. (arXiv:2205.09121v1 [cs.LG])
6. A2C is a special case of PPO. (arXiv:2205.09123v1 [cs.LG])
7. Relational representation learning with spike trains. (arXiv:2205.09140v1 [cs.NE])
8. DDXPlus: A new Dataset for Medical Automatic Diagnosis. (arXiv:2205.09148v1 [cs.CL])
9. An Approach to Investigate Public Opinion, Views, and Perspectives Towards Exoskeleton Technology. (arXiv:2205.09151v1 [cs.HC])
10. Stochastic uncertainty analysis of gravity gradient tensor components and their combinations. (arXiv:2205.09159v1 [physics.geo-ph])
11. An Invariant Matching Property for Distribution Generalization under Intervened Response. (arXiv:2205.09162v1 [stat.ME])
12. PreQuEL: Quality Estimation of Machine Translation Outputs in Advance. (arXiv:2205.09178v1 [cs.CL])
13. LeRaC: Learning Rate Curriculum. (arXiv:2205.09180v1 [cs.LG])
14. Computing the ensemble spread from deterministic weather predictions using conditional generative adversarial networks. (arXiv:2205.09182v1 [cs.LG])
15. AI-assisted Optimization of the ECCE Tracking System at the Electron Ion Collider. (arXiv:2205.09185v1 [physics.ins-det])
16. High-Order Multilinear Discriminant Analysis via Order-$\textit{n}$ Tensor Eigendecomposition. (arXiv:2205.09191v1 [cs.LG])
17. Hybrid Machine Learning Modeling of Engineering Systems -- A Probabilistic Perspective Tested on a Multiphase Flow Modeling Case Study. (arXiv:2205.09196v1 [cs.LG])
18. A False Sense of Security? Revisiting the State of Machine Learning-Based Industrial Intrusion Detection. (arXiv:2205.09199v1 [cs.CR])
19. Torchhd: An Open-Source Python Library to Support Hyperdimensional Computing Research. (arXiv:2205.09208v1 [cs.LG])
20. A Classification of $G$-invariant Shallow Neural Networks. (arXiv:2205.09219v1 [cs.LG])
21. Scalable Multi-view Clustering with Graph Filtering. (arXiv:2205.09228v1 [cs.LG])
22. Constraint-Based Causal Structure Learning from Undersampled Graphs. (arXiv:2205.09235v1 [stat.ML])
23. Neural ODE Control for Trajectory Approximation of Continuity Equation. (arXiv:2205.09241v1 [math.OC])
24. Riemannian Metric Learning via Optimal Transport. (arXiv:2205.09244v1 [cs.LG])
25. Transformer-based Program Synthesis for Low-Data Environments. (arXiv:2205.09246v1 [cs.PL])
26. MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes. (arXiv:2205.09248v1 [cs.SD])
27. IL-flOw: Imitation Learning from Observation using Normalizing Flows. (arXiv:2205.09251v1 [cs.LG])
28. A Mutually Exciting Latent Space Hawkes Process Model for Continuous-time Networks. (arXiv:2205.09263v1 [cs.LG])
29. Threshold Designer Adaptation: Improved Adaptation for Designers in Co-creative Systems. (arXiv:2205.09269v1 [cs.LG])
30. Causal Inference from Small High-dimensional Datasets. (arXiv:2205.09281v1 [cs.LG])
31. Towards Applicable Reinforcement Learning: Improving the Generalization and Sample Efficiency with Policy Ensemble. (arXiv:2205.09284v1 [cs.LG])
32. Routing and Placement of Macros using Deep Reinforcement Learning. (arXiv:2205.09289v1 [cs.LG])
33. FedILC: Weighted Geometric Mean and Invariant Gradient Covariance for Federated Learning on Non-IID Data. (arXiv:2205.09305v1 [cs.LG])
34. Mitigating Neural Network Overconfidence with Logit Normalization. (arXiv:2205.09310v1 [cs.LG])
35. TransTab: Learning Transferable Tabular Transformers Across Tables. (arXiv:2205.09328v1 [cs.LG])
36. Dataset Pruning: Reducing Training Data by Examining Generalization Influence. (arXiv:2205.09329v1 [cs.LG])
37. Accelerated Training of Physics Informed Neural Networks (PINNs) using Meshless Discretizations. (arXiv:2205.09332v1 [cs.LG])
38. A Simple Yet Effective SVD-GCN for Directed Graphs. (arXiv:2205.09335v1 [cs.LG])
39. Deep Learning in Business Analytics: A Clash of Expectations and Reality. (arXiv:2205.09337v1 [cs.LG])
40. Consistent Interpolating Ensembles via the Manifold-Hilbert Kernel. (arXiv:2205.09342v1 [stat.ML])
41. Bypassing Logits Bias in Online Class-Incremental Learning with a Generative Framework. (arXiv:2205.09347v1 [cs.LG])
42. Continual Pre-Training Mitigates Forgetting in Language and Vision. (arXiv:2205.09357v1 [cs.LG])
43. Multi-DNN Accelerators for Next-Generation AI Systems. (arXiv:2205.09376v1 [cs.AR])
44. GitRanking: A Ranking of GitHub Topics for Software Classification using Active Sampling. (arXiv:2205.09379v1 [cs.SE])
45. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v1 [eess.IV])
46. Simplifying Node Classification on Heterophilous Graphs with Compatible Label Propagation. (arXiv:2205.09389v1 [cs.LG])
47. Truncated tensor Schatten p-norm based approach for spatiotemporal traffic data imputation with complicated missing patterns. (arXiv:2205.09390v1 [stat.ML])
48. Transformers as Neural Augmentors: Class Conditional Sentence Generation via Variational Bayes. (arXiv:2205.09391v1 [cs.CL])
49. Predictive Maintenance using Machine Learning. (arXiv:2205.09402v1 [cs.LG])
50. Machine learning applications for noisy intermediate-scale quantum computers. (arXiv:2205.09414v1 [quant-ph])
51. Action Conditioned Tactile Prediction: a case study on slip prediction. (arXiv:2205.09430v1 [cs.RO])
52. CAMEO: Curiosity Augmented Metropolis for Exploratory Optimal Policies. (arXiv:2205.09433v1 [cs.LG])
53. Smooth densities and generative modeling with unsupervised random forests. (arXiv:2205.09435v1 [stat.ML])
54. Gold-standard solutions to the Schr\"odinger equation using deep learning: How much physics do we need?. (arXiv:2205.09438v1 [cs.LG])
55. Learning-based AC-OPF Solvers on Realistic Network and Realistic Loads. (arXiv:2205.09452v1 [cs.LG])
56. Differential Privacy: What is all the noise about?. (arXiv:2205.09453v1 [cs.CR])
57. Neural Network Architecture Beyond Width and Depth. (arXiv:2205.09459v1 [cs.LG])
58. Why only Micro-F1? Class Weighting of Measures for Relation Classification. (arXiv:2205.09460v1 [cs.CL])
59. Personalized Interventions for Online Moderation. (arXiv:2205.09462v1 [cs.SI])
60. Nebula-I: A General Framework for Collaboratively Training Deep Learning Models on Low-Bandwidth Cloud Clusters. (arXiv:2205.09470v1 [cs.LG])
61. Neural ODEs with Irregular and Noisy Data. (arXiv:2205.09479v1 [cs.LG])
62. A Boosting Algorithm for Positive-Unlabeled Learning. (arXiv:2205.09485v1 [cs.LG])
63. PSI Draft Specification. (arXiv:2205.09488v1 [cs.SE])
64. Spatial Autoregressive Coding for Graph Neural Recommendation. (arXiv:2205.09489v1 [cs.IR])
65. Differentially private Riemannian optimization. (arXiv:2205.09494v1 [math.OC])
66. Practical Skills Demand Forecasting via Representation Learning of Temporal Dynamics. (arXiv:2205.09508v1 [econ.GN])
67. An Introduction to Quantum Machine Learning for Engineers. (arXiv:2205.09510v1 [quant-ph])
68. The Impact of COVID-19 Pandemic on LGBTQ Online Communitie. (arXiv:2205.09511v1 [cs.SI])
69. Federated Learning: Applications, Challenges and Future Scopes. (arXiv:2205.09513v1 [cs.LG])
70. Variational Inference for Bayesian Bridge Regression. (arXiv:2205.09515v1 [stat.ML])
71. scICML: Information-theoretic Co-clustering-based Multi-view Learning for the Integrative Analysis of Single-cell Multi-omics data. (arXiv:2205.09523v1 [stat.ML])
72. Simple Regularisation for Uncertainty-Aware Knowledge Distillation. (arXiv:2205.09526v1 [cs.LG])
73. Mobility, Communication and Computation Aware Federated Learning for Internet of Vehicles. (arXiv:2205.09529v1 [cs.LG])
74. IFTT-PIN: A PIN-Entry Method Leveraging the Self-Calibration Paradigm. (arXiv:2205.09534v1 [cs.HC])
75. Data-driven prediction of Air Traffic Controllers reactions to resolving conflicts. (arXiv:2205.09539v1 [cs.AI])
76. Parallel bandit architecture based on laser chaos for reinforcement learning. (arXiv:2205.09543v1 [cs.ET])
77. Closing the gap: Exact maximum likelihood training of generative autoencoders using invertible layers. (arXiv:2205.09546v1 [stat.ML])
78. ODBO: Bayesian Optimization with Search Space Prescreening for Directed Protein Evolution. (arXiv:2205.09548v1 [q-bio.BM])
79. Data Valuation for Offline Reinforcement Learning. (arXiv:2205.09550v1 [cs.LG])
80. Hybrid Intelligent Testing in Simulation-Based Verification. (arXiv:2205.09552v1 [cs.AR])
81. Automatic Spoken Language Identification using a Time-Delay Neural Network. (arXiv:2205.09564v1 [cs.CL])
82. Provably Precise, Succinct and Efficient Explanations for Decision Trees. (arXiv:2205.09569v1 [cs.AI])
83. Jacobian Granger Causal Neural Networks for Analysis of Stationary and Nonstationary Data. (arXiv:2205.09573v1 [cs.LG])
84. Learning Graph Structure from Convolutional Mixtures. (arXiv:2205.09575v1 [cs.LG])
85. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v1 [cs.CV])
86. How catastrophic can catastrophic forgetting be in linear regression?. (arXiv:2205.09588v1 [cs.LG])
87. Learning Energy Networks with Generalized Fenchel-Young Losses. (arXiv:2205.09589v1 [cs.LG])
88. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v1 [cs.LG])
89. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v1 [cs.LG])
90. A Topological Approach for Semi-Supervised Learning. (arXiv:2205.09617v1 [cs.CV])
91. Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification. (arXiv:2205.09619v1 [cs.LG])
92. Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data. (arXiv:2205.09620v1 [cs.LG])
93. What Is Fairness? Implications For FairML. (arXiv:2205.09622v1 [cs.LG])
94. Focused Adversarial Attacks. (arXiv:2205.09624v1 [cs.LG])
95. What killed the Convex Booster ?. (arXiv:2205.09628v1 [cs.LG])
96. Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking. (arXiv:2205.09638v1 [cs.IR])
97. The First Optimal Acceleration of High-Order Methods in Smooth Convex Optimization. (arXiv:2205.09647v1 [math.OC])
98. Are Graph Representation Learning Methods Robust to Graph Sparsity and Asymmetric Node Information?. (arXiv:2205.09648v1 [cs.LG])
99. Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT, Arabic NER Corpus. (arXiv:2205.09651v1 [cs.CL])
100. Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks. (arXiv:2205.09653v1 [stat.ML])
101. The AI Mechanic: Acoustic Vehicle Characterization Neural Networks. (arXiv:2205.09667v1 [cs.SD])
102. Semi-WTC: A Practical Semi-supervised Framework for Attack Categorization through Weight-Task Consistency. (arXiv:2205.09669v1 [cs.CR])
103. Detect Professional Malicious User with Metric Learning in Recommender Systems. (arXiv:2205.09673v1 [cs.IR])
104. Disentangling Active and Passive Cosponsorship in the U.S. Congress. (arXiv:2205.09674v1 [cs.LG])
105. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v1 [cs.CV])
106. Semi-Supervised Learning for Image Classification using Compact Networks in the BioMedical Context. (arXiv:2205.09678v1 [cs.CV])
107. Metrics of calibration for probabilistic predictions. (arXiv:2205.09680v1 [math.ST])
108. Dexterous Robotic Manipulation using Deep Reinforcement Learning and Knowledge Transfer for Complex Sparse Reward-based Tasks. (arXiv:2205.09683v1 [cs.RO])
109. ArabGlossBERT: Fine-Tuning BERT on Context-Gloss Pairs for WSD. (arXiv:2205.09685v1 [cs.CL])
110. Neural network topological snake models for locating general phase diagrams. (arXiv:2205.09699v1 [cond-mat.stat-mech])
111. Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis. (arXiv:2205.09702v1 [cs.LG])
112. Extract Dynamic Information To Improve Time Series Modeling: a Case Study with Scientific Workflow. (arXiv:2205.09703v1 [cs.LG])
113. k-strip: A novel segmentation algorithm in k-space for the application of skull stripping. (arXiv:2205.09706v1 [eess.IV])
114. Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization. (arXiv:2205.09709v1 [eess.AS])
115. Flexible Modeling and Multitask Learning using Differentiable Tree Ensembles. (arXiv:2205.09717v1 [cs.LG])
116. HyperAid: Denoising in hyperbolic spaces for tree-fitting and hierarchical clustering. (arXiv:2205.09721v1 [cs.LG])
117. Robust and Efficient Medical Imaging with Self-Supervision. (arXiv:2205.09723v1 [cs.CV])
118. RankGen: Improving Text Generation with Large Ranking Models. (arXiv:2205.09726v1 [cs.CL])
119. Foundation Posteriors for Approximate Probabilistic Inference. (arXiv:2205.09735v1 [cs.LG])
120. Diverse Weight Averaging for Out-of-Distribution Generalization. (arXiv:2205.09739v1 [cs.CV])
121. Overcoming Language Disparity in Online Content Classification with Multimodal Learning. (arXiv:2205.09744v1 [cs.LG])
122. Understanding Gradient Descent on Edge of Stability in Deep Learning. (arXiv:2205.09745v1 [cs.LG])
123. Spurious Local Minima of Deep ReLU Neural Networks in the Neural Tangent Kernel Regime. (arXiv:1806.04884v3 [stat.ML] UPDATED)
124. Bayesian Network Structure Learning using Digital Annealer. (arXiv:2006.06926v3 [cs.LG] UPDATED)
125. Spherical Perspective on Learning with Normalization Layers. (arXiv:2006.13382v3 [cs.LG] UPDATED)
126. SEMI: Self-supervised Exploration via Multisensory Incongruity. (arXiv:2009.12494v2 [cs.LG] UPDATED)
127. Challenges in Deploying Machine Learning: a Survey of Case Studies. (arXiv:2011.09926v3 [cs.LG] UPDATED)
128. Learning Multiscale Convolutional Dictionaries for Image Reconstruction. (arXiv:2011.12815v3 [cs.CV] UPDATED)
129. CARMI: A Cache-Aware Learned Index with a Cost-based Construction Algorithm. (arXiv:2103.00858v4 [cs.DB] UPDATED)
130. Denoising Noisy Neural Networks: A Bayesian Approach with Compensation. (arXiv:2105.10699v3 [cs.LG] UPDATED)
131. On a class of data-driven mixed-integer programming problems under uncertainty: a distributionally robust approach. (arXiv:2105.14139v3 [math.OC] UPDATED)
132. Efficient and Modular Implicit Differentiation. (arXiv:2105.15183v4 [cs.LG] UPDATED)
133. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v4 [cs.CV] UPDATED)
134. Heterogeneous Multi-task Learning with Expert Diversity. (arXiv:2106.10595v2 [cs.LG] UPDATED)
135. A Causal Bandit Approach to Learning Good Atomic Interventions in Presence of Unobserved Confounders. (arXiv:2107.02772v2 [cs.LG] UPDATED)
136. A Graph Data Augmentation Strategy with Entropy Preservation. (arXiv:2107.06048v2 [cs.LG] UPDATED)
137. SiReN: Sign-Aware Recommendation Using Graph Neural Networks. (arXiv:2108.08735v2 [cs.IR] UPDATED)
138. A robust approach for deep neural networks in presence of label noise: relabelling and filtering instances during training. (arXiv:2109.03748v3 [cs.LG] UPDATED)
139. Cross-lingual Transfer of Monolingual Models. (arXiv:2109.07348v2 [cs.CL] UPDATED)
140. PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for Planning, Control, and Simulation. (arXiv:2109.11094v2 [cs.RO] UPDATED)
141. Morse-STF: Improved Protocols for Privacy-Preserving Machine Learning. (arXiv:2109.11726v2 [cs.CR] UPDATED)
142. Parameter-free Reduction of the Estimation Bias in Deep Reinforcement Learning for Deterministic Policy Gradients. (arXiv:2109.11788v3 [cs.LG] UPDATED)
143. Darts: User-Friendly Modern Machine Learning for Time Series. (arXiv:2110.03224v3 [cs.LG] UPDATED)
144. COVID-19 Monitoring System using Social Distancing and Face Mask Detection on Surveillance video datasets. (arXiv:2110.03905v2 [cs.CV] UPDATED)
145. Deep Fusion Prior for Multi-Focus Image Super Resolution Fusion. (arXiv:2110.05706v3 [cs.CV] UPDATED)
146. DBSegment: Fast and robust segmentation of deep brain structures -- Evaluation of transportability across acquisition domains. (arXiv:2110.09473v3 [eess.IV] UPDATED)
147. Universal Lower Bound for Learning Causal DAGs with Atomic Interventions. (arXiv:2111.05070v4 [cs.LG] UPDATED)
148. Speeding Up Entmax. (arXiv:2111.06832v3 [cs.CL] UPDATED)
149. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v3 [eess.IV] UPDATED)
150. ESCADA: Efficient Safety and Context Aware Dose Allocation for Precision Medicine. (arXiv:2111.13415v2 [cs.LG] UPDATED)
151. CoSSL: Co-Learning of Representation and Classifier for Imbalanced Semi-Supervised Learning. (arXiv:2112.04564v3 [cs.CV] UPDATED)
152. M3E2: Multi-gate Mixture-of-experts for Multi-treatment Effect Estimation. (arXiv:2112.07574v2 [cs.LG] UPDATED)
153. Privacy preserving n-party scalar product protocol. (arXiv:2112.09436v2 [cs.CR] UPDATED)
154. FlowPool: Pooling Graph Representations with Wasserstein Gradient Flows. (arXiv:2112.09990v2 [cs.LG] UPDATED)
155. Improving VAE based molecular representations for compound property prediction. (arXiv:2201.04929v3 [cs.LG] UPDATED)
156. Time Series Generation with Masked Autoencoder. (arXiv:2201.07006v3 [cs.LG] UPDATED)
157. TourBERT: A pretrained language model for the tourism industry. (arXiv:2201.07449v3 [cs.CL] UPDATED)
158. STOPS: Short-Term-based Volatility-controlled Policy Search and its Global Convergence. (arXiv:2201.09857v4 [cs.LG] UPDATED)
159. Design choice and machine learning model performances. (arXiv:2201.10239v2 [stat.ML] UPDATED)
160. Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v3 [cs.CV] UPDATED)
161. Posterior Matching for Arbitrary Conditioning. (arXiv:2201.12414v3 [cs.LG] UPDATED)
162. Generalization Analysis of Message Passing Neural Networks on Large Random Graphs. (arXiv:2202.00645v4 [cs.LG] UPDATED)
163. Deep Dynamic Effective Connectivity Estimation from Multivariate Time Series. (arXiv:2202.02393v3 [cs.LG] UPDATED)
164. Backdoor Detection in Reinforcement Learning. (arXiv:2202.03609v2 [cs.LG] UPDATED)
165. Interpretable Latent Variables in Deep State Space Models. (arXiv:2203.02057v2 [stat.ML] UPDATED)
166. SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v2 [cs.CV] UPDATED)
167. Diagonal State Spaces are as Effective as Structured State Spaces. (arXiv:2203.14343v3 [cs.LG] UPDATED)
168. Theory of Acceleration of Decision Making by Correlated Time Sequences. (arXiv:2203.16004v3 [cs.LG] UPDATED)
169. Overcoming challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v2 [stat.ML] UPDATED)
170. Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v2 [eess.SP] UPDATED)
171. Can language models learn from explanations in context?. (arXiv:2204.02329v2 [cs.CL] UPDATED)
172. Bayesian Negative Sampling for Recommendation. (arXiv:2204.06520v2 [cs.IR] UPDATED)
173. Approximating Persistent Homology for Large Datasets. (arXiv:2204.09155v2 [stat.ML] UPDATED)
174. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v2 [cs.LG] UPDATED)
175. Evolutionary latent space search for driving human portrait generation. (arXiv:2204.11887v2 [cs.CV] UPDATED)
176. Cracking White-box DNN Watermarks via Invariant Neuron Transforms. (arXiv:2205.00199v2 [cs.CR] UPDATED)
177. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v3 [eess.IV] UPDATED)
178. Multivariate Prediction Intervals for Random Forests. (arXiv:2205.02260v2 [stat.ML] UPDATED)
179. Unsupervised Learning of Rydberg Atom Array Phase Diagram with Siamese Neural Networks. (arXiv:2205.04051v2 [physics.comp-ph] UPDATED)
180. Attracting and Dispersing: A Simple Approach for Source-free Domain Adaptation. (arXiv:2205.04183v2 [cs.CV] UPDATED)
181. Stochastic first-order methods for average-reward Markov decision processes. (arXiv:2205.05800v2 [cs.LG] UPDATED)
182. Distinction Maximization Loss: Efficiently Improving Classification Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v2 [cs.LG] UPDATED)
183. Exploiting Inductive Bias in Transformers for Unsupervised Disentanglement of Syntax and Semantics with VAEs. (arXiv:2205.05943v2 [cs.CL] UPDATED)
184. A Generalist Agent. (arXiv:2205.06175v2 [cs.AI] UPDATED)
185. Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction. (arXiv:2205.06296v3 [cs.IR] UPDATED)
186. Test-time Fourier Style Calibration for Domain Generalization. (arXiv:2205.06427v2 [cs.CV] UPDATED)
187. Trajectory Inference via Mean-field Langevin in Path Space. (arXiv:2205.07146v2 [math.OC] UPDATED)
188. "What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v3 [cs.CL] UPDATED)
189. On the Convergence of Policy in Unregularized Policy Mirror Descent. (arXiv:2205.08176v2 [math.OC] UPDATED)
190. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v2 [cs.LG] UPDATED)
191. Conformalized Online Learning: Online Calibration Without a Holdout Set. (arXiv:2205.09095v2 [cs.LG] UPDATED)
192. Turbulent field fluctuations in gyrokinetic and fluid plasmas. (arXiv:2107.09744v2 [physics.plasm-ph] CROSS LISTED)
193. PTFlash : A deep learning framework for isothermal two-phase equilibrium calculations. (arXiv:2205.03090v2 [physics.chem-ph] CROSS LISTED)
194. High-resolution landscape-scale biomass mapping using a spatiotemporal patchwork of LiDAR coverages. (arXiv:2205.08530v1 [stat.AP] CROSS LISTED)
195. Property Unlearning: A Defense Strategy Against Property Inference Attacks. (arXiv:2205.08821v1 [cs.CR] CROSS LISTED)
## cs.AI
---
**91** new papers in cs.AI:-) 
1. DDXPlus: A new Dataset for Medical Automatic Diagnosis. (arXiv:2205.09148v1 [cs.CL])
2. Backdoor Attacks on Bayesian Neural Networks using Reverse Distribution. (arXiv:2205.09167v1 [cs.CR])
3. Carbon Figures of Merit Knowledge Creation with a Hybrid Solution and Carbon Tables API. (arXiv:2205.09175v1 [cs.AI])
4. Mimicking Behaviors in Separated Domains. (arXiv:2205.09201v1 [cs.AI])
5. Scalable Multi-view Clustering with Graph Filtering. (arXiv:2205.09228v1 [cs.LG])
6. PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners. (arXiv:2205.09229v1 [cs.CL])
7. Constraint-Based Causal Structure Learning from Undersampled Graphs. (arXiv:2205.09235v1 [stat.ML])
8. Debiasing Neural Retrieval via In-batch Balancing Regularization. (arXiv:2205.09240v1 [cs.IR])
9. On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets. (arXiv:2205.09249v1 [cs.CL])
10. IL-flOw: Imitation Learning from Observation using Normalizing Flows. (arXiv:2205.09251v1 [cs.LG])
11. Towards Applicable Reinforcement Learning: Improving the Generalization and Sample Efficiency with Policy Ensemble. (arXiv:2205.09284v1 [cs.LG])
12. FedILC: Weighted Geometric Mean and Invariant Gradient Covariance for Federated Learning on Non-IID Data. (arXiv:2205.09305v1 [cs.LG])
13. Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer. (arXiv:2205.09324v1 [cs.CL])
14. Let's Talk! Striking Up Conversations via Conversational Visual Question Generation. (arXiv:2205.09327v1 [cs.AI])
15. TransTab: Learning Transferable Tabular Transformers Across Tables. (arXiv:2205.09328v1 [cs.LG])
16. Bypassing Logits Bias in Online Class-Incremental Learning with a Generative Framework. (arXiv:2205.09347v1 [cs.LG])
17. Continual Pre-Training Mitigates Forgetting in Language and Vision. (arXiv:2205.09357v1 [cs.LG])
18. Sparse Adversarial Attack in Multi-agent Reinforcement Learning. (arXiv:2205.09362v1 [cs.AI])
19. Multi-DNN Accelerators for Next-Generation AI Systems. (arXiv:2205.09376v1 [cs.AR])
20. Inferring extended summary causal graphs from observational time series. (arXiv:2205.09422v1 [cs.AI])
21. Action Conditioned Tactile Prediction: a case study on slip prediction. (arXiv:2205.09430v1 [cs.RO])
22. CAMEO: Curiosity Augmented Metropolis for Exploratory Optimal Policies. (arXiv:2205.09433v1 [cs.LG])
23. Smooth densities and generative modeling with unsupervised random forests. (arXiv:2205.09435v1 [stat.ML])
24. Image Augmentation Based Momentum Memory Intrinsic Reward for Sparse Reward Visual Scenes. (arXiv:2205.09448v1 [cs.AI])
25. Differential Privacy: What is all the noise about?. (arXiv:2205.09453v1 [cs.CR])
26. Personalized Interventions for Online Moderation. (arXiv:2205.09462v1 [cs.SI])
27. Nebula-I: A General Framework for Collaboratively Training Deep Learning Models on Low-Bandwidth Cloud Clusters. (arXiv:2205.09470v1 [cs.LG])
28. A Boosting Algorithm for Positive-Unlabeled Learning. (arXiv:2205.09485v1 [cs.LG])
29. Spatial Autoregressive Coding for Graph Neural Recommendation. (arXiv:2205.09489v1 [cs.IR])
30. SDS-200: A Swiss German Speech to Standard German Text Corpus. (arXiv:2205.09501v1 [cs.CL])
31. Federated Learning: Applications, Challenges and Future Scopes. (arXiv:2205.09513v1 [cs.LG])
32. Enhancing the Transferability of Adversarial Examples via a Few Queries. (arXiv:2205.09518v1 [cs.CV])
33. Simple Regularisation for Uncertainty-Aware Knowledge Distillation. (arXiv:2205.09526v1 [cs.LG])
34. IFTT-PIN: A PIN-Entry Method Leveraging the Self-Calibration Paradigm. (arXiv:2205.09534v1 [cs.HC])
35. Data-driven prediction of Air Traffic Controllers reactions to resolving conflicts. (arXiv:2205.09539v1 [cs.AI])
36. Hybrid Intelligent Testing in Simulation-Based Verification. (arXiv:2205.09552v1 [cs.AR])
37. Provably Precise, Succinct and Efficient Explanations for Decision Trees. (arXiv:2205.09569v1 [cs.AI])
38. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v1 [cs.CV])
39. Evonne: Interactive Proof Visualization for Description Logics (System Description) -- Extended Version. (arXiv:2205.09583v1 [cs.LO])
40. Multi-Armed Bandits in Brain-Computer Interfaces. (arXiv:2205.09584v1 [cs.AI])
41. LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing. (arXiv:2205.09607v1 [cs.CL])
42. A Topological Approach for Semi-Supervised Learning. (arXiv:2205.09617v1 [cs.CV])
43. Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data. (arXiv:2205.09620v1 [cs.LG])
44. What Is Fairness? Implications For FairML. (arXiv:2205.09622v1 [cs.LG])
45. Great Power, Great Responsibility: Recommendations for Reducing Energy for Training Language Models. (arXiv:2205.09646v1 [cs.CL])
46. Are Graph Representation Learning Methods Robust to Graph Sparsity and Asymmetric Node Information?. (arXiv:2205.09648v1 [cs.LG])
47. Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT, Arabic NER Corpus. (arXiv:2205.09651v1 [cs.CL])
48. The Arabic Ontology -- An Arabic Wordnet with Ontologically Clean Content. (arXiv:2205.09664v1 [cs.CL])
49. The AI Mechanic: Acoustic Vehicle Characterization Neural Networks. (arXiv:2205.09667v1 [cs.SD])
50. A Note on Categories about Rough Sets. (arXiv:2205.09672v1 [cs.AI])
51. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v1 [cs.CV])
52. Semi-Supervised Learning for Image Classification using Compact Networks in the BioMedical Context. (arXiv:2205.09678v1 [cs.CV])
53. ArabGlossBERT: Fine-Tuning BERT on Context-Gloss Pairs for WSD. (arXiv:2205.09685v1 [cs.CL])
54. Curras + Baladi: Towards a Levantine Corpus. (arXiv:2205.09692v1 [cs.CL])
55. Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging. (arXiv:2205.09696v1 [cs.HC])
56. Distributed Multi-Agent Deep Reinforcement Learning for Robust Coordination against Noise. (arXiv:2205.09705v1 [cs.AI])
57. Bi-LSTM Scoring Based Similarity Measurement with Agglomerative Hierarchical Clustering (AHC) for Speaker Diarization. (arXiv:2205.09709v1 [eess.AS])
58. Voxel-informed Language Grounding. (arXiv:2205.09710v1 [cs.CL])
59. Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning. (arXiv:2205.09712v1 [cs.AI])
60. Robust and Efficient Medical Imaging with Self-Supervision. (arXiv:2205.09723v1 [cs.CV])
61. Reinforcement Learning with Brain-Inspired Modulation can Improve Adaptation to Environmental Changes. (arXiv:2205.09729v1 [cs.AI])
62. Enhancing Slot Tagging with Intent Features for Task Oriented Natural Language Understanding using BERT. (arXiv:2205.09732v1 [cs.CL])
63. AIGenC: AI generalisation via creativity. (arXiv:2205.09738v1 [cs.AI])
64. Diverse Weight Averaging for Out-of-Distribution Generalization. (arXiv:2205.09739v1 [cs.CV])
65. A Causal Bandit Approach to Learning Good Atomic Interventions in Presence of Unobserved Confounders. (arXiv:2107.02772v2 [cs.LG] UPDATED)
66. A Graph Data Augmentation Strategy with Entropy Preservation. (arXiv:2107.06048v2 [cs.LG] UPDATED)
67. SiReN: Sign-Aware Recommendation Using Graph Neural Networks. (arXiv:2108.08735v2 [cs.IR] UPDATED)
68. Parameter-free Reduction of the Estimation Bias in Deep Reinforcement Learning for Deterministic Policy Gradients. (arXiv:2109.11788v3 [cs.LG] UPDATED)
69. The Spread of Propaganda by Coordinated Communities on Social Media. (arXiv:2109.13046v2 [cs.SI] UPDATED)
70. Universal Lower Bound for Learning Causal DAGs with Atomic Interventions. (arXiv:2111.05070v4 [cs.LG] UPDATED)
71. Meaningful human control: actionable properties for AI system development. (arXiv:2112.01298v2 [cs.CY] UPDATED)
72. TourBERT: A pretrained language model for the tourism industry. (arXiv:2201.07449v3 [cs.CL] UPDATED)
73. Class-Aware Generative Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v3 [cs.CV] UPDATED)
74. Generalization Analysis of Message Passing Neural Networks on Large Random Graphs. (arXiv:2202.00645v4 [cs.LG] UPDATED)
75. Backdoor Detection in Reinforcement Learning. (arXiv:2202.03609v2 [cs.LG] UPDATED)
76. Differential Assessment of Black-Box AI Agents. (arXiv:2203.13236v2 [cs.AI] UPDATED)
77. Cross-modal Learning of Graph Representations using Radar Point Cloud for Long-Range Gesture Recognition. (arXiv:2203.17066v2 [eess.SP] UPDATED)
78. Can language models learn from explanations in context?. (arXiv:2204.02329v2 [cs.CL] UPDATED)
79. Bayesian Negative Sampling for Recommendation. (arXiv:2204.06520v2 [cs.IR] UPDATED)
80. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v2 [cs.LG] UPDATED)
81. Evolutionary latent space search for driving human portrait generation. (arXiv:2204.11887v2 [cs.CV] UPDATED)
82. CLIP-CLOP: CLIP-Guided Collage and Photomontage. (arXiv:2205.03146v2 [cs.CV] UPDATED)
83. Building for Tomorrow: Assessing the Temporal Persistence of Text Classifiers. (arXiv:2205.05435v2 [cs.CL] UPDATED)
84. NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition. (arXiv:2205.05832v2 [cs.CL] UPDATED)
85. Distinction Maximization Loss: Efficiently Improving Classification Accuracy, Uncertainty Estimation, and Out-of-Distribution Detection Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v2 [cs.LG] UPDATED)
86. A Generalist Agent. (arXiv:2205.06175v2 [cs.AI] UPDATED)
87. Test-time Fourier Style Calibration for Domain Generalization. (arXiv:2205.06427v2 [cs.CV] UPDATED)
88. "What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v3 [cs.CL] UPDATED)
89. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v2 [cs.LG] UPDATED)
90. PTFlash : A deep learning framework for isothermal two-phase equilibrium calculations. (arXiv:2205.03090v2 [physics.chem-ph] CROSS LISTED)
91. Property Unlearning: A Defense Strategy Against Property Inference Attacks. (arXiv:2205.08821v1 [cs.CR] CROSS LISTED)

