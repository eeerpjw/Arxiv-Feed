# Your interest papers
---
## cs.CV
---
### Attention guided global **enhancement** and local refinement network for semantic segmentation. (arXiv:2204.04363v1 [cs.CV])
- Authors : Jiangyun Li, Sen Zha, Chen Chen, Meng Ding, Tianxiang Zhang, Hong Yu
- Link : [http://arxiv.org/abs/2204.04363](http://arxiv.org/abs/2204.04363)
> ABSTRACT  :  The encoder-decoder architecture is widely used as a lightweight semantic segmentation network. However, it struggles with a limited performance compared to a well-designed Dilated-FCN model for two major problems. First, commonly used upsampling methods in the decoder such as interpolation and deconvolution suffer from a local receptive field, unable to encode global contexts. Second, low-level features may bring noises to the network decoder through skip connections for the inadequacy of semantic concepts in early encoder layers. To tackle these challenges, a Global **Enhancement** Method is proposed to aggregate global information from high-level feature maps and adaptively distribute them to different decoder layers, alleviating the shortage of global contexts in the upsampling process. Besides, a Local Refinement Module is developed by utilizing the decoder features as the semantic guidance to refine the noisy encoder features before the fusion of these two (the decoder features and the encoder features). Then, the two methods are integrated into a Context Fusion Block, and based on that, a novel Attention guided Global **enhancement** and Local refinement Network (AGLN) is elaborately designed. Extensive experiments on PASCAL Context, ADE20K, and PASCAL VOC 2012 datasets have demonstrated the effectiveness of the proposed approach. In particular, with a vanilla ResNet-101 backbone, AGLN achieves the state-of-the-art result (56.23% mean IoU) on the PASCAL Context dataset. The code is available at https://github.com/zhasen1996/AGLN.  
### Guided deep learning by subaperture decomposition: ocean patterns from SAR imagery. (arXiv:2204.04438v1 [cs.CV])
- Authors : Catalin Ristea, Andrei Anghel, Mihai Datcu, Bertrand Chapron
- Link : [http://arxiv.org/abs/2204.04438](http://arxiv.org/abs/2204.04438)
> ABSTRACT  :  Spaceborne synthetic aperture radar can provide meters scale images of the ocean surface roughness day or **night** in nearly all weather conditions. This makes it a unique asset for many geophysical applications. Sentinel 1 SAR wave mode vignettes have made possible to capture many important oceanic and atmospheric phenomena since 2014. However, considering the amount of data provided, expanding applications requires a strategy to automatically process and extract geophysical parameters. In this study, we propose to apply subaperture decomposition as a preprocessing stage for SAR deep learning models. Our data centring approach surpassed the baseline by 0.7, obtaining state of the art on the TenGeoPSARwv data set. In addition, we empirically showed that subaperture decomposition could bring additional information over the original vignette, by rising the number of clusters for an unsupervised segmentation method. Overall, we encourage the development of data centring approaches, showing that, data preprocessing could bring significant performance improvements over existing deep learning models.  
### Noise-based **Enhancement** for Foveated Rendering. (arXiv:2204.04455v1 [cs.GR])
- Authors : Taimoor Tariq, Cara Tursun, Piotr Didyk
- Link : [http://arxiv.org/abs/2204.04455](http://arxiv.org/abs/2204.04455)
> ABSTRACT  :  Human visual sensitivity to spatial details declines towards the periphery. Novel image synthesis techniques, so-called foveated rendering, exploit this observation and reduce the spatial resolution of synthesized images for the periphery, avoiding the synthesis of high-spatial-frequency details that are costly to generate but not perceived by a viewer. However, contemporary techniques do not make a clear distinction between the range of spatial frequencies that must be reproduced and those that can be omitted. For a given eccentricity, there is a range of frequencies that are detectable but not resolvable. While the accurate reproduction of these frequencies is not required, an observer can detect their absence if completely omitted. We use this observation to improve the performance of existing foveated rendering techniques. We demonstrate that this specific range of frequencies can be efficiently replaced with procedural noise whose parameters are carefully tuned to image content and human perception. Consequently, these frequencies do not have to be synthesized during rendering, allowing more aggressive foveation, and they can be replaced by noise generated in a less expensive post-processing step, leading to improved performance of the rendering system. Our main contribution is a perceptually-inspired technique for deriving the parameters of the noise required for the **enhancement** and its calibration. The method operates on rendering output and runs at rates exceeding 200FPS at 4K resolution, making it suitable for integration with real-time foveated rendering systems for VR and AR devices. We validate our results and compare them to the existing contrast **enhancement** technique in user experiments.  
### Panoptic-PartFormer: Learning a Unified Model for Panoptic Part Segmentation. (arXiv:2204.04655v1 [cs.CV])
- Authors : Xiangtai Li, Shilin Xu, Yibo Yang, Guangliang Cheng, Yunhai Tong, Dacheng Tao
- Link : [http://arxiv.org/abs/2204.04655](http://arxiv.org/abs/2204.04655)
> ABSTRACT  :  Panoptic Part Segmentation (PPS) aims to unify panoptic segmentation and part segmentation into one task. Previous work mainly utilizes separated approaches to handle thing, stuff, and part predictions individually without performing any shared computation and task association. In this work, we aim to unify these tasks at the architectural level, designing the first end-to-end unified method named Panoptic-PartFormer. In particular, motivated by the recent progress in Vision Transformer, we model things, stuff, and part as object queries and directly learn to optimize the all three predictions as unified mask prediction and classification problem. We design a decoupled decoder to generate part feature and thing/stuff feature respectively. Then we propose to utilize all the queries and corresponding features to perform reasoning jointly and iteratively. The final mask can be obtained via inner product between queries and the corresponding features. The extensive ablation studies and analysis prove the effectiveness of our framework. Our Panoptic-PartFormer achieves the new state-of-the-art results on both Cityscapes PPS and Pascal Context PPS datasets with at least 70% GFlops and 50% parameters decrease. In particular, we get 3.4% relative improvements with ResNet50 backbone and 10% improvements after adopting **Swin** Transformer on Pascal Context PPS dataset. To the best of our knowledge, we are the first to solve the PPS problem via \textit{a unified and end-to-end transformer model. Given its effectiveness and conceptual simplicity, we hope our Panoptic-PartFormer can serve as a good baseline and aid future unified research for PPS. Our code and models will be available at https://github.com/lxtGH/Panoptic-PartFormer.  
### Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation. (arXiv:2204.04656v1 [cs.CV])
- Authors : Xiangtai Li, Wenwei Zhang, Jiangmiao Pang, Kai Chen, Guangliang Cheng, Yunhai Tong, Chen Change
- Link : [http://arxiv.org/abs/2204.04656](http://arxiv.org/abs/2204.04656)
> ABSTRACT  :  This paper presents Video K-Net, a simple, strong, and unified framework for fully end-to-end video panoptic segmentation. The method is built upon K-Net, a method that unifies image segmentation via a group of learnable kernels. We observe that these learnable kernels from K-Net, which encode object appearances and contexts, can naturally associate identical instances across video frames. Motivated by this observation, Video K-Net learns to simultaneously segment and track "things" and "stuff" in a video with simple kernel-based appearance modeling and cross-temporal kernel interaction. Despite the simplicity, it achieves state-of-the-art video panoptic segmentation results on Citscapes-VPS and KITTI-STEP without bells and whistles. In particular on KITTI-STEP, the simple method can boost almost 12\% relative improvements over previous methods. We also validate its generalization on video semantic segmentation, where we boost various baselines by 2\% on the VSPW dataset. Moreover, we extend K-Net into clip-level video framework for video instance segmentation where we obtain 40.5\% for ResNet50 backbone and 51.5\% mAP for **Swin**-base on YouTube-2019 validation set. We hope this simple yet effective method can serve as a new flexible baseline in video segmentation. Both code and models are released at https://github.com/lxtGH/Video-K-Net  
### NAN: Noise-Aware **NeRF**s for Burst-Denoising. (arXiv:2204.04668v1 [cs.CV])
- Authors : Naama Pearl, Tali Treibitz, Simon Korman
- Link : [http://arxiv.org/abs/2204.04668](http://arxiv.org/abs/2204.04668)
> ABSTRACT  :  Burst denoising is now more relevant than ever, as computational photography helps overcome sensitivity issues inherent in mobile phones and small cameras. A major challenge in burst-denoising is in coping with pixel misalignment, which was so far handled with rather simplistic assumptions of simple motion, or the ability to align in pre-processing. Such assumptions are not realistic in the presence of large motion and high levels of noise. We show that Neural Radiance Fields (**NeRF**s), originally suggested for physics-based novel-view rendering, can serve as a powerful framework for burst denoising. **NeRF**s have an inherent capability of handling noise as they integrate information from multiple images, but they are limited in doing so, mainly since they build on pixel-wise operations which are suitable to ideal imaging conditions. Our approach, termed NAN, leverages inter-view and spatial information in **NeRF**s to better deal with noise. It achieves state-of-the-art results in burst denoising and is especially successful in coping with large movement and occlusions, under very high levels of noise. With the rapid advances in accelerating **NeRF**s, it could provide a powerful platform for denoising in challenging environments.  
### Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates. (arXiv:2204.04674v1 [cs.CV])
- Authors : Alina Roitberg, Kunyu Peng, David Schneider, Kailun Yang, Marios Koulakis, Manuel Martinez, Rainer Stiefelhagen
- Link : [http://arxiv.org/abs/2204.04674](http://arxiv.org/abs/2204.04674)
> ABSTRACT  :  Driver observation models are rarely deployed under perfect conditions. In practice, illumination, camera placement and type differ from the ones present during training and unforeseen behaviours may occur at any time. While observing the human behind the steering wheel leads to more intuitive human-vehicle-interaction and safer driving, it requires recognition algorithms which do not only predict the correct driver state, but also determine their prediction quality through realistic and interpretable confidence measures. Reliable uncertainty estimates are crucial for building trust and are a serious obstacle for deploying activity recognition networks in real driving systems. In this work, we for the first time examine how well the confidence values of modern driver observation models indeed match the probability of the correct outcome and show that raw neural network-based approaches tend to significantly overestimate their prediction quality. To correct this misalignment between the confidence values and the actual uncertainty, we consider two strategies. First, we enhance two activity recognition models often used for driver observation with temperature scaling-an off-the-shelf method for confidence calibration in image classification. Then, we introduce Calibrated Action Recognition with Input Guidance (CARING)-a novel approach leveraging an additional neural network to learn scaling the confidences depending on the video representation. Extensive experiments on the Drive&amp;Act dataset demonstrate that both strategies drastically improve the quality of model confidences, while our CARING model out-performs both, the original architectures and their temperature scaling **enhancement**, leading to best uncertainty estimates.  
### Simple Baselines for Image **Restoration**. (arXiv:2204.04676v1 [cs.CV])
- Authors : Liangyu Chen, Xiaojie Chu, Xiangyu Zhang, Jian Sun
- Link : [http://arxiv.org/abs/2204.04676](http://arxiv.org/abs/2204.04676)
> ABSTRACT  :  Although there have been significant advances in the field of image **restoration** recently, the system complexity of the state-of-the-art (SOTA) methods is increasing as well, which may hinder the convenient analysis and comparison of methods. In this paper, we propose a simple baseline that exceeds the SOTA methods and is computationally efficient. To further simplify the baseline, we reveal that the nonlinear activation functions, e.g. Sigmoid, ReLU, GELU, Softmax, etc. are not necessary: they could be replaced by multiplication or removed. Thus, we derive a Nonlinear Activation Free Network, namely NAFNet, from the baseline. SOTA results are achieved on various challenging benchmarks, e.g. 33.69 dB PSNR on GoPro (for image deblurring), exceeding the previous SOTA 0.38 dB with only 8.4% of its computational costs; 40.30 dB PSNR on SIDD (for image denoising), exceeding the previous SOTA 0.28 dB with less than half of its computational costs. The code and the pretrained models will be released at https://github.com/megvii-research/NAFNet.  
### Regularizing Attention Networks for Anomaly Detection in Visual Question Answering. (arXiv:2009.10054v3 [cs.CV] UPDATED)
- Authors : Doyup Lee, Yeongjae Cheon, Shin Han
- Link : [http://arxiv.org/abs/2009.10054](http://arxiv.org/abs/2009.10054)
> ABSTRACT  :  For stability and reliability of real-world applications, the robustness of DNNs in unimodal tasks has been evaluated. However, few studies consider abnormal situations that a visual question answering (VQA) model might encounter at test time after deployment in the real-world. In this study, we evaluate the robustness of state-of-the-art VQA models to five different anomalies, including worst-case scenarios, the most frequent scenarios, and the current limitation of VQA models. Different from the results in unimodal tasks, the maximum confidence of answers in VQA models cannot detect anomalous inputs, and post-training of the outputs, such as outlier **exposure**, is ineffective for VQA models. Thus, we propose an attention-based method, which uses confidence of reasoning between input images and questions and shows much more promising results than the previous methods in unimodal tasks. In addition, we show that a maximum entropy regularization of attention networks can significantly improve the attention-based anomaly detection of the VQA models. Thanks to the simplicity, attention-based anomaly detection and the regularization are model-agnostic methods, which can be used for various cross-modal attentions in the state-of-the-art VQA models. The results imply that cross-modal attention in VQA is important to improve not only VQA accuracy, but also the robustness to various anomalies.  
### **Swin** Transformer V2: Scaling Up Capacity and Resolution. (arXiv:2111.09883v2 [cs.CV] UPDATED)
- Authors : Ze Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li Dong, Furu Wei, Baining Guo
- Link : [http://arxiv.org/abs/2111.09883](http://arxiv.org/abs/2111.09883)
> ABSTRACT  :  Large-scale NLP models have been shown to significantly improve the performance on language tasks with no signs of saturation. They also demonstrate amazing few-shot capabilities like that of human beings. This paper aims to explore large-scale models in computer vision. We tackle three major issues in training and application of large vision models, including training instability, resolution gaps between pre-training and fine-tuning, and hunger on labelled data. Three main techniques are proposed: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) A log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) A self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images. Through these techniques, this paper successfully trained a 3 billion-parameter **Swin** Transformer V2 model, which is the largest dense vision model to date, and makes it capable of training with images of up to 1,536$\times$1,536 resolution. It set new performance records on 4 representative vision tasks, including ImageNet-V2 image classification, COCO object detection, ADE20K semantic segmentation, and Kinetics-400 video action classification. Also note our training is much more efficient than that in Google's billion-level visual models, which consumes 40 times less labelled data and 40 times less training time. Code is available at \url{https://github.com/microsoft/**Swin**-Transformer}.  
### Info**NeRF**: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v2 [cs.CV] UPDATED)
- Authors : Mijeong Kim, Seonguk Seo, Bohyung Han
- Link : [http://arxiv.org/abs/2112.15399](http://arxiv.org/abs/2112.15399)
> ABSTRACT  :  We present an information-theoretic regularization technique for few-shot novel view synthesis based on neural implicit representation. The proposed approach minimizes potential reconstruction inconsistency that happens due to insufficient viewpoints by imposing the entropy constraint of the density in each ray. In addition, to alleviate the potential degenerate issue when all training images are acquired from almost redundant viewpoints, we further incorporate the spatially smoothness constraint into the estimated images by restricting information gains from a pair of rays with slightly different viewpoints. The main idea of our algorithm is to make reconstructed scenes compact along individual rays and consistent across rays in the neighborhood. The proposed regularizers can be plugged into most of existing neural volume rendering techniques based on **NeRF** in a straightforward way. Despite its simplicity, we achieve consistently improved performance compared to existing neural view synthesis methods by large margins on multiple standard benchmarks.  
### **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
- Authors : Jiahao Huang, Yingying Fang, Yinzhe Wu, Huanjun Wu, Zhifan Gao, Yang Li, Javier Del, Jun Xia, Guang Yang
- Link : [http://arxiv.org/abs/2201.03230](http://arxiv.org/abs/2201.03230)
> ABSTRACT  :  Magnetic resonance imaging (MRI) is an important non-invasive clinical tool that can produce high-resolution and reproducible images. However, a long scanning time is required for high-quality MR images, which leads to exhaustion and discomfort of patients, inducing more artefacts due to voluntary movements of the patients and involuntary physiological movements. To accelerate the scanning process, methods by k-space undersampling and deep learning based reconstruction have been popularised. This work introduced **Swin**MR, a novel **Swin** transformer based method for fast MRI reconstruction. The whole network consisted of an input module (IM), a feature extraction module (FEM) and an output module (OM). The IM and OM were 2D convolutional layers and the FEM was composed of a cascaded of residual **Swin** transformer blocks (RSTBs) and 2D convolutional layers. The RSTB consisted of a series of **Swin** transformer layers (STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was performed in shifted windows rather than the multi-head self-attention (MSA) of the original transformer in the whole image space. A novel multi-channel loss was proposed by using the sensitivity maps, which was proved to reserve more textures and details. We performed a series of comparative studies and ablation studies in the Calgary-Campinas public brain MR dataset and conducted a downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation Challenge 2017 dataset. The results demonstrate our **Swin**MR achieved high-quality reconstruction compared with other benchmark methods, and it shows great robustness with different undersampling masks, under noise interruption and on different datasets. The code is publicly available at https://github.com/ayanglab/**Swin**MR.  
### DFTR: Depth-supervised Fusion Transformer for Salient Object Detection. (arXiv:2203.06429v2 [cs.CV] UPDATED)
- Authors : Heqin Zhu, Xu Sun, Yuexiang Li, Kai Ma, Kevin Zhou, Yefeng Zheng
- Link : [http://arxiv.org/abs/2203.06429](http://arxiv.org/abs/2203.06429)
> ABSTRACT  :  Automated salient object detection (SOD) plays an increasingly crucial role in many computer vision applications. By reformulating the depth information as supervision rather than as input, depth-supervised convolutional neural networks (CNN) have achieved promising results on both RGB and RGB-D SOD scenarios with the merits of no requirements for extra depth networks and depth inputs in the inference stage. This paper, for the first time, seeks to expand the applicability of depth supervision to the Transformer architecture. Specifically, we develop a Depth-supervised Fusion TRansformer (DFTR), to further improve the accuracy of both RGB and RGB-D SOD. The proposed DFTR involves three primary features: 1) DFTR, to the best of our knowledge, is the first pure Transformer-based model for depth-supervised SOD; 2) A multi-scale feature aggregation (MFA) module is proposed to fully exploit the multi-scale features encoded by the **Swin** Transformer in a coarse-to-fine manner; 3) To enable bidirectional information flow across different streams of features, a novel multi-stage feature fusion (MFF) module is further integrated into our DFTR with the emphasis on salient regions at different network learning stages. We extensively evaluate the proposed DFTR on ten benchmarking datasets. Experimental results show that our DFTR consistently outperforms the existing state-of-the-art methods for both RGB and RGB-D SOD tasks. The code and model will be made publicly available.  
## eess.IV
---
### Noise-based **Enhancement** for Foveated Rendering. (arXiv:2204.04455v1 [cs.GR])
- Authors : Taimoor Tariq, Cara Tursun, Piotr Didyk
- Link : [http://arxiv.org/abs/2204.04455](http://arxiv.org/abs/2204.04455)
> ABSTRACT  :  Human visual sensitivity to spatial details declines towards the periphery. Novel image synthesis techniques, so-called foveated rendering, exploit this observation and reduce the spatial resolution of synthesized images for the periphery, avoiding the synthesis of high-spatial-frequency details that are costly to generate but not perceived by a viewer. However, contemporary techniques do not make a clear distinction between the range of spatial frequencies that must be reproduced and those that can be omitted. For a given eccentricity, there is a range of frequencies that are detectable but not resolvable. While the accurate reproduction of these frequencies is not required, an observer can detect their absence if completely omitted. We use this observation to improve the performance of existing foveated rendering techniques. We demonstrate that this specific range of frequencies can be efficiently replaced with procedural noise whose parameters are carefully tuned to image content and human perception. Consequently, these frequencies do not have to be synthesized during rendering, allowing more aggressive foveation, and they can be replaced by noise generated in a less expensive post-processing step, leading to improved performance of the rendering system. Our main contribution is a perceptually-inspired technique for deriving the parameters of the noise required for the **enhancement** and its calibration. The method operates on rendering output and runs at rates exceeding 200FPS at 4K resolution, making it suitable for integration with real-time foveated rendering systems for VR and AR devices. We validate our results and compare them to the existing contrast **enhancement** technique in user experiments.  
### A Dual Sensor Computational Camera for High Quality **Dark** Videography. (arXiv:2204.04987v1 [eess.IV])
- Authors : Yuxiao Cheng, Runzhao Yang, Zhihong Zhang, Jinli Suo, Qionghai Dai
- Link : [http://arxiv.org/abs/2204.04987](http://arxiv.org/abs/2204.04987)
> ABSTRACT  :  Videos captured under **low light** conditions suffer from severe noise. A variety of efforts have been devoted to image/video noise suppression and made large progress. However, in extremely **dark** scenarios, extensive photon starvation would hamper precise noise modeling. Instead, developing an imaging system collecting more photons is a more effective way for high-quality video capture under low illuminations. In this paper, we propose to build a dual-sensor camera to additionally collect the photons in NIR wavelength, and make use of the correlation between RGB and near-infrared (NIR) spectrum to perform high-quality reconstruction from noisy **dark** video pairs. In hardware, we build a compact dual-sensor camera capturing RGB and NIR videos simultaneously. Computationally, we propose a dual-channel multi-frame attention network (DCMAN) utilizing spatial-temporal-spectral priors to reconstruct the **low-light** RGB and NIR videos. In addition, we build a high-quality paired RGB and NIR video dataset, based on which the approach can be applied to different sensors easily by training the DCMAN model with simulated noisy input following a physical-process-based CMOS noise model. Both experiments on synthetic and real videos validate the performance of this compact dual-sensor camera design and the corresponding reconstruction algorithm in **dark** videography.  
### Info**NeRF**: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v2 [cs.CV] UPDATED)
- Authors : Mijeong Kim, Seonguk Seo, Bohyung Han
- Link : [http://arxiv.org/abs/2112.15399](http://arxiv.org/abs/2112.15399)
> ABSTRACT  :  We present an information-theoretic regularization technique for few-shot novel view synthesis based on neural implicit representation. The proposed approach minimizes potential reconstruction inconsistency that happens due to insufficient viewpoints by imposing the entropy constraint of the density in each ray. In addition, to alleviate the potential degenerate issue when all training images are acquired from almost redundant viewpoints, we further incorporate the spatially smoothness constraint into the estimated images by restricting information gains from a pair of rays with slightly different viewpoints. The main idea of our algorithm is to make reconstructed scenes compact along individual rays and consistent across rays in the neighborhood. The proposed regularizers can be plugged into most of existing neural volume rendering techniques based on **NeRF** in a straightforward way. Despite its simplicity, we achieve consistently improved performance compared to existing neural view synthesis methods by large margins on multiple standard benchmarks.  
### **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
- Authors : Jiahao Huang, Yingying Fang, Yinzhe Wu, Huanjun Wu, Zhifan Gao, Yang Li, Javier Del, Jun Xia, Guang Yang
- Link : [http://arxiv.org/abs/2201.03230](http://arxiv.org/abs/2201.03230)
> ABSTRACT  :  Magnetic resonance imaging (MRI) is an important non-invasive clinical tool that can produce high-resolution and reproducible images. However, a long scanning time is required for high-quality MR images, which leads to exhaustion and discomfort of patients, inducing more artefacts due to voluntary movements of the patients and involuntary physiological movements. To accelerate the scanning process, methods by k-space undersampling and deep learning based reconstruction have been popularised. This work introduced **Swin**MR, a novel **Swin** transformer based method for fast MRI reconstruction. The whole network consisted of an input module (IM), a feature extraction module (FEM) and an output module (OM). The IM and OM were 2D convolutional layers and the FEM was composed of a cascaded of residual **Swin** transformer blocks (RSTBs) and 2D convolutional layers. The RSTB consisted of a series of **Swin** transformer layers (STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was performed in shifted windows rather than the multi-head self-attention (MSA) of the original transformer in the whole image space. A novel multi-channel loss was proposed by using the sensitivity maps, which was proved to reserve more textures and details. We performed a series of comparative studies and ablation studies in the Calgary-Campinas public brain MR dataset and conducted a downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation Challenge 2017 dataset. The results demonstrate our **Swin**MR achieved high-quality reconstruction compared with other benchmark methods, and it shows great robustness with different undersampling masks, under noise interruption and on different datasets. The code is publicly available at https://github.com/ayanglab/**Swin**MR.  
## cs.LG
---
### Optimization of IoT-Enabled Physical Location Monitoring Using DT and VAR. (arXiv:2204.04664v1 [cs.LG])
- Authors : Ajitkumar Sureshrao, Manoj Himmatrao
- Link : [http://arxiv.org/abs/2204.04664](http://arxiv.org/abs/2204.04664)
> ABSTRACT  :  This study shows an **enhancement** of IoT that gets sensor data and performs real-time face recognition to screen physical areas to find strange situations and send an alarm mail to the client to make remedial moves to avoid any potential misfortune in the environment. Sensor data is pushed onto the local system and GoDaddy Cloud whenever the camera detects a person to optimize the physical location monitoring system by reducing the bandwidth requirement and storage cost onto the cloud using edge computation. The study reveals that decision tree (DT) and random forest give reasonably similar macro average f1-scores to predict a person using sensor data. Experimental results show that DT is the most reliable predictive model for the cloud datasets of three different physical locations to predict a person using timestamp with an accuracy of 83.99%, 88.92%, and 80.97%. This study also explains multivariate time series prediction using vector auto regression that gives reasonably good root mean squared error to predict temperature, humidity, light-dependent resistor, and gas time series.  
### Regularizing Attention Networks for Anomaly Detection in Visual Question Answering. (arXiv:2009.10054v3 [cs.CV] UPDATED)
- Authors : Doyup Lee, Yeongjae Cheon, Shin Han
- Link : [http://arxiv.org/abs/2009.10054](http://arxiv.org/abs/2009.10054)
> ABSTRACT  :  For stability and reliability of real-world applications, the robustness of DNNs in unimodal tasks has been evaluated. However, few studies consider abnormal situations that a visual question answering (VQA) model might encounter at test time after deployment in the real-world. In this study, we evaluate the robustness of state-of-the-art VQA models to five different anomalies, including worst-case scenarios, the most frequent scenarios, and the current limitation of VQA models. Different from the results in unimodal tasks, the maximum confidence of answers in VQA models cannot detect anomalous inputs, and post-training of the outputs, such as outlier **exposure**, is ineffective for VQA models. Thus, we propose an attention-based method, which uses confidence of reasoning between input images and questions and shows much more promising results than the previous methods in unimodal tasks. In addition, we show that a maximum entropy regularization of attention networks can significantly improve the attention-based anomaly detection of the VQA models. Thanks to the simplicity, attention-based anomaly detection and the regularization are model-agnostic methods, which can be used for various cross-modal attentions in the state-of-the-art VQA models. The results imply that cross-modal attention in VQA is important to improve not only VQA accuracy, but also the robustness to various anomalies.  
### Exposing Query Identification for Search Transparency. (arXiv:2110.07701v3 [cs.IR] UPDATED)
- Authors : Ruohan Li, Jianxiang Li, Bhaskar Mitra, Fernando Diaz
- Link : [http://arxiv.org/abs/2110.07701](http://arxiv.org/abs/2110.07701)
> ABSTRACT  :  Search systems control the **exposure** of ranked content to searchers. In many cases, creators value not only the **exposure** of their content but, moreover, an understanding of the specific searches where the content is surfaced. The problem of identifying which queries expose a given piece of content in the ranking results is an important and relatively under-explored search transparency challenge. Exposing queries are useful for quantifying various issues of search bias, privacy, data protection, security, and search engine optimization.    Exact identification of exposing queries in a given system is computationally expensive, especially in dynamic contexts such as web search. We explore the feasibility of approximate exposing query identification (EQI) as a retrieval task by reversing the role of queries and documents in two classes of search systems: dense dual-encoder models and traditional BM25 models. We then propose how this approach can be improved through metric learning over the retrieval embedding space. We further derive an evaluation metric to measure the quality of a ranking of exposing queries, as well as conducting an empirical analysis focusing on various practical aspects of approximate EQI. Overall, our work contributes a novel conception of transparency in search systems and computational means of achieving it.  
### **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
- Authors : Jiahao Huang, Yingying Fang, Yinzhe Wu, Huanjun Wu, Zhifan Gao, Yang Li, Javier Del, Jun Xia, Guang Yang
- Link : [http://arxiv.org/abs/2201.03230](http://arxiv.org/abs/2201.03230)
> ABSTRACT  :  Magnetic resonance imaging (MRI) is an important non-invasive clinical tool that can produce high-resolution and reproducible images. However, a long scanning time is required for high-quality MR images, which leads to exhaustion and discomfort of patients, inducing more artefacts due to voluntary movements of the patients and involuntary physiological movements. To accelerate the scanning process, methods by k-space undersampling and deep learning based reconstruction have been popularised. This work introduced **Swin**MR, a novel **Swin** transformer based method for fast MRI reconstruction. The whole network consisted of an input module (IM), a feature extraction module (FEM) and an output module (OM). The IM and OM were 2D convolutional layers and the FEM was composed of a cascaded of residual **Swin** transformer blocks (RSTBs) and 2D convolutional layers. The RSTB consisted of a series of **Swin** transformer layers (STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was performed in shifted windows rather than the multi-head self-attention (MSA) of the original transformer in the whole image space. A novel multi-channel loss was proposed by using the sensitivity maps, which was proved to reserve more textures and details. We performed a series of comparative studies and ablation studies in the Calgary-Campinas public brain MR dataset and conducted a downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation Challenge 2017 dataset. The results demonstrate our **Swin**MR achieved high-quality reconstruction compared with other benchmark methods, and it shows great robustness with different undersampling masks, under noise interruption and on different datasets. The code is publicly available at https://github.com/ayanglab/**Swin**MR.  
### Sign and Basis Invariant Networks for Spectral Graph Representation Learning. (arXiv:2202.13013v2 [cs.LG] UPDATED)
- Authors : Derek Lim, Joshua Robinson, Lingxiao Zhao, Tess Smidt, Suvrit Sra, Haggai Maron, Stefanie Jegelka
- Link : [http://arxiv.org/abs/2202.13013](http://arxiv.org/abs/2202.13013)
> ABSTRACT  :  Many machine learning tasks involve processing eigenvectors derived from data. Especially valuable are Laplacian eigenvectors, which capture useful structural information about graphs and other geometric objects. However, ambiguities arise when computing eigenvectors: for each eigenvector $v$, the sign flipped $-v$ is also an eigenvector. More generally, higher dimensional eigenspaces contain infinitely many choices of basis eigenvectors. These ambiguities make it a challenge to process eigenvectors and eigenspaces in a consistent way. In this work we introduce SignNet and BasisNet -- new neural architectures that are invariant to all requisite symmetries and hence process collections of eigenspaces in a principled manner. Our networks are universal, i.e., they can approximate any continuous function of eigenvectors with the proper invariances. They are also theoretically strong for graph representation learning -- they can approximate any spectral graph convolution, can compute spectral invariants that go beyond message passing neural networks, and can provably simulate previously proposed graph positional encodings. Experiments show the strength of our networks for molecular graph regression, learning expressive graph representations, and learning **implicit neural representation**s on triangle meshes. Our code is available at https://github.com/cptq/SignNet-BasisNet .  
## cs.AI
---
### Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates. (arXiv:2204.04674v1 [cs.CV])
- Authors : Alina Roitberg, Kunyu Peng, David Schneider, Kailun Yang, Marios Koulakis, Manuel Martinez, Rainer Stiefelhagen
- Link : [http://arxiv.org/abs/2204.04674](http://arxiv.org/abs/2204.04674)
> ABSTRACT  :  Driver observation models are rarely deployed under perfect conditions. In practice, illumination, camera placement and type differ from the ones present during training and unforeseen behaviours may occur at any time. While observing the human behind the steering wheel leads to more intuitive human-vehicle-interaction and safer driving, it requires recognition algorithms which do not only predict the correct driver state, but also determine their prediction quality through realistic and interpretable confidence measures. Reliable uncertainty estimates are crucial for building trust and are a serious obstacle for deploying activity recognition networks in real driving systems. In this work, we for the first time examine how well the confidence values of modern driver observation models indeed match the probability of the correct outcome and show that raw neural network-based approaches tend to significantly overestimate their prediction quality. To correct this misalignment between the confidence values and the actual uncertainty, we consider two strategies. First, we enhance two activity recognition models often used for driver observation with temperature scaling-an off-the-shelf method for confidence calibration in image classification. Then, we introduce Calibrated Action Recognition with Input Guidance (CARING)-a novel approach leveraging an additional neural network to learn scaling the confidences depending on the video representation. Extensive experiments on the Drive&amp;Act dataset demonstrate that both strategies drastically improve the quality of model confidences, while our CARING model out-performs both, the original architectures and their temperature scaling **enhancement**, leading to best uncertainty estimates.  
### Exposing Query Identification for Search Transparency. (arXiv:2110.07701v3 [cs.IR] UPDATED)
- Authors : Ruohan Li, Jianxiang Li, Bhaskar Mitra, Fernando Diaz
- Link : [http://arxiv.org/abs/2110.07701](http://arxiv.org/abs/2110.07701)
> ABSTRACT  :  Search systems control the **exposure** of ranked content to searchers. In many cases, creators value not only the **exposure** of their content but, moreover, an understanding of the specific searches where the content is surfaced. The problem of identifying which queries expose a given piece of content in the ranking results is an important and relatively under-explored search transparency challenge. Exposing queries are useful for quantifying various issues of search bias, privacy, data protection, security, and search engine optimization.    Exact identification of exposing queries in a given system is computationally expensive, especially in dynamic contexts such as web search. We explore the feasibility of approximate exposing query identification (EQI) as a retrieval task by reversing the role of queries and documents in two classes of search systems: dense dual-encoder models and traditional BM25 models. We then propose how this approach can be improved through metric learning over the retrieval embedding space. We further derive an evaluation metric to measure the quality of a ranking of exposing queries, as well as conducting an empirical analysis focusing on various practical aspects of approximate EQI. Overall, our work contributes a novel conception of transparency in search systems and computational means of achieving it.  
### Social Neuro AI: Social Interaction as the "**dark** matter" of AI. (arXiv:2112.15459v3 [cs.MA] UPDATED)
- Authors : Samuele Bolotta, Guillaume Dumas
- Link : [http://arxiv.org/abs/2112.15459](http://arxiv.org/abs/2112.15459)
> ABSTRACT  :  This article introduces a three-axis framework indicating how AI can be informed by biological examples of social learning mechanisms. We argue that the complex human cognitive architecture owes a large portion of its expressive power to its ability to engage in social and cultural learning. However, the field of AI has mostly embraced a solipsistic perspective on intelligence. We thus argue that social interactions not only are largely unexplored in this field but also are an essential element of advanced cognitive ability, and therefore constitute metaphorically the **dark** matter of AI. In the first section, we discuss how social learning plays a key role in the development of intelligence. We do so by discussing social and cultural learning theories and empirical findings from social neuroscience. Then, we discuss three lines of research that fall under the umbrella of Social NeuroAI and can contribute to developing socially intelligent embodied agents in complex environments. First, neuroscientific theories of cognitive architecture, such as the global workspace theory and the attention schema theory, can enhance biological plausibility and help us understand how we could bridge individual and social theories of intelligence. Second, intelligence occurs in time as opposed to over time, and this is naturally incorporated by dynamical systems. Third, embodiment has been demonstrated to provide more sophisticated array of communicative signals. To conclude, we discuss the example of active inference, which offers powerful insights for developing agents that possess biological realism, can self-organize in time, and are socially embodied.  
### **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
- Authors : Jiahao Huang, Yingying Fang, Yinzhe Wu, Huanjun Wu, Zhifan Gao, Yang Li, Javier Del, Jun Xia, Guang Yang
- Link : [http://arxiv.org/abs/2201.03230](http://arxiv.org/abs/2201.03230)
> ABSTRACT  :  Magnetic resonance imaging (MRI) is an important non-invasive clinical tool that can produce high-resolution and reproducible images. However, a long scanning time is required for high-quality MR images, which leads to exhaustion and discomfort of patients, inducing more artefacts due to voluntary movements of the patients and involuntary physiological movements. To accelerate the scanning process, methods by k-space undersampling and deep learning based reconstruction have been popularised. This work introduced **Swin**MR, a novel **Swin** transformer based method for fast MRI reconstruction. The whole network consisted of an input module (IM), a feature extraction module (FEM) and an output module (OM). The IM and OM were 2D convolutional layers and the FEM was composed of a cascaded of residual **Swin** transformer blocks (RSTBs) and 2D convolutional layers. The RSTB consisted of a series of **Swin** transformer layers (STLs). The shifted windows multi-head self-attention (W-MSA/SW-MSA) of STL was performed in shifted windows rather than the multi-head self-attention (MSA) of the original transformer in the whole image space. A novel multi-channel loss was proposed by using the sensitivity maps, which was proved to reserve more textures and details. We performed a series of comparative studies and ablation studies in the Calgary-Campinas public brain MR dataset and conducted a downstream segmentation experiment in the Multi-modal Brain Tumour Segmentation Challenge 2017 dataset. The results demonstrate our **Swin**MR achieved high-quality reconstruction compared with other benchmark methods, and it shows great robustness with different undersampling masks, under noise interruption and on different datasets. The code is publicly available at https://github.com/ayanglab/**Swin**MR.  
### "Does it come in black?" CLIP-like models are zero-shot recommenders. (arXiv:2204.02473v2 [cs.IR] UPDATED)
- Authors : Patrick John, Jacopo Tagliabue, Federico Bianchi, Ciro Greco, Diogo Goncalves
- Link : [http://arxiv.org/abs/2204.02473](http://arxiv.org/abs/2204.02473)
> ABSTRACT  :  Product discovery is a crucial component for online shopping. However, item-to-item recommendations today do not allow users to explore changes along selected dimensions: given a query item, can a model suggest something similar but in a different color? We consider item recommendations of the comparative nature (e.g. "something **dark**er") and show how CLIP-based models can support this use case in a zero-shot manner. Leveraging a large model built for fashion, we introduce GradREC and its industry potential, and offer a first rounded assessment of its strength and weaknesses.  
# Paper List
---
## cs.CV
---
**151** new papers in cs.CV:-) 
1. Intelligent Sight and Sound: A Chronic Cancer Pain Dataset. (arXiv:2204.04214v1 [eess.IV])
2. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v1 [cs.LG])
3. Learning Trajectory-Aware Transformer for Video Super-Resolution. (arXiv:2204.04216v1 [eess.IV])
4. Feature-enhanced Adversarial Semi-supervised Semantic Segmentation Network for Pulmonary Embolism Annotation. (arXiv:2204.04217v1 [eess.IV])
5. Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes for Medical Image Super-Resolution. (arXiv:2204.04218v1 [eess.IV])
6. Towards Reliable and Explainable AI Model for Solid Pulmonary Nodule Diagnosis. (arXiv:2204.04219v1 [eess.IV])
7. Vision-Based American Sign Language Classification Approach via Deep Learning. (arXiv:2204.04235v1 [cs.CV])
8. ChildCI Framework: Analysis of Motor and Cognitive Development in Children-Computer Interaction for Age Detection. (arXiv:2204.04236v1 [cs.HC])
9. Elastic shape analysis of surfaces with second-order Sobolev metrics: a comprehensive numerical framework. (arXiv:2204.04238v1 [cs.CV])
10. Understanding the Influence of Receptive Field and Network Complexity in Neural-Network-Guided TEM Image Analysis. (arXiv:2204.04250v1 [cond-mat.mtrl-sci])
11. On Improving Cross-dataset Generalization of Deepfake Detectors. (arXiv:2204.04285v1 [cs.CV])
12. Learning to modulate random weights can induce task-specific contexts for economical meta and continual learning. (arXiv:2204.04297v1 [cs.LG])
13. Segmenting across places: The need for fair transfer learning with satellite imagery. (arXiv:2204.04358v1 [cs.CV])
14. Attention guided global **enhancement** and local refinement network for semantic segmentation. (arXiv:2204.04363v1 [cs.CV])
15. Channel Pruning In Quantization-aware Training: An Adaptive Projection-gradient Descent-shrinkage-splitting Method. (arXiv:2204.04375v1 [cs.LG])
16. Robotic Surgery Remote Mentoring via AR with 3D Scene Streaming and Hand Interaction. (arXiv:2204.04377v1 [cs.CV])
17. Beyond 3DMM: Learning to Capture High-fidelity 3D Face Shape. (arXiv:2204.04379v1 [cs.CV])
18. A dataset of ant colonies motion trajectories in indoor and outdoor scenes for social cluster behavior study. (arXiv:2204.04380v1 [cs.CV])
19. Federated Unsupervised Domain Adaptation for Face Recognition. (arXiv:2204.04382v1 [cs.CV])
20. The Two Dimensions of Worst-case Training and the Integrated Effect for Out-of-domain Generalization. (arXiv:2204.04384v1 [cs.LG])
21. Divergence-aware Federated Self-Supervised Learning. (arXiv:2204.04385v1 [cs.LG])
22. Dual-Stage Approach Toward Hyperspectral Image Super-Resolution. (arXiv:2204.04387v1 [eess.IV])
23. E^2TAD: An Energy-Efficient Tracking-based Action Detector. (arXiv:2204.04416v1 [cs.CV])
24. Mapping Temporary Slums from Satellite Imagery using a Semi-Supervised Approach. (arXiv:2204.04419v1 [cs.CV])
25. Unbiased Directed Object Attention Graph for Object Navigation. (arXiv:2204.04421v1 [cs.CV])
26. Adaptive Differential Filters for Fast and Communication-Efficient Federated Learning. (arXiv:2204.04424v1 [cs.LG])
27. ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise Semantic Alignment and Generation. (arXiv:2204.04428v1 [cs.CV])
28. HSTR-Net: High Spatio-Temporal Resolution Video Generation For Wide Area Surveillance. (arXiv:2204.04435v1 [cs.CV])
29. Guided deep learning by subaperture decomposition: ocean patterns from SAR imagery. (arXiv:2204.04438v1 [cs.CV])
30. Noise-based **Enhancement** for Foveated Rendering. (arXiv:2204.04455v1 [cs.GR])
31. Refining time-space traffic diagrams: A multiple linear regression model. (arXiv:2204.04457v1 [cs.CV])
32. A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural Network for Multisource Remote Sensing Data Classification. (arXiv:2204.04462v1 [cs.CV])
33. Ultrasound Signal Processing: From Models to Deep Learning. (arXiv:2204.04466v1 [eess.SP])
34. S4OD: Semi-Supervised learning for Single-Stage Object Detection. (arXiv:2204.04492v1 [cs.CV])
35. DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides. (arXiv:2204.04494v1 [cs.CV])
36. On the Exploitation of Deepfake Model Recognition. (arXiv:2204.04513v1 [cs.CV])
37. Uncertainty-Informed Deep Learning Models Enable High-Confidence Predictions for Digital Histopathology. (arXiv:2204.04516v1 [q-bio.QM])
38. Knowledge-Free Black-Box Watermark and Ownership Proof for Image Classification Neural Networks. (arXiv:2204.04522v1 [cs.CR])
39. Self-Labeling Refinement for Robust Representation Learning with Bootstrap Your Own Latent. (arXiv:2204.04545v1 [cs.CV])
40. Adaptive search area for fast motion estimation. (arXiv:2204.04546v1 [cs.CV])
41. Multimodal Transformer for Nursing Activity Recognition. (arXiv:2204.04564v1 [cs.CV])
42. Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification. (arXiv:2204.04567v1 [cs.CV])
43. Robust Cross-Modal Representation Learning with Progressive Self-Distillation. (arXiv:2204.04588v1 [cs.CV])
44. Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention. (arXiv:2204.04601v1 [cs.CV])
45. Self-Supervised Video Representation Learning with Motion-Contrastive Perception. (arXiv:2204.04607v1 [cs.CV])
46. Learning Pixel-Level Distinctions for Video Highlight Detection. (arXiv:2204.04615v1 [cs.CV])
47. On Principal Curve-Based Classifiers and Similarity-Based Selective Sampling in Time-Series. (arXiv:2204.04620v1 [cs.CV])
48. Unsupervised Manga Character Re-identification via Face-body and Spatial-temporal Associated Clustering. (arXiv:2204.04621v1 [cs.CV])
49. Stripformer: Strip Transformer for Fast Image Deblurring. (arXiv:2204.04627v1 [cs.CV])
50. Intersection Prediction from Single 360{\deg} Image via Deep Detection of Possible Direction of Travel. (arXiv:2204.04634v1 [cs.CV])
51. ConsInstancy: Learning Instance Representations for Semi-Supervised Panoptic Segmentation of Concrete Aggregate Particles. (arXiv:2204.04635v1 [cs.CV])
52. Spectral Unmixing of Hyperspectral Images Based on Block Sparse Structure. (arXiv:2204.04638v1 [eess.IV])
53. Counting in the 2020s: Binned Representations and Inclusive Performance Measures for Deep Crowd Counting Approaches. (arXiv:2204.04653v1 [cs.CV])
54. Fashionformer: A simple, Effective and Unified Baseline for Human Fashion Segmentation and Recognition. (arXiv:2204.04654v1 [cs.CV])
55. Panoptic-PartFormer: Learning a Unified Model for Panoptic Part Segmentation. (arXiv:2204.04655v1 [cs.CV])
56. Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation. (arXiv:2204.04656v1 [cs.CV])
57. FOSTER: Feature Boosting and Compression for Class-Incremental Learning. (arXiv:2204.04662v1 [cs.CV])
58. Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss. (arXiv:2204.04665v1 [cs.CV])
59. Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v1 [cs.LG])
60. NAN: Noise-Aware **NeRF**s for Burst-Denoising. (arXiv:2204.04668v1 [cs.CV])
61. Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates. (arXiv:2204.04674v1 [cs.CV])
62. Simple Baselines for Image **Restoration**. (arXiv:2204.04676v1 [cs.CV])
63. FedCorr: Multi-Stage Federated Learning for Label Noise Correction. (arXiv:2204.04677v1 [cs.LG])
64. Scale Invariant Semantic Segmentation with RGB-D Fusion. (arXiv:2204.04679v1 [cs.CV])
65. Reasoning with Multi-Structure Commonsense Knowledge in Visual Dialog. (arXiv:2204.04680v1 [cs.CV])
66. Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search. (arXiv:2204.04681v1 [cs.CV])
67. Coreset of Hyperspectral Images on Small Quantum Computer. (arXiv:2204.04691v1 [quant-ph])
68. An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm with Grey Wolf Optimization (GWO). (arXiv:2204.04704v1 [cs.CV])
69. Generative Adversarial Networks for Image Augmentation in Agriculture: A Systematic Review. (arXiv:2204.04707v1 [cs.CV])
70. Image Harmonization by Matching Regional References. (arXiv:2204.04715v1 [cs.CV])
71. TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-supervised Learning. (arXiv:2204.04716v1 [cs.CV])
72. Deep Non-rigid Structure-from-Motion: A Sequence-to-Sequence Translation Perspective. (arXiv:2204.04730v1 [cs.CV])
73. A Comparative Analysis of Decision-Level Fusion for Multimodal Driver Behaviour Understanding. (arXiv:2204.04734v1 [cs.CV])
74. CholecTriplet2021: A benchmark challenge for surgical action triplet recognition. (arXiv:2204.04746v1 [cs.CV])
75. Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization Using Satellite Image. (arXiv:2204.04752v1 [cs.CV])
76. DILEMMA: Self-Supervised Shape and Texture Learning with Transformers. (arXiv:2204.04788v1 [cs.CV])
77. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v1 [cs.CV])
78. DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning. (arXiv:2204.04799v1 [cs.LG])
79. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v1 [cs.CV])
80. Spatial-Spectral Feature Extraction via Deep ConvLSTM Neural Networks for Hyperspectral Image Classification. (arXiv:1905.03577v2 [cs.CV] UPDATED)
81. Harmonic Convolutional Networks based on Discrete Cosine Transform. (arXiv:2001.06570v3 [cs.CV] UPDATED)
82. Leveraging Affect Transfer Learning for Behavior Prediction in an Intelligent Tutoring System. (arXiv:2002.05242v2 [cs.CV] UPDATED)
83. Adversarial Robustness of Deep Sensor Fusion Models. (arXiv:2006.13192v3 [cs.CV] UPDATED)
84. Neural networks with late-phase weights. (arXiv:2007.12927v4 [cs.LG] UPDATED)
85. Regularizing Attention Networks for Anomaly Detection in Visual Question Answering. (arXiv:2009.10054v3 [cs.CV] UPDATED)
86. No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems. (arXiv:2011.12945v2 [cs.LG] UPDATED)
87. Curriculum Learning: A Survey. (arXiv:2101.10382v3 [cs.LG] UPDATED)
88. The MSR-Video to Text Dataset with Clean Annotations. (arXiv:2102.06448v3 [cs.CV] UPDATED)
89. VAE Approximation Error: ELBO and Exponential Families. (arXiv:2102.09310v4 [cs.LG] UPDATED)
90. Deeply Unsupervised Patch Re-Identification for Pre-training Object Detectors. (arXiv:2103.04814v2 [cs.CV] UPDATED)
91. Believe The HiPe: Hierarchical Perturbation for Fast, Robust, and Model-Agnostic Saliency Mapping. (arXiv:2103.05108v3 [cs.CV] UPDATED)
92. PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning. (arXiv:2103.09504v4 [cs.LG] UPDATED)
93. Consistency-based Active Learning for Object Detection. (arXiv:2103.10374v3 [cs.CV] UPDATED)
94. A State-of-the-art Survey of Object Detection Techniques in Microorganism Image Analysis: From Classical Methods to Deep Learning Approaches. (arXiv:2105.03148v2 [cs.CV] UPDATED)
95. Recent advances and clinical applications of deep learning in medical image analysis. (arXiv:2105.13381v3 [cs.CV] UPDATED)
96. Contextual Guided Segmentation Framework for Semi-supervised Video Instance Segmentation. (arXiv:2106.03330v2 [cs.CV] UPDATED)
97. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v2 [cs.CV] UPDATED)
98. Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective. (arXiv:2106.07115v3 [cs.LG] UPDATED)
99. SAR-Net: Shape Alignment and Recovery Network for Category-level 6D Object Pose and Size Estimation. (arXiv:2106.14193v2 [cs.CV] UPDATED)
100. Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v4 [cs.LG] UPDATED)
101. Is attention to bounding boxes all you need for pedestrian action prediction?. (arXiv:2107.08031v3 [cs.CV] UPDATED)
102. Bridging Gap between Image Pixels and Semantics via Supervision: A Survey. (arXiv:2107.13757v3 [cs.CV] UPDATED)
103. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v3 [cs.CV] UPDATED)
104. NODEO: A Neural Ordinary Differential Equation Based Optimization Framework for Deformable Image Registration. (arXiv:2108.03443v4 [cs.CV] UPDATED)
105. A Self-Distillation Embedded Supervised Affinity Attention Model for Few-Shot Segmentation. (arXiv:2108.06600v2 [cs.CV] UPDATED)
106. MMChat: Multi-Modal Chat Dataset on Social Media. (arXiv:2108.07154v2 [cs.CL] UPDATED)
107. PatchCleanser: Certifiably Robust Defense against Adversarial Patches for Any Image Classifier. (arXiv:2108.09135v2 [cs.CV] UPDATED)
108. Rethinking the Misalignment Problem in Dense Object Detection. (arXiv:2108.12176v4 [cs.CV] UPDATED)
109. On Pursuit of Designing Multi-modal Transformer for Video Grounding. (arXiv:2109.06085v2 [cs.CV] UPDATED)
110. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v3 [cs.LG] UPDATED)
111. Arch-Net: Model Distillation for Architecture Agnostic Model Deployment. (arXiv:2111.01135v2 [cs.LG] UPDATED)
112. LTD: Low Temperature Distillation for Robust Adversarial Training. (arXiv:2111.02331v2 [cs.CV] UPDATED)
113. SMU: smooth activation function for deep networks using smoothing maximum technique. (arXiv:2111.04682v2 [cs.LG] UPDATED)
114. FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy. (arXiv:2111.05623v3 [cs.RO] UPDATED)
115. **Swin** Transformer V2: Scaling Up Capacity and Resolution. (arXiv:2111.09883v2 [cs.CV] UPDATED)
116. Transferability Estimation using Bhattacharyya Class Separability. (arXiv:2111.12780v3 [cs.CV] UPDATED)
117. Towards Low-Cost and Efficient Malaria Detection. (arXiv:2111.13656v2 [cs.CV] UPDATED)
118. n-CPS: Generalising Cross Pseudo Supervision to n Networks for Semi-Supervised Semantic Segmentation. (arXiv:2112.07528v4 [cs.CV] UPDATED)
119. Spatial Distribution Patterns and Stress Potential Signs of Clownfish in Recirculating Aquaculture Systems. (arXiv:2112.14513v2 [cs.CV] UPDATED)
120. Info**NeRF**: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v2 [cs.CV] UPDATED)
121. Semantically Grounded Visual Embeddings for Zero-Shot Learning. (arXiv:2201.00577v2 [cs.CV] UPDATED)
122. An unambiguous cloudiness index for nonwovens. (arXiv:2201.02011v2 [cs.CV] UPDATED)
123. **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
124. Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection. (arXiv:2201.07131v2 [cs.CV] UPDATED)
125. POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v3 [eess.IV] UPDATED)
126. BERTHA: Video Captioning Evaluation Via Transfer-Learned Human Assessment. (arXiv:2201.10243v2 [cs.CV] UPDATED)
127. Deep Contrastive Learning is Provably (almost) Principal Component Analysis. (arXiv:2201.12680v3 [cs.LG] UPDATED)
128. Grounding Answers for Visual Questions Asked by Visually Impaired People. (arXiv:2202.01993v3 [cs.CV] UPDATED)
129. SSHA: Video Violence Recognition and Localization Using a Semi-Supervised Hard Attention Model. (arXiv:2202.02212v3 [cs.CV] UPDATED)
130. Exploring Wilderness Using Explainable Machine Learning in Satellite Imagery. (arXiv:2203.00379v2 [cs.CV] UPDATED)
131. SingleSketch2Mesh : Generating 3D Mesh model from Sketch. (arXiv:2203.03157v3 [cs.CV] UPDATED)
132. Towards Open-Set Text Recognition via Label-to-Prototype Learning. (arXiv:2203.05179v2 [cs.CV] UPDATED)
133. DFTR: Depth-supervised Fusion Transformer for Salient Object Detection. (arXiv:2203.06429v2 [cs.CV] UPDATED)
134. Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v2 [cs.CR] UPDATED)
135. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v2 [eess.IV] UPDATED)
136. RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization. (arXiv:2203.12870v3 [cs.CV] UPDATED)
137. Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction. (arXiv:2203.12997v2 [cs.CV] UPDATED)
138. Playing Lottery Tickets in Style Transfer Models. (arXiv:2203.13802v2 [cs.CV] UPDATED)
139. PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level Defective Region Segmentation. (arXiv:2203.14457v2 [cs.CV] UPDATED)
140. Data-Driven, Soft Alignment of Functional Data Using Shapes and Landmarks. (arXiv:2203.14810v2 [stat.ME] UPDATED)
141. A systematic review and meta-analysis of Digital Elevation Model (DEM) fusion: pre-processing, methods and applications. (arXiv:2203.15026v2 [cs.CV] UPDATED)
142. In-N-Out Generative Learning for Dense Unsupervised Video Segmentation. (arXiv:2203.15312v2 [cs.CV] UPDATED)
143. CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters. (arXiv:2203.15331v2 [cs.CV] UPDATED)
144. mc-BEiT: Multi-choice Discretization for Image BERT Pre-training. (arXiv:2203.15371v2 [cs.CV] UPDATED)
145. Smooth Robust Tensor Completion for Background/Foreground Separation with Missing Pixels: Novel Algorithm with Convergence Guarantee. (arXiv:2203.16328v2 [cs.CV] UPDATED)
146. GEB+: A benchmark for generic event boundary captioning, grounding and text-based retrieval. (arXiv:2204.00486v2 [cs.CV] UPDATED)
147. How stable are Transferability Metrics evaluations?. (arXiv:2204.01403v2 [cs.CV] UPDATED)
148. DSGN++: Exploiting Visual-Spatial Relation for Stereo-based 3D Detectors. (arXiv:2204.03039v2 [cs.CV] UPDATED)
149. Incremental Prototype Prompt-tuning with Pre-trained Representation for Class Incremental Learning. (arXiv:2204.03410v2 [cs.CV] UPDATED)
150. The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v2 [cs.LG] UPDATED)
151. DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image. (arXiv:2204.03688v2 [cs.CV] UPDATED)
## eess.IV
---
**46** new papers in eess.IV:-) 
1. Intelligent Sight and Sound: A Chronic Cancer Pain Dataset. (arXiv:2204.04214v1 [eess.IV])
2. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v1 [cs.LG])
3. Learning Trajectory-Aware Transformer for Video Super-Resolution. (arXiv:2204.04216v1 [eess.IV])
4. Feature-enhanced Adversarial Semi-supervised Semantic Segmentation Network for Pulmonary Embolism Annotation. (arXiv:2204.04217v1 [eess.IV])
5. Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes for Medical Image Super-Resolution. (arXiv:2204.04218v1 [eess.IV])
6. Towards Reliable and Explainable AI Model for Solid Pulmonary Nodule Diagnosis. (arXiv:2204.04219v1 [eess.IV])
7. Understanding the Influence of Receptive Field and Network Complexity in Neural-Network-Guided TEM Image Analysis. (arXiv:2204.04250v1 [cond-mat.mtrl-sci])
8. Dual-Stage Approach Toward Hyperspectral Image Super-Resolution. (arXiv:2204.04387v1 [eess.IV])
9. CMOS Circuit Implementation of Spiking Neural Network for Pattern Recognition Using On-chip Unsupervised STDP Learning. (arXiv:2204.04430v1 [eess.IV])
10. HSTR-Net: High Spatio-Temporal Resolution Video Generation For Wide Area Surveillance. (arXiv:2204.04435v1 [cs.CV])
11. Noise-based **Enhancement** for Foveated Rendering. (arXiv:2204.04455v1 [cs.GR])
12. A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural Network for Multisource Remote Sensing Data Classification. (arXiv:2204.04462v1 [cs.CV])
13. Ultrasound Signal Processing: From Models to Deep Learning. (arXiv:2204.04466v1 [eess.SP])
14. Uncertainty-Informed Deep Learning Models Enable High-Confidence Predictions for Digital Histopathology. (arXiv:2204.04516v1 [q-bio.QM])
15. Spectral Unmixing of Hyperspectral Images Based on Block Sparse Structure. (arXiv:2204.04638v1 [eess.IV])
16. Generative Adversarial Networks for Image Augmentation in Agriculture: A Systematic Review. (arXiv:2204.04707v1 [cs.CV])
17. Denoiser-based projections for 2-D super-resolution multi-reference alignment. (arXiv:2204.04754v1 [eess.IV])
18. Image Reconstruction for MRI using Deep CNN Priors Trained without Groundtruth. (arXiv:2204.04771v1 [eess.IV])
19. Why Shape Coding? Asymptotic Analysis of the Entropy Rate for Digital Images. (arXiv:2204.04857v1 [cs.IT])
20. Confusing Image Quality Assessment: Towards Better Augmented Reality Experience. (arXiv:2204.04900v1 [cs.CV])
21. A Semantic Segmentation Network Based Real-Time Computer-Aided Diagnosis System for Hydatidiform Mole Hydrops Lesion Recognition in Microscopic View. (arXiv:2204.04949v1 [eess.IV])
22. Segmentation Network with Compound Loss Function for Hydatidiform Mole Hydrops Lesion Recognition. (arXiv:2204.04956v1 [eess.IV])
23. Assessing hierarchies by their consistent segmentations. (arXiv:2204.04969v1 [cs.CV])
24. A Dual Sensor Computational Camera for High Quality **Dark** Videography. (arXiv:2204.04987v1 [eess.IV])
25. Ischemic Stroke Lesion Segmentation Using Adversarial Learning. (arXiv:2204.04993v1 [eess.IV])
26. Learning-based Lossless Point Cloud Geometry Coding using Sparse Representations. (arXiv:2204.05043v1 [eess.IV])
27. From CNNs to Vision Transformers -- A Comprehensive Evaluation of Deep Learning Models for Histopathology. (arXiv:2204.05044v1 [eess.IV])
28. PetroGAN: A novel GAN-based approach to generate realistic, label-free petrographic datasets. (arXiv:2204.05114v1 [cs.CV])
29. IMLE-Net: An Interpretable Multi-level Multi-channel Model for ECG Classification. (arXiv:2204.05116v1 [eess.SP])
30. NeoRS: a neonatal resting state fMRI data preprocessing pipeline. (arXiv:2204.05137v1 [eess.IV])
31. A Post-Processing Tool and Feasibility Study for Three-Dimensional Imaging with Electrical Impedance Tomography During Deep Brain Stimulation Surgery. (arXiv:2204.05201v1 [eess.IV])
32. CXR-FL: Deep Learning-based Chest X-ray Image Analysis Using Federated Learning. (arXiv:2204.05203v1 [eess.IV])
33. Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v1 [eess.IV])
34. Segmentation-Consistent Probabilistic Lesion Counting. (arXiv:2204.05276v1 [eess.IV])
35. Neglectable effect of brain MRI data prepreprocessing for tumor segmentation. (arXiv:2204.05278v1 [eess.IV])
36. Recent advances and clinical applications of deep learning in medical image analysis. (arXiv:2105.13381v3 [cs.CV] UPDATED)
37. SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v5 [cs.LG] UPDATED)
38. CEST MR fingerprinting (CEST-MRF) for Brain Tumor Quantification Using EPI Readout and Deep Learning Reconstruction. (arXiv:2108.08333v2 [physics.med-ph] UPDATED)
39. Info**NeRF**: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v2 [cs.CV] UPDATED)
40. An unambiguous cloudiness index for nonwovens. (arXiv:2201.02011v2 [cs.CV] UPDATED)
41. **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
42. alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty quantification from exoplanet astrometry to black hole feature extraction. (arXiv:2201.08506v2 [astro-ph.IM] UPDATED)
43. POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v3 [eess.IV] UPDATED)
44. DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v3 [cs.LG] UPDATED)
45. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v2 [eess.IV] UPDATED)
46. Playing Lottery Tickets in Style Transfer Models. (arXiv:2203.13802v2 [cs.CV] UPDATED)
## cs.LG
---
**202** new papers in cs.LG:-) 
1. Structure-aware Protein Self-supervised Learning. (arXiv:2204.04213v1 [cs.LG])
2. Intelligent Sight and Sound: A Chronic Cancer Pain Dataset. (arXiv:2204.04214v1 [eess.IV])
3. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v1 [cs.LG])
4. Multimodal Multi-Head Convolutional Attention with Various Kernel Sizes for Medical Image Super-Resolution. (arXiv:2204.04218v1 [eess.IV])
5. Towards Reliable and Explainable AI Model for Solid Pulmonary Nodule Diagnosis. (arXiv:2204.04219v1 [eess.IV])
6. Characterizing and Understanding the Behavior of Quantized Models for Reliable Deployment. (arXiv:2204.04220v1 [cs.LG])
7. Vision-Based American Sign Language Classification Approach via Deep Learning. (arXiv:2204.04235v1 [cs.CV])
8. HBFL: A Hierarchical Blockchain-based Federated Learning Framework for a Collaborative IoT Intrusion Detection. (arXiv:2204.04254v1 [cs.CR])
9. Interpretable AI for policy-making in pandemics. (arXiv:2204.04256v1 [cs.LG])
10. Evaluating the Adversarial Robustness for Fourier Neural Operators. (arXiv:2204.04259v1 [cs.LG])
11. Dimensionality Reduction in Deep Learning via Kronecker Multi-layer Architectures. (arXiv:2204.04273v1 [cs.LG])
12. On Improving Cross-dataset Generalization of Deepfake Detectors. (arXiv:2204.04285v1 [cs.CV])
13. Multi-objective evolution for Generalizable Policy Gradient Algorithms. (arXiv:2204.04292v1 [cs.LG])
14. Learning to modulate random weights can induce task-specific contexts for economical meta and continual learning. (arXiv:2204.04297v1 [cs.LG])
15. Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning for Robotics. (arXiv:2204.04308v1 [cs.LG])
16. Predicci\'on de radiaci\'on solar en sistemas fotovoltaicos utilizando t\'ecnicas de aprendizaje autom\'atico. (arXiv:2204.04313v1 [cs.LG])
17. Approximate discounting-free policy evaluation from transient and recurrent states. (arXiv:2204.04324v1 [cs.LG])
18. An Adaptive Black-box Backdoor Detection Method for Deep Neural Networks. (arXiv:2204.04329v1 [cs.CR])
19. Fuzzy temporal convolutional neural networks in P300-based Brain-computer interface for smart home interaction. (arXiv:2204.04338v1 [cs.LG])
20. Sim-to-Real Learning for Bipedal Locomotion Under Unsensed Dynamic Loads. (arXiv:2204.04340v1 [cs.RO])
21. Neural networks embrace learned diversity. (arXiv:2204.04348v1 [q-bio.NC])
22. Hardware Trojan Insertion Using Reinforcement Learning. (arXiv:2204.04350v1 [cs.LG])
23. Data Augmentation for Electrocardiograms. (arXiv:2204.04360v1 [cs.LG])
24. Application of machine learning for predicting the spread of COVID-19. (arXiv:2204.04364v1 [cs.LG])
25. A Siren Song of Open Source Reproducibility. (arXiv:2204.04372v1 [cs.LG])
26. Channel Pruning In Quantization-aware Training: An Adaptive Projection-gradient Descent-shrinkage-splitting Method. (arXiv:2204.04375v1 [cs.LG])
27. The Two Dimensions of Worst-case Training and the Integrated Effect for Out-of-domain Generalization. (arXiv:2204.04384v1 [cs.LG])
28. Divergence-aware Federated Self-Supervised Learning. (arXiv:2204.04385v1 [cs.LG])
29. Deep neural network goes lighter: A case study of deep compression techniques on automatic RF modulation recognition for Beyond 5G networks. (arXiv:2204.04390v1 [cs.LG])
30. Investigating Deep Learning Benchmarks for Electrocardiography Signal Processing. (arXiv:2204.04420v1 [cs.LG])
31. Adaptive Differential Filters for Fast and Communication-Efficient Federated Learning. (arXiv:2204.04424v1 [cs.LG])
32. Are Two Heads the Same as One? Identifying Disparate Treatment in Fair Neural Networks. (arXiv:2204.04440v1 [cs.LG])
33. Yes, Topology Matters in Decentralized Optimization: Refined Convergence and Topology Learning under Heterogeneous Data. (arXiv:2204.04452v1 [cs.LG])
34. High-dimensional Asymptotics of Langevin Dynamics in Spiked Matrix Models. (arXiv:2204.04476v1 [math.ST])
35. Uninformative Input Features and Counterfactual Invariance: Two Perspectives on Spurious Correlations in Natural Language. (arXiv:2204.04487v1 [cs.CL])
36. IDPG: An Instance-Dependent Prompt Generation Method. (arXiv:2204.04497v1 [cs.CL])
37. Explain yourself! Effects of Explanations in Human-Robot Interaction. (arXiv:2204.04501v1 [cs.RO])
38. MR-iNet Gym: Framework for Edge Deployment of Deep Reinforcement Learning on Embedded Software Defined Radio. (arXiv:2204.04507v1 [cs.LG])
39. Efficient Representation Learning of Subgraphs by Subgraph-To-Node Translation. (arXiv:2204.04510v1 [cs.LG])
40. FuNNscope: Visual microscope for interactively exploring the loss landscape of fully connected neural networks. (arXiv:2204.04511v1 [cs.LG])
41. Spectral bounds of the $\varepsilon$-entropy of kernel classes. (arXiv:2204.04512v1 [stat.ML])
42. Applying machine learning to predict behavior of bus transport in Warsaw, Poland. (arXiv:2204.04515v1 [cs.LG])
43. Attention U-Net as a surrogate model for groundwater prediction. (arXiv:2204.04518v1 [cs.LG])
44. Motion Artifacts Correction from Single-Channel EEG and fNIRS Signals using Novel Wavelet Packet Decomposition in Combination with Canonical Correlation Analysis. (arXiv:2204.04533v1 [cs.LG])
45. Super-Resolved Microbubble Localization in Single-Channel Ultrasound RF Signals Using Deep Learning. (arXiv:2204.04537v1 [physics.med-ph])
46. Survival Seq2Seq: A Survival Model based on Sequence to Sequence Architecture. (arXiv:2204.04542v1 [cs.LG])
47. Efficient Extraction of Pathologies from C-Spine Radiology Reports using Multi-Task Learning. (arXiv:2204.04544v1 [cs.LG])
48. Self-Labeling Refinement for Robust Representation Learning with Bootstrap Your Own Latent. (arXiv:2204.04545v1 [cs.CV])
49. Trajectory Optimization Using Neural Network Gradients of Learned Dynamics. (arXiv:2204.04558v1 [cs.RO])
50. Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification. (arXiv:2204.04567v1 [cs.CV])
51. Efficient Reconstruction of Stochastic Pedigrees: Some Steps From Theory to Practice. (arXiv:2204.04573v1 [q-bio.PE])
52. Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering. (arXiv:2204.04581v1 [cs.CL])
53. Real order total variation with applications to the loss functions in learning schemes. (arXiv:2204.04582v1 [math.AP])
54. Robust Cross-Modal Representation Learning with Progressive Self-Distillation. (arXiv:2204.04588v1 [cs.CV])
55. Private Sequential Hypothesis Testing for Statisticians: Privacy, Error Rates, and Sample Size. (arXiv:2204.04597v1 [stat.ML])
56. Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention. (arXiv:2204.04601v1 [cs.CV])
57. Towards efficient representation identification in supervised learning. (arXiv:2204.04606v1 [cs.LG])
58. Confidence Estimation Transformer for Long-term Renewable Energy Forecasting in Reinforcement Learning-based Power Grid Dispatching. (arXiv:2204.04612v1 [cs.LG])
59. "That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks. (arXiv:2204.04636v1 [cs.AI])
60. From graphs to DAGs: a low-complexity model and a scalable algorithm. (arXiv:2204.04644v1 [cs.LG])
61. Self-Supervised Audio-and-Text Pre-training with Extremely Low-Resource Parallel Data. (arXiv:2204.04645v1 [cs.SD])
62. Gaussian Processes for Missing Value Imputation. (arXiv:2204.04648v1 [stat.ML])
63. Expressiveness and Approximation Properties of Graph Neural Networks. (arXiv:2204.04661v1 [cs.LG])
64. FOSTER: Feature Boosting and Compression for Class-Incremental Learning. (arXiv:2204.04662v1 [cs.CV])
65. Optimization of IoT-Enabled Physical Location Monitoring Using DT and VAR. (arXiv:2204.04664v1 [cs.LG])
66. Effective Out-of-Distribution Detection in Classifier Based on PEDCC-Loss. (arXiv:2204.04665v1 [cs.CV])
67. Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v1 [cs.LG])
68. Active Learning with Label Comparisons. (arXiv:2204.04670v1 [cs.LG])
69. FedCorr: Multi-Stage Federated Learning for Label Noise Correction. (arXiv:2204.04677v1 [cs.LG])
70. MA-Dreamer: Coordination and communication through shared imagination. (arXiv:2204.04687v1 [cs.LG])
71. SplitNets: Designing Neural Architectures for Efficient Distributed Computing on Head-Mounted Systems. (arXiv:2204.04705v1 [cs.LG])
72. Rethinking Exponential Averaging of the Fisher. (arXiv:2204.04718v1 [cs.LG])
73. Regret Analysis of Online Gradient Descent-based Iterative Learning Control with Model Mismatch. (arXiv:2204.04722v1 [eess.SY])
74. Rockafellian Relaxation in Optimization under Uncertainty: Asymptotically Exact Formulations. (arXiv:2204.04762v1 [math.OC])
75. Information-theoretic Online Memory Selection for Continual Learning. (arXiv:2204.04763v1 [cs.LG])
76. Configuration and Collection Factors for Side-Channel Disassembly. (arXiv:2204.04766v1 [cs.CR])
77. Worst-case Performance of Greedy Policies in Bandits with Imperfect Context Observations. (arXiv:2204.04773v1 [stat.ML])
78. Few-Shot Cross-lingual Transfer for Coarse-grained De-identification of Code-Mixed Clinical Texts. (arXiv:2204.04775v1 [cs.CL])
79. Multimodal Machine Learning in Precision Health. (arXiv:2204.04777v1 [cs.LG])
80. Measuring the False Sense of Security. (arXiv:2204.04778v1 [cs.LG])
81. MedDistant19: A Challenging Benchmark for Distantly Supervised Biomedical Relation Extraction. (arXiv:2204.04779v1 [cs.CL])
82. Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic Representations. (arXiv:2204.04783v1 [cs.LG])
83. Driving black-box quantum thermal machines with optimal power/efficiency trade-offs using reinforcement learning. (arXiv:2204.04785v1 [quant-ph])
84. DILEMMA: Self-Supervised Shape and Texture Learning with Transformers. (arXiv:2204.04788v1 [cs.CV])
85. Edge Continual Learning for Dynamic Digital Twins over Wireless Networks. (arXiv:2204.04795v1 [cs.LG])
86. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v1 [cs.CV])
87. Multi-Label Clinical Time-Series Generation via Conditional GAN. (arXiv:2204.04797v1 [cs.LG])
88. DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning. (arXiv:2204.04799v1 [cs.LG])
89. On the pragmatism of using binary classifiers over data intensive neural network classifiers for detection of COVID-19 from voice. (arXiv:2204.04802v1 [cs.SD])
90. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v1 [cs.CV])
91. Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning. (arXiv:2204.04813v1 [cs.CL])
92. RMFGP: Rotated Multi-fidelity Gaussian process with Dimension Reduction for High-dimensional Uncertainty Quantification. (arXiv:2204.04819v1 [stat.ML])
93. Improved Approximations for Euclidean $k$-means and $k$-median, via Nested Quasi-Independent Sets. (arXiv:2204.04828v1 [cs.DS])
94. Cello: Efficient Computer Systems Optimization with Predictive Early Termination and Censored Regression. (arXiv:2204.04831v1 [cs.LG])
95. Semi-Supervised AUC Optimization based on Positive-Unlabeled Learning. (arXiv:1705.01708v3 [stat.ML] UPDATED)
96. Low-Memory Neural Network Training: A Technical Report. (arXiv:1904.10631v2 [cs.LG] UPDATED)
97. Continual learning with hypernetworks. (arXiv:1906.00695v4 [cs.LG] UPDATED)
98. Near-Optimal Methods for Minimizing Star-Convex Functions and Beyond. (arXiv:1906.11985v2 [math.OC] UPDATED)
99. Dynamic Self-training Framework for Graph Convolutional Networks. (arXiv:1910.02684v3 [cs.LG] UPDATED)
100. Harmonic Convolutional Networks based on Discrete Cosine Transform. (arXiv:2001.06570v3 [cs.CV] UPDATED)
101. Leveraging Affect Transfer Learning for Behavior Prediction in an Intelligent Tutoring System. (arXiv:2002.05242v2 [cs.CV] UPDATED)
102. An Open-set Recognition and Few-Shot Learning Dataset for Audio Event Classification in Domestic Environments. (arXiv:2002.11561v8 [cs.SD] UPDATED)
103. Randomized spectral co-clustering for large-scale directed networks. (arXiv:2004.12164v3 [stat.ML] UPDATED)
104. An $\ell_p$ theory of PCA and spectral clustering. (arXiv:2006.14062v3 [math.ST] UPDATED)
105. Neural networks with late-phase weights. (arXiv:2007.12927v4 [cs.LG] UPDATED)
106. Regularizing Attention Networks for Anomaly Detection in Visual Question Answering. (arXiv:2009.10054v3 [cs.CV] UPDATED)
107. EGMM: an Evidential Version of the Gaussian Mixture Model for Clustering. (arXiv:2010.01333v2 [cs.LG] UPDATED)
108. Targeting for long-term outcomes. (arXiv:2010.15835v2 [cs.LG] UPDATED)
109. Identifying Stress Responsive Genes using Overlapping Communities in Co-expression Networks. (arXiv:2011.03526v2 [q-bio.MN] UPDATED)
110. On the Convergence of Continuous Constrained Optimization for Structure Learning. (arXiv:2011.11150v4 [cs.LG] UPDATED)
111. No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classification Problems. (arXiv:2011.12945v2 [cs.LG] UPDATED)
112. Adaptive Deep Learning for Entity Resolution by Risk Analysis. (arXiv:2012.03513v4 [cs.LG] UPDATED)
113. Fidel: Reconstructing Private Training Samples from Weight Updates in Federated Learning. (arXiv:2101.00159v2 [cs.LG] UPDATED)
114. Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification. (arXiv:2101.07361v4 [cs.LG] UPDATED)
115. Curriculum Learning: A Survey. (arXiv:2101.10382v3 [cs.LG] UPDATED)
116. The MSR-Video to Text Dataset with Clean Annotations. (arXiv:2102.06448v3 [cs.CV] UPDATED)
117. VAE Approximation Error: ELBO and Exponential Families. (arXiv:2102.09310v4 [cs.LG] UPDATED)
118. MIND: Inductive Mutual Information Estimation, A Convex Maximum-Entropy Copula Approach. (arXiv:2102.13182v3 [stat.ML] UPDATED)
119. Believe The HiPe: Hierarchical Perturbation for Fast, Robust, and Model-Agnostic Saliency Mapping. (arXiv:2103.05108v3 [cs.CV] UPDATED)
120. PredRNN: A Recurrent Neural Network for Spatiotemporal Predictive Learning. (arXiv:2103.09504v4 [cs.LG] UPDATED)
121. Consistency-based Active Learning for Object Detection. (arXiv:2103.10374v3 [cs.CV] UPDATED)
122. BROADCAST: Reducing Both Stochastic and Compression Noise to Robustify Communication-Efficient Federated Learning. (arXiv:2104.06685v2 [cs.LG] UPDATED)
123. Assessing patient similarity through representation learning on medical records. (arXiv:2104.14229v2 [cs.IR] UPDATED)
124. CombOptNet: Fit the Right NP-Hard Problem by Learning Integer Programming Constraints. (arXiv:2105.02343v2 [cs.LG] UPDATED)
125. Bangla Natural Language Processing: A Comprehensive Analysis of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v3 [cs.CL] UPDATED)
126. Semi-Empirical Objective Functions for MCMC Proposal Optimization. (arXiv:2106.02104v5 [cs.LG] UPDATED)
127. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v2 [cs.CV] UPDATED)
128. Fair Machine Learning under Limited Demographically Labeled Data. (arXiv:2106.04757v2 [cs.LG] UPDATED)
129. Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective. (arXiv:2106.07115v3 [cs.LG] UPDATED)
130. Training Graph Neural Networks with 1000 Layers. (arXiv:2106.07476v3 [cs.LG] UPDATED)
131. Understanding Dynamics of Nonlinear Representation Learning and Its Application. (arXiv:2106.14836v4 [cs.LG] UPDATED)
132. Characterization of the Variation Spaces Corresponding to Shallow Neural Networks. (arXiv:2106.15002v2 [stat.ML] UPDATED)
133. Saturated Transformers are Constant-Depth Threshold Circuits. (arXiv:2106.16213v3 [cs.CL] UPDATED)
134. Mandoline: Model Evaluation under Distribution Shift. (arXiv:2107.00643v2 [cs.LG] UPDATED)
135. SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v5 [cs.LG] UPDATED)
136. Shell Language Processing: Unix command parsing for Machine Learning. (arXiv:2107.02438v2 [cs.LG] UPDATED)
137. Encoding Domain Information with Sparse Priors for Inferring Explainable Latent Variables. (arXiv:2107.03730v2 [stat.ML] UPDATED)
138. Is attention to bounding boxes all you need for pedestrian action prediction?. (arXiv:2107.08031v3 [cs.CV] UPDATED)
139. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v3 [cs.CV] UPDATED)
140. Slot Filling for Biomedical Information Extraction. (arXiv:2109.08564v2 [cs.CL] UPDATED)
141. Distributed Online Optimization with Byzantine Adversarial Agents. (arXiv:2109.12340v2 [math.OC] UPDATED)
142. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v3 [cs.LG] UPDATED)
143. Learning to Pick at Non-Zero-Velocity from Interactive Demonstrations. (arXiv:2110.04534v2 [cs.RO] UPDATED)
144. Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v3 [cs.GT] UPDATED)
145. Exposing Query Identification for Search Transparency. (arXiv:2110.07701v3 [cs.IR] UPDATED)
146. Attention-Free Keyword Spotting. (arXiv:2110.07749v3 [cs.LG] UPDATED)
147. Acceleration in Distributed Optimization under Similarity. (arXiv:2110.12347v2 [math.OC] UPDATED)
148. Arch-Net: Model Distillation for Architecture Agnostic Model Deployment. (arXiv:2111.01135v2 [cs.LG] UPDATED)
149. LTD: Low Temperature Distillation for Robust Adversarial Training. (arXiv:2111.02331v2 [cs.CV] UPDATED)
150. Can I use this publicly available dataset to build commercial AI software? -- A Case Study on Publicly Available Image Datasets. (arXiv:2111.02374v5 [cs.LG] UPDATED)
151. Quasi-Newton Methods for Saddle Point Problems and Beyond. (arXiv:2111.02708v5 [math.OC] UPDATED)
152. Modeling Techniques for Machine Learning Fairness: A Survey. (arXiv:2111.03015v2 [cs.LG] UPDATED)
153. Generative Adversarial Network for Probabilistic Forecast of Random Dynamical System. (arXiv:2111.03126v2 [cs.LG] UPDATED)
154. SMU: smooth activation function for deep networks using smoothing maximum technique. (arXiv:2111.04682v2 [cs.LG] UPDATED)
155. Tightening the Approximation Error of Adversarial Risk with Auto Loss Function Search. (arXiv:2111.05063v2 [cs.LG] UPDATED)
156. On the Importance of Difficulty Calibration in Membership Inference Attacks. (arXiv:2111.08440v2 [cs.CR] UPDATED)
157. How and When Random Feedback Works: A Case Study of Low-Rank Matrix Factorization. (arXiv:2111.08706v3 [cs.NE] UPDATED)
158. Transfer Learning with Jukebox for Music Source Separation. (arXiv:2111.14200v2 [eess.AS] UPDATED)
159. Towards Personalization of User Preferences in Partially Observable Smart Home Environments. (arXiv:2112.00971v4 [cs.AI] UPDATED)
160. Learning to Guide and to Be Guided in the Architect-Builder Problem. (arXiv:2112.07342v5 [cs.LG] UPDATED)
161. n-CPS: Generalising Cross Pseudo Supervision to n Networks for Semi-Supervised Semantic Segmentation. (arXiv:2112.07528v4 [cs.CV] UPDATED)
162. Interpretable Data-Based Explanations for Fairness Debugging. (arXiv:2112.09745v2 [cs.LG] UPDATED)
163. MetaCVR: Conversion Rate Prediction via Meta Learning in Small-Scale Recommendation Scenarios. (arXiv:2112.13753v3 [cs.LG] UPDATED)
164. BARACK: Partially Supervised Group Robustness With Guarantees. (arXiv:2201.00072v2 [cs.LG] UPDATED)
165. Learning Differentiable Safety-Critical Control using Control Barrier Functions for Generalization to Novel Environments. (arXiv:2201.01347v3 [eess.SY] UPDATED)
166. **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
167. Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v6 [cs.CR] UPDATED)
168. Symplectic Momentum Neural Networks -- Using Discrete Variational Mechanics as a prior in Deep Learning. (arXiv:2201.08281v3 [cs.LG] UPDATED)
169. alpha-Deep Probabilistic Inference (alpha-DPI): efficient uncertainty quantification from exoplanet astrometry to black hole feature extraction. (arXiv:2201.08506v2 [astro-ph.IM] UPDATED)
170. Differentially Private SGDA for Minimax Problems. (arXiv:2201.09046v2 [cs.LG] UPDATED)
171. POTHER: Patch-Voted Deep Learning-based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v3 [eess.IV] UPDATED)
172. BERTHA: Video Captioning Evaluation Via Transfer-Learned Human Assessment. (arXiv:2201.10243v2 [cs.CV] UPDATED)
173. Counterfactual Plans under Distributional Ambiguity. (arXiv:2201.12487v2 [cs.LG] UPDATED)
174. Deep Contrastive Learning is Provably (almost) Principal Component Analysis. (arXiv:2201.12680v3 [cs.LG] UPDATED)
175. SSHA: Video Violence Recognition and Localization Using a Semi-Supervised Hard Attention Model. (arXiv:2202.02212v3 [cs.CV] UPDATED)
176. Neural Logic Analogy Learning. (arXiv:2202.02436v2 [cs.CL] UPDATED)
177. Delay-adaptive step-sizes for asynchronous learning. (arXiv:2202.08550v3 [cs.LG] UPDATED)
178. Integration of knowledge and data in machine learning. (arXiv:2202.10337v2 [cs.AI] UPDATED)
179. Targeting occupant feedback using digital twins: Adaptive spatial-temporal thermal preference sampling to optimize personal comfort models. (arXiv:2202.10707v2 [cs.LG] UPDATED)
180. Generalised Gaussian Process Latent Variable Models (GPLVM) with Stochastic Variational Inference. (arXiv:2202.12979v2 [cs.LG] UPDATED)
181. Sign and Basis Invariant Networks for Spectral Graph Representation Learning. (arXiv:2202.13013v2 [cs.LG] UPDATED)
182. Averaging Spatio-temporal Signals using Optimal Transport and Soft Alignments. (arXiv:2203.05813v2 [stat.ML] UPDATED)
183. Physico-chemical properties extraction from the fluorescence spectrum with 1D-convolutional neural networks: application to olive oil. (arXiv:2203.07229v2 [cs.LG] UPDATED)
184. Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v2 [cs.CR] UPDATED)
185. DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v3 [cs.LG] UPDATED)
186. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v2 [eess.IV] UPDATED)
187. Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation. (arXiv:2203.09553v2 [cs.AI] UPDATED)
188. Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily. (arXiv:2203.11200v2 [cs.LG] UPDATED)
189. Automatic Debiased Machine Learning for Dynamic Treatment Effects. (arXiv:2203.13887v2 [econ.EM] UPDATED)
190. PAEDID: Patch Autoencoder Based Deep Image Decomposition For Pixel-level Defective Region Segmentation. (arXiv:2203.14457v2 [cs.CV] UPDATED)
191. Domino: Discovering Systematic Errors with Cross-Modal Embeddings. (arXiv:2203.14960v2 [cs.LG] UPDATED)
192. CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters. (arXiv:2203.15331v2 [cs.CV] UPDATED)
193. Smooth Robust Tensor Completion for Background/Foreground Separation with Missing Pixels: Novel Algorithm with Convergence Guarantee. (arXiv:2203.16328v2 [cs.CV] UPDATED)
194. Federated Learning Framework Coping with Hierarchical Heterogeneity in Cooperative ITS. (arXiv:2204.00215v2 [cs.LG] UPDATED)
195. Taking ROCKET on an Efficiency Mission: Multivariate Time Series Classification with LightWaveS. (arXiv:2204.01379v3 [cs.LG] UPDATED)
196. Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v2 [cs.LG] UPDATED)
197. Digital Twin Virtualization with Machine Learning for IoT and Beyond 5G Networks: Research Directions for Security and Optimal Control. (arXiv:2204.01950v2 [cs.NI] UPDATED)
198. MetaAudio: A Few-Shot Audio Classification Benchmark. (arXiv:2204.02121v2 [cs.SD] UPDATED)
199. Neural Implicit Flow: a mesh-agnostic dimensionality reduction paradigm of spatio-temporal data. (arXiv:2204.03216v2 [cs.LG] UPDATED)
200. The Effects of Regularization and Data Augmentation are Class Dependent. (arXiv:2204.03632v2 [cs.LG] UPDATED)
201. Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v2 [cs.AI] UPDATED)
202. Generative Adversarial Method Based on Neural Tangent Kernels. (arXiv:2204.04090v2 [cs.LG] UPDATED)
## cs.AI
---
**110** new papers in cs.AI:-) 
1. Structure-aware Protein Self-supervised Learning. (arXiv:2204.04213v1 [cs.LG])
2. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v1 [cs.LG])
3. Feature-enhanced Adversarial Semi-supervised Semantic Segmentation Network for Pulmonary Embolism Annotation. (arXiv:2204.04217v1 [eess.IV])
4. Characterizing and Understanding the Behavior of Quantized Models for Reliable Deployment. (arXiv:2204.04220v1 [cs.LG])
5. Exploiting complex pattern features for interactive pattern mining. (arXiv:2204.04242v1 [cs.AI])
6. Interpretable AI for policy-making in pandemics. (arXiv:2204.04256v1 [cs.LG])
7. Evaluating the Adversarial Robustness for Fourier Neural Operators. (arXiv:2204.04259v1 [cs.LG])
8. On Improving Cross-dataset Generalization of Deepfake Detectors. (arXiv:2204.04285v1 [cs.CV])
9. Towards Understanding Large-Scale Discourse Structures in Pre-Trained and Fine-Tuned Language Models. (arXiv:2204.04289v1 [cs.CL])
10. Preliminary Results on Using Abstract AND-OR Graphs for Generalized Solving of Stochastic Shortest Path Problems. (arXiv:2204.04301v1 [cs.AI])
11. MMTAfrica: Multilingual Machine Translation for African Languages. (arXiv:2204.04306v1 [cs.CL])
12. Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning for Robotics. (arXiv:2204.04308v1 [cs.LG])
13. Iterative Depth-First Search for Fully Observable Non-Deterministic Planning. (arXiv:2204.04322v1 [cs.AI])
14. Fuzzy temporal convolutional neural networks in P300-based Brain-computer interface for smart home interaction. (arXiv:2204.04338v1 [cs.LG])
15. On the Importance of Karaka Framework in Multi-modal Grounding. (arXiv:2204.04347v1 [cs.CL])
16. Should we tweet this? Generative response modeling for predicting reception of public health messaging on Twitter. (arXiv:2204.04353v1 [cs.CL])
17. A Siren Song of Open Source Reproducibility. (arXiv:2204.04372v1 [cs.LG])
18. Channel Pruning In Quantization-aware Training: An Adaptive Projection-gradient Descent-shrinkage-splitting Method. (arXiv:2204.04375v1 [cs.LG])
19. Federated Unsupervised Domain Adaptation for Face Recognition. (arXiv:2204.04382v1 [cs.CV])
20. Divergence-aware Federated Self-Supervised Learning. (arXiv:2204.04385v1 [cs.LG])
21. PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization. (arXiv:2204.04413v1 [cs.CL])
22. Unbiased Directed Object Attention Graph for Object Navigation. (arXiv:2204.04421v1 [cs.CV])
23. Adaptive Differential Filters for Fast and Communication-Efficient Federated Learning. (arXiv:2204.04424v1 [cs.LG])
24. FoundationLayerNorm: Scaling BERT and GPT to 1,000 Layers. (arXiv:2204.04477v1 [cs.CL])
25. Why did I fail? A Causal-based Method to Find Explanations for Robot Failures. (arXiv:2204.04483v1 [cs.RO])
26. Efficient Representation Learning of Subgraphs by Subgraph-To-Node Translation. (arXiv:2204.04510v1 [cs.LG])
27. Applying machine learning to predict behavior of bus transport in Warsaw, Poland. (arXiv:2204.04515v1 [cs.LG])
28. Extending the Scope of Out-of-Domain: Examining QA models in multiple subdomains. (arXiv:2204.04534v1 [cs.CL])
29. Efficient Extraction of Pathologies from C-Spine Radiology Reports using Multi-Task Learning. (arXiv:2204.04544v1 [cs.LG])
30. Self-Labeling Refinement for Robust Representation Learning with Bootstrap Your Own Latent. (arXiv:2204.04545v1 [cs.CV])
31. Augmenting Pre-trained Language Models with QA-Memory for Open-Domain Question Answering. (arXiv:2204.04581v1 [cs.CL])
32. Explaining Deep Convolutional Neural Networks via Latent Visual-Semantic Filter Attention. (arXiv:2204.04601v1 [cs.CV])
33. Towards efficient representation identification in supervised learning. (arXiv:2204.04606v1 [cs.LG])
34. Self-Supervised Video Representation Learning with Motion-Contrastive Perception. (arXiv:2204.04607v1 [cs.CV])
35. Decay No More: A Persistent Twitter Dataset for Learning Social Meaning. (arXiv:2204.04611v1 [cs.CL])
36. Confidence Estimation Transformer for Long-term Renewable Energy Forecasting in Reinforcement Learning-based Power Grid Dispatching. (arXiv:2204.04612v1 [cs.LG])
37. "That Is a Suspicious Reaction!": Interpreting Logits Variation to Detect NLP Adversarial Attacks. (arXiv:2204.04636v1 [cs.AI])
38. Is my Driver Observation Model Overconfident? Input-guided Calibration Networks for Reliable and Interpretable Confidence Estimates. (arXiv:2204.04674v1 [cs.CV])
39. FedCorr: Multi-Stage Federated Learning for Label Noise Correction. (arXiv:2204.04677v1 [cs.LG])
40. Enhancing the Robustness, Efficiency, and Diversity of Differentiable Architecture Search. (arXiv:2204.04681v1 [cs.CV])
41. DISK: Domain-constrained Instance Sketch for Math Word Problem Generation. (arXiv:2204.04686v1 [cs.AI])
42. An Efficient Pattern Mining Convolution Neural Network (CNN) algorithm with Grey Wolf Optimization (GWO). (arXiv:2204.04704v1 [cs.CV])
43. SplitNets: Designing Neural Architectures for Efficient Distributed Computing on Head-Mounted Systems. (arXiv:2204.04705v1 [cs.LG])
44. Data Augmentation for Biomedical Factoid Question Answering. (arXiv:2204.04711v1 [cs.CL])
45. TOV: The Original Vision Model for Optical Remote Sensing Image Understanding via Self-supervised Learning. (arXiv:2204.04716v1 [cs.CV])
46. A Comparative Analysis of Decision-Level Fusion for Multimodal Driver Behaviour Understanding. (arXiv:2204.04734v1 [cs.CV])
47. Analysis of Power-Oriented Fault Injection Attacks on Spiking Neural Networks. (arXiv:2204.04768v1 [cs.AI])
48. A Fully Polynomial Time Approximation Scheme for Fixed-Horizon Constrained Stochastic Shortest Path Problem under Local Transitions. (arXiv:2204.04780v1 [cs.AI])
49. Temporal Knowledge Graph Reasoning with Low-rank and Model-agnostic Representations. (arXiv:2204.04783v1 [cs.LG])
50. DILEMMA: Self-Supervised Shape and Texture Learning with Transformers. (arXiv:2204.04788v1 [cs.CV])
51. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v1 [cs.CV])
52. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v1 [cs.CV])
53. Explanation Graph Generation via Pre-trained Language Models: An Empirical Study with Contrastive Learning. (arXiv:2204.04813v1 [cs.CL])
54. Effective Mutation Rate Adaptation through Group Elite Selection. (arXiv:2204.04817v1 [cs.NE])
55. Markov categories, causal theories, and the do-calculus. (arXiv:2204.04821v1 [cs.AI])
56. Continual learning with hypernetworks. (arXiv:1906.00695v4 [cs.LG] UPDATED)
57. Improving the Effectiveness of Traceability Link Recovery using Hierarchical Bayesian Networks. (arXiv:2005.09046v2 [cs.SE] UPDATED)
58. Adaptive Deep Learning for Entity Resolution by Risk Analysis. (arXiv:2012.03513v4 [cs.LG] UPDATED)
59. Edge Federated Learning Via Unit-Modulus Over-The-Air Computation. (arXiv:2101.12051v5 [cs.IT] UPDATED)
60. Believe The HiPe: Hierarchical Perturbation for Fast, Robust, and Model-Agnostic Saliency Mapping. (arXiv:2103.05108v3 [cs.CV] UPDATED)
61. Consistency-based Active Learning for Object Detection. (arXiv:2103.10374v3 [cs.CV] UPDATED)
62. Analyzing Semantics of Aggregate Answer Set Programming Using Approximation Fixpoint Theory. (arXiv:2104.14789v3 [cs.AI] UPDATED)
63. A State-of-the-art Survey of Object Detection Techniques in Microorganism Image Analysis: From Classical Methods to Deep Learning Approaches. (arXiv:2105.03148v2 [cs.CV] UPDATED)
64. Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters. (arXiv:2105.06232v3 [cs.CL] UPDATED)
65. Bangla Natural Language Processing: A Comprehensive Analysis of Classical, Machine Learning, and Deep Learning Based Methods. (arXiv:2105.14875v3 [cs.CL] UPDATED)
66. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v2 [cs.CV] UPDATED)
67. Understanding Latent Correlation-Based Multiview Learning and Self-Supervision: An Identifiability Perspective. (arXiv:2106.07115v3 [cs.LG] UPDATED)
68. Training Graph Neural Networks with 1000 Layers. (arXiv:2106.07476v3 [cs.LG] UPDATED)
69. Scene-adaptive Knowledge Distillation for Sequential Recommendation via Differentiable Architecture Search. (arXiv:2107.07173v2 [cs.IR] UPDATED)
70. Improving Social Meaning Detection with Pragmatic Masking and Surrogate Fine-Tuning. (arXiv:2108.00356v2 [cs.CL] UPDATED)
71. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v3 [cs.CV] UPDATED)
72. CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v2 [cs.CL] UPDATED)
73. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v3 [cs.LG] UPDATED)
74. Towards Efficient NLP: A Standard Evaluation and A Strong Baseline. (arXiv:2110.07038v2 [cs.CL] UPDATED)
75. Exposing Query Identification for Search Transparency. (arXiv:2110.07701v3 [cs.IR] UPDATED)
76. Improving Compositional Generalization with Self-Training for Data-to-Text Generation. (arXiv:2110.08467v2 [cs.CL] UPDATED)
77. Can I use this publicly available dataset to build commercial AI software? -- A Case Study on Publicly Available Image Datasets. (arXiv:2111.02374v5 [cs.LG] UPDATED)
78. Generative Adversarial Network for Probabilistic Forecast of Random Dynamical System. (arXiv:2111.03126v2 [cs.LG] UPDATED)
79. SMU: smooth activation function for deep networks using smoothing maximum technique. (arXiv:2111.04682v2 [cs.LG] UPDATED)
80. FPM: A Collection of Large-scale Foundation Pre-trained Language Models. (arXiv:2111.04909v3 [cs.CL] UPDATED)
81. Tightening the Approximation Error of Adversarial Risk with Auto Loss Function Search. (arXiv:2111.05063v2 [cs.LG] UPDATED)
82. Towards Personalization of User Preferences in Partially Observable Smart Home Environments. (arXiv:2112.00971v4 [cs.AI] UPDATED)
83. Learning to Guide and to Be Guided in the Architect-Builder Problem. (arXiv:2112.07342v5 [cs.LG] UPDATED)
84. n-CPS: Generalising Cross Pseudo Supervision to n Networks for Semi-Supervised Semantic Segmentation. (arXiv:2112.07528v4 [cs.CV] UPDATED)
85. The brain as a probabilistic transducer: an evolutionarily plausible network architecture for knowledge representation, computation, and behavior. (arXiv:2112.13388v2 [cs.AI] UPDATED)
86. Social Neuro AI: Social Interaction as the "**dark** matter" of AI. (arXiv:2112.15459v3 [cs.MA] UPDATED)
87. **Swin** Transformer for Fast MRI. (arXiv:2201.03230v2 [eess.IV] UPDATED)
88. Structured access: an emerging paradigm for safe AI deployment. (arXiv:2201.05159v2 [cs.AI] UPDATED)
89. Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrences. (arXiv:2201.11650v3 [cs.DB] UPDATED)
90. Counterfactual Plans under Distributional Ambiguity. (arXiv:2201.12487v2 [cs.LG] UPDATED)
91. Neural Logic Analogy Learning. (arXiv:2202.02436v2 [cs.CL] UPDATED)
92. Online Approval Committee Elections. (arXiv:2202.06830v2 [cs.GT] UPDATED)
93. Integration of knowledge and data in machine learning. (arXiv:2202.10337v2 [cs.AI] UPDATED)
94. Foundations for Grassroots Democratic Metaverse. (arXiv:2203.04090v3 [cs.CY] UPDATED)
95. Physico-chemical properties extraction from the fluorescence spectrum with 1D-convolutional neural networks: application to olive oil. (arXiv:2203.07229v2 [cs.LG] UPDATED)
96. Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation. (arXiv:2203.09553v2 [cs.AI] UPDATED)
97. Lazy Rearrangement Planning in Confined Spaces. (arXiv:2203.10379v2 [cs.RO] UPDATED)
98. Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with Heterophily. (arXiv:2203.11200v2 [cs.LG] UPDATED)
99. Environment induced emergence of collective behaviour in evolving swarms with limited sensing. (arXiv:2203.11585v2 [cs.RO] UPDATED)
100. Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction. (arXiv:2203.12997v2 [cs.CV] UPDATED)
101. Component-wise Analysis of Automatically Designed Multiobjective Algorithms on Constrained Problems. (arXiv:2203.13447v2 [cs.NE] UPDATED)
102. bitsa_nlp@LT-EDI-ACL2022: Leveraging Pretrained Language Models for Detecting Homophobia and Transphobia in Social Media Comments. (arXiv:2203.14267v2 [cs.CL] UPDATED)
103. Domino: Discovering Systematic Errors with Cross-Modal Embeddings. (arXiv:2203.14960v2 [cs.LG] UPDATED)
104. LogicInference: A New Dataset for Teaching Logical Inference to seq2seq Models. (arXiv:2203.15099v3 [cs.AI] UPDATED)
105. CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters. (arXiv:2203.15331v2 [cs.CV] UPDATED)
106. A sequence-to-sequence approach for document-level relation extraction. (arXiv:2204.01098v2 [cs.CL] UPDATED)
107. "Does it come in black?" CLIP-like models are zero-shot recommenders. (arXiv:2204.02473v2 [cs.IR] UPDATED)
108. DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image. (arXiv:2204.03688v2 [cs.CV] UPDATED)
109. Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v2 [cs.AI] UPDATED)
110. Template-free Prompt Tuning for Few-shot NER. (arXiv:2109.13532v1 [cs.CL] CROSS LISTED)

