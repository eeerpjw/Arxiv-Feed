# Your interest papers
---
## cs.CV
---
### Differentiable Point-Based Radiance Fields for Efficient View Synthesis. (arXiv:2205.14330v1 [cs.CV])
- Authors : Qiang Zhang, Hwan Baek, Szymon Rusinkiewicz, Felix Heide
- Link : [http://arxiv.org/abs/2205.14330](http://arxiv.org/abs/2205.14330)
> ABSTRACT  :  We propose a differentiable rendering algorithm for efficient novel view synthesis. By departing from volume-based representations in favor of a learned point representation, we improve on existing methods more than an order of magnitude in memory and runtime, both in training and inference. The method begins with a uniformly-sampled random point cloud and learns per-point position and view-dependent appearance, using a differentiable splat-based renderer to evolve the model to match a set of input images. Our method is up to 300x faster than **NeRF** in both training and inference, with only a marginal sacrifice in quality, while using less than 10~MB of memory for a static scene. For dynamic scenes, our method trains two orders of magnitude faster than ST**NeRF** and renders at near interactive rate, while maintaining high image quality and temporal coherence even without imposing any temporal-coherency regularizers.  
### Enhancing Quality of Pose-varied Face **Restoration** with Local Weak Feature Sensing and GAN Prior. (arXiv:2205.14377v1 [cs.CV])
- Authors : Kai Hu, Yu Liu, Renhe Liu, Wei Lu, Gang Yu, Bin Fu
- Link : [http://arxiv.org/abs/2205.14377](http://arxiv.org/abs/2205.14377)
> ABSTRACT  :  Facial semantic guidance (facial landmarks, facial parsing maps, facial heatmaps, etc.) and facial generative adversarial networks (GAN) prior have been widely used in blind face **restoration** (BFR) in recent years. Although existing BFR methods have achieved good performance in ordinary cases, these solutions have limited resilience when applied to face images with serious degradation and pose-varied (look up, look down, laugh, etc.) in real-world scenarios. In this work, we propose a well-designed blind face **restoration** network with generative facial prior. The proposed network is mainly comprised of an asymmetric codec and StyleGAN2 prior network. In the asymmetric codec, we adopt a mixed multi-path residual block (MMRB) to gradually extract weak texture features of input images, which can improve the texture integrity and authenticity of our networks. Furthermore, the MMRB block can also be plug-and-play in any other network. Besides, a novel self-supervised training strategy is specially designed for face **restoration** tasks to fit the distribution closer to the target and maintain training stability. Extensive experiments over synthetic and real-world datasets demonstrate that our model achieves superior performance to the prior art for face **restoration** and face super-resolution tasks and can tackle seriously degraded face images in diverse poses and expressions.  
### A New High-Performance Approach to Approximate Pattern-Matching for Plagiarism Detection in Blockchain-Based Non-Fungible Tokens (NFTs). (arXiv:2205.14492v1 [cs.FL])
- Authors : Ciprian Pungila, Darius Galis, Viorel Negru
- Link : [http://arxiv.org/abs/2205.14492](http://arxiv.org/abs/2205.14492)
> ABSTRACT  :  We are presenting a fast and innovative approach to performing approximate pattern-matching for plagiarism detection, using an NDFA-based approach that significantly enhances performance compared to other existing similarity measures. We outline the advantages of our approach in the context of blockchain-based non-fungible tokens (NFTs). We present, formalize, discuss and test our proposed approach in several real-world scenarios and with different similarity measures commonly used in plagiarism detection, and observe significant throughput **enhancement**s throughout the entire spectrum of tests, with little to no compromises on the accuracy of the detection process overall. We conclude that our approach is suitable and adequate to perform approximate pattern-matching for plagiarism detection, and outline research directions for future improvements.  
### Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v1 [cs.CV])
- Authors : Chunwei Tian, Yixuan Yuan, Shichao Zhang, Wen Lin, Wangmeng Zuo, David Zhang
- Link : [http://arxiv.org/abs/2205.14548](http://arxiv.org/abs/2205.14548)
> ABSTRACT  :  CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal **enhancement** operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.  
### Feature-Aligned Video Raindrop Removal with Temporal Constraints. (arXiv:2205.14574v1 [cs.CV])
- Authors : Wending Yan, Lu Xu, **Wenhan Yang**
- Link : [http://arxiv.org/abs/2205.14574](http://arxiv.org/abs/2205.14574)
> ABSTRACT  :  Existing adherent raindrop removal methods focus on the detection of the raindrop locations, and then use inpainting techniques or generative networks to recover the background behind raindrops. Yet, as adherent raindrops are diverse in sizes and appearances, the detection is challenging for both single image and video. Moreover, unlike rain streaks, adherent raindrops tend to cover the same area in several frames. Addressing these problems, our method employs a two-stage video-based raindrop removal method. The first stage is the single image module, which generates initial clean results. The second stage is the multiple frame module, which further refines the initial results using temporal constraints, namely, by utilizing multiple input frames in our process and applying temporal consistency between adjacent output frames. Our single image module employs a raindrop removal network to generate initial raindrop removal results, and create a mask representing the differences between the input and initial output. Once the masks and initial results for consecutive frames are obtained, our multiple-frame module aligns the frames in both the image and feature levels and then obtains the clean background. Our method initially employs optical flow to align the frames, and then utilizes deformable convolution layers further to achieve feature-level frame alignment. To remove small raindrops and recover correct backgrounds, a target frame is predicted from adjacent frames. A series of unsupervised losses are proposed so that our second stage, which is the video raindrop removal module, can self-learn from video data without ground truths. Experimental results on real videos demonstrate the state-of-art performance of our method both quantitatively and qualitatively.  
### IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation. (arXiv:2205.14620v1 [cs.CV])
- Authors : Lingtong Kong, Boyuan Jiang, Donghao Luo, Wenqing Chu, Xiaoming Huang, Ying Tai, Chengjie Wang, Jie Yang
- Link : [http://arxiv.org/abs/2205.14620](http://arxiv.org/abs/2205.14620)
> ABSTRACT  :  Prevailing video frame interpolation algorithms, that generate the intermediate frames from consecutive inputs, typically rely on complex model architectures with heavy parameters or large delay, hindering them from diverse real-time applications. In this work, we devise an efficient encoder-decoder based network, termed IFRNet, for fast intermediate frame synthesizing. It first extracts pyramid features from given inputs, and then refines the **bilateral** intermediate flow fields together with a powerful intermediate feature until generating the desired output. The gradually refined intermediate feature can not only facilitate intermediate flow estimation, but also compensate for contextual details, making IFRNet do not need additional synthesis or refinement module. To fully release its potential, we further propose a novel task-oriented optical flow distillation loss to focus on learning the useful teacher knowledge towards frame synthesizing. Meanwhile, a new geometry consistency regularization term is imposed on the gradually refined intermediate features to keep better structure layout. Experiments on various benchmarks demonstrate the excellent performance and fast inference speed of proposed approaches. Code is available at https://github.com/ltkong218/IFRNet.  
### Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation. (arXiv:2205.14637v1 [cs.CV])
- Authors : Rohit Mohan, Abhinav Valada
- Link : [http://arxiv.org/abs/2205.14637](http://arxiv.org/abs/2205.14637)
> ABSTRACT  :  Amodal panoptic segmentation aims to connect the perception of the world to its cognitive understanding. It entails simultaneously predicting the semantic labels of visible scene regions and the entire shape of traffic participant instances, including regions that may be occluded. In this work, we formulate a proposal-free framework that tackles this task as a multi-label and multi-class problem by first assigning the amodal masks to different layers according to their relative occlusion order and then employing amodal instance regression on each layer independently while learning background semantics. We propose the \net architecture that incorporates a shared backbone and an asymmetrical dual-decoder consisting of several modules to facilitate within-scale and cross-scale feature aggregations, **bilateral** feature propagation between decoders, and integration of global instance-level and local pixel-level occlusion reasoning. Further, we propose the amodal mask refiner that resolves the ambiguity in complex occlusion scenarios by explicitly leveraging the embedding of unoccluded instance masks. Extensive evaluation on the BDD100K-APS and KITTI-360-APS datasets demonstrate that our approach set the new state-of-the-art on both benchmarks.  
### EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition. (arXiv:2205.14756v1 [cs.CV])
- Authors : Han Cai, Chuang Gan, Song Han
- Link : [http://arxiv.org/abs/2205.14756](http://arxiv.org/abs/2205.14756)
> ABSTRACT  :  Vision Transformer (ViT) has achieved remarkable performance in many vision tasks. However, ViT is inferior to convolutional neural networks (CNNs) when targeting high-resolution mobile vision applications. The key computational bottleneck of ViT is the softmax attention module which has quadratic computational complexity with the input resolution. It is essential to reduce the cost of ViT to deploy it on edge devices. Existing methods (e.g., **Swin**, PVT) restrict the softmax attention within local windows or reduce the resolution of key/value tensors to reduce the cost, which sacrifices ViT's core advantages on global feature extractions. In this work, we present EfficientViT, an efficient ViT architecture for high-resolution low-computation visual recognition. Instead of restricting the softmax attention, we propose to replace softmax attention with linear attention while enhancing its local feature extraction ability with depthwise convolution. EfficientViT maintains global and local feature extraction capability while enjoying linear computational complexity. Extensive experiments on COCO object detection and Cityscapes semantic segmentation demonstrate the effectiveness of our method. On the COCO dataset, EfficientViT achieves 42.6 AP with 4.4G MACs, surpassing EfficientDet-D1 by 2.4 AP while having 27.9% fewer MACs. On Cityscapes, EfficientViT reaches 78.7 mIoU with 19.1G MACs, outperforming SegFormer by 2.5 mIoU while requiring less than 1/3 the computational cost. On Qualcomm Snapdragon 855 CPU, EfficientViT is 3x faster than EfficientNet while achieving higher ImageNet accuracy.  
### Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?. (arXiv:2109.05422v2 [cs.CV] UPDATED)
- Authors : Chuanxin Tang, Yucheng Zhao, Guangting Wang, Chong Luo, Wenxuan Xie, Wenjun Zeng
- Link : [http://arxiv.org/abs/2109.05422](http://arxiv.org/abs/2109.05422)
> ABSTRACT  :  Transformers have sprung up in the field of computer vision. In this work, we explore whether the core self-attention module in Transformer is the key to achieving excellent performance in image recognition. To this end, we build an attention-free network called sMLPNet based on the existing MLP-based vision models. Specifically, we replace the MLP module in the token-mixing step with a novel sparse MLP (sMLP) module. For 2D image tokens, sMLP applies 1D MLP along the axial directions and the parameters are shared among rows or columns. By sparse connection and weight sharing, sMLP module significantly reduces the number of model parameters and computational complexity, avoiding the common over-fitting problem that plagues the performance of MLP-like models. When only trained on the ImageNet-1K dataset, the proposed sMLPNet achieves 81.9% top-1 accuracy with only 24M parameters, which is much better than most CNNs and vision Transformers under the same model size constraint. When scaling up to 66M parameters, sMLPNet achieves 83.4% top-1 accuracy, which is on par with the state-of-the-art **Swin** Transformer. The success of sMLPNet suggests that the self-attention mechanism is not necessarily a silver bullet in computer vision. The code and models are publicly available at https://github.com/microsoft/SPACH  
### Hallucinated Neural Radiance Fields in the Wild. (arXiv:2111.15246v3 [cs.CV] UPDATED)
- Authors : Xingyu Chen, Qi Zhang, Xiaoyu Li, Yue Chen, Ying Feng, Xuan Wang, Jue Wang
- Link : [http://arxiv.org/abs/2111.15246](http://arxiv.org/abs/2111.15246)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**) has recently gained popularity for its impressive novel view synthesis ability. This paper studies the problem of hallucinated **NeRF**: i.e., recovering a realistic **NeRF** at a different time of day from a group of tourism images. Existing solutions adopt **NeRF** with a controllable appearance embedding to render novel views under various conditions, but they cannot render view-consistent images with an unseen appearance. To solve this problem, we present an end-to-end framework for constructing a hallucinated **NeRF**, dubbed as Ha-**NeRF**. Specifically, we propose an appearance hallucination module to handle time-varying appearances and transfer them to novel views. Considering the complex occlusions of tourism images, we introduce an anti-occlusion module to decompose the static subjects for visibility accurately. Experimental results on synthetic data and real tourism photo collections demonstrate that our method can hallucinate the desired appearances and render occlusion-free images from different views. The project and supplementary materials are available at https://rover-xingyu.github.io/Ha-**NeRF**/.  
### Designing an Efficient End-to-end Machine Learning Pipeline for **Real-time** Empty-shelf Detection. (arXiv:2205.13060v2 [cs.LG] UPDATED)
- Authors : Dipendra Jha, Ata Mahjoubfar, Anupama Joshi
- Link : [http://arxiv.org/abs/2205.13060](http://arxiv.org/abs/2205.13060)
> ABSTRACT  :  On-Shelf Availability (OSA) of products in retail stores is a critical business criterion in the fast moving consumer goods and retails sector. When a product is out-of-stock (OOS) and a customer cannot find it on its designed shelf, this motivates the customer to store-switching or buying nothing, which causes fall in future sales and demands. Retailers are employing several approaches to detect empty shelves and ensure high OSA of products; however, such methods are generally ineffective and infeasible since they are either manual, expensive or less accurate. Recently machine learning based solutions have been proposed, but they suffer from high computational cost and low accuracy problem due to lack of large annotated datasets of on-shelf products. Here, we present an elegant approach for designing an end-to-end machine learning (ML) pipeline for real-time empty shelf detection. Considering the strong dependency between the quality of ML models and the quality of data, we focus on the importance of proper data collection, cleaning and correct data annotation before delving into modeling. Since an empty-shelf detection solution should be computationally-efficient for real-time predictions, we explore different run-time optimizations to improve the model performance. Our dataset contains 1000 images, collected and annotated by following well-defined guidelines. Our low-latency model achieves a mean average F1-score of 68.5%, and can process up to 67 images/s on Intel Xeon Gold and up to 860 images/s on an A100 GPU.  
## eess.IV
---
### Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v1 [cs.CV])
- Authors : Chunwei Tian, Yixuan Yuan, Shichao Zhang, Wen Lin, Wangmeng Zuo, David Zhang
- Link : [http://arxiv.org/abs/2205.14548](http://arxiv.org/abs/2205.14548)
> ABSTRACT  :  CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal **enhancement** operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.  
### GAN-based Medical Image Small Region Forgery Detection via a Two-Stage Cascade Framework. (arXiv:2205.15170v1 [eess.IV])
- Authors : Jianyi Zhang, Xuanxi Huang, Yaqi Liu, Yuyang Han, Zixiao Xiang
- Link : [http://arxiv.org/abs/2205.15170](http://arxiv.org/abs/2205.15170)
> ABSTRACT  :  Using generative adversarial network (GAN)\cite{RN90} for data **enhancement** of medical images is significantly helpful for many computer-aided diagnosis (CAD) tasks. A new attack called CT-GAN has emerged. It can inject or remove lung cancer lesions to CT scans. Because the tampering region may even account for less than 1\% of the original image, even state-of-the-art methods are challenging to detect the traces of such tampering.    This paper proposes a cascade framework to detect GAN-based medical image small region forgery like CT-GAN. In the local detection stage, we train the detector network with small sub-images so that interference information in authentic regions will not affect the detector. We use depthwise separable convolution and residual to prevent the detector from over-fitting and enhance the ability to find forged regions through the attention mechanism. The detection results of all sub-images in the same image will be combined into a heatmap. In the global classification stage, using gray level co-occurrence matrix (GLCM) can better extract features of the heatmap. Because the shape and size of the tampered area are uncertain, we train PCA and SVM methods for classification. Our method can classify whether a CT image has been tampered and locate the tampered position. Sufficient experiments show that our method can achieve excellent performance.  
## cs.LG
---
### Online Causal Inference for Advertising in Real-Time Bidding Auctions. (arXiv:1908.08600v3 [cs.LG] UPDATED)
- Authors : Caio Waisman, Carlos Carrion
- Link : [http://arxiv.org/abs/1908.08600](http://arxiv.org/abs/1908.08600)
> ABSTRACT  :  **Real-time** bidding (RTB) systems, which utilize auctions to allocate user impressions to competing advertisers, continue to enjoy success in digital advertising. Assessing the effectiveness of such advertising remains a challenge in research and practice. This paper proposes a new approach to perform causal inference on advertising bought through such mechanisms. Leveraging the economic structure of first- and second-price auctions, we first show that the effects of advertising are identified by the optimal bids. Hence, since these optimal bids are the only objects that need to be recovered, we introduce an adapted Thompson sampling (TS) algorithm to solve a multi-armed bandit problem that succeeds in recovering such bids and, consequently, the effects of advertising while minimizing the costs of experimentation. We derive a regret bound for our algorithm which is order optimal and use data from RTB auctions to show that it outperforms commonly used methods that estimate the effects of advertising.  
### Fast Neural Network based Solving of Partial Differential Equations. (arXiv:2205.08978v2 [cs.LG] UPDATED)
- Authors : Jaroslaw Rzepecki, Daniel Bates, Chris Doran
- Link : [http://arxiv.org/abs/2205.08978](http://arxiv.org/abs/2205.08978)
> ABSTRACT  :  We present a novel method for using Neural Networks (NNs) for finding solutions to a class of Partial Differential Equations (PDEs). Our method builds on recent advances in Neural Radiance Field research (**NeRF**s) and allows for a NN to converge to a PDE solution much faster than classic Physically Informed Neural Network (PINNs) approaches.  
### Designing an Efficient End-to-end Machine Learning Pipeline for **Real-time** Empty-shelf Detection. (arXiv:2205.13060v2 [cs.LG] UPDATED)
- Authors : Dipendra Jha, Ata Mahjoubfar, Anupama Joshi
- Link : [http://arxiv.org/abs/2205.13060](http://arxiv.org/abs/2205.13060)
> ABSTRACT  :  On-Shelf Availability (OSA) of products in retail stores is a critical business criterion in the fast moving consumer goods and retails sector. When a product is out-of-stock (OOS) and a customer cannot find it on its designed shelf, this motivates the customer to store-switching or buying nothing, which causes fall in future sales and demands. Retailers are employing several approaches to detect empty shelves and ensure high OSA of products; however, such methods are generally ineffective and infeasible since they are either manual, expensive or less accurate. Recently machine learning based solutions have been proposed, but they suffer from high computational cost and low accuracy problem due to lack of large annotated datasets of on-shelf products. Here, we present an elegant approach for designing an end-to-end machine learning (ML) pipeline for real-time empty shelf detection. Considering the strong dependency between the quality of ML models and the quality of data, we focus on the importance of proper data collection, cleaning and correct data annotation before delving into modeling. Since an empty-shelf detection solution should be computationally-efficient for real-time predictions, we explore different run-time optimizations to improve the model performance. Our dataset contains 1000 images, collected and annotated by following well-defined guidelines. Our low-latency model achieves a mean average F1-score of 68.5%, and can process up to 67 images/s on Intel Xeon Gold and up to 860 images/s on an A100 GPU.  
## cs.AI
---
### An adaptive admittance controller for collaborative drilling with a robot based on subtask classification via deep learning. (arXiv:2205.14457v1 [cs.RO])
- Authors : Berk Guler, Alireza Madani, Yusuf Aydin, Cagatay Basdogan
- Link : [http://arxiv.org/abs/2205.14457](http://arxiv.org/abs/2205.14457)
> ABSTRACT  :  In this paper, we propose a supervised learning approach based on an Artificial Neural Network (ANN) model for real-time classification of subtasks in a physical human-robot interaction (pHRI) task involving contact with a stiff environment. In this regard, we consider three subtasks for a given pHRI task: Idle, Driving, and Contact. Based on this classification, the parameters of an admittance controller that regulates the interaction between human and robot are adjusted adaptively in **real time** to make the robot more transparent to the operator (i.e. less resistant) during the Driving phase and more stable during the Contact phase. The Idle phase is primarily used to detect the initiation of task. Experimental results have shown that the ANN model can learn to detect the subtasks under different admittance controller conditions with an accuracy of 98% for 12 participants. Finally, we show that the admittance adaptation based on the proposed subtask classifier leads to 20% lower human effort (i.e. higher transparency) in the Driving phase and 25% lower oscillation amplitude (i.e. higher stability) during drilling in the Contact phase compared to an admittance controller with fixed parameters.  
### Feature-Aligned Video Raindrop Removal with Temporal Constraints. (arXiv:2205.14574v1 [cs.CV])
- Authors : Wending Yan, Lu Xu, **Wenhan Yang**
- Link : [http://arxiv.org/abs/2205.14574](http://arxiv.org/abs/2205.14574)
> ABSTRACT  :  Existing adherent raindrop removal methods focus on the detection of the raindrop locations, and then use inpainting techniques or generative networks to recover the background behind raindrops. Yet, as adherent raindrops are diverse in sizes and appearances, the detection is challenging for both single image and video. Moreover, unlike rain streaks, adherent raindrops tend to cover the same area in several frames. Addressing these problems, our method employs a two-stage video-based raindrop removal method. The first stage is the single image module, which generates initial clean results. The second stage is the multiple frame module, which further refines the initial results using temporal constraints, namely, by utilizing multiple input frames in our process and applying temporal consistency between adjacent output frames. Our single image module employs a raindrop removal network to generate initial raindrop removal results, and create a mask representing the differences between the input and initial output. Once the masks and initial results for consecutive frames are obtained, our multiple-frame module aligns the frames in both the image and feature levels and then obtains the clean background. Our method initially employs optical flow to align the frames, and then utilizes deformable convolution layers further to achieve feature-level frame alignment. To remove small raindrops and recover correct backgrounds, a target frame is predicted from adjacent frames. A series of unsupervised losses are proposed so that our second stage, which is the video raindrop removal module, can self-learn from video data without ground truths. Experimental results on real videos demonstrate the state-of-art performance of our method both quantitatively and qualitatively.  
### Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation. (arXiv:2205.14637v1 [cs.CV])
- Authors : Rohit Mohan, Abhinav Valada
- Link : [http://arxiv.org/abs/2205.14637](http://arxiv.org/abs/2205.14637)
> ABSTRACT  :  Amodal panoptic segmentation aims to connect the perception of the world to its cognitive understanding. It entails simultaneously predicting the semantic labels of visible scene regions and the entire shape of traffic participant instances, including regions that may be occluded. In this work, we formulate a proposal-free framework that tackles this task as a multi-label and multi-class problem by first assigning the amodal masks to different layers according to their relative occlusion order and then employing amodal instance regression on each layer independently while learning background semantics. We propose the \net architecture that incorporates a shared backbone and an asymmetrical dual-decoder consisting of several modules to facilitate within-scale and cross-scale feature aggregations, **bilateral** feature propagation between decoders, and integration of global instance-level and local pixel-level occlusion reasoning. Further, we propose the amodal mask refiner that resolves the ambiguity in complex occlusion scenarios by explicitly leveraging the embedding of unoccluded instance masks. Extensive evaluation on the BDD100K-APS and KITTI-360-APS datasets demonstrate that our approach set the new state-of-the-art on both benchmarks.  
### Hallucinated Neural Radiance Fields in the Wild. (arXiv:2111.15246v3 [cs.CV] UPDATED)
- Authors : Xingyu Chen, Qi Zhang, Xiaoyu Li, Yue Chen, Ying Feng, Xuan Wang, Jue Wang
- Link : [http://arxiv.org/abs/2111.15246](http://arxiv.org/abs/2111.15246)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**) has recently gained popularity for its impressive novel view synthesis ability. This paper studies the problem of hallucinated **NeRF**: i.e., recovering a realistic **NeRF** at a different time of day from a group of tourism images. Existing solutions adopt **NeRF** with a controllable appearance embedding to render novel views under various conditions, but they cannot render view-consistent images with an unseen appearance. To solve this problem, we present an end-to-end framework for constructing a hallucinated **NeRF**, dubbed as Ha-**NeRF**. Specifically, we propose an appearance hallucination module to handle time-varying appearances and transfer them to novel views. Considering the complex occlusions of tourism images, we introduce an anti-occlusion module to decompose the static subjects for visibility accurately. Experimental results on synthetic data and real tourism photo collections demonstrate that our method can hallucinate the desired appearances and render occlusion-free images from different views. The project and supplementary materials are available at https://rover-xingyu.github.io/Ha-**NeRF**/.  
# Paper List
---
## cs.CV
---
**133** new papers in cs.CV:-) 
1. Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity. (arXiv:2205.14177v1 [cs.CV])
2. Unsupervised learning of features and object boundaries from local prediction. (arXiv:2205.14195v1 [cs.CV])
3. Multimodal Masked Autoencoders Learn Transferable Representations. (arXiv:2205.14204v1 [cs.CV])
4. Exemplar Free Class Agnostic Counting. (arXiv:2205.14212v1 [cs.CV])
5. Semi-supervised Semantics-guided Adversarial Training for Trajectory Prediction. (arXiv:2205.14230v1 [cs.LG])
6. Image Keypoint Matching using Graph Neural Networks. (arXiv:2205.14275v1 [cs.CV])
7. Fast Object Placement Assessment. (arXiv:2205.14280v1 [cs.CV])
8. Is Lip Region-of-Interest Sufficient for Lipreading?. (arXiv:2205.14295v1 [cs.CV])
9. Fake It Till You Make It: Near-Distribution Novelty Detection by Score-Based Generative Models. (arXiv:2205.14297v1 [cs.CV])
10. Deep Learning with Label Noise: A Hierarchical Approach. (arXiv:2205.14299v1 [cs.LG])
11. Multimodal Fake News Detection via CLIP-Guided Learning. (arXiv:2205.14304v1 [cs.CV])
12. Robust Molecular Image Recognition: A Graph Generation Approach. (arXiv:2205.14311v1 [cs.CV])
13. WT-MVSNet: Window-based Transformers for Multi-view Stereo. (arXiv:2205.14319v1 [cs.CV])
14. RIAV-MVS: Recurrent-Indexing an Asymmetric Volume for Multi-View Stereo. (arXiv:2205.14320v1 [cs.CV])
15. Point RCNN: An Angle-Free Framework for Rotated Object Detection. (arXiv:2205.14328v1 [cs.CV])
16. Differentiable Point-Based Radiance Fields for Efficient View Synthesis. (arXiv:2205.14330v1 [cs.CV])
17. V4D: Voxel for 4D Novel View Synthesis. (arXiv:2205.14332v1 [cs.CV])
18. Object-wise Masked Autoencoders for Fast Pre-training. (arXiv:2205.14338v1 [cs.CV])
19. Estimation of 3D Body Shape and Clothing Measurements from Frontal- and Side-view Images. (arXiv:2205.14347v1 [cs.CV])
20. Multi-Task Learning with Multi-query Transformer for Dense Prediction. (arXiv:2205.14354v1 [cs.CV])
21. Boosting Facial Expression Recognition by A Semi-Supervised Progressive Teacher. (arXiv:2205.14361v1 [cs.CV])
22. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v1 [cs.CV])
23. Enhancing Quality of Pose-varied Face **Restoration** with Local Weak Feature Sensing and GAN Prior. (arXiv:2205.14377v1 [cs.CV])
24. Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training. (arXiv:2205.14401v1 [cs.CV])
25. Strengthening Skeletal Action Recognizers via Leveraging Temporal Patterns. (arXiv:2205.14405v1 [cs.CV])
26. Data Generation for Satellite Image Classification Using Self-Supervised Representation Learning. (arXiv:2205.14418v1 [cs.CV])
27. Looks Like Magic: Transfer Learning in GANs to Generate New Card Illustrations. (arXiv:2205.14442v1 [cs.CV])
28. A Closer Look at Self-supervised Lightweight Vision Transformers. (arXiv:2205.14443v1 [cs.CV])
29. Visual Superordinate Abstraction for Robust Concept Learning. (arXiv:2205.14444v1 [cs.CV])
30. Variational Transformer: A Framework Beyond the Trade-off between Accuracy and Diversity for Image Captioning. (arXiv:2205.14458v1 [cs.CV])
31. CyCLIP: Cyclic Contrastive Language-Image Pretraining. (arXiv:2205.14459v1 [cs.CV])
32. Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors. (arXiv:2205.14467v1 [cs.LG])
33. Perceptually Optimized Color Selection for Visualization. (arXiv:2205.14472v1 [cs.CV])
34. DeepRM: Deep Recurrent Matching for 6D Pose Refinement. (arXiv:2205.14474v1 [cs.CV])
35. MDMLP: Image Classification from Scratch on Small Datasets with MLP. (arXiv:2205.14477v1 [cs.CV])
36. A New High-Performance Approach to Approximate Pattern-Matching for Plagiarism Detection in Blockchain-Based Non-Fungible Tokens (NFTs). (arXiv:2205.14492v1 [cs.FL])
37. BadDet: Backdoor Attacks on Object Detection. (arXiv:2205.14497v1 [cs.CV])
38. SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners. (arXiv:2205.14540v1 [cs.CV])
39. The Missing Invariance Principle Found -- the Reciprocal Twin of Invariant Risk Minimization. (arXiv:2205.14546v1 [cs.LG])
40. Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v1 [cs.CV])
41. ProxyMix: Proxy-based Mixup Training with Label Refinery for Source-Free Domain Adaptation. (arXiv:2205.14566v1 [cs.CV])
42. ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation. (arXiv:2205.14573v1 [cs.CV])
43. Feature-Aligned Video Raindrop Removal with Temporal Constraints. (arXiv:2205.14574v1 [cs.CV])
44. 3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction. (arXiv:2205.14575v1 [cs.CV])
45. Towards an unsupervised large-scale 2D and 3D building mapping with LiDAR. (arXiv:2205.14585v1 [cs.CV])
46. Masked Distillation with Receptive Tokens. (arXiv:2205.14589v1 [cs.CV])
47. BiasEnsemble: Revisiting the Importance of Amplifying Bias for Debiasing. (arXiv:2205.14594v1 [cs.CV])
48. A General Multiple Data Augmentation Based Framework for Training Deep Neural Networks. (arXiv:2205.14606v1 [cs.NE])
49. IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation. (arXiv:2205.14620v1 [cs.CV])
50. SKFlow: Learning Optical Flow with Super Kernels. (arXiv:2205.14623v1 [cs.CV])
51. Cervical Glandular Cell Detection from Whole Slide Image with Out-Of-Distribution Data. (arXiv:2205.14625v1 [cs.CV])
52. Superclass Adversarial Attack. (arXiv:2205.14629v1 [cs.CV])
53. Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation. (arXiv:2205.14637v1 [cs.CV])
54. Micro-Expression Recognition Based on Attribute Information Embedding and Cross-modal Contrastive Learning. (arXiv:2205.14643v1 [cs.CV])
55. COFS: Controllable Furniture layout Synthesis. (arXiv:2205.14657v1 [cs.CV])
56. Glance to Count: Learning to Rank with Anchors for Weakly-supervised Crowd Counting. (arXiv:2205.14659v1 [cs.CV])
57. Saliency Map Based Data Augmentation. (arXiv:2205.14686v1 [cs.CV])
58. EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition. (arXiv:2205.14756v1 [cs.CV])
59. Supervised Uncertainty Quantification for Segmentation with Multiple Annotations. (arXiv:1907.01949v2 [cs.LG] UPDATED)
60. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v6 [cs.LG] UPDATED)
61. L6DNet: Light 6 DoF Network for Robust and Precise Object Pose Estimation with Small Datasets. (arXiv:2002.00911v6 [cs.CV] UPDATED)
62. A Bayesian approach to tissue-fraction estimation for oncological PET segmentation. (arXiv:2003.00317v3 [physics.med-ph] UPDATED)
63. FedBoosting: Federated Learning with Gradient Protected Boosting for Text Recognition. (arXiv:2007.07296v3 [cs.CV] UPDATED)
64. DSG-Net: Learning Disentangled Structure and Geometry for 3D Shape Generation. (arXiv:2008.05440v4 [cs.GR] UPDATED)
65. Probing Few-Shot Generalization with Attributes. (arXiv:2012.05895v3 [cs.LG] UPDATED)
66. Adversarial Momentum-Contrastive Pre-Training. (arXiv:2012.13154v4 [cs.CV] UPDATED)
67. Multi-point dimensionality reduction to improve projection layout reliability. (arXiv:2101.06224v3 [cs.CV] UPDATED)
68. DivSwapper: Towards Diversified Patch-based Arbitrary Style Transfer. (arXiv:2101.06381v2 [cs.CV] UPDATED)
69. DeepRA: Predicting Joint Damage From Radiographs Using CNN with Attention. (arXiv:2102.06982v2 [cs.CV] UPDATED)
70. Conditional Image Generation by Conditioning Variational Auto-Encoders. (arXiv:2102.12037v3 [cs.CV] UPDATED)
71. DisCo: Remedy Self-supervised Learning on Lightweight Models with Distilled Contrastive Learning. (arXiv:2104.09124v6 [cs.CV] UPDATED)
72. Aerial Map-Based Navigation Using Semantic Segmentation and Pattern Matching. (arXiv:2107.00689v3 [cs.CV] UPDATED)
73. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v8 [cs.CV] UPDATED)
74. Certifiably Optimal Outlier-Robust Geometric Perception: Semidefinite Relaxations and Scalable Global Optimization. (arXiv:2109.03349v2 [cs.CV] UPDATED)
75. Sparse MLP for Image Recognition: Is Self-Attention Really Necessary?. (arXiv:2109.05422v2 [cs.CV] UPDATED)
76. Online Unsupervised Learning of Visual Representations and Categories. (arXiv:2109.05675v4 [cs.CV] UPDATED)
77. DAFNe: A One-Stage Anchor-Free Approach for Oriented Object Detection. (arXiv:2109.06148v4 [cs.CV] UPDATED)
78. End-to-End Dense Video Grounding via Parallel Regression. (arXiv:2109.11265v4 [cs.CV] UPDATED)
79. Cross-Camera Human Motion Transfer by Time Series Analysis. (arXiv:2109.14174v2 [cs.CV] UPDATED)
80. Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. (arXiv:2110.03141v2 [cs.AI] UPDATED)
81. Pre-training Molecular Graph Representation with 3D Geometry. (arXiv:2110.07728v2 [cs.LG] UPDATED)
82. Source-free unsupervised domain adaptation for cross-modality abdominal multi-organ segmentation. (arXiv:2111.12221v4 [cs.CV] UPDATED)
83. Hallucinated Neural Radiance Fields in the Wild. (arXiv:2111.15246v3 [cs.CV] UPDATED)
84. Trimap-guided Feature Mining and Fusion Network for Natural Image Matting. (arXiv:2112.00510v3 [cs.CV] UPDATED)
85. Deep Retinex Fusion for Adaptive Infrared and Visible Image Super-resolution Fusion. (arXiv:2112.02869v3 [cs.CV] UPDATED)
86. M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural Architecture Search. (arXiv:2112.07918v3 [cs.CV] UPDATED)
87. Point2Cyl: Reverse Engineering 3D Objects from Point Clouds to Extrusion Cylinders. (arXiv:2112.09329v2 [cs.CV] UPDATED)
88. Flow-Guided Sparse Transformer for Video Deblurring. (arXiv:2201.01893v3 [eess.IV] UPDATED)
89. Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World. (arXiv:2201.08619v2 [cs.CV] UPDATED)
90. Zero-Shot Sketch Based Image Retrieval using Graph Transformer. (arXiv:2201.10185v2 [cs.CV] UPDATED)
91. Deep Image Deblurring: A Survey. (arXiv:2201.10700v2 [cs.CV] UPDATED)
92. Dual-Tasks Siamese Transformer Framework for Building Damage Assessment. (arXiv:2201.10953v2 [cs.CV] UPDATED)
93. Learning to Compose Diversified Prompts for Image Emotion Classification. (arXiv:2201.10963v2 [cs.CV] UPDATED)
94. Domain-Invariant Representation Learning from EEG with Private Encoders. (arXiv:2201.11613v2 [cs.LG] UPDATED)
95. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v3 [cs.CV] UPDATED)
96. Context Autoencoder for Self-Supervised Representation Learning. (arXiv:2202.03026v2 [cs.CV] UPDATED)
97. Sim-to-Real Domain Adaptation for Lane Detection and Classification in Autonomous Driving. (arXiv:2202.07133v2 [cs.CV] UPDATED)
98. Lie Point Symmetry Data Augmentation for Neural PDE Solvers. (arXiv:2202.07643v2 [cs.LG] UPDATED)
99. OSegNet: Operational Segmentation Network for COVID-19 Detection using Chest X-ray Images. (arXiv:2202.10185v2 [eess.IV] UPDATED)
100. TwistSLAM: Constrained SLAM in Dynamic Environment. (arXiv:2202.12384v3 [cs.RO] UPDATED)
101. The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods. (arXiv:2203.02486v2 [cs.CV] UPDATED)
102. DrawingInStyles: Portrait Image Generation and Editing with Spatially Conditioned StyleGAN. (arXiv:2203.02762v2 [cs.GR] UPDATED)
103. Do We Really Need a Learnable Classifier at the End of Deep Neural Network?. (arXiv:2203.09081v2 [cs.LG] UPDATED)
104. Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v4 [cs.CV] UPDATED)
105. Bayesian Inversion for Nonlinear Imaging Models using Deep Generative Priors. (arXiv:2203.10078v2 [cs.CV] UPDATED)
106. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v2 [cs.LG] UPDATED)
107. Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction. (arXiv:2203.12997v3 [cs.CV] UPDATED)
108. MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection. (arXiv:2203.13310v3 [cs.CV] UPDATED)
109. Min-Max Similarity: A Contrastive Learning Based Semi-Supervised Learning Network for Surgical Tools Segmentation. (arXiv:2203.15177v2 [cs.CV] UPDATED)
110. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v3 [cs.LG] UPDATED)
111. Analysis of Different Losses for Deep Learning Image Colorization. (arXiv:2204.02980v3 [cs.CV] UPDATED)
112. Pin the Memory: Learning to Generalize Semantic Segmentation. (arXiv:2204.03609v2 [cs.CV] UPDATED)
113. Transparent Shape from Single Polarization Images. (arXiv:2204.06331v4 [cs.CV] UPDATED)
114. Beyond the Prototype: Divide-and-conquer Proxies for Few-shot Segmentation. (arXiv:2204.09903v2 [cs.CV] UPDATED)
115. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v3 [cs.CV] UPDATED)
116. PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining. (arXiv:2204.14095v2 [cs.CV] UPDATED)
117. Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion Networks. (arXiv:2205.01355v3 [cs.GR] UPDATED)
118. Detecting and Understanding Harmful Memes: A Survey. (arXiv:2205.04274v2 [cs.CL] UPDATED)
119. K-textures, a self-supervised hard clustering deep learning algorithm for satellite image segmentation. (arXiv:2205.08671v2 [cs.CV] UPDATED)
120. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v3 [cs.CV] UPDATED)
121. Transformer based Generative Adversarial Network for Liver Segmentation. (arXiv:2205.10663v2 [eess.IV] UPDATED)
122. Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners. (arXiv:2205.10747v3 [cs.CV] UPDATED)
123. Fine-Grained Counting with Crowd-Sourced Supervision. (arXiv:2205.11398v2 [cs.CV] UPDATED)
124. Towards Model Generalization for Monocular 3D Object Detection. (arXiv:2205.11664v2 [cs.CV] UPDATED)
125. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v2 [cs.CV] UPDATED)
126. Accelerating Diffusion Models via Early Stop of the Diffusion Process. (arXiv:2205.12524v2 [cs.CV] UPDATED)
127. Contrastive Learning with Boosted Memorization. (arXiv:2205.12693v2 [cs.CV] UPDATED)
128. Designing an Efficient End-to-end Machine Learning Pipeline for **Real-time** Empty-shelf Detection. (arXiv:2205.13060v2 [cs.LG] UPDATED)
129. MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning. (arXiv:2205.13137v2 [cs.CV] UPDATED)
130. CA-UDA: Class-Aware Unsupervised Domain Adaptation with Optimal Assignment and Pseudo-Label Refinement. (arXiv:2205.13579v2 [cs.CV] UPDATED)
131. TraClets: Harnessing the power of computer vision for trajectory classification. (arXiv:2205.13880v2 [cs.CV] UPDATED)
132. Sharpness-Aware Training for Free. (arXiv:2205.14083v2 [cs.LG] UPDATED)
133. OpenCalib: A Multi-sensor Calibration Toolbox for Autonomous Driving. (arXiv:2205.14087v2 [cs.RO] UPDATED)
## eess.IV
---
**25** new papers in eess.IV:-) 
1. Noise analysis, error estimates, and Gamma Radiation Measurement for limited detector computerized tomography application. (arXiv:2205.14144v1 [eess.IV])
2. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v1 [eess.IV])
3. Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity. (arXiv:2205.14177v1 [cs.CV])
4. A comparison of Fourier and POD mode decomposition methods for high-speed Hall thruster video. (arXiv:2205.14207v1 [physics.plasm-ph])
5. Rethinking Bayesian Learning for Data Analysis: The Art of Prior and Inference in Sparsity-Aware Modeling. (arXiv:2205.14283v1 [stat.ML])
6. P2M-DeTrack: Processing-in-Pixel-in-Memory for Energy-efficient and Real-Time Multi-Object Detection and Tracking. (arXiv:2205.14285v1 [eess.IV])
7. PO-ELIC: Perception-Oriented Efficient Learned Image Coding. (arXiv:2205.14501v1 [eess.IV])
8. Q-LIC: Quantizing Learned Image Compression with Channel Splitting. (arXiv:2205.14510v1 [eess.IV])
9. Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v1 [cs.CV])
10. Deep Posterior Distribution-based Embedding for Hyperspectral Image Super-resolution. (arXiv:2205.14887v1 [cs.CV])
11. Task-Prior Conditional Variational Auto-Encoder for Few-Shot Image Classification. (arXiv:2205.15014v1 [cs.CV])
12. GAN-based Medical Image Small Region Forgery Detection via a Two-Stage Cascade Framework. (arXiv:2205.15170v1 [eess.IV])
13. A Bayesian approach to tissue-fraction estimation for oncological PET segmentation. (arXiv:2003.00317v3 [physics.med-ph] UPDATED)
14. Model-based Synthetic Data-driven Learning (MOST-DL): Application in Single-shot T2 Mapping with Severe Head Motion Using Overlapping-echo Acquisition. (arXiv:2107.14521v3 [eess.IV] UPDATED)
15. Information-theoretic symmetry classifications of crystal patterns in the presence of noise and strong Fedorov type pseudosymmetries for an optimal subsequent crystallographic processing of these patterns. (arXiv:2108.00829v7 [eess.IV] UPDATED)
16. Pre-training Molecular Graph Representation with 3D Geometry. (arXiv:2110.07728v2 [cs.LG] UPDATED)
17. Deep Retinex Fusion for Adaptive Infrared and Visible Image Super-resolution Fusion. (arXiv:2112.02869v3 [cs.CV] UPDATED)
18. Flow-Guided Sparse Transformer for Video Deblurring. (arXiv:2201.01893v3 [eess.IV] UPDATED)
19. Dual-Tasks Siamese Transformer Framework for Building Damage Assessment. (arXiv:2201.10953v2 [cs.CV] UPDATED)
20. OSegNet: Operational Segmentation Network for COVID-19 Detection using Chest X-ray Images. (arXiv:2202.10185v2 [eess.IV] UPDATED)
21. MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection. (arXiv:2203.13310v3 [cs.CV] UPDATED)
22. Min-Max Similarity: A Contrastive Learning Based Semi-Supervised Learning Network for Surgical Tools Segmentation. (arXiv:2203.15177v2 [cs.CV] UPDATED)
23. Transformer based Generative Adversarial Network for Liver Segmentation. (arXiv:2205.10663v2 [eess.IV] UPDATED)
24. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v2 [cs.CV] UPDATED)
25. FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation. (arXiv:2205.12465v2 [cs.LG] UPDATED)
## cs.LG
---
**266** new papers in cs.LG:-) 
1. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v1 [eess.IV])
2. Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport. (arXiv:2205.14173v1 [cs.LG])
3. Private and Byzantine-Proof Cooperative Decision-Making. (arXiv:2205.14174v1 [stat.ML])
4. Multiscale Voxel Based Decoding For Enhanced Natural Image Reconstruction From Brain Activity. (arXiv:2205.14177v1 [cs.CV])
5. Optimizing Objective Functions from Trained ReLU Neural Networks via Sampling. (arXiv:2205.14189v1 [math.OC])
6. Constrained Langevin Algorithms with L-mixing External Random Variables. (arXiv:2205.14192v1 [cs.LG])
7. FadMan: Federated Anomaly Detection across Multiple Attributed Networks. (arXiv:2205.14196v1 [cs.LG])
8. Generalized Reductions: Making any Hierarchical Clustering Fair and Balanced with Low Cost. (arXiv:2205.14198v1 [cs.LG])
9. Robust Phi-Divergence MDPs. (arXiv:2205.14202v1 [math.OC])
10. ALMA: Hierarchical Learning for Composite Multi-Agent Tasks. (arXiv:2205.14205v1 [cs.LG])
11. Targeted Adaptive Design. (arXiv:2205.14208v1 [cs.LG])
12. StarGraph: A Coarse-to-Fine Representation Method for Large-Scale Knowledge Graph. (arXiv:2205.14209v1 [cs.LG])
13. MIP-GNN: A Data-Driven Framework for Guiding Combinatorial Solvers. (arXiv:2205.14210v1 [cs.LG])
14. KL-Entropy-Regularized RL with a Generative Model is Minimax Optimal. (arXiv:2205.14211v1 [cs.LG])
15. Diffusion-LM Improves Controllable Text Generation. (arXiv:2205.14217v1 [cs.CL])
16. Will Bilevel Optimizers Benefit from Loops. (arXiv:2205.14224v1 [cs.LG])
17. Semi-supervised Semantics-guided Adversarial Training for Trajectory Prediction. (arXiv:2205.14230v1 [cs.LG])
18. Competitive Gradient Optimization. (arXiv:2205.14232v1 [math.OC])
19. FedControl: When Control Theory Meets Federated Learning. (arXiv:2205.14236v1 [cs.LG])
20. Provably Sample-Efficient RL with Side Information about Latent Dynamics. (arXiv:2205.14237v1 [cs.LG])
21. Deterministic Langevin Monte Carlo with Normalizing Flows for Bayesian Inference. (arXiv:2205.14240v1 [stat.ML])
22. Experience report of physics-informed neural networks in fluid simulations: pitfalls and frustration. (arXiv:2205.14249v1 [physics.flu-dyn])
23. On the Symmetries of Deep Learning Models and their Internal Representations. (arXiv:2205.14258v1 [cs.LG])
24. Personalized PageRank Graph Attention Networks. (arXiv:2205.14259v1 [cs.LG])
25. NeuPSL: Neural Probabilistic Soft Logic. (arXiv:2205.14268v1 [cs.LG])
26. Towards Communication-Learning Trade-off for Federated Learning at the Network Edge. (arXiv:2205.14271v1 [cs.LG])
27. Image Keypoint Matching using Graph Neural Networks. (arXiv:2205.14275v1 [cs.CV])
28. So3krates -- Self-attention for higher-order geometric interactions on arbitrary length-scales. (arXiv:2205.14276v1 [cs.LG])
29. Uniform Convergence and Generalization for Nonconvex Stochastic Minimax Problems. (arXiv:2205.14278v1 [math.OC])
30. Rethinking Bayesian Learning for Data Analysis: The Art of Prior and Inference in Sparsity-Aware Modeling. (arXiv:2205.14283v1 [stat.ML])
31. Provably Auditing Ordinary Least Squares in Low Dimensions. (arXiv:2205.14284v1 [stat.ML])
32. Fake It Till You Make It: Near-Distribution Novelty Detection by Score-Based Generative Models. (arXiv:2205.14297v1 [cs.CV])
33. MC-GEN:Multi-level Clustering for Private Synthetic Data Generation. (arXiv:2205.14298v1 [cs.LG])
34. Deep Learning with Label Noise: A Hierarchical Approach. (arXiv:2205.14299v1 [cs.LG])
35. A Quadrature Perspective on Frequency Bias in Neural Network Training with Nonuniform Data. (arXiv:2205.14300v1 [cs.LG])
36. Uncertainty quantification of two-phase flow in porous media via coupled-TgNN surrogate model. (arXiv:2205.14301v1 [physics.flu-dyn])
37. Deep Embedded Clustering with Distribution Consistency Preservation for Attributed Networks. (arXiv:2205.14303v1 [cs.LG])
38. Ensemble2: Anomaly Detection via EVT-Ensemble Framework for Seasonal KPIs in Communication Network. (arXiv:2205.14305v1 [cs.LG])
39. TFLEX: Temporal Feature-Logic Embedding Framework for Complex Reasoning over Temporal Knowledge Graph. (arXiv:2205.14307v1 [cs.LG])
40. Federated Neural Bandit. (arXiv:2205.14309v1 [cs.LG])
41. Approximate Conditional Coverage via Neural Model Approximations. (arXiv:2205.14310v1 [cs.LG])
42. Efficient Federated Learning with Spike Neural Networks for Traffic Sign Recognition. (arXiv:2205.14315v1 [cs.LG])
43. A Confidence Machine for Sparse High-Order Interaction Model. (arXiv:2205.14317v1 [stat.ML])
44. Learning from Self-Sampled Correct and Partially-Correct Programs. (arXiv:2205.14318v1 [cs.LG])
45. Automatic Expert Selection for Multi-Scenario and Multi-Task Search. (arXiv:2205.14321v1 [cs.LG])
46. Multi-agent Databases via Independent Learning. (arXiv:2205.14323v1 [cs.DB])
47. Differentially Private Covariance Revisited. (arXiv:2205.14324v1 [cs.CR])
48. Feature subset selection for kernel SVM classification via mixed-integer optimization. (arXiv:2205.14325v1 [cs.LG])
49. Survival Analysis on Structured Data using Deep Reinforcement Learning. (arXiv:2205.14331v1 [cs.LG])
50. Teaching Models to Express Their Uncertainty in Words. (arXiv:2205.14334v1 [cs.CL])
51. Gating Dropout: Communication-efficient Regularization for Sparsely Activated Transformers. (arXiv:2205.14336v1 [cs.LG])
52. List-Decodable Sparse Mean Estimation. (arXiv:2205.14337v1 [cs.LG])
53. Object-wise Masked Autoencoders for Fast Pre-training. (arXiv:2205.14338v1 [cs.CV])
54. Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories. (arXiv:2205.14345v1 [cs.LG])
55. Estimation of 3D Body Shape and Clothing Measurements from Frontal- and Side-view Images. (arXiv:2205.14347v1 [cs.CV])
56. Fair Labeled Clustering. (arXiv:2205.14358v1 [cs.LG])
57. Granular Generalized Variable Precision Rough Sets and Rational Approximations. (arXiv:2205.14365v1 [cs.AI])
58. Going Deeper into Permutation-Sensitive Graph Neural Networks. (arXiv:2205.14368v1 [cs.LG])
59. Syntax-Guided Program Reduction for Understanding Neural Code Intelligence Models. (arXiv:2205.14374v1 [cs.SE])
60. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v1 [cs.CV])
61. Deep Learning-based Spatially Explicit Emulation of an Agent-Based Simulator for Pandemic in a City. (arXiv:2205.14396v1 [cs.MA])
62. Rethinking the Setting of Semi-supervised Learning on Graphs. (arXiv:2205.14403v1 [cs.LG])
63. Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning. (arXiv:2205.14410v1 [cs.LG])
64. Non-stationary Transformers: Rethinking the Stationarity in Time Series Forecasting. (arXiv:2205.14415v1 [cs.LG])
65. Fault-Aware Design and Training to Enhance DNNs Reliability with Zero-Overhead. (arXiv:2205.14420v1 [cs.LG])
66. Approximation of Functionals by Neural Network without Curse of Dimensionality. (arXiv:2205.14421v1 [math.NA])
67. Go Beyond Multiple Instance Neural Networks: Deep-learning Models based on Local Pattern Aggregation. (arXiv:2205.14428v1 [cs.LG])
68. Laplace HypoPINN: Physics-Informed Neural Network for hypocenter localization and its predictive uncertainty. (arXiv:2205.14439v1 [cs.LG])
69. Large-Scale Privacy-Preserving Network Embedding against Private Link Inference Attacks. (arXiv:2205.14440v1 [cs.LG])
70. Looks Like Magic: Transfer Learning in GANs to Generate New Card Illustrations. (arXiv:2205.14442v1 [cs.CV])
71. Stochastic Gradient Methods with Compressed Communication for Decentralized Saddle Point Problems. (arXiv:2205.14452v1 [cs.LG])
72. Variational Transformer: A Framework Beyond the Trade-off between Accuracy and Diversity for Image Captioning. (arXiv:2205.14458v1 [cs.CV])
73. CyCLIP: Cyclic Contrastive Language-Image Pretraining. (arXiv:2205.14459v1 [cs.CV])
74. Visual Perception of Building and Household Vulnerability from Streets. (arXiv:2205.14460v1 [cs.LG])
75. Collaborative likelihood-ratio estimation over graphs. (arXiv:2205.14461v1 [stat.ML])
76. Espresso: Revisiting Gradient Compression from the System Perspective. (arXiv:2205.14465v1 [cs.LG])
77. Divide to Adapt: Mitigating Confirmation Bias for Domain Adaptation of Black-Box Predictors. (arXiv:2205.14467v1 [cs.LG])
78. Efficient-Adam: Communication-Efficient Distributed Adam with Complexity Analysis. (arXiv:2205.14473v1 [cs.LG])
79. Happenstance: Utilizing Semantic Search to Track Russian State Media Narratives about the Russo-Ukrainian War On Reddit. (arXiv:2205.14484v1 [cs.SI])
80. Noise-Aware Statistical Inference with Differentially Private Synthetic Data. (arXiv:2205.14485v1 [stat.ML])
81. Task-Agnostic Continual Reinforcement Learning: In Praise of a Simple Baseline. (arXiv:2205.14495v1 [cs.LG])
82. SuperVoice: Text-Independent Speaker Verification Using Ultrasound Energy in Human Speech. (arXiv:2205.14496v1 [cs.SD])
83. Optimal Decision Diagrams for Classification. (arXiv:2205.14500v1 [cs.LG])
84. Introducing Non-Linearity into Quantum Generative Models. (arXiv:2205.14506v1 [quant-ph])
85. Core-set Selection Using Metrics-based Explanations (CSUME) for multiclass ECG. (arXiv:2205.14508v1 [cs.LG])
86. Additive Higher-Order Factorization Machines. (arXiv:2205.14515v1 [stat.CO])
87. History-Restricted Online Learning. (arXiv:2205.14519v1 [cs.LG])
88. Transfer Learning as a Method to Reproduce High-Fidelity NLTE Opacities in Simulations. (arXiv:2205.14520v1 [physics.comp-ph])
89. Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization. (arXiv:2205.14521v1 [cs.CL])
90. A Character-Level Length-Control Algorithm for Non-Autoregressive Sentence Summarization. (arXiv:2205.14522v1 [cs.CL])
91. Group-wise Reinforcement Feature Generation for Optimal and Explainable Representation Space Reconstruction. (arXiv:2205.14526v1 [cs.LG])
92. Improving VAE-based Representation Learning. (arXiv:2205.14539v1 [stat.ML])
93. SupMAE: Supervised Masked Autoencoders Are Efficient Vision Learners. (arXiv:2205.14540v1 [cs.CV])
94. Functional Linear Regression of CDFs. (arXiv:2205.14545v1 [cs.LG])
95. The Missing Invariance Principle Found -- the Reciprocal Twin of Invariant Risk Minimization. (arXiv:2205.14546v1 [cs.LG])
96. Machine Learning for Microcontroller-Class Hardware -- A Review. (arXiv:2205.14550v1 [cs.LG])
97. A Model of One-Shot Generalization. (arXiv:2205.14553v1 [cs.LG])
98. Representation Gap in Deep Reinforcement Learning. (arXiv:2205.14557v1 [cs.LG])
99. Calibrated Predictive Distributions via Diagnostics for Conditional Coverage. (arXiv:2205.14568v1 [stat.ML])
100. AutoDisc: Automatic Distillation Schedule for Large Language Model Compression. (arXiv:2205.14570v1 [cs.CL])
101. Provable Benefits of Representational Transfer in Reinforcement Learning. (arXiv:2205.14571v1 [cs.LG])
102. No-regret Learning in Repeated First-Price Auctions with Budget Constraints. (arXiv:2205.14572v1 [cs.GT])
103. 3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction. (arXiv:2205.14575v1 [cs.CV])
104. Learning Locality and Isotropy in Dialogue Modeling. (arXiv:2205.14583v1 [cs.CL])
105. Masked Distillation with Receptive Tokens. (arXiv:2205.14589v1 [cs.CV])
106. Independent and Decentralized Learning in Markov Potential Games. (arXiv:2205.14590v1 [cs.LG])
107. Joint Abductive and Inductive Neural Logical Reasoning. (arXiv:2205.14591v1 [cs.AI])
108. An adaptive granularity clustering method based on hyper-ball. (arXiv:2205.14592v1 [cs.LG])
109. Dynamic Graph Learning Based on Hierarchical Memory for Origin-Destination Demand Prediction. (arXiv:2205.14593v1 [cs.LG])
110. Do Residual Neural Networks discretize Neural Ordinary Differential Equations?. (arXiv:2205.14612v1 [cs.LG])
111. A Conditional Randomization Test for Sparse Logistic Regression in High-Dimension. (arXiv:2205.14613v1 [stat.ML])
112. Graph Structure Based Data Augmentation Method. (arXiv:2205.14619v1 [cs.LG])
113. Continuous Generative Neural Networks. (arXiv:2205.14627v1 [stat.ML])
114. Physical Activation Functions (PAFs): An Approach for More Efficient Induction of Physics into Physics-Informed Neural Networks (PINNs). (arXiv:2205.14630v1 [cs.LG])
115. Micro-Expression Recognition Based on Attribute Information Embedding and Cross-modal Contrastive Learning. (arXiv:2205.14643v1 [cs.CV])
116. Speaker Identification using Speech Recognition. (arXiv:2205.14649v1 [cs.SD])
117. Contributions to Representation Learning with Graph Autoencoders and Applications to Music Recommendation. (arXiv:2205.14651v1 [cs.LG])
118. COFS: Controllable Furniture layout Synthesis. (arXiv:2205.14657v1 [cs.CV])
119. Heterogeneous Data-Centric Architectures for Modern Data-Intensive Applications: Case Studies in Machine Learning and Databases. (arXiv:2205.14664v1 [cs.AR])
120. Diminishing Empirical Risk Minimization for Unsupervised Anomaly Detection. (arXiv:2205.14676v1 [cs.LG])
121. The impact of memory on learning sequence-to-sequence tasks. (arXiv:2205.14683v1 [cs.LG])
122. On the Robustness of Safe Reinforcement Learning under Observational Perturbations. (arXiv:2205.14691v1 [cs.LG])
123. Generalization bounds and algorithms for estimating conditional average treatment effect of dosage. (arXiv:2205.14692v1 [cs.LG])
124. Learning Security Strategies through Game Play and Optimal Stopping. (arXiv:2205.14694v1 [cs.LG])
125. Evaluating Automated Driving Planner Robustness against Adversarial Influence. (arXiv:2205.14697v1 [cs.CR])
126. Heterogeneous Treatment Effects Estimation: When Machine Learning meets multiple treatment regime. (arXiv:2205.14714v1 [stat.ML])
127. What are People Talking about in #BackLivesMatter and #StopAsianHate? Exploring and Categorizing Twitter Topics Emerging in Online Social Movements through the Latent Dirichlet Allocation Model. (arXiv:2205.14725v1 [cs.IR])
128. L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models, and Library. (arXiv:2205.14728v1 [cs.CL])
129. Stochastic Zeroth Order Gradient and Hessian Estimators: Variance Reduction and Refined Bias Bounds. (arXiv:2205.14737v1 [cs.LG])
130. A Generative Adversarial Network-based Selective Ensemble Characteristic-to-Expression Synthesis (SE-CTES) Approach and Its Applications in Healthcare. (arXiv:2205.14751v1 [stat.ML])
131. Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles. (arXiv:1703.01347v2 [cs.AI] UPDATED)
132. Anomaly Detection on Graph Time Series. (arXiv:1708.02975v3 [cs.LG] UPDATED)
133. A Grover-search Based Quantum Learning Scheme for Classification. (arXiv:1809.06056v2 [quant-ph] UPDATED)
134. Supervised Uncertainty Quantification for Segmentation with Multiple Annotations. (arXiv:1907.01949v2 [cs.LG] UPDATED)
135. On The Smoothness of Cross-Validation-Based Estimators Of Classifier Performance. (arXiv:1907.13413v4 [stat.ML] UPDATED)
136. Online Causal Inference for Advertising in Real-Time Bidding Auctions. (arXiv:1908.08600v3 [cs.LG] UPDATED)
137. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v6 [cs.LG] UPDATED)
138. Training of Quantized Deep Neural Networks using a Magnetic Tunnel Junction-Based Synapse. (arXiv:1912.12636v2 [cs.ET] UPDATED)
139. Fast Predictive Uncertainty for Classification with Bayesian Deep Networks. (arXiv:2003.01227v3 [cs.LG] UPDATED)
140. Disentangled Representation Learning and Generation with Manifold Optimization. (arXiv:2006.07046v4 [cs.LG] UPDATED)
141. Set Based Stochastic Subsampling. (arXiv:2006.14222v4 [cs.LG] UPDATED)
142. Quantum Differentially Private Sparse Regression Learning. (arXiv:2007.11921v2 [quant-ph] UPDATED)
143. Energy-based error bound of physics-informed neural network solutions in elasticity. (arXiv:2010.09088v2 [math.NA] UPDATED)
144. Quantum circuit architecture search for variational quantum algorithms. (arXiv:2010.10217v3 [quant-ph] UPDATED)
145. Double Self-weighted Multi-view Clustering via Adaptive View Fusion. (arXiv:2011.10396v2 [cs.LG] UPDATED)
146. Towards an AI assistant for power grid operators. (arXiv:2012.02026v2 [stat.ML] UPDATED)
147. Probing Few-Shot Generalization with Attributes. (arXiv:2012.05895v3 [cs.LG] UPDATED)
148. DivSwapper: Towards Diversified Patch-based Arbitrary Style Transfer. (arXiv:2101.06381v2 [cs.CV] UPDATED)
149. Yet Another Representation of Binary Decision Trees: A Mathematical Demonstration. (arXiv:2101.07077v4 [cs.LG] UPDATED)
150. OPT-GAN: A Broad-Spectrum Global Optimizer for Black-box Problems by Learning Distribution. (arXiv:2102.03888v5 [cs.LG] UPDATED)
151. DeepRA: Predicting Joint Damage From Radiographs Using CNN with Attention. (arXiv:2102.06982v2 [cs.CV] UPDATED)
152. Scale Invariant Monte Carlo under Linear Function Approximation with Curvature based step-size. (arXiv:2104.07361v2 [cs.LG] UPDATED)
153. An Exact Poly-Time Membership-Queries Algorithm for Extraction a three-Layer ReLU Network. (arXiv:2105.09673v3 [cs.LG] UPDATED)
154. SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning. (arXiv:2105.15013v4 [cs.LG] UPDATED)
155. Solving Schr\"odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v9 [stat.ML] UPDATED)
156. CausalAdv: Adversarial Robustness through the Lens of Causality. (arXiv:2106.06196v2 [cs.LG] UPDATED)
157. NoiseGrad: Enhancing Explanations by Introducing Stochasticity to Model Weights. (arXiv:2106.10185v3 [cs.LG] UPDATED)
158. Heterogeneous Multi-task Learning with Expert Diversity. (arXiv:2106.10595v3 [cs.LG] UPDATED)
159. Policy Smoothing for Provably Robust Reinforcement Learning. (arXiv:2106.11420v3 [cs.LG] UPDATED)
160. Transfer Learning in Information Criteria-based Feature Selection. (arXiv:2107.02847v2 [stat.ML] UPDATED)
161. Epistemic Neural Networks. (arXiv:2107.08924v4 [cs.LG] UPDATED)
162. A universally consistent learning rule with a universally monotone error. (arXiv:2108.09733v2 [cs.LG] UPDATED)
163. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v8 [cs.CV] UPDATED)
164. Analyzing and Mitigating Interference in Neural Architecture Search. (arXiv:2108.12821v2 [cs.CL] UPDATED)
165. Towards Efficient Synchronous Federated Training: A Survey on System Optimization Strategies. (arXiv:2109.03999v3 [cs.DC] UPDATED)
166. Online Unsupervised Learning of Visual Representations and Categories. (arXiv:2109.05675v4 [cs.CV] UPDATED)
167. Fast Variational AutoEncoder with Inverted Multi-Index for Collaborative Filtering. (arXiv:2109.05773v2 [cs.LG] UPDATED)
168. DAFNe: A One-Stage Anchor-Free Approach for Oriented Object Detection. (arXiv:2109.06148v4 [cs.CV] UPDATED)
169. A Physics inspired Functional Operator for Model Uncertainty Quantification in the RKHS. (arXiv:2109.10888v6 [cs.LG] UPDATED)
170. On the Surrogate Gap between Contrastive and Supervised Losses. (arXiv:2110.02501v2 [cs.LG] UPDATED)
171. Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. (arXiv:2110.03141v2 [cs.AI] UPDATED)
172. On the Double Descent of Random Features Models Trained with SGD. (arXiv:2110.06910v5 [stat.ML] UPDATED)
173. Pre-training Molecular Graph Representation with 3D Geometry. (arXiv:2110.07728v2 [cs.LG] UPDATED)
174. Learning the Koopman Eigendecomposition: A Diffeomorphic Approach. (arXiv:2110.07786v2 [cs.LG] UPDATED)
175. Variational quantum algorithm for Gaussian discrete solitons and their boson sampling. (arXiv:2110.12379v2 [quant-ph] UPDATED)
176. Hinge Policy Optimization: Reinterpreting PPO-Clip and Attaining Global Optimality. (arXiv:2110.13799v3 [cs.LG] UPDATED)
177. Multivariate soft rank via entropic optimal transport: sample efficiency and generative modeling. (arXiv:2111.00043v2 [stat.ML] UPDATED)
178. Dynamic Data Augmentation with Gating Networks for Time Series Recognition. (arXiv:2111.03253v3 [cs.LG] UPDATED)
179. Fast First-Order Methods for Monotone Strongly DR-Submodular Maximization. (arXiv:2111.07990v2 [cs.LG] UPDATED)
180. A label efficient two-sample test. (arXiv:2111.08861v4 [cs.LG] UPDATED)
181. ML-based Handover Prediction and AP Selection in Cognitive Wi-Fi Networks. (arXiv:2111.13879v2 [cs.NI] UPDATED)
182. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v3 [cs.LG] UPDATED)
183. Diffeomorphically Learning Stable Koopman Operators. (arXiv:2112.04085v2 [cs.LG] UPDATED)
184. N-Cloth: Predicting 3D Cloth Deformation with Mesh-Based Networks. (arXiv:2112.06397v3 [cs.GR] UPDATED)
185. Bayesian Graph Contrastive Learning. (arXiv:2112.07823v3 [cs.LG] UPDATED)
186. Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. (arXiv:2112.08866v4 [stat.ME] UPDATED)
187. Adversarial Gradient Driven Exploration for Deep Click-Through Rate Prediction. (arXiv:2112.11136v2 [cs.IR] UPDATED)
188. GlobalWalk: Learning Global-aware Node Embeddings via Biased Sampling. (arXiv:2201.09882v2 [cs.LG] UPDATED)
189. Zero-Shot Sketch Based Image Retrieval using Graph Transformer. (arXiv:2201.10185v2 [cs.CV] UPDATED)
190. Dynamic Thresholding for Online Distributed Data Selection. (arXiv:2201.10547v2 [cs.LG] UPDATED)
191. Dual-Tasks Siamese Transformer Framework for Building Damage Assessment. (arXiv:2201.10953v2 [cs.CV] UPDATED)
192. OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v5 [q-bio.BM] UPDATED)
193. The Implicit Bias of Benign Overfitting. (arXiv:2201.11489v4 [cs.LG] UPDATED)
194. Domain-Invariant Representation Learning from EEG with Private Encoders. (arXiv:2201.11613v2 [cs.LG] UPDATED)
195. FedGCN: Convergence and Communication Tradeoffs in Federated Training of Graph Convolutional Networks. (arXiv:2201.12433v4 [cs.LG] UPDATED)
196. Certifying Model Accuracy under Distribution Shifts. (arXiv:2201.12440v2 [cs.LG] UPDATED)
197. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v3 [cs.CV] UPDATED)
198. N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. (arXiv:2201.12886v4 [cs.LG] UPDATED)
199. Riemannian Score-Based Generative Modeling. (arXiv:2202.02763v2 [cs.LG] UPDATED)
200. Conditional Gradients for the Approximately Vanishing Ideal. (arXiv:2202.03349v9 [cs.LG] UPDATED)
201. Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion. (arXiv:2202.04770v3 [cs.LG] UPDATED)
202. Robust Graph Representation Learning for Local Corruption Recovery. (arXiv:2202.04936v3 [cs.LG] UPDATED)
203. Deadwooding: Robust Global Pruning for Deep Neural Networks. (arXiv:2202.05226v3 [cs.LG] UPDATED)
204. Supported Policy Optimization for Offline Reinforcement Learning. (arXiv:2202.06239v2 [cs.LG] UPDATED)
205. Realistic Counterfactual Explanations with Learned Relations. (arXiv:2202.07356v3 [stat.ML] UPDATED)
206. Lie Point Symmetry Data Augmentation for Neural PDE Solvers. (arXiv:2202.07643v2 [cs.LG] UPDATED)
207. Structural and Semantic Contrastive Learning for Unsupervised Node Representation Learning. (arXiv:2202.08480v2 [cs.LG] UPDATED)
208. On the Implicit Bias Towards Minimal Depth of Deep Neural Networks. (arXiv:2202.09028v7 [cs.LG] UPDATED)
209. OSegNet: Operational Segmentation Network for COVID-19 Detection using Chest X-ray Images. (arXiv:2202.10185v2 [eess.IV] UPDATED)
210. Transporters with Visual Foresight for Solving Unseen Rearrangement Tasks. (arXiv:2202.10765v2 [cs.RO] UPDATED)
211. Efficient and Differentiable Conformal Prediction with General Function Classes. (arXiv:2202.11091v2 [cs.LG] UPDATED)
212. Towards Learning Causal Representations from Multi-Instance Bags. (arXiv:2202.12570v2 [cs.LG] UPDATED)
213. Biological error correction codes generate fault-tolerant neural networks. (arXiv:2202.12887v2 [cs.LG] UPDATED)
214. Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v4 [cs.LG] UPDATED)
215. Thermodynamics-informed graph neural networks. (arXiv:2203.01874v3 [cs.LG] UPDATED)
216. Distributed Methods with Absolute Compression and Error Compensation. (arXiv:2203.02383v2 [math.OC] UPDATED)
217. The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods. (arXiv:2203.02486v2 [cs.CV] UPDATED)
218. HEAR: Holistic Evaluation of Audio Representations. (arXiv:2203.03022v3 [cs.SD] UPDATED)
219. Influencing Long-Term Behavior in Multiagent Reinforcement Learning. (arXiv:2203.03535v3 [cs.LG] UPDATED)
220. Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits. (arXiv:2203.04192v2 [cs.LG] UPDATED)
221. Do We Really Need a Learnable Classifier at the End of Deep Neural Network?. (arXiv:2203.09081v2 [cs.LG] UPDATED)
222. Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v4 [cs.CV] UPDATED)
223. A Local Convergence Theory for the Stochastic Gradient Descent Method in Non-Convex Optimization With Non-isolated Local Minima. (arXiv:2203.10973v3 [cs.LG] UPDATED)
224. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v2 [cs.LG] UPDATED)
225. Wasserstein Distributionally Robust Optimization with Wasserstein Barycenters. (arXiv:2203.12136v2 [stat.ML] UPDATED)
226. Constrained Parameter Inference as a Principle for Learning. (arXiv:2203.13203v4 [cs.NE] UPDATED)
227. Gransformer: Transformer-based Graph Generation. (arXiv:2203.13655v2 [cs.LG] UPDATED)
228. Weakly supervised causal representation learning. (arXiv:2203.16437v2 [stat.ML] UPDATED)
229. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v3 [cs.LG] UPDATED)
230. PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations. (arXiv:2204.02877v2 [cs.LG] UPDATED)
231. Pin the Memory: Learning to Generalize Semantic Segmentation. (arXiv:2204.03609v2 [cs.CV] UPDATED)
232. Global ECG Classification by Self-Operational Neural Networks with Feature Injection. (arXiv:2204.03768v2 [cs.LG] UPDATED)
233. DiversiTree: A New Method to Efficiently Compute Diverse Sets of Near-Optimal Solutions to Mixed-Integer Optimization Problems. (arXiv:2204.03822v2 [cs.DM] UPDATED)
234. Generating 3D Molecules for Target Protein Binding. (arXiv:2204.09410v2 [q-bio.BM] UPDATED)
235. Counterfactual harm. (arXiv:2204.12993v3 [cs.AI] UPDATED)
236. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v3 [cs.CV] UPDATED)
237. Fast Sampling of Diffusion Models with Exponential Integrator. (arXiv:2204.13902v2 [cs.LG] UPDATED)
238. VICE: Variational Interpretable Concept Embeddings. (arXiv:2205.00756v7 [cs.LG] UPDATED)
239. Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion Networks. (arXiv:2205.01355v3 [cs.GR] UPDATED)
240. Automated Imbalanced Classification via Layered Learning. (arXiv:2205.02553v2 [cs.LG] UPDATED)
241. Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction. (arXiv:2205.02708v3 [cs.LG] UPDATED)
242. Defending against Reconstruction Attacks through Differentially Private Federated Learning for Classification of Heterogeneous Chest X-Ray Data. (arXiv:2205.03168v2 [cs.LG] UPDATED)
243. Data Distributional Properties Drive Emergent In-Context Learning in Transformers. (arXiv:2205.05055v4 [cs.AI] UPDATED)
244. Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v3 [cs.LG] UPDATED)
245. Rethinking Reinforcement Learning based Logic Synthesis. (arXiv:2205.07614v2 [cs.LG] UPDATED)
246. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v3 [cs.LG] UPDATED)
247. Fast Neural Network based Solving of Partial Differential Equations. (arXiv:2205.08978v2 [cs.LG] UPDATED)
248. Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis. (arXiv:2205.09702v4 [cs.LG] UPDATED)
249. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v3 [cs.CV] UPDATED)
250. Time Series Anomaly Detection via Reinforcement Learning-Based Model Selection. (arXiv:2205.09884v3 [cs.LG] UPDATED)
251. Nuclear Norm Maximization Based Curiosity-Driven Learning. (arXiv:2205.10484v2 [cs.LG] UPDATED)
252. Fine-Grained Counting with Crowd-Sourced Supervision. (arXiv:2205.11398v2 [cs.CV] UPDATED)
253. Towards a Defense against Backdoor Attacks in Continual Federated Learning. (arXiv:2205.11736v3 [cs.LG] UPDATED)
254. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v2 [cs.CV] UPDATED)
255. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v2 [math.OC] UPDATED)
256. FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation. (arXiv:2205.12465v2 [cs.LG] UPDATED)
257. Designing an Efficient End-to-end Machine Learning Pipeline for **Real-time** Empty-shelf Detection. (arXiv:2205.13060v2 [cs.LG] UPDATED)
258. More Recent Advances in (Hyper)Graph Partitioning. (arXiv:2205.13202v2 [cs.DS] UPDATED)
259. QUIC-FL: Quick Unbiased Compression for Federated Learning. (arXiv:2205.13341v2 [cs.LG] UPDATED)
260. Fairness in Recommendation: A Survey. (arXiv:2205.13619v2 [cs.IR] UPDATED)
261. FedFormer: Contextual Federation with Attention in Reinforcement Learning. (arXiv:2205.13697v2 [cs.LG] UPDATED)
262. TraClets: Harnessing the power of computer vision for trajectory classification. (arXiv:2205.13880v2 [cs.CV] UPDATED)
263. Sample-Efficient Optimisation with Probabilistic Transformer Surrogates. (arXiv:2205.13902v2 [cs.LG] UPDATED)
264. Federated Semi-Supervised Learning with Prototypical Networks. (arXiv:2205.13921v2 [cs.LG] UPDATED)
265. Sharpness-Aware Training for Free. (arXiv:2205.14083v2 [cs.LG] UPDATED)
266. Re-calibrating Photometric Redshift Probability Distributions Using Feature-space Regression. (arXiv:2110.15209v2 [astro-ph.IM] CROSS LISTED)
## cs.AI
---
**113** new papers in cs.AI:-) 
1. FadMan: Federated Anomaly Detection across Multiple Attributed Networks. (arXiv:2205.14196v1 [cs.LG])
2. KL-Entropy-Regularized RL with a Generative Model is Minimax Optimal. (arXiv:2205.14211v1 [cs.LG])
3. Diffusion-LM Improves Controllable Text Generation. (arXiv:2205.14217v1 [cs.CL])
4. Learning to Find Proofs and Theorems by Learning to Refine Search Strategies. (arXiv:2205.14229v1 [cs.AI])
5. Provably Sample-Efficient RL with Side Information about Latent Dynamics. (arXiv:2205.14237v1 [cs.LG])
6. Experience report of physics-informed neural networks in fluid simulations: pitfalls and frustration. (arXiv:2205.14249v1 [physics.flu-dyn])
7. On the Symmetries of Deep Learning Models and their Internal Representations. (arXiv:2205.14258v1 [cs.LG])
8. Uncertainty quantification of two-phase flow in porous media via coupled-TgNN surrogate model. (arXiv:2205.14301v1 [physics.flu-dyn])
9. Deep Embedded Clustering with Distribution Consistency Preservation for Attributed Networks. (arXiv:2205.14303v1 [cs.LG])
10. Federated Neural Bandit. (arXiv:2205.14309v1 [cs.LG])
11. Robust Molecular Image Recognition: A Graph Generation Approach. (arXiv:2205.14311v1 [cs.CV])
12. Efficient Policy Iteration for Robust Markov Decision Processes via Regularization. (arXiv:2205.14327v1 [cs.AI])
13. Survival Analysis on Structured Data using Deep Reinforcement Learning. (arXiv:2205.14331v1 [cs.LG])
14. Teaching Models to Express Their Uncertainty in Words. (arXiv:2205.14334v1 [cs.CL])
15. Fair Labeled Clustering. (arXiv:2205.14358v1 [cs.LG])
16. Granular Generalized Variable Precision Rough Sets and Rational Approximations. (arXiv:2205.14365v1 [cs.AI])
17. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v1 [cs.CV])
18. Point-M2AE: Multi-scale Masked Autoencoders for Hierarchical Point Cloud Pre-training. (arXiv:2205.14401v1 [cs.CV])
19. Multi-Source Transfer Learning for Deep Model-Based Reinforcement Learning. (arXiv:2205.14410v1 [cs.LG])
20. Fault-Aware Design and Training to Enhance DNNs Reliability with Zero-Overhead. (arXiv:2205.14420v1 [cs.LG])
21. Large-Scale Privacy-Preserving Network Embedding against Private Link Inference Attacks. (arXiv:2205.14440v1 [cs.LG])
22. An adaptive admittance controller for collaborative drilling with a robot based on subtask classification via deep learning. (arXiv:2205.14457v1 [cs.RO])
23. MDMLP: Image Classification from Scratch on Small Datasets with MLP. (arXiv:2205.14477v1 [cs.CV])
24. BadDet: Backdoor Attacks on Object Detection. (arXiv:2205.14497v1 [cs.CV])
25. Group-wise Reinforcement Feature Generation for Optimal and Explainable Representation Space Reconstruction. (arXiv:2205.14526v1 [cs.LG])
26. The Missing Invariance Principle Found -- the Reciprocal Twin of Invariant Risk Minimization. (arXiv:2205.14546v1 [cs.LG])
27. Representation Gap in Deep Reinforcement Learning. (arXiv:2205.14557v1 [cs.LG])
28. ProxyMix: Proxy-based Mixup Training with Label Refinery for Source-Free Domain Adaptation. (arXiv:2205.14566v1 [cs.CV])
29. Provable Benefits of Representational Transfer in Reinforcement Learning. (arXiv:2205.14571v1 [cs.LG])
30. ComplexGen: CAD Reconstruction by B-Rep Chain Complex Generation. (arXiv:2205.14573v1 [cs.CV])
31. Feature-Aligned Video Raindrop Removal with Temporal Constraints. (arXiv:2205.14574v1 [cs.CV])
32. 3D-C2FT: Coarse-to-fine Transformer for Multi-view 3D Reconstruction. (arXiv:2205.14575v1 [cs.CV])
33. Independent and Decentralized Learning in Markov Potential Games. (arXiv:2205.14590v1 [cs.LG])
34. Joint Abductive and Inductive Neural Logical Reasoning. (arXiv:2205.14591v1 [cs.AI])
35. An adaptive granularity clustering method based on hyper-ball. (arXiv:2205.14592v1 [cs.LG])
36. SKFlow: Learning Optical Flow with Super Kernels. (arXiv:2205.14623v1 [cs.CV])
37. Perceiving the Invisible: Proposal-Free Amodal Panoptic Segmentation. (arXiv:2205.14637v1 [cs.CV])
38. Micro-Expression Recognition Based on Attribute Information Embedding and Cross-modal Contrastive Learning. (arXiv:2205.14643v1 [cs.CV])
39. Glance to Count: Learning to Rank with Anchors for Weakly-supervised Crowd Counting. (arXiv:2205.14659v1 [cs.CV])
40. Heterogeneous Data-Centric Architectures for Modern Data-Intensive Applications: Case Studies in Machine Learning and Databases. (arXiv:2205.14664v1 [cs.AR])
41. Saliency Map Based Data Augmentation. (arXiv:2205.14686v1 [cs.CV])
42. On the Robustness of Safe Reinforcement Learning under Observational Perturbations. (arXiv:2205.14691v1 [cs.LG])
43. Learning Security Strategies through Game Play and Optimal Stopping. (arXiv:2205.14694v1 [cs.LG])
44. Evaluating Automated Driving Planner Robustness against Adversarial Influence. (arXiv:2205.14697v1 [cs.CR])
45. CPED: A Large-Scale Chinese Personalized and Emotional Dialogue Dataset for Conversational AI. (arXiv:2205.14727v1 [cs.CL])
46. A Framework for Generating Informative Benchmark Instances. (arXiv:2205.14753v1 [cs.AI])
47. Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles. (arXiv:1703.01347v2 [cs.AI] UPDATED)
48. DeepTransport: Learning Spatial-Temporal Dependency for Traffic Condition Forecasting. (arXiv:1709.09585v3 [cs.AI] UPDATED)
49. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v6 [cs.LG] UPDATED)
50. A Bayesian approach to tissue-fraction estimation for oncological PET segmentation. (arXiv:2003.00317v3 [physics.med-ph] UPDATED)
51. Double Self-weighted Multi-view Clustering via Adaptive View Fusion. (arXiv:2011.10396v2 [cs.LG] UPDATED)
52. Towards an AI assistant for power grid operators. (arXiv:2012.02026v2 [stat.ML] UPDATED)
53. Hindsight and Sequential Rationality of Correlated Play: Corrections. (arXiv:2012.05874v4 [cs.GT] UPDATED)
54. DeepRA: Predicting Joint Damage From Radiographs Using CNN with Attention. (arXiv:2102.06982v2 [cs.CV] UPDATED)
55. Conditional Image Generation by Conditioning Variational Auto-Encoders. (arXiv:2102.12037v3 [cs.CV] UPDATED)
56. Explaining Answers with Entailment Trees. (arXiv:2104.08661v3 [cs.CL] UPDATED)
57. DisCo: Remedy Self-supervised Learning on Lightweight Models with Distilled Contrastive Learning. (arXiv:2104.09124v6 [cs.CV] UPDATED)
58. SHAQ: Incorporating Shapley Value Theory into Multi-Agent Q-Learning. (arXiv:2105.15013v4 [cs.LG] UPDATED)
59. SeaNet -- Towards A Knowledge Graph Based Autonomic Management of Software Defined Networks. (arXiv:2106.13367v3 [cs.AI] UPDATED)
60. Epistemic Neural Networks. (arXiv:2107.08924v4 [cs.LG] UPDATED)
61. Discovering User-Interpretable Capabilities of Black-Box Planning Agents. (arXiv:2107.13668v3 [cs.AI] UPDATED)
62. Do What You Know: Coupling Knowledge with Action in Discrete-Event Systems. (arXiv:2108.02000v3 [cs.AI] UPDATED)
63. Put the Bear on the Chair! Intelligent Robot Interaction with Previously Unseen Chairs via Robot Imagination. (arXiv:2108.05539v2 [cs.RO] UPDATED)
64. DAFNe: A One-Stage Anchor-Free Approach for Oriented Object Detection. (arXiv:2109.06148v4 [cs.CV] UPDATED)
65. Paradigm Shift in Natural Language Processing. (arXiv:2109.12575v2 [cs.CL] UPDATED)
66. A Survey of Knowledge Enhanced Pre-trained Models. (arXiv:2110.00269v3 [cs.CL] UPDATED)
67. Efficient Sharpness-aware Minimization for Improved Training of Neural Networks. (arXiv:2110.03141v2 [cs.AI] UPDATED)
68. Hallucinated Neural Radiance Fields in the Wild. (arXiv:2111.15246v3 [cs.CV] UPDATED)
69. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v3 [cs.LG] UPDATED)
70. Unsupervised Dense Information Retrieval with Contrastive Learning. (arXiv:2112.09118v3 [cs.IR] UPDATED)
71. Privacy-Friendly Peer-to-Peer Energy Trading: A Game Theoretical Approach. (arXiv:2201.01810v2 [cs.GT] UPDATED)
72. Detecting danger in gridworlds using Gromov's Link Condition. (arXiv:2201.06274v2 [cs.AI] UPDATED)
73. Dangerous Cloaking: Natural Trigger based Backdoor Attacks on Object Detectors in the Physical World. (arXiv:2201.08619v2 [cs.CV] UPDATED)
74. GlobalWalk: Learning Global-aware Node Embeddings via Biased Sampling. (arXiv:2201.09882v2 [cs.LG] UPDATED)
75. Dynamic Thresholding for Online Distributed Data Selection. (arXiv:2201.10547v2 [cs.LG] UPDATED)
76. Behavior Tree-Based Task Planning for Multiple Mobile Robots using a Data Distribution Service. (arXiv:2201.10918v2 [cs.RO] UPDATED)
77. The KFIoU Loss for Rotated Object Detection. (arXiv:2201.12558v3 [cs.CV] UPDATED)
78. N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. (arXiv:2201.12886v4 [cs.LG] UPDATED)
79. Unsupervised Time-Series Representation Learning with Iterative Bilinear Temporal-Spectral Fusion. (arXiv:2202.04770v3 [cs.LG] UPDATED)
80. Supported Policy Optimization for Offline Reinforcement Learning. (arXiv:2202.06239v2 [cs.LG] UPDATED)
81. Enhanced Multi-Objective A* Using Balanced Binary Search Trees. (arXiv:2202.08992v3 [cs.AI] UPDATED)
82. Transporters with Visual Foresight for Solving Unseen Rearrangement Tasks. (arXiv:2202.10765v2 [cs.RO] UPDATED)
83. Efficient and Differentiable Conformal Prediction with General Function Classes. (arXiv:2202.11091v2 [cs.LG] UPDATED)
84. HEAR: Holistic Evaluation of Audio Representations. (arXiv:2203.03022v3 [cs.SD] UPDATED)
85. Influencing Long-Term Behavior in Multiagent Reinforcement Learning. (arXiv:2203.03535v3 [cs.LG] UPDATED)
86. WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition. (arXiv:2203.06925v2 [cs.CL] UPDATED)
87. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v2 [cs.LG] UPDATED)
88. Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction. (arXiv:2203.12997v3 [cs.CV] UPDATED)
89. MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection. (arXiv:2203.13310v3 [cs.CV] UPDATED)
90. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v3 [cs.LG] UPDATED)
91. PAnDR: Fast Adaptation to New Environments from Offline Experiences via Decoupling Policy and Environment Representations. (arXiv:2204.02877v2 [cs.LG] UPDATED)
92. DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation and Optimization tools for Modern AI/Non-AI Workloads. (arXiv:2204.06676v5 [cs.AR] UPDATED)
93. HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric Regularization. (arXiv:2204.08176v2 [cs.IR] UPDATED)
94. Generating 3D Molecules for Target Protein Binding. (arXiv:2204.09410v2 [q-bio.BM] UPDATED)
95. Counterfactual harm. (arXiv:2204.12993v3 [cs.AI] UPDATED)
96. PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining. (arXiv:2204.14095v2 [cs.CV] UPDATED)
97. Detecting and Understanding Harmful Memes: A Survey. (arXiv:2205.04274v2 [cs.CL] UPDATED)
98. Controlling Extra-Textual Attributes about Dialogue Participants -- A Case Study of English-to-Polish Neural Machine Translation. (arXiv:2205.04747v2 [cs.CL] UPDATED)
99. Data Distributional Properties Drive Emergent In-Context Learning in Transformers. (arXiv:2205.05055v4 [cs.AI] UPDATED)
100. Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v3 [cs.LG] UPDATED)
101. Measuring Plagiarism in Introductory Programming Course Assignments. (arXiv:2205.08520v2 [cs.CL] UPDATED)
102. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v3 [cs.LG] UPDATED)
103. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v3 [cs.CV] UPDATED)
104. Nuclear Norm Maximization Based Curiosity-Driven Learning. (arXiv:2205.10484v2 [cs.LG] UPDATED)
105. Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners. (arXiv:2205.10747v3 [cs.CV] UPDATED)
106. From Width-Based Model Checking to Width-Based Automated Theorem Proving. (arXiv:2205.10995v2 [cs.DS] UPDATED)
107. Towards a Defense against Backdoor Attacks in Continual Federated Learning. (arXiv:2205.11736v3 [cs.LG] UPDATED)
108. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v2 [math.OC] UPDATED)
109. QUIC-FL: Quick Unbiased Compression for Federated Learning. (arXiv:2205.13341v2 [cs.LG] UPDATED)
110. Fairness in Recommendation: A Survey. (arXiv:2205.13619v2 [cs.IR] UPDATED)
111. FedFormer: Contextual Federation with Attention in Reinforcement Learning. (arXiv:2205.13697v2 [cs.LG] UPDATED)
112. Federated Semi-Supervised Learning with Prototypical Networks. (arXiv:2205.13921v2 [cs.LG] UPDATED)
113. Sharpness-Aware Training for Free. (arXiv:2205.14083v2 [cs.LG] UPDATED)

