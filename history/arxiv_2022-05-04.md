# Your interest papers
---
## cs.CV
---
### RU-Net: Regularized Unrolling Network for Scene Graph Generation. (arXiv:2205.01297v1 [cs.CV])
- Authors : Xin Lin, Changxing Ding, Jing Zhang, Yibing Zhan, Dacheng Tao
- Link : [http://arxiv.org/abs/2205.01297](http://arxiv.org/abs/2205.01297)
> ABSTRACT  :  Scene graph generation (SGG) aims to detect objects and predict the relationships between each pair of objects. Existing SGG methods usually suffer from several issues, including 1) ambiguous object representations, as graph neural network-based message passing (GMP) modules are typically sensitive to spurious inter-node correlations, and 2) low diversity in relationship predictions due to severe class imbalance and a large number of missing annotations. To address both problems, in this paper, we propose a regularized unrolling network (RU-Net). We first study the relation between GMP and graph Laplacian denoising (GLD) from the perspective of the unrolling technique, determining that GMP can be formulated as a solver for GLD. Based on this observation, we propose an unrolled message passing module and introduce an $\ell_p$-based graph regularization to suppress spurious connections between nodes. Second, we propose a group diversity **enhancement** module that promotes the prediction diversity of relationships via rank maximization. Systematic experiments demonstrate that RU-Net is effective under a variety of settings and metrics. Furthermore, RU-Net achieves new state-of-the-arts on three popular databases: VG, VRD, and OI. Code is available at https://github.com/siml3/RU-Net.  
### Sampling-free obstacle gradients and reactive planning in Neural Radiance Fields (**NeRF**). (arXiv:2205.01389v1 [cs.RO])
- Authors : Michael Pantic, Cesar Cadena, Roland Siegwart, Lionel Ott
- Link : [http://arxiv.org/abs/2205.01389](http://arxiv.org/abs/2205.01389)
> ABSTRACT  :  This work investigates the use of Neural implicit representations, specifically Neural Radiance Fields (**NeRF**), for geometrical queries and motion planning. We show that by adding the capacity to infer occupancy in a radius to a pre-trained **NeRF**, we are effectively learning an approximation to a Euclidean Signed Distance Field (ESDF). Using backward differentiation of the augmented network, we obtain an obstacle gradient that is integrated into an obstacle avoidance policy based on the Riemannian Motion Policies (RMP) framework. Thus, our findings allow for very fast sampling-free obstacle avoidance planning in the implicit representation.  
### 3D Semantic Scene Perception using Distributed Smart Edge Sensors. (arXiv:2205.01460v1 [cs.CV])
- Authors : Simon Bultmann, Sven Behnke
- Link : [http://arxiv.org/abs/2205.01460](http://arxiv.org/abs/2205.01460)
> ABSTRACT  :  We present a system for 3D semantic scene perception consisting of a network of distributed smart edge sensors. The sensor nodes are based on an embedded CNN inference accelerator and RGB-D and thermal cameras. Efficient vision CNN models for object detection, semantic segmentation, and human pose estimation run on-device in **real time**. 2D human keypoint estimations, augmented with the RGB-D depth estimate, as well as semantically annotated point clouds are streamed from the sensors to a central backend, where multiple viewpoints are fused into an allocentric 3D semantic scene model. As the image interpretation is computed locally, only semantic information is sent over the network. The raw images remain on the sensor boards, significantly reducing the required bandwidth, and mitigating privacy risks for the observed persons. We evaluate the proposed system in challenging real-world multi-person scenes in our lab. The proposed perception system provides a complete scene view containing semantically annotated 3D geometry and estimates 3D poses of multiple persons in **real time**.  
### RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds. (arXiv:2205.01570v1 [cs.CV])
- Authors : Hsuan Chen, Tian Sheuan
- Link : [http://arxiv.org/abs/2205.01570](http://arxiv.org/abs/2205.01570)
> ABSTRACT  :  Semantic outdoor scene understanding based on 3D LiDAR point clouds is a challenging task for autonomous driving due to the sparse and irregular data structure. This paper takes advantages of the uneven range distribution of different LiDAR laser beams to propose a range aware instance segmentation network, RangeSeg. RangeSeg uses a shared encoder backbone with two range dependent decoders. A heavy decoder only computes top of a range image where the far and small objects locate to improve small object detection accuracy, and a light decoder computes whole range image for low computational cost. The results are further clustered by the DBSCAN method with a resolution weighted distance function to get instance-level segmentation results. Experiments on the KITTI dataset show that RangeSeg outperforms the state-of-the-art semantic segmentation methods with enormous speedup and improves the instance-level segmentation performance on small and far objects. The whole RangeSeg pipeline meets the **real time** requirement on NVIDIA\textsuperscript{\textregistered} JETSON AGX Xavier with 19 frames per second in average.  
### A Bidirectional Conversion Network for Cross-Spectral Face Recognition. (arXiv:2205.01595v1 [cs.CV])
- Authors : Zhicheng Cao, Jiaxuan Zhang, Liaojun Pang
- Link : [http://arxiv.org/abs/2205.01595](http://arxiv.org/abs/2205.01595)
> ABSTRACT  :  Face recognition in the infrared (IR) band has become an important supplement to visible light face recognition due to its advantages of independent background light, strong penetration, ability of imaging under harsh environments such as **night**time, rain and fog. However, cross-spectral face recognition (i.e., VIS to IR) is very challenging due to the dramatic difference between the visible light and IR imageries as well as the lack of paired training data. This paper proposes a framework of bidirectional cross-spectral conversion (BCSC-GAN) between the heterogeneous face images, and designs an adaptive weighted fusion mechanism based on information fusion theory. The network reduces the cross-spectral recognition problem into an intra-spectral problem, and improves performance by fusing bidirectional information. Specifically, a face identity retaining module (IRM) is introduced with the ability to preserve identity features, and a new composite loss function is designed to overcome the modal differences caused by different spectral characteristics. Two datasets of TINDERS and CASIA were tested, where performance metrics of FID, recognition rate, equal error rate and normalized distance were compared. Results show that our proposed network is superior than other state-of-the-art methods. Additionally, the proposed rule of Self Adaptive Weighted Fusion (SAWF) is better than the recognition results of the unfused case and other traditional fusion rules that are commonly used, which further justifies the effectiveness and superiority of the proposed bidirectional conversion approach.  
### Learning Enriched Features for Fast Image **Restoration** and **Enhancement**. (arXiv:2205.01649v1 [eess.IV])
- Authors : Syed Waqas, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz, Hsuan Yang, Ling Shao
- Link : [http://arxiv.org/abs/2205.01649](http://arxiv.org/abs/2205.01649)
> ABSTRACT  :  Given a degraded input image, image **restoration** aims to recover the missing high-quality image content. Numerous applications demand effective image **restoration**, e.g., computational photography, surveillance, autonomous vehicles, and remote sensing. Significant advances in image **restoration** have been made in recent years, dominated by convolutional neural networks (CNNs). The widely-used CNN-based methods typically operate either on full-resolution or on progressively low-resolution representations. In the former case, spatial details are preserved but the contextual information cannot be precisely encoded. In the latter case, generated outputs are semantically reliable but spatially less accurate. This paper presents a new architecture with a holistic goal of maintaining spatially-precise high-resolution representations through the entire network, and receiving complementary contextual information from the low-resolution representations. The core of our approach is a multi-scale residual block containing the following key elements: (a) parallel multi-resolution convolution streams for extracting multi-scale features, (b) information exchange across the multi-resolution streams, (c) non-local attention mechanism for capturing contextual information, and (d) attention based multi-scale feature aggregation. Our approach learns an enriched set of features that combines contextual information from multiple scales, while simultaneously preserving the high-resolution spatial details. Extensive experiments on six real image benchmark datasets demonstrate that our method, named as MIRNet-v2 , achieves state-of-the-art results for a variety of image processing tasks, including defocus deblurring, image denoising, super-resolution, and image **enhancement**. The source code and pre-trained models are available at https://github.com/swz30/MIRNetv2  
### ADOP: Approximate Differentiable One-Pixel Point Rendering. (arXiv:2110.06635v3 [cs.CV] UPDATED)
- Authors : Linus Franke, Marc Stamminger
- Link : [http://arxiv.org/abs/2110.06635](http://arxiv.org/abs/2110.06635)
> ABSTRACT  :  In this paper we present ADOP, a novel point-based, differentiable neural rendering pipeline. Like other neural renderers, our system takes as input calibrated camera images and a proxy geometry of the scene, in our case a point cloud. To generate a novel view, the point cloud is rasterized with learned feature vectors as colors and a deep neural network fills the remaining holes and shades each output pixel. The rasterizer renders points as one-pixel splats, which makes it very fast and allows us to compute gradients with respect to all relevant input parameters efficiently. Furthermore, our pipeline contains a fully differentiable physically-based photometric camera model, including **exposure**, white balance, and a camera response function. Following the idea of inverse rendering, we use our renderer to refine its input in order to reduce inconsistencies and optimize the quality of its output. In particular, we can optimize structural parameters like the camera pose, lens distortions, point positions and features, and a neural environment map, but also photometric parameters like camera response function, vignetting, and per-image **exposure** and white balance. Because our pipeline includes photometric parameters, e.g.~**exposure** and camera response function, our system can smoothly handle input images with varying **exposure** and white balance, and generates high-dynamic range output. We show that due to the improved input, we can achieve high render quality, also for difficult input, e.g. with imperfect camera calibrations, inaccurate proxy geometry, or varying **exposure**. As a result, a simpler and thus faster deep neural network is sufficient for reconstruction. In combination with the fast point rasterization, ADOP achieves real-time rendering rates even for models with well over 100M points. https://github.com/darglein/ADOP  
### Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
- Authors : Ankush Deshmukh
- Link : [http://arxiv.org/abs/2203.00439](http://arxiv.org/abs/2203.00439)
> ABSTRACT  :  Machine learning (ML) and Deep Learning (DL) tasks primarily depend on data. Most of the ML and DL applications involve supervised learning which requires labelled data. In the initial phases of ML realm lack of data used to be a problem, now we are in a new era of big data. The supervised ML algorithms require data to be labelled and of good quality. Labelling task requires a large amount of money and time investment. Data labelling require a skilled person who will charge high for this task, consider the case of the medical field or the data is in bulk that requires a lot of people assigned to label it. The amount of data that is well enough for training needs to be known, money and time can not be wasted to label the whole data. This paper mainly aims to propose a strategy that helps in labelling the data along with oracle in real-time. With balancing on model contribution for labelling is 89 and 81.1 for furniture type and intel scene image data sets respectively. Further with balancing being kept off model contribution is found to be 83.47 and 78.71 for furniture type and flower data sets respectively.  
### ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object Manipulation. (arXiv:2203.06856v2 [cs.CV] UPDATED)
- Authors : Bokui Shen, Zhenyu Jiang, Christopher Choy, Silvio Savarese, Anima Anandkumar, Yuke Zhu
- Link : [http://arxiv.org/abs/2203.06856](http://arxiv.org/abs/2203.06856)
> ABSTRACT  :  Manipulating volumetric deformable objects in the real world, like plush toys and pizza dough, bring substantial challenges due to infinite shape variations, non-rigid motions, and partial observability. We introduce ACID, an action-conditional visual dynamics model for volumetric deformable objects based on structured **implicit neural representation**s. ACID integrates two new techniques: implicit representations for action-conditional dynamics and geodesics-based contrastive learning. To represent deformable dynamics from partial RGB-D observations, we learn implicit representations of occupancy and flow-based forward dynamics. To accurately identify state change under large non-rigid deformations, we learn a correspondence embedding field through a novel geodesics-based contrastive loss. To evaluate our approach, we develop a simulation framework for manipulating complex deformable shapes in realistic scenes and a benchmark containing over 17,000 action trajectories with six types of plush toys and 78 variants. Our model achieves the best performance in geometry, correspondence, and dynamics predictions over existing approaches. The ACID dynamics models are successfully employed to goal-conditioned deformable manipulation tasks, resulting in a 30% increase in task success rate over the strongest baseline. For more results and information, please visit https://b0ku1.github.io/acid/ .  
### Proto2Proto: Can you recognize the car, the way I do?. (arXiv:2204.11830v2 [cs.CV] UPDATED)
- Authors : Monish Keswani, Sriranjani Ramakrishnan, Nishant Reddy
- Link : [http://arxiv.org/abs/2204.11830](http://arxiv.org/abs/2204.11830)
> ABSTRACT  :  Prototypical methods have recently gained a lot of attention due to their intrinsic interpretable nature, which is obtained through the prototypes. With growing use cases of model reuse and distillation, there is a need to also study transfer of interpretability from one model to another. We present Proto2Proto, a novel method to transfer interpretability of one prototypical part network to another via knowledge distillation. Our approach aims to add interpretability to the "**dark**" knowledge transferred from the teacher to the shallower student model. We propose two novel losses: "Global Explanation" loss and "Patch-Prototype Correspondence" loss to facilitate such a transfer. Global Explanation loss forces the student prototypes to be close to teacher prototypes, and Patch-Prototype Correspondence loss enforces the local representations of the student to be similar to that of the teacher. Further, we propose three novel metrics to evaluate the student's proximity to the teacher as measures of interpretability transfer in our settings. We qualitatively and quantitatively demonstrate the effectiveness of our method on CUB-200-2011 and Stanford Cars datasets. Our experiments show that the proposed method indeed achieves interpretability transfer from teacher to student while simultaneously exhibiting competitive performance.  
## eess.IV
---
### Learning Enriched Features for Fast Image **Restoration** and **Enhancement**. (arXiv:2205.01649v1 [eess.IV])
- Authors : Syed Waqas, Aditya Arora, Salman Khan, Munawar Hayat, Fahad Shahbaz, Hsuan Yang, Ling Shao
- Link : [http://arxiv.org/abs/2205.01649](http://arxiv.org/abs/2205.01649)
> ABSTRACT  :  Given a degraded input image, image **restoration** aims to recover the missing high-quality image content. Numerous applications demand effective image **restoration**, e.g., computational photography, surveillance, autonomous vehicles, and remote sensing. Significant advances in image **restoration** have been made in recent years, dominated by convolutional neural networks (CNNs). The widely-used CNN-based methods typically operate either on full-resolution or on progressively low-resolution representations. In the former case, spatial details are preserved but the contextual information cannot be precisely encoded. In the latter case, generated outputs are semantically reliable but spatially less accurate. This paper presents a new architecture with a holistic goal of maintaining spatially-precise high-resolution representations through the entire network, and receiving complementary contextual information from the low-resolution representations. The core of our approach is a multi-scale residual block containing the following key elements: (a) parallel multi-resolution convolution streams for extracting multi-scale features, (b) information exchange across the multi-resolution streams, (c) non-local attention mechanism for capturing contextual information, and (d) attention based multi-scale feature aggregation. Our approach learns an enriched set of features that combines contextual information from multiple scales, while simultaneously preserving the high-resolution spatial details. Extensive experiments on six real image benchmark datasets demonstrate that our method, named as MIRNet-v2 , achieves state-of-the-art results for a variety of image processing tasks, including defocus deblurring, image denoising, super-resolution, and image **enhancement**. The source code and pre-trained models are available at https://github.com/swz30/MIRNetv2  
### Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
- Authors : Ankush Deshmukh
- Link : [http://arxiv.org/abs/2203.00439](http://arxiv.org/abs/2203.00439)
> ABSTRACT  :  Machine learning (ML) and Deep Learning (DL) tasks primarily depend on data. Most of the ML and DL applications involve supervised learning which requires labelled data. In the initial phases of ML realm lack of data used to be a problem, now we are in a new era of big data. The supervised ML algorithms require data to be labelled and of good quality. Labelling task requires a large amount of money and time investment. Data labelling require a skilled person who will charge high for this task, consider the case of the medical field or the data is in bulk that requires a lot of people assigned to label it. The amount of data that is well enough for training needs to be known, money and time can not be wasted to label the whole data. This paper mainly aims to propose a strategy that helps in labelling the data along with oracle in real-time. With balancing on model contribution for labelling is 89 and 81.1 for furniture type and intel scene image data sets respectively. Further with balancing being kept off model contribution is found to be 83.47 and 78.71 for furniture type and flower data sets respectively.  
## cs.LG
---
### Transformers in Time-series Analysis: A Tutorial. (arXiv:2205.01138v1 [cs.LG])
- Authors : Sabeen Ahmed, Aakash Tripathi, Shamoon Siddiqui, Ghulam Rasool
- Link : [http://arxiv.org/abs/2205.01138](http://arxiv.org/abs/2205.01138)
> ABSTRACT  :  Transformer architecture has widespread applications, particularly in Natural Language Processing and computer vision. Recently Transformers have been employed in various aspects of time-series analysis. This tutorial provides an overview of the Transformer architecture, its applications, and a collection of examples from recent research papers in time-series analysis. We delve into an explanation of the core components of the Transformer, including the self-attention mechanism, positional encoding, multi-head, and encoder/decoder. Several **enhancement**s to the initial, Transformer architecture are highlighted to tackle time-series tasks. The tutorial also provides best practices and techniques to overcome the challenge of effectively training Transformers for time-series analysis.  
### CANShield: Signal-based Intrusion Detection for Controller Area Networks. (arXiv:2205.01306v1 [cs.CR])
- Authors : Md Hasan, Yang Xiao, Pablo Moriano, Wenjing Lou, Thomas Hou
- Link : [http://arxiv.org/abs/2205.01306](http://arxiv.org/abs/2205.01306)
> ABSTRACT  :  Modern vehicles rely on a fleet of electronic control units (ECUs) connected through controller area network (CAN) buses for critical vehicular control. However, with the expansion of advanced connectivity features in automobiles and the elevated risks of internal system **exposure**, the CAN bus is increasingly prone to intrusions and injection attacks. The ordinary injection attacks disrupt the typical timing properties of the CAN data stream, and the rule-based intrusion detection systems (IDS) can easily detect them. However, advanced attackers can inject false data to the time series sensory data (signal), while looking innocuous by the pattern/frequency of the CAN messages. Such attacks can bypass the rule-based IDS or any anomaly-based IDS built on binary payload data. To make the vehicles robust against such intelligent attacks, we propose CANShield, a signal-based intrusion detection framework for the CAN bus. CANShield consists of three modules: a data preprocessing module that handles the high-dimensional CAN data stream at the signal level and makes them suitable for a deep learning model; a data analyzer module consisting of multiple deep autoencoder (AE) networks, each analyzing the time-series data from a different temporal perspective; and finally an attack detection module that uses an ensemble method to make the final decision. Evaluation results on two high-fidelity signal-based CAN attack datasets show the high accuracy and responsiveness of CANShield in detecting wide-range of advanced intrusion attacks.  
### RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds. (arXiv:2205.01570v1 [cs.CV])
- Authors : Hsuan Chen, Tian Sheuan
- Link : [http://arxiv.org/abs/2205.01570](http://arxiv.org/abs/2205.01570)
> ABSTRACT  :  Semantic outdoor scene understanding based on 3D LiDAR point clouds is a challenging task for autonomous driving due to the sparse and irregular data structure. This paper takes advantages of the uneven range distribution of different LiDAR laser beams to propose a range aware instance segmentation network, RangeSeg. RangeSeg uses a shared encoder backbone with two range dependent decoders. A heavy decoder only computes top of a range image where the far and small objects locate to improve small object detection accuracy, and a light decoder computes whole range image for low computational cost. The results are further clustered by the DBSCAN method with a resolution weighted distance function to get instance-level segmentation results. Experiments on the KITTI dataset show that RangeSeg outperforms the state-of-the-art semantic segmentation methods with enormous speedup and improves the instance-level segmentation performance on small and far objects. The whole RangeSeg pipeline meets the **real time** requirement on NVIDIA\textsuperscript{\textregistered} JETSON AGX Xavier with 19 frames per second in average.  
### Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
- Authors : Ankush Deshmukh
- Link : [http://arxiv.org/abs/2203.00439](http://arxiv.org/abs/2203.00439)
> ABSTRACT  :  Machine learning (ML) and Deep Learning (DL) tasks primarily depend on data. Most of the ML and DL applications involve supervised learning which requires labelled data. In the initial phases of ML realm lack of data used to be a problem, now we are in a new era of big data. The supervised ML algorithms require data to be labelled and of good quality. Labelling task requires a large amount of money and time investment. Data labelling require a skilled person who will charge high for this task, consider the case of the medical field or the data is in bulk that requires a lot of people assigned to label it. The amount of data that is well enough for training needs to be known, money and time can not be wasted to label the whole data. This paper mainly aims to propose a strategy that helps in labelling the data along with oracle in real-time. With balancing on model contribution for labelling is 89 and 81.1 for furniture type and intel scene image data sets respectively. Further with balancing being kept off model contribution is found to be 83.47 and 78.71 for furniture type and flower data sets respectively.  
## cs.AI
---
### Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v1 [cs.CR])
- Authors : Mikhail Kazdagli, Mohit Tiwari, Akshat Kumar
- Link : [http://arxiv.org/abs/2205.01240](http://arxiv.org/abs/2205.01240)
> ABSTRACT  :  Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing **dark** permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances.  
### **Real-time** Cooperative Vehicle Coordination at Unsignalized Road Intersections. (arXiv:2205.01278v1 [eess.SY])
- Authors : Jiping Luo, Tingting Zhang, Rui Hao, Donglin Li, Chunsheng Chen, Zhenyu Na, Qinyu Zhang
- Link : [http://arxiv.org/abs/2205.01278](http://arxiv.org/abs/2205.01278)
> ABSTRACT  :  Cooperative coordination at unsignalized road intersections, which aims to improve the driving safety and traffic throughput for connected and automated vehicles, has attracted increasing interests in recent years. However, most existing investigations either suffer from computational complexity or cannot harness the full potential of the road infrastructure. To this end, we first present a dedicated intersection coordination framework, where the involved vehicles hand over their control authorities and follow instructions from a centralized coordinator. Then a unified cooperative trajectory optimization problem will be formulated to maximize the traffic throughput while ensuring the driving safety and long-term stability of the coordination system. To address the key computational challenges in the real-world deployment, we reformulate this non-convex sequential decision problem into a model-free Markov Decision Process (MDP) and tackle it by devising a Twin Delayed Deep Deterministic Policy Gradient (TD3)-based strategy in the deep reinforcement learning (DRL) framework. Simulation and practical experiments show that the proposed strategy could achieve near-optimal performance in sub-static coordination scenarios and significantly improve the traffic throughput in the realistic continuous traffic flow. The most remarkable advantage is that our strategy could reduce the time complexity of computation to milliseconds, and is shown scalable when the road lanes increase.  
### Prediction-Based Reachability Analysis for Collision Risk Assessment on Highways. (arXiv:2205.01357v1 [eess.SY])
- Authors : Xinwei Wang, Zirui Li, Javier Alonso, Meng Wang
- Link : [http://arxiv.org/abs/2205.01357](http://arxiv.org/abs/2205.01357)
> ABSTRACT  :  **Real-time** safety systems are crucial components of intelligent vehicles. This paper introduces a prediction-based collision risk assessment approach on highways. Given a point mass vehicle dynamics system, a stochastic forward reachable set considering two-dimensional motion with vehicle state probability distributions is firstly established. We then develop an acceleration prediction model, which provides multi-modal probabilistic acceleration distributions to propagate vehicle states. The collision probability is calculated by summing up the probabilities of the states where two vehicles spatially overlap. Simulation results show that the prediction model has superior performance in terms of vehicle motion position errors, and the proposed collision detection approach is agile and effective to identify the collision in cut-in crash events.  
### ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object Manipulation. (arXiv:2203.06856v2 [cs.CV] UPDATED)
- Authors : Bokui Shen, Zhenyu Jiang, Christopher Choy, Silvio Savarese, Anima Anandkumar, Yuke Zhu
- Link : [http://arxiv.org/abs/2203.06856](http://arxiv.org/abs/2203.06856)
> ABSTRACT  :  Manipulating volumetric deformable objects in the real world, like plush toys and pizza dough, bring substantial challenges due to infinite shape variations, non-rigid motions, and partial observability. We introduce ACID, an action-conditional visual dynamics model for volumetric deformable objects based on structured **implicit neural representation**s. ACID integrates two new techniques: implicit representations for action-conditional dynamics and geodesics-based contrastive learning. To represent deformable dynamics from partial RGB-D observations, we learn implicit representations of occupancy and flow-based forward dynamics. To accurately identify state change under large non-rigid deformations, we learn a correspondence embedding field through a novel geodesics-based contrastive loss. To evaluate our approach, we develop a simulation framework for manipulating complex deformable shapes in realistic scenes and a benchmark containing over 17,000 action trajectories with six types of plush toys and 78 variants. Our model achieves the best performance in geometry, correspondence, and dynamics predictions over existing approaches. The ACID dynamics models are successfully employed to goal-conditioned deformable manipulation tasks, resulting in a 30% increase in task success rate over the strongest baseline. For more results and information, please visit https://b0ku1.github.io/acid/ .  
# Paper List
---
## cs.CV
---
**90** new papers in cs.CV:-) 
1. Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation. (arXiv:2205.01133v1 [cs.CL])
2. D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction. (arXiv:2205.01135v1 [cs.CV])
3. Cost-Aware Comparison of LiDAR-based 3D Object Detectors. (arXiv:2205.01142v1 [cs.CV])
4. Emotion-Controllable Generalized Talking Face Generation. (arXiv:2205.01155v1 [cs.CV])
5. SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels. (arXiv:2205.01156v1 [cs.CV])
6. Saliency map using features derived from spiking neural networks of primate visual cortex. (arXiv:2205.01159v1 [cs.CV])
7. 3D Convolutional Neural Networks for Dendrite Segmentation Using Fine-Tuning and Hyperparameter Optimization. (arXiv:2205.01167v1 [cs.CV])
8. Boosting Video Object Segmentation based on Scale Inconsistency. (arXiv:2205.01197v1 [cs.CV])
9. NHA12D: A New Pavement Crack Dataset and a Comparison Study Of Crack Detection Algorithms. (arXiv:2205.01198v1 [cs.CV])
10. A Hybrid Defense Method against Adversarial Attacks on Traffic Sign Classifiers in Autonomous Vehicles. (arXiv:2205.01225v1 [cs.CR])
11. Adversarial attacks on an optical neural network. (arXiv:2205.01226v1 [cs.CR])
12. One Weird Trick to Improve Your Semi-Weakly Supervised Semantic Segmentation Model. (arXiv:2205.01233v1 [cs.CV])
13. A Performance-Consistent and Computation-Efficient CNN System for High-Quality Automated Brain Tumor Segmentation. (arXiv:2205.01239v1 [eess.IV])
14. Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation. (arXiv:2205.01271v1 [cs.CV])
15. Cross Domain Object Detection by Target-Perceived Dual Branch Distillation. (arXiv:2205.01291v1 [cs.CV])
16. RU-Net: Regularized Unrolling Network for Scene Graph Generation. (arXiv:2205.01297v1 [cs.CV])
17. Distilling Governing Laws and Source Input for Dynamical Systems from Videos. (arXiv:2205.01314v1 [cs.CV])
18. HL-Net: Heterophily Learning Network for Scene Graph Generatio. (arXiv:2205.01316v1 [cs.CV])
19. BioTouchPass: Handwritten Passwords for Touchscreen Biometrics. (arXiv:2205.01353v1 [cs.CR])
20. Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion Networks. (arXiv:2205.01355v1 [cs.GR])
21. A hybrid multi-object segmentation framework with model-based B-splines for microbial single cell analysis. (arXiv:2205.01367v1 [cs.CV])
22. Copy Motion From One to Another: Fake Motion Video Generation. (arXiv:2205.01373v1 [cs.CV])
23. Deep Learning in Multimodal Remote Sensing Data Fusion: A Comprehensive Review. (arXiv:2205.01380v1 [cs.CV])
24. Sampling-free obstacle gradients and reactive planning in Neural Radiance Fields (**NeRF**). (arXiv:2205.01389v1 [cs.RO])
25. Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP). (arXiv:2205.01397v1 [cs.CV])
26. Outdoor Monocular Depth Estimation: A Research Review. (arXiv:2205.01399v1 [cs.CV])
27. Multimodal Detection of Unknown Objects on Roads for Autonomous Driving. (arXiv:2205.01414v1 [cs.CV])
28. An Empirical Analysis of the Use of Real-Time Reachability for the Safety Assurance of Autonomous Vehicles. (arXiv:2205.01419v1 [cs.RO])
29. Frequency-Selective Geometry Upsampling of Point Clouds. (arXiv:2205.01458v1 [eess.IV])
30. 3D Semantic Scene Perception using Distributed Smart Edge Sensors. (arXiv:2205.01460v1 [cs.CV])
31. Subspace Diffusion Generative Models. (arXiv:2205.01490v1 [cs.LG])
32. A Comprehensive Survey of Image Augmentation Techniques for Deep Learning. (arXiv:2205.01491v1 [cs.CV])
33. Compact Neural Networks via Stacking Designed Basic Units. (arXiv:2205.01508v1 [cs.CV])
34. MS Lesion Segmentation: Revisiting Weighting Mechanisms for Federated Learning. (arXiv:2205.01509v1 [eess.IV])
35. Multitask Network for Joint Object Detection, Semantic Segmentation and Human Pose Estimation in Vehicle Occupancy Monitoring. (arXiv:2205.01515v1 [cs.CV])
36. Masked Generative Distillation. (arXiv:2205.01529v1 [cs.CV])
37. BiOcularGAN: Bimodal Synthesis and Annotation of Ocular Images. (arXiv:2205.01536v1 [cs.CV])
38. Multi Scale Sparse Convolution Point Cloud Semantic Segmentation Neural Network. (arXiv:2205.01550v1 [cs.CV])
39. Cross-View Cross-Scene Multi-View Crowd Counting. (arXiv:2205.01551v1 [cs.CV])
40. RAFT-MSF: Self-Supervised Monocular Scene Flow using Recurrent Optimizer. (arXiv:2205.01568v1 [cs.CV])
41. RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds. (arXiv:2205.01570v1 [cs.CV])
42. A Real Time 1280x720 Object Detection Chip With 585MB/s Memory Traffic. (arXiv:2205.01571v1 [cs.AR])
43. Better plain ViT baselines for ImageNet-1k. (arXiv:2205.01580v1 [cs.CV])
44. Simpler is Better: off-the-shelf Continual Learning Through Pretrained Backbones. (arXiv:2205.01586v1 [cs.CV])
45. A Bidirectional Conversion Network for Cross-Spectral Face Recognition. (arXiv:2205.01595v1 [cs.CV])
46. Toward Modeling Creative Processes for Algorithmic Painting. (arXiv:2205.01605v1 [cs.AI])
47. Automatic Segmentation of Aircraft Dents in Point Clouds. (arXiv:2205.01614v1 [cs.CV])
48. SynopSet: Multiscale Visual Abstraction Set for Explanatory Analysis of DNA Nanotechnology Simulations. (arXiv:2205.01628v1 [q-bio.QM])
49. Multi-view Geometry: Correspondences Refinement Based on Algebraic Properties. (arXiv:2205.01634v1 [cs.CG])
50. Cross-Domain Object Detection with Mean-Teacher Transformer. (arXiv:2205.01643v1 [cs.CV])
51. Learning Enriched Features for Fast Image **Restoration** and **Enhancement**. (arXiv:2205.01649v1 [eess.IV])
52. Episodic Memory Question Answering. (arXiv:2205.01652v1 [cs.CV])
53. GeoRefine: Self-Supervised Online Depth Refinement for Accurate Dense Mapping. (arXiv:2205.01656v1 [cs.CV])
54. Cross-modal Representation Learning for Zero-shot Action Recognition. (arXiv:2205.01657v1 [cs.CV])
55. DANBO: Disentangled Articulated Neural Body Representations via Graph Neural Networks. (arXiv:2205.01666v1 [cs.CV])
56. End-to-End Visual Editing with a Generatively Pre-Trained Artist. (arXiv:2205.01668v1 [cs.CV])
57. Domain Adaptation and Image Classification via Deep Conditional Adaptation Network. (arXiv:2006.07776v2 [cs.CV] UPDATED)
58. Weakly Supervised Learning of Multi-Object 3D Scene Decompositions Using Deep Shape Priors. (arXiv:2010.04030v5 [cs.CV] UPDATED)
59. DeepCloth: Neural Garment Representation for Shape and Style Editing. (arXiv:2011.14619v2 [cs.CV] UPDATED)
60. Generalising via Meta-Examples for Continual Learning in the Wild. (arXiv:2101.12081v2 [cs.LG] UPDATED)
61. Neural 3D Video Synthesis from Multi-view Video. (arXiv:2103.02597v2 [cs.CV] UPDATED)
62. FetalNet: Multi-task Deep Learning Framework for Fetal Ultrasound Biometric Measurements. (arXiv:2107.06943v3 [eess.IV] UPDATED)
63. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v3 [eess.IV] UPDATED)
64. An optimised deep spiking neural network architecture without gradients. (arXiv:2109.12813v3 [cs.NE] UPDATED)
65. ADOP: Approximate Differentiable One-Pixel Point Rendering. (arXiv:2110.06635v3 [cs.CV] UPDATED)
66. CeyMo: See More on Roads -- A Novel Benchmark Dataset for Road Marking Detection. (arXiv:2110.11867v3 [cs.CV] UPDATED)
67. LMGP: Lifted Multicut Meets Geometry Projections for Multi-Camera Multi-Object Tracking. (arXiv:2111.11892v3 [cs.CV] UPDATED)
68. 3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection. (arXiv:2112.04764v2 [cs.CV] UPDATED)
69. Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal Misinformation. (arXiv:2112.08594v2 [cs.CV] UPDATED)
70. Connecting the Dots between Audio and Text without Parallel Data through Visual Knowledge Transfer. (arXiv:2112.08995v2 [cs.SD] UPDATED)
71. Manifoldron: Direct Space Partition via Manifold Discovery. (arXiv:2201.05279v2 [cs.LG] UPDATED)
72. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v3 [cs.CV] UPDATED)
73. Artemis: Articulated Neural Pets with Appearance and Motion synthesis. (arXiv:2202.05628v2 [cs.GR] UPDATED)
74. Visual attention analysis of pathologists examining whole slide images of Prostate cancer. (arXiv:2202.08437v2 [eess.IV] UPDATED)
75. Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
76. Recent, rapid advancement in visual question answering architecture: a review. (arXiv:2203.01322v3 [cs.CV] UPDATED)
77. ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object Manipulation. (arXiv:2203.06856v2 [cs.CV] UPDATED)
78. Open-set Recognition via Augmentation-based Similarity Learning. (arXiv:2203.13238v2 [cs.CV] UPDATED)
79. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v2 [cs.CV] UPDATED)
80. ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension. (arXiv:2204.05991v2 [cs.CV] UPDATED)
81. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v7 [cs.CV] UPDATED)
82. Proto2Proto: Can you recognize the car, the way I do?. (arXiv:2204.11830v2 [cs.CV] UPDATED)
83. Power Bundle Adjustment for Large-Scale 3D Reconstruction. (arXiv:2204.12834v2 [cs.CV] UPDATED)
84. GRIT: General Robust Image Task Benchmark. (arXiv:2204.13653v2 [cs.CV] UPDATED)
85. A very preliminary analysis of DALL-E 2. (arXiv:2204.13807v2 [cs.CV] UPDATED)
86. Source Domain Subset Sampling for Semi-Supervised Domain Adaptation in Semantic Segmentation. (arXiv:2205.00312v2 [cs.CV] UPDATED)
87. UTC: A Unified Transformer with Inter-Task Contrastive Learning for Visual Dialog. (arXiv:2205.00423v2 [cs.CV] UPDATED)
88. DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data. (arXiv:2205.00701v2 [astro-ph.IM] UPDATED)
89. CCLF: A Contrastive-Curiosity-Driven Learning Framework for Sample-Efficient Reinforcement Learning. (arXiv:2205.00943v2 [cs.LG] UPDATED)
90. A Multi-stage deep architecture for summary generation of soccer videos. (arXiv:2205.00694v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**18** new papers in eess.IV:-) 
1. Fast algorithms for nonlinear and constrained phase retrieval in near-field X-ray holography based on Tikhonov regularization. (arXiv:2205.01099v1 [eess.IV])
2. D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction. (arXiv:2205.01135v1 [cs.CV])
3. Analysis of the Visually Detectable Wear Progress on Ball Screws. (arXiv:2205.01149v1 [eess.IV])
4. 3D Convolutional Neural Networks for Dendrite Segmentation Using Fine-Tuning and Hyperparameter Optimization. (arXiv:2205.01167v1 [cs.CV])
5. NHA12D: A New Pavement Crack Dataset and a Comparison Study Of Crack Detection Algorithms. (arXiv:2205.01198v1 [cs.CV])
6. A Performance-Consistent and Computation-Efficient CNN System for High-Quality Automated Brain Tumor Segmentation. (arXiv:2205.01239v1 [eess.IV])
7. Frequency-Selective Geometry Upsampling of Point Clouds. (arXiv:2205.01458v1 [eess.IV])
8. MS Lesion Segmentation: Revisiting Weighting Mechanisms for Federated Learning. (arXiv:2205.01509v1 [eess.IV])
9. Multi Scale Sparse Convolution Point Cloud Semantic Segmentation Neural Network. (arXiv:2205.01550v1 [cs.CV])
10. An untrained deep learning method for reconstructing dynamic magnetic resonance images from accelerated model-based data. (arXiv:2205.01604v1 [eess.IV])
11. Automatic Segmentation of Aircraft Dents in Point Clouds. (arXiv:2205.01614v1 [cs.CV])
12. Learning Enriched Features for Fast Image **Restoration** and **Enhancement**. (arXiv:2205.01649v1 [eess.IV])
13. FetalNet: Multi-task Deep Learning Framework for Fetal Ultrasound Biometric Measurements. (arXiv:2107.06943v3 [eess.IV] UPDATED)
14. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v3 [eess.IV] UPDATED)
15. Visual attention analysis of pathologists examining whole slide images of Prostate cancer. (arXiv:2202.08437v2 [eess.IV] UPDATED)
16. Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
17. Frequency-Selective Mesh-to-Mesh Resampling for Color Upsampling of Point Clouds. (arXiv:2203.09224v2 [eess.IV] UPDATED)
18. Terahertz Spatio-Temporal Deep Learning Computed Tomography. (arXiv:2205.00324v2 [eess.IV] UPDATED)
## cs.LG
---
**134** new papers in cs.LG:-) 
1. A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction. (arXiv:2205.01094v1 [cs.CR])
2. Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation. (arXiv:2205.01133v1 [cs.CL])
3. D-DPCC: Deep Dynamic Point Cloud Compression via 3D Motion Prediction. (arXiv:2205.01135v1 [cs.CV])
4. Transformers in Time-series Analysis: A Tutorial. (arXiv:2205.01138v1 [cs.LG])
5. Emotion-Controllable Generalized Talking Face Generation. (arXiv:2205.01155v1 [cs.CV])
6. SELC: Self-Ensemble Label Correction Improves Learning with Noisy Labels. (arXiv:2205.01156v1 [cs.CV])
7. Reproducing Kernels and New Approaches in Compositional Data Analysis. (arXiv:2205.01158v1 [stat.ML])
8. VAE-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation. (arXiv:2205.01179v1 [cs.RO])
9. Using Machine Learning to Evaluate Real Estate Prices Using Location Big Data. (arXiv:2205.01180v1 [cs.LG])
10. Performance Weighting for Robust Federated Learning Against Corrupted Sources. (arXiv:2205.01184v1 [cs.LG])
11. Predicting Time-to-conversion for Dementia of Alzheimer's Type using Multi-modal Deep Survival Analysis. (arXiv:2205.01188v1 [cs.LG])
12. Multi-Task Text Classification using Graph Convolutional Networks for Large-Scale Low Resource Language. (arXiv:2205.01204v1 [cs.CL])
13. Applications of Deep Learning to the Design of Enhanced Wireless Communication Systems. (arXiv:2205.01210v1 [cs.IT])
14. Streaming Inference for Infinite Non-Stationary Clustering. (arXiv:2205.01212v1 [cs.LG])
15. An improvement to a result about graph isomorphism networks using the prime factorization theorem. (arXiv:2205.01214v1 [cs.LG])
16. Leveraging Stochastic Predictions of Bayesian Neural Networks for Fluid Simulations. (arXiv:2205.01222v1 [physics.flu-dyn])
17. FINETUNA: Fine-tuning Accelerated Molecular Simulations. (arXiv:2205.01223v1 [physics.comp-ph])
18. COMET Flows: Towards Generative Modeling of Multivariate Extremes and Tail Dependence. (arXiv:2205.01224v1 [cs.LG])
19. Adversarial attacks on an optical neural network. (arXiv:2205.01226v1 [cs.CR])
20. Retrieval-Enhanced Machine Learning. (arXiv:2205.01230v1 [cs.LG])
21. One Weird Trick to Improve Your Semi-Weakly Supervised Semantic Segmentation Model. (arXiv:2205.01233v1 [cs.CV])
22. Triangular Dropout: Variable Network Width without Retraining. (arXiv:2205.01235v1 [cs.LG])
23. Scheduling with Speed Predictions. (arXiv:2205.01247v1 [cs.DS])
24. Norm-Agnostic Linear Bandits. (arXiv:2205.01257v1 [stat.ML])
25. From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks. (arXiv:2205.01265v1 [cs.AI])
26. Towards an Ensemble Regressor Model for Anomalous ISP Traffic Prediction. (arXiv:2205.01300v1 [cs.LG])
27. Convergence of Stochastic Approximation via Martingale and Converse Lyapunov Methods. (arXiv:2205.01303v1 [stat.ML])
28. CANShield: Signal-based Intrusion Detection for Controller Area Networks. (arXiv:2205.01306v1 [cs.CR])
29. FedRN: Exploiting k-Reliable Neighbors Towards Robust Federated Learning. (arXiv:2205.01310v1 [cs.LG])
30. Distilling Governing Laws and Source Input for Dynamical Systems from Videos. (arXiv:2205.01314v1 [cs.CV])
31. Open vs Closed-ended questions in attitudinal surveys -- comparing, combining, and interpreting using natural language processing. (arXiv:2205.01317v1 [econ.GN])
32. Learning Discrete Structured Variational Auto-Encoder using Natural Evolution Strategies. (arXiv:2205.01324v1 [cs.LG])
33. Predicting Issue Types with seBERT. (arXiv:2205.01335v1 [cs.SE])
34. Predicting Loose-Fitting Garment Deformations Using Bone-Driven Motion Networks. (arXiv:2205.01355v1 [cs.GR])
35. Learning Label Initialization for Time-Dependent Harmonic Extension. (arXiv:2205.01358v1 [cs.LG])
36. TracInAD: Measuring Influence for Anomaly Detection. (arXiv:2205.01362v1 [cs.LG])
37. Finding patterns in Knowledge Attribution for Transformers. (arXiv:2205.01366v1 [cs.CL])
38. Deep Learning in Multimodal Remote Sensing Data Fusion: A Comprehensive Review. (arXiv:2205.01380v1 [cs.CV])
39. Smooth over-parameterized solvers for non-smooth structured optimization. (arXiv:2205.01385v1 [math.OC])
40. Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP). (arXiv:2205.01397v1 [cs.CV])
41. Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?. (arXiv:2205.01404v1 [cs.CL])
42. Multimodal Detection of Unknown Objects on Roads for Autonomous Driving. (arXiv:2205.01414v1 [cs.CV])
43. An Empirical Analysis of the Use of Real-Time Reachability for the Safety Assurance of Autonomous Vehicles. (arXiv:2205.01419v1 [cs.RO])
44. A Falsificationist Account of Artificial Neural Networks. (arXiv:2205.01421v1 [cs.LG])
45. Autonomy and Intelligence in the Computing Continuum: Challenges, Enablers, and Future Directions for Orchestration. (arXiv:2205.01423v1 [cs.MA])
46. ARCADE: Adversarially Regularized Convolutional Autoencoder for Network Anomaly Detection. (arXiv:2205.01432v1 [cs.LG])
47. RLFlow: Optimising Neural Network Subgraph Transformation with World Models. (arXiv:2205.01435v1 [cs.LG])
48. Efficient and Convergent Federated Learning. (arXiv:2205.01438v1 [cs.LG])
49. Learning Coulomb Diamonds in Large Quantum Dot Arrays. (arXiv:2205.01443v1 [cond-mat.mes-hall])
50. High-dimensional Asymptotics of Feature Learning: How One Gradient Step Improves the Representation. (arXiv:2205.01445v1 [stat.ML])
51. Efficient implementation of incremental proximal-point methods. (arXiv:2205.01457v1 [cs.LG])
52. On the Convergence of Fictitious Play: A Decomposition Approach. (arXiv:2205.01469v1 [cs.GT])
53. Revisiting Communication-Efficient Federated Learning with Balanced Global and Local Updates. (arXiv:2205.01470v1 [cs.LG])
54. Residual Graph Convolutional Recurrent Networks For Multi-step Traffic Flow Forecasting. (arXiv:2205.01480v1 [cs.LG])
55. Scalable Regularised Joint Mixture Models. (arXiv:2205.01486v1 [stat.ML])
56. Subspace Diffusion Generative Models. (arXiv:2205.01490v1 [cs.LG])
57. A unified view on Self-Organizing Maps (SOMs) and Stochastic Neighbor Embedding (SNE). (arXiv:2205.01492v1 [cs.LG])
58. On the uncertainty principle of neural networks. (arXiv:2205.01493v1 [cs.LG])
59. Meta Learning for Natural Language Processing: A Survey. (arXiv:2205.01500v1 [cs.CL])
60. Compact Neural Networks via Stacking Designed Basic Units. (arXiv:2205.01508v1 [cs.CV])
61. ExSpliNet: An interpretable and expressive spline-based neural network. (arXiv:2205.01510v1 [cs.LG])
62. Fair Feature Subset Selection using Multiobjective Genetic Algorithm. (arXiv:2205.01512v1 [cs.NE])
63. BiOcularGAN: Bimodal Synthesis and Annotation of Ocular Images. (arXiv:2205.01536v1 [cs.CV])
64. Efficient Fine-Tuning of BERT Models on the Edge. (arXiv:2205.01541v1 [cs.LG])
65. Privacy Amplification via Random Participation in Federated Learning. (arXiv:2205.01556v1 [cs.LG])
66. RAFT-MSF: Self-Supervised Monocular Scene Flow using Recurrent Optimizer. (arXiv:2205.01568v1 [cs.CV])
67. PSCNN: A 885.86 TOPS/W Programmable SRAM-based Computing-In-Memory Processor for Keyword Spotting. (arXiv:2205.01569v1 [cs.AR])
68. RangeSeg: Range-Aware Real Time Segmentation of 3D LiDAR Point Clouds. (arXiv:2205.01570v1 [cs.CV])
69. A Real Time 1280x720 Object Detection Chip With 585MB/s Memory Traffic. (arXiv:2205.01571v1 [cs.AR])
70. An Empirical Study on Internet Traffic Prediction Using Statistical Rolling Model. (arXiv:2205.01590v1 [cs.NI])
71. Conditional $\beta$-VAE for De Novo Molecular Generation. (arXiv:2205.01592v1 [q-bio.BM])
72. Modeling and Correcting Bias in Sequential Evaluation. (arXiv:2205.01607v1 [stat.ML])
73. Local Stochastic Bilevel Optimization with Momentum-Based Variance Reduction. (arXiv:2205.01608v1 [cs.LG])
74. Automatic Segmentation of Aircraft Dents in Point Clouds. (arXiv:2205.01614v1 [cs.CV])
75. Toward Robust Spiking Neural Network Against Adversarial Perturbation. (arXiv:2205.01625v1 [cs.NE])
76. Automated Learning of Interpretable Models with Quantified Uncertainty. (arXiv:2205.01626v1 [cs.NE])
77. AutoFi: Towards Automatic WiFi Human Sensing via Geometric Self-Supervised Learning. (arXiv:2205.01629v1 [cs.NI])
78. Dynamic and Context-Dependent Stock Price Prediction Using Attention Modules and News Sentiment. (arXiv:2205.01639v1 [q-fin.CP])
79. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v1 [cs.LG])
80. Population Predictive Checks. (arXiv:1908.00882v3 [stat.ME] UPDATED)
81. Learning Mixtures of Random Utility Models with Features from Incomplete Preferences. (arXiv:2006.03869v3 [cs.LG] UPDATED)
82. A Bandit Model for Human-Machine Decision Making with Private Information and Opacity. (arXiv:2007.04800v3 [cs.LG] UPDATED)
83. Regularization in network optimization via trimmed stochastic gradient descent with noisy label. (arXiv:2012.11073v3 [cs.LG] UPDATED)
84. Generalising via Meta-Examples for Continual Learning in the Wild. (arXiv:2101.12081v2 [cs.LG] UPDATED)
85. Diffusion Mechanism in Residual Neural Network: Theory and Applications. (arXiv:2105.03155v4 [cs.LG] UPDATED)
86. Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more Scalable than Optimism?. (arXiv:2106.08771v2 [cs.LG] UPDATED)
87. Partial Maximum Correntropy Regression for Robust Trajectory Decoding from Noisy Epidural Electrocorticographic Signals. (arXiv:2106.13086v2 [eess.SP] UPDATED)
88. Convergent and Efficient Deep Q Network Algorithm. (arXiv:2106.15419v3 [cs.LG] UPDATED)
89. FetalNet: Multi-task Deep Learning Framework for Fetal Ultrasound Biometric Measurements. (arXiv:2107.06943v3 [eess.IV] UPDATED)
90. A diffusion-map-based algorithm for gradient computation on manifolds and applications. (arXiv:2108.06988v3 [cs.LG] UPDATED)
91. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v3 [eess.IV] UPDATED)
92. Explainable Identification of Dementia from Transcripts using Transformer Networks. (arXiv:2109.06980v2 [cs.CL] UPDATED)
93. Self-Training with Differentiable Teacher. (arXiv:2109.07049v2 [cs.CL] UPDATED)
94. Linear Asymptotic Convergence of Anderson Acceleration: Fixed-Point Analysis. (arXiv:2109.14176v2 [math.OC] UPDATED)
95. Adapt to Adaptation: Learning Personalization for Cross-Silo Federated Learning. (arXiv:2110.08394v2 [cs.LG] UPDATED)
96. Finite Horizon Q-learning: Stability, Convergence, Simulations and an application on Smart Grids. (arXiv:2110.15093v2 [cs.LG] UPDATED)
97. Robust Federated Learning via Over-The-Air Computation. (arXiv:2111.01221v3 [cs.LG] UPDATED)
98. A comparison of mixed-variables Bayesian optimization approaches. (arXiv:2111.01533v3 [math.OC] UPDATED)
99. Eluding Secure Aggregation in Federated Learning via Model Inconsistency. (arXiv:2111.07380v3 [cs.LG] UPDATED)
100. A Unified Framework for Adversarial Attack and Defense in Constrained Feature Space. (arXiv:2112.01156v2 [cs.AI] UPDATED)
101. 3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection. (arXiv:2112.04764v2 [cs.CV] UPDATED)
102. FedNI: Federated Graph Learning with Network Inpainting for Population-Based Disease Prediction. (arXiv:2112.10166v2 [cs.LG] UPDATED)
103. Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation. (arXiv:2201.01666v3 [cs.LG] UPDATED)
104. Manifoldron: Direct Space Partition via Manifold Discovery. (arXiv:2201.05279v2 [cs.LG] UPDATED)
105. Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models. (arXiv:2201.06503v3 [cs.LG] UPDATED)
106. Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming. (arXiv:2201.08484v3 [cs.MA] UPDATED)
107. Ad-datasets: a meta-collection of data sets for autonomous driving. (arXiv:2202.01909v3 [cs.LG] UPDATED)
108. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v3 [cs.CV] UPDATED)
109. Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality. (arXiv:2202.06450v2 [cs.LG] UPDATED)
110. Signal Decomposition Using Masked Proximal Operators. (arXiv:2202.09338v3 [cs.LG] UPDATED)
111. Constant matters: Fine-grained Complexity of Differentially Private Continual Observation. (arXiv:2202.11205v3 [cs.DS] UPDATED)
112. Active learning with binary models for **real time** data labelling. (arXiv:2203.00439v2 [cs.CV] UPDATED)
113. Target Network and Truncation Overcome The Deadly Triad in $Q$-Learning. (arXiv:2203.02628v2 [cs.LG] UPDATED)
114. Enhancing Mechanical Metamodels with a Generative Model-Based Augmented Training Dataset. (arXiv:2203.04183v2 [cs.LG] UPDATED)
115. Interpretable machine learning in Physics. (arXiv:2203.08021v3 [hep-ph] UPDATED)
116. On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers. (arXiv:2203.08958v3 [cs.LG] UPDATED)
117. Self-Ensemble Adversarial Training for Improved Robustness. (arXiv:2203.09678v2 [cs.LG] UPDATED)
118. Structured Pruning Learns Compact and Accurate Models. (arXiv:2204.00408v3 [cs.CL] UPDATED)
119. Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization. (arXiv:2204.02246v3 [cs.LG] UPDATED)
120. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v2 [cs.CV] UPDATED)
121. FederatedScope: A Flexible Federated Learning Platform for Heterogeneity. (arXiv:2204.05011v2 [cs.LG] UPDATED)
122. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v7 [cs.CV] UPDATED)
123. XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v3 [cs.CL] UPDATED)
124. Limit theorems of Chatterjee's rank correlation. (arXiv:2204.08031v2 [math.ST] UPDATED)
125. Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems. (arXiv:2204.09183v2 [cs.LG] UPDATED)
126. Theoretical Understanding of the Information Flow on Continual Learning Performance. (arXiv:2204.12010v2 [cs.LG] UPDATED)
127. Social learning spontaneously emerges by searching optimal heuristics with deep reinforcement learning. (arXiv:2204.12371v2 [cs.LG] UPDATED)
128. None Class Ranking Loss for Document-Level Relation Extraction. (arXiv:2205.00476v2 [cs.CL] UPDATED)
129. DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data. (arXiv:2205.00701v2 [astro-ph.IM] UPDATED)
130. VICE: Variational Inference for Concept Embeddings. (arXiv:2205.00756v2 [cs.LG] UPDATED)
131. CCLF: A Contrastive-Curiosity-Driven Learning Framework for Sample-Efficient Reinforcement Learning. (arXiv:2205.00943v2 [cs.LG] UPDATED)
132. A Change Dynamic Model for the Online Detection of Gradual Change. (arXiv:2205.01054v2 [stat.ML] UPDATED)
133. OPT: Open Pre-trained Transformer Language Models. (arXiv:2205.01068v2 [cs.CL] UPDATED)
134. A Multi-stage deep architecture for summary generation of soccer videos. (arXiv:2205.00694v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**76** new papers in cs.AI:-) 
1. Neurocompositional computing: From the Central Paradox of Cognition to a new generation of AI systems. (arXiv:2205.01128v1 [cs.AI])
2. The Theory of Artificial Immutability: Protecting Algorithmic Groups Under Anti-Discrimination Law. (arXiv:2205.01166v1 [cs.CY])
3. Multi-Task Text Classification using Graph Convolutional Networks for Large-Scale Low Resource Language. (arXiv:2205.01204v1 [cs.CL])
4. Streaming Inference for Infinite Non-Stationary Clustering. (arXiv:2205.01212v1 [cs.LG])
5. ADDAI: Anomaly Detection using Distributed AI. (arXiv:2205.01231v1 [cs.DC])
6. TRUST XAI: Model-Agnostic Explanations for AI With a Case Study on IIoT Security. (arXiv:2205.01232v1 [cs.AI])
7. Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v1 [cs.CR])
8. Norm-Agnostic Linear Bandits. (arXiv:2205.01257v1 [stat.ML])
9. From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks. (arXiv:2205.01265v1 [cs.AI])
10. Modus ponens and modus tollens for the compositional rule of inference with aggregation functions. (arXiv:2205.01269v1 [math.LO])
11. **Real-time** Cooperative Vehicle Coordination at Unsignalized Road Intersections. (arXiv:2205.01278v1 [eess.SY])
12. DrugEHRQA: A Question Answering Dataset on Structured and Unstructured Electronic Health Records For Medicine Related Queries. (arXiv:2205.01290v1 [cs.AI])
13. A Survey of Deep Learning Models for Structural Code Understanding. (arXiv:2205.01293v1 [cs.SE])
14. Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions. (arXiv:2205.01296v1 [cs.AI])
15. Embedding Hallucination for Few-Shot Language Fine-tuning. (arXiv:2205.01307v1 [cs.CL])
16. Contrastive Learning for Prompt-Based Few-Shot Language Learners. (arXiv:2205.01308v1 [cs.CL])
17. Distilling Governing Laws and Source Input for Dynamical Systems from Videos. (arXiv:2205.01314v1 [cs.CV])
18. GRAPHYP: A Scientific Knowledge Graph with Manifold Subnetworks of Communities. Detection of Scholarly Disputes in Adversarial Information Routes. (arXiv:2205.01331v1 [cs.AI])
19. Neural Combinatorial Optimization: a New Player in the Field. (arXiv:2205.01356v1 [cs.AI])
20. Prediction-Based Reachability Analysis for Collision Risk Assessment on Highways. (arXiv:2205.01357v1 [eess.SY])
21. Copy Motion From One to Another: Fake Motion Video Generation. (arXiv:2205.01373v1 [cs.CV])
22. Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?. (arXiv:2205.01404v1 [cs.CL])
23. On the Utility of Prediction Sets in Human-AI Teams. (arXiv:2205.01411v1 [cs.AI])
24. How Does Embodiment Affect the Human Perception of Computational Creativity? An Experimental Study Framework. (arXiv:2205.01418v1 [cs.HC])
25. A Falsificationist Account of Artificial Neural Networks. (arXiv:2205.01421v1 [cs.LG])
26. Autonomy and Intelligence in the Computing Continuum: Challenges, Enablers, and Future Directions for Orchestration. (arXiv:2205.01423v1 [cs.MA])
27. Model-Free Opponent Shaping. (arXiv:2205.01447v1 [cs.AI])
28. On the Effect of Information Asymmetry in Human-AI Teams. (arXiv:2205.01467v1 [cs.HC])
29. On the Convergence of Fictitious Play: A Decomposition Approach. (arXiv:2205.01469v1 [cs.GT])
30. Residual Graph Convolutional Recurrent Networks For Multi-step Traffic Flow Forecasting. (arXiv:2205.01480v1 [cs.LG])
31. Meta Learning for Natural Language Processing: A Survey. (arXiv:2205.01500v1 [cs.CL])
32. BasqueParl: A Bilingual Corpus of Basque Parliamentary Transcriptions. (arXiv:2205.01506v1 [cs.CL])
33. Compact Neural Networks via Stacking Designed Basic Units. (arXiv:2205.01508v1 [cs.CV])
34. Using Ontologies for the Formalization and Recognition of Criticality for Automated Driving. (arXiv:2205.01532v1 [cs.AI])
35. Learn To Remember: Transformer with Recurrent Memory for Document-Level Machine Translation. (arXiv:2205.01546v1 [cs.AI])
36. Adaptable Adapters. (arXiv:2205.01549v1 [cs.CL])
37. SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals. (arXiv:2205.01588v1 [cs.CL])
38. Toward Modeling Creative Processes for Algorithmic Painting. (arXiv:2205.01605v1 [cs.AI])
39. Toward Robust Spiking Neural Network Against Adversarial Perturbation. (arXiv:2205.01625v1 [cs.NE])
40. AutoFi: Towards Automatic WiFi Human Sensing via Geometric Self-Supervised Learning. (arXiv:2205.01629v1 [cs.NI])
41. Intelligent Trajectory Design for RIS-NOMA aided Multi-robot Communications. (arXiv:2205.01647v1 [cs.RO])
42. Episodic Memory Question Answering. (arXiv:2205.01652v1 [cs.CV])
43. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v1 [cs.LG])
44. The ghosts of forgotten things: A study on size after forgetting. (arXiv:2005.04123v3 [cs.LO] UPDATED)
45. Extended Parallel Corpus for Amharic-English Machine Translation. (arXiv:2104.03543v3 [cs.CL] UPDATED)
46. Causal Learning for Socially Responsible AI. (arXiv:2104.12278v2 [cs.AI] UPDATED)
47. Reinforcement Learning for Markovian Bandits: Is Posterior Sampling more Scalable than Optimism?. (arXiv:2106.08771v2 [cs.LG] UPDATED)
48. Convergent and Efficient Deep Q Network Algorithm. (arXiv:2106.15419v3 [cs.LG] UPDATED)
49. FetalNet: Multi-task Deep Learning Framework for Fetal Ultrasound Biometric Measurements. (arXiv:2107.06943v3 [eess.IV] UPDATED)
50. Finite Horizon Q-learning: Stability, Convergence, Simulations and an application on Smart Grids. (arXiv:2110.15093v2 [cs.LG] UPDATED)
51. MetaICL: Learning to Learn In Context. (arXiv:2110.15943v2 [cs.CL] UPDATED)
52. A Unified Framework for Adversarial Attack and Defense in Constrained Feature Space. (arXiv:2112.01156v2 [cs.AI] UPDATED)
53. Maximum Bayes Smatch Ensemble Distillation for AMR Parsing. (arXiv:2112.07790v2 [cs.CL] UPDATED)
54. Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation. (arXiv:2201.01666v3 [cs.LG] UPDATED)
55. Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming. (arXiv:2201.08484v3 [cs.MA] UPDATED)
56. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v3 [cs.CV] UPDATED)
57. Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality. (arXiv:2202.06450v2 [cs.LG] UPDATED)
58. Online Approval Committee Elections. (arXiv:2202.06830v3 [cs.GT] UPDATED)
59. Recent, rapid advancement in visual question answering architecture: a review. (arXiv:2203.01322v3 [cs.CV] UPDATED)
60. ACID: Action-Conditional Implicit Visual Dynamics for Deformable Object Manipulation. (arXiv:2203.06856v2 [cs.CV] UPDATED)
61. On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers. (arXiv:2203.08958v3 [cs.LG] UPDATED)
62. Open-set Recognition via Augmentation-based Similarity Learning. (arXiv:2203.13238v2 [cs.CV] UPDATED)
63. Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization. (arXiv:2204.02246v3 [cs.LG] UPDATED)
64. SOS! Self-supervised Learning Over Sets Of Handled Objects In Egocentric Action Recognition. (arXiv:2204.04796v2 [cs.CV] UPDATED)
65. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v7 [cs.CV] UPDATED)
66. XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v3 [cs.CL] UPDATED)
67. Robustness Testing of Data and Knowledge Driven Anomaly Detection in Cyber-Physical Systems. (arXiv:2204.09183v2 [cs.LG] UPDATED)
68. On the Verification of Belief Programs. (arXiv:2204.12562v3 [cs.AI] UPDATED)
69. A very preliminary analysis of DALL-E 2. (arXiv:2204.13807v2 [cs.CV] UPDATED)
70. Opponent Modeling in Negotiation Dialogues by Related Data Adaptation. (arXiv:2205.00344v2 [cs.CL] UPDATED)
71. The Ludii Game Description Language is Universal. (arXiv:2205.00451v2 [cs.AI] UPDATED)
72. DeepGraviLens: a Multi-Modal Architecture for Classifying Gravitational Lensing Data. (arXiv:2205.00701v2 [astro-ph.IM] UPDATED)
73. CCLF: A Contrastive-Curiosity-Driven Learning Framework for Sample-Efficient Reinforcement Learning. (arXiv:2205.00943v2 [cs.LG] UPDATED)
74. Quantifying Health Inequalities Induced by Data and AI Models. (arXiv:2205.01066v2 [cs.CY] UPDATED)
75. RoBERTuito: a pre-trained language model for social media text in Spanish. (arXiv:2111.09453v2 [cs.CL] CROSS LISTED)
76. A Multi-stage deep architecture for summary generation of soccer videos. (arXiv:2205.00694v1 [cs.CV] CROSS LISTED)

