# Your interest papers
---
## cs.CV
---
### Imaging through the Atmosphere using Turbulence Mitigation Transformer. (arXiv:2207.06465v1 [eess.IV])
- Authors : Xingguang Zhang, Zhiyuan Mao, Nicholas Chimitt
- Link : [http://arxiv.org/abs/2207.06465](http://arxiv.org/abs/2207.06465)
> ABSTRACT  :  Restoring images distorted by atmospheric turbulence is a long-standing problem due to the spatially varying nature of the distortion, nonlinearity of the image formation process, and scarcity of training and testing data. Existing methods often have strong statistical assumptions on the distortion model which in many cases will lead to a limited performance in real-world scenarios as they do not generalize. To overcome the challenge, this paper presents an end-to-end physics-driven approach that is efficient and can generalize to real-world turbulence. On the data synthesis front, we significantly increase the image resolution that can be handled by the SOTA turbulence simulator by approximating the random field via wide-sense stationarity. The new data synthesis process enables the generation of large-scale multi-level turbulence and ground truth pairs for training. On the network design front, we propose the turbulence mitigation transformer (TMT), a two stage U-Net shaped multi-frame **restoration** network which has a noval efficient self-attention mechanism named temporal channel joint attention (TCJA). We also introduce a new training scheme that is enabled by the new simulator, and we design new transformer units to reduce the memory consumption. Experimental results on both static and dynamic scenes are promising, including various real turbulence scenarios.  
### Rethinking Super-Resolution as Text-Guided Details Generation. (arXiv:2207.06604v1 [cs.CV])
- Authors : Chenxi Ma, Bo Yan, Qing Lin, Weimin Tan, Siming Chen
- Link : [http://arxiv.org/abs/2207.06604](http://arxiv.org/abs/2207.06604)
> ABSTRACT  :  Deep neural networks have greatly promoted the performance of single image super-resolution (SISR). Conventional methods still resort to restoring the single high-resolution (HR) solution only based on the input of image modality. However, the image-level information is insufficient to predict adequate details and photo-realistic visual quality facing large upscaling factors (x8, x16). In this paper, we propose a new perspective that regards the SISR as a semantic image detail **enhancement** problem to generate semantically reasonable HR image that are faithful to the ground truth. To enhance the semantic accuracy and the visual quality of the reconstructed image, we explore the multi-modal fusion learning in SISR by proposing a Text-Guided Super-Resolution (TGSR) framework, which can effectively utilize the information from the text and image modalities. Different from existing methods, the proposed TGSR could generate HR image details that match the text descriptions through a coarse-to-fine process. Extensive experiments and ablation studies demonstrate the effect of the TGSR, which exploits the text reference to recover realistic images.  
### Continuous Facial Motion Deblurring. (arXiv:2207.06626v1 [cs.CV])
- Authors : Tae Bok, Sujy Han, Yong Seok
- Link : [http://arxiv.org/abs/2207.06626](http://arxiv.org/abs/2207.06626)
> ABSTRACT  :  We introduce a novel framework for continuous facial motion deblurring that restores the continuous sharp moment latent in a single motion-blurred face image via a moment control factor. Although a motion-blurred image is the accumulated signal of continuous sharp moments during the **exposure** time, most existing single image deblurring approaches aim to restore a fixed number of frames using multiple networks and training stages. To address this problem, we propose a continuous facial motion deblurring network based on GAN (CFMD-GAN), which is a novel framework for restoring the continuous moment latent in a single motion-blurred face image with a single network and a single training stage. To stabilize the network training, we train the generator to restore continuous moments in the order determined by our facial motion-based reordering process (FMR) utilizing domain-specific knowledge of the face. Moreover, we propose an auxiliary regressor that helps our generator produce more accurate images by estimating continuous sharp moments. Furthermore, we introduce a control-adaptive (ContAda) block that performs spatially deformable convolution and channel-wise attention as a function of the control factor. Extensive experiments on the 300VW datasets demonstrate that the proposed framework generates a various number of continuous output frames by varying the moment control factor. Compared with the recent single-to-single image deblurring networks trained with the same 300VW training set, the proposed method show the superior performance in restoring the central sharp frame in terms of perceptual metrics, including LPIPS, FID and Arcface identity distance. The proposed method outperforms the existing single-to-video deblurring method for both qualitative and quantitative comparisons.  
### Forcing the Whole Video as Background: An Adversarial Learning Strategy for Weakly Temporal Action Localization. (arXiv:2207.06659v1 [cs.CV])
- Authors : Ziqiang Li, Yongxin Ge, Jiaruo Yu, Zhongming Chen
- Link : [http://arxiv.org/abs/2207.06659](http://arxiv.org/abs/2207.06659)
> ABSTRACT  :  With video-level labels, weakly supervised temporal action localization (WTAL) applies a localization-by-classification paradigm to detect and classify the action in untrimmed videos. Due to the characteristic of classification, class-specific background snippets are inevitably mis-activated to improve the discriminability of the classifier in WTAL. To alleviate the disturbance of background, existing methods try to enlarge the discrepancy between action and background through modeling background snippets with pseudo-snippet-level annotations, which largely rely on artificial hypotheticals. Distinct from the previous works, we present an adversarial learning strategy to break the limitation of mining pseudo background snippets. Concretely, the background classification loss forces the whole video to be regarded as the background by a background gradient reinforcement strategy, confusing the recognition model. Reversely, the foreground(action) loss guides the model to focus on action snippets under such conditions. As a result, competition between the two classification losses drives the model to boost its ability for action modeling. Simultaneously, a novel temporal **enhancement** network is designed to facilitate the model to construct temporal relation of affinity snippets based on the proposed strategy, for further improving the performance of action localization. Finally, extensive experiments conducted on THUMOS14 and ActivityNet1.2 demonstrate the effectiveness of the proposed method.  
### Neural apparent BRDF fields for multiview photometric stereo. (arXiv:2207.06793v1 [cs.CV])
- Authors : Meghna Asthana, Patrik Huber
- Link : [http://arxiv.org/abs/2207.06793](http://arxiv.org/abs/2207.06793)
> ABSTRACT  :  We propose to tackle the multiview photometric stereo problem using an extension of Neural Radiance Fields (**NeRF**s), conditioned on light source direction. The geometric part of our neural representation predicts surface normal direction, allowing us to reason about local surface reflectance. The appearance part of our neural representation is decomposed into a neural bidirectional reflectance function (BRDF), learnt as part of the fitting process, and a shadow prediction network (conditioned on light source direction) allowing us to model the apparent BRDF. This balance of learnt components with inductive biases based on physical image formation models allows us to extrapolate far from the light source and viewer directions observed during training. We demonstrate our approach on a multiview photometric stereo benchmark and show that competitive performance can be obtained with the neural density representation of a **NeRF**.  
### Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions. (arXiv:2207.06825v1 [cs.CV])
- Authors : David Bruggemann, Christos Sakaridis, Prune Truong, Luc Van
- Link : [http://arxiv.org/abs/2207.06825](http://arxiv.org/abs/2207.06825)
> ABSTRACT  :  Due to the scarcity of dense pixel-level semantic annotations for images recorded in adverse visual conditions, there has been a keen interest in unsupervised domain adaptation (UDA) for the semantic segmentation of such images. UDA adapts models trained on normal conditions to the target adverse-condition domains. Meanwhile, multiple datasets with driving scenes provide corresponding images of the same scenes across multiple conditions, which can serve as a form of weak supervision for domain adaptation. We propose Refign, a generic extension to self-training-based UDA methods which leverages these cross-domain correspondences. Refign consists of two steps: (1) aligning the normal-condition image to the corresponding adverse-condition image using an uncertainty-aware dense matching network, and (2) refining the adverse prediction with the normal prediction using an adaptive label correction mechanism. We design custom modules to streamline both steps and set the new state of the art for domain-adaptive semantic segmentation on several adverse-condition benchmarks, including ACDC and **Dark** Zurich. The approach introduces no extra training parameters, minimal computational overhead -- during training only -- and can be used as a drop-in extension to improve any given self-training-based UDA method. Code is available at https://github.com/brdav/refign.  
### E2FIF: Push the limit of Binarized Deep Imagery Super-resolution using End-to-end Full-precision Information Flow. (arXiv:2207.06893v1 [cs.CV])
- Authors : Zhiqiang Lang, **Lei Zhang**, Wei Wei
- Link : [http://arxiv.org/abs/2207.06893](http://arxiv.org/abs/2207.06893)
> ABSTRACT  :  Binary neural network (BNN) provides a promising solution to deploy parameter-intensive deep single image super-resolution (SISR) models onto real devices with limited storage and computational resources. To achieve comparable performance with the full-precision counterpart, most existing BNNs for SISR mainly focus on compensating the information loss incurred by binarizing weights and activations in the network through better approximations to the binarized convolution. In this study, we revisit the difference between BNNs and their full-precision counterparts and argue that the key for good generalization performance of BNNs lies on preserving a complete full-precision information flow as well as an accurate gradient flow passing through each binarized convolution layer. Inspired by this, we propose to introduce a full-precision skip connection or its variant over each binarized convolution layer across the entire network, which can increase the forward expressive capability and the accuracy of back-propagated gradient, thus enhancing the generalization performance. More importantly, such a scheme is applicable to any existing BNN backbones for SISR without introducing any additional computation cost. To testify its efficacy, we evaluate it using four different backbones for SISR on four benchmark datasets and report obviously superior performance over existing BNNs and even some 4-bit competitors.  
### **Real-time** Streaming Video Denoising with Bidirectional Buffers. (arXiv:2207.06937v1 [cs.CV])
- Authors : Chenyang Qi, Junming Chen, Xin Yang, Qifeng Chen
- Link : [http://arxiv.org/abs/2207.06937](http://arxiv.org/abs/2207.06937)
> ABSTRACT  :  Video streams are delivered continuously to save the cost of storage and device memory. **Real-time** denoising algorithms are typically adopted on the user device to remove the noise involved during the shooting and transmission of video streams. However, sliding-window-based methods feed multiple input frames for a single output and lack computation efficiency. Recent multi-output inference works propagate the bidirectional temporal feature with a parallel or recurrent framework, which either suffers from performance drops on the temporal edges of clips or can not achieve online inference. In this paper, we propose a Bidirectional Streaming Video Denoising (BSVD) framework, to achieve high-fidelity real-time denoising for streaming videos with both past and future temporal receptive fields. The bidirectional temporal fusion for online inference is considered not applicable in the MoViNet. However, we introduce a novel Bidirectional Buffer Block as the core module of our BSVD, which makes it possible during our pipeline-style inference. In addition, our method is concise and flexible to be utilized in both non-blind and blind video denoising. We compare our model with various state-of-the-art video denoising models qualitatively and quantitatively on synthetic and real noise. Our method outperforms previous methods in terms of **restoration** fidelity and runtime. Our source code is publicly available at https://github.com/ChenyangQiQi/BSVD  
### Accurate Ground-Truth Depth Image Generation via Overfit Training of Point Cloud Registration using Local Frame Sets. (arXiv:2207.07016v1 [cs.CV])
- Authors : Jiwan Kim, Minchang Kim, Gil Shin, Minyoung Chung
- Link : [http://arxiv.org/abs/2207.07016](http://arxiv.org/abs/2207.07016)
> ABSTRACT  :  Accurate three-dimensional perception is a fundamental task in several computer vision applications. Recently, commercial RGB-depth (RGB-D) cameras have been widely adopted as single-view depth-sensing devices owing to their efficient depth-sensing abilities. However, the depth quality of most RGB-D sensors remains insufficient owing to the inherent noise from a single-view environment. Recently, several studies have focused on the single-view depth **enhancement** of RGB-D cameras. Recent research has proposed deep-learning-based approaches that typically train networks using high-quality supervised depth datasets, which indicates that the quality of the ground-truth (GT) depth dataset is a top-most important factor for accurate system; however, such high-quality GT datasets are difficult to obtain. In this study, we developed a novel method for high-quality GT depth generation based on an RGB-D stream dataset. First, we defined consecutive depth frames in a local spatial region as a local frame set. Then, the depth frames were aligned to a certain frame in the local frame set using an unsupervised point cloud registration scheme. The registration parameters were trained based on an overfit-training scheme, which was primarily used to construct a single GT depth image for each frame set. The final GT depth dataset was constructed using several local frame sets, and each local frame set was trained independently. The primary advantage of this study is that a high-quality GT depth dataset can be constructed under various scanning environments using only the RGB-D stream dataset. Moreover, our proposed method can be used as a new benchmark GT dataset for accurate performance evaluations. We evaluated our GT dataset on previously benchmarked GT depth datasets and demonstrated that our method is superior to state-of-the-art depth **enhancement** frameworks.  
### Explaining Image **Enhancement** Black-Box Methods through a Path Planning Based Algorithm. (arXiv:2207.07092v1 [cs.CV])
- Authors : Marco Cotogni, Claudio Cusano
- Link : [http://arxiv.org/abs/2207.07092](http://arxiv.org/abs/2207.07092)
> ABSTRACT  :  Nowadays, image-to-image translation methods, are the state of the art for the **enhancement** of natural images. Even if they usually show high performance in terms of accuracy, they often suffer from several limitations such as the generation of artifacts and the scalability to high resolutions. Moreover, their main drawback is the completely black-box approach that does not allow to provide the final user with any insight about the **enhancement** processes applied. In this paper we present a path planning algorithm which provides a step-by-step explanation of the output produced by state of the art **enhancement** methods, overcoming black-box limitation. This algorithm, called eXIE, uses a variant of the A* algorithm to emulate the **enhancement** process of another method through the application of an equivalent sequence of enhancing operators. We applied eXIE to explain the output of several state-of-the-art models trained on the Five-K dataset, obtaining sequences of enhancing operators able to produce very similar results in terms of performance and overcoming the huge limitation of poor interpretability of the best performing algorithms.  
### BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring. (arXiv:2101.07518v3 [cs.CV] UPDATED)
- Authors : Jen Tsai, Tsung Peng, Yu Lin, Chi Tsai, Wen Lin
- Link : [http://arxiv.org/abs/2101.07518](http://arxiv.org/abs/2101.07518)
> ABSTRACT  :  Image motion blur usually results from moving objects or camera shakes. Such blur is generally directional and non-uniform. Previous research efforts attempt to solve non-uniform blur by using self-recurrent multi-scale or multi-patch architectures accompanying with self-attention. However, using self-recurrent frameworks typically leads to a longer inference time, while inter-pixel or inter-channel self-attention may cause excessive memory usage. This paper proposes blur-aware attention networks (BANet) that accomplish accurate and efficient deblurring via a single forward pass. Our BANet utilizes region-based self-attention with multi-kernel strip pooling to disentangle blur patterns of different degrees and with cascaded parallel dilated convolution to aggregate multi-scale content features. Extensive experimental results on the GoPro and HIDE benchmarks demonstrate that the proposed BANet performs favorably against the state-of-the-art in blurred image **restoration** and can provide deblurred results in real-time.  
### D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust **Night** Image **Restoration**. (arXiv:2207.03294v2 [cs.CV] UPDATED)
- Authors : Yuzhi Zhao, Yongzhe Xu, Qiong Yan, Dingdong Yang, Xuehui Wang, Man Po
- Link : [http://arxiv.org/abs/2207.03294](http://arxiv.org/abs/2207.03294)
> ABSTRACT  :  **Night** imaging with modern smartphone cameras is troublesome due to low photon count and unavoidable noise in the imaging system. Directly adjusting **exposure** time and ISO ratings cannot obtain sharp and noise-free images at the same time in **low-light** conditions. Though many methods have been proposed to enhance noisy or blurry **night** images, their performances on real-world **night** photos are still unsatisfactory due to two main reasons: 1) Limited information in a single image and 2) Domain gap between synthetic training images and real-world photos (e.g., differences in blur area and resolution). To exploit the information from successive long- and short-**exposure** images, we propose a learning-based pipeline to fuse them. A D2HNet framework is developed to recover a high-quality image by deblurring and enhancing a long-**exposure** image under the guidance of a short-**exposure** image. To shrink the domain gap, we leverage a two-phase DeblurNet-EnhanceNet architecture, which performs accurate blur removal on a fixed low resolution so that it is able to handle large ranges of blur in different resolution inputs. In addition, we synthesize a D2-Dataset from HD videos and experiment on it. The results on the validation set and real photos demonstrate our methods achieve better visual quality and state-of-the-art quantitative scores. The D2HNet codes and D2-Dataset can be found at https://github.com/zhaoyuzhi/D2HNet.  
## eess.IV
---
### Imaging through the Atmosphere using Turbulence Mitigation Transformer. (arXiv:2207.06465v1 [eess.IV])
- Authors : Xingguang Zhang, Zhiyuan Mao, Nicholas Chimitt
- Link : [http://arxiv.org/abs/2207.06465](http://arxiv.org/abs/2207.06465)
> ABSTRACT  :  Restoring images distorted by atmospheric turbulence is a long-standing problem due to the spatially varying nature of the distortion, nonlinearity of the image formation process, and scarcity of training and testing data. Existing methods often have strong statistical assumptions on the distortion model which in many cases will lead to a limited performance in real-world scenarios as they do not generalize. To overcome the challenge, this paper presents an end-to-end physics-driven approach that is efficient and can generalize to real-world turbulence. On the data synthesis front, we significantly increase the image resolution that can be handled by the SOTA turbulence simulator by approximating the random field via wide-sense stationarity. The new data synthesis process enables the generation of large-scale multi-level turbulence and ground truth pairs for training. On the network design front, we propose the turbulence mitigation transformer (TMT), a two stage U-Net shaped multi-frame **restoration** network which has a noval efficient self-attention mechanism named temporal channel joint attention (TCJA). We also introduce a new training scheme that is enabled by the new simulator, and we design new transformer units to reduce the memory consumption. Experimental results on both static and dynamic scenes are promising, including various real turbulence scenarios.  
### D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust **Night** Image **Restoration**. (arXiv:2207.03294v2 [cs.CV] UPDATED)
- Authors : Yuzhi Zhao, Yongzhe Xu, Qiong Yan, Dingdong Yang, Xuehui Wang, Man Po
- Link : [http://arxiv.org/abs/2207.03294](http://arxiv.org/abs/2207.03294)
> ABSTRACT  :  **Night** imaging with modern smartphone cameras is troublesome due to low photon count and unavoidable noise in the imaging system. Directly adjusting **exposure** time and ISO ratings cannot obtain sharp and noise-free images at the same time in **low-light** conditions. Though many methods have been proposed to enhance noisy or blurry **night** images, their performances on real-world **night** photos are still unsatisfactory due to two main reasons: 1) Limited information in a single image and 2) Domain gap between synthetic training images and real-world photos (e.g., differences in blur area and resolution). To exploit the information from successive long- and short-**exposure** images, we propose a learning-based pipeline to fuse them. A D2HNet framework is developed to recover a high-quality image by deblurring and enhancing a long-**exposure** image under the guidance of a short-**exposure** image. To shrink the domain gap, we leverage a two-phase DeblurNet-EnhanceNet architecture, which performs accurate blur removal on a fixed low resolution so that it is able to handle large ranges of blur in different resolution inputs. In addition, we synthesize a D2-Dataset from HD videos and experiment on it. The results on the validation set and real photos demonstrate our methods achieve better visual quality and state-of-the-art quantitative scores. The D2HNet codes and D2-Dataset can be found at https://github.com/zhaoyuzhi/D2HNet.  
## cs.LG
---
### Discovery of New Multi-Level Features for Domain Generalization via Knowledge Corruption. (arXiv:2109.04320v2 [cs.LG] UPDATED)
- Authors : Ahmed Frikha, Denis Krompa, Volker Tresp
- Link : [http://arxiv.org/abs/2109.04320](http://arxiv.org/abs/2109.04320)
> ABSTRACT  :  Machine learning models that can generalize to unseen domains are essential when applied in real-world scenarios involving strong domain shifts. We address the challenging domain generalization (DG) problem, where a model trained on a set of source domains is expected to generalize well in unseen domains without any **exposure** to their data. The main challenge of DG is that the features learned from the source domains are not necessarily present in the unseen target domains, leading to performance deterioration. We assume that learning a richer set of features is crucial to improve the transfer to a wider set of unknown domains. For this reason, we propose COLUMBUS, a method that enforces new feature discovery via a targeted corruption of the most relevant input and multi-level representations of the data. We conduct an extensive empirical evaluation to demonstrate the effectiveness of the proposed approach which achieves new state-of-the-art results by outperforming 18 DG algorithms on multiple DG benchmark datasets in the DomainBed framework.  
### Speech-enhanced and Noise-aware Networks for Robust Speech Recognition. (arXiv:2203.13696v2 [cs.SD] UPDATED)
- Authors : Shin Lee, Yuan Chen, Fei Cheng, Yu Tsao, Min Wang
- Link : [http://arxiv.org/abs/2203.13696](http://arxiv.org/abs/2203.13696)
> ABSTRACT  :  Compensation for channel mismatch and noise interference is essential for robust automatic speech recognition. Enhanced speech has been introduced into the multi-condition training of acoustic models to improve their generalization ability. In this paper, a noise-aware training framework based on two cascaded neural structures is proposed to jointly optimize speech **enhancement** and speech recognition. The feature **enhancement** module is composed of a multi-task autoencoder, where noisy speech is decomposed into clean speech and noise. By concatenating its enhanced, noise-aware, and noisy features for each frame, the acoustic-modeling module maps each feature-augmented frame into a triphone state by optimizing the lattice-free maximum mutual information and cross entropy between the predicted and actual state sequences. On top of the factorized time delay neural network (TDNN-F) and its convolutional variant (CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error rate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared with the best existing systems that use bigram and trigram language models for decoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction of 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based system also outperforms the baseline CNN-TDNNF system on the AMI task.  
## cs.AI
---
### Marvin: an Innovative Omni-Directional Robotic Assistant for Domestic Environments. (arXiv:2112.05597v3 [cs.RO] UPDATED)
- Authors : Andrea Eirale, Mauro Martini, Luigi Tagliavini, Dario Gandini, Marcello Chiaberge, Giuseppe Quaglia
- Link : [http://arxiv.org/abs/2112.05597](http://arxiv.org/abs/2112.05597)
> ABSTRACT  :  Population ageing and pandemics recently demonstrate to cause isolation of elderly people in their houses, generating the need for a reliable assistive figure. Robotic assistants are the new frontier of innovation for domestic welfare, and elderly monitoring is one of the services a robot can handle for collective well-being. Despite these emerging needs, in the actual landscape of robotic assistants there are no platform which successfully combines a reliable mobility in cluttered domestic spaces, with lightweight and offline Artificial Intelligence (AI) solutions for perception and interaction. In this work, we present Marvin, a novel assistive robotic platform we developed with a modular layer-based architecture, merging a flexible mechanical design with cutting-edge AI for perception and vocal control. We focus the design of Marvin on three target service functions: monitoring of elderly and reduced-mobility subjects, remote presence and connectivity, and **night** assistance. Compared to previous works, we propose a tiny omnidirectional platform, which enables agile mobility and effective obstacle avoidance. Moreover, we design a controllable positioning device, which easily allows the user to access the interface for connectivity and extends the visual range of the camera sensor. Nonetheless, we delicately consider the privacy issues arising from private data collection on cloud services, a critical aspect of commercial AI-based assistants. To this end, we demonstrate how lightweight deep learning solutions for visual perception and vocal command can be adopted, completely running offline on the embedded hardware of the robot.  
### Speech-enhanced and Noise-aware Networks for Robust Speech Recognition. (arXiv:2203.13696v2 [cs.SD] UPDATED)
- Authors : Shin Lee, Yuan Chen, Fei Cheng, Yu Tsao, Min Wang
- Link : [http://arxiv.org/abs/2203.13696](http://arxiv.org/abs/2203.13696)
> ABSTRACT  :  Compensation for channel mismatch and noise interference is essential for robust automatic speech recognition. Enhanced speech has been introduced into the multi-condition training of acoustic models to improve their generalization ability. In this paper, a noise-aware training framework based on two cascaded neural structures is proposed to jointly optimize speech **enhancement** and speech recognition. The feature **enhancement** module is composed of a multi-task autoencoder, where noisy speech is decomposed into clean speech and noise. By concatenating its enhanced, noise-aware, and noisy features for each frame, the acoustic-modeling module maps each feature-augmented frame into a triphone state by optimizing the lattice-free maximum mutual information and cross entropy between the predicted and actual state sequences. On top of the factorized time delay neural network (TDNN-F) and its convolutional variant (CNN-TDNNF), both with SpecAug, the two proposed systems achieve word error rate (WER) of 3.90% and 3.55%, respectively, on the Aurora-4 task. Compared with the best existing systems that use bigram and trigram language models for decoding, the proposed CNN-TDNNF-based system achieves a relative WER reduction of 15.20% and 33.53%, respectively. In addition, the proposed CNN-TDNNF-based system also outperforms the baseline CNN-TDNNF system on the AMI task.  
# Paper List
---
## cs.CV
---
**136** new papers in cs.CV:-) 
1. Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution. (arXiv:2207.06418v1 [eess.IV])
2. Graph CNN for Moving Object Detection in Complex Environments from Unseen Videos. (arXiv:2207.06440v1 [cs.CV])
3. Imaging through the Atmosphere using Turbulence Mitigation Transformer. (arXiv:2207.06465v1 [eess.IV])
4. Analysis of face detection, face landmarking, and face recognition performance with masked face images. (arXiv:2207.06478v1 [cs.CV])
5. Study on Image Filtering -- Techniques, Algorithm and Applications. (arXiv:2207.06481v1 [cs.CV])
6. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v1 [eess.IV])
7. One Model to Unite Them All: Personalized Federated Learning of Multi-Contrast MRI Synthesis. (arXiv:2207.06509v1 [eess.IV])
8. Lipschitz Continuity Retained Binary Neural Network. (arXiv:2207.06540v1 [cs.LG])
9. Body Composition Assessment with Limited Field-of-view Computed Tomography: A Semantic Image Extension Perspective. (arXiv:2207.06551v1 [eess.IV])
10. QML for Argoverse 2 Motion Forecasting Challenge. (arXiv:2207.06553v1 [cs.CV])
11. Supervised Attribute Information Removal and Reconstruction for Image Manipulation. (arXiv:2207.06555v1 [cs.CV])
12. Improving the diagnosis of breast cancer based on biophysical ultrasound features utilizing machine learning. (arXiv:2207.06560v1 [eess.IV])
13. Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting. (arXiv:2207.06569v1 [cs.LG])
14. Virtual stain transfer in histology via cascaded deep neural networks. (arXiv:2207.06578v1 [physics.med-ph])
15. Temporal Action Detection with Global Segmentation Mask Learning. (arXiv:2207.06580v1 [cs.CV])
16. Transformer-based Context Condensation for Boosting Feature Pyramids in Object Detection. (arXiv:2207.06603v1 [cs.CV])
17. Rethinking Super-Resolution as Text-Guided Details Generation. (arXiv:2207.06604v1 [cs.CV])
18. Deepfake Video Detection with Spatiotemporal Dropout Transformer. (arXiv:2207.06612v1 [cs.CV])
19. T-RECX: Tiny-Resource Efficient Convolutional Neural Networks with Early-Exit. (arXiv:2207.06613v1 [cs.LG])
20. Perception-Oriented Stereo Image Super-Resolution. (arXiv:2207.06617v1 [eess.IV])
21. Continuous Facial Motion Deblurring. (arXiv:2207.06626v1 [cs.CV])
22. EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations. (arXiv:2207.06635v1 [cs.CV])
23. Source-Free Domain Adaptation for Real-world Image Dehazing. (arXiv:2207.06644v1 [cs.CV])
24. Prototypical Contrast Adaptation for Domain Adaptive Semantic Segmentation. (arXiv:2207.06654v1 [cs.CV])
25. Exploration of an End-to-End Automatic Number-plate Recognition neural network for Indian datasets. (arXiv:2207.06657v1 [cs.CV])
26. Universal Adaptive Data Augmentation. (arXiv:2207.06658v1 [cs.CV])
27. Forcing the Whole Video as Background: An Adversarial Learning Strategy for Weakly Temporal Action Localization. (arXiv:2207.06659v1 [cs.CV])
28. Deep Point-to-Plane Registration by Efficient Backpropagation for Error Minimizing Function. (arXiv:2207.06661v1 [cs.CV])
29. Detecting Volunteer Cotton Plants in a Corn Field with Deep Learning on UAV Remote-Sensing Imagery. (arXiv:2207.06673v1 [cs.CV])
30. Subgraph Frequency Distribution Estimation using Graph Neural Networks. (arXiv:2207.06684v1 [cs.LG])
31. Dynamic Low-Resolution Distillation for Cost-Efficient End-to-End Text Spotting. (arXiv:2207.06694v1 [cs.CV])
32. DavarOCR: A Toolbox for OCR and Multi-Modal Document Understanding. (arXiv:2207.06695v1 [cs.CV])
33. SHREC 2022 Track on Online Detection of Heterogeneous Gestures. (arXiv:2207.06706v1 [cs.CV])
34. Octuplet Loss: Make Face Recognition Robust to Image Resolution. (arXiv:2207.06726v1 [cs.CV])
35. ConCL: Concept Contrastive Learning for Dense Prediction Pre-training in Pathology Images. (arXiv:2207.06733v1 [cs.CV])
36. Semi-supervised Vector-Quantization in Visual SLAM using HGCN. (arXiv:2207.06738v1 [cs.CV])
37. TRIE++: Towards End-to-End Information Extraction from Visually Rich Documents. (arXiv:2207.06744v1 [cs.CV])
38. Single-Pixel Image Reconstruction Based on Block Compressive Sensing and Deep Learning. (arXiv:2207.06746v1 [eess.IV])
39. E2-AEN: End-to-End Incremental Learning with Adaptively Expandable Network. (arXiv:2207.06754v1 [cs.CV])
40. Neighbor Correspondence Matching for Flow-based Video Frame Synthesis. (arXiv:2207.06763v1 [cs.CV])
41. GeoSegNet: Point Cloud Semantic Segmentation via Geometric Encoder-Decoder Modeling. (arXiv:2207.06766v1 [cs.CV])
42. An Empirical Evaluation of Four Off-the-Shelf Proprietary Visual-Inertial Odometry Systems. (arXiv:2207.06780v1 [cs.RO])
43. Inertial Hallucinations -- When Wearable Inertial Devices Start Seeing Things. (arXiv:2207.06789v1 [cs.CV])
44. Neural apparent BRDF fields for multiview photometric stereo. (arXiv:2207.06793v1 [cs.CV])
45. A Multi-Modality Ovarian Tumor Ultrasound Image Dataset for Unsupervised Cross-Domain Semantic Segmentation. (arXiv:2207.06799v1 [cs.CV])
46. Pseudo-Labeling Based Practical Semi-Supervised Meta-Training for Few-Shot Learning. (arXiv:2207.06817v1 [cs.CV])
47. DEXTER: An end-to-end system to extract table contents from electronic medical health documents. (arXiv:2207.06823v1 [cs.CV])
48. Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions. (arXiv:2207.06825v1 [cs.CV])
49. Point-to-Box Network for Accurate Object Detection via Single Point Supervision. (arXiv:2207.06827v1 [cs.CV])
50. Pose-based Tremor Classification for Parkinson's Disease Diagnosis from Video. (arXiv:2207.06828v1 [cs.CV])
51. iColoriT: Towards Propagating Local Hint to the Right Region in Interactive Colorization by Leveraging Vision Transformer. (arXiv:2207.06831v1 [cs.CV])
52. Enforcing connectivity of 3D linear structures using their 2D projections. (arXiv:2207.06832v1 [cs.CV])
53. Deep Dictionary Learning with An Intra-class Constraint. (arXiv:2207.06841v1 [cs.LG])
54. AIParsing: Anchor-free Instance-level Human Parsing. (arXiv:2207.06854v1 [cs.CV])
55. Immunofluorescence Capillary Imaging Segmentation: Cases Study. (arXiv:2207.06861v1 [eess.IV])
56. BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks. (arXiv:2207.06873v1 [cs.CV])
57. E2FIF: Push the limit of Binarized Deep Imagery Super-resolution using End-to-end Full-precision Information Flow. (arXiv:2207.06893v1 [cs.CV])
58. Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation. (arXiv:2207.06899v1 [cs.CV])
59. **Real-time** Streaming Video Denoising with Bidirectional Buffers. (arXiv:2207.06937v1 [cs.CV])
60. Insurgency as Complex Network: Image Co-Appearance and Hierarchy in the PKK. (arXiv:2207.06946v1 [cs.SI])
61. Tackling Background Distraction in Video Object Segmentation. (arXiv:2207.06953v1 [cs.CV])
62. Learning Implicit Templates for Point-Based Clothed Human Modeling. (arXiv:2207.06955v1 [cs.CV])
63. AutoMerge: A Framework for Map Assembling and Smoothing in City-scale Environments. (arXiv:2207.06965v1 [cs.RO])
64. Scene Text Recognition with Permuted Autoregressive Sequence Models. (arXiv:2207.06966v1 [cs.CV])
65. PR-DARTS: Pruning-Based Differentiable Architecture Search. (arXiv:2207.06968v1 [cs.CV])
66. Learning Discriminative Representation via Metric Learning for Imbalanced Medical Image Classification. (arXiv:2207.06975v1 [cs.CV])
67. ObjectBox: From Centers to Boxes for Anchor-Free Object Detection. (arXiv:2207.06985v1 [cs.CV])
68. Tree Structure-Aware Few-Shot Image Classification via Hierarchical Aggregation. (arXiv:2207.06989v1 [cs.CV])
69. Language Modelling with Pixels. (arXiv:2207.06991v1 [cs.CL])
70. Accurate Ground-Truth Depth Image Generation via Overfit Training of Point Cloud Registration using Local Frame Sets. (arXiv:2207.07016v1 [cs.CV])
71. MedFuse: Multi-modal fusion with clinical time-series data and chest X-ray images. (arXiv:2207.07027v1 [eess.IV])
72. Adversarial Attacks on Monocular Pose Estimation. (arXiv:2207.07032v1 [cs.CV])
73. A Single Self-Supervised Model for Many Speech Modalities Enables Zero-Shot Modality Transfer. (arXiv:2207.07036v1 [cs.CL])
74. Convolutional Bypasses Are Better Vision Transformer Adapters. (arXiv:2207.07039v1 [cs.CV])
75. Semi-Supervised Temporal Action Detection with Proposal-Free Masking. (arXiv:2207.07059v1 [cs.CV])
76. Egocentric Scene Understanding via Multimodal Spatial Rectifier. (arXiv:2207.07077v1 [cs.CV])
77. Towards Grand Unification of Object Tracking. (arXiv:2207.07078v1 [cs.CV])
78. An Asymmetric Contrastive Loss for Handling Imbalanced Datasets. (arXiv:2207.07080v1 [cs.LG])
79. A Personalized Zero-Shot ECG Arrhythmia Monitoring System: From Sparse Representation Based Domain Adaption to Energy Efficient Abnormal Beat Detection for Practical ECG Surveillance. (arXiv:2207.07089v1 [cs.LG])
80. Explaining Image **Enhancement** Black-Box Methods through a Path Planning Based Algorithm. (arXiv:2207.07092v1 [cs.CV])
81. ReAct: Temporal Action Detection with Relational Queries. (arXiv:2207.07097v1 [cs.CV])
82. Relighting4D: Neural Relightable Human from Videos. (arXiv:2207.07104v1 [cs.CV])
83. Benchmarking Omni-Vision Representation through the Lens of Visual Realms. (arXiv:2207.07106v1 [cs.CV])
84. Fine-grained Few-shot Recognition by Deep Object Parsing. (arXiv:2207.07110v1 [cs.CV])
85. XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model. (arXiv:2207.07115v1 [cs.CV])
86. Bootstrapped Masked Autoencoders for Vision BERT Pretraining. (arXiv:2207.07116v1 [cs.CV])
87. A Novel Implementation of Machine Learning for the Efficient, Explainable Diagnosis of COVID-19 from Chest CT. (arXiv:2207.07117v1 [eess.IV])
88. Unsupervised Deep Epipolar Flow for Stationary or Dynamic Scenes. (arXiv:1904.03848v2 [cs.CV] UPDATED)
89. Surface Normal Estimation of Tilted Images via Spatial Rectifier. (arXiv:2007.09264v2 [cs.CV] UPDATED)
90. RGB-D Salient Object Detection: A Survey. (arXiv:2008.00230v4 [cs.CV] UPDATED)
91. BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring. (arXiv:2101.07518v3 [cs.CV] UPDATED)
92. Blurs Behave Like Ensembles: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness. (arXiv:2105.12639v4 [cs.LG] UPDATED)
93. Continual Contrastive Learning for Image Classification. (arXiv:2107.01776v3 [cs.CV] UPDATED)
94. FOCUS: Familiar Objects in Common and Uncommon Settings. (arXiv:2110.03804v2 [cs.CV] UPDATED)
95. Wide Neural Networks Forget Less Catastrophically. (arXiv:2110.11526v3 [cs.LG] UPDATED)
96. Class-agnostic Object Detection with Multi-modal Transformer. (arXiv:2111.11430v4 [cs.CV] UPDATED)
97. Graph Modularity: Towards Understanding the Cross-Layer Transition of Feature Representations in Deep Neural Networks. (arXiv:2111.12485v2 [cs.CV] UPDATED)
98. Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval. (arXiv:2112.01832v2 [cs.MM] UPDATED)
99. Data-Free Neural Architecture Search via Recursive Label Calibration. (arXiv:2112.02086v2 [cs.LG] UPDATED)
100. Adaptive Feature Interpolation for Low-Shot Image Generation. (arXiv:2112.02450v3 [cs.CV] UPDATED)
101. Pose2Room: Understanding 3D Scenes from Human Activities. (arXiv:2112.03030v2 [cs.RO] UPDATED)
102. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v4 [eess.IV] UPDATED)
103. Improving the Behaviour of Vision Transformers with Token-consistent Stochastic Layers. (arXiv:2112.15111v3 [cs.CV] UPDATED)
104. Iterative training of robust k-space interpolation networks for improved image reconstruction with limited scan specific training samples. (arXiv:2201.03560v2 [eess.IV] UPDATED)
105. HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning. (arXiv:2201.04182v3 [cs.LG] UPDATED)
106. Contrastive Pretraining for Echocardiography Segmentation with Limited Data. (arXiv:2201.07219v3 [eess.IV] UPDATED)
107. Enhancing variational generation through self-decomposition. (arXiv:2202.02738v2 [cs.CV] UPDATED)
108. Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?. (arXiv:2202.06675v2 [cs.AI] UPDATED)
109. CAR: Class-aware Regularizations for Semantic Segmentation. (arXiv:2203.07160v2 [cs.CV] UPDATED)
110. Animatable Implicit Neural Representations for Creating Realistic Avatars from Videos. (arXiv:2203.08133v2 [cs.CV] UPDATED)
111. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v5 [cs.CV] UPDATED)
112. End-to-End Video Text Spotting with Transformer. (arXiv:2203.10539v2 [cs.CV] UPDATED)
113. Spatially Multi-conditional Image Generation. (arXiv:2203.13812v2 [cs.CV] UPDATED)
114. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v3 [eess.IV] UPDATED)
115. Deep Unlearning via Randomized Conditionally Independent Hessians. (arXiv:2204.07655v2 [cs.CV] UPDATED)
116. MMRotate: A Rotated Object Detection Benchmark using Pytorch. (arXiv:2204.13317v3 [cs.CV] UPDATED)
117. Privacy Preserving Image Registration. (arXiv:2205.10120v4 [cs.CV] UPDATED)
118. Superclass Adversarial Attack. (arXiv:2205.14629v2 [cs.CV] UPDATED)
119. Strongly Augmented Contrastive Clustering. (arXiv:2206.00380v2 [cs.LG] UPDATED)
120. Cross-Modal Transformer GAN: A Brain Structure-Function Deep Fusing Framework for Alzheimer's Disease. (arXiv:2206.13393v2 [eess.IV] UPDATED)
121. On-Device Training Under 256KB Memory. (arXiv:2206.15472v2 [cs.CV] UPDATED)
122. Detection of ADHD based on Eye Movements during Natural Viewing. (arXiv:2207.01377v5 [cs.CV] UPDATED)
123. Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising. (arXiv:2207.02377v2 [eess.IV] UPDATED)
124. What Makes for Automatic Reconstruction of Pulmonary Segments. (arXiv:2207.03078v3 [eess.IV] UPDATED)
125. D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust **Night** Image **Restoration**. (arXiv:2207.03294v2 [cs.CV] UPDATED)
126. A simple normalization technique using window statistics to improve the out-of-distribution generalization on medical images. (arXiv:2207.03366v2 [cs.CV] UPDATED)
127. Direct Handheld Burst Imaging to Simulated Defocus. (arXiv:2207.04175v2 [cs.CV] UPDATED)
128. Radiomics-Guided Global-Local Transformer for Weakly Supervised Pathology Localization in Chest X-Rays. (arXiv:2207.04394v3 [cs.CV] UPDATED)
129. A Waste Copper Granules Rating System Based on Machine Vision. (arXiv:2207.04575v2 [cs.CV] UPDATED)
130. Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v3 [cs.LG] UPDATED)
131. Enhancing Fairness of Visual Attribute Predictors. (arXiv:2207.05727v2 [cs.CV] UPDATED)
132. Collaborative Quantization Embeddings for Intra-Subject Prostate MR Image Registration. (arXiv:2207.06189v2 [eess.IV] UPDATED)
133. Adversarially-Aware Robust Object Detector. (arXiv:2207.06202v2 [cs.CV] UPDATED)
134. Entry-Flipped Transformer for Inference and Prediction of Participant Behavior. (arXiv:2207.06235v2 [cs.CV] UPDATED)
135. Organic Priors in Non-Rigid Structure from Motion. (arXiv:2207.06262v2 [cs.CV] UPDATED)
136. Towards Adaptive Unknown Authentication for Universal Domain Adaptation by Classifier Paradox. (arXiv:2207.04494v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**31** new papers in eess.IV:-) 
1. MorphoActivation: Generalizing ReLU activation function by mathematical morphology. (arXiv:2207.06413v1 [cs.LG])
2. Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution. (arXiv:2207.06418v1 [eess.IV])
3. Imaging through the Atmosphere using Turbulence Mitigation Transformer. (arXiv:2207.06465v1 [eess.IV])
4. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v1 [eess.IV])
5. One Model to Unite Them All: Personalized Federated Learning of Multi-Contrast MRI Synthesis. (arXiv:2207.06509v1 [eess.IV])
6. A Deep Learning-Based GPR Forward Solver for Predicting B-Scans of Subsurface Objects. (arXiv:2207.06527v1 [eess.IV])
7. High-fidelity intensity diffraction tomography with a non-paraxial multiple-scattering model. (arXiv:2207.06532v1 [physics.optics])
8. Body Composition Assessment with Limited Field-of-view Computed Tomography: A Semantic Image Extension Perspective. (arXiv:2207.06551v1 [eess.IV])
9. Improving the diagnosis of breast cancer based on biophysical ultrasound features utilizing machine learning. (arXiv:2207.06560v1 [eess.IV])
10. Virtual stain transfer in histology via cascaded deep neural networks. (arXiv:2207.06578v1 [physics.med-ph])
11. T-RECX: Tiny-Resource Efficient Convolutional Neural Networks with Early-Exit. (arXiv:2207.06613v1 [cs.LG])
12. Perception-Oriented Stereo Image Super-Resolution. (arXiv:2207.06617v1 [eess.IV])
13. Single-Pixel Image Reconstruction Based on Block Compressive Sensing and Deep Learning. (arXiv:2207.06746v1 [eess.IV])
14. Adaptive joint spatio-temporal error concealment for video communication. (arXiv:2207.06794v1 [eess.IV])
15. Multiple Selection Extrapolation for Improved Spatial Error Concealment. (arXiv:2207.06795v1 [eess.IV])
16. Adaptive frequency prior for frequency selective reconstruction of images from non-regular subsampling. (arXiv:2207.06797v1 [eess.IV])
17. Immunofluorescence Capillary Imaging Segmentation: Cases Study. (arXiv:2207.06861v1 [eess.IV])
18. MedFuse: Multi-modal fusion with clinical time-series data and chest X-ray images. (arXiv:2207.07027v1 [eess.IV])
19. A Single Self-Supervised Model for Many Speech Modalities Enables Zero-Shot Modality Transfer. (arXiv:2207.07036v1 [cs.CL])
20. A Novel Implementation of Machine Learning for the Efficient, Explainable Diagnosis of COVID-19 from Chest CT. (arXiv:2207.07117v1 [eess.IV])
21. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v4 [eess.IV] UPDATED)
22. Iterative training of robust k-space interpolation networks for improved image reconstruction with limited scan specific training samples. (arXiv:2201.03560v2 [eess.IV] UPDATED)
23. Contrastive Pretraining for Echocardiography Segmentation with Limited Data. (arXiv:2201.07219v3 [eess.IV] UPDATED)
24. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v3 [eess.IV] UPDATED)
25. Deep learning-augmented Computational Miniature Mesoscope. (arXiv:2205.00123v2 [physics.optics] UPDATED)
26. Privacy Preserving Image Registration. (arXiv:2205.10120v4 [cs.CV] UPDATED)
27. Cross-Modal Transformer GAN: A Brain Structure-Function Deep Fusing Framework for Alzheimer's Disease. (arXiv:2206.13393v2 [eess.IV] UPDATED)
28. Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising. (arXiv:2207.02377v2 [eess.IV] UPDATED)
29. What Makes for Automatic Reconstruction of Pulmonary Segments. (arXiv:2207.03078v3 [eess.IV] UPDATED)
30. D2HNet: Joint Denoising and Deblurring with Hierarchical Network for Robust **Night** Image **Restoration**. (arXiv:2207.03294v2 [cs.CV] UPDATED)
31. Collaborative Quantization Embeddings for Intra-Subject Prostate MR Image Registration. (arXiv:2207.06189v2 [eess.IV] UPDATED)
## cs.LG
---
**169** new papers in cs.LG:-) 
1. ECG beat classification using machine learning and pre-trained convolutional neural networks. (arXiv:2207.06408v1 [eess.SP])
2. Changepoint Detection for Real-Time Spectrum Sharing Radar. (arXiv:2207.06409v1 [eess.SY])
3. MDEAW: A Multimodal Dataset for Emotion Analysis through EDA and PPG signals from wireless wearable low-cost off-the-shelf Devices. (arXiv:2207.06410v1 [cs.HC])
4. RobustAnalog: Fast Variation-Aware Analog Circuit Design Via Multi-task RL. (arXiv:2207.06412v1 [cs.ET])
5. MorphoActivation: Generalizing ReLU activation function by mathematical morphology. (arXiv:2207.06413v1 [cs.LG])
6. Modeling Long-term Dependencies and Short-term Correlations in Patient Journey Data with Temporal Attention Networks for Health Prediction. (arXiv:2207.06414v1 [cs.LG])
7. The Free Energy Principle for Perception and Action: A Deep Learning Perspective. (arXiv:2207.06415v1 [cs.LG])
8. Collaborative Machine Learning-Driven Internet of Medical Things -- A Systematic Literature Review. (arXiv:2207.06416v1 [cs.LG])
9. Open High-Resolution Satellite Imagery: The WorldStrat Dataset -- With Application to Super-Resolution. (arXiv:2207.06418v1 [eess.IV])
10. Deep Learning Discovery of Demographic Biomarkers in Echocardiography. (arXiv:2207.06421v1 [cs.LG])
11. Wakeword Detection under Distribution Shifts. (arXiv:2207.06423v1 [cs.SD])
12. Graph Neural Network Bandits. (arXiv:2207.06456v1 [cs.LG])
13. Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime. (arXiv:2207.06475v1 [cs.LG])
14. Dynamically handling task disruptions by composing together behavior modules. (arXiv:2207.06482v1 [cs.LG])
15. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v1 [eess.IV])
16. A Robustly Optimized Long Text to Math Models for Numerical Reasoning On FinQA. (arXiv:2207.06490v1 [cs.CL])
17. One Model to Unite Them All: Personalized Federated Learning of Multi-Contrast MRI Synthesis. (arXiv:2207.06509v1 [eess.IV])
18. A Generalized Framework for Microstructural Optimization using Neural Networks. (arXiv:2207.06512v1 [cond-mat.mtrl-sci])
19. Estimating Classification Confidence Using Kernel Densities. (arXiv:2207.06529v1 [stat.ML])
20. Reachability Analysis of a General Class of Neural Ordinary Differential Equations. (arXiv:2207.06531v1 [cs.LG])
21. Lipschitz Continuity Retained Binary Neural Network. (arXiv:2207.06540v1 [cs.LG])
22. Self-Play PSRO: Toward Optimal Populations in Two-Player Zero-Sum Games. (arXiv:2207.06541v1 [cs.GT])
23. CoSCL: Cooperation of Small Continual Learners is Stronger than a Big One. (arXiv:2207.06543v1 [cs.LG])
24. Volatility Based Kernels and Moving Average Means for Accurate Forecasting with Gaussian Processes. (arXiv:2207.06544v1 [cs.LG])
25. Fully Decentralized Model-based Policy Optimization for Networked Systems. (arXiv:2207.06559v1 [cs.LG])
26. Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting. (arXiv:2207.06569v1 [cs.LG])
27. Virtual stain transfer in histology via cascaded deep neural networks. (arXiv:2207.06578v1 [physics.med-ph])
28. Soil Erosion in the United States. Present and Future (2020-2050). (arXiv:2207.06579v1 [physics.ao-ph])
29. Temporal Action Detection with Global Segmentation Mask Learning. (arXiv:2207.06580v1 [cs.CV])
30. Near-Optimal Bounds for Testing Histogram Distributions. (arXiv:2207.06596v1 [cs.DS])
31. T-RECX: Tiny-Resource Efficient Convolutional Neural Networks with Early-Exit. (arXiv:2207.06613v1 [cs.LG])
32. Antibody-Antigen Docking and Design via Hierarchical Equivariant Refinement. (arXiv:2207.06616v1 [q-bio.BM])
33. Identifying Orientation-specific Lipid-protein Fingerprints using Deep Learning. (arXiv:2207.06630v1 [q-bio.BM])
34. DropNet: Reducing Neural Network Complexity via Iterative Pruning. (arXiv:2207.06646v1 [cs.LG])
35. PIAT: Physics Informed Adversarial Training for Solving Partial Differential Equations. (arXiv:2207.06647v1 [cs.LG])
36. Have we been Naive to Select Machine Learning Models? Noisy Data are here to Stay!. (arXiv:2207.06651v1 [cs.LG])
37. Every Preference Changes Differently: Neural Multi-Interest Preference Model with Temporal Dynamics for Recommendation. (arXiv:2207.06652v1 [cs.IR])
38. Large-scale Knowledge Distillation with Elastic Heterogeneous Computing Resources. (arXiv:2207.06667v1 [cs.DC])
39. A Meta-learning Formulation of the Autoencoder Problem. (arXiv:2207.06676v1 [cs.LG])
40. Deep Learning Methods for Protein Family Classification on PDB Sequencing Data. (arXiv:2207.06678v1 [q-bio.QM])
41. Learning to Prove Trigonometric Identities. (arXiv:2207.06679v1 [cs.LG])
42. Equivariant Hypergraph Diffusion Neural Operators. (arXiv:2207.06680v1 [cs.LG])
43. Subgraph Frequency Distribution Estimation using Graph Neural Networks. (arXiv:2207.06684v1 [cs.LG])
44. Improved OOD Generalization via Conditional Invariant Regularizer. (arXiv:2207.06687v1 [cs.LG])
45. problexity -- an open-source Python library for binary classification problem complexity assessment. (arXiv:2207.06709v1 [cs.LG])
46. Differentiable Logics for Neural Network Training and Verification. (arXiv:2207.06741v1 [cs.AI])
47. Verification of Sigmoidal Artificial Neural Networks using iSAT. (arXiv:2207.06755v1 [cs.AI])
48. Work In Progress: Safety and Robustness Verification of Autoencoder-Based Regression Models using the NNV Tool. (arXiv:2207.06759v1 [cs.LG])
49. Semi-supervised cross-lingual speech emotion recognition. (arXiv:2207.06767v1 [cs.SD])
50. Strain-Minimizing Hyperbolic Network Embeddings with Landmarks. (arXiv:2207.06775v1 [stat.CO])
51. GrabQC: Graph based Query Contextualization for automated ICD coding. (arXiv:2207.06802v1 [cs.LG])
52. In-memory Realization of In-situ Few-shot Continual Learning with a Dynamically Evolving Explicit Memory. (arXiv:2207.06810v1 [cs.LG])
53. Comparing the latent space of generative models. (arXiv:2207.06812v1 [cs.LG])
54. Anomal-E: A Self-Supervised Network Intrusion Detection System based on Graph Neural Networks. (arXiv:2207.06819v1 [cs.LG])
55. Pose-based Tremor Classification for Parkinson's Disease Diagnosis from Video. (arXiv:2207.06828v1 [cs.CV])
56. Instance Selection Mechanisms for Human-in-the-Loop Systems in Few-Shot Learning. (arXiv:2207.06835v1 [cs.LG])
57. Deep Dictionary Learning with An Intra-class Constraint. (arXiv:2207.06841v1 [cs.LG])
58. Low-Precision Arithmetic for Fast Gaussian Processes. (arXiv:2207.06856v1 [cs.LG])
59. RSD-GAN: Regularized Sobolev Defense GAN Against Speech-to-Text Adversarial Attacks. (arXiv:2207.06858v1 [cs.SD])
60. Recurrent Memory Transformer. (arXiv:2207.06881v1 [cs.CL])
61. Multilinguals at SemEval-2022 Task 11: Complex NER in Semantically Ambiguous Settings for Low Resource Languages. (arXiv:2207.06882v1 [cs.CL])
62. Frequency-Encoded Deep Learning with Speed-of-Light Dominated Latency. (arXiv:2207.06883v1 [cs.ET])
63. Distance Learner: Incorporating Manifold Prior to Model Training. (arXiv:2207.06888v1 [cs.LG])
64. Adaptive Attitude Estimation Using a Hybrid Model-Learning Approach. (arXiv:2207.06903v1 [eess.SP])
65. Attention mechanisms for physiological signal deep learning: which attention should we take?. (arXiv:2207.06904v1 [eess.SP])
66. Improving self-supervised pretraining models for epileptic seizure detection from EEG data. (arXiv:2207.06911v1 [eess.SP])
67. An Investigation on Non-Invasive Brain-Computer Interfaces: Emotiv Epoc+ Neuroheadset and Its Effectiveness. (arXiv:2207.06914v1 [eess.SP])
68. Online Bayesian Meta-Learning for Cognitive Tracking Radar. (arXiv:2207.06917v1 [cs.IT])
69. Interference-Limited Ultra-Reliable and Low-Latency Communications: Graph Neural Networks or Stochastic Geometry?. (arXiv:2207.06918v1 [eess.SP])
70. Sub 8-Bit Quantization of Streaming Keyword Spotting Models for Embedded Chipsets. (arXiv:2207.06920v1 [cs.SD])
71. Pediatric Sleep Scoring In-the-wild from Millions of Multi-channel EEG Signals. (arXiv:2207.06921v1 [eess.SP])
72. Learning Representations for CSI Adaptive Quantization and Feedback. (arXiv:2207.06924v1 [eess.SP])
73. Multi-Level Branched Regularization for Federated Learning. (arXiv:2207.06936v1 [cs.LG])
74. PASHA: Efficient HPO with Progressive Resource Allocation. (arXiv:2207.06940v1 [cs.LG])
75. Differentially Private Graph Learning via Sensitivity-Bounded Personalized PageRank. (arXiv:2207.06944v1 [cs.CR])
76. Insurgency as Complex Network: Image Co-Appearance and Hierarchy in the PKK. (arXiv:2207.06946v1 [cs.SI])
77. Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v1 [stat.ML])
78. Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models. (arXiv:2207.06950v1 [stat.ML])
79. Proceedings of the ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts. (arXiv:2207.06958v1 [cs.SD])
80. Spatiotemporal Propagation Learning for Network-Wide Flight Delay Prediction. (arXiv:2207.06959v1 [cs.LG])
81. Forming Trees with Treeformers. (arXiv:2207.06960v1 [cs.CL])
82. Multitrack Music Transformer: Learning Long-Term Dependencies in Music with Diverse Instruments. (arXiv:2207.06983v1 [cs.SD])
83. Language Modelling with Pixels. (arXiv:2207.06991v1 [cs.CL])
84. AutoML-Based Drought Forecast with Meteorological Variables. (arXiv:2207.07012v1 [cs.LG])
85. Detecting People Interested in Non-Suicidal Self-Injury on Social Media. (arXiv:2207.07014v1 [cs.SI])
86. MedFuse: Multi-modal fusion with clinical time-series data and chest X-ray images. (arXiv:2207.07027v1 [eess.IV])
87. Early Detection of Ovarian Cancer by Wavelet Analysis of Protein Mass Spectra. (arXiv:2207.07028v1 [cs.LG])
88. From Shapley back to Pearson: Hypothesis Testing via the Shapley Value. (arXiv:2207.07038v1 [cs.LG])
89. Leakage and the Reproducibility Crisis in ML-based Science. (arXiv:2207.07048v1 [cs.LG])
90. How do tuna schools associate to dFADs? A study using echo-sounder buoys to identify global patterns. (arXiv:2207.07049v1 [stat.ML])
91. Language models show human-like content effects on reasoning. (arXiv:2207.07051v1 [cs.CL])
92. Semi-Supervised Temporal Action Detection with Proposal-Free Masking. (arXiv:2207.07059v1 [cs.CV])
93. Confident Adaptive Language Modeling. (arXiv:2207.07061v1 [cs.CL])
94. On the Strong Correlation Between Model Invariance and Generalization. (arXiv:2207.07065v1 [cs.LG])
95. Bia Mitigation for Machine Learning Classifiers: A Comprehensive Survey. (arXiv:2207.07068v1 [cs.LG])
96. A Query-Optimal Algorithm for Finding Counterfactuals. (arXiv:2207.07072v1 [cs.DS])
97. An Asymmetric Contrastive Loss for Handling Imbalanced Datasets. (arXiv:2207.07080v1 [cs.LG])
98. Parameter-Efficient Prompt Tuning Makes Generalized and Calibrated Neural Text Retrievers. (arXiv:2207.07087v1 [cs.CL])
99. A Personalized Zero-Shot ECG Arrhythmia Monitoring System: From Sparse Representation Based Domain Adaption to Energy Efficient Abnormal Beat Detection for Practical ECG Surveillance. (arXiv:2207.07089v1 [cs.LG])
100. Continuous-time Analysis for Variational Inequalities: An Overview and Desiderata. (arXiv:2207.07105v1 [stat.ML])
101. Bootstrapped Masked Autoencoders for Vision BERT Pretraining. (arXiv:2207.07116v1 [cs.CV])
102. A Novel Implementation of Machine Learning for the Efficient, Explainable Diagnosis of COVID-19 from Chest CT. (arXiv:2207.07117v1 [eess.IV])
103. Noise-Stable Rigid Graphs for Euclidean Embedding. (arXiv:1907.06441v5 [cs.CG] UPDATED)
104. A Bayesian Lasso based Sparse Learning Model. (arXiv:1908.07220v3 [stat.ML] UPDATED)
105. Musical Instrument Classification via Low-Dimensional Feature Vectors. (arXiv:1909.08444v2 [cs.SD] UPDATED)
106. Neural Networks for Encoding Dynamic Security-Constrained Optimal Power Flow. (arXiv:2003.07939v5 [eess.SY] UPDATED)
107. A survey on domain adaptation theory: learning bounds and theoretical guarantees. (arXiv:2004.11829v6 [cs.LG] UPDATED)
108. Fixing Inventory Inaccuracies At Scale. (arXiv:2006.13126v3 [stat.ML] UPDATED)
109. Several Approximation Algorithms for Sparse Best Rank-1 Approximation to Higher-Order Tensors. (arXiv:2012.03092v2 [math.NA] UPDATED)
110. Auto-weighted Robust Federated Learning with Corrupted Data Sources. (arXiv:2101.05880v3 [cs.LG] UPDATED)
111. Low-skilled Occupations Face the Highest Re-skilling Pressure. (arXiv:2101.11505v2 [cs.CY] UPDATED)
112. DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck. (arXiv:2102.13268v4 [cs.AI] UPDATED)
113. Robot Program Parameter Inference via Differentiable Shadow Program Inversion. (arXiv:2103.14452v2 [cs.RO] UPDATED)
114. Blurs Behave Like Ensembles: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness. (arXiv:2105.12639v4 [cs.LG] UPDATED)
115. Estimating Instance-dependent Bayes-label Transition Matrix using a Deep Neural Network. (arXiv:2105.13001v3 [cs.LG] UPDATED)
116. Contextual Inverse Optimization: Offline and Online Learning. (arXiv:2106.14015v2 [cs.LG] UPDATED)
117. A comparison of latent semantic analysis and correspondence analysis of document-term matrices. (arXiv:2108.06197v3 [cs.IR] UPDATED)
118. Rethinking Multidimensional Discriminator Output for Generative Adversarial Networks. (arXiv:2109.03378v3 [stat.ML] UPDATED)
119. Discovery of New Multi-Level Features for Domain Generalization via Knowledge Corruption. (arXiv:2109.04320v2 [cs.LG] UPDATED)
120. Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Primal-Dual Approach. (arXiv:2109.06332v3 [cs.LG] UPDATED)
121. FOCUS: Familiar Objects in Common and Uncommon Settings. (arXiv:2110.03804v2 [cs.CV] UPDATED)
122. Ranking and Tuning Pre-trained Models: A New Paradigm for Exploiting Model Hubs. (arXiv:2110.10545v4 [cs.LG] UPDATED)
123. Likelihood Training of Schr\"odinger Bridge using Forward-Backward SDEs Theory. (arXiv:2110.11291v4 [stat.ML] UPDATED)
124. Wide Neural Networks Forget Less Catastrophically. (arXiv:2110.11526v3 [cs.LG] UPDATED)
125. Interpretable Decision Trees Through MaxSAT. (arXiv:2110.13854v2 [cs.AI] UPDATED)
126. Graph Modularity: Towards Understanding the Cross-Layer Transition of Feature Representations in Deep Neural Networks. (arXiv:2111.12485v2 [cs.CV] UPDATED)
127. Data-Free Neural Architecture Search via Recursive Label Calibration. (arXiv:2112.02086v2 [cs.LG] UPDATED)
128. Mirror Learning: A Unifying Framework of Policy Optimisation. (arXiv:2201.02373v10 [cs.LG] UPDATED)
129. A Unified Granular-ball Learning Model of Pawlak Rough Set and Neighborhood Rough Set. (arXiv:2201.03349v4 [cs.AI] UPDATED)
130. Iterative training of robust k-space interpolation networks for improved image reconstruction with limited scan specific training samples. (arXiv:2201.03560v2 [eess.IV] UPDATED)
131. HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning. (arXiv:2201.04182v3 [cs.LG] UPDATED)
132. Contrastive Pretraining for Echocardiography Segmentation with Limited Data. (arXiv:2201.07219v3 [eess.IV] UPDATED)
133. Bayesian Inference with Nonlinear Generative Models: Comments on Secure Learning. (arXiv:2201.09986v3 [cs.IT] UPDATED)
134. Improved Certified Defenses against Data Poisoning with (Deterministic) Finite Aggregation. (arXiv:2202.02628v3 [cs.LG] UPDATED)
135. Adversarial Graph Contrastive Learning with Information Regularization. (arXiv:2202.06491v4 [cs.LG] UPDATED)
136. Learning to Detect Slip with Barometric Tactile Sensors and a Temporal Convolutional Neural Network. (arXiv:2202.09549v2 [cs.RO] UPDATED)
137. Combating Distribution Shift for Accurate Time Series Forecasting via Hypernetworks. (arXiv:2202.10808v2 [cs.LG] UPDATED)
138. Closing the Loop: A Framework for Trustworthy Machine Learning in Power Systems. (arXiv:2203.07505v2 [eess.SY] UPDATED)
139. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v5 [cs.CV] UPDATED)
140. Improving Meta-learning for Low-resource Text Classification and Generation via Memory Imitation. (arXiv:2203.11670v2 [cs.CL] UPDATED)
141. Speech-enhanced and Noise-aware Networks for Robust Speech Recognition. (arXiv:2203.13696v2 [cs.SD] UPDATED)
142. Hypergraphon Mean Field Games. (arXiv:2203.16223v2 [cs.GT] UPDATED)
143. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v3 [eess.IV] UPDATED)
144. Perfectly Balanced: Improving Transfer and Robustness of Supervised Contrastive Learning. (arXiv:2204.07596v2 [stat.ML] UPDATED)
145. Deep Unlearning via Randomized Conditionally Independent Hessians. (arXiv:2204.07655v2 [cs.CV] UPDATED)
146. Protein 3D structure-based neural networks highly improve the accuracy in compound-protein binding affinity prediction. (arXiv:2204.12586v2 [q-bio.BM] UPDATED)
147. Learning to Parallelize in a Shared-Memory Environment with Transformers. (arXiv:2204.12835v4 [cs.DC] UPDATED)
148. Regotron: Regularizing the Tacotron2 architecture via monotonic alignment loss. (arXiv:2204.13437v2 [cs.SD] UPDATED)
149. AGIC: Approximate Gradient Inversion Attack on Federated Learning. (arXiv:2204.13784v3 [cs.LG] UPDATED)
150. Evaluating Multimodal Interactive Agents. (arXiv:2205.13274v2 [cs.LG] UPDATED)
151. Strongly Augmented Contrastive Clustering. (arXiv:2206.00380v2 [cs.LG] UPDATED)
152. In Defense of Core-set: A Density-aware Core-set Selection for Active Learning. (arXiv:2206.04838v3 [cs.LG] UPDATED)
153. A Spatio-Temporal Neural Network Forecasting Approach for Emulation of Firefront Models. (arXiv:2206.08523v3 [cs.LG] UPDATED)
154. Motley: Benchmarking Heterogeneity and Personalization in Federated Learning. (arXiv:2206.09262v4 [cs.LG] UPDATED)
155. Epicasting: An Ensemble Wavelet Neural Network (EWNet) for Forecasting Epidemics. (arXiv:2206.10696v2 [cs.LG] UPDATED)
156. Learning Optimal Treatment Strategies for Sepsis Using Offline Reinforcement Learning in Continuous Space. (arXiv:2206.11190v2 [cs.LG] UPDATED)
157. Set Norm and Equivariant Skip Connections: Putting the Deep in Deep Sets. (arXiv:2206.11925v2 [cs.LG] UPDATED)
158. On the Limitations of Elo: Real-World Games, are Transitive, not Additive. (arXiv:2206.12301v2 [cs.GT] UPDATED)
159. HyGNN: Drug-Drug Interaction Prediction via Hypergraph Neural Network. (arXiv:2206.12747v2 [q-bio.QM] UPDATED)
160. Cross-Modal Transformer GAN: A Brain Structure-Function Deep Fusing Framework for Alzheimer's Disease. (arXiv:2206.13393v2 [eess.IV] UPDATED)
161. Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods. (arXiv:2207.02829v2 [math.OC] UPDATED)
162. Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v3 [cs.LG] UPDATED)
163. Improved Binary Forward Exploration: Learning Rate Scheduling Method for Stochastic Optimization. (arXiv:2207.04198v2 [cs.LG] UPDATED)
164. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v2 [cs.CL] UPDATED)
165. Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v3 [cs.LG] UPDATED)
166. Unsupervised Learning for Combinatorial Optimization with Principled Objective Relaxation. (arXiv:2207.05984v2 [cs.LG] UPDATED)
167. Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel Test Environments. (arXiv:2207.05991v2 [cs.LG] UPDATED)
168. DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting. (arXiv:2207.06046v2 [cs.LG] UPDATED)
169. Towards Adaptive Unknown Authentication for Universal Domain Adaptation by Classifier Paradox. (arXiv:2207.04494v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**87** new papers in cs.AI:-) 
1. MDEAW: A Multimodal Dataset for Emotion Analysis through EDA and PPG signals from wireless wearable low-cost off-the-shelf Devices. (arXiv:2207.06410v1 [cs.HC])
2. RobustAnalog: Fast Variation-Aware Analog Circuit Design Via Multi-task RL. (arXiv:2207.06412v1 [cs.ET])
3. Modeling Long-term Dependencies and Short-term Correlations in Patient Journey Data with Temporal Attention Networks for Health Prediction. (arXiv:2207.06414v1 [cs.LG])
4. The Free Energy Principle for Perception and Action: A Deep Learning Perspective. (arXiv:2207.06415v1 [cs.LG])
5. Deep Learning Discovery of Demographic Biomarkers in Echocardiography. (arXiv:2207.06421v1 [cs.LG])
6. Wakeword Detection under Distribution Shifts. (arXiv:2207.06423v1 [cs.SD])
7. Graph Neural Network Bandits. (arXiv:2207.06456v1 [cs.LG])
8. Quantum Metropolis Solver: A Quantum Walks Approach to Optimization Problems. (arXiv:2207.06462v1 [quant-ph])
9. Analysis of Catastrophic Forgetting for Random Orthogonal Transformation Tasks in the Overparameterized Regime. (arXiv:2207.06475v1 [cs.LG])
10. A Robustly Optimized Long Text to Math Models for Numerical Reasoning On FinQA. (arXiv:2207.06490v1 [cs.CL])
11. Approximate Nash Equilibrium Learning for n-Player Markov Games in Dynamic Pricing. (arXiv:2207.06492v1 [cs.GT])
12. Scheduling Out-of-Coverage Vehicular Communications Using Reinforcement Learning. (arXiv:2207.06537v1 [cs.NI])
13. CoSCL: Cooperation of Small Continual Learners is Stronger than a Big One. (arXiv:2207.06543v1 [cs.LG])
14. Fully Decentralized Model-based Policy Optimization for Networked Systems. (arXiv:2207.06559v1 [cs.LG])
15. Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting. (arXiv:2207.06569v1 [cs.LG])
16. Temporal Action Detection with Global Segmentation Mask Learning. (arXiv:2207.06580v1 [cs.CV])
17. A tool to overcome technical barriers for bias assessment in human language technologies. (arXiv:2207.06591v1 [cs.CL])
18. Few-Shot Specific Emitter Identification via Deep Metric Ensemble Learning. (arXiv:2207.06592v1 [eess.SP])
19. Deepfake Video Detection with Spatiotemporal Dropout Transformer. (arXiv:2207.06612v1 [cs.CV])
20. Source-Free Domain Adaptation for Real-world Image Dehazing. (arXiv:2207.06644v1 [cs.CV])
21. DropNet: Reducing Neural Network Complexity via Iterative Pruning. (arXiv:2207.06646v1 [cs.LG])
22. Every Preference Changes Differently: Neural Multi-Interest Preference Model with Temporal Dynamics for Recommendation. (arXiv:2207.06652v1 [cs.IR])
23. Golden Reference-Free Hardware Trojan Localization using Graph Convolutional Network. (arXiv:2207.06664v1 [cs.CY])
24. Large-scale Knowledge Distillation with Elastic Heterogeneous Computing Resources. (arXiv:2207.06667v1 [cs.DC])
25. Detecting Volunteer Cotton Plants in a Corn Field with Deep Learning on UAV Remote-Sensing Imagery. (arXiv:2207.06673v1 [cs.CV])
26. Reinforced Path Reasoning for Counterfactual Explainable Recommendation. (arXiv:2207.06674v1 [cs.IR])
27. Learning to Prove Trigonometric Identities. (arXiv:2207.06679v1 [cs.LG])
28. Subgraph Frequency Distribution Estimation using Graph Neural Networks. (arXiv:2207.06684v1 [cs.LG])
29. Differentiable Logics for Neural Network Training and Verification. (arXiv:2207.06741v1 [cs.AI])
30. Verification of Sigmoidal Artificial Neural Networks using iSAT. (arXiv:2207.06755v1 [cs.AI])
31. Work In Progress: Safety and Robustness Verification of Autoencoder-Based Regression Models using the NNV Tool. (arXiv:2207.06759v1 [cs.LG])
32. Semi-supervised cross-lingual speech emotion recognition. (arXiv:2207.06767v1 [cs.SD])
33. BERTIN: Efficient Pre-Training of a Spanish Language Model using Perplexity Sampling. (arXiv:2207.06814v1 [cs.CL])
34. Anomal-E: A Self-Supervised Network Intrusion Detection System based on Graph Neural Networks. (arXiv:2207.06819v1 [cs.LG])
35. Covy: An AI-powered Robot for Detection of Breaches in Social Distancing. (arXiv:2207.06847v1 [cs.RO])
36. BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks. (arXiv:2207.06873v1 [cs.CV])
37. Multilinguals at SemEval-2022 Task 11: Complex NER in Semantically Ambiguous Settings for Low Resource Languages. (arXiv:2207.06882v1 [cs.CL])
38. Distance Learner: Incorporating Manifold Prior to Model Training. (arXiv:2207.06888v1 [cs.LG])
39. Attention mechanisms for physiological signal deep learning: which attention should we take?. (arXiv:2207.06904v1 [eess.SP])
40. An Investigation on Non-Invasive Brain-Computer Interfaces: Emotiv Epoc+ Neuroheadset and Its Effectiveness. (arXiv:2207.06914v1 [eess.SP])
41. Insurgency as Complex Network: Image Co-Appearance and Hierarchy in the PKK. (arXiv:2207.06946v1 [cs.SI])
42. Spatiotemporal Propagation Learning for Network-Wide Flight Delay Prediction. (arXiv:2207.06959v1 [cs.LG])
43. Forming Trees with Treeformers. (arXiv:2207.06960v1 [cs.CL])
44. Multitrack Music Transformer: Learning Long-Term Dependencies in Music with Diverse Instruments. (arXiv:2207.06983v1 [cs.SD])
45. Language Modelling with Pixels. (arXiv:2207.06991v1 [cs.CL])
46. Learning to translate by learning to communicate. (arXiv:2207.07025v1 [cs.CL])
47. Adversarial Attacks on Monocular Pose Estimation. (arXiv:2207.07032v1 [cs.CV])
48. Developing a Series of AI Challenges for the United States Department of the Air Force. (arXiv:2207.07033v1 [cs.AI])
49. A Single Self-Supervised Model for Many Speech Modalities Enables Zero-Shot Modality Transfer. (arXiv:2207.07036v1 [cs.CL])
50. Leakage and the Reproducibility Crisis in ML-based Science. (arXiv:2207.07048v1 [cs.LG])
51. Language models show human-like content effects on reasoning. (arXiv:2207.07051v1 [cs.CL])
52. Semi-Supervised Temporal Action Detection with Proposal-Free Masking. (arXiv:2207.07059v1 [cs.CV])
53. Egocentric Scene Understanding via Multimodal Spatial Rectifier. (arXiv:2207.07077v1 [cs.CV])
54. ReAct: Temporal Action Detection with Relational Queries. (arXiv:2207.07097v1 [cs.CV])
55. Fine-grained Few-shot Recognition by Deep Object Parsing. (arXiv:2207.07110v1 [cs.CV])
56. Auto-weighted Robust Federated Learning with Corrupted Data Sources. (arXiv:2101.05880v3 [cs.LG] UPDATED)
57. DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck. (arXiv:2102.13268v4 [cs.AI] UPDATED)
58. Robot Program Parameter Inference via Differentiable Shadow Program Inversion. (arXiv:2103.14452v2 [cs.RO] UPDATED)
59. Blurs Behave Like Ensembles: Spatial Smoothings to Improve Accuracy, Uncertainty, and Robustness. (arXiv:2105.12639v4 [cs.LG] UPDATED)
60. Continual Contrastive Learning for Image Classification. (arXiv:2107.01776v3 [cs.CV] UPDATED)
61. Off-line approximate dynamic programming for the vehicle routing problem with a highly variable customer basis and stochastic demands. (arXiv:2109.10200v2 [math.OC] UPDATED)
62. Wide Neural Networks Forget Less Catastrophically. (arXiv:2110.11526v3 [cs.LG] UPDATED)
63. Interpretable Decision Trees Through MaxSAT. (arXiv:2110.13854v2 [cs.AI] UPDATED)
64. Big Data Testing Techniques: Taxonomy, Challenges and Future Trends. (arXiv:2111.02853v4 [cs.AI] UPDATED)
65. Doxastic Extensions of \L ukasiewicz Logic. (arXiv:2111.08564v2 [cs.LO] UPDATED)
66. Data-Free Neural Architecture Search via Recursive Label Calibration. (arXiv:2112.02086v2 [cs.LG] UPDATED)
67. Marvin: an Innovative Omni-Directional Robotic Assistant for Domestic Environments. (arXiv:2112.05597v3 [cs.RO] UPDATED)
68. Mirror Learning: A Unifying Framework of Policy Optimisation. (arXiv:2201.02373v10 [cs.LG] UPDATED)
69. A Unified Granular-ball Learning Model of Pawlak Rough Set and Neighborhood Rough Set. (arXiv:2201.03349v4 [cs.AI] UPDATED)
70. Can Machines Help Us Answering Question 16 in Datasheets, and In Turn Reflecting on Inappropriate Content?. (arXiv:2202.06675v2 [cs.AI] UPDATED)
71. Combating Distribution Shift for Accurate Time Series Forecasting via Hypernetworks. (arXiv:2202.10808v2 [cs.LG] UPDATED)
72. End-to-End Video Text Spotting with Transformer. (arXiv:2203.10539v2 [cs.CV] UPDATED)
73. RILI: Robustly Influencing Latent Intent. (arXiv:2203.12705v2 [cs.RO] UPDATED)
74. Speech-enhanced and Noise-aware Networks for Robust Speech Recognition. (arXiv:2203.13696v2 [cs.SD] UPDATED)
75. MMRotate: A Rotated Object Detection Benchmark using Pytorch. (arXiv:2204.13317v3 [cs.CV] UPDATED)
76. Privacy Preserving Image Registration. (arXiv:2205.10120v4 [cs.CV] UPDATED)
77. Non-Parametric Domain Adaptation for End-to-End Speech Translation. (arXiv:2205.11211v4 [cs.CL] UPDATED)
78. Evaluating Multimodal Interactive Agents. (arXiv:2205.13274v2 [cs.LG] UPDATED)
79. In Defense of Core-set: A Density-aware Core-set Selection for Active Learning. (arXiv:2206.04838v3 [cs.LG] UPDATED)
80. Learning Optimal Treatment Strategies for Sepsis Using Offline Reinforcement Learning in Continuous Space. (arXiv:2206.11190v2 [cs.LG] UPDATED)
81. HyGNN: Drug-Drug Interaction Prediction via Hypergraph Neural Network. (arXiv:2206.12747v2 [q-bio.QM] UPDATED)
82. Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v3 [cs.LG] UPDATED)
83. Sequential Manipulation Planning on Scene Graph. (arXiv:2207.04364v3 [cs.RO] UPDATED)
84. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v2 [cs.CL] UPDATED)
85. Reward-Sharing Relational Networks in Multi-Agent Reinforcement Learning as a Framework for Emergent Behavior. (arXiv:2207.05886v2 [cs.AI] UPDATED)
86. Brick Tic-Tac-Toe: Exploring the Generalizability of AlphaZero to Novel Test Environments. (arXiv:2207.05991v2 [cs.LG] UPDATED)
87. DeepTIMe: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting. (arXiv:2207.06046v2 [cs.LG] UPDATED)

