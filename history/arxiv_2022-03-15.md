# Your interest papers
---
## cs.CV
---
### Semi-supervised classification of medical ultrasound images based on generative adversarial network. (arXiv:2203.06184v1 [eess.IV])
- Authors : Zhaoshan Liu, Chau Hung, Lei Shen
- Link : [http://arxiv.org/abs/2203.06184](http://arxiv.org/abs/2203.06184)
> ABSTRACT  :  Medical ultrasound (US) is one of the most widely used imaging modalities in clinical practice. However, its use presents unique challenges such as variable imaging quality. Deep learning (DL) can be used as an advanced medical US images analysis tool, while the performance of the DL model is greatly limited by the scarcity of big datasets. Here, we develop semi-supervised classification **enhancement** (SSCE) structures by constructing seven convolutional neural network (CNN) models and one of the most state-of-the-art generative adversarial network (GAN) models, StyleGAN2-ADA, to address this problem. A breast cancer dataset with 780 images is used as our base dataset. The results show that our SSCE structures obtain an accuracy of up to 97.9%, showing a maximum 21.6% improvement compared with utilizing CNN models alone and outperforming the previous methods using the same dataset by up to 23.9%. We believe our proposed state-of-the-art method can be regarded as a potential auxiliary tool for on-the-fly diagnoses of medical US images.  
### MISF: Multi-level Interactive Siamese Filtering for High-Fidelity Image Inpainting. (arXiv:2203.06304v1 [cs.CV])
- Authors : Xiaoguang Li, Qing Guo, Di Lin, Ping Li, Wei Feng, Song Wang
- Link : [http://arxiv.org/abs/2203.06304](http://arxiv.org/abs/2203.06304)
> ABSTRACT  :  Although achieving significant progress, existing deep generative inpainting methods are far from real-world applications due to the low generalization across different scenes. As a result, the generated images usually contain artifacts or the filled pixels differ greatly from the ground truth. Image-level predictive filtering is a widely used image **restoration** technique, predicting suitable kernels adaptively according to different input scenes. Inspired by this inherent advantage, we explore the possibility of addressing image inpainting as a filtering task. To this end, we first study the advantages and challenges of image-level predictive filtering for image inpainting: the method can preserve local structures and avoid artifacts but fails to fill large missing areas. Then, we propose semantic filtering by conducting filtering on the deep feature level, which fills the missing semantic information but fails to recover the details. To address the issues while adopting the respective advantages, we propose a novel filtering technique, i.e., Multilevel Interactive Siamese Filtering (MISF), which contains two branches: kernel prediction branch (KPB) and semantic &amp; image filtering branch (SIFB). These two branches are interactively linked: SIFB provides multi-level features for KPB while KPB predicts dynamic kernels for SIFB. As a result, the final method takes the advantage of effective semantic &amp; image-level filling for high-fidelity inpainting. We validate our method on three challenging datasets, i.e., Dunhuang, Places2, and CelebA. Our method outperforms state-of-the-art baselines on four metrics, i.e., L1, PSNR, SSIM, and LPIPS. Please try the released code and model at https://github.com/tsingqguo/misf.  
### One-stage Video Instance Segmentation: From Frame-in Frame-out to Clip-in Clip-out. (arXiv:2203.06421v1 [cs.CV])
- Authors : Minghan Li, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.06421](http://arxiv.org/abs/2203.06421)
> ABSTRACT  :  Many video instance segmentation (VIS) methods partition a video sequence into individual frames to detect and segment objects frame by frame. However, such a frame-in frame-out (FiFo) pipeline is ineffective to exploit the temporal information. Based on the fact that adjacent frames in a short clip are highly coherent in content, we propose to extend the one-stage FiFo framework to a clip-in clip-out (CiCo) one, which performs VIS clip by clip. Specifically, we stack FPN features of all frames in a short video clip to build a spatio-temporal feature cube, and replace the 2D conv layers in the prediction heads and the mask branch with 3D conv layers, forming clip-level prediction heads (CPH) and clip-level mask heads (CMH). Then the clip-level masks of an instance can be generated by feeding its box-level predictions from CPH and clip-level features from CMH into a small fully convolutional network. A clip-level segmentation loss is proposed to ensure that the generated instance masks are temporally coherent in the clip. The proposed CiCo strategy is free of inter-frame alignment, and can be easily embedded into existing FiFo based VIS approaches. To validate the generality and effectiveness of our CiCo strategy, we apply it to two representative FiFo methods, Yolact \cite{bolya2019yolact} and CondInst \cite{tian2020conditional}, resulting in two new one-stage VIS models, namely CiCo-Yolact and CiCo-CondInst, which achieve 37.1/37.3\%, 35.2/35.4\% and 17.2/18.0\% mask AP using the ResNet50 backbone, and 41.8/41.4\%, 38.0/38.9\% and 18.0/18.2\% mask AP using the **Swin** Transformer tiny backbone on YouTube-VIS 2019, 2021 and OVIS valid sets, respectively, recording new state-of-the-arts. Code and video demos of CiCo can be found at \url{https://github.com/MinghanLi/CiCo}.  
### DFTR: Depth-supervised Hierarchical Feature Fusion Transformer for Salient Object Detection. (arXiv:2203.06429v1 [cs.CV])
- Authors : Heqin Zhu, Xu Sun, Yuexiang Li, Kai Ma, Kevin Zhou, Yefeng Zheng
- Link : [http://arxiv.org/abs/2203.06429](http://arxiv.org/abs/2203.06429)
> ABSTRACT  :  Automated salient object detection (SOD) plays an increasingly crucial role in many computer vision applications. Although existing frameworks achieve impressive SOD performances especially with the development of deep learning techniques, their performances still have room for improvement. In this work, we propose a novel pure Transformer-based SOD framework, namely Depth-supervised hierarchical feature Fusion TRansformer (DFTR), to further improve the accuracy of both RGB and RGB-D SOD. The proposed DFTR involves three primary improvements: 1) The backbone of feature encoder is switched from a convolutional neural network to a **Swin** Transformer for more effective feature extraction; 2) We propose a multi-scale feature aggregation (MFA) module to fully exploit the multi-scale features encoded by the **Swin** Transformer in a coarse-to-fine manner; 3) Following recent studies, we formulate an auxiliary task of depth map prediction and use the ground-truth depth maps as extra supervision signals for network learning. To enable bidirectional information flow between saliency and depth branches, a novel multi-task feature fusion (MFF) module is integrated into our DFTR. We extensively evaluate the proposed DFTR on ten benchmarking datasets. Experimental results show that our DFTR consistently outperforms the existing state-of-the-art methods for both RGB and RGB-D SOD tasks. The code and model will be released.  
### Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
- Authors : Frederic Madesta, Thilo Sentker, Tobias Gauer, Rene Werner
- Link : [http://arxiv.org/abs/2203.06431](http://arxiv.org/abs/2203.06431)
> ABSTRACT  :  4D CT imaging is an essential component of radiotherapy of thoracic/abdominal tumors. 4D CT images are, however, often affected by artifacts that compromise treatment planning quality. In this work, deep learning (DL)-based conditional inpainting is proposed to restore anatomically correct image information of artifact-affected areas. The **restoration** approach consists of a two-stage process: DL-based detection of common interpolation (INT) and double structure (DS) artifacts, followed by conditional inpainting applied to the artifact areas. In this context, conditional refers to a guidance of the inpainting process by patient-specific image data to ensure anatomically reliable results. Evaluation is based on 65 in-house 4D CT data sets of lung cancer patients (48 with only slight artifacts, 17 with pronounced artifacts) and the publicly available DIRLab 4D CT data (independent external test set). Automated artifact detection revealed a ROC-AUC of 0.99 for INT and 0.97 for DS artifacts (in-house data). The proposed inpainting method decreased the average root mean squared error (RMSE) by 60% (DS) and 42% (INT) for the in-house evaluation data (simulated artifacts for the slight artifact data; original data were considered as ground truth for RMSE computation). For the external DIR-Lab data, the RMSE decreased by 65% and 36%, respectively. Applied to the pronounced artifact data group, on average 68% of the detectable artifacts were removed. The results highlight the potential of DL-based inpainting for the **restoration** of artifact-affected 4D CT data. Improved performance of conditional inpainting (compared to standard inpainting) illustrates the benefits of exploiting patient-specific prior knowledge.  
### Bringing Rolling Shutter Images Alive with Dual Reversed Distortion. (arXiv:2203.06451v1 [cs.CV])
- Authors : Zhihang Zhong, Mingdeng Cao, Xiao Sun, Zhirong Wu, Zhongyi Zhou, Yinqiang Zheng, Stephen Lin, Imari Sato
- Link : [http://arxiv.org/abs/2203.06451](http://arxiv.org/abs/2203.06451)
> ABSTRACT  :  Rolling shutter (RS) distortion can be interpreted as the result of picking a row of pixels from instant global shutter (GS) frames over time during the **exposure** of the RS camera. This means that the information of each instant GS frame is partially, yet sequentially, embedded into the row-dependent distortion. Inspired by this fact, we address the challenging task of reversing this process, i.e., extracting undistorted GS frames from images suffering from RS distortion. However, since RS distortion is coupled with other factors such as readout settings and the relative velocity of scene elements to the camera, models that only exploit the geometric correlation between temporally adjacent images suffer from poor generality in processing data with different readout settings and dynamic scenes with both camera motion and object motion. In this paper, instead of two consecutive frames, we propose to exploit a pair of images captured by dual RS cameras with reversed RS directions for this highly challenging task. Grounded on the symmetric and complementary nature of dual reversed distortion, we develop a novel end-to-end model, IFED, to generate dual optical flow sequence through iterative learning of the velocity field during the RS time. Extensive experimental results demonstrate that IFED is superior to naive cascade schemes, as well as the state-of-the-art which utilizes adjacent RS images. Most importantly, although it is trained on a synthetic dataset, IFED is shown to be effective at retrieving GS frame sequences from real-world RS distorted images of dynamic scenes.  
### A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
- Authors : Paulo Ricardo, Lisboa de, Jeovane Hon, rio Alves, Rafael Stubs, Jean Paul
- Link : [http://arxiv.org/abs/2203.06463](http://arxiv.org/abs/2203.06463)
> ABSTRACT  :  Computer vision-based parking lot management methods have been extensively researched upon owing to their flexibility and cost-effectiveness. To evaluate such methods authors often employ publicly available parking lot image datasets. In this study, we surveyed and compared robust publicly available image datasets specifically crafted to test computer vision-based methods for parking lot management approaches and consequently present a systematic and comprehensive review of existing works that employ such datasets. The literature review identified relevant gaps that require further research, such as the requirement of dataset-independent approaches and methods suitable for autonomous detection of position of parking spaces. In addition, we have noticed that several important factors such as the presence of the same cars across consecutive images, have been neglected in most studies, thereby rendering unrealistic assessment protocols. Furthermore, the analysis of the datasets also revealed that certain features that should be present when developing new benchmarks, such as the availability of video sequences and images taken in more diverse conditions, including **night**time and snow, have not been incorporated.  
### A Mixed Quantization Network for Computationally Efficient Mobile Inverse Tone Mapping. (arXiv:2203.06504v1 [cs.CV])
- Authors : Juan Borrego, Mete Ozay, Frederik Laboyrie, Paul Wisbey
- Link : [http://arxiv.org/abs/2203.06504](http://arxiv.org/abs/2203.06504)
> ABSTRACT  :  Recovering a **high dynamic range** (**HDR**) image from a single low dynamic range (LDR) image, namely inverse tone mapping (ITM), is challenging due to the lack of information in over- and under-exposed regions. Current methods focus exclusively on training high-performing but computationally inefficient ITM models, which in turn hinder deployment of the ITM models in resource-constrained environments with limited computing power such as edge and mobile device applications.    To this end, we propose combining efficient operations of deep neural networks with a novel mixed quantization scheme to construct a well-performing but computationally efficient mixed quantization network (MQN) which can perform single image ITM on mobile platforms. In the ablation studies, we explore the effect of using different attention mechanisms, quantization schemes, and loss functions on the performance of MQN in ITM tasks. In the comparative analyses, ITM models trained using MQN perform on par with the state-of-the-art methods on benchmark datasets. MQN models provide up to 10 times improvement on latency and 25 times improvement on memory consumption.  
### CVFNet: **Real-time** 3D Object Detection by Learning Cross View Features. (arXiv:2203.06585v1 [cs.CV])
- Authors : Jiaqi Gu, Zhiyu Xiang, Pan Zhao, Tingming Bai, Lingxuan Wang, Zhiyuan Zhang
- Link : [http://arxiv.org/abs/2203.06585](http://arxiv.org/abs/2203.06585)
> ABSTRACT  :  In recent years 3D object detection from LiDAR point clouds has made great progress thanks to the development of deep learning technologies. Although voxel or point based methods are popular in 3D object detection, they usually involve time-consuming operations such as 3D convolutions on voxels or ball query among points, making the resulting network inappropriate for time critical applications. On the other hand, 2D view-based methods feature high computing efficiency while usually obtaining inferior performance than the voxel or point based methods. In this work, we present a real-time view-based single stage 3D object detector, namely CVFNet to fulfill this task. To strengthen the cross-view feature learning under the condition of demanding efficiency, our framework extracts the features of different views and fuses them in an efficient progressive way. We first propose a novel Point-Range feature fusion module that deeply integrates point and range view features in multiple stages. Then, a special Slice Pillar is designed to well maintain the 3D geometry when transforming the obtained deep point-view features into bird's eye view. To better balance the ratio of samples, a sparse pillar detection head is presented to focus the detection on the nonempty grids. We conduct experiments on the popular KITTI and NuScenes benchmark, and state-of-the-art performances are achieved in terms of both accuracy and speed.  
### Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v1 [cs.CV])
- Authors : Nico Messikommer, Stamatios Georgoulis, Daniel Gehrig, Stepan Tulyakov, Julius Erbach, Alfredo Bochicchio, Yuanyou Li, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.06622](http://arxiv.org/abs/2203.06622)
> ABSTRACT  :  Modern **high dynamic range** (**HDR**) imaging pipelines align and fuse multiple low dynamic range (LDR) images captured at different **exposure** times. While these methods work well in static scenes, dynamic scenes remain a challenge since the LDR images still suffer from saturation and noise. In such scenarios, event cameras would be a valid complement, thanks to their higher temporal resolution and dynamic range. In this paper, we propose the first multi-bracket **HDR** pipeline combining a standard camera with an event camera. Our results show better overall robustness when using events, with improvements in PSNR by up to 5dB on synthetic data and up to 0.7dB on real-world data. We also introduce a new dataset containing bracketed LDR images with aligned events and **HDR** ground truth.  
### Efficient Long-Range Attention Network for Image Super-resolution. (arXiv:2203.06697v1 [cs.CV])
- Authors : Xindong Zhang, Hui Zeng, Shi Guo, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.06697](http://arxiv.org/abs/2203.06697)
> ABSTRACT  :  Recently, transformer-based methods have demonstrated impressive results in various vision tasks, including image super-resolution (SR), by exploiting the self-attention (SA) for feature extraction. However, the computation of SA in most existing transformer based models is very expensive, while some employed operations may be redundant for the SR task. This limits the range of SA computation and consequently the SR performance. In this work, we propose an efficient long-range attention network (ELAN) for image SR. Specifically, we first employ shift convolution (shift-conv) to effectively extract the image local structural information while maintaining the same level of complexity as 1x1 convolution, then propose a group-wise multi-scale self-attention (GMSA) module, which calculates SA on non-overlapped groups of features using different window sizes to exploit the long-range image dependency. A highly efficient long-range attention block (ELAB) is then built by simply cascading two shift-conv with a GMSA module, which is further accelerated by using a shared attention mechanism. Without bells and whistles, our ELAN follows a fairly simple design by sequentially cascading the ELABs. Extensive experiments demonstrate that ELAN obtains even better results against the transformer-based SR models but with significantly less complexity. The source code can be found at https://github.com/xindongzhang/ELAN.  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  In this paper we revisit large kernel design in modern convolutional neural networks (CNNs), which is often neglected in the past few years. Inspired by recent advances of vision transformers (ViTs), we point out that using a few large kernels instead of a stack of small convolutions could be a more powerful paradigm. We therefore summarize 5 guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31. RepLKNet greatly bridges the performance gap between CNNs and ViTs, e.g., achieving comparable or better results than **Swin** Transformer on ImageNet and downstream tasks, while the latency of RepLKNet is much lower. Moreover, RepLKNet also shows feasible scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0%} mIoU on ADE20K. At last, our study further suggests large-kernel CNNs share several nice properties with ViTs, e.g., much larger effective receptive fields than conventional CNNs, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
### Underwater Image **Enhancement** via Learning Water Type Desensitized Representations. (arXiv:2102.00676v2 [cs.CV] UPDATED)
- Authors : Zhenqi Fu, Xiaopeng Lin, Wu Wang, Yue Huang, Xinghao Ding
- Link : [http://arxiv.org/abs/2102.00676](http://arxiv.org/abs/2102.00676)
> ABSTRACT  :  We present a novel underwater image **enhancement** method termed SCNet to improve the image quality meanwhile cope with the degradation diversity caused by the water. SCNet is based on normalization schemes across both spatial and channel dimensions with the key idea of learning water type desensitized features. Specifically, we apply whitening to de-correlate activations across spatial dimensions for each instance in a mini-batch. We also eliminate channel-wise correlation by standardizing and re-injecting the first two moments of the activations across channels. The normalization schemes of spatial and channel dimensions are performed at each scale of the U-Net to obtain multi-scale representations. With such water type irrelevant encodings, the decoder can easily reconstruct the clean signal and be unaffected by the distortion types. Experimental results on two real-world underwater image datasets show that our approach can successfully enhance images with diverse water types, and achieves competitive performance in visual quality improvement.  
### Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
- Authors : Jeff Clune, Nick Cheney
- Link : [http://arxiv.org/abs/2108.12056](http://arxiv.org/abs/2108.12056)
> ABSTRACT  :  Existing machines are functionally specific tools that were made for easy prediction and control. Tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. But first they must be capable of learning, and retaining, new information without repeated **exposure** to it. Past efforts to engineer such systems have sought to build or regulate artificial neural networks using task-specific modules with constrained circumstances of application. This has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. In this paper, we introduce a system that can learn sequentially over previously unseen datasets (ImageNet, CIFAR-100) with little forgetting over time. This is accomplished by regulating the activity of weights in a convolutional neural network on the basis of inputs using top-down modulation generated by a second feed-forward neural network. We find that our method learns continually under domain transfer with sparse bursts of activity in weights that are recycled across tasks, rather than by maintaining task-specific modules. Sparse synaptic bursting is found to balance enhanced and diminished activity in a way that facilitates adaptation to new inputs without corrupting previously acquired functions. This behavior emerges during a prior meta-learning phase in which regulated synapses are selectively disinhibited, or grown, from an initial state of uniform suppression.  
### Unpaired Deep Image Deraining Using Dual Contrastive Learning. (arXiv:2109.02973v3 [cs.CV] UPDATED)
- Authors : Xiang Chen, Jinshan Pan, Kui Jiang, Yufeng Li, Yufeng Huang, Caihua Kong, Longgang Dai, Zhentao Fan
- Link : [http://arxiv.org/abs/2109.02973](http://arxiv.org/abs/2109.02973)
> ABSTRACT  :  Learning single image deraining (SID) networks from an unpaired set of clean and rainy images is practical and valuable as acquiring paired real-world data is almost infeasible. However, without the paired data as the supervision, learning a SID network is challenging. Moreover, simply using existing unpaired learning methods (e.g., unpaired adversarial learning and cycle-consistency constraints) in the SID task is insufficient to learn the underlying relationship from rainy inputs to clean outputs as there exists significant domain gap between the rainy and clean images. In this paper, we develop an effective unpaired SID adversarial framework which explores mutual properties of the unpaired exemplars by a dual contrastive learning manner in a deep feature space, named as DCD-GAN. The proposed method mainly consists of two cooperative branches: Bidirectional Translation Branch (BTB) and Contrastive Guidance Branch (CGB). Specifically, BTB exploits full advantage of the circulatory architecture of adversarial consistency to generate abundant exemplar pairs and excavates latent feature distributions between two domains by equipping it with bidirectional mapping. Simultaneously, CGB implicitly constrains the embeddings of different exemplars in the deep feature space by encouraging the similar feature distributions closer while pushing the dissimilar further away, in order to better facilitate rain removal and help image **restoration**. Extensive experiments demonstrate that our method performs favorably against existing unpaired deraining approaches on both synthetic and real-world datasets, and generates comparable results against several fully-supervised or semi-supervised models.  
### Language as Queries for Referring Video Object Segmentation. (arXiv:2201.00487v2 [cs.CV] UPDATED)
- Authors : Jiannan Wu, Yi Jiang, Peize Sun, Zehuan Yuan, Ping Luo
- Link : [http://arxiv.org/abs/2201.00487](http://arxiv.org/abs/2201.00487)
> ABSTRACT  :  Referring video object segmentation (R-VOS) is an emerging cross-modal task that aims to segment the target object referred by a language expression in all video frames. In this work, we propose a simple and unified framework built upon Transformer, termed ReferFormer. It views the language as queries and directly attends to the most relevant regions in the video frames. Concretely, we introduce a small set of object queries conditioned on the language as the input to the Transformer. In this manner, all the queries are obligated to find the referred objects only. They are eventually transformed into dynamic kernels which capture the crucial object-level information, and play the role of convolution filters to generate the segmentation masks from feature maps. The object tracking is achieved naturally by linking the corresponding queries across frames. This mechanism greatly simplifies the pipeline and the end-to-end framework is significantly different from the previous methods. Extensive experiments on Ref-Youtube-VOS, Ref-DAVIS17, A2D-Sentences and JHMDB-Sentences show the effectiveness of ReferFormer. On Ref-Youtube-VOS, Refer-Former achieves 55.6J&amp;F with a ResNet-50 backbone without bells and whistles, which exceeds the previous state-of-the-art performance by 8.4 points. In addition, with the strong **Swin**-Large backbone, ReferFormer achieves the best J&amp;F of 64.2 among all existing methods. Moreover, we show the impressive results of 55.0 mAP and 43.7 mAP on A2D-Sentences andJHMDB-Sentences respectively, which significantly outperforms the previous methods by a large margin. Code is publicly available at https://github.com/wjn922/ReferFormer.  
### ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification. (arXiv:2202.07570v2 [cs.CV] UPDATED)
- Authors : Thomas Stegm, Behzad Bozorgtabar, Antoine Spahr, Philippe Thiran
- Link : [http://arxiv.org/abs/2202.07570](http://arxiv.org/abs/2202.07570)
> ABSTRACT  :  Progress in digital pathology is hindered by high-resolution images and the prohibitive cost of exhaustive localized annotations. The commonly used paradigm to categorize pathology images is patch-based processing, which often incorporates multiple instance learning (MIL) to aggregate local patch-level representations yielding image-level prediction. Nonetheless, diagnostically relevant regions may only take a small fraction of the whole tissue, and current MIL-based approaches often process images uniformly, discarding the inter-patches interactions. To alleviate these issues, we propose ScoreNet, a new efficient transformer that exploits a differentiable recommendation stage to extract discriminative image regions and dedicate computational resources accordingly. The proposed transformer leverages the local and global attention of a few dynamically recommended high-resolution regions at an efficient computational cost. We further introduce a novel Mixup-based data-augmentation, namely ScoreMix, by leveraging the image's semantic distribution to guide the data mixing and produce coherent sample-label pairs. ScoreMix is embarrassingly simple and mitigates the pitfalls of previous augmentations, which assume a uniform semantic distribution and risk mislabeling the samples. Thorough experiments and ablation studies on three breast cancer histology datasets of Haematoxylin &amp; Eosin (H&amp;E) have validated the superiority of our approach over prior arts, including transformer-based models on tumour regions-of-interest (TRoIs) classification. ScoreNet equipped with proposed ScoreMix augmentation demonstrates better generalization capabilities and achieves new state-of-the-art (SOTA) results with only 50% of the data compared to other Mixup augmentation variants. Finally, ScoreNet yields high efficacy and outperforms SOTA efficient transformers, namely TransPath and **Swin**Transformer.  
### PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation. (arXiv:2203.04568v2 [eess.IV] UPDATED)
- Authors : Wentao Liu, Tong Tian, Weijin Xu, Huihua Yang, Xipeng Pan
- Link : [http://arxiv.org/abs/2203.04568](http://arxiv.org/abs/2203.04568)
> ABSTRACT  :  The success of Transformer in computer vision has attracted increasing attention in the medical imaging community. Especially for medical image segmentation, many excellent hybrid architectures based on convolutional neural networks (CNNs) and Transformer have been presented and achieve impressive performance. However, most of these methods, which embed modular Transformer into CNNs, struggle to reach their full potential. In this paper, we propose a novel hybrid architecture for medical image segmentation called PHTrans, which parallelly hybridizes Transformer and CNN in main building blocks to produce hierarchical representations from global and local features and adaptively aggregate them, aiming to fully exploit their strengths to obtain better segmentation performance. Specifically, PHTrans follows the U-shaped encoder-decoder design and introduces the parallel hybird module in deep stages, where convolution blocks and the modified 3D **Swin** Transformer learn local features and global dependencies separately, then a sequence-to-volume operation unifies the dimensions of the outputs to achieve feature aggregation. Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its effectiveness, consistently outperforming state-of-the-art methods.  
## eess.IV
---
### Semi-supervised classification of medical ultrasound images based on generative adversarial network. (arXiv:2203.06184v1 [eess.IV])
- Authors : Zhaoshan Liu, Chau Hung, Lei Shen
- Link : [http://arxiv.org/abs/2203.06184](http://arxiv.org/abs/2203.06184)
> ABSTRACT  :  Medical ultrasound (US) is one of the most widely used imaging modalities in clinical practice. However, its use presents unique challenges such as variable imaging quality. Deep learning (DL) can be used as an advanced medical US images analysis tool, while the performance of the DL model is greatly limited by the scarcity of big datasets. Here, we develop semi-supervised classification **enhancement** (SSCE) structures by constructing seven convolutional neural network (CNN) models and one of the most state-of-the-art generative adversarial network (GAN) models, StyleGAN2-ADA, to address this problem. A breast cancer dataset with 780 images is used as our base dataset. The results show that our SSCE structures obtain an accuracy of up to 97.9%, showing a maximum 21.6% improvement compared with utilizing CNN models alone and outperforming the previous methods using the same dataset by up to 23.9%. We believe our proposed state-of-the-art method can be regarded as a potential auxiliary tool for on-the-fly diagnoses of medical US images.  
### One-stage Video Instance Segmentation: From Frame-in Frame-out to Clip-in Clip-out. (arXiv:2203.06421v1 [cs.CV])
- Authors : Minghan Li, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.06421](http://arxiv.org/abs/2203.06421)
> ABSTRACT  :  Many video instance segmentation (VIS) methods partition a video sequence into individual frames to detect and segment objects frame by frame. However, such a frame-in frame-out (FiFo) pipeline is ineffective to exploit the temporal information. Based on the fact that adjacent frames in a short clip are highly coherent in content, we propose to extend the one-stage FiFo framework to a clip-in clip-out (CiCo) one, which performs VIS clip by clip. Specifically, we stack FPN features of all frames in a short video clip to build a spatio-temporal feature cube, and replace the 2D conv layers in the prediction heads and the mask branch with 3D conv layers, forming clip-level prediction heads (CPH) and clip-level mask heads (CMH). Then the clip-level masks of an instance can be generated by feeding its box-level predictions from CPH and clip-level features from CMH into a small fully convolutional network. A clip-level segmentation loss is proposed to ensure that the generated instance masks are temporally coherent in the clip. The proposed CiCo strategy is free of inter-frame alignment, and can be easily embedded into existing FiFo based VIS approaches. To validate the generality and effectiveness of our CiCo strategy, we apply it to two representative FiFo methods, Yolact \cite{bolya2019yolact} and CondInst \cite{tian2020conditional}, resulting in two new one-stage VIS models, namely CiCo-Yolact and CiCo-CondInst, which achieve 37.1/37.3\%, 35.2/35.4\% and 17.2/18.0\% mask AP using the ResNet50 backbone, and 41.8/41.4\%, 38.0/38.9\% and 18.0/18.2\% mask AP using the **Swin** Transformer tiny backbone on YouTube-VIS 2019, 2021 and OVIS valid sets, respectively, recording new state-of-the-arts. Code and video demos of CiCo can be found at \url{https://github.com/MinghanLi/CiCo}.  
### Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
- Authors : Frederic Madesta, Thilo Sentker, Tobias Gauer, Rene Werner
- Link : [http://arxiv.org/abs/2203.06431](http://arxiv.org/abs/2203.06431)
> ABSTRACT  :  4D CT imaging is an essential component of radiotherapy of thoracic/abdominal tumors. 4D CT images are, however, often affected by artifacts that compromise treatment planning quality. In this work, deep learning (DL)-based conditional inpainting is proposed to restore anatomically correct image information of artifact-affected areas. The **restoration** approach consists of a two-stage process: DL-based detection of common interpolation (INT) and double structure (DS) artifacts, followed by conditional inpainting applied to the artifact areas. In this context, conditional refers to a guidance of the inpainting process by patient-specific image data to ensure anatomically reliable results. Evaluation is based on 65 in-house 4D CT data sets of lung cancer patients (48 with only slight artifacts, 17 with pronounced artifacts) and the publicly available DIRLab 4D CT data (independent external test set). Automated artifact detection revealed a ROC-AUC of 0.99 for INT and 0.97 for DS artifacts (in-house data). The proposed inpainting method decreased the average root mean squared error (RMSE) by 60% (DS) and 42% (INT) for the in-house evaluation data (simulated artifacts for the slight artifact data; original data were considered as ground truth for RMSE computation). For the external DIR-Lab data, the RMSE decreased by 65% and 36%, respectively. Applied to the pronounced artifact data group, on average 68% of the detectable artifacts were removed. The results highlight the potential of DL-based inpainting for the **restoration** of artifact-affected 4D CT data. Improved performance of conditional inpainting (compared to standard inpainting) illustrates the benefits of exploiting patient-specific prior knowledge.  
### Underwater Image **Enhancement** via Learning Water Type Desensitized Representations. (arXiv:2102.00676v2 [cs.CV] UPDATED)
- Authors : Zhenqi Fu, Xiaopeng Lin, Wu Wang, Yue Huang, Xinghao Ding
- Link : [http://arxiv.org/abs/2102.00676](http://arxiv.org/abs/2102.00676)
> ABSTRACT  :  We present a novel underwater image **enhancement** method termed SCNet to improve the image quality meanwhile cope with the degradation diversity caused by the water. SCNet is based on normalization schemes across both spatial and channel dimensions with the key idea of learning water type desensitized features. Specifically, we apply whitening to de-correlate activations across spatial dimensions for each instance in a mini-batch. We also eliminate channel-wise correlation by standardizing and re-injecting the first two moments of the activations across channels. The normalization schemes of spatial and channel dimensions are performed at each scale of the U-Net to obtain multi-scale representations. With such water type irrelevant encodings, the decoder can easily reconstruct the clean signal and be unaffected by the distortion types. Experimental results on two real-world underwater image datasets show that our approach can successfully enhance images with diverse water types, and achieves competitive performance in visual quality improvement.  
### PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation. (arXiv:2203.04568v2 [eess.IV] UPDATED)
- Authors : Wentao Liu, Tong Tian, Weijin Xu, Huihua Yang, Xipeng Pan
- Link : [http://arxiv.org/abs/2203.04568](http://arxiv.org/abs/2203.04568)
> ABSTRACT  :  The success of Transformer in computer vision has attracted increasing attention in the medical imaging community. Especially for medical image segmentation, many excellent hybrid architectures based on convolutional neural networks (CNNs) and Transformer have been presented and achieve impressive performance. However, most of these methods, which embed modular Transformer into CNNs, struggle to reach their full potential. In this paper, we propose a novel hybrid architecture for medical image segmentation called PHTrans, which parallelly hybridizes Transformer and CNN in main building blocks to produce hierarchical representations from global and local features and adaptively aggregate them, aiming to fully exploit their strengths to obtain better segmentation performance. Specifically, PHTrans follows the U-shaped encoder-decoder design and introduces the parallel hybird module in deep stages, where convolution blocks and the modified 3D **Swin** Transformer learn local features and global dependencies separately, then a sequence-to-volume operation unifies the dimensions of the outputs to achieve feature aggregation. Extensive experimental results on both Multi-Atlas Labeling Beyond the Cranial Vault and Automated Cardiac Diagnosis Challeng datasets corroborate its effectiveness, consistently outperforming state-of-the-art methods.  
## cs.LG
---
### Learning cardiac activation maps from 12-lead ECG with multi-fidelity Bayesian optimization on manifolds. (arXiv:2203.06222v1 [eess.SP])
- Authors : Simone Pezzuto, Paris Perdikaris, Francisco Sahli
- Link : [http://arxiv.org/abs/2203.06222](http://arxiv.org/abs/2203.06222)
> ABSTRACT  :  We propose a method for identifying an ectopic activation in the heart non-invasively. Ectopic activity in the heart can trigger deadly arrhythmias. The localization of the ectopic foci or earliest activation sites (EASs) is therefore a critical information for cardiologists in deciding the optimal treatment. In this work, we formulate the identification problem as a global optimization problem, by minimizing the mismatch between the ECG predicted by a cardiac model, when paced at a given EAS, and the observed ECG during the ectopic activity. Our cardiac model amounts at solving an anisotropic eikonal equation for cardiac activation and the forward bidomain model in the torso with the lead field approach for computing the ECG. We build a Gaussian process surrogate model of the loss function on the heart surface to perform Bayesian optimization. In this procedure, we iteratively evaluate the loss function following the lower confidence bound criterion, which combines exploring the surface with exploitation of the minimum region. We also extend this framework to incorporate multiple levels of fidelity of the model. We show that our procedure converges to the minimum only after $11.7\pm10.4$ iterations (20 independent runs) for the single-fidelity case and $3.5\pm1.7$ iterations for the multi-fidelity case. We envision that this tool could be applied in **real time** in a clinical setting to identify potentially dangerous EASs.  
### Varying Coefficient Linear Discriminant Analysis via B-Spline Approximation. (arXiv:2203.06371v1 [stat.ME])
- Authors : Yajie Bao, Yuyang Liu
- Link : [http://arxiv.org/abs/2203.06371](http://arxiv.org/abs/2203.06371)
> ABSTRACT  :  Linear discriminant analysis (LDA) is a vital classification tool in statistics and machine learning. This paper investigates the varying coefficient LDA model for dynamic data, with Bayes' discriminant direction being a function of some **exposure** variable to address the heterogeneity. By deriving a new discriminant direction function parallel with Bayes' direction, we propose a least-square estimation procedure based on the B-spline approximation. For high-dimensional regime, the corresponding data-driven discriminant rule is more computationally efficient than the existed dynamic linear programming rule. We also establish the corresponding theoretical results, including estimation error bound and the uniform excess misclassification rate. Numerical experiments on synthetic data and real data both corroborate the superiority of our proposed classification method.  
### Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
- Authors : Frederic Madesta, Thilo Sentker, Tobias Gauer, Rene Werner
- Link : [http://arxiv.org/abs/2203.06431](http://arxiv.org/abs/2203.06431)
> ABSTRACT  :  4D CT imaging is an essential component of radiotherapy of thoracic/abdominal tumors. 4D CT images are, however, often affected by artifacts that compromise treatment planning quality. In this work, deep learning (DL)-based conditional inpainting is proposed to restore anatomically correct image information of artifact-affected areas. The **restoration** approach consists of a two-stage process: DL-based detection of common interpolation (INT) and double structure (DS) artifacts, followed by conditional inpainting applied to the artifact areas. In this context, conditional refers to a guidance of the inpainting process by patient-specific image data to ensure anatomically reliable results. Evaluation is based on 65 in-house 4D CT data sets of lung cancer patients (48 with only slight artifacts, 17 with pronounced artifacts) and the publicly available DIRLab 4D CT data (independent external test set). Automated artifact detection revealed a ROC-AUC of 0.99 for INT and 0.97 for DS artifacts (in-house data). The proposed inpainting method decreased the average root mean squared error (RMSE) by 60% (DS) and 42% (INT) for the in-house evaluation data (simulated artifacts for the slight artifact data; original data were considered as ground truth for RMSE computation). For the external DIR-Lab data, the RMSE decreased by 65% and 36%, respectively. Applied to the pronounced artifact data group, on average 68% of the detectable artifacts were removed. The results highlight the potential of DL-based inpainting for the **restoration** of artifact-affected 4D CT data. Improved performance of conditional inpainting (compared to standard inpainting) illustrates the benefits of exploiting patient-specific prior knowledge.  
### A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
- Authors : Paulo Ricardo, Lisboa de, Jeovane Hon, rio Alves, Rafael Stubs, Jean Paul
- Link : [http://arxiv.org/abs/2203.06463](http://arxiv.org/abs/2203.06463)
> ABSTRACT  :  Computer vision-based parking lot management methods have been extensively researched upon owing to their flexibility and cost-effectiveness. To evaluate such methods authors often employ publicly available parking lot image datasets. In this study, we surveyed and compared robust publicly available image datasets specifically crafted to test computer vision-based methods for parking lot management approaches and consequently present a systematic and comprehensive review of existing works that employ such datasets. The literature review identified relevant gaps that require further research, such as the requirement of dataset-independent approaches and methods suitable for autonomous detection of position of parking spaces. In addition, we have noticed that several important factors such as the presence of the same cars across consecutive images, have been neglected in most studies, thereby rendering unrealistic assessment protocols. Furthermore, the analysis of the datasets also revealed that certain features that should be present when developing new benchmarks, such as the availability of video sequences and images taken in more diverse conditions, including **night**time and snow, have not been incorporated.  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  In this paper we revisit large kernel design in modern convolutional neural networks (CNNs), which is often neglected in the past few years. Inspired by recent advances of vision transformers (ViTs), we point out that using a few large kernels instead of a stack of small convolutions could be a more powerful paradigm. We therefore summarize 5 guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31. RepLKNet greatly bridges the performance gap between CNNs and ViTs, e.g., achieving comparable or better results than **Swin** Transformer on ImageNet and downstream tasks, while the latency of RepLKNet is much lower. Moreover, RepLKNet also shows feasible scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0%} mIoU on ADE20K. At last, our study further suggests large-kernel CNNs share several nice properties with ViTs, e.g., much larger effective receptive fields than conventional CNNs, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
### Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
- Authors : Jeff Clune, Nick Cheney
- Link : [http://arxiv.org/abs/2108.12056](http://arxiv.org/abs/2108.12056)
> ABSTRACT  :  Existing machines are functionally specific tools that were made for easy prediction and control. Tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. But first they must be capable of learning, and retaining, new information without repeated **exposure** to it. Past efforts to engineer such systems have sought to build or regulate artificial neural networks using task-specific modules with constrained circumstances of application. This has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. In this paper, we introduce a system that can learn sequentially over previously unseen datasets (ImageNet, CIFAR-100) with little forgetting over time. This is accomplished by regulating the activity of weights in a convolutional neural network on the basis of inputs using top-down modulation generated by a second feed-forward neural network. We find that our method learns continually under domain transfer with sparse bursts of activity in weights that are recycled across tasks, rather than by maintaining task-specific modules. Sparse synaptic bursting is found to balance enhanced and diminished activity in a way that facilitates adaptation to new inputs without corrupting previously acquired functions. This behavior emerges during a prior meta-learning phase in which regulated synapses are selectively disinhibited, or grown, from an initial state of uniform suppression.  
### SoftSNN: Low-Cost Fault Tolerance for Spiking Neural Network Accelerators under Soft Errors. (arXiv:2203.05523v2 [cs.AR] UPDATED)
- Authors : Rachmad Vidya, Wicaksana Putra, Muhammad Abdullah, Muhammad Shafique
- Link : [http://arxiv.org/abs/2203.05523](http://arxiv.org/abs/2203.05523)
> ABSTRACT  :  Specialized hardware accelerators have been designed and employed to maximize the performance efficiency of Spiking Neural Networks (SNNs). However, such accelerators are vulnerable to transient faults (i.e., soft errors), which occur due to high-energy particle strikes, and manifest as bit flips at the hardware layer. These errors can change the weight values and neuron operations in the compute engine of SNN accelerators, thereby leading to incorrect outputs and accuracy degradation. However, the impact of soft errors in the compute engine and the respective mitigation techniques have not been thoroughly studied yet for SNNs. A potential solution is employing redundant executions (re-execution) for ensuring correct outputs, but it leads to huge latency and energy overheads. Toward this, we propose SoftSNN, a novel methodology to mitigate soft errors in the weight registers (synapses) and neurons of SNN accelerators without re-execution, thereby maintaining the accuracy with low latency and energy overheads. Our SoftSNN methodology employs the following key steps: (1) analyzing the SNN characteristics under soft errors to identify faulty weights and neuron operations, which are required for recognizing faulty SNN behavior; (2) a Bound-and-Protect technique that leverages this analysis to improve the SNN fault tolerance by bounding the weight values and protecting the neurons from faulty operations; and (3) devising lightweight hardware **enhancement**s for the neural hardware accelerator to efficiently support the proposed technique. The experimental results show that, for a 900-neuron network with even a high fault rate, our SoftSNN maintains the accuracy degradation below 3%, while reducing latency and energy by up to 3x and 2.3x respectively, as compared to the re-execution technique.  
## cs.AI
---
### A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
- Authors : Paulo Ricardo, Lisboa de, Jeovane Hon, rio Alves, Rafael Stubs, Jean Paul
- Link : [http://arxiv.org/abs/2203.06463](http://arxiv.org/abs/2203.06463)
> ABSTRACT  :  Computer vision-based parking lot management methods have been extensively researched upon owing to their flexibility and cost-effectiveness. To evaluate such methods authors often employ publicly available parking lot image datasets. In this study, we surveyed and compared robust publicly available image datasets specifically crafted to test computer vision-based methods for parking lot management approaches and consequently present a systematic and comprehensive review of existing works that employ such datasets. The literature review identified relevant gaps that require further research, such as the requirement of dataset-independent approaches and methods suitable for autonomous detection of position of parking spaces. In addition, we have noticed that several important factors such as the presence of the same cars across consecutive images, have been neglected in most studies, thereby rendering unrealistic assessment protocols. Furthermore, the analysis of the datasets also revealed that certain features that should be present when developing new benchmarks, such as the availability of video sequences and images taken in more diverse conditions, including **night**time and snow, have not been incorporated.  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  In this paper we revisit large kernel design in modern convolutional neural networks (CNNs), which is often neglected in the past few years. Inspired by recent advances of vision transformers (ViTs), we point out that using a few large kernels instead of a stack of small convolutions could be a more powerful paradigm. We therefore summarize 5 guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31. RepLKNet greatly bridges the performance gap between CNNs and ViTs, e.g., achieving comparable or better results than **Swin** Transformer on ImageNet and downstream tasks, while the latency of RepLKNet is much lower. Moreover, RepLKNet also shows feasible scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0%} mIoU on ADE20K. At last, our study further suggests large-kernel CNNs share several nice properties with ViTs, e.g., much larger effective receptive fields than conventional CNNs, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
### Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
- Authors : Jeff Clune, Nick Cheney
- Link : [http://arxiv.org/abs/2108.12056](http://arxiv.org/abs/2108.12056)
> ABSTRACT  :  Existing machines are functionally specific tools that were made for easy prediction and control. Tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. But first they must be capable of learning, and retaining, new information without repeated **exposure** to it. Past efforts to engineer such systems have sought to build or regulate artificial neural networks using task-specific modules with constrained circumstances of application. This has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. In this paper, we introduce a system that can learn sequentially over previously unseen datasets (ImageNet, CIFAR-100) with little forgetting over time. This is accomplished by regulating the activity of weights in a convolutional neural network on the basis of inputs using top-down modulation generated by a second feed-forward neural network. We find that our method learns continually under domain transfer with sparse bursts of activity in weights that are recycled across tasks, rather than by maintaining task-specific modules. Sparse synaptic bursting is found to balance enhanced and diminished activity in a way that facilitates adaptation to new inputs without corrupting previously acquired functions. This behavior emerges during a prior meta-learning phase in which regulated synapses are selectively disinhibited, or grown, from an initial state of uniform suppression.  
# Paper List
---
## cs.CV
---
**174** new papers in cs.CV:-) 
1. Semi-supervised classification of medical ultrasound images based on generative adversarial network. (arXiv:2203.06184v1 [eess.IV])
2. Leveraging universality of jet taggers through transfer learning. (arXiv:2203.06210v1 [hep-ph])
3. Can I see an Example? Active Learning the Long Tail of Attributes and Relations. (arXiv:2203.06215v1 [cs.CV])
4. Medical Image Segmentation on MRI Images with Missing Modalities: A Review. (arXiv:2203.06217v1 [eess.IV])
5. Pressure Ulcer Categorisation using Deep Learning: A Clinical Trial to Evaluate Model Performance. (arXiv:2203.06248v1 [cs.LG])
6. Perception Over Time: Temporal Dynamics for Robust Image Understanding. (arXiv:2203.06254v1 [cs.CV])
7. Preliminary experiments on automatic gender recognition based on online capital letters. (arXiv:2203.06265v1 [cs.CV])
8. MISF: Multi-level Interactive Siamese Filtering for High-Fidelity Image Inpainting. (arXiv:2203.06304v1 [cs.CV])
9. Tensor Radiomics: Paradigm for Systematic Incorporation of Multi-Flavoured Radiomics Features. (arXiv:2203.06314v1 [cs.CV])
10. Deformable VisTR: Spatio temporal deformable attention for video instance segmentation. (arXiv:2203.06318v1 [cs.CV])
11. PillarGrid: Deep Learning-based Cooperative Perception for 3D Object Detection from Onboard-Roadside LiDAR. (arXiv:2203.06319v1 [cs.CV])
12. Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation. (arXiv:2203.06321v1 [cs.CV])
13. Image Style Transfer: from Artistic to Photorealistic. (arXiv:2203.06328v1 [cs.CV])
14. Auto-FedRL: Federated Hyperparameter Optimization for Multi-institutional Medical Image Segmentation. (arXiv:2203.06338v1 [eess.IV])
15. The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy. (arXiv:2203.06345v1 [cs.LG])
16. LesionPaste: One-Shot Anomaly Detection for Medical Images. (arXiv:2203.06354v1 [eess.IV])
17. EventFormer: AU Event Transformer for Facial Action Unit Event Detection. (arXiv:2203.06355v1 [cs.CV])
18. Taking an Emotional Look at Video Paragraph Captioning. (arXiv:2203.06356v1 [cs.CV])
19. Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning. (arXiv:2203.06359v1 [cs.CV])
20. MDT-Net: Multi-domain Transfer by Perceptual Supervision for Unpaired Images in OCT Scan. (arXiv:2203.06363v1 [cs.CV])
21. Differentiated Relevances Embedding for Group-based Referring Expression Comprehension. (arXiv:2203.06382v1 [cs.CV])
22. Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation. (arXiv:2203.06386v1 [cs.CL])
23. Joint CNN and Transformer Network via weakly supervised Learning for efficient crowd counting. (arXiv:2203.06388v1 [cs.CV])
24. SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection. (arXiv:2203.06398v1 [cs.CV])
25. Kernel Proposal Network for Arbitrary Shape Text Detection. (arXiv:2203.06410v1 [cs.CV])
26. Recurrence-in-Recurrence Networks for Video Deblurring. (arXiv:2203.06418v1 [eess.IV])
27. One-stage Video Instance Segmentation: From Frame-in Frame-out to Clip-in Clip-out. (arXiv:2203.06421v1 [cs.CV])
28. VariabilityTrack:Multi-Object Tracking with Variable Speed Object Movement. (arXiv:2203.06424v1 [cs.CV])
29. VAFO-Loss: VAscular Feature Optimised Loss Function for Retinal Artery/Vein Segmentation. (arXiv:2203.06425v1 [cs.CV])
30. DFTR: Depth-supervised Hierarchical Feature Fusion Transformer for Salient Object Detection. (arXiv:2203.06429v1 [cs.CV])
31. Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
32. DATR: Domain-adaptive transformer for multi-domain landmark detection. (arXiv:2203.06433v1 [cs.CV])
33. Bringing Rolling Shutter Images Alive with Dual Reversed Distortion. (arXiv:2203.06451v1 [cs.CV])
34. 3D-GIF: 3D-Controllable Object Generation via Implicit Factorized Representations. (arXiv:2203.06457v1 [cs.CV])
35. Factored Attention and Embedding for Unstructured-view Topic-related Ultrasound Report Generation. (arXiv:2203.06458v1 [cs.CV])
36. A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
37. Unsupervised Lifelong Person Re-identification via Contrastive Rehearsal. (arXiv:2203.06468v1 [cs.CV])
38. Evaluating Explainable AI on a Multi-Modal Medical Imaging Task: Can Existing Algorithms Fulfill Clinical Requirements?. (arXiv:2203.06487v1 [cs.CV])
39. TEN: Twin Embedding Networks for the Jigsaw Puzzle Problem with Eroded Boundaries. (arXiv:2203.06488v1 [cs.CV])
40. Adaptive Information Bottleneck Guided Joint Source-Channel Coding. (arXiv:2203.06492v1 [cs.IT])
41. A Mixed Quantization Network for Computationally Efficient Mobile Inverse Tone Mapping. (arXiv:2203.06504v1 [cs.CV])
42. Sparsity and Heterogeneous Dropout for Continual Learning in the Null Space of Neural Activations. (arXiv:2203.06514v1 [cs.LG])
43. Sparse Local Patch Transformer for Robust Face Alignment and Landmarks Inherent Relation Learning. (arXiv:2203.06541v1 [cs.CV])
44. Change Detection from Synthetic Aperture Radar Images via Dual Path Denoising Network. (arXiv:2203.06543v1 [eess.IV])
45. CEKD:Cross Ensemble Knowledge Distillation for Augmented Fine-grained Data. (arXiv:2203.06551v1 [cs.CV])
46. Contrastive Learning for Automotive mmWave Radar Detection Points Based Instance Segmentation. (arXiv:2203.06553v1 [cs.CV])
47. AutoGPart: Intermediate Supervision Search for Generalizable 3D Part Segmentation. (arXiv:2203.06558v1 [cs.CV])
48. Query-Efficient Black-box Adversarial Attacks Guided by a Transfer-based Prior. (arXiv:2203.06560v1 [cs.LG])
49. Worst Case Matters for Few-Shot Recognition. (arXiv:2203.06574v1 [cs.CV])
50. CVFNet: **Real-time** 3D Object Detection by Learning Cross View Features. (arXiv:2203.06585v1 [cs.CV])
51. AugShuffleNet: Improve ShuffleNetV2 via More Information Communication. (arXiv:2203.06589v1 [cs.CV])
52. Masked Autoencoders for Point Cloud Self-supervised Learning. (arXiv:2203.06604v1 [cs.CV])
53. Depth-Aware Generative Adversarial Network for Talking Head Video Generation. (arXiv:2203.06605v1 [cs.CV])
54. Context-LSTM: a robust classifier for video detection on UCF101. (arXiv:2203.06610v1 [cs.CV])
55. A Single Correspondence Is Enough: Robust Global Registration to Avoid Degeneracy in Urban Environments. (arXiv:2203.06612v1 [cs.CV])
56. LAS-AT: Adversarial Training with Learnable Attack Strategy. (arXiv:2203.06616v1 [cs.CV])
57. Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v1 [cs.CV])
58. Revisiting Deep Semi-supervised Learning: An Empirical Distribution Alignment Framework and Its Generalization Bound. (arXiv:2203.06639v1 [cs.CV])
59. Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4. (arXiv:2203.06649v1 [q-bio.NC])
60. Global2Local: A Joint-Hierarchical Attention for Video Captioning. (arXiv:2203.06663v1 [cs.CV])
61. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v1 [cs.CV])
62. PNM: Pixel Null Model for General Image Segmentation. (arXiv:2203.06677v1 [cs.CV])
63. Privacy-friendly Synthetic Data for the Development of Face Morphing Attack Detectors. (arXiv:2203.06691v1 [cs.CV])
64. Training Protocol Matters: Towards Accurate Scene Text Recognition via Training Protocol Searching. (arXiv:2203.06696v1 [cs.CV])
65. Efficient Long-Range Attention Network for Image Super-resolution. (arXiv:2203.06697v1 [cs.CV])
66. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
67. Food Recipe Recommendation Based on Ingredients Detection Using Deep Learning. (arXiv:2203.06721v1 [cs.CV])
68. Feature space reduction as data preprocessing for the anomaly detection. (arXiv:2203.06747v1 [cs.CV])
69. Decontextualized I3D ConvNet for ultra-distance runners performance analysis at a glance. (arXiv:2203.06749v1 [cs.CV])
70. TurbuGAN: An Adversarial Learning Approach to Spatially-Varying Multiframe Blind Deconvolution with Applications to Imaging Through Turbulence. (arXiv:2203.06764v1 [cs.CV])
71. Similarity Equivariant Linear Transformation of Joint Orientation-Scale Space Representations. (arXiv:2203.06786v1 [cs.CV])
72. Euclidean Invariant Recognition of 2D Shapes Using Histograms of Magnitudes of Local Fourier-Mellin Descriptors. (arXiv:2203.06787v1 [cs.CV])
73. Automated Learning for Deformable Medical Image Registration by Jointly Optimizing Network Architectures and Objective Functions. (arXiv:2203.06810v1 [cs.CV])
74. ADAS: A Direct Adaptation Strategy for Multi-Target Domain Adaptive Semantic Segmentation. (arXiv:2203.06811v1 [cs.CV])
75. Grounding Commands for Autonomous Vehicles via Layer Fusion with Region-specific Dynamic Layer Attention. (arXiv:2203.06822v1 [cs.CV])
76. SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation. (arXiv:2203.06823v1 [eess.IV])
77. Fairness Evaluation in Deepfake Detection Models using Metamorphic Testing. (arXiv:2203.06825v1 [cs.CV])
78. Bures Joint Distribution Alignment with Dynamic Margin for Unsupervised Domain Adaptation. (arXiv:2203.06836v1 [cs.CV])
79. STDAN: Deformable Attention Network for Space-Time Video Super-Resolution. (arXiv:2203.06841v1 [cs.CV])
80. RecursiveMix: Mixed Learning with History. (arXiv:2203.06844v1 [cs.CV])
81. Large Scale Open-Set Deep Logo Detection. (arXiv:1911.07440v4 [cs.CV] UPDATED)
82. Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v3 [cs.CV] UPDATED)
83. Efficient Transformers: A Survey. (arXiv:2009.06732v3 [cs.LG] UPDATED)
84. Knowledge Guided Learning: Towards Open Domain Egocentric Action Recognition with Zero Supervision. (arXiv:2009.07470v2 [cs.CV] UPDATED)
85. SWIPENET: Object detection in noisy underwater images. (arXiv:2010.10006v3 [cs.CV] UPDATED)
86. Progressively Volumetrized Deep Generative Models for Data-Efficient Contextual Learning of MR Image Recovery. (arXiv:2011.13913v4 [cs.CV] UPDATED)
87. Probabilistic Graph Attention Network with Conditional Kernels for Pixel-Wise Prediction. (arXiv:2101.02843v2 [cs.CV] UPDATED)
88. Underwater Image **Enhancement** via Learning Water Type Desensitized Representations. (arXiv:2102.00676v2 [cs.CV] UPDATED)
89. You Only Learn Once: Universal Anatomical Landmark Detection. (arXiv:2103.04657v3 [cs.CV] UPDATED)
90. R-PointHop: A Green, Accurate, and Unsupervised Point Cloud Registration Method. (arXiv:2103.08129v3 [cs.CV] UPDATED)
91. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v4 [cs.CL] UPDATED)
92. Exploiting Explanations for Model Inversion Attacks. (arXiv:2104.12669v3 [cs.CV] UPDATED)
93. Visual Grounding with Transformers. (arXiv:2105.04281v3 [cs.CV] UPDATED)
94. Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v3 [cs.LG] UPDATED)
95. When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations. (arXiv:2106.01548v3 [cs.CV] UPDATED)
96. Exploring Memorization in Adversarial Training. (arXiv:2106.01606v2 [cs.LG] UPDATED)
97. Incremental False Negative Detection for Contrastive Learning. (arXiv:2106.03719v5 [cs.CV] UPDATED)
98. ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v2 [cs.LG] UPDATED)
99. Score-Based Point Cloud Denoising (Learning Implicit Gradient Fields for Point Cloud Denoising). (arXiv:2107.10981v3 [cs.CV] UPDATED)
100. Automated Human Cell Classification in Sparse Datasets using Few-Shot Learning. (arXiv:2107.13093v2 [cs.CV] UPDATED)
101. WSDesc: Weakly Supervised 3D Local Descriptor Learning for Point Cloud Registration. (arXiv:2108.02740v2 [cs.CV] UPDATED)
102. Full-resolution quality assessment for pansharpening. (arXiv:2108.06144v2 [cs.CV] UPDATED)
103. Towards unconstrained joint hand-object reconstruction from RGB videos. (arXiv:2108.07044v2 [cs.CV] UPDATED)
104. Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
105. Unpaired Deep Image Deraining Using Dual Contrastive Learning. (arXiv:2109.02973v3 [cs.CV] UPDATED)
106. M5Product: Self-harmonized Contrastive Learning for E-commercial Multi-modal Pretraining. (arXiv:2109.04275v3 [cs.CV] UPDATED)
107. Integrated Construction of Multimodal Atlases with Structural Connectomes in the Space of Riemannian Metrics. (arXiv:2109.09808v2 [cs.CV] UPDATED)
108. End-to-End Dense Video Grounding via Parallel Regression. (arXiv:2109.11265v3 [cs.CV] UPDATED)
109. Bringing Generalization to Deep Multi-View Pedestrian Detection. (arXiv:2109.12227v4 [cs.CV] UPDATED)
110. Motion-aware Contrastive Video Representation Learning via Foreground-background Merging. (arXiv:2109.15130v3 [cs.CV] UPDATED)
111. Learning Sparse Masks for Diffusion-based Image Inpainting. (arXiv:2110.02636v3 [eess.IV] UPDATED)
112. MPSN: Motion-aware Pseudo Siamese Network for Indoor Video Head Detection in Buildings. (arXiv:2110.03302v3 [cs.CV] UPDATED)
113. Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm. (arXiv:2110.05208v2 [cs.CV] UPDATED)
114. Rethinking Supervised Pre-training for Better Downstream Transferring. (arXiv:2110.06014v2 [cs.CV] UPDATED)
115. Ego4D: Around the World in 3,000 Hours of Egocentric Video. (arXiv:2110.07058v3 [cs.CV] UPDATED)
116. Weakly Supervised Semantic Segmentation by Pixel-to-Prototype Contrast. (arXiv:2110.07110v3 [cs.CV] UPDATED)
117. Image Translation using Texture Co-occurrence and Spatial Self-Similarity for Texture Debiasing. (arXiv:2110.07920v3 [cs.CV] UPDATED)
118. Multimodal-Boost: Multimodal Medical Image Super-Resolution using Multi-Attention Network with Wavelet Transform. (arXiv:2110.11684v2 [eess.IV] UPDATED)
119. Longitudinal Analysis of Mask and No-Mask on Child Face Recognition. (arXiv:2111.00121v5 [cs.CV] UPDATED)
120. Rethinking Keypoint Representations: Modeling Keypoints and Poses as Objects for Multi-Person Human Pose Estimation. (arXiv:2111.08557v3 [cs.CV] UPDATED)
121. Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection. (arXiv:2111.09099v6 [cs.CV] UPDATED)
122. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v8 [cs.CV] UPDATED)
123. NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition. (arXiv:2111.12994v2 [cs.CV] UPDATED)
124. Few-Shot Real Image Super-resolution via Distortion-Relation Guided Transfer Learning. (arXiv:2111.13078v2 [cs.CV] UPDATED)
125. On the Integration of Self-Attention and Convolution. (arXiv:2111.14556v2 [cs.CV] UPDATED)
126. AssistSR: Task-oriented Question-driven Video Segment Retrieval. (arXiv:2111.15050v3 [cs.CV] UPDATED)
127. AirObject: A Temporally Evolving Graph Embedding for Object Identification. (arXiv:2111.15150v2 [cs.CV] UPDATED)
128. ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation. (arXiv:2111.15242v2 [cs.CV] UPDATED)
129. Revisiting the Transferability of Supervised Pretraining: an MLP Perspective. (arXiv:2112.00496v2 [cs.CV] UPDATED)
130. Extrapolating from a Single Image to a Thousand Classes using Distillation. (arXiv:2112.00725v3 [cs.CV] UPDATED)
131. Fast Neural Representations for Direct Volume Rendering. (arXiv:2112.01579v2 [cs.GR] UPDATED)
132. Implicit Data Augmentation Using Feature Interpolation for Low-Shot Image Generation. (arXiv:2112.02450v2 [cs.CV] UPDATED)
133. Classification-Then-Grounding: Reformulating Video Scene Graphs as Temporal Bipartite Graphs. (arXiv:2112.04222v3 [cs.CV] UPDATED)
134. FaceFormer: Speech-Driven 3D Facial Animation with Transformers. (arXiv:2112.05329v3 [cs.CV] UPDATED)
135. The Overlooked Classifier in Human-Object Interaction Recognition. (arXiv:2112.06392v2 [cs.CV] UPDATED)
136. VALSE: A Task-Independent Benchmark for Vision and Language Models Centered on Linguistic Phenomena. (arXiv:2112.07566v2 [cs.CL] UPDATED)
137. Impact of class imbalance on chest x-ray classifiers: towards better evaluation practices for discrimination and calibration performance. (arXiv:2112.12843v2 [cs.CV] UPDATED)
138. PRIME: A few primitives can boost robustness to common corruptions. (arXiv:2112.13547v2 [cs.CV] UPDATED)
139. Contrastive Fine-grained Class Clustering via Generative Adversarial Networks. (arXiv:2112.14971v3 [cs.CV] UPDATED)
140. Language as Queries for Referring Video Object Segmentation. (arXiv:2201.00487v2 [cs.CV] UPDATED)
141. Enabling Verification of Deep Neural Networks in Perception Tasks Using Fuzzy Logic and Concept Embeddings. (arXiv:2201.00572v2 [cs.CV] UPDATED)
142. Implicit Autoencoder for Point Cloud Self-supervised Representation Learning. (arXiv:2201.00785v2 [cs.CV] UPDATED)
143. Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction. (arXiv:2201.02184v2 [eess.AS] UPDATED)
144. MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v2 [cs.CV] UPDATED)
145. Language-biased image classification: evaluation based on semantic representations. (arXiv:2201.11014v2 [cs.CV] UPDATED)
146. Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains. (arXiv:2201.11528v4 [cs.CV] UPDATED)
147. LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks. (arXiv:2201.11808v2 [cs.CV] UPDATED)
148. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v3 [cs.RO] UPDATED)
149. Entroformer: A Transformer-based Entropy Model for Learned Image Compression. (arXiv:2202.05492v2 [eess.IV] UPDATED)
150. Geometric Transformer for Fast and Robust Point Cloud Registration. (arXiv:2202.06688v2 [cs.CV] UPDATED)
151. ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification. (arXiv:2202.07570v2 [cs.CV] UPDATED)
152. Movies2Scenes: Learning Scene Representations Using Movie Similarities. (arXiv:2202.10650v2 [cs.CV] UPDATED)
153. Deepfake Network Architecture Attribution. (arXiv:2202.13843v2 [cs.CV] UPDATED)
154. Effectiveness of Delivered Information Trade Study. (arXiv:2203.00116v2 [cs.CV] UPDATED)
155. CycleMix: A Holistic Strategy for Medical Image Segmentation from Scribble Supervision. (arXiv:2203.01475v2 [eess.IV] UPDATED)
156. ViTransPAD: Video Transformer using convolution and self-attention for Face Presentation Attack Detection. (arXiv:2203.01562v2 [cs.CV] UPDATED)
157. Weakly Supervised Object Localization as Domain Adaption. (arXiv:2203.01714v2 [cs.CV] UPDATED)
158. Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation. (arXiv:2203.02925v5 [cs.CV] UPDATED)
159. Signature and Log-signature for the Study of Empirical Distributions Generated with GANs. (arXiv:2203.03226v2 [cs.CV] UPDATED)
160. Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels. (arXiv:2203.03884v2 [cs.CV] UPDATED)
161. BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary Camera Rigs. (arXiv:2203.04050v2 [cs.CV] UPDATED)
162. Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment. (arXiv:2203.04121v2 [cs.CV] UPDATED)
163. Autonomous Mosquito Habitat Detection Using Satellite Imagery and Convolutional Neural Networks for Disease Risk Mapping. (arXiv:2203.04463v2 [cs.CV] UPDATED)
164. The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another in Neural Networks. (arXiv:2203.04466v2 [cs.LG] UPDATED)
165. All You Need is LUV: Unsupervised Collection of Labeled Images using Invisible UV Fluorescent Indicators. (arXiv:2203.04566v2 [cs.CV] UPDATED)
166. PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation. (arXiv:2203.04568v2 [eess.IV] UPDATED)
167. Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification. (arXiv:2203.04614v2 [eess.IV] UPDATED)
168. CEU-Net: Ensemble Semantic Segmentation of Hyperspectral Images Using Clustering. (arXiv:2203.04873v2 [cs.CV] UPDATED)
169. Cross-modal Map Learning for Vision and Language Navigation. (arXiv:2203.05137v2 [cs.CV] UPDATED)
170. Adaptive Background Matting Using Background Matching. (arXiv:2203.05193v2 [cs.CV] UPDATED)
171. Non-generative Generalized Zero-shot Learning via Task-correlated Disentanglement and Controllable Samples Synthesis. (arXiv:2203.05335v2 [cs.CV] UPDATED)
172. Spatial Commonsense Graph for Object Localisation in Partial Scenes. (arXiv:2203.05380v2 [cs.CV] UPDATED)
173. An Empirical Investigation of 3D Anomaly Detection and Segmentation. (arXiv:2203.05550v2 [cs.CV] UPDATED)
174. Dual-Domain Reconstruction Networks with V-Net and K-Net for fast MRI. (arXiv:2203.05725v2 [cs.CV] UPDATED)
## eess.IV
---
**28** new papers in eess.IV:-) 
1. Semi-supervised classification of medical ultrasound images based on generative adversarial network. (arXiv:2203.06184v1 [eess.IV])
2. Medical Image Segmentation on MRI Images with Missing Modalities: A Review. (arXiv:2203.06217v1 [eess.IV])
3. Pressure Ulcer Categorisation using Deep Learning: A Clinical Trial to Evaluate Model Performance. (arXiv:2203.06248v1 [cs.LG])
4. DURRNet: Deep Unfolded Single Image Reflection Removal Network. (arXiv:2203.06306v1 [eess.IV])
5. Auto-FedRL: Federated Hyperparameter Optimization for Multi-institutional Medical Image Segmentation. (arXiv:2203.06338v1 [eess.IV])
6. LesionPaste: One-Shot Anomaly Detection for Medical Images. (arXiv:2203.06354v1 [eess.IV])
7. SSCU-Net: Spatial-Spectral Collaborative Unmixing Network for Hyperspectral Images. (arXiv:2203.06375v1 [eess.IV])
8. Recurrence-in-Recurrence Networks for Video Deblurring. (arXiv:2203.06418v1 [eess.IV])
9. One-stage Video Instance Segmentation: From Frame-in Frame-out to Clip-in Clip-out. (arXiv:2203.06421v1 [cs.CV])
10. Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
11. Change Detection from Synthetic Aperture Radar Images via Dual Path Denoising Network. (arXiv:2203.06543v1 [eess.IV])
12. SKM-TEA: A Dataset for Accelerated MRI Reconstruction with Dense Image Labels for Quantitative Clinical Evaluation. (arXiv:2203.06823v1 [eess.IV])
13. DS3-Net: Difficulty-perceived Common-to-T1ce Semi-Supervised Multimodal MRI Synthesis Network. (arXiv:2203.06920v1 [eess.IV])
14. Compressing CNN Kernels for Videos Using Tucker Decompositions: Towards Lightweight CNN Applications. (arXiv:2203.07033v1 [cs.LG])
15. Human Attention Detection Using AM-FM Representations. (arXiv:2203.07093v1 [cs.CV])
16. WSSAMNet: Weakly Supervised Semantic Attentive Medical Image Registration Network. (arXiv:2203.07114v1 [eess.IV])
17. Accelerating Plug-and-Play Image Reconstruction via Multi-Stage Sketched Gradients. (arXiv:2203.07308v1 [eess.IV])
18. Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v3 [cs.CV] UPDATED)
19. Probabilistic Graph Attention Network with Conditional Kernels for Pixel-Wise Prediction. (arXiv:2101.02843v2 [cs.CV] UPDATED)
20. Underwater Image **Enhancement** via Learning Water Type Desensitized Representations. (arXiv:2102.00676v2 [cs.CV] UPDATED)
21. Learning Sparse Masks for Diffusion-based Image Inpainting. (arXiv:2110.02636v3 [eess.IV] UPDATED)
22. Multimodal-Boost: Multimodal Medical Image Super-Resolution using Multi-Attention Network with Wavelet Transform. (arXiv:2110.11684v2 [eess.IV] UPDATED)
23. Few-Shot Real Image Super-resolution via Distortion-Relation Guided Transfer Learning. (arXiv:2111.13078v2 [cs.CV] UPDATED)
24. Entroformer: A Transformer-based Entropy Model for Learned Image Compression. (arXiv:2202.05492v2 [eess.IV] UPDATED)
25. Effectiveness of Delivered Information Trade Study. (arXiv:2203.00116v2 [cs.CV] UPDATED)
26. CycleMix: A Holistic Strategy for Medical Image Segmentation from Scribble Supervision. (arXiv:2203.01475v2 [eess.IV] UPDATED)
27. PHTrans: Parallelly Aggregating Global and Local Representations for Medical Image Segmentation. (arXiv:2203.04568v2 [eess.IV] UPDATED)
28. Uni4Eye: Unified 2D and 3D Self-supervised Pre-training via Masked Image Modeling Transformer for Ophthalmic Image Classification. (arXiv:2203.04614v2 [eess.IV] UPDATED)
## cs.LG
---
**210** new papers in cs.LG:-) 
1. Tactile-ViewGCN: Learning Shape Descriptor from Tactile Data using Graph Convolutional Network. (arXiv:2203.06183v1 [cs.RO])
2. Leveraging universality of jet taggers through transfer learning. (arXiv:2203.06210v1 [hep-ph])
3. TrafPS: A Visual Analysis System Interpreting Traffic Prediction in Shapley. (arXiv:2203.06213v1 [cs.HC])
4. Learning cardiac activation maps from 12-lead ECG with multi-fidelity Bayesian optimization on manifolds. (arXiv:2203.06222v1 [eess.SP])
5. Generalized Key-Value Memory to Flexibly Adjust Redundancy in Memory-Augmented Networks. (arXiv:2203.06223v1 [cs.LG])
6. verBERT: Automating Brazilian Case Law Document Multi-label Categorization Using BERT. (arXiv:2203.06224v1 [cs.LG])
7. Sampling Bias Correction for Supervised Machine Learning: A Bayesian Inference Approach with Practical Applications. (arXiv:2203.06239v1 [stat.ML])
8. AI agents for facilitating social interactions and wellbeing. (arXiv:2203.06244v1 [cs.CY])
9. Pressure Ulcer Categorisation using Deep Learning: A Clinical Trial to Evaluate Model Performance. (arXiv:2203.06248v1 [cs.LG])
10. Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task. (arXiv:2203.06250v1 [cs.LG])
11. Preliminary experiments on automatic gender recognition based on online capital letters. (arXiv:2203.06265v1 [cs.CV])
12. Parameter Inference of Time Series by Delay Embeddings and Learning Differentiable Operators. (arXiv:2203.06269v1 [cs.LG])
13. Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory. (arXiv:2203.06271v1 [cs.IT])
14. Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications. (arXiv:2203.06273v1 [cs.IT])
15. SOCKS: A Stochastic Optimal Control and Reachability Toolbox Using Kernel Methods. (arXiv:2203.06290v1 [cs.LG])
16. Instance-Dependent Regret Analysis of Kernelized Bandits. (arXiv:2203.06297v1 [cs.LG])
17. The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy. (arXiv:2203.06345v1 [cs.LG])
18. Combining Deep Learning with Physics Based Features in Explosion-Earthquake Discrimination. (arXiv:2203.06347v1 [physics.geo-ph])
19. The Health Gym: Synthetic Health-Related Datasets for the Development of Reinforcement Learning Algorithms. (arXiv:2203.06369v1 [cs.LG])
20. Varying Coefficient Linear Discriminant Analysis via B-Spline Approximation. (arXiv:2203.06371v1 [stat.ME])
21. GRAND+: Scalable Graph Random Neural Networks. (arXiv:2203.06389v1 [cs.LG])
22. A Proposal to Study "Is High Quality Data All We Need?". (arXiv:2203.06404v1 [cs.LG])
23. Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems. (arXiv:2203.06416v1 [cs.AI])
24. Categories of Differentiable Polynomial Circuits for Machine Learning. (arXiv:2203.06430v1 [cs.LG])
25. Deep learning-based conditional inpainting for **restoration** of artifact-affected 4D CT images. (arXiv:2203.06431v1 [physics.med-ph])
26. Equivariant Graph Mechanics Networks with Constraints. (arXiv:2203.06442v1 [cs.LG])
27. Energy networks for state estimation with random sensors using sparse labels. (arXiv:2203.06456v1 [cs.LG])
28. Low-Rank Softmax Can Have Unargmaxable Classes in Theory but Rarely in Practice. (arXiv:2203.06462v1 [cs.LG])
29. A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
30. Towards On-Device AI and Blockchain for 6G enabled Agricultural Supply-chain Management. (arXiv:2203.06465v1 [cs.AI])
31. G$^3$SR: Global Graph Guided Session-based Recommendation. (arXiv:2203.06467v1 [cs.IR])
32. Optimizer Amalgamation. (arXiv:2203.06474v1 [cs.LG])
33. GATSBI: Generative Adversarial Training for Simulation-Based Inference. (arXiv:2203.06481v1 [stat.ML])
34. TEN: Twin Embedding Networks for the Jigsaw Puzzle Problem with Eroded Boundaries. (arXiv:2203.06488v1 [cs.CV])
35. The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. (arXiv:2203.06498v1 [cs.LG])
36. Wasserstein Adversarial Transformer for Cloud Workload Prediction. (arXiv:2203.06501v1 [cs.LG])
37. Sparsity and Heterogeneous Dropout for Continual Learning in the Null Space of Neural Activations. (arXiv:2203.06514v1 [cs.LG])
38. Whats Missing? Learning Hidden Markov Models When the Locations of Missing Observations are Unknown. (arXiv:2203.06527v1 [stat.ML])
39. Reinforced Imitative Graph Learning for Mobile User Profiling. (arXiv:2203.06550v1 [cs.AI])
40. Query-Efficient Black-box Adversarial Attacks Guided by a Transfer-based Prior. (arXiv:2203.06560v1 [cs.LG])
41. Symbolic Learning to Optimize: Towards Interpretability and Scalability. (arXiv:2203.06578v1 [cs.LG])
42. Policy Learning for Robust Markov Decision Process with a Mismatched Generative Mode. (arXiv:2203.06587v1 [cs.LG])
43. AugShuffleNet: Improve ShuffleNetV2 via More Information Communication. (arXiv:2203.06589v1 [cs.CV])
44. ORDSIM: Ordinal Regression for E-Commerce Query Similarity Prediction. (arXiv:2203.06591v1 [cs.LG])
45. Informative Causality Extraction from Medical Literature via Dependency-tree based Patterns. (arXiv:2203.06592v1 [cs.CL])
46. Context-LSTM: a robust classifier for video detection on UCF101. (arXiv:2203.06610v1 [cs.CV])
47. ALDI++: Automatic and parameter-less discord and outlier detection for building energy load profiles. (arXiv:2203.06618v1 [cs.LG])
48. Scaling the Wild: Decentralizing Hogwild!-style Shared-memory SGD. (arXiv:2203.06638v1 [cs.LG])
49. Measuring anomalies in cigarette sales by using official data from Spanish provinces: Are there only the anomalies detected by the Empty Pack Surveys (EPS) used by Transnational Tobacco Companies (TTCs)?. (arXiv:2203.06640v1 [stat.AP])
50. Exploring Customer Price Preference and Product Profit Role in Recommender Systems. (arXiv:2203.06641v1 [cs.IR])
51. The Yield Curve as a Recession Leading Indicator. An Application for Gradient Boosting and Random Forest. (arXiv:2203.06648v1 [stat.ML])
52. Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4. (arXiv:2203.06649v1 [q-bio.NC])
53. DARA: Dynamics-Aware Reward Augmentation in Offline Reinforcement Learning. (arXiv:2203.06662v1 [cs.LG])
54. FlexBlock: A Flexible DNN Training Accelerator with Multi-Mode Block Floating Point Support. (arXiv:2203.06673v1 [cs.LG])
55. Set-valued prediction in hierarchical classification with constrained representation complexity. (arXiv:2203.06676v1 [cs.LG])
56. Algebraic Learning: Towards Interpretable Information Modeling. (arXiv:2203.06690v1 [cs.LG])
57. A Survey on Deep Graph Generation: Methods and Applications. (arXiv:2203.06714v1 [cs.LG])
58. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
59. Private Non-Convex Federated Learning Without a Trusted Server. (arXiv:2203.06735v1 [cs.LG])
60. TurbuGAN: An Adversarial Learning Approach to Spatially-Varying Multiframe Blind Deconvolution with Applications to Imaging Through Turbulence. (arXiv:2203.06764v1 [cs.CV])
61. Algorithmic Recourse in the Face of Noisy Human Responses. (arXiv:2203.06768v1 [cs.LG])
62. Adaptive Model Predictive Control by Learning Classifiers. (arXiv:2203.06783v1 [cs.RO])
63. The Role of Local Steps in Local SGD. (arXiv:2203.06798v1 [cs.LG])
64. MetaBalance: Improving Multi-Task Recommendations via Adapting Gradient Magnitudes of Auxiliary Tasks. (arXiv:2203.06801v1 [cs.LG])
65. Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits. (arXiv:2203.06803v1 [cs.LG])
66. Automated Learning for Deformable Medical Image Registration by Jointly Optimizing Network Architectures and Objective Functions. (arXiv:2203.06810v1 [cs.CV])
67. CheckSel: Efficient and Accurate Data-valuation Through Online Checkpoint Selection. (arXiv:2203.06814v1 [cs.LG])
68. Semi-Discrete Normalizing Flows through Differentiable Tessellation. (arXiv:2203.06832v1 [cs.LG])
69. A Comparative Study on Forecasting of Retail Sales. (arXiv:2203.06848v1 [cs.LG])
70. Doubly Robust Crowdsourcing. (arXiv:1906.08591v2 [cs.HC] UPDATED)
71. MACER: Attack-free and Scalable Robust Training via Maximizing Certified Radius. (arXiv:2001.02378v4 [cs.LG] UPDATED)
72. Integrating Scientific Knowledge with Machine Learning for Engineering and Environmental Systems. (arXiv:2003.04919v6 [physics.comp-ph] UPDATED)
73. In Pursuit of Interpretable, Fair and Accurate Machine Learning for Criminal Recidivism Prediction. (arXiv:2005.04176v3 [stat.ML] UPDATED)
74. Analogical Proportions. (arXiv:2006.02854v12 [cs.LO] UPDATED)
75. The Hidden Convex Optimization Landscape of Two-Layer ReLU Neural Networks: an Exact Characterization of the Optimal Solutions. (arXiv:2006.05900v4 [cs.LG] UPDATED)
76. Acquisition of Channel State Information for mmWave Massive MIMO: Traditional and Machine Learning-based Approaches. (arXiv:2006.08894v2 [eess.SP] UPDATED)
77. Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search. (arXiv:2007.00708v2 [cs.LG] UPDATED)
78. Split and Expand: An inference-time improvement for Weakly Supervised Cell Instance Segmentation. (arXiv:2007.10817v3 [cs.CV] UPDATED)
79. Efficient Transformers: A Survey. (arXiv:2009.06732v3 [cs.LG] UPDATED)
80. SWIPENET: Object detection in noisy underwater images. (arXiv:2010.10006v3 [cs.CV] UPDATED)
81. Distributed Saddle-Point Problems: Lower Bounds, Near-Optimal and Robust Algorithms. (arXiv:2010.13112v7 [cs.LG] UPDATED)
82. Bayesian Deep Learning via Subnetwork Inference. (arXiv:2010.14689v4 [cs.LG] UPDATED)
83. Revisiting Model-Agnostic Private Learning: Faster Rates and Active Learning. (arXiv:2011.03186v4 [cs.LG] UPDATED)
84. Entropic regularization of Wasserstein distance between infinite-dimensional Gaussian measures and Gaussian processes. (arXiv:2011.07489v3 [stat.ML] UPDATED)
85. Compressive Sensing Approaches for Sparse Distribution Estimation Under Local Privacy. (arXiv:2012.02081v2 [cs.IT] UPDATED)
86. Data Appraisal Without Data Sharing. (arXiv:2012.06430v2 [cs.LG] UPDATED)
87. Visually Grounding Language Instruction for History-Dependent Manipulation. (arXiv:2012.08977v2 [cs.RO] UPDATED)
88. Meta Learning Backpropagation And Improving It. (arXiv:2012.14905v4 [cs.LG] UPDATED)
89. HINT: Hierarchical Interaction Network for Trial Outcome Prediction Leveraging Web Data. (arXiv:2102.04252v3 [cs.CY] UPDATED)
90. Learning-augmented count-min sketches via Bayesian nonparametrics. (arXiv:2102.04462v2 [stat.ML] UPDATED)
91. GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v4 [cs.LG] UPDATED)
92. New Algorithms for Discrete-Time Parameter Estimation. (arXiv:2103.16653v2 [cs.LG] UPDATED)
93. Qubit Routing using Graph Neural Network aided Monte Carlo Tree Search. (arXiv:2104.01992v2 [quant-ph] UPDATED)
94. Survey on reinforcement learning for language processing. (arXiv:2104.05565v2 [cs.CL] UPDATED)
95. Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis. (arXiv:2104.08336v2 [eess.SP] UPDATED)
96. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v4 [cs.CL] UPDATED)
97. Exploiting Explanations for Model Inversion Attacks. (arXiv:2104.12669v3 [cs.CV] UPDATED)
98. Reward (Mis)design for Autonomous Driving. (arXiv:2104.13906v2 [cs.LG] UPDATED)
99. Efficient Stochastic Optimal Control through Approximate Bayesian Input Inference. (arXiv:2105.07693v2 [cs.LG] UPDATED)
100. Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v3 [cs.LG] UPDATED)
101. When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations. (arXiv:2106.01548v3 [cs.CV] UPDATED)
102. Exploring Memorization in Adversarial Training. (arXiv:2106.01606v2 [cs.LG] UPDATED)
103. Churn Reduction via Distillation. (arXiv:2106.02654v2 [cs.LG] UPDATED)
104. The Medkit-Learn(ing) Environment: Medical Decision Modelling through Simulation. (arXiv:2106.04240v2 [cs.LG] UPDATED)
105. Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v2 [cs.LG] UPDATED)
106. Measuring the robustness of Gaussian processes to kernel choice. (arXiv:2106.06510v2 [stat.ML] UPDATED)
107. KL Guided Domain Adaptation. (arXiv:2106.07780v2 [cs.LG] UPDATED)
108. Ada-BKB: Scalable Gaussian Process Optimization on Continuous Domains by Adaptive Discretization. (arXiv:2106.08598v3 [cs.LG] UPDATED)
109. Analysis and Optimisation of Bellman Residual Errors with Neural Function Approximation. (arXiv:2106.08774v5 [cs.LG] UPDATED)
110. Shuffle Private Stochastic Convex Optimization. (arXiv:2106.09805v2 [cs.LG] UPDATED)
111. Bayesian Inference in High-Dimensional Time-Serieswith the Orthogonal Stochastic Linear Mixing Model. (arXiv:2106.13379v2 [cs.LG] UPDATED)
112. Laplace Redux -- Effortless Bayesian Deep Learning. (arXiv:2106.14806v3 [cs.LG] UPDATED)
113. Data Poisoning Won't Save You From Facial Recognition. (arXiv:2106.14851v2 [cs.LG] UPDATED)
114. MAML is a Noisy Contrastive Learner in Classification. (arXiv:2106.15367v4 [cs.LG] UPDATED)
115. ResIST: Layer-Wise Decomposition of ResNets for Distributed Training. (arXiv:2107.00961v2 [cs.LG] UPDATED)
116. Leveraging Graph and Deep Learning Uncertainties to Detect Anomalous Trajectories. (arXiv:2107.01557v2 [cs.LG] UPDATED)
117. SGD with a Constant Large Learning Rate Can Converge to Local Maxima. (arXiv:2107.11774v3 [cs.LG] UPDATED)
118. Automated Human Cell Classification in Sparse Datasets using Few-Shot Learning. (arXiv:2107.13093v2 [cs.CV] UPDATED)
119. Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
120. Mal2GCN: A Robust Malware Detection Approach Using Deep Graph Convolutional Networks With Non-Negative Weights. (arXiv:2108.12473v2 [cs.CR] UPDATED)
121. Neural Network Gaussian Processes by Increasing Depth. (arXiv:2108.12862v2 [cs.LG] UPDATED)
122. PowerGym: A Reinforcement Learning Environment for Volt-Var Control in Power Distribution Systems. (arXiv:2109.03970v3 [cs.LG] UPDATED)
123. Soft Actor-Critic With Integer Actions. (arXiv:2109.08512v2 [cs.LG] UPDATED)
124. Learning in Sinusoidal Spaces with Physics-Informed Neural Networks. (arXiv:2109.09338v2 [cs.LG] UPDATED)
125. A Multi-Agent Deep Reinforcement Learning Coordination Framework for Connected and Automated Vehicles at Merging Roadways. (arXiv:2109.11672v2 [eess.SY] UPDATED)
126. Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations. (arXiv:2109.13059v4 [cs.CL] UPDATED)
127. Quantum Semi-Supervised Learning with Quantum Supremacy. (arXiv:2110.02343v3 [quant-ph] UPDATED)
128. Learning Sparse Masks for Diffusion-based Image Inpainting. (arXiv:2110.02636v3 [eess.IV] UPDATED)
129. Multi-objective Optimization by Learning Space Partitions. (arXiv:2110.03173v3 [cs.LG] UPDATED)
130. Understanding Domain Randomization for Sim-to-real Transfer. (arXiv:2110.03239v2 [cs.LG] UPDATED)
131. Near-Optimal Reward-Free Exploration for Linear Mixture MDPs with Plug-in Solver. (arXiv:2110.03244v4 [cs.LG] UPDATED)
132. Hyperparameter Tuning with Renyi Differential Privacy. (arXiv:2110.03620v2 [cs.LG] UPDATED)
133. Training Transition Policies via Distribution Matching for Complex Tasks. (arXiv:2110.04357v2 [cs.LG] UPDATED)
134. Rethinking Supervised Pre-training for Better Downstream Transferring. (arXiv:2110.06014v2 [cs.CV] UPDATED)
135. Crystal Diffusion Variational Autoencoder for Periodic Material Generation. (arXiv:2110.06197v3 [cs.LG] UPDATED)
136. Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design. (arXiv:2110.06389v2 [cs.LG] UPDATED)
137. Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?. (arXiv:2110.06918v2 [cs.CL] UPDATED)
138. Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings. (arXiv:2110.07385v2 [cs.CL] UPDATED)
139. Towards Better Plasticity-Stability Trade-off in Incremental Learning: A Simple Linear Connector. (arXiv:2110.07905v2 [cs.LG] UPDATED)
140. Actor-critic is implicitly biased towards high entropy optimal policies. (arXiv:2110.11280v2 [cs.LG] UPDATED)
141. An Operator Theoretic View on Pruning Deep Neural Networks. (arXiv:2110.14856v3 [cs.LG] UPDATED)
142. Manipulation of Granular Materials by Learning Particle Interactions. (arXiv:2111.02274v3 [cs.RO] UPDATED)
143. Augmentations in Graph Contrastive Learning: Current Methodological Flaws & Towards Better Practices. (arXiv:2111.03220v2 [cs.LG] UPDATED)
144. Cold Brew: Distilling Graph Node Representations with Incomplete or Missing Neighborhoods. (arXiv:2111.04840v3 [cs.LG] UPDATED)
145. Active Sampling for Linear Regression Beyond the $\ell_2$ Norm. (arXiv:2111.04888v2 [cs.LG] UPDATED)
146. Enhancing Backdoor Attacks with Multi-Level MMD Regularization. (arXiv:2111.05077v2 [cs.LG] UPDATED)
147. Learning Perceptual Concepts by Bootstrapping from Human Queries. (arXiv:2111.05251v2 [cs.RO] UPDATED)
148. On Sparse High-Dimensional Graphical Model Learning For Dependent Time Series. (arXiv:2111.07897v2 [eess.SP] UPDATED)
149. Learn Locally, Correct Globally: A Distributed Algorithm for Training Graph Neural Networks. (arXiv:2111.08202v4 [cs.LG] UPDATED)
150. Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection. (arXiv:2111.09099v6 [cs.CV] UPDATED)
151. Density Ratio Estimation via Infinitesimal Classification. (arXiv:2111.11010v2 [cs.LG] UPDATED)
152. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v8 [cs.CV] UPDATED)
153. Bootstrap Your Flow. (arXiv:2111.11510v4 [cs.LG] UPDATED)
154. Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization. (arXiv:2111.13807v2 [cs.LG] UPDATED)
155. ConDA: Unsupervised Domain Adaptation for LiDAR Segmentation via Regularized Domain Concatenation. (arXiv:2111.15242v2 [cs.CV] UPDATED)
156. Fast Topological Clustering with Wasserstein Distance. (arXiv:2112.00101v2 [cs.LG] UPDATED)
157. Self-Organized Polynomial-Time Coordination Graphs. (arXiv:2112.03547v2 [cs.LG] UPDATED)
158. Regularized Modal Regression on Markov-dependent Observations: A Theoretical Assessment. (arXiv:2112.04779v2 [stat.ML] UPDATED)
159. Learning Transferable Motor Skills with Hierarchical Latent Mixture Policies. (arXiv:2112.05062v2 [cs.LG] UPDATED)
160. Neural Network-based Power Flow Model. (arXiv:2112.08418v2 [eess.SY] UPDATED)
161. Learning Interpretable Models Through Multi-Objective Neural Architecture Search. (arXiv:2112.08645v2 [cs.LG] UPDATED)
162. WebGPT: Browser-assisted question-answering with human feedback. (arXiv:2112.09332v2 [cs.CL] UPDATED)
163. Towards Federated Learning on Time-Evolving Heterogeneous Data. (arXiv:2112.13246v2 [cs.LG] UPDATED)
164. PRIME: A few primitives can boost robustness to common corruptions. (arXiv:2112.13547v2 [cs.CV] UPDATED)
165. Enabling Verification of Deep Neural Networks in Perception Tasks Using Fuzzy Logic and Concept Embeddings. (arXiv:2201.00572v2 [cs.CV] UPDATED)
166. Robust Linear Predictions: Analyses of Uniform Concentration, Fast Rates and Model Misspecification. (arXiv:2201.01973v2 [stat.ML] UPDATED)
167. MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v2 [cs.CV] UPDATED)
168. Detecting CAN Masquerade Attacks with Signal Clustering Similarity. (arXiv:2201.02665v2 [cs.CR] UPDATED)
169. Assemble Foundation Models for Automatic Code Summarization. (arXiv:2201.05222v2 [cs.SE] UPDATED)
170. Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios. (arXiv:2201.08474v2 [cs.CR] UPDATED)
171. Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming. (arXiv:2201.08484v2 [cs.MA] UPDATED)
172. Predicting Physics in Mesh-reduced Space with Temporal Attention. (arXiv:2201.09113v2 [cs.LG] UPDATED)
173. Two heads are better than one: Enhancing medical representations by pre-training over structured and unstructured electronic health records. (arXiv:2201.10113v3 [cs.CL] UPDATED)
174. Neural Architecture Search for Spiking Neural Networks. (arXiv:2201.10355v2 [cs.NE] UPDATED)
175. Language-biased image classification: evaluation based on semantic representations. (arXiv:2201.11014v2 [cs.CV] UPDATED)
176. LAP: An Attention-Based Module for Faithful Interpretation and Knowledge Injection in Convolutional Neural Networks. (arXiv:2201.11808v2 [cs.CV] UPDATED)
177. Can Wikipedia Help Offline Reinforcement Learning?. (arXiv:2201.12122v2 [cs.LG] UPDATED)
178. Calibration of P-values for calibration and for deviation of a subpopulation from the full population. (arXiv:2202.00100v2 [stat.ME] UPDATED)
179. L3Cube-MahaCorpus and MahaBERT: Marathi Monolingual Corpus, Marathi BERT Language Models, and Resources. (arXiv:2202.01159v2 [cs.CL] UPDATED)
180. Weighted Random Cut Forest Algorithm for Anomaly Detection. (arXiv:2202.01891v4 [cs.LG] UPDATED)
181. Accelerometer-based Bed Occupancy Detection for Automatic, Non-invasive Long-term Cough Monitoring. (arXiv:2202.03936v2 [cs.LG] UPDATED)
182. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v3 [cs.RO] UPDATED)
183. Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam. (arXiv:2202.06009v2 [cs.LG] UPDATED)
184. Evolving Neural Networks with Optimal Balance between Information Flow and Connections Cost. (arXiv:2202.06163v4 [cs.NE] UPDATED)
185. A Prospective Approach for Human-to-Human Interaction Recognition from Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural Network with GUI Application Implementation. (arXiv:2202.08146v2 [cs.LG] UPDATED)
186. On the Implicit Bias Towards Minimal Depth of Deep Neural Networks. (arXiv:2202.09028v2 [cs.LG] UPDATED)
187. Off-Policy Confidence Interval Estimation with Confounded Markov Decision Process. (arXiv:2202.10589v2 [stat.ML] UPDATED)
188. Designing Decision Support Systems for Emergency Response: Challenges and Opportunities. (arXiv:2202.11268v2 [cs.AI] UPDATED)
189. Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v2 [cs.LG] UPDATED)
190. Effectiveness of Delivered Information Trade Study. (arXiv:2203.00116v2 [cs.CV] UPDATED)
191. On genetic programming representations and fitness functions for interpretable dimensionality reduction. (arXiv:2203.00528v2 [cs.NE] UPDATED)
192. On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features. (arXiv:2203.01238v2 [cs.LG] UPDATED)
193. Weakly Supervised Object Localization as Domain Adaption. (arXiv:2203.01714v2 [cs.CV] UPDATED)
194. Speech watermarking: an approach for the forensic analysis of digital telephonic recordings. (arXiv:2203.02275v2 [cs.CR] UPDATED)
195. Koopman operator for time-dependent reliability analysis. (arXiv:2203.02658v2 [stat.ML] UPDATED)
196. Singular Value Perturbation and Deep Network Optimization. (arXiv:2203.03099v2 [cs.LG] UPDATED)
197. Generalized Spectral Clustering for Directed and Undirected Graphs. (arXiv:2203.03221v2 [stat.ML] UPDATED)
198. GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records. (arXiv:2203.03540v2 [cs.CL] UPDATED)
199. Assessment of contextualised representations in detecting outcome phrases in clinical trials. (arXiv:2203.03547v2 [cs.CL] UPDATED)
200. The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another in Neural Networks. (arXiv:2203.04466v2 [cs.LG] UPDATED)
201. All You Need is LUV: Unsupervised Collection of Labeled Images using Invisible UV Fluorescent Indicators. (arXiv:2203.04566v2 [cs.CV] UPDATED)
202. CEU-Net: Ensemble Semantic Segmentation of Hyperspectral Images Using Clustering. (arXiv:2203.04873v2 [cs.CV] UPDATED)
203. Deep Generative Models for Downlink Channel Estimation in FDD Massive MIMO Systems. (arXiv:2203.04935v2 [cs.IT] UPDATED)
204. Universal Regression with Adversarial Responses. (arXiv:2203.05067v2 [cs.LG] UPDATED)
205. projUNN: efficient method for training deep networks with unitary matrices. (arXiv:2203.05483v2 [cs.LG] UPDATED)
206. Geometric and Topological Inference for Deep Representations of Complex Networks. (arXiv:2203.05488v2 [cs.LG] UPDATED)
207. SoftSNN: Low-Cost Fault Tolerance for Spiking Neural Network Accelerators under Soft Errors. (arXiv:2203.05523v2 [cs.AR] UPDATED)
208. Overcoming Temptation: Incentive Design For Intertemporal Choice. (arXiv:2203.05782v2 [cs.LG] UPDATED)
209. An Empirical Study of Graphormer on Large-Scale Molecular Modeling Datasets. (arXiv:2203.06123v2 [physics.chem-ph] UPDATED)
210. Protein Representation Learning by Geometric Structure Pretraining. (arXiv:2203.06125v2 [cs.LG] UPDATED)
## cs.AI
---
**116** new papers in cs.AI:-) 
1. Can I see an Example? Active Learning the Long Tail of Attributes and Relations. (arXiv:2203.06215v1 [cs.CV])
2. CoDA21: Evaluating Language Understanding Capabilities of NLP Models With Context-Definition Alignment. (arXiv:2203.06228v1 [cs.CL])
3. AI agents for facilitating social interactions and wellbeing. (arXiv:2203.06244v1 [cs.CY])
4. An Uncommon Task: Participatory Design in Legal AI. (arXiv:2203.06246v1 [cs.CY])
5. Pressure Ulcer Categorisation using Deep Learning: A Clinical Trial to Evaluate Model Performance. (arXiv:2203.06248v1 [cs.LG])
6. Neural Topic Modeling with Deep Mutual Information Estimation. (arXiv:2203.06298v1 [cs.CL])
7. Ensemble Semi-supervised Entity Alignment via Cycle-teaching. (arXiv:2203.06308v1 [cs.AI])
8. ELLE: Efficient Lifelong Pre-training for Emerging Data. (arXiv:2203.06311v1 [cs.CL])
9. Towards Equal Opportunity Fairness through Adversarial Learning. (arXiv:2203.06317v1 [cs.CL])
10. PillarGrid: Deep Learning-based Cooperative Perception for 3D Object Detection from Onboard-Roadside LiDAR. (arXiv:2203.06319v1 [cs.CV])
11. Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation. (arXiv:2203.06321v1 [cs.CV])
12. What Makes Reading Comprehension Questions Difficult?. (arXiv:2203.06342v1 [cs.CL])
13. Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation. (arXiv:2203.06386v1 [cs.CL])
14. Transition Relation Aware Self-Attention for Session-based Recommendation. (arXiv:2203.06407v1 [cs.IR])
15. Information retrieval for label noise document ranking by bag sampling and group-wise loss. (arXiv:2203.06408v1 [cs.IT])
16. Concentration Network for Reinforcement Learning of Large-Scale Multi-Agent Systems. (arXiv:2203.06416v1 [cs.AI])
17. When did you become so smart, oh wise one?! Sarcasm Explanation in Multi-modal Multi-party Dialogues. (arXiv:2203.06419v1 [cs.CL])
18. A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets. (arXiv:2203.06463v1 [cs.CV])
19. Towards On-Device AI and Blockchain for 6G enabled Agricultural Supply-chain Management. (arXiv:2203.06465v1 [cs.AI])
20. G$^3$SR: Global Graph Guided Session-based Recommendation. (arXiv:2203.06467v1 [cs.IR])
21. Evaluating Explainable AI on a Multi-Modal Medical Imaging Task: Can Existing Algorithms Fulfill Clinical Requirements?. (arXiv:2203.06487v1 [cs.CV])
22. Wasserstein Adversarial Transformer for Cloud Workload Prediction. (arXiv:2203.06501v1 [cs.LG])
23. Sparsity and Heterogeneous Dropout for Continual Learning in the Null Space of Neural Activations. (arXiv:2203.06514v1 [cs.LG])
24. Whats Missing? Learning Hidden Markov Models When the Locations of Missing Observations are Unknown. (arXiv:2203.06527v1 [stat.ML])
25. Reinforced Imitative Graph Learning for Mobile User Profiling. (arXiv:2203.06550v1 [cs.AI])
26. Label-only Model Inversion Attack: The Attack that Requires the Least Information. (arXiv:2203.06555v1 [cs.CR])
27. Model Inversion Attack against Transfer Learning: Inverting a Model without Accessing It. (arXiv:2203.06570v1 [cs.CR])
28. Worst Case Matters for Few-Shot Recognition. (arXiv:2203.06574v1 [cs.CV])
29. Symbolic Learning to Optimize: Towards Interpretability and Scalability. (arXiv:2203.06578v1 [cs.LG])
30. One Parameter Defense -- Defending against Data Inference Attacks via Differential Privacy. (arXiv:2203.06580v1 [cs.CR])
31. Bi-Sampling Approach to Classify Music Mood leveraging Raga-Rasa Association in Indian Classical Music. (arXiv:2203.06583v1 [cs.SD])
32. Deep Learning for 1-Bit Compressed Sensing-based Superimposed CSI Feedback. (arXiv:2203.06606v1 [cs.IT])
33. A Systematic Study and Analysis of Bengali Folklore with Natural Language Processing Systems. (arXiv:2203.06607v1 [cs.CL])
34. Context-LSTM: a robust classifier for video detection on UCF101. (arXiv:2203.06610v1 [cs.CV])
35. A ROS Architecture for Personalised HRI with a Bartender Social Robot. (arXiv:2203.06631v1 [cs.RO])
36. Exploring Customer Price Preference and Product Profit Role in Recommender Systems. (arXiv:2203.06641v1 [cs.IR])
37. Joint rotational invariance and adversarial training of a dual-stream Transformer yields state of the art Brain-Score for Area V4. (arXiv:2203.06649v1 [q-bio.NC])
38. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v1 [cs.CV])
39. Towards Personalized Intelligence at Scale. (arXiv:2203.06668v1 [cs.CL])
40. FlexBlock: A Flexible DNN Training Accelerator with Multi-Mode Block Floating Point Support. (arXiv:2203.06673v1 [cs.LG])
41. Set-valued prediction in hierarchical classification with constrained representation complexity. (arXiv:2203.06676v1 [cs.LG])
42. Algebraic Learning: Towards Interpretable Information Modeling. (arXiv:2203.06690v1 [cs.LG])
43. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v1 [cs.CV])
44. CMKD: CNN/Transformer-Based Cross-Model Knowledge Distillation for Audio Classification. (arXiv:2203.06760v1 [cs.SD])
45. Adaptive Model Predictive Control by Learning Classifiers. (arXiv:2203.06783v1 [cs.RO])
46. Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits. (arXiv:2203.06803v1 [cs.LG])
47. Putting Ridesharing to the Test: Efficient and Scalable Solutions and the Power of Dynamic Vehicle Relocation. (arXiv:1912.08066v3 [cs.MA] UPDATED)
48. Analogical Proportions. (arXiv:2006.02854v12 [cs.LO] UPDATED)
49. Learning Search Space Partition for Black-box Optimization using Monte Carlo Tree Search. (arXiv:2007.00708v2 [cs.LG] UPDATED)
50. A Review on Drivers Red Light Running Behavior Predictions and Technology Based Countermeasures. (arXiv:2008.06727v3 [cs.AI] UPDATED)
51. Efficient Transformers: A Survey. (arXiv:2009.06732v3 [cs.LG] UPDATED)
52. Knowledge Guided Learning: Towards Open Domain Egocentric Action Recognition with Zero Supervision. (arXiv:2009.07470v2 [cs.CV] UPDATED)
53. A Distributed Differentially Private Algorithm for Resource Allocation in Unboundedly Large Settings. (arXiv:2011.07934v2 [cs.MA] UPDATED)
54. Zero-Shot Visual Slot Filling as Question Answering. (arXiv:2011.12340v2 [cs.AI] UPDATED)
55. Conditional independence structures over four discrete random variables revisited: conditional Ingleton inequalities. (arXiv:2012.04092v3 [cs.IT] UPDATED)
56. Meta Learning Backpropagation And Improving It. (arXiv:2012.14905v4 [cs.LG] UPDATED)
57. HINT: Hierarchical Interaction Network for Trial Outcome Prediction Leveraging Web Data. (arXiv:2102.04252v3 [cs.CY] UPDATED)
58. Nominal Unification and Matching of Higher Order Expressions with Recursive Let. (arXiv:2102.08146v2 [cs.LO] UPDATED)
59. GIST: Distributed Training for Large-Scale Graph Convolutional Networks. (arXiv:2102.10424v4 [cs.LG] UPDATED)
60. Toward Building Science Discovery Machines. (arXiv:2103.15551v7 [cs.AI] UPDATED)
61. Survey on reinforcement learning for language processing. (arXiv:2104.05565v2 [cs.CL] UPDATED)
62. Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis. (arXiv:2104.08336v2 [eess.SP] UPDATED)
63. Cross-Task Generalization via Natural Language Crowdsourcing Instructions. (arXiv:2104.08773v4 [cs.CL] UPDATED)
64. Learning Robust Recommenders through Cross-Model Agreement. (arXiv:2105.09605v3 [cs.IR] UPDATED)
65. Churn Reduction via Distillation. (arXiv:2106.02654v2 [cs.LG] UPDATED)
66. Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v2 [cs.LG] UPDATED)
67. MAML is a Noisy Contrastive Learner in Classification. (arXiv:2106.15367v4 [cs.LG] UPDATED)
68. Leveraging Graph and Deep Learning Uncertainties to Detect Anomalous Trajectories. (arXiv:2107.01557v2 [cs.LG] UPDATED)
69. Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning. (arXiv:2107.03961v5 [cs.AI] UPDATED)
70. IGrow: A Smart Agriculture Solution to Autonomous Greenhouse Control. (arXiv:2107.05464v2 [cs.AI] UPDATED)
71. TAPEX: Table Pre-training via Learning a Neural SQL Executor. (arXiv:2107.07653v3 [cs.CL] UPDATED)
72. Automated Human Cell Classification in Sparse Datasets using Few-Shot Learning. (arXiv:2107.13093v2 [cs.CV] UPDATED)
73. Fact-Tree Reasoning for N-ary Question Answering over Knowledge Graphs. (arXiv:2108.08297v2 [cs.AI] UPDATED)
74. Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v6 [cs.LG] UPDATED)
75. Neural Network Gaussian Processes by Increasing Depth. (arXiv:2108.12862v2 [cs.LG] UPDATED)
76. PowerGym: A Reinforcement Learning Environment for Volt-Var Control in Power Distribution Systems. (arXiv:2109.03970v3 [cs.LG] UPDATED)
77. DPMPC-Planner: A real-time UAV trajectory planning framework for complex static environments with dynamic obstacles. (arXiv:2109.07024v2 [cs.RO] UPDATED)
78. Soft Actor-Critic With Integer Actions. (arXiv:2109.08512v2 [cs.LG] UPDATED)
79. Learning in Sinusoidal Spaces with Physics-Informed Neural Networks. (arXiv:2109.09338v2 [cs.LG] UPDATED)
80. A Multi-Agent Deep Reinforcement Learning Coordination Framework for Connected and Automated Vehicles at Merging Roadways. (arXiv:2109.11672v2 [eess.SY] UPDATED)
81. Trans-Encoder: Unsupervised sentence-pair modelling through self- and mutual-distillations. (arXiv:2109.13059v4 [cs.CL] UPDATED)
82. Multi-objective Optimization by Learning Space Partitions. (arXiv:2110.03173v3 [cs.LG] UPDATED)
83. Training Transition Policies via Distribution Matching for Complex Tasks. (arXiv:2110.04357v2 [cs.LG] UPDATED)
84. Ego4D: Around the World in 3,000 Hours of Egocentric Video. (arXiv:2110.07058v3 [cs.CV] UPDATED)
85. Towards Better Plasticity-Stability Trade-off in Incremental Learning: A Simple Linear Connector. (arXiv:2110.07905v2 [cs.LG] UPDATED)
86. Learning Perceptual Concepts by Bootstrapping from Human Queries. (arXiv:2111.05251v2 [cs.RO] UPDATED)
87. Rethinking Keypoint Representations: Modeling Keypoints and Poses as Objects for Multi-Person Human Pose Estimation. (arXiv:2111.08557v3 [cs.CV] UPDATED)
88. Bootstrap Your Flow. (arXiv:2111.11510v4 [cs.LG] UPDATED)
89. Offline Neural Contextual Bandits: Pessimism, Optimization and Generalization. (arXiv:2111.13807v2 [cs.LG] UPDATED)
90. Self-Organized Polynomial-Time Coordination Graphs. (arXiv:2112.03547v2 [cs.LG] UPDATED)
91. Learning Transferable Motor Skills with Hierarchical Latent Mixture Policies. (arXiv:2112.05062v2 [cs.LG] UPDATED)
92. Learning Interpretable Models Through Multi-Objective Neural Architecture Search. (arXiv:2112.08645v2 [cs.LG] UPDATED)
93. WebGPT: Browser-assisted question-answering with human feedback. (arXiv:2112.09332v2 [cs.CL] UPDATED)
94. CI-AVSR: A Cantonese Audio-Visual Speech Dataset for In-car Command Recognition. (arXiv:2201.03804v2 [cs.CL] UPDATED)
95. Iterated Reasoning with Mutual Information in Cooperative and Byzantine Decentralized Teaming. (arXiv:2201.08484v2 [cs.MA] UPDATED)
96. Neural Architecture Search for Spiking Neural Networks. (arXiv:2201.10355v2 [cs.NE] UPDATED)
97. Can Wikipedia Help Offline Reinforcement Learning?. (arXiv:2201.12122v2 [cs.LG] UPDATED)
98. Novelty Controlled Paraphrase Generation with Retrieval Augmented Conditional Prompt Tuning. (arXiv:2202.00535v2 [cs.CL] UPDATED)
99. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v3 [cs.RO] UPDATED)
100. A Prospective Approach for Human-to-Human Interaction Recognition from Wi-Fi Channel Data using Attention Bidirectional Gated Recurrent Neural Network with GUI Application Implementation. (arXiv:2202.08146v2 [cs.LG] UPDATED)
101. Designing Decision Support Systems for Emergency Response: Challenges and Opportunities. (arXiv:2202.11268v2 [cs.AI] UPDATED)
102. Brain Principles Programming. (arXiv:2202.12710v2 [q-bio.NC] UPDATED)
103. ASSIST: Towards Label Noise-Robust Dialogue State Tracking. (arXiv:2202.13024v2 [cs.CL] UPDATED)
104. QuoteR: A Benchmark of Quote Recommendation for Writing. (arXiv:2202.13145v2 [cs.CL] UPDATED)
105. Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation. (arXiv:2202.13663v2 [cs.CL] UPDATED)
106. On the Optimization Landscape of Neural Collapse under MSE Loss: Global Optimality with Unconstrained Features. (arXiv:2203.01238v2 [cs.LG] UPDATED)
107. GraspARL: Dynamic Grasping via Adversarial Reinforcement Learning. (arXiv:2203.02119v2 [cs.RO] UPDATED)
108. Time-aware Graph Neural Networks for Entity Alignment between Temporal Knowledge Graphs. (arXiv:2203.02150v2 [cs.AI] UPDATED)
109. Story Point Effort Estimation by Text Level Graph Neural Network. (arXiv:2203.03062v2 [cs.SE] UPDATED)
110. GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records. (arXiv:2203.03540v2 [cs.CL] UPDATED)
111. Trusted Data Forever: Is AI the Answer?. (arXiv:2203.03712v2 [cs.CY] UPDATED)
112. Foundations for Grassroots Democratic Metaverse. (arXiv:2203.04090v2 [cs.CY] UPDATED)
113. All You Need is LUV: Unsupervised Collection of Labeled Images using Invisible UV Fluorescent Indicators. (arXiv:2203.04566v2 [cs.CV] UPDATED)
114. projUNN: efficient method for training deep networks with unitary matrices. (arXiv:2203.05483v2 [cs.LG] UPDATED)
115. A new approach to calculating BERTScore for automatic assessment of translation quality. (arXiv:2203.05598v2 [cs.CL] UPDATED)
116. Dual-Domain Reconstruction Networks with V-Net and K-Net for fast MRI. (arXiv:2203.05725v2 [cs.CV] UPDATED)

