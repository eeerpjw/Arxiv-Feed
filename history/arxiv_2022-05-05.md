# Your interest papers
---
## cs.CV
---
### Deep Learning Framework for **Real-time** Fetal Brain Segmentation in MRI. (arXiv:2205.01675v1 [eess.IV])
- Authors : Razieh Faghihpirayesh, Davood Karimi, Deniz Erdogmus, Ali Gholipour
- Link : [http://arxiv.org/abs/2205.01675](http://arxiv.org/abs/2205.01675)
> ABSTRACT  :  Fetal brain segmentation is an important first step for slice-level motion correction and slice-to-volume reconstruction in fetal MRI. Fast and accurate segmentation of the fetal brain on fetal MRI is required to achieve real-time fetal head pose estimation and motion tracking for slice re-acquisition and steering. To address this critical unmet need, in this work we analyzed the speed-accuracy performance of a variety of deep neural network models, and devised a symbolically small convolutional neural network that combines spatial details at high resolution with context features extracted at lower resolutions. We used multiple branches with skip connections to maintain high accuracy while devising a parallel combination of convolution and pooling operations as an input downsampling module to further reduce inference time. We trained our model as well as eight alternative, state-of-the-art networks with manually-labeled fetal brain MRI slices and tested on two sets of normal and challenging test cases. Experimental results show that our network achieved the highest accuracy and lowest inference time among all of the compared state-of-the-art real-time segmentation methods. We achieved average Dice scores of 97.99\% and 84.04\% on the normal and challenging test sets, respectively, with an inference time of 3.36 milliseconds per image on an NVIDIA GeForce RTX 2080 Ti. Code, data, and the trained models are available at https://github.com/bchimagine/real_time_fetal_brain_segmentation.  
### Comparison of CoModGANs, LaMa and GLIDE for Art Inpainting- Completing M.C Escher's Print Gallery. (arXiv:2205.01741v1 [cs.CV])
- Authors : Lucia Cipolina, Simone Caenazzo, Gaston Mazzei
- Link : [http://arxiv.org/abs/2205.01741](http://arxiv.org/abs/2205.01741)
> ABSTRACT  :  Digital art **restoration** has benefited from inpainting models to correct the degradation or missing sections of a painting. This work compares three current state-of-the art models for inpainting of large missing regions. We provide qualitative and quantitative comparison of the performance by CoModGANs, LaMa and GLIDE in inpainting of blurry and missing sections of images. We use Escher's incomplete painting Print Gallery as our test study since it presents several of the challenges commonly present in restorative inpainting.  
### UCL-Dehaze: Towards Real-world Image Dehazing via Unsupervised Contrastive Learning. (arXiv:2205.01871v1 [cs.CV])
- Authors : Yongzhen Wang, Xuefeng Yan, Fu Lee, Haoran Xie, **Wenhan Yang**, Mingqiang Wei, Jing Qin
- Link : [http://arxiv.org/abs/2205.01871](http://arxiv.org/abs/2205.01871)
> ABSTRACT  :  While the wisdom of training an image dehazing model on synthetic hazy data can alleviate the difficulty of collecting real-world hazy/clean image pairs, it brings the well-known domain shift problem. From a different yet new perspective, this paper explores contrastive learning with an adversarial training effort to leverage unpaired real-world hazy and clean images, thus bridging the gap between synthetic and real-world haze is avoided. We propose an effective unsupervised contrastive learning paradigm for image dehazing, dubbed UCL-Dehaze. Unpaired real-world clean and hazy images are easily captured, and will serve as the important positive and negative samples respectively when training our UCL-Dehaze network. To train the network more effectively, we formulate a new self-contrastive perceptual loss function, which encourages the restored images to approach the positive samples and keep away from the negative samples in the embedding space. Besides the overall network architecture of UCL-Dehaze, adversarial training is utilized to align the distributions between the positive samples and the dehazed images. Compared with recent image dehazing works, UCL-Dehaze does not require paired data during training and utilizes unpaired positive/negative data to better enhance the dehazing performance. We conduct comprehensive experiments to evaluate our UCL-Dehaze and demonstrate its superiority over the state-of-the-arts, even only 1,800 unpaired real-world images are used to train our network. Source code has been available at https://github.com/yz-wang/UCL-Dehaze.  
### Pik-Fix: Restoring and Colorizing Old Photo. (arXiv:2205.01902v1 [cs.CV])
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Alan Bovik, Hongkai Yu
- Link : [http://arxiv.org/abs/2205.01902](http://arxiv.org/abs/2205.01902)
> ABSTRACT  :  Restoring and inpainting the visual memories that are present, but often impaired, in old photos remains an intriguing but unsolved research topic. Decades-old photos often suffer from severe and commingled degradation such as cracks, defocus, and color-fading, which are difficult to treat individually and harder to repair when they interact. Deep learning presents a plausible avenue, but the lack of large-scale datasets of old photos makes addressing this **restoration** task very challenging. Here we present a novel reference-based end-to-end learning framework that is able to both repair and colorize old and degraded pictures. Our proposed framework consists of three modules: a **restoration** sub-network that conducts **restoration** from degradations, a similarity sub-network that performs color histogram matching and color transfer, and a colorization subnet that learns to predict the chroma elements of images that have been conditioned on chromatic reference signals. The overall system makes uses of color histogram priors from reference images, which greatly reduces the need for large-scale training data. We have also created a first-of-a-kind public dataset of real old photos that are paired with ground truth "pristine" photos that have been that have been manually restored by PhotoShop experts. We conducted extensive experiments on this dataset and synthetic datasets, and found that our method significantly outperforms previous state-of-the-art models using both qualitative comparisons and quantitative measurements.  
### Self-Supervised Super-Resolution for Multi-**Exposure** Push-Frame Satellites. (arXiv:2205.02031v1 [cs.CV])
- Authors : Ngoc Long, my Anger, Axel Davy, Pablo Arias, Gabriele Facciolo
- Link : [http://arxiv.org/abs/2205.02031](http://arxiv.org/abs/2205.02031)
> ABSTRACT  :  Modern Earth observation satellites capture multi-**exposure** bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-**exposure** sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the **exposure** times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the **exposure** times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-**exposure** approaches that we adapted to the multi-**exposure** case.  
### An Analysis of Generative Methods for Multiple Image Inpainting. (arXiv:2205.02146v1 [cs.CV])
- Authors : Coloma Ballester, Aurelie Bugeau, Samuel Hurault, Simone Parisotto, Patricia Vitoria
- Link : [http://arxiv.org/abs/2205.02146](http://arxiv.org/abs/2205.02146)
> ABSTRACT  :  Image inpainting refers to the **restoration** of an image with missing regions in a way that is not detectable by the observer. The inpainting regions can be of any size and shape. This is an ill-posed inverse problem that does not have a unique solution. In this work, we focus on learning-based image completion methods for multiple and diverse inpainting which goal is to provide a set of distinct solutions for a given damaged image. These methods capitalize on the probabilistic nature of certain generative models to sample various solutions that coherently restore the missing content. Along the chapter, we will analyze the underlying theory and analyze the recent proposals for multiple inpainting. To investigate the pros and cons of each method, we present quantitative and qualitative comparisons, on common datasets, regarding both the quality and the diversity of the set of inpainted solutions. Our analysis allows us to identify the most successful generative strategies in both inpainting quality and inpainting diversity. This task is closely related to the learning of an accurate probability distribution of images. Depending on the dataset in use, the challenges that entail the training of such a model will be discussed through the analysis.  
### A Universal Deep Learning Framework for Real-Time Denoising of Ultrasound Images. (arXiv:2101.09122v2 [eess.IV] UPDATED)
- Authors : Simone Cammarasana, Paolo Nicolardi, Giuseppe Patan
- Link : [http://arxiv.org/abs/2101.09122](http://arxiv.org/abs/2101.09122)
> ABSTRACT  :  Ultrasound images are widespread in medical diagnosis for muscle-skeletal, cardiac, and obstetrical diseases, due to the efficiency and non-invasiveness of the acquisition methodology. However, ultrasound acquisition introduces noise in the signal, which corrupts the resulting image and affects further processing steps, e.g., segmentation and quantitative analysis. We define a novel deep learning framework for the real-time denoising of ultrasound images. Firstly, we compare state-of-the-art methods for denoising (e.g., spectral, low-rank methods) and select WNNM (Weighted Nuclear Norm Minimisation) as the best denoising in terms of accuracy, preservation of anatomical features, and edge **enhancement**. Then, we propose a tuned version of WNNM (tuned-WNNM) that improves the quality of the denoised images and extends its applicability to ultrasound images. Through a deep learning framework, the tuned-WNNM qualitatively and quantitatively replicates WNNM results in real-time. Finally, our approach is general in terms of its building blocks and parameters of the deep learning and high-performance computing framework; in fact, we can select different denoising algorithms and deep learning architectures.  
### Palette: Image-to-Image Diffusion Models. (arXiv:2111.05826v2 [cs.CV] UPDATED)
- Authors : Chitwan Saharia, William Chan, Huiwen Chang, Jonathan Ho, Tim Salimans, Mohammad Norouzi
- Link : [http://arxiv.org/abs/2111.05826](http://arxiv.org/abs/2111.05826)
> ABSTRACT  :  This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG **restoration**. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. We uncover the impact of an L2 vs. L1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. Importantly, we advocate a unified evaluation protocol based on ImageNet, with human evaluation and sample quality scores (FID, Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images). We expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. Finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. Check out https://diffusion-palette.github.io for an overview of the results.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v5 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
## eess.IV
---
### Deep Learning Framework for **Real-time** Fetal Brain Segmentation in MRI. (arXiv:2205.01675v1 [eess.IV])
- Authors : Razieh Faghihpirayesh, Davood Karimi, Deniz Erdogmus, Ali Gholipour
- Link : [http://arxiv.org/abs/2205.01675](http://arxiv.org/abs/2205.01675)
> ABSTRACT  :  Fetal brain segmentation is an important first step for slice-level motion correction and slice-to-volume reconstruction in fetal MRI. Fast and accurate segmentation of the fetal brain on fetal MRI is required to achieve real-time fetal head pose estimation and motion tracking for slice re-acquisition and steering. To address this critical unmet need, in this work we analyzed the speed-accuracy performance of a variety of deep neural network models, and devised a symbolically small convolutional neural network that combines spatial details at high resolution with context features extracted at lower resolutions. We used multiple branches with skip connections to maintain high accuracy while devising a parallel combination of convolution and pooling operations as an input downsampling module to further reduce inference time. We trained our model as well as eight alternative, state-of-the-art networks with manually-labeled fetal brain MRI slices and tested on two sets of normal and challenging test cases. Experimental results show that our network achieved the highest accuracy and lowest inference time among all of the compared state-of-the-art real-time segmentation methods. We achieved average Dice scores of 97.99\% and 84.04\% on the normal and challenging test sets, respectively, with an inference time of 3.36 milliseconds per image on an NVIDIA GeForce RTX 2080 Ti. Code, data, and the trained models are available at https://github.com/bchimagine/real_time_fetal_brain_segmentation.  
### Self-Supervised Super-Resolution for Multi-**Exposure** Push-Frame Satellites. (arXiv:2205.02031v1 [cs.CV])
- Authors : Ngoc Long, my Anger, Axel Davy, Pablo Arias, Gabriele Facciolo
- Link : [http://arxiv.org/abs/2205.02031](http://arxiv.org/abs/2205.02031)
> ABSTRACT  :  Modern Earth observation satellites capture multi-**exposure** bursts of push-frame images that can be super-resolved via computational means. In this work, we propose a super-resolution method for such multi-**exposure** sequences, a problem that has received very little attention in the literature. The proposed method can handle the signal-dependent noise in the inputs, process sequences of any length, and be robust to inaccuracies in the **exposure** times. Furthermore, it can be trained end-to-end with self-supervision, without requiring ground truth high resolution frames, which makes it especially suited to handle real data. Central to our method are three key contributions: i) a base-detail decomposition for handling errors in the **exposure** times, ii) a noise-level-aware feature encoding for improved fusion of frames with varying signal-to-noise ratio and iii) a permutation invariant fusion strategy by temporal pooling operators. We evaluate the proposed method on synthetic and real data and show that it outperforms by a significant margin existing single-**exposure** approaches that we adapted to the multi-**exposure** case.  
### A Universal Deep Learning Framework for Real-Time Denoising of Ultrasound Images. (arXiv:2101.09122v2 [eess.IV] UPDATED)
- Authors : Simone Cammarasana, Paolo Nicolardi, Giuseppe Patan
- Link : [http://arxiv.org/abs/2101.09122](http://arxiv.org/abs/2101.09122)
> ABSTRACT  :  Ultrasound images are widespread in medical diagnosis for muscle-skeletal, cardiac, and obstetrical diseases, due to the efficiency and non-invasiveness of the acquisition methodology. However, ultrasound acquisition introduces noise in the signal, which corrupts the resulting image and affects further processing steps, e.g., segmentation and quantitative analysis. We define a novel deep learning framework for the real-time denoising of ultrasound images. Firstly, we compare state-of-the-art methods for denoising (e.g., spectral, low-rank methods) and select WNNM (Weighted Nuclear Norm Minimisation) as the best denoising in terms of accuracy, preservation of anatomical features, and edge **enhancement**. Then, we propose a tuned version of WNNM (tuned-WNNM) that improves the quality of the denoised images and extends its applicability to ultrasound images. Through a deep learning framework, the tuned-WNNM qualitatively and quantitatively replicates WNNM results in real-time. Finally, our approach is general in terms of its building blocks and parameters of the deep learning and high-performance computing framework; in fact, we can select different denoising algorithms and deep learning architectures.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v5 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
## cs.LG
---
### Pre-RTL DNN Hardware Evaluator With Fused Layer Support. (arXiv:2205.01729v1 [cs.AR])
- Authors : Chyau Yang, Sheuan Chang
- Link : [http://arxiv.org/abs/2205.01729](http://arxiv.org/abs/2205.01729)
> ABSTRACT  :  With the popularity of the deep neural network (DNN), hardware accelerators are demanded for **real time** execution. However, lengthy design process and fast evolving DNN models make hardware evaluation hard to meet the time to market need. This paper proposes a pre-RTL DNN hardware evaluator that supports conventional layer-by-layer processing as well as the fused layer processing for low external bandwidth requirement. The evaluator supports two state-of-the-art accelerator architectures and finds the best hardware and layer fusion group The experimental results show the layer fusion scheme can achieve 55.6% memory bandwidth reduction, 36.7% latency improvement and 49.2% energy reduction compared with layer-by-layer operation.  
### Spatial-Temporal Meta-path Guided Explainable Crime Prediction. (arXiv:2205.01901v1 [cs.LG])
- Authors : Yuting Sun, Tong Chen, Hongzhi Yin
- Link : [http://arxiv.org/abs/2205.01901](http://arxiv.org/abs/2205.01901)
> ABSTRACT  :  **Exposure** to crime and violence can harm individuals' quality of life and the economic growth of communities. In light of the rapid development in machine learning, there is a rise in the need to explore automated solutions to prevent crimes. With the increasing availability of both fine-grained urban and public service data, there is a recent surge in fusing such cross-domain information to facilitate crime prediction. By capturing the information about social structure, environment, and crime trends, existing machine learning predictive models have explored the dynamic crime patterns from different views. However, these approaches mostly convert such multi-source knowledge into implicit and latent representations (e.g., learned embeddings of districts), making it still a challenge to investigate the impacts of explicit factors for the occurrences of crimes behind the scenes. In this paper, we present a Spatial-Temporal Metapath guided Explainable Crime prediction (STMEC) framework to capture dynamic patterns of crime behaviours and explicitly characterize how the environmental and social factors mutually interact to produce the forecasts. Extensive experiments show the superiority of STMEC compared with other advanced spatiotemporal models, especially in predicting felonies (e.g., robberies and assaults with dangerous weapons).  
### Efficient Accelerator for Dilated and Transposed Convolution with Decomposition. (arXiv:2205.02103v1 [cs.AR])
- Authors : Wei Chang, Sheuan Chang
- Link : [http://arxiv.org/abs/2205.02103](http://arxiv.org/abs/2205.02103)
> ABSTRACT  :  Hardware acceleration for dilated and transposed convolution enables **real time** execution of related tasks like segmentation, but current designs are specific for these convolutional types or suffer from complex control for reconfigurable designs. This paper presents a design that decomposes input or weight for dilated and transposed convolutions respectively to skip redundant computations and thus executes efficiently on existing dense CNN hardware as well. The proposed architecture can cut down 87.8\% of the cycle counts to achieve 8.2X speedup over a naive execution for the ENet case.  
### Palette: Image-to-Image Diffusion Models. (arXiv:2111.05826v2 [cs.CV] UPDATED)
- Authors : Chitwan Saharia, William Chan, Huiwen Chang, Jonathan Ho, Tim Salimans, Mohammad Norouzi
- Link : [http://arxiv.org/abs/2111.05826](http://arxiv.org/abs/2111.05826)
> ABSTRACT  :  This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG **restoration**. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. We uncover the impact of an L2 vs. L1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. Importantly, we advocate a unified evaluation protocol based on ImageNet, with human evaluation and sample quality scores (FID, Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images). We expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. Finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. Check out https://diffusion-palette.github.io for an overview of the results.  
### Shedding New Light on the Language of the **Dark** Web. (arXiv:2204.06885v2 [cs.CL] UPDATED)
- Authors : Youngjin Jin, Eugene Jang, Yongjae Lee, Seungwon Shin, Woo Chung
- Link : [http://arxiv.org/abs/2204.06885](http://arxiv.org/abs/2204.06885)
> ABSTRACT  :  The hidden nature and the limited accessibility of the **Dark** Web, combined with the lack of public datasets in this domain, make it difficult to study its inherent characteristics such as linguistic properties. Previous works on text classification of **Dark** Web domain have suggested that the use of deep neural models may be ineffective, potentially due to the linguistic differences between the **Dark** and Surface Webs. However, not much work has been done to uncover the linguistic characteristics of the **Dark** Web. This paper introduces CoDA, a publicly available **Dark** Web dataset consisting of 10000 web documents tailored towards text-based **Dark** Web analysis. By leveraging CoDA, we conduct a thorough linguistic analysis of the **Dark** Web and examine the textual differences between the **Dark** Web and the Surface Web. We also assess the performance of various methods of **Dark** Web page classification. Finally, we compare CoDA with an existing public **Dark** Web dataset and evaluate their suitability for various use cases.  
## cs.AI
---
### Pik-Fix: Restoring and Colorizing Old Photo. (arXiv:2205.01902v1 [cs.CV])
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Alan Bovik, Hongkai Yu
- Link : [http://arxiv.org/abs/2205.01902](http://arxiv.org/abs/2205.01902)
> ABSTRACT  :  Restoring and inpainting the visual memories that are present, but often impaired, in old photos remains an intriguing but unsolved research topic. Decades-old photos often suffer from severe and commingled degradation such as cracks, defocus, and color-fading, which are difficult to treat individually and harder to repair when they interact. Deep learning presents a plausible avenue, but the lack of large-scale datasets of old photos makes addressing this **restoration** task very challenging. Here we present a novel reference-based end-to-end learning framework that is able to both repair and colorize old and degraded pictures. Our proposed framework consists of three modules: a **restoration** sub-network that conducts **restoration** from degradations, a similarity sub-network that performs color histogram matching and color transfer, and a colorization subnet that learns to predict the chroma elements of images that have been conditioned on chromatic reference signals. The overall system makes uses of color histogram priors from reference images, which greatly reduces the need for large-scale training data. We have also created a first-of-a-kind public dataset of real old photos that are paired with ground truth "pristine" photos that have been that have been manually restored by PhotoShop experts. We conducted extensive experiments on this dataset and synthetic datasets, and found that our method significantly outperforms previous state-of-the-art models using both qualitative comparisons and quantitative measurements.  
# Paper List
---
## cs.CV
---
**109** new papers in cs.CV:-) 
1. The scope for AI-augmented interpretation of building blueprints in commercial and industrial property insurance. (arXiv:2205.01671v1 [cs.CV])
2. A Deep Learning-based Integrated Framework for Quality-aware Undersampled Cine Cardiac MRI Reconstruction and Analysis. (arXiv:2205.01673v1 [eess.IV])
3. MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer. (arXiv:2205.01674v1 [eess.IV])
4. Deep Learning Framework for **Real-time** Fetal Brain Segmentation in MRI. (arXiv:2205.01675v1 [eess.IV])
5. FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for Fundus Images Quality Grading. (arXiv:2205.01676v1 [eess.IV])
6. Physics to the Rescue: Deep Non-line-of-sight Reconstruction for High-speed Imaging. (arXiv:2205.01679v1 [eess.IV])
7. SpineNetV2: Automated Detection, Labelling and Radiological Grading Of Clinical MR Scans. (arXiv:2205.01683v1 [eess.IV])
8. Effect of Random Histogram Equalization on Breast Calcification Analysis Using Deep Learning. (arXiv:2205.01684v1 [eess.IV])
9. Smart City Intersections: Intelligence Nodes for Future Metropolises. (arXiv:2205.01686v1 [cs.CV])
10. End2End Multi-View Feature Matching using Differentiable Pose Optimization. (arXiv:2205.01694v1 [cs.CV])
11. Object Class Aware Video Anomaly Detection through Image Translation. (arXiv:2205.01706v1 [cs.CV])
12. In Defense of Image Pre-Training for Spatiotemporal Recognition. (arXiv:2205.01721v1 [cs.CV])
13. License Plate Privacy in Collaborative Visual Analysis of Traffic Scenes. (arXiv:2205.01724v1 [cs.CV])
14. Application of belief functions to medical image segmentation: A review. (arXiv:2205.01733v1 [cs.CV])
15. Comparison of CoModGANs, LaMa and GLIDE for Art Inpainting- Completing M.C Escher's Print Gallery. (arXiv:2205.01741v1 [cs.CV])
16. Data-Consistent Non-Cartesian Deep Subspace Learning for Efficient Dynamic MR Image Reconstruction. (arXiv:2205.01770v1 [eess.IV])
17. Os Dados dos Brasileiros sob Risco na Era da Intelig\^encia Artificial?. (arXiv:2205.01772v1 [cs.CV])
18. Deep Multi-Scale U-Net Architecture and Noise-Robust Training Strategies for Histopathological Image Segmentation. (arXiv:2205.01777v1 [eess.IV])
19. Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition. (arXiv:2205.01782v1 [cs.CV])
20. A Pre-study on Data Processing Pipelines for Roadside Object Detection Systems Towards Safer Road Infrastructure. (arXiv:2205.01783v1 [cs.CV])
21. Synthesized Speech Detection Using Convolutional Transformer-Based Spectrogram Analysis. (arXiv:2205.01800v1 [cs.SD])
22. Splicing Detection and Localization In Satellite Imagery Using Conditional GANs. (arXiv:2205.01805v1 [cs.CV])
23. Frequency Domain-Based Detection of Generated Audio. (arXiv:2205.01806v1 [cs.SD])
24. Assessing Dataset Bias in Computer Vision. (arXiv:2205.01811v1 [cs.CV])
25. Diverse Image Captioning with Grounded Style. (arXiv:2205.01813v1 [cs.CV])
26. i-Code: An Integrative and Composable Multimodal Learning Framework. (arXiv:2205.01818v1 [cs.LG])
27. FedMix: Mixed Supervised Federated Learning for Medical Image Segmentation. (arXiv:2205.01840v1 [cs.CV])
28. Visual Commonsense in Pretrained Unimodal and Multimodal Models. (arXiv:2205.01850v1 [cs.CL])
29. UCL-Dehaze: Towards Real-world Image Dehazing via Unsupervised Contrastive Learning. (arXiv:2205.01871v1 [cs.CV])
30. Joint Image Compression and Denoising via Latent-Space Scalability. (arXiv:2205.01874v1 [eess.IV])
31. All You May Need for VQA are Image Captions. (arXiv:2205.01883v1 [cs.CV])
32. Unsupervised Domain Adaptation Learning for Hierarchical Infant Pose Recognition with Synthetic Data. (arXiv:2205.01892v1 [cs.CV])
33. Pik-Fix: Restoring and Colorizing Old Photo. (arXiv:2205.01902v1 [cs.CV])
34. Self-Taught Metric Learning without Labels. (arXiv:2205.01903v1 [cs.CV])
35. Generalized Knowledge Distillation via Relationship Matching. (arXiv:2205.01915v1 [cs.CV])
36. CoCa: Contrastive Captioners are Image-Text Foundation Models. (arXiv:2205.01917v1 [cs.CV])
37. Scene Clustering Based Pseudo-labeling Strategy for Multi-modal Aerial View Object Classification. (arXiv:2205.01920v1 [cs.CV])
38. Zero-Episode Few-Shot Contrastive Predictive Coding: Solving intelligence tests without prior training. (arXiv:2205.01924v1 [cs.CV])
39. Self-supervised learning unveils morphological clusters behind lung cancer types and prognosis. (arXiv:2205.01931v1 [cs.CV])
40. Homography-Based Loss Function for Camera Pose Regression. (arXiv:2205.01937v1 [cs.CV])
41. EllSeg-Gen, towards Domain Generalization for head-mounted eyetracking. (arXiv:2205.01947v1 [cs.CV])
42. Sequencer: Deep LSTM for Image Classification. (arXiv:2205.01972v1 [cs.CV])
43. MM-Claims: A Dataset for Multimodal Claim Detection in Social Media. (arXiv:2205.01989v1 [cs.CL])
44. Impact of a DCT-driven Loss in Attention-based Knowledge-Distillation for Scene Recognition. (arXiv:2205.01997v1 [cs.CV])
45. TransRank: Self-supervised Video Representation Learning via Ranking-based Transformation Recognition. (arXiv:2205.02028v1 [cs.CV])
46. Self-Supervised Super-Resolution for Multi-**Exposure** Push-Frame Satellites. (arXiv:2205.02031v1 [cs.CV])
47. Self-Supervised Learning for Invariant Representations from Multi-Spectral and SAR Images. (arXiv:2205.02049v1 [cs.CV])
48. SVTS: Scalable Video-to-Speech Synthesis. (arXiv:2205.02058v1 [cs.SD])
49. Mobile-URSONet: an Embeddable Neural Network for Onboard Spacecraft Pose Estimation. (arXiv:2205.02065v1 [cs.CV])
50. Dual Branch Neural Network for Sea Fog Detection in Geostationary Ocean Color Imager. (arXiv:2205.02069v1 [cs.CV])
51. DeepPortraitDrawing: Generating Human Body Images from Freehand Sketches. (arXiv:2205.02070v1 [cs.CV])
52. ANUBIS: Review and Benchmark Skeleton-Based Action Recognition Methods with a New Dataset. (arXiv:2205.02071v1 [cs.CV])
53. SDF-based RGB-D Camera Tracking in Neural Scene Representations. (arXiv:2205.02079v1 [cs.CV])
54. Video Extrapolationin Space and Time. (arXiv:2205.02084v1 [cs.CV])
55. Hypercomplex Image-to-Image Translation. (arXiv:2205.02087v1 [cs.CV])
56. A Novel Fully Annotated Thermal Infrared Face Dataset: Recorded in Various Environment Conditions and Distances From The Camera. (arXiv:2205.02093v1 [cs.CV])
57. Dynamic Sparse R-CNN. (arXiv:2205.02101v1 [cs.CV])
58. Concept Activation Vectors for Generating User-Defined 3D Shapes. (arXiv:2205.02102v1 [cs.CV])
59. Neuroevolutionary Multi-objective approaches to Trajectory Prediction in Autonomous Vehicles. (arXiv:2205.02105v1 [cs.NE])
60. Prediction of fish location by combining fisheries data and sea bottom temperature forecasting. (arXiv:2205.02107v1 [cs.CV])
61. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v1 [cs.CV])
62. Engineering deep learning methods on automatic detection of damage in infrastructure due to extreme events. (arXiv:2205.02125v1 [cs.CV])
63. Domino Saliency Metrics: Improving Existing Channel Saliency Metrics with Structural Information. (arXiv:2205.02131v1 [cs.CV])
64. RecipeSnap -- a lightweight image-to-recipe model. (arXiv:2205.02141v1 [cs.CV])
65. An Analysis of Generative Methods for Multiple Image Inpainting. (arXiv:2205.02146v1 [cs.CV])
66. Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification. (arXiv:2205.02151v1 [cs.CV])
67. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v1 [eess.IV])
68. UnrealNAS: Can We Search Neural Architectures with Unreal Data?. (arXiv:2205.02162v1 [cs.CV])
69. Compound virtual screening by learning-to-rank with gradient boosting decision tree and enrichment-based cumulative gain. (arXiv:2205.02169v1 [q-bio.BM])
70. COOPERNAUT: End-to-End Driving with Cooperative Perception for Networked Vehicles. (arXiv:2205.02222v1 [cs.CV])
71. Visual Similarity Attention. (arXiv:1911.07381v2 [cs.CV] UPDATED)
72. EllSeg: An Ellipse Segmentation Framework for Robust Gaze Tracking. (arXiv:2007.09600v2 [cs.CV] UPDATED)
73. Sparse Representations of Positive Functions via First and Second-Order Pseudo-Mirror Descent. (arXiv:2011.07142v4 [stat.ML] UPDATED)
74. Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration Categorization. (arXiv:2012.01879v2 [cs.CV] UPDATED)
75. Conditional Generation of Medical Images via Disentangled Adversarial Inference. (arXiv:2012.04764v3 [eess.IV] UPDATED)
76. A Universal Deep Learning Framework for Real-Time Denoising of Ultrasound Images. (arXiv:2101.09122v2 [eess.IV] UPDATED)
77. Learning Purified Feature Representations from Task-irrelevant Labels. (arXiv:2102.10955v2 [cs.LG] UPDATED)
78. Diagnosing Vision-and-Language Navigation: What Really Matters. (arXiv:2103.16561v2 [cs.CV] UPDATED)
79. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v4 [cs.RO] UPDATED)
80. Enabling 3D Object Detection with a Low-Resolution LiDAR. (arXiv:2105.01765v2 [cs.CV] UPDATED)
81. A Comprehensive Survey and Taxonomy on Image Dehazing Based on Deep Learning. (arXiv:2106.03323v2 [cs.CV] UPDATED)
82. On Deep Neural Network Calibration by Regularization and its Impact on Refinement. (arXiv:2106.09385v3 [cs.LG] UPDATED)
83. Cross-domain Few-shot Learning with Task-specific Adapters. (arXiv:2107.00358v4 [cs.CV] UPDATED)
84. Deep Slap Fingerprint Segmentation for Juveniles and Adults. (arXiv:2110.04067v2 [cs.CV] UPDATED)
85. Authentication Attacks on Projection-based Cancelable Biometric Schemes (long version). (arXiv:2110.15163v3 [cs.CR] UPDATED)
86. Palette: Image-to-Image Diffusion Models. (arXiv:2111.05826v2 [cs.CV] UPDATED)
87. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v5 [cs.CV] UPDATED)
88. Learning Multiple Dense Prediction Tasks from Partially Annotated Data. (arXiv:2111.14893v3 [cs.CV] UPDATED)
89. Zero-Shot Text-Guided Object Generation with Dream Fields. (arXiv:2112.01455v2 [cs.CV] UPDATED)
90. Music-to-Dance Generation with Optimal Transport. (arXiv:2112.01806v2 [cs.SD] UPDATED)
91. Controllable Animation of Fluid Elements in Still Images. (arXiv:2112.03051v2 [cs.CV] UPDATED)
92. Ensembling Off-the-shelf Models for GAN Training. (arXiv:2112.09130v3 [cs.CV] UPDATED)
93. A Streaming Volumetric Image Generation Framework for Development and Evaluation of Out-of-Core Methods. (arXiv:2112.09809v2 [cs.CV] UPDATED)
94. MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding. (arXiv:2112.10728v2 [cs.CL] UPDATED)
95. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v3 [eess.IV] UPDATED)
96. Instant Neural Graphics Primitives with a Multiresolution Hash Encoding. (arXiv:2201.05989v2 [cs.CV] UPDATED)
97. Few-Shot Backdoor Attacks on Visual Object Tracking. (arXiv:2201.13178v2 [cs.CV] UPDATED)
98. AssistQ: Affordance-centric Question-driven Task Completion for Egocentric Assistant. (arXiv:2203.04203v2 [cs.CV] UPDATED)
99. MDsrv -- visual sharing and analysis of molecular dynamics simulations. (arXiv:2203.13658v2 [cs.CV] UPDATED)
100. iSDF: Real-Time Neural Signed Distance Fields for Robot Perception. (arXiv:2204.02296v2 [cs.RO] UPDATED)
101. FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and Support-Vector Machines. (arXiv:2204.05112v2 [cs.CV] UPDATED)
102. Vision-and-Language Pretrained Models: A Survey. (arXiv:2204.07356v5 [cs.CV] UPDATED)
103. Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency. (arXiv:2204.10310v2 [cs.CV] UPDATED)
104. Learning Dynamic View Synthesis With Few RGBD Cameras. (arXiv:2204.10477v2 [cs.CV] UPDATED)
105. Controllable Image Captioning. (arXiv:2204.13324v2 [cs.CV] UPDATED)
106. Dual networks based 3D Multi-Person Pose Estimation from Monocular Video. (arXiv:2205.00748v2 [cs.CV] UPDATED)
107. Understanding CNNs from excitations. (arXiv:2205.00932v2 [cs.CV] UPDATED)
108. HL-Net: Heterophily Learning Network for Scene Graph Generation. (arXiv:2205.01316v2 [cs.CV] UPDATED)
109. Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network. (arXiv:2205.01550v2 [cs.CV] UPDATED)
## eess.IV
---
**23** new papers in eess.IV:-) 
1. The scope for AI-augmented interpretation of building blueprints in commercial and industrial property insurance. (arXiv:2205.01671v1 [cs.CV])
2. A Deep Learning-based Integrated Framework for Quality-aware Undersampled Cine Cardiac MRI Reconstruction and Analysis. (arXiv:2205.01673v1 [eess.IV])
3. MIRST-DM: Multi-Instance RST with Drop-Max Layer for Robust Classification of Breast Cancer. (arXiv:2205.01674v1 [eess.IV])
4. Deep Learning Framework for **Real-time** Fetal Brain Segmentation in MRI. (arXiv:2205.01675v1 [eess.IV])
5. FundusQ-Net: a Regression Quality Assessment Deep Learning Algorithm for Fundus Images Quality Grading. (arXiv:2205.01676v1 [eess.IV])
6. Physics to the Rescue: Deep Non-line-of-sight Reconstruction for High-speed Imaging. (arXiv:2205.01679v1 [eess.IV])
7. SpineNetV2: Automated Detection, Labelling and Radiological Grading Of Clinical MR Scans. (arXiv:2205.01683v1 [eess.IV])
8. Effect of Random Histogram Equalization on Breast Calcification Analysis Using Deep Learning. (arXiv:2205.01684v1 [eess.IV])
9. Smart City Intersections: Intelligence Nodes for Future Metropolises. (arXiv:2205.01686v1 [cs.CV])
10. License Plate Privacy in Collaborative Visual Analysis of Traffic Scenes. (arXiv:2205.01724v1 [cs.CV])
11. Data-Consistent Non-Cartesian Deep Subspace Learning for Efficient Dynamic MR Image Reconstruction. (arXiv:2205.01770v1 [eess.IV])
12. Deep Multi-Scale U-Net Architecture and Noise-Robust Training Strategies for Histopathological Image Segmentation. (arXiv:2205.01777v1 [eess.IV])
13. Splicing Detection and Localization In Satellite Imagery Using Conditional GANs. (arXiv:2205.01805v1 [cs.CV])
14. Joint Image Compression and Denoising via Latent-Space Scalability. (arXiv:2205.01874v1 [eess.IV])
15. Self-Supervised Super-Resolution for Multi-**Exposure** Push-Frame Satellites. (arXiv:2205.02031v1 [cs.CV])
16. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v1 [eess.IV])
17. Conditional Generation of Medical Images via Disentangled Adversarial Inference. (arXiv:2012.04764v3 [eess.IV] UPDATED)
18. A Universal Deep Learning Framework for Real-Time Denoising of Ultrasound Images. (arXiv:2101.09122v2 [eess.IV] UPDATED)
19. Deep Slap Fingerprint Segmentation for Juveniles and Adults. (arXiv:2110.04067v2 [cs.CV] UPDATED)
20. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v5 [cs.CV] UPDATED)
21. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v3 [eess.IV] UPDATED)
22. Point Cloud Semantic Segmentation using Multi Scale Sparse Convolution Neural Network. (arXiv:2205.01550v2 [cs.CV] UPDATED)
23. An untrained deep learning method for reconstructing dynamic magnetic resonance images from accelerated model-based data. (arXiv:2205.01604v2 [eess.IV] UPDATED)
## cs.LG
---
**162** new papers in cs.LG:-) 
1. The scope for AI-augmented interpretation of building blueprints in commercial and industrial property insurance. (arXiv:2205.01671v1 [cs.CV])
2. Branch & Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize. (arXiv:2205.01672v1 [cs.LG])
3. A Deep Learning-based Integrated Framework for Quality-aware Undersampled Cine Cardiac MRI Reconstruction and Analysis. (arXiv:2205.01673v1 [eess.IV])
4. ASTROMER: A transformer-based embedding for the representation of light curves. (arXiv:2205.01677v1 [astro-ph.IM])
5. Growing Isotropic Neural Cellular Automata. (arXiv:2205.01681v1 [cs.NE])
6. Deep Sequence Modeling for Anomalous ISP Traffic Prediction. (arXiv:2205.01685v1 [cs.LG])
7. On Circuit Depth Scaling For Quantum Approximate Optimization. (arXiv:2205.01698v1 [quant-ph])
8. MemSE: Fast MSE Prediction for Noisy Memristor-Based DNN Accelerators. (arXiv:2205.01707v1 [cs.LG])
9. Don't sweat the small stuff, classify the rest: Sample Shielding to protect text classifiers against adversarial attacks. (arXiv:2205.01714v1 [cs.CL])
10. Pre-RTL DNN Hardware Evaluator With Fused Layer Support. (arXiv:2205.01729v1 [cs.AR])
11. Self-focusing virtual screening with active design space pruning. (arXiv:2205.01753v1 [q-bio.QM])
12. B\'ezier Curve Gaussian Processes. (arXiv:2205.01754v1 [stat.ML])
13. XLTime: A Cross-Lingual Knowledge Transfer Framework for Temporal Expression Extraction. (arXiv:2205.01757v1 [cs.CL])
14. Differentiable Simulation of Soft Multi-body Systems. (arXiv:2205.01758v1 [cs.LG])
15. Explain and Conquer: Personalised Text-based Reviews to Achieve Transparency. (arXiv:2205.01759v1 [cs.LG])
16. The ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts. (arXiv:2205.01780v1 [eess.AS])
17. Do More Negative Samples Necessarily Hurt in Contrastive Learning?. (arXiv:2205.01789v1 [cs.LG])
18. Meta-Cognition. An Inverse-Inverse Reinforcement Learning Approach for Cognitive Radars. (arXiv:2205.01794v1 [eess.SP])
19. Synthesized Speech Detection Using Convolutional Transformer-Based Spectrogram Analysis. (arXiv:2205.01800v1 [cs.SD])
20. Splicing Detection and Localization In Satellite Imagery Using Conditional GANs. (arXiv:2205.01805v1 [cs.CV])
21. Frequency Domain-Based Detection of Generated Audio. (arXiv:2205.01806v1 [cs.SD])
22. Assessing Dataset Bias in Computer Vision. (arXiv:2205.01811v1 [cs.CV])
23. Diverse Image Captioning with Grounded Style. (arXiv:2205.01813v1 [cs.CV])
24. i-Code: An Integrative and Composable Multimodal Learning Framework. (arXiv:2205.01818v1 [cs.LG])
25. Zero-shot Sonnet Generation with Discourse-level Planning and Aesthetics Features. (arXiv:2205.01821v1 [cs.CL])
26. AmbiPun: Generating Humorous Puns with Ambiguous Context. (arXiv:2205.01825v1 [cs.CL])
27. Optimizing Mixture of Experts using Dynamic Recompilations. (arXiv:2205.01848v1 [cs.LG])
28. SMLT: A Serverless Framework for Scalable and Adaptive Machine Learning Design and Training. (arXiv:2205.01853v1 [cs.DC])
29. DeeptDCS: Deep Learning-Based Estimation of Currents Induced During Transcranial Direct Current Stimulation. (arXiv:2205.01858v1 [q-bio.QM])
30. Provably Confidential Language Modelling. (arXiv:2205.01863v1 [cs.CL])
31. Machine Learning based Framework for Robust Price-Sensitivity Estimation with Application to Airline Pricing. (arXiv:2205.01875v1 [stat.ML])
32. fairlib: A Unified Framework for Assessing and Improving Classification Fairness. (arXiv:2205.01876v1 [cs.LG])
33. Uncertainty estimation of pedestrian future trajectory using Bayesian approximation. (arXiv:2205.01887v1 [cs.LG])
34. Crystal Twins: Self-supervised Learning for Crystalline Material Property Prediction. (arXiv:2205.01893v1 [cs.LG])
35. Virtual Analog Modeling of Distortion Circuits Using Neural Ordinary Differential Equations. (arXiv:2205.01897v1 [eess.AS])
36. Spatial-Temporal Meta-path Guided Explainable Crime Prediction. (arXiv:2205.01901v1 [cs.LG])
37. Self-Taught Metric Learning without Labels. (arXiv:2205.01903v1 [cs.CV])
38. ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters. (arXiv:2205.01906v1 [cs.GR])
39. Modeling Task Interactions in Document-Level Joint Entity and Relation Extraction. (arXiv:2205.01909v1 [cs.CL])
40. Generalized Knowledge Distillation via Relationship Matching. (arXiv:2205.01915v1 [cs.CV])
41. CoCa: Contrastive Captioners are Image-Text Foundation Models. (arXiv:2205.01917v1 [cs.CV])
42. Second Order Path Variationals in Non-Stationary Online Learning. (arXiv:2205.01921v1 [cs.LG])
43. Zero-Episode Few-Shot Contrastive Predictive Coding: Solving intelligence tests without prior training. (arXiv:2205.01924v1 [cs.CV])
44. Probabilistic Symmetry for Improved Trajectory Forecasting. (arXiv:2205.01927v1 [cs.LG])
45. Explain to Not Forget: Defending Against Catastrophic Forgetting with XAI. (arXiv:2205.01929v1 [cs.LG])
46. Self-supervised learning unveils morphological clusters behind lung cancer types and prognosis. (arXiv:2205.01931v1 [cs.CV])
47. DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs. (arXiv:2205.01938v1 [cs.SE])
48. Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs. (arXiv:2205.01940v1 [cs.LG])
49. Uncertainty-Autoencoder-Based Privacy and Utility Preserving Data Type Conscious Transformation. (arXiv:2205.01950v1 [cs.LG])
50. Word Tour: One-dimensional Word Embeddings via the Traveling Salesman Problem. (arXiv:2205.01954v1 [cs.CL])
51. State Representation Learning for Goal-Conditioned Reinforcement Learning. (arXiv:2205.01965v1 [cs.LG])
52. Nonstationary Bandit Learning via Predictive Sampling. (arXiv:2205.01970v1 [cs.LG])
53. Sequencer: Deep LSTM for Image Classification. (arXiv:2205.01972v1 [cs.CV])
54. The Isabelle ENIGMA. (arXiv:2205.01981v1 [cs.AI])
55. Lifelong Ensemble Learning based on Multiple Representations for Few-Shot Object Recognition. (arXiv:2205.01982v1 [cs.RO])
56. Modelling calibration uncertainty in networks of environmental sensors. (arXiv:2205.01988v1 [cs.LG])
57. Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning. (arXiv:2205.01992v1 [cs.LG])
58. EmoBank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis. (arXiv:2205.01996v1 [cs.CL])
59. On Continual Model Refinement in Out-of-Distribution Data Streams. (arXiv:2205.02014v1 [cs.CL])
60. A Manifold Two-Sample Test Study: Integral Probability Metric with Neural Networks. (arXiv:2205.02043v1 [stat.ML])
61. Few-Shot Document-Level Relation Extraction. (arXiv:2205.02048v1 [cs.CL])
62. Exploring Rawlsian Fairness for K-Means Clustering. (arXiv:2205.02052v1 [cs.LG])
63. SVTS: Scalable Video-to-Speech Synthesis. (arXiv:2205.02058v1 [cs.SD])
64. Hypercomplex Image-to-Image Translation. (arXiv:2205.02087v1 [cs.CV])
65. Learning Abstract and Transferable Representations for Planning. (arXiv:2205.02092v1 [cs.LG])
66. Data Cleansing for Indoor Positioning Wi-Fi Fingerprinting Datasets. (arXiv:2205.02096v1 [eess.SP])
67. MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time Series. (arXiv:2205.02100v1 [cs.LG])
68. Dynamic Sparse R-CNN. (arXiv:2205.02101v1 [cs.CV])
69. Concept Activation Vectors for Generating User-Defined 3D Shapes. (arXiv:2205.02102v1 [cs.CV])
70. Efficient Accelerator for Dilated and Transposed Convolution with Decomposition. (arXiv:2205.02103v1 [cs.AR])
71. Prediction of fish location by combining fisheries data and sea bottom temperature forecasting. (arXiv:2205.02107v1 [cs.CV])
72. Using Deep Reinforcement Learning to solve Optimal Power Flow problem with generator failures. (arXiv:2205.02108v1 [cs.LG])
73. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v1 [cs.CV])
74. Predicting vacant parking space availability zone-wisely: a graph based spatio-temporal prediction approach. (arXiv:2205.02113v1 [cs.LG])
75. Axonal Delay As a Short-Term Memory for Feed Forward Deep Spiking Neural Networks. (arXiv:2205.02115v1 [cs.NE])
76. Optimizing One-pixel Black-box Adversarial Attacks. (arXiv:2205.02116v1 [cs.CR])
77. Processing Network Controls via Deep Reinforcement Learning. (arXiv:2205.02119v1 [math.OC])
78. Accelerating phase-field-based simulation via machine learning. (arXiv:2205.02121v1 [cond-mat.mtrl-sci])
79. The Limits of Word Level Differential Privacy. (arXiv:2205.02130v1 [cs.CR])
80. Domino Saliency Metrics: Improving Existing Channel Saliency Metrics with Structural Information. (arXiv:2205.02131v1 [cs.CV])
81. Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification. (arXiv:2205.02151v1 [cs.CV])
82. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v1 [eess.IV])
83. Making SGD Parameter-Free. (arXiv:2205.02160v1 [math.OC])
84. Compound virtual screening by learning-to-rank with gradient boosting decision tree and enrichment-based cumulative gain. (arXiv:2205.02169v1 [q-bio.BM])
85. Efficient Few-Shot Fine-Tuning for Opinion Summarization. (arXiv:2205.02170v1 [cs.CL])
86. Wavelet neural operator: a neural operator for parametric partial differential equations. (arXiv:2205.02191v1 [physics.comp-ph])
87. Semi-Supervised Cascaded Clustering for Classification of Noisy Label Data. (arXiv:2205.02209v1 [cs.LG])
88. FEDNEST: Federated Bilevel, Minimax, and Compositional Optimization. (arXiv:2205.02215v1 [cs.LG])
89. Negative Sampling in Variational Autoencoders. (arXiv:1910.02760v3 [cs.LG] UPDATED)
90. Visual Similarity Attention. (arXiv:1911.07381v2 [cs.CV] UPDATED)
91. The Grammar of Interactive Explanatory Model Analysis. (arXiv:2005.00497v4 [cs.LG] UPDATED)
92. Recurrent Flow Networks: A Recurrent Latent Variable Model for Density Modelling of Urban Mobility. (arXiv:2006.05256v2 [stat.ML] UPDATED)
93. Better Parameter-free Stochastic Optimization with ODE Updates for Coin-Betting. (arXiv:2006.07507v3 [cs.LG] UPDATED)
94. EllSeg: An Ellipse Segmentation Framework for Robust Gaze Tracking. (arXiv:2007.09600v2 [cs.CV] UPDATED)
95. Generalized Multi-Output Gaussian Process Censored Regression. (arXiv:2009.04822v2 [stat.ML] UPDATED)
96. Sparse Representations of Positive Functions via First and Second-Order Pseudo-Mirror Descent. (arXiv:2011.07142v4 [stat.ML] UPDATED)
97. Towards All-around Knowledge Transferring: Learning From Task-irrelevant Labels. (arXiv:2011.08470v2 [cs.LG] UPDATED)
98. Cross-Loss Influence Functions to Explain Deep Network Representations. (arXiv:2012.01685v2 [cs.LG] UPDATED)
99. Regret-Optimal Filtering for Prediction and Estimation. (arXiv:2101.10357v3 [math.OC] UPDATED)
100. Saving Stochastic Bandits from Poisoning Attacks via Limited Data Verification. (arXiv:2102.07711v2 [cs.LG] UPDATED)
101. Learning Purified Feature Representations from Task-irrelevant Labels. (arXiv:2102.10955v2 [cs.LG] UPDATED)
102. Graph Self-Supervised Learning: A Survey. (arXiv:2103.00111v5 [cs.LG] UPDATED)
103. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v4 [cs.RO] UPDATED)
104. A Comprehensive Survey and Taxonomy on Image Dehazing Based on Deep Learning. (arXiv:2106.03323v2 [cs.CV] UPDATED)
105. CausalNLP: A Practical Toolkit for Causal Inference with Text. (arXiv:2106.08043v4 [cs.CL] UPDATED)
106. On Deep Neural Network Calibration by Regularization and its Impact on Refinement. (arXiv:2106.09385v3 [cs.LG] UPDATED)
107. Leveraging Language to Learn Program Abstractions and Search Heuristics. (arXiv:2106.11053v3 [cs.LG] UPDATED)
108. DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual Network for the DiCOVA Challenge 2021. (arXiv:2107.06126v2 [cs.SD] UPDATED)
109. Learning the temporal evolution of multivariate densities via normalizing flows. (arXiv:2107.13735v2 [stat.ML] UPDATED)
110. Policy Optimization Using Semi-parametric Models for Dynamic Pricing. (arXiv:2109.06368v2 [cs.LG] UPDATED)
111. Local versions of sum-of-norms clustering. (arXiv:2109.09589v2 [cs.LG] UPDATED)
112. Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking for Smart Cities. (arXiv:2109.11661v3 [cs.LG] UPDATED)
113. UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis. (arXiv:2110.00135v2 [cs.LG] UPDATED)
114. Themis: A Network Bandwidth-Aware Collective Scheduling Policy for Distributed Training of DL Models. (arXiv:2110.04478v2 [cs.DC] UPDATED)
115. Multistage linguistic conditioning of convolutional layers for speech emotion recognition. (arXiv:2110.06650v2 [cs.LG] UPDATED)
116. When is BERT Multilingual? Isolating Crucial Ingredients for Cross-lingual Transfer. (arXiv:2110.14782v3 [cs.CL] UPDATED)
117. A Game-Theoretic Approach for Improving Generalization Ability of TSP Solvers. (arXiv:2110.15105v3 [cs.LG] UPDATED)
118. Palette: Image-to-Image Diffusion Models. (arXiv:2111.05826v2 [cs.CV] UPDATED)
119. Inverting brain grey matter models with likelihood-free inference: a tool for trustable cytoarchitecture measurements. (arXiv:2111.08693v2 [q-bio.QM] UPDATED)
120. Zero-Shot Text-Guided Object Generation with Dream Fields. (arXiv:2112.01455v2 [cs.CV] UPDATED)
121. Music-to-Dance Generation with Optimal Transport. (arXiv:2112.01806v2 [cs.SD] UPDATED)
122. BERTMap: A BERT-based Ontology Alignment System. (arXiv:2112.02682v4 [cs.AI] UPDATED)
123. Depth Uncertainty Networks for Active Learning. (arXiv:2112.06796v2 [cs.LG] UPDATED)
124. Ensembling Off-the-shelf Models for GAN Training. (arXiv:2112.09130v3 [cs.CV] UPDATED)
125. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v3 [cs.LG] UPDATED)
126. Balsa: Learning a Query Optimizer Without Expert Demonstrations. (arXiv:2201.01441v2 [cs.DB] UPDATED)
127. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v6 [cs.LG] UPDATED)
128. Discrete Simulation Optimization for Tuning Machine Learning Method Hyperparameters. (arXiv:2201.05978v2 [cs.LG] UPDATED)
129. Instant Neural Graphics Primitives with a Multiresolution Hash Encoding. (arXiv:2201.05989v2 [cs.CV] UPDATED)
130. Stochastic Coded Federated Learning with Convergence and Privacy Guarantees. (arXiv:2201.10092v4 [cs.LG] UPDATED)
131. Few-Shot Backdoor Attacks on Visual Object Tracking. (arXiv:2201.13178v2 [cs.CV] UPDATED)
132. Approximation of Images via Generalized Higher Order Singular Value Decomposition over Finite-dimensional Commutative Semisimple Algebra. (arXiv:2202.00450v4 [cs.LG] UPDATED)
133. Learning Mechanically Driven Emergent Behavior with Message Passing Neural Networks. (arXiv:2202.01380v2 [cs.LG] UPDATED)
134. The leap to ordinal: detailed functional prognosis after traumatic brain injury with a flexible modelling approach. (arXiv:2202.04801v2 [cs.LG] UPDATED)
135. Signal Decomposition Using Masked Proximal Operators. (arXiv:2202.09338v4 [cs.LG] UPDATED)
136. ViKiNG: Vision-Based Kilometer-Scale Navigation with Geographic Hints. (arXiv:2202.11271v2 [cs.RO] UPDATED)
137. Microgrid Day-Ahead Scheduling Considering Neural Network based Battery Degradation Model. (arXiv:2202.12416v2 [eess.SP] UPDATED)
138. AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First -- Using Relation Extraction to Identify Entities. (arXiv:2203.05325v2 [cs.CL] UPDATED)
139. DIAS: A Domain-Independent Alife-Based Problem-Solving System. (arXiv:2203.06855v2 [cs.NE] UPDATED)
140. Root-aligned SMILES: A Tight Representation for Chemical Reaction Prediction. (arXiv:2203.11444v3 [cs.LG] UPDATED)
141. An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks. (arXiv:2203.16773v2 [eess.AS] UPDATED)
142. Informativeness and Invariance: Two Perspectives on Spurious Correlations in Natural Language. (arXiv:2204.04487v2 [cs.CL] UPDATED)
143. FederatedScope: A Flexible Federated Learning Platform for Heterogeneity. (arXiv:2204.05011v3 [cs.LG] UPDATED)
144. FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and Support-Vector Machines. (arXiv:2204.05112v2 [cs.CV] UPDATED)
145. Shedding New Light on the Language of the **Dark** Web. (arXiv:2204.06885v2 [cs.CL] UPDATED)
146. Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v2 [cs.SD] UPDATED)
147. Convergence and Implicit Regularization Properties of Gradient Descent for Deep Residual Networks. (arXiv:2204.07261v2 [cs.LG] UPDATED)
148. Differentiable Time-Frequency Scattering in Kymatio. (arXiv:2204.08269v3 [cs.SD] UPDATED)
149. Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift. (arXiv:2204.08816v4 [astro-ph.GA] UPDATED)
150. Accelerating Inhibitor Discovery for Multiple SARS-CoV-2 Targets with a Single, Sequence-Guided Deep Generative Framework. (arXiv:2204.09042v2 [q-bio.QM] UPDATED)
151. An improved central limit theorem and fast convergence rates for entropic transportation costs. (arXiv:2204.09105v2 [math.ST] UPDATED)
152. Understanding and Preventing Capacity Loss in Reinforcement Learning. (arXiv:2204.09560v2 [cs.LG] UPDATED)
153. fairDMS: Rapid Model Training by Data and Model Reuse. (arXiv:2204.09805v2 [cs.LG] UPDATED)
154. Analysis of Temporal Difference Learning: Linear System Approach. (arXiv:2204.10479v3 [cs.LG] UPDATED)
155. Can Rationalization Improve Robustness?. (arXiv:2204.11790v2 [cs.CL] UPDATED)
156. Brainish: Formalizing A Multimodal Language for Intelligence and Consciousness. (arXiv:2205.00001v2 [cs.AI] UPDATED)
157. Generalized Reference Kernel for One-class Classification. (arXiv:2205.00534v2 [cs.LG] UPDATED)
158. VICE: Variational Inference for Concept Embeddings. (arXiv:2205.00756v3 [cs.LG] UPDATED)
159. Understanding CNNs from excitations. (arXiv:2205.00932v2 [cs.CV] UPDATED)
160. TracInAD: Measuring Influence for Anomaly Detection. (arXiv:2205.01362v2 [cs.LG] UPDATED)
161. Finding patterns in Knowledge Attribution for Transformers. (arXiv:2205.01366v2 [cs.CL] UPDATED)
162. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v2 [cs.LG] UPDATED)
## cs.AI
---
**86** new papers in cs.AI:-) 
1. The scope for AI-augmented interpretation of building blueprints in commercial and industrial property insurance. (arXiv:2205.01671v1 [cs.CV])
2. Branch & Learn for Recursively and Iteratively Solvable Problems in Predict+Optimize. (arXiv:2205.01672v1 [cs.LG])
3. Object Class Aware Video Anomaly Detection through Image Translation. (arXiv:2205.01706v1 [cs.CV])
4. Explain and Conquer: Personalised Text-based Reviews to Achieve Transparency. (arXiv:2205.01759v1 [cs.LG])
5. Os Dados dos Brasileiros sob Risco na Era da Intelig\^encia Artificial?. (arXiv:2205.01772v1 [cs.CV])
6. Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition. (arXiv:2205.01782v1 [cs.CV])
7. A Pre-study on Data Processing Pipelines for Roadside Object Detection Systems Towards Safer Road Infrastructure. (arXiv:2205.01783v1 [cs.CV])
8. A Review on Pushing the Limits of Baseline Recommendation Systems with the integration of Opinion Mining & Information Retrieval Techniques. (arXiv:2205.01802v1 [cs.IR])
9. Scientific Explanation and Natural Language: A Unified Epistemological-Linguistic Perspective for Explainable AI. (arXiv:2205.01809v1 [cs.AI])
10. i-Code: An Integrative and Composable Multimodal Learning Framework. (arXiv:2205.01818v1 [cs.LG])
11. Zero-shot Sonnet Generation with Discourse-level Planning and Aesthetics Features. (arXiv:2205.01821v1 [cs.CL])
12. AmbiPun: Generating Humorous Puns with Ambiguous Context. (arXiv:2205.01825v1 [cs.CL])
13. Explainable Knowledge Graph Embedding: Inference Reconciliation for Knowledge Inferences Supporting Robot Actions. (arXiv:2205.01836v1 [cs.AI])
14. Great Truths are Always Simple: A Rather Simple Knowledge Encoder for Enhancing the Commonsense Reasoning Capacity of Pre-Trained Models. (arXiv:2205.01841v1 [cs.CL])
15. fairlib: A Unified Framework for Assessing and Improving Classification Fairness. (arXiv:2205.01876v1 [cs.LG])
16. Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness. (arXiv:2205.01889v1 [cs.CL])
17. Go Back in Time: Generating Flashbacks in Stories with Event Temporal Prompts. (arXiv:2205.01898v1 [cs.CL])
18. Pik-Fix: Restoring and Colorizing Old Photo. (arXiv:2205.01902v1 [cs.CV])
19. Self-Taught Metric Learning without Labels. (arXiv:2205.01903v1 [cs.CV])
20. ASE: Large-Scale Reusable Adversarial Skill Embeddings for Physically Simulated Characters. (arXiv:2205.01906v1 [cs.GR])
21. Probabilistic Symmetry for Improved Trajectory Forecasting. (arXiv:2205.01927v1 [cs.LG])
22. Towards Theoretical Analysis of Transformation Complexity of ReLU DNNs. (arXiv:2205.01940v1 [cs.LG])
23. Word Tour: One-dimensional Word Embeddings via the Traveling Salesman Problem. (arXiv:2205.01954v1 [cs.CL])
24. Sequencer: Deep LSTM for Image Classification. (arXiv:2205.01972v1 [cs.CV])
25. Aligning to Social Norms and Values in Interactive Narratives. (arXiv:2205.01975v1 [cs.CL])
26. ASP-Based Declarative Process Mining. (arXiv:2205.01979v1 [cs.AI])
27. The Isabelle ENIGMA. (arXiv:2205.01981v1 [cs.AI])
28. MM-Claims: A Dataset for Multimodal Claim Detection in Social Media. (arXiv:2205.01989v1 [cs.CL])
29. Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning. (arXiv:2205.01992v1 [cs.LG])
30. EmoBank: Studying the Impact of Annotation Perspective and Representation Format on Dimensional Emotion Analysis. (arXiv:2205.01996v1 [cs.CL])
31. Multi-subgoal Robot Navigation in Crowds with History Information and Interactions. (arXiv:2205.02003v1 [cs.RO])
32. A Framework to Generate High-Quality Datapoints for Multiple Novel Intent Detection. (arXiv:2205.02005v1 [cs.CL])
33. On Continual Model Refinement in Out-of-Distribution Data Streams. (arXiv:2205.02014v1 [cs.CL])
34. CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training. (arXiv:2205.02029v1 [cs.PL])
35. Few-Shot Document-Level Relation Extraction. (arXiv:2205.02048v1 [cs.CL])
36. Video Extrapolationin Space and Time. (arXiv:2205.02084v1 [cs.CV])
37. A New Dimensionality Reduction Method Based on Hensel's Compression for Privacy Protection in Federated Learning. (arXiv:2205.02089v1 [cs.CR])
38. Improve Discourse Dependency Parsing with Contextualized Representations. (arXiv:2205.02090v1 [cs.CL])
39. Learning Abstract and Transferable Representations for Planning. (arXiv:2205.02092v1 [cs.LG])
40. MAD: Self-Supervised Masked Anomaly Detection Task for Multivariate Time Series. (arXiv:2205.02100v1 [cs.LG])
41. Dynamic Sparse R-CNN. (arXiv:2205.02101v1 [cs.CV])
42. Using Deep Reinforcement Learning to solve Optimal Power Flow problem with generator failures. (arXiv:2205.02108v1 [cs.LG])
43. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v1 [cs.CV])
44. Axonal Delay As a Short-Term Memory for Feed Forward Deep Spiking Neural Networks. (arXiv:2205.02115v1 [cs.NE])
45. Processing Network Controls via Deep Reinforcement Learning. (arXiv:2205.02119v1 [math.OC])
46. Dual Cross-Attention Learning for Fine-Grained Visual Categorization and Object Re-Identification. (arXiv:2205.02151v1 [cs.CV])
47. Efficient Few-Shot Fine-Tuning for Opinion Summarization. (arXiv:2205.02170v1 [cs.CL])
48. Ontology-Mediated Querying on Databases of Bounded Cliquewidth. (arXiv:2205.02190v1 [cs.DB])
49. Semi-Supervised Cascaded Clustering for Classification of Noisy Label Data. (arXiv:2205.02209v1 [cs.LG])
50. Chasing Streams with Existential Rules. (arXiv:2205.02220v1 [cs.AI])
51. HiURE: Hierarchical Exemplar Contrastive Learning for Unsupervised Relation Extraction. (arXiv:2205.02225v1 [cs.CL])
52. Learning Two-Stream CNN for Multi-Modal Age-related Macular Degeneration Categorization. (arXiv:2012.01879v2 [cs.CV] UPDATED)
53. Data Obsolescence Detection in the Light of Newly Acquired Valid Observations. (arXiv:2101.07067v3 [cs.AI] UPDATED)
54. Saving Stochastic Bandits from Poisoning Attacks via Limited Data Verification. (arXiv:2102.07711v2 [cs.LG] UPDATED)
55. Diagnosing Vision-and-Language Navigation: What Really Matters. (arXiv:2103.16561v2 [cs.CV] UPDATED)
56. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v4 [cs.RO] UPDATED)
57. Leveraging Language to Learn Program Abstractions and Search Heuristics. (arXiv:2106.11053v3 [cs.LG] UPDATED)
58. DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual Network for the DiCOVA Challenge 2021. (arXiv:2107.06126v2 [cs.SD] UPDATED)
59. Lyra: A Benchmark for Turducken-Style Code Generation. (arXiv:2108.12144v2 [cs.SE] UPDATED)
60. DEGREE: A Data-Efficient Generation-Based Event Extraction Model. (arXiv:2108.12724v3 [cs.CL] UPDATED)
61. Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking for Smart Cities. (arXiv:2109.11661v3 [cs.LG] UPDATED)
62. UserIdentifier: Implicit User Representations for Simple and Effective Personalized Sentiment Analysis. (arXiv:2110.00135v2 [cs.LG] UPDATED)
63. RoBERTuito: a pre-trained language model for social media text in Spanish. (arXiv:2111.09453v3 [cs.CL] UPDATED)
64. Zero-Shot Text-Guided Object Generation with Dream Fields. (arXiv:2112.01455v2 [cs.CV] UPDATED)
65. BERTMap: A BERT-based Ontology Alignment System. (arXiv:2112.02682v4 [cs.AI] UPDATED)
66. Learning Cross-Lingual IR from an English Retriever. (arXiv:2112.08185v2 [cs.CL] UPDATED)
67. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v3 [cs.LG] UPDATED)
68. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v6 [cs.LG] UPDATED)
69. Few-Shot Backdoor Attacks on Visual Object Tracking. (arXiv:2201.13178v2 [cs.CV] UPDATED)
70. ViKiNG: Vision-Based Kilometer-Scale Navigation with Geographic Hints. (arXiv:2202.11271v2 [cs.RO] UPDATED)
71. AIFB-WebScience at SemEval-2022 Task 12: Relation Extraction First -- Using Relation Extraction to Identify Entities. (arXiv:2203.05325v2 [cs.CL] UPDATED)
72. DIAS: A Domain-Independent Alife-Based Problem-Solving System. (arXiv:2203.06855v2 [cs.NE] UPDATED)
73. Symbolic music generation conditioned on continuous-valued emotions. (arXiv:2203.16165v2 [eess.AS] UPDATED)
74. Successes and critical failures of neural networks in capturing human-like speech recognition. (arXiv:2204.03740v2 [cs.SD] UPDATED)
75. Curriculum: A Broad-Coverage Benchmark for Linguistic Phenomena in Natural Language Understanding. (arXiv:2204.06283v2 [cs.CL] UPDATED)
76. CRUSH: Contextually Regularized and User anchored Self-supervised Hate speech Detection. (arXiv:2204.06389v2 [cs.CL] UPDATED)
77. DRAGON : A suite of Hardware Simulation and Optimization tools for Modern Workloads. (arXiv:2204.06676v3 [cs.AR] UPDATED)
78. Exploiting Session Information in BERT-based Session-aware Sequential Recommendation. (arXiv:2204.10851v2 [cs.IR] UPDATED)
79. Fuzzy Expert System for Stock Portfolio Selection: An Application to Bombay Stock Exchange. (arXiv:2204.13385v2 [cs.AI] UPDATED)
80. Brainish: Formalizing A Multimodal Language for Intelligence and Consciousness. (arXiv:2205.00001v2 [cs.AI] UPDATED)
81. What do we Really Know about State of the Art NER?. (arXiv:2205.00034v2 [cs.CL] UPDATED)
82. Re-defining Radiology Quality Assurance (QA) -- Artificial Intelligence (AI)-Based QA by Restricted Investigation of Unequal Scores (AQUARIUS). (arXiv:2205.00629v2 [cs.HC] UPDATED)
83. Demographic-Reliant Algorithmic Fairness: Characterizing the Risks of Demographic Data Collection in the Pursuit of Fairness. (arXiv:2205.01038v2 [cs.CY] UPDATED)
84. Visual Knowledge Discovery with Artificial Intelligence: Challenges and Future Directions. (arXiv:2205.01296v2 [cs.AI] UPDATED)
85. Intelligent Trajectory Design for RIS-NOMA aided Multi-robot Communications. (arXiv:2205.01647v2 [cs.RO] UPDATED)
86. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v2 [cs.LG] UPDATED)

