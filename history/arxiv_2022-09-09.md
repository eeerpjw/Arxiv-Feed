# Your interest papers
---
## cs.CV
---
### Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations. (arXiv:2209.03494v1 [cs.CV])
- Authors : Vadim Tschernezki, Iro Laina, Diane Larlus, Andrea Vedaldi
- Link : [http://arxiv.org/abs/2209.03494](http://arxiv.org/abs/2209.03494)
> ABSTRACT  :  We present Neural Feature Fusion Fields (N3F), a method that improves dense 2D image feature extractors when the latter are applied to the analysis of multiple images reconstructible as a 3D scene. Given an image feature extractor, for example pre-trained using self-supervision, N3F uses it as a teacher to learn a student network defined in 3D space. The 3D student network is similar to a neural radiance field that distills said features and can be trained with the usual differentiable rendering machinery. As a consequence, N3F is readily applicable to most neural rendering formulations, including vanilla **NeRF** and its extensions to complex dynamic scenes. We show that our method not only enables semantic understanding in the context of scene-specific neural fields without the use of manual labels, but also consistently improves over the self-supervised 2D baselines. This is demonstrated by considering various tasks, such as 2D object retrieval, 3D segmentation, and scene editing, in diverse sequences, including long egocentric videos in the EPIC-KITCHENS benchmark.  
### Suspicious and Anomaly Detection. (arXiv:2209.03576v1 [cs.CV])
- Authors : Shubham Deshmukh, Favin Fernandes, Monali Ahire, Devarshi Borse, Amey Chavan
- Link : [http://arxiv.org/abs/2209.03576](http://arxiv.org/abs/2209.03576)
> ABSTRACT  :  In this project we propose a CNN architecture to detect anomaly and suspicious activities; the activities chosen for the project are running, jumping and kicking in public places and carrying gun, bat and knife in public places. With the trained model we compare it with the pre-existing models like Yolo, vgg16, vgg19. The trained Model is then implemented for **real time** detection and also used the. tflite format of the trained .h5 model to build an android classification.  
### Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
- Authors : Devarsh Patel, Sarthak Patel, Megh Patel
- Link : [http://arxiv.org/abs/2209.03625](http://arxiv.org/abs/2209.03625)
> ABSTRACT  :  The lack of effective target regions makes it difficult to perform several visual functions in low intensity light, including pedestrian recognition, and image-to-image translation. In this situation, with the accumulation of high-quality information by the combined use of infrared and visible images it is possible to detect pedestrians even in **low light**. In this study we are going to use advanced deep learning models like pix2pixGAN and YOLOv7 on LLVIP dataset, containing visible-infrared image pairs for **low light** vision. This dataset contains 33672 images and most of the images were captured in **dark** scenes, tightly synchronized with time and location.  
### R$^3$LIVE++: A Robust, **Real-time**, Radiance reconstruction package with a tightly-coupled LiDAR-Inertial-Visual state Estimator. (arXiv:2209.03666v1 [cs.CV])
- Authors : Jiarong Lin, Fu Zhang
- Link : [http://arxiv.org/abs/2209.03666](http://arxiv.org/abs/2209.03666)
> ABSTRACT  :  Simultaneous localization and mapping (SLAM) are crucial for autonomous robots (e.g., self-driving cars, autonomous drones), 3D mapping systems, and AR/VR applications. This work proposed a novel LiDAR-inertial-visual fusion framework termed R$^3$LIVE++ to achieve robust and accurate state estimation while simultaneously reconstructing the radiance map on the fly. R$^3$LIVE++ consists of a LiDAR-inertial odometry (LIO) and a visual-inertial odometry (VIO), both running in real-time. The LIO subsystem utilizes the measurements from a LiDAR for reconstructing the geometric structure (i.e., the positions of 3D points), while the VIO subsystem simultaneously recovers the radiance information of the geometric structure from the input images. R$^3$LIVE++ is developed based on R$^3$LIVE and further improves the accuracy in localization and mapping by accounting for the camera photometric calibration (e.g., non-linear response function and lens vignetting) and the online estimation of camera **exposure** time. We conduct more extensive experiments on both public and our private datasets to compare our proposed system against other state-of-the-art SLAM systems. Quantitative and qualitative results show that our proposed system has significant improvements over others in both accuracy and robustness. In addition, to demonstrate the extendability of our work, {we developed several applications based on our reconstructed radiance maps, such as **high dynamic range** (**HDR**) imaging, virtual environment exploration, and 3D video gaming.} Lastly, to share our findings and make contributions to the community, we make our codes, hardware design, and dataset publicly available on our Github: github.com/hku-mars/r3live  
### PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
- Authors : Prajwal Chidananda, Saurabh Nair, Douglas Lee, Adrian Kaehler
- Link : [http://arxiv.org/abs/2209.03910](http://arxiv.org/abs/2209.03910)
> ABSTRACT  :  We present PixTrack, a vision based object pose tracking framework using novel view synthesis and deep feature-metric alignment. Our evaluations demonstrate that our method produces highly accurate, robust, and jitter-free 6DoF pose estimates of objects in RGB images without the need of any data annotation or trajectory smoothing. Our method is also computationally efficient making it easy to have multi-object tracking with no alteration to our method and just using CPU multiprocessing.  
### Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v2 [eess.IV] UPDATED)
- Authors : Sibi Catley, Thomas Tanay, Lucas Vandroux, Gregory Slabaugh
- Link : [http://arxiv.org/abs/2201.02625](http://arxiv.org/abs/2201.02625)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is of fundamental importance in modern digital photography pipelines and used to produce a high-quality photograph with well exposed regions despite varying illumination across the image. This is typically achieved by merging multiple low dynamic range (LDR) images taken at different **exposure**s. However, over-exposed regions and misalignment errors due to poorly compensated motion result in artefacts such as ghosting. In this paper, we present a new **HDR** imaging technique that specifically models alignment and **exposure** uncertainties to produce high quality **HDR** results. We introduce a strategy that learns to jointly align and assess the alignment and **exposure** reliability using an **HDR**-aware, uncertainty-driven attention map that robustly merges the frames into a single high quality **HDR** image. Further, we introduce a progressive, multi-stage image fusion approach that can flexibly merge any number of LDR images in a permutation-invariant manner. Experimental results show our method can produce better quality **HDR** images with up to 1.1dB PSNR improvement to the state-of-the-art, and subjective improvements in terms of better detail, colours, and fewer artefacts.  
### Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
- Authors : Ali Hatamizadeh, Hongxu Yin, Jan Kautz, Pavlo Molchanov
- Link : [http://arxiv.org/abs/2206.09959](http://arxiv.org/abs/2206.09959)
> ABSTRACT  :  We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization. Our method leverages global context self-attention modules, joint with local self-attention, to effectively yet efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the issue of lack of the inductive bias in ViTs via proposing to use a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the tiny, small and base variants of GC ViT with 28M, 51M and 90M parameters achieve 83.3%, 83.9% and 84.5% Top-1 accuracy, respectively, surpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based **Swin** Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, and semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently, sometimes by large margins. Code available at https://github.com/NVlabs/GCViT.  
### Positive-Negative Equal Contrastive Loss for Semantic Segmentation. (arXiv:2207.01417v3 [cs.CV] UPDATED)
- Authors : Jing Wang, Lingfei Xuan, Wenxuan Wang, Tianxiang Zhang, Jiangyun Li
- Link : [http://arxiv.org/abs/2207.01417](http://arxiv.org/abs/2207.01417)
> ABSTRACT  :  The contextual information is critical for various computer vision tasks, previous works commonly design plug-and-play modules and structural losses to effectively extract and aggregate the global context. These methods utilize fine-label to optimize the model but ignore that fine-trained features are also precious training resources, which can introduce preferable distribution to hard pixels (i.e., misclassified pixels). Inspired by contrastive learning in unsupervised paradigm, we apply the contrastive loss in a supervised manner and re-design the loss function to cast off the stereotype of unsupervised learning (e.g., imbalance of positives and negatives, confusion of anchors computing). To this end, we propose Positive-Negative Equal contrastive loss (PNE loss), which increases the latent impact of positive embedding on the anchor and treats the positive as well as negative sample pairs equally. The PNE loss can be directly plugged right into existing semantic segmentation frameworks and leads to excellent performance with neglectable extra computational costs. We utilize a number of classic segmentation methods (e.g., DeepLabV3, HRNetV2, OCRNet, UperNet) and backbone (e.g., ResNet, HRNet, **Swin** Transformer) to conduct comprehensive experiments and achieve state-of-the-art performance on three benchmark datasets (e.g., Cityscapes, COCO-Stuff and ADE20K). Our code will be publicly available soon.  
### AI Illustrator: Translating Raw Descriptions into Images by Prompt-based Cross-Modal Generation. (arXiv:2209.03160v2 [cs.CV] UPDATED)
- Authors : Yiyang Ma, Huan Yang, Bei Liu, Jianlong Fu, **Jiaying Liu**
- Link : [http://arxiv.org/abs/2209.03160](http://arxiv.org/abs/2209.03160)
> ABSTRACT  :  AI illustrator aims to automatically design visually appealing images for books to provoke rich thoughts and emotions. To achieve this goal, we propose a framework for translating raw descriptions with complex semantics into semantically corresponding images. The main challenge lies in the complexity of the semantics of raw descriptions, which may be hard to be visualized (e.g., "gloomy" or "Asian"). It usually poses challenges for existing methods to handle such descriptions. To address this issue, we propose a Prompt-based Cross-Modal Generation Framework (PCM-Frame) to leverage two powerful pre-trained models, including CLIP and StyleGAN. Our framework consists of two components: a projection module from Text Embeddings to Image Embeddings based on prompts, and an adapted image generation module built on StyleGAN which takes Image Embeddings as inputs and is trained by combined semantic consistency losses. To bridge the gap between realistic images and illustration designs, we further adopt a stylization model as post-processing in our framework for better visual effects. Benefiting from the pre-trained models, our method can handle complex descriptions and does not require external paired data for training. Furthermore, we have built a benchmark that consists of 200 raw descriptions. We conduct a user study to demonstrate our superiority over the competing methods with complicated texts. We release our code at https://github.com/researchmm/AI_Illustrator.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v3 [cs.LG] CROSS LISTED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedure and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm on improving the performance of diffusion model. In this article, we present a first comprehensive review of existing variants of the diffusion models. Specifically, we provide a first taxonomy of diffusion models and categorize them variants to three types, namely sampling-acceleration **enhancement**, likelihood-maximization **enhancement** and data-generalization **enhancement**. We also introduce in detail other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models), and clarify the connections between diffusion models and these generative models. Then we make a thorough investigation into the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## eess.IV
---
### Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v2 [eess.IV] UPDATED)
- Authors : Sibi Catley, Thomas Tanay, Lucas Vandroux, Gregory Slabaugh
- Link : [http://arxiv.org/abs/2201.02625](http://arxiv.org/abs/2201.02625)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is of fundamental importance in modern digital photography pipelines and used to produce a high-quality photograph with well exposed regions despite varying illumination across the image. This is typically achieved by merging multiple low dynamic range (LDR) images taken at different **exposure**s. However, over-exposed regions and misalignment errors due to poorly compensated motion result in artefacts such as ghosting. In this paper, we present a new **HDR** imaging technique that specifically models alignment and **exposure** uncertainties to produce high quality **HDR** results. We introduce a strategy that learns to jointly align and assess the alignment and **exposure** reliability using an **HDR**-aware, uncertainty-driven attention map that robustly merges the frames into a single high quality **HDR** image. Further, we introduce a progressive, multi-stage image fusion approach that can flexibly merge any number of LDR images in a permutation-invariant manner. Experimental results show our method can produce better quality **HDR** images with up to 1.1dB PSNR improvement to the state-of-the-art, and subjective improvements in terms of better detail, colours, and fewer artefacts.  
## cs.LG
---
### DIY-IPS: Towards an Off-the-Shelf Accurate Indoor Positioning System. (arXiv:2209.03613v1 [cs.NI])
- Authors : Riccardo Menon, Abdallah Lakhdari, Amani Abusafia, Qijun He, Athman Bouguettaya
- Link : [http://arxiv.org/abs/2209.03613](http://arxiv.org/abs/2209.03613)
> ABSTRACT  :  We present DIY-IPS - Do It Yourself - Indoor Positioning System, an open-source real-time indoor positioning mobile application. DIY-IPS detects users' indoor position by employing dual-band RSSI fingerprinting of available WiFi access points. The app can be used, without additional infrastructural costs, to detect users' indoor positions in **real time**. We published our app as an open source to save other researchers time recreating it. The app enables researchers/users to (1) collect indoor positioning datasets with a ground truth label, (2) customize the app for higher accuracy or other research purposes (3) test the accuracy of modified methods by live testing with ground truth. We ran preliminary experiments to demonstrate the effectiveness of the app.  
### Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
- Authors : Devarsh Patel, Sarthak Patel, Megh Patel
- Link : [http://arxiv.org/abs/2209.03625](http://arxiv.org/abs/2209.03625)
> ABSTRACT  :  The lack of effective target regions makes it difficult to perform several visual functions in low intensity light, including pedestrian recognition, and image-to-image translation. In this situation, with the accumulation of high-quality information by the combined use of infrared and visible images it is possible to detect pedestrians even in **low light**. In this study we are going to use advanced deep learning models like pix2pixGAN and YOLOv7 on LLVIP dataset, containing visible-infrared image pairs for **low light** vision. This dataset contains 33672 images and most of the images were captured in **dark** scenes, tightly synchronized with time and location.  
### PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
- Authors : Prajwal Chidananda, Saurabh Nair, Douglas Lee, Adrian Kaehler
- Link : [http://arxiv.org/abs/2209.03910](http://arxiv.org/abs/2209.03910)
> ABSTRACT  :  We present PixTrack, a vision based object pose tracking framework using novel view synthesis and deep feature-metric alignment. Our evaluations demonstrate that our method produces highly accurate, robust, and jitter-free 6DoF pose estimates of objects in RGB images without the need of any data annotation or trajectory smoothing. Our method is also computationally efficient making it easy to have multi-object tracking with no alteration to our method and just using CPU multiprocessing.  
### Sequential Information Design: Learning to Persuade in the **Dark**. (arXiv:2209.03927v1 [cs.LG])
- Authors : Martino Bernasconi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti, Francesco Trovo
- Link : [http://arxiv.org/abs/2209.03927](http://arxiv.org/abs/2209.03927)
> ABSTRACT  :  We study a repeated information design problem faced by an informed sender who tries to influence the behavior of a self-interested receiver. We consider settings where the receiver faces a sequential decision making (SDM) problem. At each round, the sender observes the realizations of random events in the SDM problem. This begets the challenge of how to incrementally disclose such information to the receiver to persuade them to follow (desirable) action recommendations. We study the case in which the sender does not know random events probabilities, and, thus, they have to gradually learn them while persuading the receiver. We start by providing a non-trivial polytopal approximation of the set of sender's persuasive information structures. This is crucial to design efficient learning algorithms. Next, we prove a negative result: no learning algorithm can be persuasive. Thus, we relax persuasiveness requirements by focusing on algorithms that guarantee that the receiver's regret in following recommendations grows sub-linearly. In the full-feedback setting -- where the sender observes all random events realizations -- , we provide an algorithm with $\tilde{O}(\sqrt{T})$ regret for both the sender and the receiver. Instead, in the bandit-feedback setting -- where the sender only observes the realizations of random events actually occurring in the SDM problem -- , we design an algorithm that, given an $\alpha \in [1/2, 1]$ as input, ensures $\tilde{O}({T^\alpha})$ and $\tilde{O}( T^{\max \{ \alpha, 1-\frac{\alpha}{2} \} })$ regrets, for the sender and the receiver respectively. This result is complemented by a lower bound showing that such a regrets trade-off is essentially tight.  
### HiFi++: a Unified Framework for Bandwidth Extension and Speech **Enhancement**. (arXiv:2203.13086v2 [cs.SD] UPDATED)
- Authors : Pavel Andreev, Aibek Alanov, Oleg Ivanov, Dmitry Vetrov
- Link : [http://arxiv.org/abs/2203.13086](http://arxiv.org/abs/2203.13086)
> ABSTRACT  :  Generative adversarial networks have recently demonstrated outstanding performance in neural vocoding outperforming best autoregressive and flow-based models. In this paper, we show that this success can be extended to other tasks of conditional audio generation. In particular, building upon HiFi vocoders, we propose a novel HiFi++ general framework for bandwidth extension and speech **enhancement**. We show that with the improved generator architecture and simplified multi-discriminator training, HiFi++ performs better or on par with the state-of-the-art in these tasks while spending significantly less computational resources. The effectiveness of our approach is validated through a series of extensive experiments.  
### Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
- Authors : Ali Hatamizadeh, Hongxu Yin, Jan Kautz, Pavlo Molchanov
- Link : [http://arxiv.org/abs/2206.09959](http://arxiv.org/abs/2206.09959)
> ABSTRACT  :  We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization. Our method leverages global context self-attention modules, joint with local self-attention, to effectively yet efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the issue of lack of the inductive bias in ViTs via proposing to use a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the tiny, small and base variants of GC ViT with 28M, 51M and 90M parameters achieve 83.3%, 83.9% and 84.5% Top-1 accuracy, respectively, surpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based **Swin** Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, and semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently, sometimes by large margins. Code available at https://github.com/NVlabs/GCViT.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v3 [cs.LG] CROSS LISTED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedure and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm on improving the performance of diffusion model. In this article, we present a first comprehensive review of existing variants of the diffusion models. Specifically, we provide a first taxonomy of diffusion models and categorize them variants to three types, namely sampling-acceleration **enhancement**, likelihood-maximization **enhancement** and data-generalization **enhancement**. We also introduce in detail other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models), and clarify the connections between diffusion models and these generative models. Then we make a thorough investigation into the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## cs.AI
---
### Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
- Authors : Devarsh Patel, Sarthak Patel, Megh Patel
- Link : [http://arxiv.org/abs/2209.03625](http://arxiv.org/abs/2209.03625)
> ABSTRACT  :  The lack of effective target regions makes it difficult to perform several visual functions in low intensity light, including pedestrian recognition, and image-to-image translation. In this situation, with the accumulation of high-quality information by the combined use of infrared and visible images it is possible to detect pedestrians even in **low light**. In this study we are going to use advanced deep learning models like pix2pixGAN and YOLOv7 on LLVIP dataset, containing visible-infrared image pairs for **low light** vision. This dataset contains 33672 images and most of the images were captured in **dark** scenes, tightly synchronized with time and location.  
### PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
- Authors : Prajwal Chidananda, Saurabh Nair, Douglas Lee, Adrian Kaehler
- Link : [http://arxiv.org/abs/2209.03910](http://arxiv.org/abs/2209.03910)
> ABSTRACT  :  We present PixTrack, a vision based object pose tracking framework using novel view synthesis and deep feature-metric alignment. Our evaluations demonstrate that our method produces highly accurate, robust, and jitter-free 6DoF pose estimates of objects in RGB images without the need of any data annotation or trajectory smoothing. Our method is also computationally efficient making it easy to have multi-object tracking with no alteration to our method and just using CPU multiprocessing.  
### Sequential Information Design: Learning to Persuade in the **Dark**. (arXiv:2209.03927v1 [cs.LG])
- Authors : Martino Bernasconi, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti, Francesco Trovo
- Link : [http://arxiv.org/abs/2209.03927](http://arxiv.org/abs/2209.03927)
> ABSTRACT  :  We study a repeated information design problem faced by an informed sender who tries to influence the behavior of a self-interested receiver. We consider settings where the receiver faces a sequential decision making (SDM) problem. At each round, the sender observes the realizations of random events in the SDM problem. This begets the challenge of how to incrementally disclose such information to the receiver to persuade them to follow (desirable) action recommendations. We study the case in which the sender does not know random events probabilities, and, thus, they have to gradually learn them while persuading the receiver. We start by providing a non-trivial polytopal approximation of the set of sender's persuasive information structures. This is crucial to design efficient learning algorithms. Next, we prove a negative result: no learning algorithm can be persuasive. Thus, we relax persuasiveness requirements by focusing on algorithms that guarantee that the receiver's regret in following recommendations grows sub-linearly. In the full-feedback setting -- where the sender observes all random events realizations -- , we provide an algorithm with $\tilde{O}(\sqrt{T})$ regret for both the sender and the receiver. Instead, in the bandit-feedback setting -- where the sender only observes the realizations of random events actually occurring in the SDM problem -- , we design an algorithm that, given an $\alpha \in [1/2, 1]$ as input, ensures $\tilde{O}({T^\alpha})$ and $\tilde{O}( T^{\max \{ \alpha, 1-\frac{\alpha}{2} \} })$ regrets, for the sender and the receiver respectively. This result is complemented by a lower bound showing that such a regrets trade-off is essentially tight.  
### Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
- Authors : Ali Hatamizadeh, Hongxu Yin, Jan Kautz, Pavlo Molchanov
- Link : [http://arxiv.org/abs/2206.09959](http://arxiv.org/abs/2206.09959)
> ABSTRACT  :  We propose global context vision transformer (GC ViT), a novel architecture that enhances parameter and compute utilization. Our method leverages global context self-attention modules, joint with local self-attention, to effectively yet efficiently model both long and short-range spatial interactions, without the need for expensive operations such as computing attention masks or shifting local windows. In addition, we address the issue of lack of the inductive bias in ViTs via proposing to use a modified fused inverted residual blocks in our architecture. Our proposed GC ViT achieves state-of-the-art results across image classification, object detection and semantic segmentation tasks. On ImageNet-1K dataset for classification, the tiny, small and base variants of GC ViT with 28M, 51M and 90M parameters achieve 83.3%, 83.9% and 84.5% Top-1 accuracy, respectively, surpassing comparably-sized prior art such as CNN-based ConvNeXt and ViT-based **Swin** Transformer by a large margin. Pre-trained GC ViT backbones in downstream tasks of object detection, instance segmentation, and semantic segmentation using MS COCO and ADE20K datasets outperform prior work consistently, sometimes by large margins. Code available at https://github.com/NVlabs/GCViT.  
# Paper List
---
## cs.CV
---
**77** new papers in cs.CV:-) 
1. Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation. (arXiv:2209.03355v1 [eess.IV])
2. Securing the Spike: On the Transferabilty and Security of Spiking Neural Networks to Adversarial Examples. (arXiv:2209.03358v1 [cs.NE])
3. Using Computational Approaches in Visual Identity Design: A Visual Identity for the Design and Multimedia Courses of Faculty of Sciences and Technology of University of Coimbra. (arXiv:2209.03420v1 [cs.MM])
4. Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions. (arXiv:2209.03430v1 [cs.LG])
5. Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip. (arXiv:2209.03440v1 [eess.IV])
6. Information Maximization for Extreme Pose Face Recognition. (arXiv:2209.03456v1 [cs.CV])
7. Supervised GAN Watermarking for Intellectual Property Protection. (arXiv:2209.03466v1 [cs.CV])
8. Convolutional Neural Network (CNN) to reduce construction loss in JPEG compression. (arXiv:2209.03475v1 [eess.IV])
9. Neural Feature Fusion Fields: 3D Distillation of Self-Supervised 2D Image Representations. (arXiv:2209.03494v1 [cs.CV])
10. RGB-X Classification for Electronics Sorting. (arXiv:2209.03509v1 [cs.CV])
11. Measuring Human Perception to Improve Open Set Recognition. (arXiv:2209.03519v1 [cs.CV])
12. Video Vision Transformers for Violence Detection. (arXiv:2209.03561v1 [cs.CV])
13. SANIP: Shopping Assistant and Navigation for the visually impaired. (arXiv:2209.03570v1 [cs.CV])
14. Suspicious and Anomaly Detection. (arXiv:2209.03576v1 [cs.CV])
15. Sign Language Detection. (arXiv:2209.03578v1 [cs.CV])
16. Multi-Granularity Prediction for Scene Text Recognition. (arXiv:2209.03592v1 [cs.CV])
17. Levenshtein OCR. (arXiv:2209.03594v1 [cs.CV])
18. nVFNet-RDC: Replay and Non-Local Distillation Collaboration for Continual Object Detection. (arXiv:2209.03603v1 [cs.CV])
19. Frame-Subtitle Self-Supervision for Multi-Modal Video Question Answering. (arXiv:2209.03609v1 [cs.CV])
20. Representing Camera Response Function by a Single Latent Variable and Fully Connected Neural Network. (arXiv:2209.03624v1 [cs.CV])
21. Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
22. FETA: Towards Specializing Foundation Models for Expert Task Applications. (arXiv:2209.03648v1 [cs.CV])
23. Saliency-based Multiple Region of Interest Detection from a Single 360{\deg} image. (arXiv:2209.03656v1 [cs.CV])
24. Generalized One-shot Domain Adaption of Generative Adversarial Networks. (arXiv:2209.03665v1 [cs.CV])
25. R$^3$LIVE++: A Robust, **Real-time**, Radiance reconstruction package with a tightly-coupled LiDAR-Inertial-Visual state Estimator. (arXiv:2209.03666v1 [cs.CV])
26. Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging. (arXiv:2209.03671v1 [eess.IV])
27. Aerial View Goal Localization with Reinforcement Learning. (arXiv:2209.03694v1 [cs.CV])
28. Unsupervised Video Object Segmentation via Prototype Memory Network. (arXiv:2209.03712v1 [cs.CV])
29. Incorporating Locality of Images to Generate Targeted Transferable Adversarial Examples. (arXiv:2209.03716v1 [cs.CV])
30. A crowdsourced dataset of aerial images with annotated solar photovoltaic arrays and installation metadata. (arXiv:2209.03726v1 [cs.CV])
31. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v1 [eess.IV])
32. Prior Knowledge-Guided Attention in Self-Supervised Vision Transformers. (arXiv:2209.03745v1 [cs.CV])
33. Automatic fetal fat quantification from MRI. (arXiv:2209.03748v1 [cs.CV])
34. Towards Multidimensional Textural Perception and Classification Through Whisker. (arXiv:2209.03750v1 [eess.SP])
35. Self-Supervised Multimodal Fusion Transformer for Passive Activity Recognition. (arXiv:2209.03765v1 [eess.SP])
36. Lightweight Long-Range Generative Adversarial Networks. (arXiv:2209.03793v1 [cs.CV])
37. T$^2$LR-Net: An Unrolling Reconstruction Network Learning Transformed Tensor Low-Rank prior for Dynamic MR Imaging. (arXiv:2209.03832v1 [eess.IV])
38. Tuning arrays with rays: Physics-informed tuning of quantum dot charge states. (arXiv:2209.03837v1 [cond-mat.mes-hall])
39. Transformer based Fingerprint Feature Extraction. (arXiv:2209.03846v1 [cs.CV])
40. Simpler is better: Multilevel Abstraction with Graph Convolutional Recurrent Neural Network Cells for Traffic Prediction. (arXiv:2209.03858v1 [cs.LG])
41. Histogram Layers for Synthetic Aperture Sonar Imagery. (arXiv:2209.03878v1 [cs.CV])
42. PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
43. Exploring Target Representations for Masked Autoencoders. (arXiv:2209.03917v1 [cs.CV])
44. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v1 [eess.IV])
45. Data Feedback Loops: Model-driven Amplification of Dataset Biases. (arXiv:2209.03942v1 [cs.LG])
46. Text-Free Learning of a Natural Language Interface for Pretrained Face Generators. (arXiv:2209.03953v1 [cs.CV])
47. Learning to Generate Realistic LiDAR Point Clouds. (arXiv:2209.03954v1 [cs.CV])
48. Applying Data Augmentation to Handwritten Arabic Numeral Recognition Using Deep Learning Neural Networks. (arXiv:1708.05969v5 [cs.CV] UPDATED)
49. An Iteratively Optimized Patch Label Inference Network for Automatic Pavement Distress Detection. (arXiv:2005.13298v3 [cs.CV] UPDATED)
50. TransCrowd: weakly-supervised crowd counting with transformers. (arXiv:2104.09116v3 [cs.CV] UPDATED)
51. Image Feature Information Extraction for Interest Point Detection: A Review. (arXiv:2106.07929v5 [cs.CV] UPDATED)
52. A persistent homology-based topological loss for CNN-based multi-class segmentation of CMR. (arXiv:2107.12689v2 [eess.IV] UPDATED)
53. HybridSDF: Combining Deep Implicit Shapes and Geometric Primitives for 3D Shape Representation and Manipulation. (arXiv:2109.10767v4 [cs.CV] UPDATED)
54. FathomNet: A global image database for enabling artificial intelligence in the ocean. (arXiv:2109.14646v4 [cs.CV] UPDATED)
55. Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and Beyond. (arXiv:2110.14759v2 [cs.LG] UPDATED)
56. Sparse Coding with Multi-Layer Decoders using Variance Regularization. (arXiv:2112.09214v2 [cs.CV] UPDATED)
57. Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v2 [eess.IV] UPDATED)
58. Generalizability of Machine Learning Models: Quantitative Evaluation of Three Methodological Pitfalls. (arXiv:2202.01337v2 [cs.LG] UPDATED)
59. Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers. (arXiv:2203.02664v2 [cs.CV] UPDATED)
60. Do better ImageNet classifiers assess perceptual similarity better?. (arXiv:2203.04946v2 [cs.CV] UPDATED)
61. Magnification Prior: A Self-Supervised Method for Learning Representations on Breast Cancer Histopathological Images. (arXiv:2203.07707v2 [eess.IV] UPDATED)
62. Zero Pixel Directional Boundary by Vector Transform. (arXiv:2203.08795v2 [cs.CV] UPDATED)
63. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v6 [cs.LG] UPDATED)
64. Exploring Adversarial Attacks and Defenses in Vision Transformers trained with DINO. (arXiv:2206.06761v4 [cs.CV] UPDATED)
65. Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
66. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v5 [eess.IV] UPDATED)
67. Positive-Negative Equal Contrastive Loss for Semantic Segmentation. (arXiv:2207.01417v3 [cs.CV] UPDATED)
68. Discover and Mitigate Unknown Biases with Debiasing Alternate Networks. (arXiv:2207.10077v2 [cs.CV] UPDATED)
69. VICTOR: Visual Incompatibility Detection with Transformers and Fashion-specific contrastive pre-training. (arXiv:2207.13458v2 [cs.CV] UPDATED)
70. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v2 [eess.IV] UPDATED)
71. Restructurable Activation Networks. (arXiv:2208.08562v2 [cs.CV] UPDATED)
72. JVLDLoc: a Joint Optimization of Visual-LiDAR Constraints and Direction Priors for Localization in Driving Scenario. (arXiv:2208.09777v3 [cs.CV] UPDATED)
73. Masked Video Modeling with Correlation-aware Contrastive Learning for Breast Cancer Diagnosis in Ultrasound. (arXiv:2208.09881v2 [cs.CV] UPDATED)
74. EGFR Mutation Prediction of Lung Biopsy Images using Deep Learning. (arXiv:2208.12506v2 [cs.CV] UPDATED)
75. Spatial-Temporal Transformer for Video Snapshot Compressive Imaging. (arXiv:2209.01578v2 [eess.IV] UPDATED)
76. AI Illustrator: Translating Raw Descriptions into Images by Prompt-based Cross-Modal Generation. (arXiv:2209.03160v2 [cs.CV] UPDATED)
77. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v3 [cs.LG] CROSS LISTED)
## eess.IV
---
**19** new papers in eess.IV:-) 
1. Learned Image Compression with Generalized Octave Convolution and Cross-Resolution Parameter Estimation. (arXiv:2209.03353v1 [eess.IV])
2. A Survey on Automated Diagnosis of Alzheimer's Disease Using Optical Coherence Tomography and Angiography. (arXiv:2209.03354v1 [eess.IV])
3. Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation. (arXiv:2209.03355v1 [eess.IV])
4. Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip. (arXiv:2209.03440v1 [eess.IV])
5. Convolutional Neural Network (CNN) to reduce construction loss in JPEG compression. (arXiv:2209.03475v1 [eess.IV])
6. Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging. (arXiv:2209.03671v1 [eess.IV])
7. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v1 [eess.IV])
8. T$^2$LR-Net: An Unrolling Reconstruction Network Learning Transformed Tensor Low-Rank prior for Dynamic MR Imaging. (arXiv:2209.03832v1 [eess.IV])
9. Histogram Layers for Synthetic Aperture Sonar Imagery. (arXiv:2209.03878v1 [cs.CV])
10. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v1 [eess.IV])
11. A persistent homology-based topological loss for CNN-based multi-class segmentation of CMR. (arXiv:2107.12689v2 [eess.IV] UPDATED)
12. FathomNet: A global image database for enabling artificial intelligence in the ocean. (arXiv:2109.14646v4 [cs.CV] UPDATED)
13. Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v2 [eess.IV] UPDATED)
14. Generalizability of Machine Learning Models: Quantitative Evaluation of Three Methodological Pitfalls. (arXiv:2202.01337v2 [cs.LG] UPDATED)
15. Magnification Prior: A Self-Supervised Method for Learning Representations on Breast Cancer Histopathological Images. (arXiv:2203.07707v2 [eess.IV] UPDATED)
16. Deep-learning-augmented Computational Miniature Mesoscope. (arXiv:2205.00123v5 [physics.optics] UPDATED)
17. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v5 [eess.IV] UPDATED)
18. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v2 [eess.IV] UPDATED)
19. Spatial-Temporal Transformer for Video Snapshot Compressive Imaging. (arXiv:2209.01578v2 [eess.IV] UPDATED)
## cs.LG
---
**146** new papers in cs.LG:-) 
1. Beyond Random Split for Assessing Statistical Model Performance. (arXiv:2209.03346v1 [cs.LG])
2. A hybrid Bayesian network for medical device risk assessment and management. (arXiv:2209.03352v1 [cs.LG])
3. Learned Image Compression with Generalized Octave Convolution and Cross-Resolution Parameter Estimation. (arXiv:2209.03353v1 [eess.IV])
4. A Survey on Automated Diagnosis of Alzheimer's Disease Using Optical Coherence Tomography and Angiography. (arXiv:2209.03354v1 [eess.IV])
5. Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation. (arXiv:2209.03355v1 [eess.IV])
6. AST-GIN: Attribute-Augmented Spatial-Temporal Graph Informer Network for Electric Vehicle Charging Station Availability Forecasting. (arXiv:2209.03356v1 [cs.LG])
7. Distilling Deep RL Models Into Interpretable Neuro-Fuzzy Systems. (arXiv:2209.03357v1 [cs.LG])
8. Securing the Spike: On the Transferabilty and Security of Spiking Neural Networks to Adversarial Examples. (arXiv:2209.03358v1 [cs.NE])
9. The (Un)Scalability of Heuristic Approximators for NP-Hard Search Problems. (arXiv:2209.03393v1 [cs.AI])
10. A Survey of Neural Trees. (arXiv:2209.03415v1 [cs.LG])
11. Bispectral Neural Networks. (arXiv:2209.03416v1 [cs.LG])
12. Causal discovery for time series with latent confounders. (arXiv:2209.03427v1 [stat.ML])
13. Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions. (arXiv:2209.03430v1 [cs.LG])
14. Physics-Guided Adversarial Machine Learning for Aircraft Systems Simulation. (arXiv:2209.03431v1 [cs.LG])
15. Responsibility: An Example-based Explainable AI approach via Training Process Inspection. (arXiv:2209.03433v1 [cs.LG])
16. SmOOD: Smoothness-based Out-of-Distribution Detection Approach for Surrogate Neural Networks in Aircraft Design. (arXiv:2209.03438v1 [cs.LG])
17. Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip. (arXiv:2209.03440v1 [eess.IV])
18. Blessing of Class Diversity in Pre-training. (arXiv:2209.03447v1 [cs.LG])
19. A Greedy Algorithm for Building Compact Binary Activated Neural Networks. (arXiv:2209.03450v1 [cs.LG])
20. AILAB-Udine@SMM4H 22: Limits of Transformers and BERT Ensembles. (arXiv:2209.03452v1 [cs.CL])
21. TAG: Learning Circuit Spatial Embedding From Layouts. (arXiv:2209.03465v1 [cs.AR])
22. Higher-order Clustering and Pooling for Graph Neural Networks. (arXiv:2209.03473v1 [cs.LG])
23. Convolutional Neural Network (CNN) to reduce construction loss in JPEG compression. (arXiv:2209.03475v1 [eess.IV])
24. A simple approach for quantizing neural networks. (arXiv:2209.03487v1 [cs.LG])
25. Peer to Peer Learning Platform Optimized With Machine Learning. (arXiv:2209.03489v1 [cs.CY])
26. On the Near-Optimality of Local Policies in Large Cooperative Multi-Agent Reinforcement Learning. (arXiv:2209.03491v1 [cs.LG])
27. Machine Learning Sensors for Diagnosis of COVID-19 Disease Using Routine Blood Values for Internet of Things Application. (arXiv:2209.03522v1 [cs.LG])
28. Implicit Full Waveform Inversion with Deep Neural Representation. (arXiv:2209.03525v1 [physics.geo-ph])
29. CLaCLab at SocialDisNER: Using Medical Gazetteers for Named-Entity Recognition of Disease Mentions in Spanish Tweets. (arXiv:2209.03528v1 [cs.CL])
30. CAP: instance complexity-aware network pruning. (arXiv:2209.03534v1 [cs.LG])
31. Reward Delay Attacks on Deep Reinforcement Learning. (arXiv:2209.03540v1 [cs.LG])
32. Knowledge Based Template Machine Translation In Low-Resource Setting. (arXiv:2209.03554v1 [cs.CL])
33. An Empirical Evaluation of Posterior Sampling for Constrained Reinforcement Learning. (arXiv:2209.03596v1 [cs.LG])
34. DIY-IPS: Towards an Off-the-Shelf Accurate Indoor Positioning System. (arXiv:2209.03613v1 [cs.NI])
35. IMAP: Individual huMAn mobility Patterns visualizing platform. (arXiv:2209.03615v1 [cs.SI])
36. Black-Box Audits for Group Distribution Shifts. (arXiv:2209.03620v1 [cs.LG])
37. Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
38. Hierarchical Graph Pooling is an Effective Citywide Traffic Condition Prediction Model. (arXiv:2209.03629v1 [cs.LG])
39. Geolocation of Cultural Heritage using Multi-View Knowledge Graph Embedding. (arXiv:2209.03638v1 [cs.LG])
40. Tag-Aware Document Representation for Research Paper Recommendation. (arXiv:2209.03660v1 [cs.IR])
41. Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints. (arXiv:2209.03668v1 [cs.AI])
42. Learning-based and unrolled motion-compensated reconstruction for cardiac MR CINE imaging. (arXiv:2209.03671v1 [eess.IV])
43. Aerial View Goal Localization with Reinforcement Learning. (arXiv:2209.03694v1 [cs.CV])
44. Training Scale-Invariant Neural Networks on the Sphere Can Happen in Three Regimes. (arXiv:2209.03695v1 [cs.LG])
45. Incremental Correction in Dynamic Systems Modelled with Neural Networks for Constraint Satisfaction. (arXiv:2209.03698v1 [math.OC])
46. Kernel-Segregated Transpose Convolution Operation. (arXiv:2209.03704v1 [cs.LG])
47. Losing momentum in continuous-time stochastic optimisation. (arXiv:2209.03705v1 [math.OC])
48. Developing a multi-variate prediction model for the detection of COVID-19 from Crowd-sourced Respiratory Voice Data. (arXiv:2209.03727v1 [cs.SD])
49. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v1 [eess.IV])
50. Towards Multidimensional Textural Perception and Classification Through Whisker. (arXiv:2209.03750v1 [eess.SP])
51. Improved Robust Algorithms for Learning with Discriminative Feature Feedback. (arXiv:2209.03753v1 [cs.LG])
52. Fact-Saboteurs: A Taxonomy of Evidence Manipulation Attacks against Fact-Verification Systems. (arXiv:2209.03755v1 [cs.CR])
53. Representation Learning for Appliance Recognition: A Comparison to Classical Machine Learning. (arXiv:2209.03759v1 [eess.SP])
54. Too Fine or Too Coarse? The Goldilocks Composition of Data Complexity for Robust Left-Right Eye-Tracking Classifiers. (arXiv:2209.03761v1 [eess.SP])
55. Deep Multi-Scale Representation Learning with Attention for Automatic Modulation Classification. (arXiv:2209.03764v1 [eess.SP])
56. Self-Supervised Multimodal Fusion Transformer for Passive Activity Recognition. (arXiv:2209.03765v1 [eess.SP])
57. Stochastic gradient descent with gradient estimator for categorical features. (arXiv:2209.03771v1 [cs.LG])
58. A Novel Semi-supervised Meta Learning Method for Subject-transfer Brain-computer Interface. (arXiv:2209.03785v1 [eess.SP])
59. Impact of dataset size and long-term ECoG-based BCI usage on deep learning decoders performance. (arXiv:2209.03789v1 [eess.SP])
60. Applying Transformer-based Text Summarization for Keyphrase Generation. (arXiv:2209.03791v1 [cs.CL])
61. Lightweight Long-Range Generative Adversarial Networks. (arXiv:2209.03793v1 [cs.CV])
62. ReX: A Framework for Generating Local Explanations to Recurrent Neural Networks. (arXiv:2209.03798v1 [cs.LG])
63. FAT Forensics: A Python Toolbox for Implementing and Deploying Fairness, Accountability and Transparency Algorithms in Predictive Systems. (arXiv:2209.03805v1 [cs.LG])
64. What and How of Machine Learning Transparency: Building Bespoke Explainability Tools with Interoperable Algorithmic Components. (arXiv:2209.03813v1 [cs.LG])
65. T$^2$LR-Net: An Unrolling Reconstruction Network Learning Transformed Tensor Low-Rank prior for Dynamic MR Imaging. (arXiv:2209.03832v1 [eess.IV])
66. Tuning arrays with rays: Physics-informed tuning of quantum dot charge states. (arXiv:2209.03837v1 [cond-mat.mes-hall])
67. FADE: Enabling Large-Scale Federated Adversarial Training on Resource-Constrained Edge Devices. (arXiv:2209.03839v1 [cs.LG])
68. Transformer-based classification of premise in tweets related to COVID-19. (arXiv:2209.03851v1 [cs.CL])
69. SE(3)-DiffusionFields: Learning cost functions for joint grasp and motion optimization through diffusion. (arXiv:2209.03855v1 [cs.RO])
70. Simpler is better: Multilevel Abstraction with Graph Convolutional Recurrent Neural Network Cells for Traffic Prediction. (arXiv:2209.03858v1 [cs.LG])
71. A Survey on Large-Population Systems and Scalable Multi-Agent Reinforcement Learning. (arXiv:2209.03859v1 [cs.MA])
72. Histogram Layers for Synthetic Aperture Sonar Imagery. (arXiv:2209.03878v1 [cs.CV])
73. Learning Sparse Graphon Mean Field Games. (arXiv:2209.03880v1 [cs.MA])
74. Valuing Players Over Time. (arXiv:2209.03882v1 [cs.LG])
75. A Framework for Evaluating Privacy-Utility Trade-off in Vertical Federated Learning. (arXiv:2209.03885v1 [cs.LG])
76. Mean Field Games on Weighted and Directed Graphs via Colored Digraphons. (arXiv:2209.03887v1 [cs.MA])
77. IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach. (arXiv:2209.03895v1 [cs.CL])
78. Analyzing the Effect of Sampling in GNNs on Individual Fairness. (arXiv:2209.03904v1 [cs.LG])
79. PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
80. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v1 [eess.IV])
81. Multiobjective Ranking and Selection Using Stochastic Kriging. (arXiv:2209.03919v1 [stat.ML])
82. Sequential Information Design: Learning to Persuade in the **Dark**. (arXiv:2209.03927v1 [cs.LG])
83. NeuralFMU: Presenting a workflow for integrating hybrid NeuralODEs into real world applications. (arXiv:2209.03933v1 [cs.LG])
84. Data Feedback Loops: Model-driven Amplification of Dataset Biases. (arXiv:2209.03942v1 [cs.LG])
85. W-Transformers : A Wavelet-based Transformer Framework for Univariate Time Series Forecasting. (arXiv:2209.03945v1 [cs.LG])
86. Text-Free Learning of a Natural Language Interface for Pretrained Face Generators. (arXiv:2209.03953v1 [cs.CV])
87. Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization. (arXiv:2002.11860v6 [math.OC] UPDATED)
88. End-to-end Robustness for Sensing-Reasoning Machine Learning Pipelines. (arXiv:2003.00120v4 [cs.LG] UPDATED)
89. Meta Clustering for Collaborative Learning. (arXiv:2006.00082v2 [cs.LG] UPDATED)
90. Meta Discovery: Learning to Discover Novel Classes given Very Limited Data. (arXiv:2102.04002v4 [cs.LG] UPDATED)
91. Inapproximability of a Pair of Forms Defining a Partial Boolean Function. (arXiv:2102.04703v4 [cs.LG] UPDATED)
92. PredDiff: Explanations and Interactions from Conditional Expectations. (arXiv:2102.13519v4 [cs.LG] UPDATED)
93. Sparsity in long-time control of neural ODEs. (arXiv:2102.13566v3 [cs.LG] UPDATED)
94. Federated Learning for Short-term Residential Load Forecasting. (arXiv:2105.13325v2 [cs.LG] UPDATED)
95. Differentially Empirical Risk Minimization under the Fairness Lens. (arXiv:2106.02674v2 [cs.LG] UPDATED)
96. Feature Importance Guided Attack: A Model Agnostic Adversarial Attack. (arXiv:2106.14815v2 [cs.LG] UPDATED)
97. Toward Robust Autotuning of Noisy Quantum Dot Devices. (arXiv:2108.00043v3 [quant-ph] UPDATED)
98. A Decentralized Federated Learning Framework via Committee Mechanism with Convergence Guarantee. (arXiv:2108.00365v2 [cs.LG] UPDATED)
99. Multihop: Leveraging Complex Models to Learn Accurate Simple Models. (arXiv:2109.06961v2 [cs.LG] UPDATED)
100. SGDE: Secure Generative Data Exchange for Cross-Silo Federated Learning. (arXiv:2109.12062v3 [cs.LG] UPDATED)
101. FathomNet: A global image database for enabling artificial intelligence in the ocean. (arXiv:2109.14646v4 [cs.CV] UPDATED)
102. Regularized Frank-Wolfe for Dense CRFs: Generalizing Mean Field and Beyond. (arXiv:2110.14759v2 [cs.LG] UPDATED)
103. Causal Forecasting:Generalization Bounds for Autoregressive Models. (arXiv:2111.09831v2 [stat.ML] UPDATED)
104. Sparse Coding with Multi-Layer Decoders using Variance Regularization. (arXiv:2112.09214v2 [cs.CV] UPDATED)
105. Modified DDPG car-following model with a real-world human driving experience with CARLA simulator. (arXiv:2112.14602v3 [cs.RO] UPDATED)
106. A deep learning-based model reduction (DeePMR) method for simplifying chemical kinetics. (arXiv:2201.02025v3 [cs.LG] UPDATED)
107. Stochastic Coded Federated Learning with Convergence and Privacy Guarantees. (arXiv:2201.10092v5 [cs.LG] UPDATED)
108. Generalizability of Machine Learning Models: Quantitative Evaluation of Three Methodological Pitfalls. (arXiv:2202.01337v2 [cs.LG] UPDATED)
109. Deep Neural Networks to Correct Sub-Precision Errors in CFD. (arXiv:2202.04233v2 [physics.flu-dyn] UPDATED)
110. A Light-Weight Multi-Objective Asynchronous Hyper-Parameter Optimizer. (arXiv:2202.07735v2 [cs.LG] UPDATED)
111. Differential Privacy and Fairness in Decisions and Learning Tasks: A Survey. (arXiv:2202.08187v2 [cs.LG] UPDATED)
112. E-LMC: Extended Linear Model of Coregionalization for Spatial Field Prediction. (arXiv:2203.00525v2 [cs.LG] UPDATED)
113. Zero Pixel Directional Boundary by Vector Transform. (arXiv:2203.08795v2 [cs.CV] UPDATED)
114. SwiftAgg+: Achieving Asymptotically Optimal Communication Loads in Secure Aggregation for Federated Learning. (arXiv:2203.13060v3 [cs.IT] UPDATED)
115. HiFi++: a Unified Framework for Bandwidth Extension and Speech **Enhancement**. (arXiv:2203.13086v2 [cs.SD] UPDATED)
116. Position Aided Beam Prediction in the Real World: How Useful GPS Locations Actually Are?. (arXiv:2205.09054v5 [eess.SP] UPDATED)
117. SafeNet: The Unreasonable Effectiveness of Ensembles in Private Collaborative Learning. (arXiv:2205.09986v2 [cs.CR] UPDATED)
118. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v6 [cs.LG] UPDATED)
119. Actionable Guidance for High-Consequence AI Risk Management: Towards Standards Addressing AI Catastrophic Risks. (arXiv:2206.08966v2 [cs.CY] UPDATED)
120. Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
121. Traffic Congestion Prediction Using Machine Learning Techniques. (arXiv:2206.10983v3 [cs.LG] UPDATED)
122. reStructured Pre-training. (arXiv:2206.11147v2 [cs.CL] UPDATED)
123. Recovering network topology and dynamics via sequence characterization. (arXiv:2206.15190v2 [cs.SI] UPDATED)
124. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v5 [eess.IV] UPDATED)
125. Few-shot training LLMs for project-specific code-summarization. (arXiv:2207.04237v2 [cs.SE] UPDATED)
126. Sub 8-Bit Quantization of Streaming Keyword Spotting Models for Embedded Chipsets. (arXiv:2207.06920v2 [cs.SD] UPDATED)
127. Fixed Points of Cone Mapping with the Application to Neural Networks. (arXiv:2207.09947v2 [math.DS] UPDATED)
128. Discover and Mitigate Unknown Biases with Debiasing Alternate Networks. (arXiv:2207.10077v2 [cs.CV] UPDATED)
129. MQRetNN: Multi-Horizon Time Series Forecasting with Retrieval Augmentation. (arXiv:2207.10517v2 [cs.LG] UPDATED)
130. Combing for Credentials: Active Pattern Extraction from Smart Reply. (arXiv:2207.10802v2 [cs.CR] UPDATED)
131. Distributed Nonlinear State Estimation in Electric Power Systems using Graph Neural Networks. (arXiv:2207.11465v2 [cs.LG] UPDATED)
132. Bayesian regularization of empirical MDPs. (arXiv:2208.02362v2 [cs.LG] UPDATED)
133. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v2 [eess.IV] UPDATED)
134. POCS-based Clustering Algorithm. (arXiv:2208.08888v2 [cs.LG] UPDATED)
135. Is Monte Carlo a bad sampling strategy for learning smooth functions in high dimensions?. (arXiv:2208.09045v2 [math.NA] UPDATED)
136. Non-Stationary Dynamic Pricing Via Actor-Critic Information-Directed Pricing. (arXiv:2208.09372v3 [stat.ML] UPDATED)
137. Inferring Sensitive Attributes from Model Explanations. (arXiv:2208.09967v2 [cs.CR] UPDATED)
138. LTE4G: Long-Tail Experts for Graph Neural Networks. (arXiv:2208.10205v2 [cs.LG] UPDATED)
139. Psychophysical Machine Learning. (arXiv:2208.11236v4 [cs.LG] UPDATED)
140. EGFR Mutation Prediction of Lung Biopsy Images using Deep Learning. (arXiv:2208.12506v2 [cs.CV] UPDATED)
141. A Survey of Machine Unlearning. (arXiv:2209.02299v3 [cs.LG] UPDATED)
142. Depression Symptoms Modelling from Social Media Text: An Active Learning Approach. (arXiv:2209.02765v2 [cs.CL] UPDATED)
143. Semi-supervised Invertible DeepONets for Bayesian Inverse Problems. (arXiv:2209.02772v2 [stat.ML] UPDATED)
144. Detecting Stance in Scientific Papers: Did we get more Negative Recently?. (arXiv:2202.13610v2 [cs.CL] CROSS LISTED)
145. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v3 [cs.LG] CROSS LISTED)
146. Neighborhood-aware Scalable Temporal Network Representation Learning. (arXiv:2209.01084v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**75** new papers in cs.AI:-) 
1. A hybrid Bayesian network for medical device risk assessment and management. (arXiv:2209.03352v1 [cs.LG])
2. A Survey on Automated Diagnosis of Alzheimer's Disease Using Optical Coherence Tomography and Angiography. (arXiv:2209.03354v1 [eess.IV])
3. Generative Adversarial Super-Resolution at the Edge with Knowledge Distillation. (arXiv:2209.03355v1 [eess.IV])
4. Distilling Deep RL Models Into Interpretable Neuro-Fuzzy Systems. (arXiv:2209.03357v1 [cs.LG])
5. Securing the Spike: On the Transferabilty and Security of Spiking Neural Networks to Adversarial Examples. (arXiv:2209.03358v1 [cs.NE])
6. The (Un)Scalability of Heuristic Approximators for NP-Hard Search Problems. (arXiv:2209.03393v1 [cs.AI])
7. A Survey of Neural Trees. (arXiv:2209.03415v1 [cs.LG])
8. Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions. (arXiv:2209.03430v1 [cs.LG])
9. Deep Learning-Based Automatic Diagnosis System for Developmental Dysplasia of the Hip. (arXiv:2209.03440v1 [eess.IV])
10. Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots. (arXiv:2209.03463v1 [cs.CY])
11. Supervised GAN Watermarking for Intellectual Property Protection. (arXiv:2209.03466v1 [cs.CV])
12. Higher-order Clustering and Pooling for Graph Neural Networks. (arXiv:2209.03473v1 [cs.LG])
13. Evaluating Temporal Patterns in Applied Infant Affect Recognition. (arXiv:2209.03496v1 [cs.HC])
14. Sell Me the Blackbox! Why eXplainable Artificial Intelligence (XAI) May Hurt Customers. (arXiv:2209.03499v1 [cs.AI])
15. A Secure and Efficient Multi-Object Grasping Detection Approach for Robotic Arms. (arXiv:2209.03511v1 [cs.RO])
16. CLaCLab at SocialDisNER: Using Medical Gazetteers for Named-Entity Recognition of Disease Mentions in Spanish Tweets. (arXiv:2209.03528v1 [cs.CL])
17. Reward Delay Attacks on Deep Reinforcement Learning. (arXiv:2209.03540v1 [cs.LG])
18. Extractive is not Faithful: An Investigation of Broad Unfaithfulness Problems in Extractive Summarization. (arXiv:2209.03549v1 [cs.CL])
19. Video Vision Transformers for Violence Detection. (arXiv:2209.03561v1 [cs.CV])
20. SSL-WM: A Black-Box Watermarking Approach for Encoders Pre-trained by Self-supervised Learning. (arXiv:2209.03563v1 [cs.CR])
21. Conformal Methods for Quantifying Uncertainty in Spatiotemporal Data: A Survey. (arXiv:2209.03580v1 [cs.AI])
22. Application of image-to-image translation in improving pedestrian detection. (arXiv:2209.03625v1 [cs.CV])
23. Generalized One-shot Domain Adaption of Generative Adversarial Networks. (arXiv:2209.03665v1 [cs.CV])
24. Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints. (arXiv:2209.03668v1 [cs.AI])
25. Kernel-Segregated Transpose Convolution Operation. (arXiv:2209.03704v1 [cs.LG])
26. What Did I Just Hear? Detecting Pornographic Sounds in Adult Videos Using Neural Networks. (arXiv:2209.03711v1 [cs.SD])
27. Towards explainable evaluation of language models on the semantic similarity of visual concepts. (arXiv:2209.03723v1 [cs.CL])
28. Knowledge-Driven Program Synthesis via Adaptive Replacement Mutation and Auto-constructed Subprogram Archives. (arXiv:2209.03736v1 [cs.NE])
29. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v1 [eess.IV])
30. Improved Sensor-Based Animal Behavior Classification Performance through Conditional Generative Adversarial Network. (arXiv:2209.03758v1 [eess.SP])
31. Representation Learning for Appliance Recognition: A Comparison to Classical Machine Learning. (arXiv:2209.03759v1 [eess.SP])
32. A Novel Semi-supervised Meta Learning Method for Subject-transfer Brain-computer Interface. (arXiv:2209.03785v1 [eess.SP])
33. Applying Transformer-based Text Summarization for Keyphrase Generation. (arXiv:2209.03791v1 [cs.CL])
34. Double Q-Learning for Citizen Relocation During Natural Hazards. (arXiv:2209.03800v1 [cs.RO])
35. FAT Forensics: A Python Toolbox for Implementing and Deploying Fairness, Accountability and Transparency Algorithms in Predictive Systems. (arXiv:2209.03805v1 [cs.LG])
36. What and How of Machine Learning Transparency: Building Bespoke Explainability Tools with Interoperable Algorithmic Components. (arXiv:2209.03813v1 [cs.LG])
37. Ethical and Social Considerations in Automatic Expert Identification and People Recommendation in Organizational Knowledge Management Systems. (arXiv:2209.03819v1 [cs.HC])
38. Transformer-based classification of premise in tweets related to COVID-19. (arXiv:2209.03851v1 [cs.CL])
39. A Survey on Large-Population Systems and Scalable Multi-Agent Reinforcement Learning. (arXiv:2209.03859v1 [cs.MA])
40. Histogram Layers for Synthetic Aperture Sonar Imagery. (arXiv:2209.03878v1 [cs.CV])
41. Learning Sparse Graphon Mean Field Games. (arXiv:2209.03880v1 [cs.MA])
42. Mean Field Games on Weighted and Directed Graphs via Colored Digraphons. (arXiv:2209.03887v1 [cs.MA])
43. IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model. (arXiv:2209.03891v1 [cs.CL])
44. IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach. (arXiv:2209.03895v1 [cs.CL])
45. Dyadic Interaction Assessment from Free-living Audio for Depression Severity Assessment. (arXiv:2209.03901v1 [cs.SD])
46. Analyzing the Effect of Sampling in GNNs on Individual Fairness. (arXiv:2209.03904v1 [cs.LG])
47. PixTrack: Precise 6DoF Object Pose Tracking using **NeRF** Templates and Feature-metric Alignment. (arXiv:2209.03910v1 [cs.CV])
48. Sequential Information Design: Learning to Persuade in the **Dark**. (arXiv:2209.03927v1 [cs.LG])
49. Lost in Translation: Reimagining the Machine Learning Life Cycle in Education. (arXiv:2209.03929v1 [cs.AI])
50. Data Feedback Loops: Model-driven Amplification of Dataset Biases. (arXiv:2209.03942v1 [cs.LG])
51. The Utility of Explainable AI in Ad Hoc Human-Machine Teaming. (arXiv:2209.03943v1 [cs.AI])
52. PredDiff: Explanations and Interactions from Conditional Expectations. (arXiv:2102.13519v4 [cs.LG] UPDATED)
53. Differentially Empirical Risk Minimization under the Fairness Lens. (arXiv:2106.02674v2 [cs.LG] UPDATED)
54. Feature Importance Guided Attack: A Model Agnostic Adversarial Attack. (arXiv:2106.14815v2 [cs.LG] UPDATED)
55. A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v6 [cs.CL] UPDATED)
56. Multihop: Leveraging Complex Models to Learn Accurate Simple Models. (arXiv:2109.06961v2 [cs.LG] UPDATED)
57. HybridSDF: Combining Deep Implicit Shapes and Geometric Primitives for 3D Shape Representation and Manipulation. (arXiv:2109.10767v4 [cs.CV] UPDATED)
58. SGDE: Secure Generative Data Exchange for Cross-Silo Federated Learning. (arXiv:2109.12062v3 [cs.LG] UPDATED)
59. Modified DDPG car-following model with a real-world human driving experience with CARLA simulator. (arXiv:2112.14602v3 [cs.RO] UPDATED)
60. Differential Privacy and Fairness in Decisions and Learning Tasks: A Survey. (arXiv:2202.08187v2 [cs.LG] UPDATED)
61. E-LMC: Extended Linear Model of Coregionalization for Spatial Field Prediction. (arXiv:2203.00525v2 [cs.LG] UPDATED)
62. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v6 [cs.LG] UPDATED)
63. Exploring Adversarial Attacks and Defenses in Vision Transformers trained with DINO. (arXiv:2206.06761v4 [cs.CV] UPDATED)
64. Actionable Guidance for High-Consequence AI Risk Management: Towards Standards Addressing AI Catastrophic Risks. (arXiv:2206.08966v2 [cs.CY] UPDATED)
65. Global Context Vision Transformers. (arXiv:2206.09959v2 [cs.CV] UPDATED)
66. reStructured Pre-training. (arXiv:2206.11147v2 [cs.CL] UPDATED)
67. On Decentralizing Federated Reinforcement Learning in Multi-Robot Scenarios. (arXiv:2207.09372v2 [cs.RO] UPDATED)
68. MQRetNN: Multi-Horizon Time Series Forecasting with Retrieval Augmentation. (arXiv:2207.10517v2 [cs.LG] UPDATED)
69. Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services. (arXiv:2208.05438v3 [cs.AI] UPDATED)
70. Restructurable Activation Networks. (arXiv:2208.08562v2 [cs.CV] UPDATED)
71. Psychophysical Machine Learning. (arXiv:2208.11236v4 [cs.LG] UPDATED)
72. EGFR Mutation Prediction of Lung Biopsy Images using Deep Learning. (arXiv:2208.12506v2 [cs.CV] UPDATED)
73. Hidden Author Bias in Book Recommendation. (arXiv:2209.00371v2 [cs.IR] UPDATED)
74. A Survey of Machine Unlearning. (arXiv:2209.02299v3 [cs.LG] UPDATED)
75. Depression Symptoms Modelling from Social Media Text: An Active Learning Approach. (arXiv:2209.02765v2 [cs.CL] UPDATED)

