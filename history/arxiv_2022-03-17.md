# Your interest papers
---
## cs.CV
---
### Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for Face **Restoration**. (arXiv:2203.08444v1 [cs.CV])
- Authors : Yinhuai Wang, Yujie Hu, Jian Zhang
- Link : [http://arxiv.org/abs/2203.08444](http://arxiv.org/abs/2203.08444)
> ABSTRACT  :  Emerging high-quality face **restoration** (FR) methods often utilize pre-trained GAN models (\textit{i.e.}, StyleGAN2) as GAN Prior. However, these methods usually struggle to balance realness and fidelity when facing various degradation levels. Besides, there is still a noticeable visual quality gap compared with pre-trained GAN models. In this paper, we propose a novel GAN Prior based degradation-aware feature interpolation network, dubbed Panini-Net, for FR tasks by explicitly learning the abstract representations to distinguish various degradations. Specifically, an unsupervised degradation representation learning (UDRL) strategy is first developed to extract degradation representations (DR) of the input degraded images. Then, a degradation-aware feature interpolation (DAFI) module is proposed to dynamically fuse the two types of informative features (\textit{i.e.}, features from input images and features from GAN Prior) with flexible adaption to various degradations based on DR. Ablation studies reveal the working mechanism of DAFI and its potential for editable FR. Extensive experiments demonstrate that our Panini-Net achieves state-of-the-art performance for multi-degradation face **restoration** and face super-resolution. The source code is available at https://github.com/jianzhangcs/panini.  
### The Devil Is in the Details: Window-based Attention for Image Compression. (arXiv:2203.08450v1 [cs.CV])
- Authors : Renjie Zou, Chunfeng Song, Zhaoxiang Zhang
- Link : [http://arxiv.org/abs/2203.08450](http://arxiv.org/abs/2203.08450)
> ABSTRACT  :  Learned image compression methods have exhibited superior rate-distortion performance than classical image compression standards. Most existing learned image compression models are based on Convolutional Neural Networks (CNNs). Despite great contributions, a main drawback of CNN based model is that its structure is not designed for capturing local redundancy, especially the non-repetitive textures, which severely affects the reconstruction quality. Therefore, how to make full use of both global structure and local texture becomes the core problem for learning-based image compression. Inspired by recent progresses of Vision Transformer (ViT) and **Swin** Transformer, we found that combining the local-aware attention mechanism with the global-related feature learning could meet the expectation in image compression. In this paper, we first extensively study the effects of multiple kinds of attention mechanisms for local features learning, then introduce a more straightforward yet effective window-based local attention block. The proposed window-based attention is very flexible which could work as a plug-and-play component to enhance CNN and Transformer models. Moreover, we propose a novel Symmetrical TransFormer (STF) framework with absolute transformer blocks in the down-sampling encoder and up-sampling decoder. Extensive experimental evaluations have shown that the proposed method is effective and outperforms the state-of-the-art methods. The code is publicly available at https://github.com/Googolxx/STF.  
### Efficient conditioned face animation using frontally-viewed embedding. (arXiv:2203.08765v1 [cs.CV])
- Authors : Maxime Oquab, Daniel Haziza, Ludovic Schwartz, Tao Xu, Katayoun Zand, Rui Wang, Peirong Liu, Camille Couprie
- Link : [http://arxiv.org/abs/2203.08765](http://arxiv.org/abs/2203.08765)
> ABSTRACT  :  As the quality of few shot facial animation from landmarks increases, new applications become possible, such as ultra low bandwidth video chat compression with a high degree of realism. However, there are some important challenges to tackle in order to improve the experience in real world conditions. In particular, the current approaches fail to represent profile views without distortions, while running in a low compute regime. We focus on this key problem by introducing a multi-frames embedding dubbed Frontalizer to improve profile views rendering. In addition to this core improvement, we explore the learning of a latent code conditioning generations along with landmarks to better convey facial expressions. Our dense models achieves 22% of improvement in perceptual quality and 73% reduction of landmark error over the first order model baseline on a subset of DFDC videos containing head movements. Declined with mobile architectures, our models outperform the previous state-of-the-art (improving perceptual quality by more than 16% and reducing landmark error by more than 47% on two datasets) while running on **real time** on iPhone 8 with very low bandwidth requirements.  
### Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. (arXiv:2103.00370v3 [cs.LG] UPDATED)
- Authors : Mark Hamilton, Scott Lundberg, **Lei Zhang**, Stephanie Fu
- Link : [http://arxiv.org/abs/2103.00370](http://arxiv.org/abs/2103.00370)
> ABSTRACT  :  Visual search, recommendation, and contrastive similarity learning power technologies that impact billions of users worldwide. Modern model architectures can be complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a $\textit{unique}$ axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we show when existing approaches violate "fairness" and derive methods that sidestep these shortcomings and naturally handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained $\textit{opaque-box}$ models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we show that these game-theoretic measures yield more consistent explanations for image similarity architectures.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
### Blind Image Super-resolution with Elaborate Degradation Modeling on Noise and Kernel. (arXiv:2107.00986v4 [cs.CV] UPDATED)
- Authors : Zongsheng Yue, Qian Zhao, Jianwen Xie, **Lei Zhang**, Deyu Meng
- Link : [http://arxiv.org/abs/2107.00986](http://arxiv.org/abs/2107.00986)
> ABSTRACT  :  While researches on model-based blind single image super-resolution (SISR) have achieved tremendous successes recently, most of them do not consider the image degradation sufficiently. Firstly, they always assume image noise obeys an independent and identically distributed (i.i.d.) Gaussian or Laplacian distribution, which largely underestimates the complexity of real noise. Secondly, previous commonly-used kernel priors (e.g., normalization, sparsity) are not effective enough to guarantee a rational kernel solution, and thus degenerates the performance of subsequent SISR task. To address the above issues, this paper proposes a model-based blind SISR method under the probabilistic framework, which elaborately models image degradation from the perspectives of noise and blur kernel. Specifically, instead of the traditional i.i.d. noise assumption, a patch-based non-i.i.d. noise model is proposed to tackle the complicated real noise, expecting to increase the degrees of freedom of the model for noise representation. As for the blur kernel, we novelly construct a concise yet effective kernel generator, and plug it into the proposed blind SISR method as an explicit kernel prior (EKP). To solve the proposed model, a theoretically grounded Monte Carlo EM algorithm is specifically designed. Comprehensive experiments demonstrate the superiority of our method over current state-of-the-arts on synthetic and real datasets. The source code is available at https://github.com/zsyOAOA/BSRDM.  
### Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and Document **Enhancement**. (arXiv:2203.04814v3 [cs.CV] UPDATED)
- Authors : Mohamed Ali, Sanket Biswas, Andres Mafla, Ali Furkan, Alicia Forn, Yousri Kessentini, Josep Llad, Lluis Gomez, Dimosthenis Karatzas
- Link : [http://arxiv.org/abs/2203.04814](http://arxiv.org/abs/2203.04814)
> ABSTRACT  :  In this work, we propose Text-Degradation Invariant Auto Encoder (Text-DIAE) aimed to solve two tasks, text recognition (handwritten or scene-text) and document image **enhancement**. We define three pretext tasks as learning objectives to be optimized during pre-training without the usage of labelled data. Each of the pre-text objectives is specifically tailored for the final downstream tasks. We conduct several ablation experiments that show the importance of each degradation for a specific domain. Exhaustive experimentation shows that our method does not have limitations of previous state-of-the-art based on contrastive losses while at the same time requiring essentially fewer data samples to converge. Finally, we demonstrate that our method surpasses the state-of-the-art significantly in existing supervised and self-supervised settings in handwritten and scene text recognition and document image **enhancement**. Our code and trained models will be made publicly available at~\url{ <a href="http://Upon_Acceptance">this http URL</a>}.  
### Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution. (arXiv:2203.07682v2 [cs.CV] UPDATED)
- Authors : Jinsu Yoo, Taehoon Kim, Sihaeng Lee, Seung Hwan, Honglak Lee, Tae Hyun
- Link : [http://arxiv.org/abs/2203.07682](http://arxiv.org/abs/2203.07682)
> ABSTRACT  :  Recent vision transformers along with self-attention have achieved promising results on various computer vision tasks. In particular, a pure transformer-based image **restoration** architecture surpasses the existing CNN-based methods using multi-task pre-training with a large number of trainable parameters. In this paper, we introduce an effective hybrid architecture for super-resolution (SR) tasks, which leverages local features from CNNs and long-range dependencies captured by transformers to further improve the SR results. Specifically, our architecture comprises of transformer and convolution branches, and we substantially elevate the performance by mutually fusing two branches to complement each representation. Furthermore, we propose a cross-scale token attention module, which allows the transformer to efficiently exploit the informative relationships among tokens across different scales. Our proposed method achieves state-of-the-art SR results on numerous benchmark datasets.  
## eess.IV
---
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
## cs.LG
---
### TAKDE: Temporal Adaptive Kernel Density Estimator for Real-Time Dynamic Density Estimation. (arXiv:2203.08317v1 [stat.ML])
- Authors : Yinsong Wang, Yu Ding, Shahin Shahrampour
- Link : [http://arxiv.org/abs/2203.08317](http://arxiv.org/abs/2203.08317)
> ABSTRACT  :  **Real-time** density estimation is ubiquitous in many applications, including computer vision and signal processing. Kernel density estimation is arguably one of the most commonly used density estimation techniques, and the use of "sliding window" mechanism adapts kernel density estimators to dynamic processes. In this paper, we derive the asymptotic mean integrated squared error (AMISE) upper bound for the "sliding window" kernel density estimator. This upper bound provides a principled guide to devise a novel estimator, which we name the temporal adaptive kernel density estimator (TAKDE). Compared to heuristic approaches for "sliding window" kernel density estimator, TAKDE is theoretically optimal in terms of the worst-case AMISE. We provide numerical experiments using synthetic and real-world datasets, showing that TAKDE outperforms other state-of-the-art dynamic density estimators (including those outside of kernel family). In particular, TAKDE achieves a superior test log-likelihood with a smaller runtime.  
### SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher. (arXiv:2011.08908v2 [cs.LG] UPDATED)
- Authors : Thai Le, Noseong Park, Dongwon Lee
- Link : [http://arxiv.org/abs/2011.08908](http://arxiv.org/abs/2011.08908)
> ABSTRACT  :  Even though several methods have proposed to defend textual neural network (NN) models against black-box adversarial attacks, they often defend against a specific text perturbation strategy and/or require re-training the models from scratch. This leads to a lack of generalization in practice and redundant computation. In particular, the state-of-the-art transformer models (e.g., BERT, RoBERTa) require great time and computation resources. By borrowing an idea from software engineering, in order to address these limitations, we propose a novel algorithm, SHIELD, which modifies and re-trains only the last layer of a textual NN, and thus it "patches" and "transforms" the NN into a stochastic weighted ensemble of multi-expert prediction heads. Considering that most of current black-box attacks rely on iterative search mechanisms to optimize their adversarial perturbations, SHIELD confuses the attackers by automatically utilizing different weighted ensembles of predictors depending on the input. In other words, SHIELD breaks a fundamental assumption of the attack, which is a victim NN model remains constant during an attack. By conducting comprehensive experiments, we demonstrate that all of CNN, RNN, BERT, and RoBERTa-based textual NNs, once patched by SHIELD, exhibit a relative **enhancement** of 15%--70% in accuracy on average against 14 different black-box attacks, outperforming 6 defensive baselines across 3 public datasets. All codes are to be released.  
### Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. (arXiv:2103.00370v3 [cs.LG] UPDATED)
- Authors : Mark Hamilton, Scott Lundberg, **Lei Zhang**, Stephanie Fu
- Link : [http://arxiv.org/abs/2103.00370](http://arxiv.org/abs/2103.00370)
> ABSTRACT  :  Visual search, recommendation, and contrastive similarity learning power technologies that impact billions of users worldwide. Modern model architectures can be complex and difficult to interpret, and there are several competing techniques one can use to explain a search engine's behavior. We show that the theory of fair credit assignment provides a $\textit{unique}$ axiomatic solution that generalizes several existing recommendation- and metric-explainability techniques in the literature. Using this formalism, we show when existing approaches violate "fairness" and derive methods that sidestep these shortcomings and naturally handle counterfactual information. More specifically, we show existing approaches implicitly approximate second-order Shapley-Taylor indices and extend CAM, GradCAM, LIME, SHAP, SBSM, and other methods to search engines. These extensions can extract pairwise correspondences between images from trained $\textit{opaque-box}$ models. We also introduce a fast kernel-based method for estimating Shapley-Taylor indices that require orders of magnitude fewer function evaluations to converge. Finally, we show that these game-theoretic measures yield more consistent explanations for image similarity architectures.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
## cs.AI
---
### CODER: An efficient framework for improving retrieval through COntextual Document Embedding Reranking. (arXiv:2112.08766v2 [cs.IR] UPDATED)
- Authors : George Zerveas, Navid Rekabsaz, Daniel Cohen, Carsten Eickhoff
- Link : [http://arxiv.org/abs/2112.08766](http://arxiv.org/abs/2112.08766)
> ABSTRACT  :  We present CODER, a lightweight performance **enhancement** framework for a wide range of dense retrieval models. It employs a list-wise loss and jointly scores a large set of retrieved candidate documents, rather than randomly sampled documents, for each query. When scoring a document representation based on its similarity to a query, the model is thus aware of the representation of its "peer" documents within the same retrieval context. We investigate the effect of training through contextual reranking of document embeddings and show that our approach leads to substantial improvement in retrieval performance over pair-wise scoring of candidate documents in isolation from one another. Crucially, CODER incurs only a negligible computational overhead (~ 5.5 ms delay per query) on top of any first-stage method at run time, allowing it to be easily combined with any state-of-the-art dense retrieval method.  
# Paper List
---
## cs.CV
---
**138** new papers in cs.CV:-) 
1. Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v1 [cs.CR])
2. UNet Architectures in Multiplanar Volumetric Segmentation -- Validated on Three Knee MRI Cohorts. (arXiv:2203.08194v1 [eess.IV])
3. DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection. (arXiv:2203.08195v1 [cs.CV])
4. SocialVAE: Human Trajectory Prediction using Timewise Latents. (arXiv:2203.08207v1 [cs.CV])
5. HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction. (arXiv:2203.08213v1 [eess.IV])
6. Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait Task Videos. (arXiv:2203.08215v1 [cs.CV])
7. Interactive Portrait Harmonization. (arXiv:2203.08216v1 [cs.CV])
8. CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP. (arXiv:2203.08219v1 [cs.CV])
9. A Deep Dive into Dataset Imbalance and Bias in Face Identification. (arXiv:2203.08235v1 [cs.CV])
10. Unified Visual Transformer Compression. (arXiv:2203.08243v1 [cs.LG])
11. 2-speed network ensemble for efficient classification of incremental land-use/land-cover satellite image chips. (arXiv:2203.08267v1 [cs.CV])
12. Driving Anomaly Detection Using Conditional Generative Adversarial Network. (arXiv:2203.08289v1 [cs.CV])
13. An explainability framework for cortical surface-based deep learning. (arXiv:2203.08312v1 [q-bio.NC])
14. Motif Mining: Finding and Summarizing Remixed Image Content. (arXiv:2203.08327v1 [cs.CV])
15. WeakM3D: Towards Weakly Supervised Monocular 3D Object Detection. (arXiv:2203.08332v1 [cs.CV])
16. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v1 [cs.CV])
17. Gradient Correction beyond Gradient Descent. (arXiv:2203.08345v1 [cs.LG])
18. Represent, Compare, and Learn: A Similarity-Aware Framework for Class-Agnostic Counting. (arXiv:2203.08354v1 [cs.CV])
19. Spot the Difference: A Cooperative Object-Referring Game in Non-Perfectly Co-Observable Scene. (arXiv:2203.08362v1 [cs.CV])
20. Mixed-Precision Neural Network Quantization via Learned Layer-wise Importance. (arXiv:2203.08368v1 [cs.LG])
21. Dual Diffusion Implicit Bridges for Image-to-Image Translation. (arXiv:2203.08382v1 [cs.CV])
22. Patch-Fool: Are Vision Transformers Always Robust Against Adversarial Perturbations?. (arXiv:2203.08392v1 [cs.CV])
23. Privacy-preserving Online AutoML for Domain-Specific Face Detection. (arXiv:2203.08399v1 [cs.CV])
24. RBC: Rectifying the Biased Context in Continual Semantic Segmentation. (arXiv:2203.08404v1 [cs.CV])
25. Multi-Scale Context-Guided Lumbar Spine Disease Identification with Coarse-to-fine Localization and Classification. (arXiv:2203.08408v1 [cs.CV])
26. FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction. (arXiv:2203.08411v1 [cs.CL])
27. Unsupervised Semantic Segmentation by Distilling Feature Correspondences. (arXiv:2203.08414v1 [cs.CV])
28. WegFormer: Transformers for Weakly Supervised Semantic Segmentation. (arXiv:2203.08421v1 [cs.CV])
29. Attribute Group Editing for Reliable Few-shot Image Generation. (arXiv:2203.08422v1 [cs.CV])
30. DiFT: Differentiable Differential Feature Transform for Multi-View Stereo. (arXiv:2203.08435v1 [cs.CV])
31. Open Set Recognition using Vision Transformer with an Additional Detection Head. (arXiv:2203.08441v1 [cs.CV])
32. Panini-Net: GAN Prior Based Degradation-Aware Feature Interpolation for Face **Restoration**. (arXiv:2203.08444v1 [cs.CV])
33. The Devil Is in the Details: Window-based Attention for Image Compression. (arXiv:2203.08450v1 [cs.CV])
34. PPCD-GAN: Progressive Pruning and Class-Aware Distillation for Large-Scale Conditional GANs Compression. (arXiv:2203.08456v1 [cs.CV])
35. Fusing Local Similarities for Retrieval-based 3D Orientation Estimation of Unseen Objects. (arXiv:2203.08472v1 [cs.CV])
36. Data Efficient 3D Learner via Knowledge Transferred from 2D Model. (arXiv:2203.08479v1 [cs.CV])
37. Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding. (arXiv:2203.08481v1 [cs.CV])
38. QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation. (arXiv:2203.08483v1 [cs.CV])
39. PointAttN: You Only Need Attention for Point Cloud Completion. (arXiv:2203.08485v1 [cs.CV])
40. A Survey of Historical Document Image Datasets. (arXiv:2203.08504v1 [cs.CV])
41. Multi-focus thermal image fusion. (arXiv:2203.08513v1 [cs.CV])
42. Fantastic Style Channels and Where to Find Them: A Submodular Framework for Discovering Diverse Directions in GANs. (arXiv:2203.08516v1 [cs.CV])
43. Towards Practical Certifiable Patch Defense with Vision Transformer. (arXiv:2203.08519v1 [cs.CV])
44. Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation from Monocular Video. (arXiv:2203.08534v1 [cs.CV])
45. Scribble-Supervised LiDAR Semantic Segmentation. (arXiv:2203.08537v1 [cs.CV])
46. Integrating Language Guidance into Vision-based Deep Metric Learning. (arXiv:2203.08543v1 [cs.CV])
47. Non-isotropy Regularization for Proxy-based Deep Metric Learning. (arXiv:2203.08547v1 [cs.CV])
48. Is it all a cluster game? -- Exploring Out-of-Distribution Detection based on Clustering in the Embedding Space. (arXiv:2203.08549v1 [cs.CV])
49. MonoJSG: Joint Semantic and Geometric Cost Volume for Monocular 3D Object Detection. (arXiv:2203.08563v1 [cs.CV])
50. EDTER: Edge Detection with Transformer. (arXiv:2203.08566v1 [cs.CV])
51. PMAL: Open Set Recognition via Robust Prototype Mining. (arXiv:2203.08569v1 [cs.CV])
52. A Survey on Infrared Image and Video Sets. (arXiv:2203.08581v1 [cs.CV])
53. Deep vanishing point detection: Geometric priors make dataset variations vanish. (arXiv:2203.08586v1 [cs.CV])
54. CtlGAN: Few-shot Artistic Portraits Generation with Contrastive Transfer Learning. (arXiv:2203.08612v1 [cs.CV])
55. Conditional Measurement Density Estimation in Sequential Monte Carlo via Normalizing Flow. (arXiv:2203.08617v1 [cs.AI])
56. Coverage Optimization of Camera Network for Continuous Deformable Object. (arXiv:2203.08632v1 [cs.CV])
57. Complexity Reduction of Learned In-Loop Filtering in Video Coding. (arXiv:2203.08650v1 [eess.IV])
58. Topology-Preserving Shape Reconstruction and Registration via Neural Diffeomorphic Flow. (arXiv:2203.08652v1 [cs.CV])
59. Occlusion Fields: An Implicit Representation for Non-Line-of-Sight Surface Reconstruction. (arXiv:2203.08657v1 [cs.CV])
60. Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient Medical Image Segmentation. (arXiv:2203.08667v1 [cs.CV])
61. Know your sensORs $\unicode{x2013}$ A Modality Study For Surgical Action Classification. (arXiv:2203.08674v1 [cs.CV])
62. Decoupled Knowledge Distillation. (arXiv:2203.08679v1 [cs.CV])
63. Learning video retrieval models with relevance-aware online mining. (arXiv:2203.08688v1 [cs.CV])
64. DeciWatch: A Simple Baseline for 10x Efficient 2D and 3D Pose Estimation. (arXiv:2203.08713v1 [cs.CV])
65. Relational Self-Supervised Learning. (arXiv:2203.08717v1 [cs.CV])
66. Attacking deep networks with surrogate-based adversarial black-box methods is easy. (arXiv:2203.08725v1 [cs.LG])
67. Tangles and Hierarchical Clustering. (arXiv:2203.08731v1 [cs.DM])
68. Learning Where To Look -- Generative NAS is Surprisingly Efficient. (arXiv:2203.08734v1 [cs.LG])
69. What Do Adversarially trained Neural Networks Focus: A Fourier Domain-based Study. (arXiv:2203.08739v1 [cs.CV])
70. UnseenNet: Fast Training Detector for Any Unseen Concept. (arXiv:2203.08759v1 [cs.CV])
71. X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation. (arXiv:2203.08764v1 [cs.CV])
72. Efficient conditioned face animation using frontally-viewed embedding. (arXiv:2203.08765v1 [cs.CV])
73. Object discovery and representation networks. (arXiv:2203.08777v1 [cs.CV])
74. PosePipe: Open-Source Human Pose Estimation Pipeline for Clinical Research. (arXiv:2203.08792v1 [cs.CV])
75. Zero Pixel Directional Boundary by Vector Transform. (arXiv:2203.08795v1 [cs.CV])
76. A Continual Learning Framework for Adaptive Defect Classification and Inspection. (arXiv:2203.08796v1 [cs.CV])
77. Theme-Aware Aesthetic Distribution Prediction With Full-Resolution Photographs. (arXiv:1908.01308v3 [cs.CV] UPDATED)
78. A Survey on Deep Learning-based Architectures for Semantic Segmentation on 2D images. (arXiv:1912.10230v5 [cs.CV] UPDATED)
79. Neural Parameter Allocation Search. (arXiv:2006.10598v4 [cs.LG] UPDATED)
80. Video Super Resolution Based on Deep Learning: A Comprehensive Survey. (arXiv:2007.12928v3 [cs.CV] UPDATED)
81. Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win. (arXiv:2010.03533v2 [cs.LG] UPDATED)
82. The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction. (arXiv:2101.07295v4 [cs.LG] UPDATED)
83. Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. (arXiv:2103.00370v3 [cs.LG] UPDATED)
84. Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance Normalization. (arXiv:2103.11784v3 [cs.CV] UPDATED)
85. Text to Image Generation with Semantic-Spatial Aware GAN. (arXiv:2104.00567v4 [cs.CV] UPDATED)
86. Do Deep Neural Networks Forget Facial Action Units? -- Exploring the Effects of Transfer Learning in Health Related Facial Expression Recognition. (arXiv:2104.07389v2 [cs.CV] UPDATED)
87. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
88. VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator. (arXiv:2105.11589v2 [cs.CV] UPDATED)
89. Incremental False Negative Detection for Contrastive Learning. (arXiv:2106.03719v6 [cs.CV] UPDATED)
90. On the relation between statistical learning and perceptual distances. (arXiv:2106.04427v4 [cs.CV] UPDATED)
91. Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v3 [cs.CV] UPDATED)
92. Looking Outside the Window: Wide-Context Transformer for the Semantic Segmentation of High-Resolution Remote Sensing Images. (arXiv:2106.15754v5 [cs.CV] UPDATED)
93. Fast whole-slide cartography in colon cancer histology using superpixels and CNN classification. (arXiv:2106.15893v3 [eess.IV] UPDATED)
94. Blind Image Super-resolution with Elaborate Degradation Modeling on Noise and Kernel. (arXiv:2107.00986v4 [cs.CV] UPDATED)
95. Unsupervised Discovery of Object Radiance Fields. (arXiv:2107.07905v2 [cs.CV] UPDATED)
96. Perceiver IO: A General Architecture for Structured Inputs & Outputs. (arXiv:2107.14795v3 [cs.LG] UPDATED)
97. Rapid Elastic Architecture Search under Specialized Classes and Resource Constraints. (arXiv:2108.01224v3 [cs.CV] UPDATED)
98. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v2 [cs.CV] UPDATED)
99. The University of California San Francisco Preoperative Diffuse Glioma MRI (UCSF-PDGM) Dataset. (arXiv:2109.00356v2 [cs.CV] UPDATED)
100. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v3 [cs.CV] UPDATED)
101. Learning to Downsample for Segmentation of Ultra-High Resolution Images. (arXiv:2109.11071v2 [cs.CV] UPDATED)
102. Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural Networks. (arXiv:2110.02865v3 [cs.NE] UPDATED)
103. DeepSSM: A Blueprint for Image-to-Shape Deep Learning Models. (arXiv:2110.07152v2 [cs.CV] UPDATED)
104. Understanding Procedural Knowledge by Sequencing Multimodal Instructional Manuals. (arXiv:2110.08486v2 [cs.CL] UPDATED)
105. The Efficiency Misnomer. (arXiv:2110.12894v2 [cs.LG] UPDATED)
106. Temporally Consistent Online Depth Estimation in Dynamic Scenes. (arXiv:2111.09337v2 [cs.CV] UPDATED)
107. Mesa: A Memory-saving Training Framework for Transformers. (arXiv:2111.11124v2 [cs.CV] UPDATED)
108. PointMixer: MLP-Mixer for Point Cloud Understanding. (arXiv:2111.11187v4 [cs.CV] UPDATED)
109. Pruning Self-attentions into Convolutional Layers in Single Path. (arXiv:2111.11802v2 [cs.CV] UPDATED)
110. Source-free unsupervised domain adaptation for cross-modality abdominal multi-organ segmentation. (arXiv:2111.12221v3 [cs.CV] UPDATED)
111. Sharpness-aware Quantization for Deep Neural Networks. (arXiv:2111.12273v2 [cs.CV] UPDATED)
112. Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements. (arXiv:2111.12855v2 [cs.CV] UPDATED)
113. Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v3 [cs.CV] UPDATED)
114. AdaptPose: Cross-Dataset Adaptation for 3D Human Pose Estimation by Learnable Motion Generation. (arXiv:2112.11593v2 [cs.CV] UPDATED)
115. MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v3 [cs.CV] UPDATED)
116. Collapse by Conditioning: Training Class-conditional GANs with Limited Data. (arXiv:2201.06578v2 [cs.CV] UPDATED)
117. DeepMix: Mobility-aware, Lightweight, and Hybrid 3D Object Detection for Headsets. (arXiv:2201.08812v2 [cs.CV] UPDATED)
118. Point-NeRF: Point-based Neural Radiance Fields. (arXiv:2201.08845v4 [cs.CV] UPDATED)
119. Indicative Image Retrieval: Turning Blackbox Learning into Grey. (arXiv:2201.11898v2 [cs.CV] UPDATED)
120. Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v4 [cs.LG] UPDATED)
121. GAN-generated Faces Detection: A Survey and New Perspectives (2022). (arXiv:2202.07145v2 [cs.CV] UPDATED)
122. Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding. (arXiv:2203.00867v2 [cs.CV] UPDATED)
123. Debiased Batch Normalization via Gaussian Process for Generalizable Person Re-Identification. (arXiv:2203.01723v2 [cs.CV] UPDATED)
124. Modality-Adaptive Mixup and Invariant Decomposition for RGB-Infrared Person Re-Identification. (arXiv:2203.01735v2 [cs.CV] UPDATED)
125. Playable Environments: Video Manipulation in Space and Time. (arXiv:2203.01914v2 [cs.CV] UPDATED)
126. FS-COCO: Towards Understanding of Freehand Sketches of Common Objects in Context. (arXiv:2203.02113v2 [cs.CV] UPDATED)
127. Spatio-temporal Gait Feature with Adaptive Distance Alignment. (arXiv:2203.03376v2 [cs.CV] UPDATED)
128. Deep Rectangling for Image Stitching: A Learning Baseline. (arXiv:2203.03831v2 [cs.CV] UPDATED)
129. Text-DIAE: Degradation Invariant Autoencoders for Text Recognition and Document **Enhancement**. (arXiv:2203.04814v3 [cs.CV] UPDATED)
130. Self-Sustaining Representation Expansion for Non-Exemplar Class-Incremental Learning. (arXiv:2203.06359v2 [cs.CV] UPDATED)
131. Privacy-friendly Synthetic Data for the Development of Face Morphing Attack Detectors. (arXiv:2203.06691v2 [cs.CV] UPDATED)
132. A Two-Block RNN-based Trajectory Prediction from Incomplete Trajectory. (arXiv:2203.07098v2 [cs.CV] UPDATED)
133. Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution. (arXiv:2203.07682v2 [cs.CV] UPDATED)
134. Implicit field supervision for robust non-rigid shape matching. (arXiv:2203.07694v2 [cs.CV] UPDATED)
135. Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation. (arXiv:2203.07697v2 [cs.CV] UPDATED)
136. Object Detection as Probabilistic Set Prediction. (arXiv:2203.07980v2 [cs.CV] UPDATED)
137. On Hyperbolic Embeddings in 2D Object Detection. (arXiv:2203.08049v2 [cs.CV] UPDATED)
138. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v2 [cs.CV] UPDATED)
## eess.IV
---
**11** new papers in eess.IV:-) 
1. UNet Architectures in Multiplanar Volumetric Segmentation -- Validated on Three Knee MRI Cohorts. (arXiv:2203.08194v1 [eess.IV])
2. HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction. (arXiv:2203.08213v1 [eess.IV])
3. Laplacian Filters for Integral Equations: Further Developments and Fast Algorithms. (arXiv:2203.08603v1 [eess.IV])
4. Complexity Reduction of Learned In-Loop Filtering in Video Coding. (arXiv:2203.08650v1 [eess.IV])
5. Video Super Resolution Based on Deep Learning: A Comprehensive Survey. (arXiv:2007.12928v3 [cs.CV] UPDATED)
6. Towards Ultra-Resolution Neural Style Transfer via Thumbnail Instance Normalization. (arXiv:2103.11784v3 [cs.CV] UPDATED)
7. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
8. On the relation between statistical learning and perceptual distances. (arXiv:2106.04427v4 [cs.CV] UPDATED)
9. Fast whole-slide cartography in colon cancer histology using superpixels and CNN classification. (arXiv:2106.15893v3 [eess.IV] UPDATED)
10. The University of California San Francisco Preoperative Diffuse Glioma MRI (UCSF-PDGM) Dataset. (arXiv:2109.00356v2 [cs.CV] UPDATED)
11. Robust Equivariant Imaging: a fully unsupervised framework for learning to image from noisy and partial measurements. (arXiv:2111.12855v2 [cs.CV] UPDATED)
## cs.LG
---
**195** new papers in cs.LG:-) 
1. HiSA-SMFM: Historical and Sentiment Analysis based Stock Market Forecasting Model. (arXiv:2203.08143v1 [q-fin.ST])
2. DeepTrust: A Reliable Financial Knowledge Retrieval Framework For Explaining Extreme Pricing Anomalies. (arXiv:2203.08144v1 [q-fin.ST])
3. Learning Transient Partial Differential Equations with Local Neural Operators. (arXiv:2203.08145v1 [cs.LG])
4. Energy-Latency Attacks via Sponge Poisoning. (arXiv:2203.08147v1 [cs.CR])
5. RES-HD: Resilient Intelligent Fault Diagnosis Against Adversarial Attacks Using Hyper-Dimensional Computing. (arXiv:2203.08148v1 [cs.CR])
6. MoReL: Multi-omics Relational Learning. (arXiv:2203.08149v1 [q-bio.QM])
7. A physics and data co-driven surrogate modeling approach for temperature field prediction on irregular geometric domain. (arXiv:2203.08150v1 [cs.LG])
8. Towards understanding deep learning with the natural clustering prior. (arXiv:2203.08174v1 [cs.LG])
9. SemiPFL: Personalized Semi-Supervised Federated Learning Framework for Edge Intelligence. (arXiv:2203.08176v1 [cs.LG])
10. Fiber Bundle Morphisms as a Framework for Modeling Many-to-Many Maps. (arXiv:2203.08189v1 [cs.LG])
11. UNet Architectures in Multiplanar Volumetric Segmentation -- Validated on Three Knee MRI Cohorts. (arXiv:2203.08194v1 [eess.IV])
12. Learning Deep Implicit Fourier Neural Operators (IFNOs) with Applications to Heterogeneous Material Modeling. (arXiv:2203.08205v1 [cs.LG])
13. SocialVAE: Human Trajectory Prediction using Timewise Latents. (arXiv:2203.08207v1 [cs.CV])
14. A Differentiable Approach to Combinatorial Optimization using Dataless Neural Networks. (arXiv:2203.08209v1 [cs.LG])
15. AUTOMATA: Gradient Based Data Subset Selection for Compute-Efficient Hyper-parameter Tuning. (arXiv:2203.08212v1 [cs.LG])
16. HUMUS-Net: Hybrid unrolled multi-scale network architecture for accelerated MRI reconstruction. (arXiv:2203.08213v1 [eess.IV])
17. Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision on Gait Task Videos. (arXiv:2203.08215v1 [cs.CV])
18. Zipfian environments for Reinforcement Learning. (arXiv:2203.08222v1 [cs.LG])
19. Sex Trouble: Common pitfalls in incorporating sex/gender in medical machine learning and how to avoid them. (arXiv:2203.08227v1 [cs.CY])
20. A Deep Dive into Dataset Imbalance and Bias in Face Identification. (arXiv:2203.08235v1 [cs.CV])
21. Data Contamination: From Memorization to Exploitation. (arXiv:2203.08242v1 [cs.CL])
22. Unified Visual Transformer Compression. (arXiv:2203.08243v1 [cs.LG])
23. Reconstructing Missing EHRs Using Time-Aware Within- and Cross-Visit Information for Septic Shock Early Prediction. (arXiv:2203.08245v1 [cs.LG])
24. Non-Linear Reinforcement Learning in Large Action Spaces: Structural Conditions and Sample-efficiency of Posterior Sampling. (arXiv:2203.08248v1 [cs.LG])
25. Neural RF SLAM for unsupervised positioning and mapping with channel state information. (arXiv:2203.08264v1 [cs.IT])
26. 2-speed network ensemble for efficient classification of incremental land-use/land-cover satellite image chips. (arXiv:2203.08267v1 [cs.CV])
27. Bi-Manual Manipulation and Attachment via Sim-to-Real Reinforcement Learning. (arXiv:2203.08277v1 [cs.RO])
28. Self-Distribution Distillation: Efficient Uncertainty Estimation. (arXiv:2203.08295v1 [cs.LG])
29. Improving Word Translation via Two-Stage Contrastive Learning. (arXiv:2203.08307v1 [cs.CL])
30. TAKDE: Temporal Adaptive Kernel Density Estimator for Real-Time Dynamic Density Estimation. (arXiv:2203.08317v1 [stat.ML])
31. ADATIME: A Benchmarking Suite for Domain Adaptation on Time Series Data. (arXiv:2203.08321v1 [cs.LG])
32. NURD: Negative-Unlabeled Learning for Online Datacenter Straggler Prediction. (arXiv:2203.08339v1 [cs.LG])
33. Adaptive Noisy Matrix Completion. (arXiv:2203.08340v1 [cs.LG])
34. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v1 [cs.CV])
35. Gradient Correction beyond Gradient Descent. (arXiv:2203.08345v1 [cs.LG])
36. A Multi-parameter Updating Fourier Online Gradient Descent Algorithm for Large-scale Nonlinear Classification. (arXiv:2203.08349v1 [eess.SP])
37. Mixed-Precision Neural Network Quantization via Learned Layer-wise Importance. (arXiv:2203.08368v1 [cs.LG])
38. Dual Diffusion Implicit Bridges for Image-to-Image Translation. (arXiv:2203.08382v1 [cs.CV])
39. Reducing Flipping Errors in Deep Neural Networks. (arXiv:2203.08390v1 [cs.LG])
40. COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks. (arXiv:2203.08398v1 [cs.LG])
41. How to Learn from Risk: Explicit Risk-Utility Reinforcement Learning for Efficient and Safe Driving Strategies. (arXiv:2203.08409v1 [cs.LG])
42. FormNet: Structural Encoding beyond Sequential Modeling in Form Document Information Extraction. (arXiv:2203.08411v1 [cs.CL])
43. CTDS: Centralized Teacher with Decentralized Student for Multi-Agent Reinforcement Learning. (arXiv:2203.08412v1 [cs.MA])
44. Unsupervised Semantic Segmentation by Distilling Feature Correspondences. (arXiv:2203.08414v1 [cs.CV])
45. On the Use of Fine-grained Vulnerable Code Statements for Software Vulnerability Assessment Models. (arXiv:2203.08417v1 [cs.SE])
46. Deep Residual Error and Bag-of-Tricks Learning for Gravitational Wave Surrogate Modeling. (arXiv:2203.08434v1 [astro-ph.IM])
47. Playing with blocks: Toward re-usable deep learning models for side-channel profiled attacks. (arXiv:2203.08448v1 [cs.CR])
48. Coach-assisted Multi-Agent Reinforcement Learning Framework for Unexpected Crashed Agents. (arXiv:2203.08454v1 [cs.LG])
49. Learning Audio Representations with MLPs. (arXiv:2203.08490v1 [cs.SD])
50. Deepchecks: A Library for Testing and Validating Machine Learning Models and Data. (arXiv:2203.08491v1 [cs.LG])
51. Resilient Neural Forecasting Systems. (arXiv:2203.08492v1 [cs.LG])
52. Monte Carlo PINNs: deep learning approach for forward and inverse problems involving high dimensional fractional partial differential equations. (arXiv:2203.08501v1 [cs.LG])
53. Differentiable DAG Sampling. (arXiv:2203.08509v1 [cs.LG])
54. Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When to Act. (arXiv:2203.08542v1 [cs.LG])
55. Learning to Generate Synthetic Training Data using Gradient Matching and Implicit Differentiation. (arXiv:2203.08559v1 [cs.LG])
56. An elementary analysis of ridge regression with random design. (arXiv:2203.08564v1 [math.ST])
57. Undersmoothing Causal Estimators with Generative Trees. (arXiv:2203.08570v1 [cs.LG])
58. MIMO-GAN: Generative MIMO Channel Modeling. (arXiv:2203.08588v1 [cs.IT])
59. Less is More: Summary of Long Instructions is Better for Program Synthesis. (arXiv:2203.08597v1 [cs.CL])
60. Generic Lithography Modeling with Dual-band Optics-Inspired Neural Networks. (arXiv:2203.08616v1 [cs.OH])
61. Extended vehicle energy dataset (eVED): an enhanced large-scale dataset for deep learning on vehicle trip energy consumption. (arXiv:2203.08630v1 [cs.LG])
62. Adversarial Learned Fair Representations using Dampening and Stacking. (arXiv:2203.08637v1 [cs.LG])
63. Context-Aware Drift Detection. (arXiv:2203.08644v1 [stat.ML])
64. The Structured Abstain Problem and the Lov\'asz Hinge. (arXiv:2203.08645v1 [cs.LG])
65. Artificial Intelligence Enables Real-Time and Intuitive Control of Prostheses via Nerve Interface. (arXiv:2203.08648v1 [cs.RO])
66. Counterfactual Inference of Second Opinions. (arXiv:2203.08653v1 [cs.LG])
67. Unraveled Multilevel Transformation Networks for Predicting Sparsely-Observed Spatiotemporal Dynamics. (arXiv:2203.08655v1 [cs.LG])
68. Learning Representation for Bayesian Optimization with Collision-free Regularization. (arXiv:2203.08656v1 [cs.LG])
69. Occlusion Fields: An Implicit Representation for Non-Line-of-Sight Surface Reconstruction. (arXiv:2203.08657v1 [cs.CV])
70. MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients. (arXiv:2203.08669v1 [cs.CR])
71. Measuring Fairness of Text Classifiers via Prediction Sensitivity. (arXiv:2203.08670v1 [cs.LG])
72. High dimensional change-point detection: a complete graph approach. (arXiv:2203.08709v1 [stat.ML])
73. Multiscale Sensor Fusion and Continuous Control with Neural CDEs. (arXiv:2203.08715v1 [cs.RO])
74. Relational Self-Supervised Learning. (arXiv:2203.08717v1 [cs.CV])
75. Attacking deep networks with surrogate-based adversarial black-box methods is easy. (arXiv:2203.08725v1 [cs.LG])
76. Tangles and Hierarchical Clustering. (arXiv:2203.08731v1 [cs.DM])
77. Learning Where To Look -- Generative NAS is Surprisingly Efficient. (arXiv:2203.08734v1 [cs.LG])
78. Hardware Approximate Techniques for Deep Neural Network Accelerators: A Survey. (arXiv:2203.08737v1 [cs.AR])
79. What Do Adversarially trained Neural Networks Focus: A Fourier Domain-based Study. (arXiv:2203.08739v1 [cs.CV])
80. Practical Conditional Neural Processes Via Tractable Dependent Predictions. (arXiv:2203.08775v1 [stat.ML])
81. Object discovery and representation networks. (arXiv:2203.08777v1 [cs.CV])
82. Are Shortest Rationales the Best Explanations for Human Understanding?. (arXiv:2203.08788v1 [cs.CL])
83. Zero Pixel Directional Boundary by Vector Transform. (arXiv:2203.08795v1 [cs.CV])
84. A Continual Learning Framework for Adaptive Defect Classification and Inspection. (arXiv:2203.08796v1 [cs.CV])
85. Regret analysis of the Piyavskii-Shubert algorithm for global Lipschitz optimization. (arXiv:2002.02390v2 [cs.LG] UPDATED)
86. MCMC Should Mix: Learning Energy-Based Model with Neural Transport Latent Space MCMC. (arXiv:2006.06897v2 [stat.ML] UPDATED)
87. Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v6 [cs.LG] UPDATED)
88. Neural Parameter Allocation Search. (arXiv:2006.10598v4 [cs.LG] UPDATED)
89. Counterfactually Guided Off-policy Transfer in Clinical Settings. (arXiv:2006.11654v3 [cs.LG] UPDATED)
90. Accurate Parameter Estimation for Risk-aware Autonomous Systems. (arXiv:2006.12687v2 [eess.SY] UPDATED)
91. Failure Modes of Variational Autoencoders and Their Effects on Downstream Tasks. (arXiv:2007.07124v4 [stat.ML] UPDATED)
92. Stochastic Optimization Forests. (arXiv:2008.07473v6 [math.OC] UPDATED)
93. Neural Identification for Control. (arXiv:2009.11782v4 [eess.SY] UPDATED)
94. Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win. (arXiv:2010.03533v2 [cs.LG] UPDATED)
95. A Random Matrix Theory Approach to Damping in Deep Learning. (arXiv:2011.08181v5 [stat.ML] UPDATED)
96. SHIELD: Defending Textual Neural Networks against Multiple Black-Box Adversarial Attacks with Stochastic Multi-Expert Patcher. (arXiv:2011.08908v2 [cs.LG] UPDATED)
97. Accelerating amorphous polymer electrolyte screening by learning to reduce errors in molecular dynamics simulated properties. (arXiv:2101.05339v2 [cond-mat.mtrl-sci] UPDATED)
98. Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. (arXiv:2101.05467v2 [cs.LG] UPDATED)
99. LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning. (arXiv:2101.06223v2 [cs.LG] UPDATED)
100. The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction. (arXiv:2101.07295v4 [cs.LG] UPDATED)
101. Proof Artifact Co-training for Theorem Proving with Language Models. (arXiv:2102.06203v2 [cs.AI] UPDATED)
102. Bayesian Neural Network Priors Revisited. (arXiv:2102.06571v3 [stat.ML] UPDATED)
103. Pareto Optimal Model Selection in Linear Bandits. (arXiv:2102.06593v2 [stat.ML] UPDATED)
104. Axiomatic Explanations for Visual Search, Retrieval, and Similarity Learning. (arXiv:2103.00370v3 [cs.LG] UPDATED)
105. Text to Image Generation with Semantic-Spatial Aware GAN. (arXiv:2104.00567v4 [cs.CV] UPDATED)
106. Survey on reinforcement learning for language processing. (arXiv:2104.05565v3 [cs.CL] UPDATED)
107. Iterative Alignment Flows. (arXiv:2104.07232v3 [cs.LG] UPDATED)
108. Do Deep Neural Networks Forget Facial Action Units? -- Exploring the Effects of Transfer Learning in Health Related Facial Expression Recognition. (arXiv:2104.07389v2 [cs.CV] UPDATED)
109. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v4 [cs.CV] UPDATED)
110. Continual Learning via Bit-Level Information Preserving. (arXiv:2105.04444v4 [cs.LG] UPDATED)
111. Natural Posterior Network: Deep Bayesian Uncertainty for Exponential Family Distributions. (arXiv:2105.04471v2 [cs.LG] UPDATED)
112. Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks. (arXiv:2105.08621v2 [cs.LG] UPDATED)
113. VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator. (arXiv:2105.11589v2 [cs.CV] UPDATED)
114. Fully Hyperbolic Neural Networks. (arXiv:2105.14686v3 [cs.CL] UPDATED)
115. NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning. (arXiv:2106.01613v3 [cs.LG] UPDATED)
116. Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL. (arXiv:2106.02193v2 [cs.LG] UPDATED)
117. Energy-Based Learning for Cooperative Games, with Applications to Valuation Problems in Machine Learning. (arXiv:2106.02938v3 [cs.LG] UPDATED)
118. Fixed-Budget Best-Arm Identification in Structured Bandits. (arXiv:2106.04763v7 [cs.LG] UPDATED)
119. FedBABU: Towards Enhanced Representation for Federated Image Classification. (arXiv:2106.06042v3 [cs.LG] UPDATED)
120. Guaranteed Fixed-Confidence Best Arm Identification in Multi-Armed Bandits: Simple Sequential Elimination Algorithms. (arXiv:2106.06848v5 [cs.LG] UPDATED)
121. Multi-modal Scene-compliant User Intention Estimation in Navigation. (arXiv:2106.06920v2 [cs.RO] UPDATED)
122. Backdoor Learning Curves: Explaining Backdoor Poisoning Beyond Influence Functions. (arXiv:2106.07214v3 [cs.LG] UPDATED)
123. Unified Interpretation of Softmax Cross-Entropy and Negative Sampling: With Case Study for Knowledge Graph Embedding. (arXiv:2106.07250v4 [cs.LG] UPDATED)
124. CROP: Certifying Robust Policies for Reinforcement Learning through Functional Smoothing. (arXiv:2106.09292v2 [cs.LG] UPDATED)
125. PAC Prediction Sets Under Covariate Shift. (arXiv:2106.09848v2 [cs.LG] UPDATED)
126. A Reduction-Based Framework for Conservative Bandits and Reinforcement Learning. (arXiv:2106.11692v2 [cs.LG] UPDATED)
127. Bregman Gradient Policy Optimization. (arXiv:2106.12112v3 [cs.LG] UPDATED)
128. SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption. (arXiv:2106.15147v2 [cs.LG] UPDATED)
129. Classical Planning in Deep Latent Space. (arXiv:2107.00110v2 [cs.AI] UPDATED)
130. An Investigation of the (In)effectiveness of Counterfactually Augmented Data. (arXiv:2107.00753v3 [cs.CL] UPDATED)
131. DPPIN: A Biological Repository of Dynamic Protein-Protein Interaction Network Data. (arXiv:2107.02168v3 [cs.LG] UPDATED)
132. Optimality of the Johnson-Lindenstrauss Dimensionality Reduction for Practical Measures. (arXiv:2107.06626v2 [cs.DS] UPDATED)
133. Perceiver IO: A General Architecture for Structured Inputs & Outputs. (arXiv:2107.14795v3 [cs.LG] UPDATED)
134. Rapid Elastic Architecture Search under Specialized Classes and Resource Constraints. (arXiv:2108.01224v3 [cs.CV] UPDATED)
135. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v2 [cs.CV] UPDATED)
136. PI3NN: Out-of-distribution-aware prediction intervals from three neural networks. (arXiv:2108.02327v3 [cs.LG] UPDATED)
137. Deep Learning Enhanced Dynamic Mode Decomposition. (arXiv:2108.04433v4 [cs.LG] UPDATED)
138. FedChain: Chained Algorithms for Near-Optimal Communication Cost in Federated Learning. (arXiv:2108.06869v2 [cs.LG] UPDATED)
139. Bootstrapped Meta-Learning. (arXiv:2109.04504v2 [cs.LG] UPDATED)
140. HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation. (arXiv:2109.05490v3 [cs.LG] UPDATED)
141. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v3 [cs.CV] UPDATED)
142. Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data. (arXiv:2109.07117v3 [cs.LG] UPDATED)
143. Reframing Instructional Prompts to GPTk's Language. (arXiv:2109.07830v3 [cs.CL] UPDATED)
144. Learning to Downsample for Segmentation of Ultra-High Resolution Images. (arXiv:2109.11071v2 [cs.CV] UPDATED)
145. Dropout Q-Functions for Doubly Efficient Reinforcement Learning. (arXiv:2110.02034v2 [cs.LG] UPDATED)
146. Top-N: Equivariant set and graph generation without exchangeability. (arXiv:2110.02096v3 [cs.LG] UPDATED)
147. PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v3 [cs.CL] UPDATED)
148. Spike-inspired Rank Coding for Fast and Accurate Recurrent Neural Networks. (arXiv:2110.02865v3 [cs.NE] UPDATED)
149. Frame Averaging for Invariant and Equivariant Network Design. (arXiv:2110.03336v4 [cs.LG] UPDATED)
150. Revisiting Design Choices in Offline Model-Based Reinforcement Learning. (arXiv:2110.04135v2 [cs.LG] UPDATED)
151. Neural Link Prediction with Walk Pooling. (arXiv:2110.04375v2 [cs.LG] UPDATED)
152. Graph-Guided Network for Irregularly Sampled Multivariate Time Series. (arXiv:2110.05357v2 [cs.LG] UPDATED)
153. Embedded-model flows: Combining the inductive biases of model-free deep learning and explicit probabilistic modeling. (arXiv:2110.06021v3 [stat.ML] UPDATED)
154. Meta Learning Low Rank Covariance Factors for Energy-Based Deterministic Uncertainty. (arXiv:2110.06381v3 [stat.ML] UPDATED)
155. DeepSSM: A Blueprint for Image-to-Shape Deep Learning Models. (arXiv:2110.07152v2 [cs.CV] UPDATED)
156. Sharpness-Aware Minimization Improves Language Model Generalization. (arXiv:2110.08529v2 [cs.CL] UPDATED)
157. The Efficiency Misnomer. (arXiv:2110.12894v2 [cs.LG] UPDATED)
158. What Do We Mean by Generalization in Federated Learning?. (arXiv:2110.14216v2 [cs.LG] UPDATED)
159. PDE-READ: Human-readable Partial Differential Equation Discovery using Deep Learning. (arXiv:2111.00998v4 [cs.LG] UPDATED)
160. Deep learning of multi-resolution X-Ray micro-CT images for multi-scale modelling. (arXiv:2111.01270v3 [physics.geo-ph] UPDATED)
161. Brain-inspired Cognition in Next Generation Racetrack Memories. (arXiv:2111.02246v2 [cs.LG] UPDATED)
162. Mesa: A Memory-saving Training Framework for Transformers. (arXiv:2111.11124v2 [cs.CV] UPDATED)
163. On the Existence of Universal Lottery Tickets. (arXiv:2111.11146v2 [cs.LG] UPDATED)
164. Lossless Compression with Probabilistic Circuits. (arXiv:2111.11632v2 [cs.LG] UPDATED)
165. Pruning Self-attentions into Convolutional Layers in Single Path. (arXiv:2111.11802v2 [cs.CV] UPDATED)
166. Sharpness-aware Quantization for Deep Neural Networks. (arXiv:2111.12273v2 [cs.CV] UPDATED)
167. Understanding over-squashing and bottlenecks on graphs via curvature. (arXiv:2111.14522v2 [stat.ML] UPDATED)
168. p2pGNN: A Decentralized Graph Neural Network for Node Classification in Peer-to-Peer Networks. (arXiv:2111.14837v2 [cs.LG] UPDATED)
169. Zero-Shot Cross-Lingual Machine Reading Comprehension via Inter-sentence Dependency Graph. (arXiv:2112.00503v5 [cs.CL] UPDATED)
170. Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v3 [cs.CV] UPDATED)
171. Sharpness-Aware Minimization with Dynamic Reweighting. (arXiv:2112.08772v2 [cs.LG] UPDATED)
172. Neural Echo State Network using oscillations of gas bubbles in water. (arXiv:2112.11592v2 [physics.flu-dyn] UPDATED)
173. Representation Learning via Consistent Assignment of Views to Clusters. (arXiv:2112.15421v2 [cs.LG] UPDATED)
174. MERLOT Reserve: Neural Script Knowledge through Vision and Language and Sound. (arXiv:2201.02639v3 [cs.CV] UPDATED)
175. GRPE: Relative Positional Encoding for Graph Transformer. (arXiv:2201.12787v2 [cs.LG] UPDATED)
176. Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v4 [cs.LG] UPDATED)
177. Improving Screening Processes via Calibrated Subset Selection. (arXiv:2202.01147v2 [cs.LG] UPDATED)
178. Theoretical Exploration of Solutions of Feedforward ReLU networks. (arXiv:2202.01919v5 [cs.LG] UPDATED)
179. From Generalisation Error to Transportation-cost Inequalities and Back. (arXiv:2202.03956v2 [cs.IT] UPDATED)
180. Cyclical Curriculum Learning. (arXiv:2202.05531v2 [cs.LG] UPDATED)
181. Development and Comparison of Scoring Functions in Curriculum Learning. (arXiv:2202.06823v2 [cs.LG] UPDATED)
182. DARL1N: Distributed multi-Agent Reinforcement Learning with One-hop Neighbors. (arXiv:2202.09019v2 [cs.MA] UPDATED)
183. Distributed Out-of-Memory NMF of Dense and Sparse Data on CPU/GPU Architectures with Automatic Model Selection for Exascale Data. (arXiv:2202.09518v2 [cs.DC] UPDATED)
184. Using Deep Reinforcement Learning with Automatic Curriculum Learning for Mapless Navigation in Intralogistics. (arXiv:2202.11512v2 [cs.RO] UPDATED)
185. Deep Learning to advance the Eigenspace Perturbation Method for Turbulence Model Uncertainty Quantification. (arXiv:2202.12378v2 [cs.LG] UPDATED)
186. Evaluating Local Model-Agnostic Explanations of Learning to Rank Models with Decision Paths. (arXiv:2203.02295v2 [stat.ML] UPDATED)
187. On Embeddings for Numerical Features in Tabular Deep Learning. (arXiv:2203.05556v2 [cs.LG] UPDATED)
188. The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. (arXiv:2203.06498v2 [cs.LG] UPDATED)
189. Identifying the root cause of cable network problems with machine learning. (arXiv:2203.06989v2 [cs.NI] UPDATED)
190. Dawn of the transformer era in speech emotion recognition: closing the valence gap. (arXiv:2203.07378v2 [eess.AS] UPDATED)
191. Don't fear the unlabelled: safe deep semi-supervised learning via simple debiasing. (arXiv:2203.07512v2 [stat.ML] UPDATED)
192. Lifelong Matrix Completion with Sparsity-Number. (arXiv:2203.07637v2 [cs.LG] UPDATED)
193. Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation. (arXiv:2203.07735v2 [cs.IR] UPDATED)
194. Object Detection as Probabilistic Set Prediction. (arXiv:2203.07980v2 [cs.CV] UPDATED)
195. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v2 [cs.CV] UPDATED)
## cs.AI
---
**89** new papers in cs.AI:-) 
1. HiSA-SMFM: Historical and Sentiment Analysis based Stock Market Forecasting Model. (arXiv:2203.08143v1 [q-fin.ST])
2. The Design and Implementation of a Broadly Applicable Algorithm for Optimizing Intra-Day Surgical Scheduling. (arXiv:2203.08146v1 [cs.AI])
3. Towards understanding deep learning with the natural clustering prior. (arXiv:2203.08174v1 [cs.LG])
4. SemiPFL: Personalized Semi-Supervised Federated Learning Framework for Edge Intelligence. (arXiv:2203.08176v1 [cs.LG])
5. A Differentiable Approach to Combinatorial Optimization using Dataless Neural Networks. (arXiv:2203.08209v1 [cs.LG])
6. CrowdMLP: Weakly-Supervised Crowd Counting via Multi-Granularity MLP. (arXiv:2203.08219v1 [cs.CV])
7. Development of Decision Support System for Effective COVID-19 Management. (arXiv:2203.08221v1 [eess.SY])
8. Toward Improving Attentive Neural Networks in Legal Text Processing. (arXiv:2203.08244v1 [cs.CL])
9. Non-Linear Reinforcement Learning in Large Action Spaces: Structural Conditions and Sample-efficiency of Posterior Sampling. (arXiv:2203.08248v1 [cs.LG])
10. Better Quality Estimation for Low Resource Corpus Mining. (arXiv:2203.08259v1 [cs.CL])
11. Bi-Manual Manipulation and Attachment via Sim-to-Real Reinforcement Learning. (arXiv:2203.08277v1 [cs.RO])
12. Self-Distribution Distillation: Efficient Uncertainty Estimation. (arXiv:2203.08295v1 [cs.LG])
13. Improving Word Translation via Two-Stage Contrastive Learning. (arXiv:2203.08307v1 [cs.CL])
14. Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go. (arXiv:2203.08351v1 [cs.CL])
15. Dual Diffusion Implicit Bridges for Image-to-Image Translation. (arXiv:2203.08382v1 [cs.CV])
16. Towards Formalizing HRI Data Collection Processes. (arXiv:2203.08396v1 [cs.RO])
17. Multi-Scale Context-Guided Lumbar Spine Disease Identification with Coarse-to-fine Localization and Classification. (arXiv:2203.08408v1 [cs.CV])
18. Unsupervised Semantic Segmentation by Distilling Feature Correspondences. (arXiv:2203.08414v1 [cs.CV])
19. Open Set Recognition using Vision Transformer with an Additional Detection Head. (arXiv:2203.08441v1 [cs.CV])
20. Understanding and Improving Sequence-to-Sequence Pretraining for Neural Machine Translation. (arXiv:2203.08442v1 [cs.CL])
21. Can Pre-trained Language Models Interpret Similes as Smart as Human?. (arXiv:2203.08452v1 [cs.CL])
22. Building AI Innovation Labs together with Companies. (arXiv:2203.08465v1 [cs.SE])
23. E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning. (arXiv:2203.08480v1 [cs.CL])
24. Raw waveform speaker verification for supervised and self-supervised learning. (arXiv:2203.08488v1 [eess.AS])
25. Resilient Neural Forecasting Systems. (arXiv:2203.08492v1 [cs.LG])
26. TegTok: Augmenting Text Generation via Task-specific and Open-world Knowledge. (arXiv:2203.08517v1 [cs.CL])
27. Towards Practical Certifiable Patch Defense with Vision Transformer. (arXiv:2203.08519v1 [cs.CV])
28. Lazy-MDPs: Towards Interpretable Reinforcement Learning by Learning When to Act. (arXiv:2203.08542v1 [cs.LG])
29. PMIC: Improving Multi-Agent Reinforcement Learning with Progressive Mutual Information Collaboration. (arXiv:2203.08553v1 [cs.MA])
30. LEVEN: A Large-Scale Chinese Legal Event Detection Dataset. (arXiv:2203.08556v1 [cs.CL])
31. Learning to Generate Synthetic Training Data using Gradient Matching and Implicit Differentiation. (arXiv:2203.08559v1 [cs.LG])
32. A Survey on Infrared Image and Video Sets. (arXiv:2203.08581v1 [cs.CV])
33. MIMO-GAN: Generative MIMO Channel Modeling. (arXiv:2203.08588v1 [cs.IT])
34. Towards a Roadmap on Software Engineering for Responsible AI. (arXiv:2203.08594v1 [cs.SE])
35. Less is More: Summary of Long Instructions is Better for Program Synthesis. (arXiv:2203.08597v1 [cs.CL])
36. Scientific and Technological Information Oriented Semantics-adversarial and Media-adversarial Cross-media Retrieval. (arXiv:2203.08615v1 [cs.IR])
37. Conditional Measurement Density Estimation in Sequential Monte Carlo via Normalizing Flow. (arXiv:2203.08617v1 [cs.AI])
38. Adversarial Learned Fair Representations using Dampening and Stacking. (arXiv:2203.08637v1 [cs.LG])
39. Artificial Intelligence Enables Real-Time and Intuitive Control of Prostheses via Nerve Interface. (arXiv:2203.08648v1 [cs.RO])
40. Learning Representation for Bayesian Optimization with Collision-free Regularization. (arXiv:2203.08656v1 [cs.LG])
41. Decoupled Knowledge Distillation. (arXiv:2203.08679v1 [cs.CV])
42. A Feasibility Study of Answer-Unaware Question Generation for Education. (arXiv:2203.08685v1 [cs.CL])
43. Multiscale Sensor Fusion and Continuous Control with Neural CDEs. (arXiv:2203.08715v1 [cs.RO])
44. Multi-Stage Prompting for Knowledgeable Dialogue Generation. (arXiv:2203.08745v1 [cs.CL])
45. X-Learner: Learning Cross Sources and Tasks for Universal Visual Representation. (arXiv:2203.08764v1 [cs.CV])
46. Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data. (arXiv:2203.08773v1 [cs.CL])
47. Object discovery and representation networks. (arXiv:2203.08777v1 [cs.CV])
48. Exploring Variational Graph Auto-Encoders for Extract Class Refactoring Recommendation. (arXiv:2203.08787v1 [cs.SE])
49. Are Shortest Rationales the Best Explanations for Human Understanding?. (arXiv:2203.08788v1 [cs.CL])
50. Accelerating amorphous polymer electrolyte screening by learning to reduce errors in molecular dynamics simulated properties. (arXiv:2101.05339v2 [cond-mat.mtrl-sci] UPDATED)
51. LIME: Learning Inductive Bias for Primitives of Mathematical Reasoning. (arXiv:2101.06223v2 [cs.LG] UPDATED)
52. Proof Artifact Co-training for Theorem Proving with Language Models. (arXiv:2102.06203v2 [cs.AI] UPDATED)
53. Survey on reinforcement learning for language processing. (arXiv:2104.05565v3 [cs.CL] UPDATED)
54. Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks. (arXiv:2105.08621v2 [cs.LG] UPDATED)
55. VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator. (arXiv:2105.11589v2 [cs.CV] UPDATED)
56. SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues. (arXiv:2106.01006v3 [cs.CL] UPDATED)
57. Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL. (arXiv:2106.02193v2 [cs.LG] UPDATED)
58. SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption. (arXiv:2106.15147v2 [cs.LG] UPDATED)
59. Bounded rationality for relaxing best response and mutual consistency: The Quantal Hierarchy model of decision-making. (arXiv:2106.15844v3 [cs.GT] UPDATED)
60. Classical Planning in Deep Latent Space. (arXiv:2107.00110v2 [cs.AI] UPDATED)
61. Unsupervised Discovery of Object Radiance Fields. (arXiv:2107.07905v2 [cs.CV] UPDATED)
62. Predicting Patch Correctness Based on the Similarity of Failing Test Cases. (arXiv:2107.13296v2 [cs.SE] UPDATED)
63. SphereFace2: Binary Classification is All You Need for Deep Face Recognition. (arXiv:2108.01513v2 [cs.CV] UPDATED)
64. Bootstrapped Meta-Learning. (arXiv:2109.04504v2 [cs.LG] UPDATED)
65. HyAR: Addressing Discrete-Continuous Action Reinforcement Learning via Hybrid Action Representation. (arXiv:2109.05490v3 [cs.LG] UPDATED)
66. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v3 [cs.CV] UPDATED)
67. Reframing Instructional Prompts to GPTk's Language. (arXiv:2109.07830v3 [cs.CL] UPDATED)
68. On the Feasibility of Learning Finger-gaiting In-hand Manipulation with Intrinsic Sensing. (arXiv:2109.12720v2 [cs.RO] UPDATED)
69. Dropout Q-Functions for Doubly Efficient Reinforcement Learning. (arXiv:2110.02034v2 [cs.LG] UPDATED)
70. PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v3 [cs.CL] UPDATED)
71. Revisiting Design Choices in Offline Model-Based Reinforcement Learning. (arXiv:2110.04135v2 [cs.LG] UPDATED)
72. Graph-Guided Network for Irregularly Sampled Multivariate Time Series. (arXiv:2110.05357v2 [cs.LG] UPDATED)
73. The Efficiency Misnomer. (arXiv:2110.12894v2 [cs.LG] UPDATED)
74. A trained humanoid robot can perform human-like crossmodal social attention and conflict resolution. (arXiv:2111.01906v2 [cs.RO] UPDATED)
75. On the Existence of Universal Lottery Tickets. (arXiv:2111.11146v2 [cs.LG] UPDATED)
76. CODER: An efficient framework for improving retrieval through COntextual Document Embedding Reranking. (arXiv:2112.08766v2 [cs.IR] UPDATED)
77. Collapse by Conditioning: Training Class-conditional GANs with Limited Data. (arXiv:2201.06578v2 [cs.CV] UPDATED)
78. Indicative Image Retrieval: Turning Blackbox Learning into Grey. (arXiv:2201.11898v2 [cs.CV] UPDATED)
79. GRPE: Relative Positional Encoding for Graph Transformer. (arXiv:2201.12787v2 [cs.LG] UPDATED)
80. Auto-Transfer: Learning to Route Transferrable Representations. (arXiv:2202.01011v4 [cs.LG] UPDATED)
81. Theoretical Exploration of Solutions of Feedforward ReLU networks. (arXiv:2202.01919v5 [cs.LG] UPDATED)
82. Cyclical Curriculum Learning. (arXiv:2202.05531v2 [cs.LG] UPDATED)
83. Development and Comparison of Scoring Functions in Curriculum Learning. (arXiv:2202.06823v2 [cs.LG] UPDATED)
84. SGPT: GPT Sentence Embeddings for Semantic Search. (arXiv:2202.08904v3 [cs.CL] UPDATED)
85. Structure Extraction in Task-Oriented Dialogues with Slot Clustering. (arXiv:2203.00073v3 [cs.CL] UPDATED)
86. Playable Environments: Video Manipulation in Space and Time. (arXiv:2203.01914v2 [cs.CV] UPDATED)
87. Don't fear the unlabelled: safe deep semi-supervised learning via simple debiasing. (arXiv:2203.07512v2 [stat.ML] UPDATED)
88. Seamlessly Integrating Factual Information and Social Content with Persuasive Dialogue. (arXiv:2203.07657v2 [cs.CL] UPDATED)
89. Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation. (arXiv:2203.07735v2 [cs.IR] UPDATED)

