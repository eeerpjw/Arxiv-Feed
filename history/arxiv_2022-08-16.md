# Your interest papers
---
## cs.CV
---
### Self-supervised Matting-specific Portrait **Enhancement** and Generation. (arXiv:2208.06601v1 [cs.CV])
- Authors : Yangyang Xu, Zeyang Zhou, Shengfeng He
- Link : [http://arxiv.org/abs/2208.06601](http://arxiv.org/abs/2208.06601)
> ABSTRACT  :  We resolve the ill-posed alpha matting problem from a completely different perspective. Given an input portrait image, instead of estimating the corresponding alpha matte, we focus on the other end, to subtly enhance this input so that the alpha matte can be easily estimated by any existing matting models. This is accomplished by exploring the latent space of GAN models. It is demonstrated that interpretable directions can be found in the latent space and they correspond to semantic image transformations. We further explore this property in alpha matting. Particularly, we invert an input portrait into the latent code of StyleGAN, and our aim is to discover whether there is an enhanced version in the latent space which is more compatible with a reference matting model. We optimize multi-scale latent vectors in the latent spaces under four tailored losses, ensuring matting-specificity and subtle modifications on the portrait. We demonstrate that the proposed method can refine real portrait images for arbitrary matting models, boosting the performance of automatic alpha matting by a large margin. In addition, we leverage the generative property of StyleGAN, and propose to generate enhanced portrait data which can be treated as the pseudo GT. It addresses the problem of expensive alpha matte annotation, further augmenting the matting performance of existing models. Code is available at~\url{https://github.com/cnnlstm/StyleGAN_Matting}.  
### **HDR**-Plenoxels: Self-Calibrating **High Dynamic Range** Radiance Fields. (arXiv:2208.06787v1 [cs.CV])
- Authors : Kim Jun, Kim Yu, Moon Ye, Hyun Oh
- Link : [http://arxiv.org/abs/2208.06787](http://arxiv.org/abs/2208.06787)
> ABSTRACT  :  We propose **high dynamic range** radiance (**HDR**) fields, **HDR**-Plenoxels, that learn a plenoptic function of 3D **HDR** radiance fields, geometry information, and varying camera settings inherent in 2D low dynamic range (LDR) images. Our voxel-based volume rendering pipeline reconstructs **HDR** radiance fields with only multi-view LDR images taken from varying camera settings in an end-to-end manner and has a fast convergence speed. To deal with various cameras in real-world scenarios, we introduce a tone mapping module that models the digital in-camera imaging pipeline (ISP) and disentangles radiometric settings. Our tone mapping module allows us to render by controlling the radiometric settings of each novel view. Finally, we build a multi-view dataset with varying camera conditions, which fits our problem setting. Our experiments show that **HDR**-Plenoxels can express detail and high-quality **HDR** novel views from only LDR images with various cameras.  
### Remote Photoplethysmography from Low Resolution videos: An end-to-end solution using Efficient ConvNets. (arXiv:2208.06817v1 [cs.CV])
- Authors : Bharath Ramakrishnan, Ruijia Deng
- Link : [http://arxiv.org/abs/2208.06817](http://arxiv.org/abs/2208.06817)
> ABSTRACT  :  Measurement of the cardiac pulse from facial video has become an interesting pursuit of research over the last few years. This is mainly due to the increasing importance of obtaining the heart rate of an individual in a non-invasive manner, which can be highly useful for applications in gaming and the medical industry. Another instrumental area of research over the past few years has been the advent of Deep Learning and using Deep Neural networks to enhance task performance. In this work, we propose to use efficient convolutional networks to accurately measure the heart rate of user from low resolution facial videos. Furthermore, to ensure that we are able to obtain the heart rate in **real time**, we compress the deep learning model by pruning it, thereby reducing its memory footprint. We benchmark the performance of our approach on the MAHNOB dataset and compare its performance across multiple approaches.  
### HighlightNet: Highlighting **Low-Light** Potential Features for Real-Time UAV Tracking. (arXiv:2208.06818v1 [cs.RO])
- Authors : Changhong Fu, Haolin Dong, Junjie Ye, Guangze Zheng, Sihang Li, Jilin Zhao
- Link : [http://arxiv.org/abs/2208.06818](http://arxiv.org/abs/2208.06818)
> ABSTRACT  :  **Low-light** environments have posed a formidable challenge for robust unmanned aerial vehicle (UAV) tracking even with state-of-the-art (SOTA) trackers since the potential image features are hard to extract under adverse light conditions. Besides, due to the low visibility, accurate online selection of the object also becomes extremely difficult for human monitors to initialize UAV tracking in ground control stations. To solve these problems, this work proposes a novel enhancer, i.e., HighlightNet, to light up potential objects for both human operators and UAV trackers. By employing Transformer, HighlightNet can adjust **enhancement** parameters according to global features and is thus adaptive for the illumination variation. Pixel-level range mask is introduced to make HighlightNet more focused on the **enhancement** of the tracking object and regions without light sources. Furthermore, a soft truncation mechanism is built to prevent background noise from being mistaken for crucial features. Evaluations on image **enhancement** benchmarks demonstrate HighlightNet has advantages in facilitating human perception. Experiments on the public UAV**Dark**135 benchmark show that HightlightNet is more suitable for UAV tracking tasks than other SOTA **low-light** enhancers. In addition, real-world tests on a typical UAV platform verify HightlightNet's practicability and efficiency in **night**time aerial tracking-related applications. The code and demo videos are available at https://github.com/vision4robotics/HighlightNet.  
### Surrogate-assisted Multi-objective Neural Architecture Search for **Real-time** Semantic Segmentation. (arXiv:2208.06820v1 [cs.CV])
- Authors : Zhichao Lu, Ran Cheng, Shihua Huang, Haoming Zhang, Changxiao Qiu, Fan Yang
- Link : [http://arxiv.org/abs/2208.06820](http://arxiv.org/abs/2208.06820)
> ABSTRACT  :  The architectural advancements in deep neural networks have led to remarkable leap-forwards across a broad array of computer vision tasks. Instead of relying on human expertise, neural architecture search (NAS) has emerged as a promising avenue toward automating the design of architectures. While recent achievements in image classification have suggested opportunities, the promises of NAS have yet to be thoroughly assessed on more challenging tasks of semantic segmentation. The main challenges of applying NAS to semantic segmentation arise from two aspects: (i) high-resolution images to be processed; (ii) additional requirement of real-time inference speed (i.e., real-time semantic segmentation) for applications such as autonomous driving. To meet such challenges, we propose a surrogate-assisted multi-objective method in this paper. Through a series of customized prediction models, our method effectively transforms the original NAS task into an ordinary multi-objective optimization problem. Followed by a hierarchical pre-screening criterion for in-fill selection, our method progressively achieves a set of efficient architectures trading-off between segmentation accuracy and inference speed. Empirical evaluations on three benchmark datasets together with an application using Huawei Atlas 200 DK suggest that our method can identify architectures significantly outperforming existing state-of-the-art architectures designed both manually by human experts and automatically by other NAS methods.  
### Underwater Ranker: Learn Which Is Better and How to Be Better. (arXiv:2208.06857v1 [cs.CV])
- Authors : Chunle Guo, Ruiqi Wu, Xin Jin, Linghao Han, Zhi Chai, Weidong Zhang, **Chongyi Li**
- Link : [http://arxiv.org/abs/2208.06857](http://arxiv.org/abs/2208.06857)
> ABSTRACT  :  In this paper, we present a ranking-based underwater image quality assessment (UIQA) method, abbreviated as URanker. The URanker is built on the efficient conv-attentional image Transformer. In terms of underwater images, we specially devise (1) the histogram prior that embeds the color distribution of an underwater image as histogram token to attend global degradation and (2) the dynamic cross-scale correspondence to model local degradation. The final prediction depends on the class tokens from different scales, which comprehensively considers multi-scale dependencies. With the margin ranking loss, our URanker can accurately rank the order of underwater images of the same scene enhanced by different underwater image **enhancement** (UIE) algorithms according to their visual quality. To achieve that, we also contribute a dataset, URankerSet, containing sufficient results enhanced by different UIE algorithms and the corresponding perceptual rankings, to train our URanker. Apart from the good performance of URanker, we found that a simple U-shape UIE network can obtain promising performance when it is coupled with our pre-trained URanker as additional supervision. In addition, we also propose a normalization tail that can significantly improve the performance of UIE networks. Extensive experiments demonstrate the state-of-the-art performance of our method. The key designs of our method are discussed. We will release our dataset and code.  
### Global Priors Guided Modulation Network for Joint Super-Resolution and Inverse Tone-Mapping. (arXiv:2208.06885v1 [cs.CV])
- Authors : Gang He, Shaoyi Long, Li Xu, Chang Wu, Jinjia Zhou, Ming Sun, Xing Wen, Yurong Dai
- Link : [http://arxiv.org/abs/2208.06885](http://arxiv.org/abs/2208.06885)
> ABSTRACT  :  Joint super-resolution and inverse tone-mapping (SR-ITM) aims to enhance the visual quality of videos that have quality deficiencies in resolution and dynamic range. This problem arises when using 4K **high dynamic range** (**HDR**) TVs to watch a low-resolution standard dynamic range (LR SDR) video. Previous methods that rely on learning local information typically cannot do well in preserving color conformity and long-range structural similarity, resulting in unnatural color transition and texture artifacts. In order to tackle these challenges, we propose a global priors guided modulation network (GPGMNet) for joint SR-ITM. In particular, we design a global priors extraction module (GPEM) to extract color conformity prior and structural similarity prior that are beneficial for ITM and SR tasks, respectively. To further exploit the global priors and preserve spatial information, we devise multiple global priors guided spatial-wise modulation blocks (GSMBs) with a few parameters for intermediate feature modulation, in which the modulation parameters are generated by the shared global priors and the spatial features map from the spatial pyramid convolution block (SPCB). With these elaborate designs, the GPGMNet can achieve higher visual quality with lower computational complexity. Extensive experiments demonstrate that our proposed GPGMNet is superior to the state-of-the-art methods. Specifically, our proposed model exceeds the state-of-the-art by 0.64 dB in PSNR, with 69$\%$ fewer parameters and 3.1$\times$ speedup. The code will be released soon.  
### AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility. (arXiv:2208.06888v1 [cs.CV])
- Authors : Mubashir Noman, Wafa Al, Daniya Najiha, Christoph Mayer, Akshay Dudhane, Martin Danelljan, Hisham Cholakkal, Salman Khan, Luc Van, Fahad Shahbaz
- Link : [http://arxiv.org/abs/2208.06888](http://arxiv.org/abs/2208.06888)
> ABSTRACT  :  One of the key factors behind the recent success in visual tracking is the availability of dedicated benchmarks. While being greatly benefiting to the tracking research, existing benchmarks do not pose the same difficulty as before with recent trackers achieving higher performance mainly due to (i) the introduction of more sophisticated transformers-based methods and (ii) the lack of diverse scenarios with adverse visibility such as, severe weather conditions, camouflage and imaging effects.    We introduce AVisT, a dedicated benchmark for visual tracking in diverse scenarios with adverse visibility. AVisT comprises 120 challenging sequences with 80k annotated frames, spanning 18 diverse scenarios broadly grouped into five attributes with 42 object categories. The key contribution of AVisT is diverse and challenging scenarios covering severe weather conditions such as, dense fog, heavy rain and sandstorm; obstruction effects including, fire, sun glare and splashing water; adverse imaging effects such as, **low-light**; target effects including, small targets and distractor objects along with camouflage. We further benchmark 17 popular and recent trackers on AVisT with detailed analysis of their tracking performance across attributes, demonstrating a big room for improvement in performance. We believe that AVisT can greatly benefit the tracking community by complementing the existing benchmarks, in developing new creative tracking solutions in order to continue pushing the boundaries of the state-of-the-art. Our dataset along with the complete tracking performance evaluation is available at: https://github.com/visionml/pytracking  
### On a Mechanism Framework of Autoencoders. (arXiv:2208.06995v1 [cs.LG])
- Authors : Changcun Huang
- Link : [http://arxiv.org/abs/2208.06995](http://arxiv.org/abs/2208.06995)
> ABSTRACT  :  This paper proposes a theoretical framework on the mechanism of autoencoders. To the encoder part, under the main use of dimensionality reduction, we investigate its two fundamental properties: bijective maps and data disentangling. The general construction methods of an encoder that satisfies either or both of the above two properties are given. To the decoder part, as a consequence of the encoder constructions, we present a new basic principle of the solution, without using affine transforms. The generalization mechanism of autoencoders is modeled. The results of ReLU autoencoders are generalized to some non-ReLU cases, particularly for the sigmoid-unit autoencoder. Based on the theoretical framework above, we explain some experimental results of variational autoencoders, denoising autoencoders, and linear-unit autoencoders, with emphasis on the interpretation of the lower-dimensional representation of data via encoders; and the mechanism of image **restoration** through autoencoders is natural to be understood by those explanations. Compared to PCA and decision trees, the advantages of (generalized) autoencoders on dimensionality reduction and classification are demonstrated, respectively. Convolutional neural networks and randomly weighted neural networks are also interpreted by this framework.  
### UPST-**NeRF**: Universal Photorealistic Style Transfer of Neural Radiance Fields for 3D Scene. (arXiv:2208.07059v1 [cs.CV])
- Authors : Yaosen Chen, Qi Yuan, Zhiqiang Li, Yuegen Liu, Wei Wang, Chaoping Xie, Xuming Wen, Qien Yu
- Link : [http://arxiv.org/abs/2208.07059](http://arxiv.org/abs/2208.07059)
> ABSTRACT  :  3D scenes photorealistic stylization aims to generate photorealistic images from arbitrary novel views according to a given style image while ensuring consistency when rendering from different viewpoints. Some existing stylization methods with neural radiance fields can effectively predict stylized scenes by combining the features of the style image with multi-view images to train 3D scenes. However, these methods generate novel view images that contain objectionable artifacts. Besides, they cannot achieve universal photorealistic stylization for a 3D scene. Therefore, a styling image must retrain a 3D scene representation network based on a neural radiation field. We propose a novel 3D scene photorealistic style transfer framework to address these issues. It can realize photorealistic 3D scene style transfer with a 2D style image. We first pre-trained a 2D photorealistic style transfer network, which can meet the photorealistic style transfer between any given content image and style image. Then, we use voxel features to optimize a 3D scene and get the geometric representation of the scene. Finally, we jointly optimize a hyper network to realize the scene photorealistic style transfer of arbitrary style images. In the transfer stage, we use a pre-trained 2D photorealistic network to constrain the photorealistic style of different views and different style images in the 3D scene. The experimental results show that our method not only realizes the 3D photorealistic style transfer of arbitrary style images but also outperforms the existing methods in terms of visual quality and consistency. Project page:https://semchan.github.io/UPST_**NeRF**.  
### Dense Nested Attention Network for Infrared Small Target Detection. (arXiv:2106.00487v2 [cs.CV] UPDATED)
- Authors : Boyang Li, Chao Xiao, Longguang Wang, Yingqian Wang, Zaiping Lin, Miao Li, Wei An, Yulan Guo
- Link : [http://arxiv.org/abs/2106.00487](http://arxiv.org/abs/2106.00487)
> ABSTRACT  :  Single-frame infrared small target (SIRST) detection aims at separating small targets from clutter backgrounds. With the advances of deep learning, CNN-based methods have yielded promising results in generic object detection due to their powerful modeling capability. However, existing CNN-based methods cannot be directly applied for infrared small targets since pooling layers in their networks could lead to the loss of targets in deep layers. To handle this problem, we propose a dense nested attention network (DNANet) in this paper. Specifically, we design a dense nested interactive module (DNIM) to achieve progressive interaction among high-level and low-level features. With the repeated interaction in DNIM, infrared small targets in deep layers can be maintained. Based on DNIM, we further propose a cascaded channel and spatial attention module (CSAM) to adaptively enhance multi-level features. With our DNANet, contextual information of small targets can be well incorporated and fully exploited by repeated fusion and **enhancement**. Moreover, we develop an infrared small target dataset (namely, NUDT-SIRST) and propose a set of evaluation metrics to conduct comprehensive performance evaluation. Experiments on both public and our self-developed datasets demonstrate the effectiveness of our method. Compared to other state-of-the-art methods, our method achieves better performance in terms of probability of detection (Pd), false-alarm rate (Fa), and intersection of union (IoU).  
### Cross Attention-guided Dense Network for Images Fusion. (arXiv:2109.11393v2 [cs.CV] UPDATED)
- Authors : Zhengwen Shen, Jun Wang, Zaiyu Pan, Yulian Li, Jiangyu Wang
- Link : [http://arxiv.org/abs/2109.11393](http://arxiv.org/abs/2109.11393)
> ABSTRACT  :  In recent years, various applications in computer vision have achieved substantial progress based on deep learning, which has been widely used for image fusion and shown to achieve adequate performance. However, suffering from limited ability in modeling the spatial correspondence of different source images, it still remains a great challenge for existing unsupervised image fusion models to extract appropriate feature and achieves adaptive and balanced fusion. In this paper, we propose a novel cross-attention-guided image fusion network, which is a unified and unsupervised framework for multi-modal image fusion, multi-**exposure** image fusion, and multi-focus image fusion. Different from the existing self-attention module, our cross-attention module focus on modeling the cross-correlation between different source images. Using the proposed cross attention module as a core block, a densely connected cross attention-guided network is built to dynamically learn the spatial correspondence to derive better alignment of important details from different input images. Meanwhile, an auxiliary branch is also designed to model the long-range information, and a merging network is attached to finally reconstruct the fusion image. Extensive experiments have been carried out on publicly available datasets, and the results demonstrate that the proposed model outperforms the state-of-the-art quantitatively and qualitatively.  
### A Deep Learning Framework for Diffeomorphic Mapping Problems via Quasi-conformal Geometry applied to Imaging. (arXiv:2110.10580v2 [cs.CV] UPDATED)
- Authors : Qiguang Chen, Zhiwen Li, Lok Ming
- Link : [http://arxiv.org/abs/2110.10580](http://arxiv.org/abs/2110.10580)
> ABSTRACT  :  Many imaging problems can be formulated as mapping problems. A general mapping problem aims to obtain an optimal mapping that minimizes an energy functional subject to the given constraints. Existing methods to solve the mapping problems are often inefficient and can sometimes get trapped in local minima. An extra challenge arises when the optimal mapping is required to be diffeomorphic. In this work, we address the problem by proposing a deep-learning framework based on the Quasiconformal (QC) Teichmuller theories. The main strategy is to learn the Beltrami coefficient (BC) that represents a mapping as the latent feature vector in the deep neural network. The BC measures the local geometric distortion under the mapping, with which the interpretability of the deep neural network can be enhanced. Under this framework, the diffeomorphic property of the mapping can be controlled via a simple activation function within the network. The optimal mapping can also be easily regularized by integrating the BC into the loss function. A crucial advantage of the proposed framework is that once the network is successfully trained, the optimized mapping corresponding to each input data information can be obtained in **real time**. To examine the efficacy of the proposed framework, we apply the method to the diffeomorphic image registration problem. Experimental results outperform other state-of-the-art registration algorithms in both efficiency and accuracy, which demonstrate the effectiveness of our proposed framework to solve the mapping problem.  
### MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal Representation Learning. (arXiv:2111.12527v2 [cs.CV] UPDATED)
- Authors : David Junhao, Kunchang Li, Yali Wang, Yunpeng Chen, Shashwat Chandra, Yu Qiao, Luoqi Liu, Mike Zheng
- Link : [http://arxiv.org/abs/2111.12527](http://arxiv.org/abs/2111.12527)
> ABSTRACT  :  Recently, MLP-Like networks have been revived for image recognition. However, whether it is possible to build a generic MLP-Like architecture on video domain has not been explored, due to complex spatial-temporal modeling with large computation burden. To fill this gap, we present an efficient self-attention free backbone, namely MorphMLP, which flexibly leverages the concise Fully-Connected (FC) layer for video representation learning. Specifically, a MorphMLP block consists of two key layers in sequence, i.e., MorphFC_s and MorphFC_t, for spatial and temporal modeling respectively. MorphFC_s can effectively capture core semantics in each frame, by progressive token interaction along both height and width dimensions. Alternatively, MorphFC_t can adaptively learn long-term dependency over frames, by temporal token aggregation on each spatial location. With such multi-dimension and multi-scale factorization, our MorphMLP block can achieve a great accuracy-computation balance. Finally, we evaluate our MorphMLP on a number of popular video benchmarks. Compared with the recent state-of-the-art models, MorphMLP significantly reduces computation but with better accuracy, e.g., MorphMLP-S only uses 50% GFLOPs of Video**Swin**-T but achieves 0.9% top-1 improvement on Kinetics400, under ImageNet1K pretraining. MorphMLP-B only uses 43% GFLOPs of MViT-B but achieves 2.4% top-1 improvement on SSV2, even though MorphMLP-B is pretrained on ImageNet1K while MViT-B is pretrained on Kinetics400. Moreover, our method adapted to the image domain outperforms previous SOTA MLP-Like architectures. Code is available at https://github.com/MTLab/MorphMLP.  
### Multi-modal Text Recognition Networks: Interactive **Enhancement**s between Visual and Semantic Features. (arXiv:2111.15263v3 [cs.CV] UPDATED)
- Authors : Byeonghu Na, Yoonsik Kim, Sungrae Park
- Link : [http://arxiv.org/abs/2111.15263](http://arxiv.org/abs/2111.15263)
> ABSTRACT  :  Linguistic knowledge has brought great benefits to scene text recognition by providing semantics to refine character sequences. However, since linguistic knowledge has been applied individually on the output sequence, previous methods have not fully utilized the semantics to understand visual clues for text recognition. This paper introduces a novel method, called Multi-modAl Text Recognition Network (MATRN), that enables interactions between visual and semantic features for better recognition performances. Specifically, MATRN identifies visual and semantic feature pairs and encodes spatial information into semantic features. Based on the spatial encoding, visual and semantic features are enhanced by referring to related features in the other modality. Furthermore, MATRN stimulates combining semantic features into visual features by hiding visual clues related to the character in the training phase. Our experiments demonstrate that MATRN achieves state-of-the-art performances on seven benchmarks with large margins, while naive combinations of two modalities show less-effective improvements. Further ablative studies prove the effectiveness of our proposed components. Our implementation is available at https://github.com/wp03052/MATRN.  
### Information-Theoretic Odometry Learning. (arXiv:2203.05724v2 [cs.CV] UPDATED)
- Authors : Sen Zhang, Jing Zhang, Dacheng Tao
- Link : [http://arxiv.org/abs/2203.05724](http://arxiv.org/abs/2203.05724)
> ABSTRACT  :  In this paper, we propose a unified information theoretic framework for learning-motivated methods aimed at odometry estimation, a crucial component of many robotics and vision tasks such as navigation and virtual reality where relative camera poses are required in **real time**. We formulate this problem as optimizing a variational information bottleneck objective function, which eliminates pose-irrelevant information from the latent representation. The proposed framework provides an elegant tool for performance evaluation and understanding in information-theoretic language. Specifically, we bound the generalization errors of the deep information bottleneck framework and the predictability of the latent representation. These provide not only a performance guarantee but also practical guidance for model design, sample collection, and sensor selection. Furthermore, the stochastic latent representation provides a natural uncertainty measure without the needs for extra structures or computations. Experiments on two well-known odometry datasets demonstrate the effectiveness of our method.  
### Positional Label for Self-Supervised Vision Transformer. (arXiv:2206.04981v2 [cs.CV] UPDATED)
- Authors : Zhemin Zhang, Xun Gong
- Link : [http://arxiv.org/abs/2206.04981](http://arxiv.org/abs/2206.04981)
> ABSTRACT  :  Positional encoding is important for vision transformer (ViT) to capture the spatial structure of the input image. General effectiveness has been proven in ViT. In our work we propose to train ViT to recognize the positional label of patches of the input image, this apparently simple task actually yields a meaningful self-supervisory task. Based on previous work on ViT positional encoding, we propose two positional labels dedicated to 2D images including absolute position and relative position. Our positional labels can be easily plugged into various current ViT variants. It can work in two ways: (a) As an auxiliary training target for vanilla ViT (e.g., ViT-B and **Swin**-B) for better performance. (b) Combine the self-supervised ViT (e.g., MAE) to provide a more powerful self-supervised signal for semantic feature learning. Experiments demonstrate that with the proposed self-supervised methods, ViT-B and **Swin**-B gain improvements of 1.20% (top-1 Acc) and 0.74% (top-1 Acc) on ImageNet, respectively, and 6.15% and 1.14% improvement on Mini-ImageNet.  
## eess.IV
---
### Remote Photoplethysmography from Low Resolution videos: An end-to-end solution using Efficient ConvNets. (arXiv:2208.06817v1 [cs.CV])
- Authors : Bharath Ramakrishnan, Ruijia Deng
- Link : [http://arxiv.org/abs/2208.06817](http://arxiv.org/abs/2208.06817)
> ABSTRACT  :  Measurement of the cardiac pulse from facial video has become an interesting pursuit of research over the last few years. This is mainly due to the increasing importance of obtaining the heart rate of an individual in a non-invasive manner, which can be highly useful for applications in gaming and the medical industry. Another instrumental area of research over the past few years has been the advent of Deep Learning and using Deep Neural networks to enhance task performance. In this work, we propose to use efficient convolutional networks to accurately measure the heart rate of user from low resolution facial videos. Furthermore, to ensure that we are able to obtain the heart rate in **real time**, we compress the deep learning model by pruning it, thereby reducing its memory footprint. We benchmark the performance of our approach on the MAHNOB dataset and compare its performance across multiple approaches.  
### Global Priors Guided Modulation Network for Joint Super-Resolution and Inverse Tone-Mapping. (arXiv:2208.06885v1 [cs.CV])
- Authors : Gang He, Shaoyi Long, Li Xu, Chang Wu, Jinjia Zhou, Ming Sun, Xing Wen, Yurong Dai
- Link : [http://arxiv.org/abs/2208.06885](http://arxiv.org/abs/2208.06885)
> ABSTRACT  :  Joint super-resolution and inverse tone-mapping (SR-ITM) aims to enhance the visual quality of videos that have quality deficiencies in resolution and dynamic range. This problem arises when using 4K **high dynamic range** (**HDR**) TVs to watch a low-resolution standard dynamic range (LR SDR) video. Previous methods that rely on learning local information typically cannot do well in preserving color conformity and long-range structural similarity, resulting in unnatural color transition and texture artifacts. In order to tackle these challenges, we propose a global priors guided modulation network (GPGMNet) for joint SR-ITM. In particular, we design a global priors extraction module (GPEM) to extract color conformity prior and structural similarity prior that are beneficial for ITM and SR tasks, respectively. To further exploit the global priors and preserve spatial information, we devise multiple global priors guided spatial-wise modulation blocks (GSMBs) with a few parameters for intermediate feature modulation, in which the modulation parameters are generated by the shared global priors and the spatial features map from the spatial pyramid convolution block (SPCB). With these elaborate designs, the GPGMNet can achieve higher visual quality with lower computational complexity. Extensive experiments demonstrate that our proposed GPGMNet is superior to the state-of-the-art methods. Specifically, our proposed model exceeds the state-of-the-art by 0.64 dB in PSNR, with 69$\%$ fewer parameters and 3.1$\times$ speedup. The code will be released soon.  
### Ghost projection. II. Beam shaping using realistic spatially-random masks. (arXiv:2202.10572v2 [eess.IV] UPDATED)
- Authors : David Ceddia, Daniele Pelliccia, Alexander Rack
- Link : [http://arxiv.org/abs/2202.10572](http://arxiv.org/abs/2202.10572)
> ABSTRACT  :  Spatial light modulation is important for many scientific and industrial applications. The spatial light modulator and optical data projector both rely on precisely configurable optical elements to shape a light beam. Here we explore an image-projection approach which does not require a configurable beam-shaping element. We term this approach ghost projection on account of its conceptual relation to computational ghost imaging. Instead of a configurable beam shaping element, the method transversely displaces a single illuminated mask, such as a spatially-random screen, to create specified distributions of radiant **exposure**. The method has potential applicability to image projection employing a variety of radiation and matter wave fields, such as hard x rays, neutrons, muons, atomic beams and molecular beams. Building on our previous theoretical and computational studies, we here seek to understand the effects, sensitivity, and tolerance of some key experimental limitations of the method. Focusing on the case of hard x rays, we employ experimentally acquired masks to numerically study the deleterious effects of photon shot noise, inaccuracies in random-mask **exposure** time, and inaccuracies in mask positioning, as well as adapting to spatially non-uniform illumination. Understanding the influence of these factors will assist in optimizing experimental design and work towards achieving ghost projection in practice.  
## cs.LG
---
### Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models. (arXiv:2208.06677v1 [cs.LG])
- Authors : Xingyu Xie, Pan Zhou, Huan Li, Zhouchen Lin, Shuicheng Yan
- Link : [http://arxiv.org/abs/2208.06677](http://arxiv.org/abs/2208.06677)
> ABSTRACT  :  Adaptive gradient algorithms borrow the moving average idea of heavy ball acceleration to estimate accurate first- and second-order moments of gradient for accelerating convergence. However, Nesterov acceleration which converges faster than heavy ball acceleration in theory and also in many empirical cases is much less investigated under the adaptive gradient setting. In this work, we propose the ADAptive Nesterov momentum algorithm, Adan for short, to effectively speedup the training of deep neural networks. Adan first reformulates the vanilla Nesterov acceleration to develop a new Nesterov momentum estimation (NME) method, which avoids the extra computation and memory overhead of computing gradient at the extrapolation point. Then Adan adopts NME to estimate the first- and second-order moments of the gradient in adaptive gradient algorithms for convergence acceleration. Besides, we prove that Adan finds an $\epsilon$-approximate first-order stationary point within $O(\epsilon^{-3.5})$ stochastic gradient complexity on the nonconvex stochastic problems (e.g., deep learning problems), matching the best-known lower bound. Extensive experimental results show that Adan surpasses the corresponding SoTA optimizers on both vision transformers (ViTs) and CNNs, and sets new SoTAs for many popular networks, e.g., ResNet, ConvNext, ViT, **Swin**, MAE, LSTM, Transformer-XL, and BERT. More surprisingly, Adan can use half of the training cost (epochs) of SoTA optimizers to achieve higher or comparable performance on ViT and ResNet, e.t.c., and also shows great tolerance to a large range of minibatch size, e.g., from 1k to 32k. We hope Adan can contribute to the development of deep learning by reducing training cost and relieving engineering burden of trying different optimizers on various architectures. Code will be released at https://github.com/sail-sg/Adan.  
### How Does Data Freshness Affect **Real-time** Supervised Learning?. (arXiv:2208.06948v1 [cs.NI])
- Authors : Md Kamran, Chowdhury Shisher, Yin Sun
- Link : [http://arxiv.org/abs/2208.06948](http://arxiv.org/abs/2208.06948)
> ABSTRACT  :  In this paper, we analyze the impact of data freshness on real-time supervised learning, where a neural network is trained to infer a time-varying target (e.g., the position of the vehicle in front) based on features (e.g., video frames) observed at a sensing node (e.g., camera or lidar). One might expect that the performance of real-time supervised learning degrades monotonically as the feature becomes stale. Using an information-theoretic analysis, we show that this is true if the feature and target data sequence can be closely approximated as a Markov chain; it is not true if the data sequence is far from Markovian. Hence, the prediction error of real-time supervised learning is a function of the Age of Information (AoI), where the function could be non-monotonic. Several experiments are conducted to illustrate the monotonic and non-monotonic behaviors of the prediction error. To minimize the inference error in real-time, we propose a new "selection-from-buffer" model for sending the features, which is more general than the "generate-at-will" model used in earlier studies. By using Gittins and Whittle indices, low-complexity scheduling strategies are developed to minimize the inference error, where a new connection between the Gittins index theory and Age of Information (AoI) minimization is discovered. These scheduling results hold (i) for minimizing general AoI functions (monotonic or non-monotonic) and (ii) for general feature transmission time distributions. Data-driven evaluations are presented to illustrate the benefits of the proposed scheduling algorithms.  
### On a Mechanism Framework of Autoencoders. (arXiv:2208.06995v1 [cs.LG])
- Authors : Changcun Huang
- Link : [http://arxiv.org/abs/2208.06995](http://arxiv.org/abs/2208.06995)
> ABSTRACT  :  This paper proposes a theoretical framework on the mechanism of autoencoders. To the encoder part, under the main use of dimensionality reduction, we investigate its two fundamental properties: bijective maps and data disentangling. The general construction methods of an encoder that satisfies either or both of the above two properties are given. To the decoder part, as a consequence of the encoder constructions, we present a new basic principle of the solution, without using affine transforms. The generalization mechanism of autoencoders is modeled. The results of ReLU autoencoders are generalized to some non-ReLU cases, particularly for the sigmoid-unit autoencoder. Based on the theoretical framework above, we explain some experimental results of variational autoencoders, denoising autoencoders, and linear-unit autoencoders, with emphasis on the interpretation of the lower-dimensional representation of data via encoders; and the mechanism of image **restoration** through autoencoders is natural to be understood by those explanations. Compared to PCA and decision trees, the advantages of (generalized) autoencoders on dimensionality reduction and classification are demonstrated, respectively. Convolutional neural networks and randomly weighted neural networks are also interpreted by this framework.  
### Deep-Learning-Aided Path Planning and Map Construction for Expediting Indoor Mapping. (arXiv:2011.02043v2 [cs.LG] UPDATED)
- Authors : Elchanan Zwecher, Eran Iceland, Ahavatya Revivo, Ariel Barel
- Link : [http://arxiv.org/abs/2011.02043](http://arxiv.org/abs/2011.02043)
> ABSTRACT  :  The problem of autonomous indoor mapping is addressed. The goal is to minimize the time to achieve a predefined percentage of **exposure** with some desired level of certainty. The use of a pre-trained generative deep neural network, acting as a map predictor, in both the path planning and the map construction is proposed in order to expedite the mapping process. This method is examined in combination with several frontier-based path planners for two distinct floorplan datasets. Simulations are run for several configurations of the integrated map predictor, the results of which reveal that by utilizing the prediction a significant reduction in mapping time is possible. When the prediction is integrated in both path planning and map construction processes it is shown that the mapping time may in some cases be cut by over 50%.  
### Accelerating hydrodynamic simulations of urban drainage systems with physics-guided machine learning. (arXiv:2206.01538v2 [cs.LG] UPDATED)
- Authors : Rocco Palmitessa, Morten Grum, Allan Peter
- Link : [http://arxiv.org/abs/2206.01538](http://arxiv.org/abs/2206.01538)
> ABSTRACT  :  We propose and demonstrate a new approach for fast and accurate surrogate modelling of urban drainage system hydraulics based on physics-guided machine learning. The surrogates are trained against a limited set of simulation results from a hydrodynamic (HiFi) model. Our approach reduces simulation times by one to two orders of magnitude compared to a HiFi model. It is thus slower than e.g. conceptual hydrological models, but it enables simulations of water levels, flows and surcharges in all nodes and links of a drainage network and thus largely preserves the level of detail provided by HiFi models. Comparing time series simulated by the surrogate and the HiFi model, R2 values in the order of 0.9 are achieved. Surrogate training times are currently in the order of one hour. However, they can likely be reduced through the application of transfer learning and graph neural networks. Our surrogate approach will be useful for interactive workshops in initial design phases of urban drainage systems, as well as for **real time** applications. In addition, our model formulation is generic and future research should investigate its application for simulating other water systems.  
## cs.AI
---
### Self-supervised Matting-specific Portrait **Enhancement** and Generation. (arXiv:2208.06601v1 [cs.CV])
- Authors : Yangyang Xu, Zeyang Zhou, Shengfeng He
- Link : [http://arxiv.org/abs/2208.06601](http://arxiv.org/abs/2208.06601)
> ABSTRACT  :  We resolve the ill-posed alpha matting problem from a completely different perspective. Given an input portrait image, instead of estimating the corresponding alpha matte, we focus on the other end, to subtly enhance this input so that the alpha matte can be easily estimated by any existing matting models. This is accomplished by exploring the latent space of GAN models. It is demonstrated that interpretable directions can be found in the latent space and they correspond to semantic image transformations. We further explore this property in alpha matting. Particularly, we invert an input portrait into the latent code of StyleGAN, and our aim is to discover whether there is an enhanced version in the latent space which is more compatible with a reference matting model. We optimize multi-scale latent vectors in the latent spaces under four tailored losses, ensuring matting-specificity and subtle modifications on the portrait. We demonstrate that the proposed method can refine real portrait images for arbitrary matting models, boosting the performance of automatic alpha matting by a large margin. In addition, we leverage the generative property of StyleGAN, and propose to generate enhanced portrait data which can be treated as the pseudo GT. It addresses the problem of expensive alpha matte annotation, further augmenting the matting performance of existing models. Code is available at~\url{https://github.com/cnnlstm/StyleGAN_Matting}.  
### **HDR**-Plenoxels: Self-Calibrating **High Dynamic Range** Radiance Fields. (arXiv:2208.06787v1 [cs.CV])
- Authors : Kim Jun, Kim Yu, Moon Ye, Hyun Oh
- Link : [http://arxiv.org/abs/2208.06787](http://arxiv.org/abs/2208.06787)
> ABSTRACT  :  We propose **high dynamic range** radiance (**HDR**) fields, **HDR**-Plenoxels, that learn a plenoptic function of 3D **HDR** radiance fields, geometry information, and varying camera settings inherent in 2D low dynamic range (LDR) images. Our voxel-based volume rendering pipeline reconstructs **HDR** radiance fields with only multi-view LDR images taken from varying camera settings in an end-to-end manner and has a fast convergence speed. To deal with various cameras in real-world scenarios, we introduce a tone mapping module that models the digital in-camera imaging pipeline (ISP) and disentangles radiometric settings. Our tone mapping module allows us to render by controlling the radiometric settings of each novel view. Finally, we build a multi-view dataset with varying camera conditions, which fits our problem setting. Our experiments show that **HDR**-Plenoxels can express detail and high-quality **HDR** novel views from only LDR images with various cameras.  
### **Real-time** Caller Intent Detection In Human-Human Customer Support Spoken Conversations. (arXiv:2208.06802v1 [cs.AI])
- Authors : Mrinal Rawat, Victor Barres
- Link : [http://arxiv.org/abs/2208.06802](http://arxiv.org/abs/2208.06802)
> ABSTRACT  :  Agent assistance during human-human customer support spoken interactions requires triggering workflows based on the caller's intent (reason for call). Timeliness of prediction is essential for a good user experience. The goal is for a system to detect the caller's intent at the time the agent would have been able to detect it (Intent Boundary). Some approaches focus on predicting the output offline, i.e. once the full spoken input (e.g. the whole conversational turn) has been processed by the ASR system. This introduces an undesirable latency in the prediction each time the intent could have been detected earlier in the turn. Recent work on voice assistants has used incremental real-time predictions at a word-by-word level to detect intent before the end of a command. Human-directed and machine-directed speech however have very different characteristics. In this work, we propose to apply a method developed in the context of voice-assistant to the problem of online **real time** caller's intent detection in human-human spoken interactions. We use a dual architecture in which two LSTMs are jointly trained: one predicting the Intent Boundary (IB) and then other predicting the intent class at the IB. We conduct our experiments on our private dataset comprising transcripts of human-human telephone conversations from the telecom customer support domain. We report results analyzing both the accuracy of our system as well as the impact of different architectures on the trade off between overall accuracy and prediction latency.  
### Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task. (arXiv:2208.07097v1 [cs.CL])
- Authors : Radostin Cholakov, Todor Kolev
- Link : [http://arxiv.org/abs/2208.07097](http://arxiv.org/abs/2208.07097)
> ABSTRACT  :  The adoption of pre-trained language models in task-oriented dialogue systems has resulted in significant **enhancement**s of their text generation abilities. However, these architectures are slow to use because of the large number of trainable parameters and can sometimes fail to generate diverse responses. To address these limitations, we propose two models with auxiliary tasks for response selection - (1) distinguishing distractors from ground truth responses and (2) distinguishing synthetic responses from ground truth labels. They achieve state-of-the-art results on the MultiWOZ 2.1 dataset with combined scores of 107.5 and 108.3 and outperform a baseline with three times more parameters. We publish reproducible code and checkpoints and discuss the effects of applying auxiliary tasks to T5-based architectures.  
# Paper List
---
## cs.CV
---
**163** new papers in cs.CV:-) 
1. SFF-DA: Sptialtemporal Feature Fusion for Detecting Anxiety Nonintrusively. (arXiv:2208.06411v1 [cs.CV])
2. Contrastive Learning for Object Detection. (arXiv:2208.06412v1 [cs.CV])
3. Generating Pixel Art Character Sprites using GANs. (arXiv:2208.06413v1 [cs.GR])
4. Uni6Dv2: Noise Elimination for 6D Pose Estimation. (arXiv:2208.06416v1 [cs.CV])
5. CCRL: Contrastive Cell Representation Learning. (arXiv:2208.06445v1 [cs.CV])
6. When CNN Meet with ViT: Towards Semi-Supervised Learning for Multi-Class Medical Image Semantic Segmentation. (arXiv:2208.06449v1 [eess.IV])
7. Real-Time Accident Detection in Traffic Surveillance Using Deep Learning. (arXiv:2208.06461v1 [cs.CV])
8. View Sub-sampling and Reconstruction for Efficient Light Field Compression. (arXiv:2208.06464v1 [cs.CV])
9. Guided Evolutionary Neural Architecture Search With Efficient Performance Estimation. (arXiv:2208.06475v1 [cs.NE])
10. Occlusion-Robust Multi-Sensory Posture Estimation in Physical Human-Robot Interaction. (arXiv:2208.06494v1 [cs.RO])
11. Continual Unsupervised Domain Adaptation for Semantic Segmentation using a Class-Specific Transfer. (arXiv:2208.06507v1 [cs.CV])
12. CycleGAN with three different unpaired datasets. (arXiv:2208.06526v1 [cs.CV])
13. Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons. (arXiv:2208.06537v1 [cs.LG])
14. MaskBlock: Transferable Adversarial Examples with Bayes Approach. (arXiv:2208.06538v1 [cs.LG])
15. ExpansionNet v2: Block Static Expansion in fast end to end training for Image Captioning. (arXiv:2208.06551v1 [cs.CV])
16. Memory Efficient Temporal & Visual Graph Model for Unsupervised Video Domain Adaptation. (arXiv:2208.06554v1 [cs.CV])
17. Finding Point with Image: An End-to-End Benchmark for Vision-based UAV Localization. (arXiv:2208.06561v1 [cs.CV])
18. Enhanced Vehicle Re-identification for ITS: A Feature Fusion approach using Deep Learning. (arXiv:2208.06579v1 [cs.CV])
19. Confidence Matters: Inspecting Backdoors in Deep Neural Networks via Distribution Transfer. (arXiv:2208.06592v1 [cs.CR])
20. Self-supervised Matting-specific Portrait **Enhancement** and Generation. (arXiv:2208.06601v1 [cs.CV])
21. Combating Label Distribution Shift for Active Domain Adaptation. (arXiv:2208.06604v1 [cs.LG])
22. A Study of Demographic Bias in CNN-based Brain MR Segmentation. (arXiv:2208.06613v1 [cs.CV])
23. A Unified Two-Stage Group Semantics Propagation and Contrastive Learning Network for Co-Saliency Detection. (arXiv:2208.06615v1 [cs.CV])
24. Online Refinement of a Scene Recognition Model for Mobile Robots by Observing Human's Interaction with Environments. (arXiv:2208.06636v1 [cs.RO])
25. Medical image analysis based on transformer: A Review. (arXiv:2208.06643v1 [eess.IV])
26. ULDGNN: A Fragmented UI Layer Detector Based on Graph Neural Networks. (arXiv:2208.06658v1 [cs.CV])
27. Entropy Induced Pruning Framework for Convolutional Neural Networks. (arXiv:2208.06660v1 [cs.CV])
28. SSP-Pose: Symmetry-Aware Shape Prior Deformation for Direct Category-Level Object Pose Estimation. (arXiv:2208.06661v1 [cs.CV])
29. Self-Contained Entity Discovery from Captioned Videos. (arXiv:2208.06662v1 [cs.CV])
30. Bidirectional Feature Globalization for Few-shot Semantic Segmentation of 3D Point Cloud Scenes. (arXiv:2208.06671v1 [cs.CV])
31. DS-MVSNet: Unsupervised Multi-view Stereo via Depth Synthesis. (arXiv:2208.06674v1 [cs.CV])
32. A new way of video compression via forward-referencing using deep learning. (arXiv:2208.06678v1 [cs.CV])
33. Modeling Biological Face Recognition with Deep Convolutional Neural Networks. (arXiv:2208.06681v1 [cs.CV])
34. UAV-CROWD: Violent and non-violent crowd activity simulator from the perspective of UAV. (arXiv:2208.06702v1 [cs.CV])
35. Simulating Personal Food Consumption Patterns using a Modified Markov Chain. (arXiv:2208.06709v1 [cs.CV])
36. Progressive Multi-scale Light Field Networks. (arXiv:2208.06710v1 [cs.CV])
37. Machine Learning Based Radiomics for Glial Tumor Classification and Comparison with Volumetric Analysis. (arXiv:2208.06739v1 [eess.IV])
38. Predicting skull fractures via CNN with classification algorithms. (arXiv:2208.06756v1 [cs.CV])
39. MAFNet: A Multi-Attention Fusion Network for RGB-T Crowd Counting. (arXiv:2208.06761v1 [cs.CV])
40. Flow-Guided Transformer for Video Inpainting. (arXiv:2208.06768v1 [cs.CV])
41. TL;DW? Summarizing Instructional Videos with Task Relevance & Cross-Modal Saliency. (arXiv:2208.06773v1 [cs.CV])
42. **HDR**-Plenoxels: Self-Calibrating **High Dynamic Range** Radiance Fields. (arXiv:2208.06787v1 [cs.CV])
43. Light Weight Character and Shape Recognition for Autonomous Drones. (arXiv:2208.06804v1 [cs.CV])
44. Semi-Supervised Video Inpainting with Cycle Consistency Constraints. (arXiv:2208.06807v1 [cs.CV])
45. Multi-Attribute Open Set Recognition. (arXiv:2208.06809v1 [cs.CV])
46. Contrastive Learning for Joint Normal Estimation and Point Cloud Filtering. (arXiv:2208.06811v1 [cs.CV])
47. Remote Photoplethysmography from Low Resolution videos: An end-to-end solution using Efficient ConvNets. (arXiv:2208.06817v1 [cs.CV])
48. HighlightNet: Highlighting **Low-Light** Potential Features for Real-Time UAV Tracking. (arXiv:2208.06818v1 [cs.RO])
49. Surrogate-assisted Multi-objective Neural Architecture Search for **Real-time** Semantic Segmentation. (arXiv:2208.06820v1 [cs.CV])
50. Fast Learning Radiance Fields by Shooting Much Fewer Rays. (arXiv:2208.06821v1 [cs.CV])
51. BDSL 49: A Comprehensive Dataset of Bangla Sign Language. (arXiv:2208.06827v1 [cs.CV])
52. Shuffle Instances-based Vision Transformer for Pancreatic Cancer ROSE Image Classification. (arXiv:2208.06833v1 [eess.IV])
53. Underwater Ranker: Learn Which Is Better and How to Be Better. (arXiv:2208.06857v1 [cs.CV])
54. HyP$^2$ Loss: Beyond Hypersphere Metric Space for Multi-label Image Retrieval. (arXiv:2208.06866v1 [cs.CV])
55. SketchSampler: Sketch-based 3D Reconstruction via View-dependent Depth Sampling. (arXiv:2208.06880v1 [cs.CV])
56. CoShNet: A Hybird Complex Valued Neural Network using Shearlets. (arXiv:2208.06882v1 [cs.CV])
57. Global Priors Guided Modulation Network for Joint Super-Resolution and Inverse Tone-Mapping. (arXiv:2208.06885v1 [cs.CV])
58. AVisT: A Benchmark for Visual Object Tracking in Adverse Visibility. (arXiv:2208.06888v1 [cs.CV])
59. The SVD of Convolutional Weights: A CNN Interpretability Framework. (arXiv:2208.06894v1 [cs.CV])
60. MTCSNN: Multi-task Clinical Siamese Neural Network for Diabetic Retinopathy Severity Prediction. (arXiv:2208.06917v1 [cs.CV])
61. Gradient Mask: Lateral Inhibition Mechanism Improves Performance in Artificial Neural Networks. (arXiv:2208.06918v1 [cs.CV])
62. Visual Localization via Few-Shot Scene Region Classification. (arXiv:2208.06933v1 [cs.CV])
63. InvisibiliTee: Angle-agnostic Cloaking from Person-Tracking Systems with a Tee. (arXiv:2208.06962v1 [cs.CV])
64. STAR-GNN: Spatial-Temporal Video Representation for Content-based Retrieval. (arXiv:2208.06966v1 [cs.CV])
65. Learning Semantic Correspondence with Sparse Annotations. (arXiv:2208.06974v1 [cs.CV])
66. Faster Attention Is What You Need: A Fast Self-Attention Neural Network Backbone Architecture for the Edge via Double-Condensing Attention Condensers. (arXiv:2208.06980v1 [cs.CV])
67. A Multi-objective Memetic Algorithm for Auto Adversarial Attack Optimization Design. (arXiv:2208.06984v1 [cs.CV])
68. Deepfake Detection using ImageNet models and Temporal Images of 468 Facial Landmarks. (arXiv:2208.06990v1 [cs.CV])
69. On a Mechanism Framework of Autoencoders. (arXiv:2208.06995v1 [cs.LG])
70. HoW-3D: Holistic 3D Wireframe Perception from a Single Image. (arXiv:2208.06999v1 [cs.CV])
71. Adaptive Joint Optimization for 3D Reconstruction with Differentiable Rendering. (arXiv:2208.07003v1 [cs.CV])
72. Automatic Landmark Detection and Registration of Brain Cortical Surfaces via Quasi-Conformal Geometry and Convolutional Neural Networks. (arXiv:2208.07010v1 [cs.CV])
73. Automatic Controlling Fish Feeding Machine using Feature Extraction of Nutriment and Ripple Behavior. (arXiv:2208.07011v1 [cs.CV])
74. Pyramidal Predictive Network: A Model for Visual-frame Prediction Based on Predictive Coding Theory. (arXiv:2208.07021v1 [cs.CV])
75. Memory-Driven Text-to-Image Generation. (arXiv:2208.07022v1 [cs.CV])
76. Hierarchical Attention Network for Few-Shot Object Detection via Meta-Contrastive Learning. (arXiv:2208.07039v1 [cs.CV])
77. Self-Supervised Vision Transformers for Malware Detection. (arXiv:2208.07049v1 [cs.CR])
78. UPST-**NeRF**: Universal Photorealistic Style Transfer of Neural Radiance Fields for 3D Scene. (arXiv:2208.07059v1 [cs.CV])
79. A Vision Transformer-Based Approach to Bearing Fault Classification via Vibration Signals. (arXiv:2208.07070v1 [cs.CV])
80. Crowd Counting on Heavily Compressed Images with Curriculum Pre-Training. (arXiv:2208.07075v1 [cs.CV])
81. Enhancing Deep Learning-based 3-lead ECG Classification with Heartbeat Counting and Demographic Data Integration. (arXiv:2208.07088v1 [cs.CV])
82. Global Consistent Point Cloud Registration Based on Lie-algebraic Cohomology. (arXiv:2208.07103v1 [cs.CV])
83. CAME: Context-aware Mixture-of-Experts for Unbiased Scene Graph Generation. (arXiv:2208.07109v1 [cs.CV])
84. A Unified Image Preprocessing Framework For Image Compression. (arXiv:2208.07110v1 [cs.CV])
85. An Empirical Study of Pseudo-Labeling for Image-based 3D Object Detection. (arXiv:2208.07137v1 [cs.CV])
86. Perspective Reconstruction of Human Faces by Joint Mesh and Landmark Regression. (arXiv:2208.07142v1 [cs.CV])
87. Where is VALDO? VAscular Lesions Detection and segmentatiOn challenge at MICCAI 2021. (arXiv:2208.07167v1 [cs.CV])
88. Man-in-the-Middle Attack against Object Detection Systems. (arXiv:2208.07174v1 [cs.RO])
89. One-shot Generative Prior Learned from Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v1 [cs.CV])
90. Determining HEDP Foams' Quality with Multi-View Deep Learning Classification. (arXiv:2208.07196v1 [cs.CV])
91. Extraction of Pulmonary Airway in CT Scans Using Deep Fully Convolutional Networks. (arXiv:2208.07202v1 [eess.IV])
92. USB: A Unified Semi-supervised Learning Benchmark. (arXiv:2208.07204v1 [cs.LG])
93. Class-attention Video Transformer for Engagement Intensity Prediction. (arXiv:2208.07216v1 [cs.CV])
94. PatchDropout: Economizing Vision Transformers Using Patch Dropout. (arXiv:2208.07220v1 [cs.CV])
95. RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v5 [cs.LG] UPDATED)
96. Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching. (arXiv:2012.08950v4 [cs.CV] UPDATED)
97. PSCC-Net: Progressive Spatio-Channel Correlation Network for Image Manipulation Detection and Localization. (arXiv:2103.10596v2 [cs.CV] UPDATED)
98. Comprehensive Multi-Modal Interactions for Referring Image Segmentation. (arXiv:2104.10412v4 [cs.CV] UPDATED)
99. Egocentric Activity Recognition and Localization on a 3D Map. (arXiv:2105.09544v3 [cs.CV] UPDATED)
100. DSR: Direct Simultaneous Registration for Multiple 3D Images. (arXiv:2105.10087v2 [cs.CV] UPDATED)
101. Dense Nested Attention Network for Infrared Small Target Detection. (arXiv:2106.00487v2 [cs.CV] UPDATED)
102. Dynamic Convolution for 3D Point Cloud Instance Segmentation. (arXiv:2107.08392v2 [cs.CV] UPDATED)
103. Poison Ink: Robust and Invisible Backdoor Attack. (arXiv:2108.02488v3 [cs.CR] UPDATED)
104. Cross Attention-guided Dense Network for Images Fusion. (arXiv:2109.11393v2 [cs.CV] UPDATED)
105. Unsupervised Cross-Modality Domain Adaptation for Segmenting Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble. (arXiv:2109.12169v3 [eess.IV] UPDATED)
106. Estimating Image Depth in the Comics Domain. (arXiv:2110.03575v2 [cs.CV] UPDATED)
107. A Deep Learning Framework for Diffeomorphic Mapping Problems via Quasi-conformal Geometry applied to Imaging. (arXiv:2110.10580v2 [cs.CV] UPDATED)
108. Information Extraction from Visually Rich Documents with Font Style Embeddings. (arXiv:2111.04045v2 [cs.CL] UPDATED)
109. Pruning Self-attentions into Convolutional Layers in Single Path. (arXiv:2111.11802v3 [cs.CV] UPDATED)
110. MorphMLP: An Efficient MLP-Like Backbone for Spatial-Temporal Representation Learning. (arXiv:2111.12527v2 [cs.CV] UPDATED)
111. Multi-modal Text Recognition Networks: Interactive **Enhancement**s between Visual and Semantic Features. (arXiv:2111.15263v3 [cs.CV] UPDATED)
112. Recovery of Continuous 3D Refractive Index Maps from Discrete Intensity-Only Measurements using Neural Fields. (arXiv:2112.00002v2 [eess.IV] UPDATED)
113. Self-Supervised Transformers for fMRI representation. (arXiv:2112.05761v2 [eess.IV] UPDATED)
114. Volley Revolver: A Novel Matrix-Encoding Method for Privacy-Preserving Neural Networks (Inference). (arXiv:2201.12577v2 [cs.CR] UPDATED)
115. A Dataset for Interactive Vision-Language Navigation with Unknown Command Feasibility. (arXiv:2202.02312v3 [cs.CL] UPDATED)
116. Do Inpainting Yourself: Generative Facial Inpainting Guided by Exemplars. (arXiv:2202.06358v3 [cs.CV] UPDATED)
117. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v3 [cs.CV] UPDATED)
118. Multi-image Super-resolution via Quality Map Associated Temporal Attention Network. (arXiv:2202.13124v2 [eess.IV] UPDATED)
119. Adversarial Texture for Fooling Person Detectors in the Physical World. (arXiv:2203.03373v4 [cs.CV] UPDATED)
120. Information-Theoretic Odometry Learning. (arXiv:2203.05724v2 [cs.CV] UPDATED)
121. LiDAR Distillation: Bridging the Beam-Induced Domain Gap for 3D Object Detection. (arXiv:2203.14956v2 [cs.CV] UPDATED)
122. Agreement or Disagreement in Noise-tolerant Mutual Learning?. (arXiv:2203.15317v2 [cs.CV] UPDATED)
123. Inductive Biases for Object-Centric Representations in the Presence of Complex Textures. (arXiv:2204.08479v3 [cs.CV] UPDATED)
124. Channel Pruned YOLOv5-based Deep Learning Approach for Rapid and Accurate Outdoor Obstacles Detection. (arXiv:2204.13699v2 [cs.CV] UPDATED)
125. Elucidating Meta-Structures of Noisy Labels in Semantic Segmentation by Deep Neural Networks. (arXiv:2205.00160v2 [cs.CV] UPDATED)
126. Deep Multi-Scale U-Net Architecture and Label-Noise Robust Training Strategies for Histopathological Image Segmentation. (arXiv:2205.01777v2 [eess.IV] UPDATED)
127. Point is a Vector: A Feature Representation in Point Analysis. (arXiv:2205.10528v2 [cs.CV] UPDATED)
128. Multi-scale frequency separation network for image deblurring. (arXiv:2206.00798v2 [cs.CV] UPDATED)
129. Positional Label for Self-Supervised Vision Transformer. (arXiv:2206.04981v2 [cs.CV] UPDATED)
130. Diffusion Models for Video Prediction and Infilling. (arXiv:2206.07696v2 [cs.CV] UPDATED)
131. Exploiting Transformation Invariance and Equivariance for Self-supervised Sound Localisation. (arXiv:2206.12772v2 [cs.CV] UPDATED)
132. A View Independent Classification Framework for Yoga Postures. (arXiv:2206.13577v2 [cs.CV] UPDATED)
133. LViT: Language meets Vision Transformer in Medical Image Segmentation. (arXiv:2206.14718v2 [cs.CV] UPDATED)
134. DUET: Cross-modal Semantic Grounding for Contrastive Zero-shot Learning. (arXiv:2207.01328v2 [cs.CV] UPDATED)
135. PIC 4th Challenge: Semantic-Assisted Multi-Feature Encoding and Multi-Head Decoding for Dense Video Captioning. (arXiv:2207.02583v3 [cs.CV] UPDATED)
136. Semi-supervised Human Pose Estimation in Art-historical Images. (arXiv:2207.02976v3 [cs.CV] UPDATED)
137. ExpansionNet: exploring the sequence length bottleneck in the Transformer for Image Captioning. (arXiv:2207.03327v3 [cs.CV] UPDATED)
138. Text to Image Synthesis using Stacked Conditional Variational Autoencoders and Conditional Generative Adversarial Networks. (arXiv:2207.03332v2 [cs.CV] UPDATED)
139. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v3 [cs.CV] UPDATED)
140. Collaborative Neural Rendering using Anime Character Sheets. (arXiv:2207.05378v2 [cs.CV] UPDATED)
141. Learning from Label Relationships in Human Affect. (arXiv:2207.05577v2 [cs.CV] UPDATED)
142. Tackling Background Distraction in Video Object Segmentation. (arXiv:2207.06953v3 [cs.CV] UPDATED)
143. MDM: Multiple Dynamic Masks for Visual Explanation of Neural Networks. (arXiv:2207.08046v5 [cs.CV] UPDATED)
144. Source-free Unsupervised Domain Adaptation for Blind Image Quality Assessment. (arXiv:2207.08124v2 [cs.CV] UPDATED)
145. METER-ML: A Multi-Sensor Earth Observation Benchmark for Automated Methane Source Mapping. (arXiv:2207.11166v2 [cs.CV] UPDATED)
146. Combining Hybrid Architecture and Pseudo-label for Semi-supervised Abdominal Organ Segmentation. (arXiv:2207.11512v2 [cs.CV] UPDATED)
147. Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering. (arXiv:2207.12647v2 [cs.CV] UPDATED)
148. NewsStories: Illustrating articles with visual summaries. (arXiv:2207.13061v2 [cs.CV] UPDATED)
149. Boosting Point-BERT by Multi-choice Tokens. (arXiv:2207.13226v2 [cs.CV] UPDATED)
150. Generative Steganography Network. (arXiv:2207.13867v3 [cs.CV] UPDATED)
151. Learning with Limited Annotations: A Survey on Deep Semi-Supervised Learning for Medical Image Segmentation. (arXiv:2207.14191v2 [cs.CV] UPDATED)
152. Pro-tuning: Unified Prompt Tuning for Vision Tasks. (arXiv:2207.14381v2 [cs.CV] UPDATED)
153. TAG: Boosting Text-VQA via Text-aware Visual Question-answer Generation. (arXiv:2208.01813v2 [cs.CV] UPDATED)
154. ACSGRegNet: A Deep Learning-based Framework for Unsupervised Joint Affine and Diffeomorphic Registration of Lumbar Spine CT via Cross- and Self-Attention Fusion. (arXiv:2208.02642v2 [cs.CV] UPDATED)
155. OCFR 2022: Competition on Occluded Face Recognition From Synthetically Generated Structure-Aware Occlusions. (arXiv:2208.02760v2 [cs.CV] UPDATED)
156. Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions. (arXiv:2208.03392v3 [cs.LG] UPDATED)
157. Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer. (arXiv:2208.03767v2 [cs.CV] UPDATED)
158. Distinctive Image Captioning via CLIP Guided Group Optimization. (arXiv:2208.04254v4 [cs.CV] UPDATED)
159. U-Net vs Transformer: Is U-Net Outdated in Medical Image Registration?. (arXiv:2208.04939v2 [eess.IV] UPDATED)
160. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v2 [eess.IV] UPDATED)
161. MILAN: Masked Image Pretraining on Language Assisted Representation. (arXiv:2208.06049v2 [cs.CV] UPDATED)
162. A Case for Rejection in Low Resource ML Deployment. (arXiv:2208.06359v2 [cs.LG] UPDATED)
163. RangeUDF: Semantic Surface Reconstruction from 3D Point Clouds. (arXiv:2204.09138v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**30** new papers in eess.IV:-) 
1. SFF-DA: Sptialtemporal Feature Fusion for Detecting Anxiety Nonintrusively. (arXiv:2208.06411v1 [cs.CV])
2. When CNN Meet with ViT: Towards Semi-Supervised Learning for Multi-Class Medical Image Semantic Segmentation. (arXiv:2208.06449v1 [eess.IV])
3. Medical image analysis based on transformer: A Review. (arXiv:2208.06643v1 [eess.IV])
4. Machine Learning Based Radiomics for Glial Tumor Classification and Comparison with Volumetric Analysis. (arXiv:2208.06739v1 [eess.IV])
5. A reconstruction method for binary limited-data tomography using a dictionary-based sparse shape recovery. (arXiv:2208.06766v1 [eess.IV])
6. Remote Photoplethysmography from Low Resolution videos: An end-to-end solution using Efficient ConvNets. (arXiv:2208.06817v1 [cs.CV])
7. Shuffle Instances-based Vision Transformer for Pancreatic Cancer ROSE Image Classification. (arXiv:2208.06833v1 [eess.IV])
8. Global Priors Guided Modulation Network for Joint Super-Resolution and Inverse Tone-Mapping. (arXiv:2208.06885v1 [cs.CV])
9. Faster Attention Is What You Need: A Fast Self-Attention Neural Network Backbone Architecture for the Edge via Double-Condensing Attention Condensers. (arXiv:2208.06980v1 [cs.CV])
10. One-shot Generative Prior Learned from Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v1 [cs.CV])
11. Extraction of Pulmonary Airway in CT Scans Using Deep Fully Convolutional Networks. (arXiv:2208.07202v1 [eess.IV])
12. Task Oriented Video Coding: A Survey. (arXiv:2208.07313v1 [eess.IV])
13. Learn2Trust: A video and streamlit-based educational programme for AI-based medical image analysis targeted towards medical students. (arXiv:2208.07314v1 [eess.IV])
14. Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v3 [physics.med-ph] UPDATED)
15. DSR: Direct Simultaneous Registration for Multiple 3D Images. (arXiv:2105.10087v2 [cs.CV] UPDATED)
16. Volume of hyperintense inflammation (VHI): a deep learning-enabled quantitative imaging biomarker of inflammation load in spondyloarthritis. (arXiv:2106.11343v3 [eess.IV] UPDATED)
17. Unsupervised Cross-Modality Domain Adaptation for Segmenting Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble. (arXiv:2109.12169v3 [eess.IV] UPDATED)
18. Recovery of Continuous 3D Refractive Index Maps from Discrete Intensity-Only Measurements using Neural Fields. (arXiv:2112.00002v2 [eess.IV] UPDATED)
19. Self-Supervised Transformers for fMRI representation. (arXiv:2112.05761v2 [eess.IV] UPDATED)
20. Ghost projection. II. Beam shaping using realistic spatially-random masks. (arXiv:2202.10572v2 [eess.IV] UPDATED)
21. Multi-image Super-resolution via Quality Map Associated Temporal Attention Network. (arXiv:2202.13124v2 [eess.IV] UPDATED)
22. Learning Nonlocal Sparse and Low-Rank Models for Image Compressive Sensing. (arXiv:2203.09656v4 [eess.IV] UPDATED)
23. Deep learning-augmented Computational Miniature Mesoscope. (arXiv:2205.00123v3 [physics.optics] UPDATED)
24. Deep Multi-Scale U-Net Architecture and Label-Noise Robust Training Strategies for Histopathological Image Segmentation. (arXiv:2205.01777v2 [eess.IV] UPDATED)
25. Text to Image Synthesis using Stacked Conditional Variational Autoencoders and Conditional Generative Adversarial Networks. (arXiv:2207.03332v2 [cs.CV] UPDATED)
26. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v3 [cs.CV] UPDATED)
27. Source-free Unsupervised Domain Adaptation for Blind Image Quality Assessment. (arXiv:2207.08124v2 [cs.CV] UPDATED)
28. Optimization of Artificial Neural Networks models applied to the identification of images of asteroids' resonant arguments. (arXiv:2207.14181v2 [astro-ph.EP] UPDATED)
29. U-Net vs Transformer: Is U-Net Outdated in Medical Image Registration?. (arXiv:2208.04939v2 [eess.IV] UPDATED)
30. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v2 [eess.IV] UPDATED)
## cs.LG
---
**202** new papers in cs.LG:-) 
1. Optimistic No-regret Algorithms for Discrete Caching. (arXiv:2208.06414v1 [cs.LG])
2. RandomSCM: interpretable ensembles of sparse classifiers tailored for omics data. (arXiv:2208.06436v1 [cs.LG])
3. Smart caching in a Data Lake for High Energy Physics analysis. (arXiv:2208.06437v1 [cs.DC])
4. Topological Data Analysis of Neural Network Layer Representations. (arXiv:2208.06438v1 [cs.LG])
5. RLang: A Declarative Language for Expression Prior Knowledge for Reinforcement Learning. (arXiv:2208.06448v1 [cs.AI])
6. LM-CORE: Language Models with Contextually Relevant External Knowledge. (arXiv:2208.06458v1 [cs.CL])
7. Guided Evolutionary Neural Architecture Search With Efficient Performance Estimation. (arXiv:2208.06475v1 [cs.NE])
8. Orthogonal Gated Recurrent Unit with Neumann-Cayley Transformation. (arXiv:2208.06496v1 [cs.LG])
9. Forecasting Question Answering over Temporal Knowledge Graphs. (arXiv:2208.06501v1 [cs.AI])
10. Siamese neural networks for a generalized, quantitative comparison of complex model outputs. (arXiv:2208.06530v1 [cs.LG])
11. Three-Player Game Training Dynamics. (arXiv:2208.06531v1 [cs.LG])
12. SNGuess: A method for the selection of young extragalactic transients. (arXiv:2208.06534v1 [astro-ph.IM])
13. Double Auctions with Two-sided Bandit Feedback. (arXiv:2208.06536v1 [cs.LG])
14. Defense against Backdoor Attacks via Identifying and Purifying Bad Neurons. (arXiv:2208.06537v1 [cs.LG])
15. MaskBlock: Transferable Adversarial Examples with Bayes Approach. (arXiv:2208.06538v1 [cs.LG])
16. A Novel Regularization Approach to Fair ML. (arXiv:2208.06557v1 [cs.LG])
17. On the Limitations of Continual Learning for Malware Classification. (arXiv:2208.06568v1 [cs.CR])
18. Demo: RhythmEdge: Enabling Contactless Heart Rate Estimation on the Edge. (arXiv:2208.06572v1 [cs.LG])
19. GEDI: A Graph-based End-to-end Data Imputation Framework. (arXiv:2208.06573v1 [cs.LG])
20. An Adam-adjusting-antennae BAS Algorithm for Refining Latent Factors. (arXiv:2208.06603v1 [cs.LG])
21. Combating Label Distribution Shift for Active Domain Adaptation. (arXiv:2208.06604v1 [cs.LG])
22. Incoporating Weighted Board Learning System for Accurate Occupational Pneumoconiosis Staging. (arXiv:2208.06607v1 [cs.LG])
23. Self-supervised Contrastive Representation Learning for Semi-supervised Time-Series Classification. (arXiv:2208.06616v1 [cs.LG])
24. Riemannian accelerated gradient methods via extrapolation. (arXiv:2208.06619v1 [math.OC])
25. Opinion Market Model: Stemming Far-Right Opinion Spread using Positive Interventions. (arXiv:2208.06620v1 [cs.SI])
26. Modeling Network-level Traffic Flow Transitions on Sparse Data. (arXiv:2208.06646v1 [cs.LG])
27. Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness. (arXiv:2208.06648v1 [cs.AI])
28. Revisiting Adversarial Attacks on Graph Neural Networks for Graph Classification. (arXiv:2208.06651v1 [cs.SI])
29. Cloud-Based Real-Time Molecular Screening Platform with MolFormer. (arXiv:2208.06665v1 [cs.LG])
30. May the force be with you. (arXiv:2208.06676v1 [cs.LG])
31. Adan: Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models. (arXiv:2208.06677v1 [cs.LG])
32. Locating disparities in machine learning. (arXiv:2208.06680v1 [cs.LG])
33. BinBert: Binary Code Understanding with a Fine-tunable and Execution-aware Transformer. (arXiv:2208.06692v1 [cs.CR])
34. Learning Linear Non-Gaussian Polytree Models. (arXiv:2208.06701v1 [stat.ML])
35. UAV-CROWD: Violent and non-violent crowd activity simulator from the perspective of UAV. (arXiv:2208.06702v1 [cs.CV])
36. An Empirical Comparison of Explainable Artificial Intelligence Methods for Clinical Data: A Case Study on Traumatic Brain Injury. (arXiv:2208.06717v1 [cs.AI])
37. A Near-Optimal Algorithm for Univariate Zeroth-Order Budget Convex Optimization. (arXiv:2208.06720v1 [math.OC])
38. Machine Learning Based Radiomics for Glial Tumor Classification and Comparison with Volumetric Analysis. (arXiv:2208.06739v1 [eess.IV])
39. Feasibility Layer Aided Machine Learning Approach for Day-Ahead Operations. (arXiv:2208.06742v1 [eess.SY])
40. Enhancing Graph Contrastive Learning with Node Similarity. (arXiv:2208.06743v1 [cs.LG])
41. Learning to Infer Counterfactuals: Meta-Learning for Estimating Multiple Imbalanced Treatment Effects. (arXiv:2208.06748v1 [cs.LG])
42. Sharp Frequency Bounds for Sample-Based Queries. (arXiv:2208.06753v1 [cs.LG])
43. Predicting skull fractures via CNN with classification algorithms. (arXiv:2208.06756v1 [cs.CV])
44. TL;DW? Summarizing Instructional Videos with Task Relevance & Cross-Modal Saliency. (arXiv:2208.06773v1 [cs.CV])
45. \b{eta}-Divergence-Based Latent Factorization of Tensors model for QoS prediction. (arXiv:2208.06778v1 [cs.LG])
46. DisenHCN: Disentangled Hypergraph Convolutional Networks for Spatiotemporal Activity Prediction. (arXiv:2208.06794v1 [cs.LG])
47. Teacher Guided Training: An Efficient Framework for Knowledge Transfer. (arXiv:2208.06825v1 [cs.LG])
48. Multinomial Logistic Regression Algorithms via Quadratic Gradient. (arXiv:2208.06828v1 [cs.LG])
49. Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning. (arXiv:2208.06838v1 [cs.AI])
50. Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves. (arXiv:2208.06859v1 [astro-ph.IM])
51. HyP$^2$ Loss: Beyond Hypersphere Metric Space for Multi-label Image Retrieval. (arXiv:2208.06866v1 [cs.CV])
52. Frouros: A Python library for drift detection in Machine Learning problems. (arXiv:2208.06868v1 [cs.LG])
53. Fast Vocabulary Projection Method via Clustering for Multilingual Machine Translation on GPU. (arXiv:2208.06874v1 [cs.CL])
54. Models of Music Cognition and Composition. (arXiv:2208.06878v1 [cs.SD])
55. Confidence-Guided Learning Process for Continuous Classification of Time Series. (arXiv:2208.06883v1 [cs.LG])
56. The SVD of Convolutional Weights: A CNN Interpretability Framework. (arXiv:2208.06894v1 [cs.CV])
57. Model Generalization: A Sharpness Aware Optimization Perspective. (arXiv:2208.06915v1 [cs.LG])
58. A Theory for Knowledge Transfer in Continual Learning. (arXiv:2208.06931v1 [cs.LG])
59. Novel Ordering-based Approaches for Causal Structure Learning in the Presence of Unobserved Variables. (arXiv:2208.06935v1 [cs.LG])
60. Towards Spatio-Temporal Cross-Platform Graph Embedding Fusion for Urban Traffic Flow Prediction. (arXiv:2208.06947v1 [cs.LG])
61. How Does Data Freshness Affect **Real-time** Supervised Learning?. (arXiv:2208.06948v1 [cs.NI])
62. Continuous Active Learning Using Pretrained Transformers. (arXiv:2208.06955v1 [cs.IR])
63. ARIEL: Adversarial Graph Contrastive Learning. (arXiv:2208.06956v1 [cs.LG])
64. Syntax-driven Data Augmentation for Named Entity Recognition. (arXiv:2208.06957v1 [cs.CL])
65. Evaluating Dense Passage Retrieval using Transformers. (arXiv:2208.06959v1 [cs.IR])
66. InvisibiliTee: Angle-agnostic Cloaking from Person-Tracking Systems with a Tee. (arXiv:2208.06962v1 [cs.CV])
67. Privacy-Preserving Decentralized Inference with Graph Neural Networks in Wireless Networks. (arXiv:2208.06963v1 [cs.IT])
68. Rethinking Graph Neural Networks for the Graph Coloring Problem. (arXiv:2208.06975v1 [cs.LG])
69. DuETA: Traffic Congestion Propagation Pattern Modeling via Efficient Graph Learning for ETA Prediction at Baidu Maps. (arXiv:2208.06979v1 [cs.LG])
70. Explainable Artificial Intelligence for Assault Sentence Prediction in New Zealand. (arXiv:2208.06981v1 [cs.LG])
71. A Unified Causal View of Domain Invariant Representation Learning. (arXiv:2208.06987v1 [stat.ML])
72. IRL with Partial Observations using the Principle of Uncertain Maximum Entropy. (arXiv:2208.06988v1 [cs.LG])
73. Towards Interpretable Sleep Stage Classification Using Cross-Modal Transformers. (arXiv:2208.06991v1 [cs.LG])
74. On a Mechanism Framework of Autoencoders. (arXiv:2208.06995v1 [cs.LG])
75. Combining deep learning and crowdsourcing geo-images to predict housing quality in rural China. (arXiv:2208.06997v1 [cs.LG])
76. AI for Global Climate Cooperation: Modeling Global Climate Negotiations, Agreements, and Long-Term Cooperation in RICE-N. (arXiv:2208.07004v1 [cs.LG])
77. MM-GNN: Mix-Moment Graph Neural Network towards Modeling Neighborhood Feature Distribution. (arXiv:2208.07012v1 [cs.LG])
78. Prospects of federated machine learning in fluid dynamics. (arXiv:2208.07017v1 [cs.LG])
79. Memory-Driven Text-to-Image Generation. (arXiv:2208.07022v1 [cs.CV])
80. Acceleration of Subspace Learning Machine via Particle Swarm Optimization and Parallel Processing. (arXiv:2208.07023v1 [cs.LG])
81. Predictive Data Calibration for Linear Correlation Significance Testing. (arXiv:2208.07081v1 [stat.ME])
82. Z-BERT-A: a zero-shot Pipeline for Unknown Intent detection. (arXiv:2208.07084v1 [cs.CL])
83. Analysis of impact of emotions on target speech extraction and speech separation. (arXiv:2208.07091v1 [cs.SD])
84. Grasping Core Rules of Time Series through Pure Models. (arXiv:2208.07105v1 [cs.LG])
85. Deception for Cyber Defence: Challenges and Opportunities. (arXiv:2208.07127v1 [cs.CR])
86. Applying Regularized Schr\"odinger-Bridge-Based Stochastic Process in Generative Modeling. (arXiv:2208.07131v1 [cs.LG])
87. Asset Allocation: From Markowitz to Deep Reinforcement Learning. (arXiv:2208.07158v1 [q-fin.PM])
88. A Hybrid Approach on Conditional GAN for Portfolio Analysis. (arXiv:2208.07159v1 [q-fin.PM])
89. Deep Reinforcement Learning Approach for Trading Automation in The Stock Market. (arXiv:2208.07165v1 [q-fin.TR])
90. WiFi Based Distance Estimation Using Supervised Machine Learning. (arXiv:2208.07190v1 [cs.LG])
91. An Efficient and Reliable Asynchronous Federated Learning Scheme for Smart Public Transportation. (arXiv:2208.07194v1 [cs.LG])
92. Determining HEDP Foams' Quality with Multi-View Deep Learning Classification. (arXiv:2208.07196v1 [cs.CV])
93. USB: A Unified Semi-supervised Learning Benchmark. (arXiv:2208.07204v1 [cs.LG])
94. RuDi: Explaining Behavior Sequence Models by Automatic Statistics Generation and Rule Distillation. (arXiv:2208.07211v1 [cs.LG])
95. Class-attention Video Transformer for Engagement Intensity Prediction. (arXiv:2208.07216v1 [cs.CV])
96. Comparison of Forecasting Methods of House Electricity Consumption for Honda Smart Home. (arXiv:2208.07217v1 [cs.LG])
97. PatchDropout: Economizing Vision Transformers Using Patch Dropout. (arXiv:2208.07220v1 [cs.CV])
98. Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting. (arXiv:1905.10696v4 [cs.LG] UPDATED)
99. On the Effect of Dropping Layers of Pre-trained Transformer Models. (arXiv:2004.03844v3 [cs.CL] UPDATED)
100. On the Estimation of Derivatives Using Plug-in KRR Estimators. (arXiv:2006.01350v3 [stat.ML] UPDATED)
101. Unifying supervised learning and VAEs -- automating statistical inference in (astro-)particle physics with amortized conditional normalizing flows. (arXiv:2008.05825v3 [cs.LG] UPDATED)
102. RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v5 [cs.LG] UPDATED)
103. Deep-Learning-Aided Path Planning and Map Construction for Expediting Indoor Mapping. (arXiv:2011.02043v2 [cs.LG] UPDATED)
104. The FEDHC Bayesian network learning algorithm. (arXiv:2012.00113v6 [stat.ML] UPDATED)
105. Near Real-Time Social Distance Estimation in London. (arXiv:2012.07751v4 [cs.CY] UPDATED)
106. Revocable Deep Reinforcement Learning with Affinity Regularization for Outlier-Robust Graph Matching. (arXiv:2012.08950v4 [cs.CV] UPDATED)
107. Inference for BART with Multinomial Outcomes. (arXiv:2101.06823v2 [stat.ME] UPDATED)
108. Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v3 [physics.med-ph] UPDATED)
109. How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation. (arXiv:2102.02805v5 [cs.LG] UPDATED)
110. Learning Contact Dynamics using Physically Structured Neural Networks. (arXiv:2102.11206v2 [cs.LG] UPDATED)
111. Deep Neural Networks with ReLU-Sine-Exponential Activations Break Curse of Dimensionality in Approximation on H\"older Class. (arXiv:2103.00542v6 [cs.LG] UPDATED)
112. Alleviation of Temperature Variation Induced Accuracy Degradation in Ferroelectric FinFET Based Neural Network. (arXiv:2103.03111v5 [cs.LG] UPDATED)
113. Sequence-based deep learning antibody design for in silico antibody affinity maturation. (arXiv:2103.03724v2 [q-bio.BM] UPDATED)
114. Reinforcement Learning for Ridesharing: An Extended Survey. (arXiv:2105.01099v6 [cs.LG] UPDATED)
115. Towards Theoretical Understandings of Robust Markov Decision Processes: Sample Complexity and Asymptotics. (arXiv:2105.03863v3 [stat.ML] UPDATED)
116. Reverse Engineering the Neural Tangent Kernel. (arXiv:2106.03186v4 [cs.LG] UPDATED)
117. Federated Learning with Positive and Unlabeled Data. (arXiv:2106.10904v3 [cs.LG] UPDATED)
118. Policy Gradient Methods Find the Nash Equilibrium in N-player General-sum Linear-quadratic Games. (arXiv:2107.13090v2 [math.OC] UPDATED)
119. Compositional Clustering for Multi-Label Few-Shot Learning. (arXiv:2109.04160v3 [cs.LG] UPDATED)
120. Direct Advantage Estimation. (arXiv:2109.06093v2 [cs.LG] UPDATED)
121. Robust Contrastive Active Learning with Feature-guided Query Strategies. (arXiv:2109.06873v2 [cs.LG] UPDATED)
122. Covert Message Passing over Public Internet Platforms Using Model-Based Format-Transforming Encryption. (arXiv:2110.07009v2 [cs.CR] UPDATED)
123. Equivariant Finite Normalizing Flows. (arXiv:2110.08649v2 [cs.LG] UPDATED)
124. Quantum Boosting using Domain-Partitioning Hypotheses. (arXiv:2110.12793v3 [quant-ph] UPDATED)
125. Membership Inference Attacks Against Self-supervised Speech Models. (arXiv:2111.05113v4 [cs.CR] UPDATED)
126. Pruning Self-attentions into Convolutional Layers in Single Path. (arXiv:2111.11802v3 [cs.CV] UPDATED)
127. Expert Aggregation for Financial Forecasting. (arXiv:2111.15365v3 [q-fin.ST] UPDATED)
128. Recent Advances in Reinforcement Learning in Finance. (arXiv:2112.04553v3 [q-fin.MF] UPDATED)
129. Self-Supervised Transformers for fMRI representation. (arXiv:2112.05761v2 [eess.IV] UPDATED)
130. A Sparse Expansion For Deep Gaussian Processes. (arXiv:2112.05888v2 [stat.ML] UPDATED)
131. Accelerated and instance-optimal policy evaluation with linear function approximation. (arXiv:2112.13109v2 [stat.ML] UPDATED)
132. Succinct Differentiation of Disparate Boosting Ensemble Learning Methods for Prognostication of Polycystic Ovary Syndrome Diagnosis. (arXiv:2201.00418v2 [cs.LG] UPDATED)
133. Deep Neural Network Approximation For H\"older Functions. (arXiv:2201.03747v2 [cs.LG] UPDATED)
134. Overcoming Oversmoothness in Graph Convolutional Networks via Hybrid Scattering Networks. (arXiv:2201.08932v2 [stat.ML] UPDATED)
135. DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities. (arXiv:2201.09058v2 [q-fin.TR] UPDATED)
136. The Enforced Transfer: An Instance-Based Divide-and-Conquer Unsupervised Domain Adaptation Algorithm. (arXiv:2201.10001v3 [cs.LG] UPDATED)
137. Privacy-Preserving Logistic Regression Training with A Faster Gradient Variant. (arXiv:2201.10838v2 [cs.CR] UPDATED)
138. Learning Physics-Consistent Particle Interactions. (arXiv:2202.00299v2 [cs.LG] UPDATED)
139. Theoretical Exploration of Solutions of Feedforward ReLU Networks. (arXiv:2202.01919v6 [cs.LG] UPDATED)
140. Cost-effective Framework for Gradual Domain Adaptation with Multifidelity. (arXiv:2202.04359v2 [stat.ML] UPDATED)
141. When do Models Generalize? A Perspective from Data-Algorithm Compatibility. (arXiv:2202.06054v2 [cs.LG] UPDATED)
142. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v3 [cs.CV] UPDATED)
143. Bounding Membership Inference. (arXiv:2202.12232v3 [cs.LG] UPDATED)
144. NURD: Negative-Unlabeled Learning for Online Datacenter Straggler Prediction. (arXiv:2203.08339v2 [cs.LG] UPDATED)
145. Plasticity Neural Network Based on Astrocytic Influence at Critical Period, Synaptic Competition and Compensation by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v3 [cs.NE] UPDATED)
146. Agreement or Disagreement in Noise-tolerant Mutual Learning?. (arXiv:2203.15317v2 [cs.CV] UPDATED)
147. Explainable Predictive Process Monitoring: Evaluation Metrics and Guidelines for Process Outcome Prediction. (arXiv:2203.16073v3 [cs.LG] UPDATED)
148. DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores. (arXiv:2204.03219v3 [eess.AS] UPDATED)
149. Active Learning with Label Comparisons. (arXiv:2204.04670v2 [cs.LG] UPDATED)
150. Inductive Biases for Object-Centric Representations in the Presence of Complex Textures. (arXiv:2204.08479v3 [cs.CV] UPDATED)
151. A Deep Reinforcement Learning Approach to Supply Chain Inventory Management. (arXiv:2204.09603v2 [cs.LG] UPDATED)
152. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v3 [cs.LG] UPDATED)
153. Transformer-Empowered 6G Intelligent Networks: From Massive MIMO Processing to Semantic Communication. (arXiv:2205.03770v2 [cs.IT] UPDATED)
154. An Edge-Cloud Integrated Framework for Flexible and Dynamic Stream Analytics. (arXiv:2205.04622v3 [cs.DC] UPDATED)
155. Fundamental limitations on optimization in variational quantum algorithms. (arXiv:2205.05056v2 [quant-ph] UPDATED)
156. DendroMap: Visual Exploration of Large-Scale Image Datasets for Machine Learning with Treemaps. (arXiv:2205.06935v2 [cs.HC] UPDATED)
157. DECONET: an Unfolding Network for Analysis-based Compressed Sensing with Generalization Error Estimates. (arXiv:2205.07050v5 [cs.IT] UPDATED)
158. Sharp asymptotics on the compression of two-layer neural networks. (arXiv:2205.08199v3 [cs.IT] UPDATED)
159. Conformalized Online Learning: Online Calibration Without a Holdout Set. (arXiv:2205.09095v3 [cs.LG] UPDATED)
160. Fast & Furious: Modelling Malware Detection as Evolving Data Streams. (arXiv:2205.12311v2 [cs.CR] UPDATED)
161. Embedding Principle in Depth for the Loss Landscape Analysis of Deep Neural Networks. (arXiv:2205.13283v2 [cs.LG] UPDATED)
162. An Analytic Framework for Robust Training of Artificial Neural Networks. (arXiv:2205.13502v2 [cs.LG] UPDATED)
163. Generalization Bounds for Gradient Methods via Discrete and Continuous Prior. (arXiv:2205.13799v3 [cs.LG] UPDATED)
164. PAC Generalization via Invariant Representations. (arXiv:2205.15196v3 [cs.LG] UPDATED)
165. Hide and Seek: on the Stealthiness of Attacks against Deep Learning Systems. (arXiv:2205.15944v2 [cs.CR] UPDATED)
166. Accelerating hydrodynamic simulations of urban drainage systems with physics-guided machine learning. (arXiv:2206.01538v2 [cs.LG] UPDATED)
167. Combinatorial Causal Bandits. (arXiv:2206.01995v3 [cs.LG] UPDATED)
168. Class Prior Estimation under Covariate Shift: No Problem?. (arXiv:2206.02449v2 [stat.ML] UPDATED)
169. Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure. (arXiv:2206.03569v2 [cs.LG] UPDATED)
170. Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning. (arXiv:2206.03996v4 [cs.LG] UPDATED)
171. ReCo: A Dataset for Residential Community Layout Planning. (arXiv:2206.04678v2 [cs.LG] UPDATED)
172. Diffusion Models for Video Prediction and Infilling. (arXiv:2206.07696v2 [cs.CV] UPDATED)
173. Finite Expression Method for Solving High-Dimensional Partial Differential Equations. (arXiv:2206.10121v2 [math.NA] UPDATED)
174. TabText: a Systematic Approach to Aggregate Knowledge Across Tabular Data Structures. (arXiv:2206.10381v2 [cs.LG] UPDATED)
175. Graph Neural Networks as Gradient Flows. (arXiv:2206.10991v2 [cs.LG] UPDATED)
176. A View Independent Classification Framework for Yoga Postures. (arXiv:2206.13577v2 [cs.CV] UPDATED)
177. Learning Controllable 3D Level Generators. (arXiv:2206.13623v3 [cs.AI] UPDATED)
178. Towards out of distribution generalization for problems in mechanics. (arXiv:2206.14917v2 [stat.ML] UPDATED)
179. When Does Differentially Private Learning Not Suffer in High Dimensions?. (arXiv:2207.00160v3 [cs.LG] UPDATED)
180. Efficient Adaptive Regret Minimization. (arXiv:2207.00646v3 [cs.LG] UPDATED)
181. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v3 [cs.CV] UPDATED)
182. PAC Reinforcement Learning for Predictive State Representations. (arXiv:2207.05738v3 [cs.LG] UPDATED)
183. GANzilla: User-Driven Direction Discovery in Generative Adversarial Networks. (arXiv:2207.08320v2 [cs.HC] UPDATED)
184. Distributed Robust Principal Component Analysis. (arXiv:2207.11669v2 [cs.DC] UPDATED)
185. A Hybrid Model and Learning-Based Adaptive Navigation Filter. (arXiv:2207.12082v2 [eess.SY] UPDATED)
186. Multi-Objective Provisioning of Network Slices using Deep Reinforcement Learning. (arXiv:2207.13821v4 [cs.NI] UPDATED)
187. Optimization of Artificial Neural Networks models applied to the identification of images of asteroids' resonant arguments. (arXiv:2207.14181v2 [astro-ph.EP] UPDATED)
188. OCFR 2022: Competition on Occluded Face Recognition From Synthetically Generated Structure-Aware Occlusions. (arXiv:2208.02760v2 [cs.CV] UPDATED)
189. Federated Learning for Medical Applications: A Taxonomy, Current Trends, Challenges, and Future Research Directions. (arXiv:2208.03392v3 [cs.LG] UPDATED)
190. Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer. (arXiv:2208.03767v2 [cs.CV] UPDATED)
191. Court Judgement Labeling Using Topic Modeling and Syntactic Parsing. (arXiv:2208.04225v2 [cs.IR] UPDATED)
192. Partial Least Square Regression via Three-factor SVD-type Manifold Optimization for EEG Decoding. (arXiv:2208.04324v2 [cs.LG] UPDATED)
193. Adaptive Zeroth-Order Optimisation of Nonconvex Composite Objectives. (arXiv:2208.04579v2 [math.OC] UPDATED)
194. Causal Discovery in Probabilistic Networks with an Identifiable Causal Effect. (arXiv:2208.04627v2 [cs.LG] UPDATED)
195. TSInterpret: A unified framework for time series interpretability. (arXiv:2208.05280v2 [cs.LG] UPDATED)
196. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v2 [eess.IV] UPDATED)
197. Neural Embedding: Learning the Embedding of the Manifold of Physics Data. (arXiv:2208.05484v2 [hep-ph] UPDATED)
198. Empirical investigations on WVA structural issues. (arXiv:2208.05791v2 [cs.LG] UPDATED)
199. GEM-2: Next Generation Molecular Property Prediction Network with Many-body and Full-range Interaction Modeling. (arXiv:2208.05863v2 [cs.LG] UPDATED)
200. MILAN: Masked Image Pretraining on Language Assisted Representation. (arXiv:2208.06049v2 [cs.CV] UPDATED)
201. A Case for Rejection in Low Resource ML Deployment. (arXiv:2208.06359v2 [cs.LG] UPDATED)
202. RangeUDF: Semantic Surface Reconstruction from 3D Point Clouds. (arXiv:2204.09138v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**93** new papers in cs.AI:-) 
1. Generating Pixel Art Character Sprites using GANs. (arXiv:2208.06413v1 [cs.GR])
2. Topological Data Analysis of Neural Network Layer Representations. (arXiv:2208.06438v1 [cs.LG])
3. RLang: A Declarative Language for Expression Prior Knowledge for Reinforcement Learning. (arXiv:2208.06448v1 [cs.AI])
4. Real-Time Accident Detection in Traffic Surveillance Using Deep Learning. (arXiv:2208.06461v1 [cs.CV])
5. Guided Evolutionary Neural Architecture Search With Efficient Performance Estimation. (arXiv:2208.06475v1 [cs.NE])
6. Occlusion-Robust Multi-Sensory Posture Estimation in Physical Human-Robot Interaction. (arXiv:2208.06494v1 [cs.RO])
7. Forecasting Question Answering over Temporal Knowledge Graphs. (arXiv:2208.06501v1 [cs.AI])
8. A Gentle Introduction and Survey on Computing with Words (CWW) Methodologies. (arXiv:2208.06532v1 [cs.AI])
9. BenchPress: A Deep Active Benchmark Genertor. (arXiv:2208.06555v1 [cs.AI])
10. On the Limitations of Continual Learning for Malware Classification. (arXiv:2208.06568v1 [cs.CR])
11. Recognition of All Categories of Entities by AI. (arXiv:2208.06590v1 [cs.AI])
12. Self-supervised Matting-specific Portrait **Enhancement** and Generation. (arXiv:2208.06601v1 [cs.CV])
13. Combating Label Distribution Shift for Active Domain Adaptation. (arXiv:2208.06604v1 [cs.LG])
14. Granular Directed Rough Sets, Concept Organization and Soft Clustering. (arXiv:2208.06623v1 [cs.AI])
15. Modeling Network-level Traffic Flow Transitions on Sparse Data. (arXiv:2208.06646v1 [cs.LG])
16. Imputation Strategies Under Clinical Presence: Impact on Algorithmic Fairness. (arXiv:2208.06648v1 [cs.AI])
17. Differentiable Inductive Logic Programming in High-Dimensional Space. (arXiv:2208.06652v1 [cs.AI])
18. ULDGNN: A Fragmented UI Layer Detector Based on Graph Neural Networks. (arXiv:2208.06658v1 [cs.CV])
19. An Empirical Comparison of Explainable Artificial Intelligence Methods for Clinical Data: A Case Study on Traumatic Brain Injury. (arXiv:2208.06717v1 [cs.AI])
20. Link-Backdoor: Backdoor Attack on Link Prediction via Node Injection. (arXiv:2208.06776v1 [cs.SI])
21. **HDR**-Plenoxels: Self-Calibrating **High Dynamic Range** Radiance Fields. (arXiv:2208.06787v1 [cs.CV])
22. DisenHCN: Disentangled Hypergraph Convolutional Networks for Spatiotemporal Activity Prediction. (arXiv:2208.06794v1 [cs.LG])
23. **Real-time** Caller Intent Detection In Human-Human Customer Support Spoken Conversations. (arXiv:2208.06802v1 [cs.AI])
24. Simply Logical -- Intelligent Reasoning by Example (Fully Interactive Online Edition). (arXiv:2208.06823v1 [cs.AI])
25. Analogical proportions in monounary algebras and difference proportions. (arXiv:2208.06829v1 [cs.AI])
26. Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning. (arXiv:2208.06838v1 [cs.AI])
27. Who Finds the Short Proof? An Exploration of variants of Boolos' Curious Inference using Higher-order Automated Theorem Provers. (arXiv:2208.06879v1 [math.LO])
28. The SVD of Convolutional Weights: A CNN Interpretability Framework. (arXiv:2208.06894v1 [cs.CV])
29. Limits of an AI program for solving college math problems. (arXiv:2208.06906v1 [cs.AI])
30. Model Generalization: A Sharpness Aware Optimization Perspective. (arXiv:2208.06915v1 [cs.LG])
31. GNPassGAN: Improved Generative Adversarial Networks For Trawling Offline Password Guessing. (arXiv:2208.06943v1 [cs.CR])
32. Targeted Honeyword Generation with Language Models. (arXiv:2208.06946v1 [cs.AI])
33. Continuous Active Learning Using Pretrained Transformers. (arXiv:2208.06955v1 [cs.IR])
34. Syntax-driven Data Augmentation for Named Entity Recognition. (arXiv:2208.06957v1 [cs.CL])
35. Evaluating Dense Passage Retrieval using Transformers. (arXiv:2208.06959v1 [cs.IR])
36. Rethinking Graph Neural Networks for the Graph Coloring Problem. (arXiv:2208.06975v1 [cs.LG])
37. DuETA: Traffic Congestion Propagation Pattern Modeling via Efficient Graph Learning for ETA Prediction at Baidu Maps. (arXiv:2208.06979v1 [cs.LG])
38. A Multi-objective Memetic Algorithm for Auto Adversarial Attack Optimization Design. (arXiv:2208.06984v1 [cs.CV])
39. Pyramidal Predictive Network: A Model for Visual-frame Prediction Based on Predictive Coding Theory. (arXiv:2208.07021v1 [cs.CV])
40. Non-Blocking Batch A* (Technical Report). (arXiv:2208.07031v1 [cs.AI])
41. Sound and Relatively Complete Belief Hoare Logic for Statistical Hypothesis Testing Programs. (arXiv:2208.07074v1 [cs.AI])
42. Estimating Personal Model Parameters from Utterances in Model-based Reminiscence. (arXiv:2208.07087v1 [cs.HC])
43. Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task. (arXiv:2208.07097v1 [cs.CL])
44. Seminaive Materialisation in DatalogMTL. (arXiv:2208.07100v1 [cs.DB])
45. Grasping Core Rules of Time Series through Pure Models. (arXiv:2208.07105v1 [cs.LG])
46. Preventing Deterioration of Classification Accuracy in Predictive Coding Networks. (arXiv:2208.07114v1 [cs.AI])
47. Online 3D Bin Packing Reinforcement Learning Solution with Buffer. (arXiv:2208.07123v1 [cs.RO])
48. C-Causal Blindness An experimental computational framework on the isomorphic relationship between biological computation, artificial computation, and logic using weighted hidden Markov models. (arXiv:2208.07143v1 [cs.AI])
49. Asset Allocation: From Markowitz to Deep Reinforcement Learning. (arXiv:2208.07158v1 [q-fin.PM])
50. Where is VALDO? VAscular Lesions Detection and segmentatiOn challenge at MICCAI 2021. (arXiv:2208.07167v1 [cs.CV])
51. Computational Empathy Counteracts the Negative Effects of Anger on Creative Problem Solving. (arXiv:2208.07178v1 [cs.HC])
52. USB: A Unified Semi-supervised Learning Benchmark. (arXiv:2208.07204v1 [cs.LG])
53. RuDi: Explaining Behavior Sequence Models by Automatic Statistics Generation and Rule Distillation. (arXiv:2208.07211v1 [cs.LG])
54. Comparison of Forecasting Methods of House Electricity Consumption for Honda Smart Home. (arXiv:2208.07217v1 [cs.LG])
55. Incompleteness for stably consistent formal systems. (arXiv:2001.07592v7 [cs.LO] UPDATED)
56. RG-Flow: A hierarchical and explainable flow model based on renormalization group and sparse prior. (arXiv:2010.00029v5 [cs.LG] UPDATED)
57. A Feasibility-Driven Approach to Control-Limited DDP. (arXiv:2010.00411v4 [cs.RO] UPDATED)
58. Reinforcement Learning for Ridesharing: An Extended Survey. (arXiv:2105.01099v6 [cs.LG] UPDATED)
59. Robust Contrastive Active Learning with Feature-guided Query Strategies. (arXiv:2109.06873v2 [cs.LG] UPDATED)
60. Low-Resource Named Entity Recognition Based on Multi-hop Dependency Trigger. (arXiv:2109.07118v3 [cs.CL] UPDATED)
61. Equivariant Finite Normalizing Flows. (arXiv:2110.08649v2 [cs.LG] UPDATED)
62. Examining Zero-Shot Vulnerability Repair with Large Language Models. (arXiv:2112.02125v3 [cs.CR] UPDATED)
63. Hybrid Self-Attention NEAT: A novel evolutionary approach to improve the NEAT algorithm. (arXiv:2112.03670v3 [cs.NE] UPDATED)
64. DeepScalper: A Risk-Aware Reinforcement Learning Framework to Capture Fleeting Intraday Trading Opportunities. (arXiv:2201.09058v2 [q-fin.TR] UPDATED)
65. The Enforced Transfer: An Instance-Based Divide-and-Conquer Unsupervised Domain Adaptation Algorithm. (arXiv:2201.10001v3 [cs.LG] UPDATED)
66. Theoretical Exploration of Solutions of Feedforward ReLU Networks. (arXiv:2202.01919v6 [cs.LG] UPDATED)
67. Do Inpainting Yourself: Generative Facial Inpainting Guided by Exemplars. (arXiv:2202.06358v3 [cs.CV] UPDATED)
68. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v3 [cs.CV] UPDATED)
69. A Survey of Ad Hoc Teamwork Research. (arXiv:2202.10450v2 [cs.MA] UPDATED)
70. WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition. (arXiv:2203.06925v5 [cs.CL] UPDATED)
71. Continual Learning and Private Unlearning. (arXiv:2203.12817v2 [cs.AI] UPDATED)
72. Agreement or Disagreement in Noise-tolerant Mutual Learning?. (arXiv:2203.15317v2 [cs.CV] UPDATED)
73. Explainable Predictive Process Monitoring: Evaluation Metrics and Guidelines for Process Outcome Prediction. (arXiv:2203.16073v3 [cs.LG] UPDATED)
74. A Deep Reinforcement Learning Approach to Supply Chain Inventory Management. (arXiv:2204.09603v2 [cs.LG] UPDATED)
75. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v3 [cs.LG] UPDATED)
76. Transformer-Empowered 6G Intelligent Networks: From Massive MIMO Processing to Semantic Communication. (arXiv:2205.03770v2 [cs.IT] UPDATED)
77. DendroMap: Visual Exploration of Large-Scale Image Datasets for Machine Learning with Treemaps. (arXiv:2205.06935v2 [cs.HC] UPDATED)
78. Computable Artificial General Intelligence. (arXiv:2205.10513v5 [cs.AI] UPDATED)
79. An Analytic Framework for Robust Training of Artificial Neural Networks. (arXiv:2205.13502v2 [cs.LG] UPDATED)
80. Hide and Seek: on the Stealthiness of Attacks against Deep Learning Systems. (arXiv:2205.15944v2 [cs.CR] UPDATED)
81. ReCo: A Dataset for Residential Community Layout Planning. (arXiv:2206.04678v2 [cs.LG] UPDATED)
82. Unified BERT for Few-shot Natural Language Understanding. (arXiv:2206.12094v2 [cs.CL] UPDATED)
83. A View Independent Classification Framework for Yoga Postures. (arXiv:2206.13577v2 [cs.CV] UPDATED)
84. Learning Controllable 3D Level Generators. (arXiv:2206.13623v3 [cs.AI] UPDATED)
85. DUET: Cross-modal Semantic Grounding for Contrastive Zero-shot Learning. (arXiv:2207.01328v2 [cs.CV] UPDATED)
86. GANzilla: User-Driven Direction Discovery in Generative Adversarial Networks. (arXiv:2207.08320v2 [cs.HC] UPDATED)
87. Cross-Modal Causal Relational Reasoning for Event-Level Visual Question Answering. (arXiv:2207.12647v2 [cs.CV] UPDATED)
88. NewsStories: Illustrating articles with visual summaries. (arXiv:2207.13061v2 [cs.CV] UPDATED)
89. Search for or Navigate to? Dual Adaptive Thinking for Object Navigation. (arXiv:2208.00553v2 [cs.AI] UPDATED)
90. ACSGRegNet: A Deep Learning-based Framework for Unsupervised Joint Affine and Diffeomorphic Registration of Lumbar Spine CT via Cross- and Self-Attention Fusion. (arXiv:2208.02642v2 [cs.CV] UPDATED)
91. Class-Incremental Learning with Cross-Space Clustering and Controlled Transfer. (arXiv:2208.03767v2 [cs.CV] UPDATED)
92. DeepHider: A Multi-module and Invisibility Watermarking Scheme for Language Model. (arXiv:2208.04676v2 [cs.CR] UPDATED)
93. RangeUDF: Semantic Surface Reconstruction from 3D Point Clouds. (arXiv:2204.09138v1 [cs.CV] CROSS LISTED)

