# Your interest papers
---
## cs.CV
---
### RestoreX-AI: A Contrastive Approach towards Guiding Image **Restoration** via Explainable AI Systems. (arXiv:2204.01719v1 [eess.IV])
- Authors : Aboli Marathe, Pushkar Jain, Rahee Walambe, Ketan Kotecha
- Link : [http://arxiv.org/abs/2204.01719](http://arxiv.org/abs/2204.01719)
> ABSTRACT  :  Modern applications such as self-driving cars and drones rely heavily upon robust object detection techniques. However, weather corruptions can hinder the object detectability and pose a serious threat to their navigation and reliability. Thus, there is a need for efficient denoising, deraining, and **restoration** techniques. Generative adversarial networks and transformers have been widely adopted for image **restoration**. However, the training of these methods is often unstable and time-consuming. Furthermore, when used for object detection (OD), the output images generated by these methods may provide unsatisfactory results despite image clarity. In this work, we propose a contrastive approach towards mitigating this problem, by evaluating images generated by **restoration** models during and post training. This approach leverages OD scores combined with attention maps for predicting the usefulness of restored images for the OD task. We conduct experiments using two novel use-cases of conditional GANs and two transformer methods that probe the robustness of the proposed approach on multi-weather corruptions in the OD task. Our approach achieves an averaged 178 percent increase in mAP between the input and restored images under adverse weather conditions like dust tornadoes and snowfall. We report unique cases where greater denoising does not improve OD performance and conversely where noisy generated images demonstrate good results. We conclude the need for explainability frameworks to bridge the gap between human and machine perception, especially in the context of robust object detection for autonomous vehicles.  
### Lightweight **HDR** Camera ISP for Robust Perception in Dynamic Illumination Conditions via Fourier Adversarial Networks. (arXiv:2204.01795v1 [cs.CV])
- Authors : Pranjay Shyam, Sandeep Singh, Jin Yoon, Soo Kim
- Link : [http://arxiv.org/abs/2204.01795](http://arxiv.org/abs/2204.01795)
> ABSTRACT  :  The limited dynamic range of commercial compact camera sensors results in an inaccurate representation of scenes with varying illumination conditions, adversely affecting image quality and subsequently limiting the performance of underlying image processing algorithms. Current state-of-the-art (SoTA) convolutional neural networks (CNN) are developed as post-processing techniques to independently recover under-/over-exposed images. However, when applied to images containing real-world degradations such as glare, high-beam, color bleeding with varying noise intensity, these algorithms amplify the degradations, further degrading image quality. We propose a lightweight two-stage image **enhancement** algorithm sequentially balancing illumination and noise removal using frequency priors for structural guidance to overcome these limitations. Furthermore, to ensure realistic image quality, we leverage the relationship between frequency and spatial domain properties of an image and propose a Fourier spectrum-based adversarial framework (AFNet) for consistent image **enhancement** under varying illumination conditions. While current formulations of image **enhancement** are envisioned as post-processing techniques, we examine if such an algorithm could be extended to integrate the functionality of the Image Signal Processing (ISP) pipeline within the camera sensor benefiting from RAW sensor data and lightweight CNN architecture. Based on quantitative and qualitative evaluations, we also examine the practicality and effects of image **enhancement** techniques on the performance of common perception tasks such as object detection and semantic segmentation in varying illumination conditions.  
### Region Rebalance for Long-Tailed Semantic Segmentation. (arXiv:2204.01969v1 [cs.CV])
- Authors : Jiequan Cui, Yuhui Yuan, Zhisheng Zhong, Zhuotao Tian, Han Hu, Stephen Lin, Jiaya Jia
- Link : [http://arxiv.org/abs/2204.01969](http://arxiv.org/abs/2204.01969)
> ABSTRACT  :  In this paper, we study the problem of class imbalance in semantic segmentation. We first investigate and identify the main challenges of addressing this issue through pixel rebalance. Then a simple and yet effective region rebalance scheme is derived based on our analysis. In our solution, pixel features belonging to the same class are grouped into region features, and a rebalanced region classifier is applied via an auxiliary region rebalance branch during training. To verify the flexibility and effectiveness of our method, we apply the region rebalance module into various semantic segmentation methods, such as Deeplabv3+, OCRNet, and **Swin**. Our strategy achieves consistent improvement on the challenging ADE20K and COCO-Stuff benchmark. In particular, with the proposed region rebalance scheme, state-of-the-art BEiT receives +0.7% gain in terms of mIoU on the ADE20K val set.  
### Audio-visual multi-channel speech separation, dereverberation and recognition. (arXiv:2204.01977v1 [cs.SD])
- Authors : Guinan Li, Jianwei Yu, Jiajun Deng, Xunying Liu, Helen Meng
- Link : [http://arxiv.org/abs/2204.01977](http://arxiv.org/abs/2204.01977)
> ABSTRACT  :  Despite the rapid advance of automatic speech recognition (ASR) technologies, accurate recognition of cocktail party speech characterised by the interference from overlapping speakers, background noise and room reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, audio-visual speech **enhancement** techniques have been developed, although predominantly targeting overlapping speech separation and recognition tasks. In this paper, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all three stages of the system is proposed. The advantage of the additional visual modality over using audio only is demonstrated on two neural dereverberation approaches based on DNN-WPE and spectral mapping respectively. The learning cost function mismatch between the separation and dereverberation models and their integration with the back-end recognition system is minimised using fine-tuning on the MSE and LF-MMI criteria. Experiments conducted on the LRS2 dataset suggest that the proposed audio-visual multi-channel speech separation, dereverberation and recognition system outperforms the baseline audio-visual multi-channel speech separation and recognition system containing no dereverberation module by a statistically significant word error rate (WER) reduction of 2.06% absolute (8.77% relative).  
### **Real-time** Online Multi-Object Tracking in Compressed Domain. (arXiv:2204.02081v1 [cs.CV])
- Authors : Qiankun Liu, Bin Liu, Yue Wu, Weihai Li, Nenghai Yu
- Link : [http://arxiv.org/abs/2204.02081](http://arxiv.org/abs/2204.02081)
> ABSTRACT  :  Recent online Multi-Object Tracking (MOT) methods have achieved desirable tracking performance. However, the tracking speed of most existing methods is rather slow. Inspired from the fact that the adjacent frames are highly relevant and redundant, we divide the frames into key and non-key frames respectively and track objects in the compressed domain. For the key frames, the RGB images are restored for detection and data association. To make data association more reliable, an appearance Convolutional Neural Network (CNN) which can be jointly trained with the detector is proposed. For the non-key frames, the objects are directly propagated by a tracking CNN based on the motion information provided in the compressed domain. Compared with the state-of-the-art online MOT methods,our tracker is about 6x faster while maintaining a comparable tracking performance.  
### **Real-time** Hyperspectral Imaging in Hardware via Trained Metasurface Encoders. (arXiv:2204.02084v1 [cs.CV])
- Authors : Maksim Makarenko, Arturo Burguete, Qizhou Wang, Fedor Getman, Silvio Giancola, Bernard Ghanem, Andrea Fratalocchi
- Link : [http://arxiv.org/abs/2204.02084](http://arxiv.org/abs/2204.02084)
> ABSTRACT  :  Hyperspectral imaging has attracted significant attention to identify spectral signatures for image classification and automated pattern recognition in computer vision. State-of-the-art implementations of snapshot hyperspectral imaging rely on bulky, non-integrated, and expensive optical elements, including lenses, spectrometers, and filters. These macroscopic components do not allow fast data processing for, e.g real-time and high-resolution videos. This work introduces Hyplex, a new integrated architecture addressing the limitations discussed above. Hyplex is a CMOS-compatible, fast hyperspectral camera that replaces bulk optics with nanoscale metasurfaces inversely designed through artificial intelligence. Hyplex does not require spectrometers but makes use of conventional monochrome cameras, opening up the possibility for real-time and high-resolution hyperspectral imaging at inexpensive costs. Hyplex exploits a model-driven optimization, which connects the physical metasurfaces layer with modern visual computing approaches based on end-to-end training. We design and implement a prototype version of Hyplex and compare its performance against the state-of-the-art for typical imaging tasks such as spectral reconstruction and semantic segmentation. In all benchmarks, Hyplex reports the smallest reconstruction error. We additionally present what is, to the best of our knowledge, the largest publicly available labeled hyperspectral dataset for semantic segmentation.  
### A lightweight and accurate YOLO-like network for small target detection in Aerial Imagery. (arXiv:2204.02325v1 [cs.CV])
- Authors : Alessandro Betti
- Link : [http://arxiv.org/abs/2204.02325](http://arxiv.org/abs/2204.02325)
> ABSTRACT  :  Despite the breakthrough deep learning performances achieved for automatic object detection, small target detection is still a challenging problem, especially when looking at fast and accurate solutions suitable for mobile or edge applications. In this work we present YOLO-S, a simple, fast and efficient network for small target detection. The architecture exploits a small feature extractor based on **Dark**net20, as well as skip connection, via both bypass and concatenation, and reshape-passthrough layer to alleviate the vanishing gradient problem, promote feature reuse across network and combine low-level positional information with more meaningful high-level information. To verify the performances of YOLO-S, we build "AIRES", a novel dataset for cAr detectIon fRom hElicopter imageS acquired in Europe, and set up experiments on both AIRES and VEDAI datasets, benchmarking this architecture with four baseline detectors. Furthermore, in order to handle efficiently the issue of data insufficiency and domain gap when dealing with a transfer learning strategy, we introduce a transitional learning task over a combined dataset based on DOTAv2 and VEDAI and demonstrate that can enhance the overall accuracy with respect to more general features transferred from COCO data. YOLO-S is from 25% to 50% faster than YOLOv3 and only 15-25% slower than Tiny-YOLOv3, outperforming also YOLOv3 in terms of accuracy in a wide range of experiments. Further simulations performed on SARD dataset demonstrate also its applicability to different scenarios such as for search and rescue operations. Besides, YOLO-S has an 87% decrease of parameter size and almost one half FLOPs of YOLOv3, making practical the deployment for low-power industrial applications.  
### ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer. (arXiv:2204.02389v1 [cs.CV])
- Authors : Ruohan Gao, Zilin Si, Yu Chang, Samuel Clarke, Jeannette Bohg, Li Fei, Wenzhen Yuan, Jiajun Wu
- Link : [http://arxiv.org/abs/2204.02389](http://arxiv.org/abs/2204.02389)
> ABSTRACT  :  Objects play a crucial role in our everyday activities. Though multisensory object-centric learning has shown great potential lately, the modeling of objects in prior work is rather unrealistic. ObjectFolder 1.0 is a recent dataset that introduces 100 virtualized objects with visual, acoustic, and tactile sensory data. However, the dataset is small in scale and the multisensory data is of limited quality, hampering generalization to real-world scenarios. We present ObjectFolder 2.0, a large-scale, multisensory dataset of common household objects in the form of **implicit neural representation**s that significantly enhances ObjectFolder 1.0 in three aspects. First, our dataset is 10 times larger in the amount of objects and orders of magnitude faster in rendering time. Second, we significantly improve the multisensory rendering quality for all three modalities. Third, we show that models learned from virtual objects in our dataset successfully transfer to their real-world counterparts in three challenging tasks: object scale estimation, contact localization, and shape reconstruction. ObjectFolder 2.0 offers a new path and testbed for multisensory learning in computer vision and robotics. The dataset is available at https://github.com/rhgao/ObjectFolder.  
### Spatio-Temporal Recurrent Networks for Event-Based Optical Flow Estimation. (arXiv:2109.04871v2 [cs.CV] UPDATED)
- Authors : Ziluo Ding, Rui Zhao, Jiyuan Zhang, Tianxiao Gao, Ruiqin Xiong, Zhaofei Yu, Tiejun Huang
- Link : [http://arxiv.org/abs/2109.04871](http://arxiv.org/abs/2109.04871)
> ABSTRACT  :  Event camera has offered promising alternative for visual perception, especially in high speed and **high dynamic range** scenes. Recently, many deep learning methods have shown great success in providing promising solutions to many event-based problems, such as optical flow estimation. However, existing deep learning methods did not address the importance of temporal information well from the perspective of architecture design and cannot effectively extract spatio-temporal features. Another line of research that utilizes Spiking Neural Network suffers from training issues for deeper architecture.To address these points, a novel input representation is proposed that captures the events' temporal distribution for signal **enhancement**. Moreover, we introduce a spatio-temporal recurrent encoding-decoding neural network architecture for event-based optical flow estimation, which utilizes Convolutional Gated Recurrent Units to extract feature maps from a series of event images. Besides, our architecture allows some traditional frame-based core modules, such as correlation layer and iterative residual refine scheme, to be incorporated. The network is end-to-end trained with self-supervised learning on the Multi-Vehicle Stereo Event Camera dataset. We have shown that it outperforms all the existing state-of-the-art methods by a large margin. The code link is https://github.com/ruizhao26/STE-FlowNet.  
### Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v2 [eess.IV] UPDATED)
- Authors : Abril Corona, Jonathan Frawley, Sam Bond, Sarath Bethapudi
- Link : [http://arxiv.org/abs/2202.01020](http://arxiv.org/abs/2202.01020)
> ABSTRACT  :  Computed tomography (CT) is an effective medical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multiplanar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qualitative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets is available at https://github.com/jonathanfrawley/mednerf  
### Large-Scale Pre-training for Person Re-identification with Noisy Labels. (arXiv:2203.16533v2 [cs.CV] UPDATED)
- Authors : Dengpan Fu, Dongdong Chen, Hao Yang, Jianmin Bao, Lu Yuan, **Lei Zhang**, Houqiang Li, Fang Wen, Dong Chen
- Link : [http://arxiv.org/abs/2203.16533](http://arxiv.org/abs/2203.16533)
> ABSTRACT  :  This paper aims to address the problem of pre-training for person re-identification (Re-ID) with noisy labels. To setup the pre-training task, we apply a simple online multi-object tracking system on raw videos of an existing unlabeled Re-ID dataset "LUPerson" nd build the Noisy Labeled variant called "LUPerson-NL". Since theses ID labels automatically derived from tracklets inevitably contain noises, we develop a large-scale Pre-training framework utilizing Noisy Labels (PNL), which consists of three learning modules: supervised Re-ID learning, prototype-based contrastive learning, and label-guided contrastive learning. In principle, joint learning of these three modules not only clusters similar examples to one prototype, but also rectifies noisy labels based on the prototype assignment. We demonstrate that learning directly from raw videos is a promising alternative for pre-training, which utilizes spatial and temporal correlations as weak supervision. This simple pre-training task provides a scalable way to learn SOTA Re-ID representations from scratch on "LUPerson-NL" without bells and whistles. For example, by applying on the same supervised Re-ID method MGN, our pre-trained model improves the mAP over the unsupervised pre-training counterpart by 5.7%, 2.2%, 2.3% on CUHK03, DukeMTMC, and MSMT17 respectively. Under the small-scale or few-shot setting, the performance gain is even more significant, suggesting a better transferability of the learned representation. Code is available at https://github.com/DengpanFu/LUPerson-NL  
### UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
- Authors : Ali Hatamizadeh, Ziyue Xu, Dong Yang, Wenqi Li, Holger Roth, Daguang Xu
- Link : [http://arxiv.org/abs/2204.00631](http://arxiv.org/abs/2204.00631)
> ABSTRACT  :  Vision Transformers (ViT)s have recently become popular due to their outstanding modeling capabilities, in particular for capturing long-range information, and scalability to dataset and model sizes which has led to state-of-the-art performance in various computer vision and medical image analysis tasks. In this work, we introduce a unified framework consisting of two architectures, dubbed UNetFormer, with a 3D **Swin** Transformer-based encoder and Convolutional Neural Network (CNN) and transformer-based decoders. In the proposed model, the encoder is linked to the decoder via skip connections at five different resolutions with deep supervision. The design of proposed architecture allows for meeting a wide range of trade-off requirements between accuracy and computational cost. In addition, we present a methodology for self-supervised pre-training of the encoder backbone via learning to predict randomly masked volumetric tokens using contextual information of visible tokens. We pre-train our framework on a cohort of $5050$ CT images, gathered from publicly available CT datasets, and present a systematic investigation of various components such as masking ratio and patch size that affect the representation learning capability and performance of downstream tasks. We validate the effectiveness of our pre-training approach by fine-tuning and testing our model on liver and liver tumor segmentation task using the Medical Segmentation Decathlon (MSD) dataset and achieve state-of-the-art performance in terms of various segmentation metrics. To demonstrate its generalizability, we train and test the model on BraTS 21 dataset for brain tumor segmentation using MRI images and outperform other methods in terms of Dice score. Code: https://github.com/Project-MONAI/research-contributions  
### Adjusting for Bias with Procedural Data. (arXiv:2204.01108v2 [cs.CV] UPDATED)
- Authors : Shesh Narayan, Nicholas Bear
- Link : [http://arxiv.org/abs/2204.01108](http://arxiv.org/abs/2204.01108)
> ABSTRACT  :  3D softwares are now capable of producing highly realistic images that look nearly indistinguishable from the real images. This raises the question: can real datasets be enhanced with 3D rendered data? We investigate this question. In this paper we demonstrate the use of 3D rendered data, procedural, data for the adjustment of bias in image datasets. We perform error analysis of images of animals which shows that the misclassification of some animal breeds is largely a data issue. We then create procedural images of the poorly classified breeds and that model further trained on procedural data can better classify poorly performing breeds on real data. We believe that this approach can be used for the **enhancement** of visual data for any underrepresented group, including rare diseases, or any data bias potentially improving the accuracy and fairness of models. We find that the resulting representations rival or even out-perform those learned directly from real data, but that good performance requires care in the 3D rendered procedural data generation. 3D image dataset can be viewed as a compressed and organized copy of a real dataset, and we envision a future where more and more procedural data proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future.  
## eess.IV
---
### RestoreX-AI: A Contrastive Approach towards Guiding Image **Restoration** via Explainable AI Systems. (arXiv:2204.01719v1 [eess.IV])
- Authors : Aboli Marathe, Pushkar Jain, Rahee Walambe, Ketan Kotecha
- Link : [http://arxiv.org/abs/2204.01719](http://arxiv.org/abs/2204.01719)
> ABSTRACT  :  Modern applications such as self-driving cars and drones rely heavily upon robust object detection techniques. However, weather corruptions can hinder the object detectability and pose a serious threat to their navigation and reliability. Thus, there is a need for efficient denoising, deraining, and **restoration** techniques. Generative adversarial networks and transformers have been widely adopted for image **restoration**. However, the training of these methods is often unstable and time-consuming. Furthermore, when used for object detection (OD), the output images generated by these methods may provide unsatisfactory results despite image clarity. In this work, we propose a contrastive approach towards mitigating this problem, by evaluating images generated by **restoration** models during and post training. This approach leverages OD scores combined with attention maps for predicting the usefulness of restored images for the OD task. We conduct experiments using two novel use-cases of conditional GANs and two transformer methods that probe the robustness of the proposed approach on multi-weather corruptions in the OD task. Our approach achieves an averaged 178 percent increase in mAP between the input and restored images under adverse weather conditions like dust tornadoes and snowfall. We report unique cases where greater denoising does not improve OD performance and conversely where noisy generated images demonstrate good results. We conclude the need for explainability frameworks to bridge the gap between human and machine perception, especially in the context of robust object detection for autonomous vehicles.  
### Lightweight **HDR** Camera ISP for Robust Perception in Dynamic Illumination Conditions via Fourier Adversarial Networks. (arXiv:2204.01795v1 [cs.CV])
- Authors : Pranjay Shyam, Sandeep Singh, Jin Yoon, Soo Kim
- Link : [http://arxiv.org/abs/2204.01795](http://arxiv.org/abs/2204.01795)
> ABSTRACT  :  The limited dynamic range of commercial compact camera sensors results in an inaccurate representation of scenes with varying illumination conditions, adversely affecting image quality and subsequently limiting the performance of underlying image processing algorithms. Current state-of-the-art (SoTA) convolutional neural networks (CNN) are developed as post-processing techniques to independently recover under-/over-exposed images. However, when applied to images containing real-world degradations such as glare, high-beam, color bleeding with varying noise intensity, these algorithms amplify the degradations, further degrading image quality. We propose a lightweight two-stage image **enhancement** algorithm sequentially balancing illumination and noise removal using frequency priors for structural guidance to overcome these limitations. Furthermore, to ensure realistic image quality, we leverage the relationship between frequency and spatial domain properties of an image and propose a Fourier spectrum-based adversarial framework (AFNet) for consistent image **enhancement** under varying illumination conditions. While current formulations of image **enhancement** are envisioned as post-processing techniques, we examine if such an algorithm could be extended to integrate the functionality of the Image Signal Processing (ISP) pipeline within the camera sensor benefiting from RAW sensor data and lightweight CNN architecture. Based on quantitative and qualitative evaluations, we also examine the practicality and effects of image **enhancement** techniques on the performance of common perception tasks such as object detection and semantic segmentation in varying illumination conditions.  
### **Real-time** Online Multi-Object Tracking in Compressed Domain. (arXiv:2204.02081v1 [cs.CV])
- Authors : Qiankun Liu, Bin Liu, Yue Wu, Weihai Li, Nenghai Yu
- Link : [http://arxiv.org/abs/2204.02081](http://arxiv.org/abs/2204.02081)
> ABSTRACT  :  Recent online Multi-Object Tracking (MOT) methods have achieved desirable tracking performance. However, the tracking speed of most existing methods is rather slow. Inspired from the fact that the adjacent frames are highly relevant and redundant, we divide the frames into key and non-key frames respectively and track objects in the compressed domain. For the key frames, the RGB images are restored for detection and data association. To make data association more reliable, an appearance Convolutional Neural Network (CNN) which can be jointly trained with the detector is proposed. For the non-key frames, the objects are directly propagated by a tracking CNN based on the motion information provided in the compressed domain. Compared with the state-of-the-art online MOT methods,our tracker is about 6x faster while maintaining a comparable tracking performance.  
### **Real-time** Hyperspectral Imaging in Hardware via Trained Metasurface Encoders. (arXiv:2204.02084v1 [cs.CV])
- Authors : Maksim Makarenko, Arturo Burguete, Qizhou Wang, Fedor Getman, Silvio Giancola, Bernard Ghanem, Andrea Fratalocchi
- Link : [http://arxiv.org/abs/2204.02084](http://arxiv.org/abs/2204.02084)
> ABSTRACT  :  Hyperspectral imaging has attracted significant attention to identify spectral signatures for image classification and automated pattern recognition in computer vision. State-of-the-art implementations of snapshot hyperspectral imaging rely on bulky, non-integrated, and expensive optical elements, including lenses, spectrometers, and filters. These macroscopic components do not allow fast data processing for, e.g real-time and high-resolution videos. This work introduces Hyplex, a new integrated architecture addressing the limitations discussed above. Hyplex is a CMOS-compatible, fast hyperspectral camera that replaces bulk optics with nanoscale metasurfaces inversely designed through artificial intelligence. Hyplex does not require spectrometers but makes use of conventional monochrome cameras, opening up the possibility for real-time and high-resolution hyperspectral imaging at inexpensive costs. Hyplex exploits a model-driven optimization, which connects the physical metasurfaces layer with modern visual computing approaches based on end-to-end training. We design and implement a prototype version of Hyplex and compare its performance against the state-of-the-art for typical imaging tasks such as spectral reconstruction and semantic segmentation. In all benchmarks, Hyplex reports the smallest reconstruction error. We additionally present what is, to the best of our knowledge, the largest publicly available labeled hyperspectral dataset for semantic segmentation.  
### Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v2 [eess.IV] UPDATED)
- Authors : Abril Corona, Jonathan Frawley, Sam Bond, Sarath Bethapudi
- Link : [http://arxiv.org/abs/2202.01020](http://arxiv.org/abs/2202.01020)
> ABSTRACT  :  Computed tomography (CT) is an effective medical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multiplanar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qualitative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets is available at https://github.com/jonathanfrawley/mednerf  
### Restoring Vision through Retinal Implants -- A Systematic Literature Review. (arXiv:2203.17200v2 [q-bio.NC] UPDATED)
- Authors : Magali Andreia, Sylviane da, Silva Vitor
- Link : [http://arxiv.org/abs/2203.17200](http://arxiv.org/abs/2203.17200)
> ABSTRACT  :  This work presents a bunched of promising technologies to treat blind people: the bionic eyes. The strategy is to combine a retina implant with software capable to interpret the information received. Along this line of thinking, projects such as Retinal Prosthetic Strategy with the Capacity to Restore Normal Vision from Weill Medical College of Cornell University Project, Update on Retinal Prosthetic Research from The Boston Retinal Implant Project, and **Restoration** of Vision Using Wireless Cortical Implants from Monash Vision Group Project, have shown in a different context the use of technologies that commits to bring the vision through its use.  
### UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
- Authors : Ali Hatamizadeh, Ziyue Xu, Dong Yang, Wenqi Li, Holger Roth, Daguang Xu
- Link : [http://arxiv.org/abs/2204.00631](http://arxiv.org/abs/2204.00631)
> ABSTRACT  :  Vision Transformers (ViT)s have recently become popular due to their outstanding modeling capabilities, in particular for capturing long-range information, and scalability to dataset and model sizes which has led to state-of-the-art performance in various computer vision and medical image analysis tasks. In this work, we introduce a unified framework consisting of two architectures, dubbed UNetFormer, with a 3D **Swin** Transformer-based encoder and Convolutional Neural Network (CNN) and transformer-based decoders. In the proposed model, the encoder is linked to the decoder via skip connections at five different resolutions with deep supervision. The design of proposed architecture allows for meeting a wide range of trade-off requirements between accuracy and computational cost. In addition, we present a methodology for self-supervised pre-training of the encoder backbone via learning to predict randomly masked volumetric tokens using contextual information of visible tokens. We pre-train our framework on a cohort of $5050$ CT images, gathered from publicly available CT datasets, and present a systematic investigation of various components such as masking ratio and patch size that affect the representation learning capability and performance of downstream tasks. We validate the effectiveness of our pre-training approach by fine-tuning and testing our model on liver and liver tumor segmentation task using the Medical Segmentation Decathlon (MSD) dataset and achieve state-of-the-art performance in terms of various segmentation metrics. To demonstrate its generalizability, we train and test the model on BraTS 21 dataset for brain tumor segmentation using MRI images and outperform other methods in terms of Dice score. Code: https://github.com/Project-MONAI/research-contributions  
## cs.LG
---
### A lightweight and accurate YOLO-like network for small target detection in Aerial Imagery. (arXiv:2204.02325v1 [cs.CV])
- Authors : Alessandro Betti
- Link : [http://arxiv.org/abs/2204.02325](http://arxiv.org/abs/2204.02325)
> ABSTRACT  :  Despite the breakthrough deep learning performances achieved for automatic object detection, small target detection is still a challenging problem, especially when looking at fast and accurate solutions suitable for mobile or edge applications. In this work we present YOLO-S, a simple, fast and efficient network for small target detection. The architecture exploits a small feature extractor based on **Dark**net20, as well as skip connection, via both bypass and concatenation, and reshape-passthrough layer to alleviate the vanishing gradient problem, promote feature reuse across network and combine low-level positional information with more meaningful high-level information. To verify the performances of YOLO-S, we build "AIRES", a novel dataset for cAr detectIon fRom hElicopter imageS acquired in Europe, and set up experiments on both AIRES and VEDAI datasets, benchmarking this architecture with four baseline detectors. Furthermore, in order to handle efficiently the issue of data insufficiency and domain gap when dealing with a transfer learning strategy, we introduce a transitional learning task over a combined dataset based on DOTAv2 and VEDAI and demonstrate that can enhance the overall accuracy with respect to more general features transferred from COCO data. YOLO-S is from 25% to 50% faster than YOLOv3 and only 15-25% slower than Tiny-YOLOv3, outperforming also YOLOv3 in terms of accuracy in a wide range of experiments. Further simulations performed on SARD dataset demonstrate also its applicability to different scenarios such as for search and rescue operations. Besides, YOLO-S has an 87% decrease of parameter size and almost one half FLOPs of YOLOv3, making practical the deployment for low-power industrial applications.  
### ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer. (arXiv:2204.02389v1 [cs.CV])
- Authors : Ruohan Gao, Zilin Si, Yu Chang, Samuel Clarke, Jeannette Bohg, Li Fei, Wenzhen Yuan, Jiajun Wu
- Link : [http://arxiv.org/abs/2204.02389](http://arxiv.org/abs/2204.02389)
> ABSTRACT  :  Objects play a crucial role in our everyday activities. Though multisensory object-centric learning has shown great potential lately, the modeling of objects in prior work is rather unrealistic. ObjectFolder 1.0 is a recent dataset that introduces 100 virtualized objects with visual, acoustic, and tactile sensory data. However, the dataset is small in scale and the multisensory data is of limited quality, hampering generalization to real-world scenarios. We present ObjectFolder 2.0, a large-scale, multisensory dataset of common household objects in the form of **implicit neural representation**s that significantly enhances ObjectFolder 1.0 in three aspects. First, our dataset is 10 times larger in the amount of objects and orders of magnitude faster in rendering time. Second, we significantly improve the multisensory rendering quality for all three modalities. Third, we show that models learned from virtual objects in our dataset successfully transfer to their real-world counterparts in three challenging tasks: object scale estimation, contact localization, and shape reconstruction. ObjectFolder 2.0 offers a new path and testbed for multisensory learning in computer vision and robotics. The dataset is available at https://github.com/rhgao/ObjectFolder.  
### LDE-Net: L\'evy Induced Stochastic Differential Equation Equipped with Neural Network for Time Series Forecasting. (arXiv:2111.13164v4 [cs.LG] UPDATED)
- Authors : Luxuan Yang, Ting Gao, Yubin Lu, Jinqiao Duan, Tao Liu
- Link : [http://arxiv.org/abs/2111.13164](http://arxiv.org/abs/2111.13164)
> ABSTRACT  :  With the fast development of modern deep learning techniques, the study of dynamic systems and neural networks is increasingly benefiting each other in a lot of different ways. Since uncertainties often arise in real world observations, SDEs (stochastic differential equations) come to play an important role in scientific modeling. To this end, we employ a collection of SDEs with drift and diffusion terms approximated by neural networks to predict the trend of chaotic time series which has big jump properties. Our contributions are, first, we propose LDE-Net, which explores compounded SDEs with $\alpha$-stable L\'evy motion to model complex time series data and solve the problem through neural network approximation. Second, we theoretically prove the convergence of our algorithm with respect to hyper-parameters of the neural network, and obtain the error bound without curse of dimensionality. Finally, we illustrate our method by applying it to **real time** series data and find the accuracy increases through the use of non-Gaussian L\'evy processes. We also present detailed comparisons in terms of data patterns, various models, different shapes of L\'evy motion and the prediction lengths.  
### UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
- Authors : Ali Hatamizadeh, Ziyue Xu, Dong Yang, Wenqi Li, Holger Roth, Daguang Xu
- Link : [http://arxiv.org/abs/2204.00631](http://arxiv.org/abs/2204.00631)
> ABSTRACT  :  Vision Transformers (ViT)s have recently become popular due to their outstanding modeling capabilities, in particular for capturing long-range information, and scalability to dataset and model sizes which has led to state-of-the-art performance in various computer vision and medical image analysis tasks. In this work, we introduce a unified framework consisting of two architectures, dubbed UNetFormer, with a 3D **Swin** Transformer-based encoder and Convolutional Neural Network (CNN) and transformer-based decoders. In the proposed model, the encoder is linked to the decoder via skip connections at five different resolutions with deep supervision. The design of proposed architecture allows for meeting a wide range of trade-off requirements between accuracy and computational cost. In addition, we present a methodology for self-supervised pre-training of the encoder backbone via learning to predict randomly masked volumetric tokens using contextual information of visible tokens. We pre-train our framework on a cohort of $5050$ CT images, gathered from publicly available CT datasets, and present a systematic investigation of various components such as masking ratio and patch size that affect the representation learning capability and performance of downstream tasks. We validate the effectiveness of our pre-training approach by fine-tuning and testing our model on liver and liver tumor segmentation task using the Medical Segmentation Decathlon (MSD) dataset and achieve state-of-the-art performance in terms of various segmentation metrics. To demonstrate its generalizability, we train and test the model on BraTS 21 dataset for brain tumor segmentation using MRI images and outperform other methods in terms of Dice score. Code: https://github.com/Project-MONAI/research-contributions  
## cs.AI
---
### An End-to-End Integrated Computation and Communication Architecture for Goal-oriented Networking: A Perspective on Live Surveillance Video. (arXiv:2204.01987v1 [cs.NI])
- Authors : Suvadip Batabyal, Ozgur Ercetin
- Link : [http://arxiv.org/abs/2204.01987](http://arxiv.org/abs/2204.01987)
> ABSTRACT  :  **Real-time** video surveillance has become a crucial technology for smart cities, made possible through the large-scale deployment of mobile and fixed video cameras. In this paper, we propose situation-aware streaming, for real-time identification of important events from live-feeds at the source rather than a cloud based analysis. For this, we first identify the frames containing a specific situation and assign them a high scale-of-importance (SI). The identification is made at the source using a tiny neural network (having a small number of hidden layers), which incurs a small computational resource, albeit at the cost of accuracy. The frames with a high SI value are then streamed with a certain required Signal-to-Noise-Ratio (SNR) to retain the frame quality, while the remaining ones are transmitted with a small SNR. The received frames are then analyzed using a deep neural network (with many hidden layers) to extract the situation accurately. We show that the proposed scheme is able to reduce the required power consumption of the transmitter by 38.5% for 2160p (UHD) video, while achieving a classification accuracy of 97.5%, for the given situation.  
### UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
- Authors : Ali Hatamizadeh, Ziyue Xu, Dong Yang, Wenqi Li, Holger Roth, Daguang Xu
- Link : [http://arxiv.org/abs/2204.00631](http://arxiv.org/abs/2204.00631)
> ABSTRACT  :  Vision Transformers (ViT)s have recently become popular due to their outstanding modeling capabilities, in particular for capturing long-range information, and scalability to dataset and model sizes which has led to state-of-the-art performance in various computer vision and medical image analysis tasks. In this work, we introduce a unified framework consisting of two architectures, dubbed UNetFormer, with a 3D **Swin** Transformer-based encoder and Convolutional Neural Network (CNN) and transformer-based decoders. In the proposed model, the encoder is linked to the decoder via skip connections at five different resolutions with deep supervision. The design of proposed architecture allows for meeting a wide range of trade-off requirements between accuracy and computational cost. In addition, we present a methodology for self-supervised pre-training of the encoder backbone via learning to predict randomly masked volumetric tokens using contextual information of visible tokens. We pre-train our framework on a cohort of $5050$ CT images, gathered from publicly available CT datasets, and present a systematic investigation of various components such as masking ratio and patch size that affect the representation learning capability and performance of downstream tasks. We validate the effectiveness of our pre-training approach by fine-tuning and testing our model on liver and liver tumor segmentation task using the Medical Segmentation Decathlon (MSD) dataset and achieve state-of-the-art performance in terms of various segmentation metrics. To demonstrate its generalizability, we train and test the model on BraTS 21 dataset for brain tumor segmentation using MRI images and outperform other methods in terms of Dice score. Code: https://github.com/Project-MONAI/research-contributions  
# Paper List
---
## cs.CV
---
**140** new papers in cs.CV:-) 
1. QuadraLib: A Performant Quadratic Neural Network Library for Architecture Optimization and Design Exploration. (arXiv:2204.01701v1 [cs.LG])
2. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v1 [eess.IV])
3. Data and Physics Driven Learning Models for Fast MRI -- Fundamentals and Methodologies from CNN, GAN to Attention and Transformers. (arXiv:2204.01706v1 [eess.IV])
4. MRI-based Multi-task Decoupling Learning for Alzheimer's Disease Detection and MMSE Score Prediction: A Multi-site Validation. (arXiv:2204.01708v1 [eess.IV])
5. Forestry digital twin with machine learning in Landsat 7 data. (arXiv:2204.01709v1 [cs.LG])
6. Convolutional Neural Networks for Image Spam Detection. (arXiv:2204.01710v1 [cs.CV])
7. Single Image Internal Distribution Measurement Using Non-Local Variational Autoencoder. (arXiv:2204.01711v1 [eess.IV])
8. Histogram of Oriented Gradients Meet Deep Learning: A Novel Multi-task Deep Network for Medical Image Semantic Segmentation. (arXiv:2204.01712v1 [eess.IV])
9. Exemplar Learning for Medical Image Segmentation. (arXiv:2204.01713v1 [eess.IV])
10. Estimating Fine-Grained Noise Model via Contrastive Learning. (arXiv:2204.01716v1 [eess.IV])
11. RestoreX-AI: A Contrastive Approach towards Guiding Image **Restoration** via Explainable AI Systems. (arXiv:2204.01719v1 [eess.IV])
12. Distinguishing Homophenes Using Multi-Head Visual-Audio Memory for Lip Reading. (arXiv:2204.01725v1 [cs.CV])
13. Lip to Speech Synthesis with Visual Context Attentional GAN. (arXiv:2204.01726v1 [cs.CV])
14. Generalized Zero Shot Learning For Medical Image Classification. (arXiv:2204.01728v1 [eess.IV])
15. Analyzing the Effects of Handling Data Imbalance on Learned Features from Medical Images by Looking Into the Models. (arXiv:2204.01729v1 [eess.IV])
16. Transient motion classification through turbid volumes via parallelized single-photon detection and deep contrastive embedding. (arXiv:2204.01733v1 [eess.IV])
17. On Explaining Multimodal Hateful Meme Detection Models. (arXiv:2204.01734v1 [cs.CV])
18. Tracking Urbanization in Developing Regions with Remote Sensing Spatial-Temporal Super-Resolution. (arXiv:2204.01736v1 [eess.IV])
19. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v1 [eess.IV])
20. Face Recognition In Children: A Longitudinal Study. (arXiv:2204.01760v1 [cs.CV])
21. The First Principles of Deep Learning and Compression. (arXiv:2204.01782v1 [eess.IV])
22. Object Permanence Emerges in a Random Walk along Memory. (arXiv:2204.01784v1 [cs.CV])
23. Lightweight **HDR** Camera ISP for Robust Perception in Dynamic Illumination Conditions via Fourier Adversarial Networks. (arXiv:2204.01795v1 [cs.CV])
24. Revisiting Near/Remote Sensing with Geospatial Attention. (arXiv:2204.01807v1 [cs.CV])
25. Towards Infield Navigation: leveraging simulated data for crop row detection. (arXiv:2204.01811v1 [cs.CV])
26. High Efficiency Pedestrian Crossing Prediction. (arXiv:2204.01862v1 [cs.CV])
27. Truck Axle Detection with Convolutional Neural Networks. (arXiv:2204.01868v1 [cs.CV])
28. MonoTrack: Shuttle trajectory reconstruction from monocular badminton video. (arXiv:2204.01899v1 [cs.CV])
29. An Exploration of Active Learning for Affective Digital Phenotyping. (arXiv:2204.01915v1 [cs.LG])
30. Text Spotting Transformers. (arXiv:2204.01918v1 [cs.CV])
31. High-Quality Pluralistic Image Completion via Code Shared VQGAN. (arXiv:2204.01931v1 [cs.CV])
32. Attention Distraction: Watermark Removal Through Continual Learning with Selective Forgetting. (arXiv:2204.01934v1 [cs.CV])
33. Unified Implicit Neural Stylization. (arXiv:2204.01943v1 [cs.CV])
34. Towards On-Board Panoptic Segmentation of Multispectral Satellite Images. (arXiv:2204.01952v1 [cs.CV])
35. Autoregressive 3D Shape Generation via Canonical Mapping. (arXiv:2204.01955v1 [cs.CV])
36. FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes. (arXiv:2204.01960v1 [cs.CV])
37. Controllable Garment Transfer. (arXiv:2204.01965v1 [cs.CV])
38. PSDoodle: Searching for App Screens via Interactive Sketching. (arXiv:2204.01968v1 [cs.CV])
39. Region Rebalance for Long-Tailed Semantic Segmentation. (arXiv:2204.01969v1 [cs.CV])
40. Non-Local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation. (arXiv:2204.01971v1 [cs.CV])
41. Audio-visual multi-channel speech separation, dereverberation and recognition. (arXiv:2204.01977v1 [cs.SD])
42. Multi-Weight Respecification of Scan-specific Learning for Parallel Imaging. (arXiv:2204.01979v1 [eess.IV])
43. Bimodal Distributed Binarized Neural Networks. (arXiv:2204.02004v1 [cs.LG])
44. Learning Video Salient Object Detection Progressively from Unlabeled Videos. (arXiv:2204.02008v1 [cs.CV])
45. LatentGAN Autoencoder: Learning Disentangled Latent Distribution. (arXiv:2204.02010v1 [cs.CV])
46. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v1 [physics.ao-ph])
47. Learning to Reduce Information Bottleneck for Object Detection in Aerial Images. (arXiv:2204.02033v1 [cs.CV])
48. DT2I: Dense Text-to-Image Generation from Region Descriptions. (arXiv:2204.02035v1 [cs.CV])
49. An efficient real-time target tracking algorithm using adaptive feature fusion. (arXiv:2204.02054v1 [cs.CV])
50. Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation. (arXiv:2204.02070v1 [cs.LG])
51. Split Hierarchical Variational Compression. (arXiv:2204.02071v1 [eess.IV])
52. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v1 [cs.LG])
53. Semi-supervised Semantic Segmentation with Error Localization Network. (arXiv:2204.02078v1 [cs.CV])
54. **Real-time** Online Multi-Object Tracking in Compressed Domain. (arXiv:2204.02081v1 [cs.CV])
55. **Real-time** Hyperspectral Imaging in Hardware via Trained Metasurface Encoders. (arXiv:2204.02084v1 [cs.CV])
56. VocaLiST: An Audio-Visual Synchronisation Model for Lips and Voices. (arXiv:2204.02090v1 [cs.CV])
57. P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior. (arXiv:2204.02091v1 [cs.CV])
58. Birds of A Feather Flock Together: Category-Divergence Guidance for Domain Adaptive Segmentation. (arXiv:2204.02111v1 [cs.CV])
59. Overcoming Catastrophic Forgetting in Incremental Object Detection via Elastic Response Distillation. (arXiv:2204.02136v1 [cs.CV])
60. Detector-Free Weakly Supervised Group Activity Recognition. (arXiv:2204.02139v1 [cs.CV])
61. Dual-AI: Dual-path Action Interaction Learning for Group Activity Recognition. (arXiv:2204.02148v1 [cs.CV])
62. Automatic Image Content Extraction: Operationalizing Machine Learning in Humanistic Photographic Studies of Large Visual Archives. (arXiv:2204.02149v1 [cs.CV])
63. Leveraging Equivariant Features for Absolute Pose Regression. (arXiv:2204.02163v1 [cs.CV])
64. Joint Learning of Feature Extraction and Cost Aggregation for Semantic Correspondence. (arXiv:2204.02164v1 [cs.CV])
65. Multi-View Transformer for 3D Visual Grounding. (arXiv:2204.02174v1 [cs.CV])
66. Vision Transformer Equipped with Neural Resizer on Facial Expression Recognition Task. (arXiv:2204.02181v1 [cs.CV])
67. SNUG: Self-Supervised Neural Dynamic Garments. (arXiv:2204.02219v1 [cs.CV])
68. When Sparsity Meets Dynamic Convolution. (arXiv:2204.02227v1 [cs.CV])
69. IRON: Inverse Rendering by Optimizing Neural SDFs and Materials from Photometric Images. (arXiv:2204.02232v1 [cs.CV])
70. RBGNet: Ray-based Grouping for 3D Object Detection. (arXiv:2204.02251v1 [cs.CV])
71. The Probabilistic Normal Epipolar Constraint for Frame-To-Frame Rotation Optimization under Uncertain Feature Positions. (arXiv:2204.02256v1 [cs.CV])
72. Arbitrary-Scale Image Synthesis. (arXiv:2204.02273v1 [cs.CV])
73. Grounding of the Functional Object-Oriented Network in Industrial Tasks. (arXiv:2204.02274v1 [cs.RO])
74. Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets. (arXiv:2204.02275v1 [eess.IV])
75. Lost in Latent Space: Disentangled Models and the Challenge of Combinatorial Generalisation. (arXiv:2204.02283v1 [cs.LG])
76. SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering. (arXiv:2204.02285v1 [cs.CV])
77. Rethinking Visual Geo-localization for Large-Scale Applications. (arXiv:2204.02287v1 [cs.CV])
78. Neural Convolutional Surfaces. (arXiv:2204.02289v1 [cs.CV])
79. iSDF: Real-Time Neural Signed Distance Fields for Robot Perception. (arXiv:2204.02296v1 [cs.RO])
80. Learning Generalizable Dexterous Manipulation from Human Grasp Affordance. (arXiv:2204.02320v1 [cs.RO])
81. A lightweight and accurate YOLO-like network for small target detection in Aerial Imagery. (arXiv:2204.02325v1 [cs.CV])
82. CLEVR-X: A Visual Reasoning Dataset for Natural Language Explanations. (arXiv:2204.02380v1 [cs.CV])
83. Pyramid Frequency Network with Spatial Attention Residual Refinement Module for Monocular Depth Estimation. (arXiv:2204.02386v1 [cs.CV])
84. ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer. (arXiv:2204.02389v1 [cs.CV])
85. Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower. (arXiv:2204.02390v1 [cs.RO])
86. Action-Conditioned Contrastive Policy Pretraining. (arXiv:2204.02393v1 [cs.CV])
87. SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space. (arXiv:2204.02394v1 [cs.CV])
88. SALISA: Saliency-based Input Sampling for Efficient Video Object Detection. (arXiv:2204.02397v1 [cs.CV])
89. VerSe: A Vertebrae Labelling and Segmentation Benchmark for Multi-detector CT Images. (arXiv:2001.09193v6 [cs.CV] UPDATED)
90. Domain Generalization via Optimal Transport with Metric Similarity Learning. (arXiv:2007.10573v2 [cs.CV] UPDATED)
91. Classification and Segmentation of Pulmonary Lesions in CT Images Using a Combined VGG-XGBoost Method, and an Integrated Fuzzy Clustering-Level Set Technique. (arXiv:2101.00948v2 [cs.CV] UPDATED)
92. Common Limitations of Image Processing Metrics: A Picture Story. (arXiv:2104.05642v3 [cs.CV] UPDATED)
93. Enhanced Isotropy Maximization Loss: Seamless and High-Performance Out-of-Distribution Detection Simply Replacing the SoftMax Loss. (arXiv:2105.14399v10 [cs.LG] UPDATED)
94. Styleformer: Transformer based Generative Adversarial Networks with Style Vector. (arXiv:2106.07023v3 [cs.CV] UPDATED)
95. Training of deep cross-modality conversion models with a small dataset, and their application in megavoltage CT to kilovoltage CT conversion. (arXiv:2107.05238v2 [cs.CV] UPDATED)
96. Deep Image-based Illumination Harmonization. (arXiv:2108.00150v2 [cs.CV] UPDATED)
97. Blindly Assess Quality of In-the-Wild Videos via Quality-aware Pre-training and Motion Perception. (arXiv:2108.08505v2 [eess.IV] UPDATED)
98. Light Field-Based Underwater 3D Reconstruction Via Angular Resampling. (arXiv:2109.02116v3 [cs.CV] UPDATED)
99. Spatio-Temporal Recurrent Networks for Event-Based Optical Flow Estimation. (arXiv:2109.04871v2 [cs.CV] UPDATED)
100. Incremental Abstraction in Distributed Probabilistic SLAM Graphs. (arXiv:2109.06241v2 [cs.CV] UPDATED)
101. Distract Your Attention: Multi-head Cross Attention Network for Facial Expression Recognition. (arXiv:2109.07270v4 [cs.CV] UPDATED)
102. Markerless Suture Needle 6D Pose Tracking with Robust Uncertainty Estimation for Autonomous Minimally Invasive Robotic Surgery. (arXiv:2109.12722v2 [cs.RO] UPDATED)
103. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v4 [cs.CV] UPDATED)
104. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v2 [cs.LG] UPDATED)
105. Representational Continuity for Unsupervised Continual Learning. (arXiv:2110.06976v3 [cs.LG] UPDATED)
106. Deep Attention-guided Graph Clustering with Dual Self-supervision. (arXiv:2111.05548v2 [cs.CV] UPDATED)
107. A Multi-Stage model based on YOLOv3 for defect detection in PV panels based on IR and Visible Imaging by Unmanned Aerial Vehicle. (arXiv:2111.11709v2 [cs.CV] UPDATED)
108. Less is More: Generating Grounded Navigation Instructions from Landmarks. (arXiv:2111.12872v4 [cs.CV] UPDATED)
109. Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective. (arXiv:2111.14820v4 [cs.LG] UPDATED)
110. The Norm Must Go On: Dynamic Unsupervised Domain Adaptation by Normalization. (arXiv:2112.00463v2 [cs.CV] UPDATED)
111. GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v2 [cs.CV] UPDATED)
112. Spatio-temporal Relation Modeling for Few-shot Action Recognition. (arXiv:2112.05132v2 [cs.CV] UPDATED)
113. GAN-Supervised Dense Visual Alignment. (arXiv:2112.05143v2 [cs.CV] UPDATED)
114. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v2 [cs.CV] UPDATED)
115. It's All in the Head: Representation Knowledge Distillation through Classifier Sharing. (arXiv:2201.06945v2 [cs.CV] UPDATED)
116. Reliable Detection of Doppelg\"angers based on Deep Face Representations. (arXiv:2201.08831v2 [cs.CV] UPDATED)
117. SelfRecon: Self Reconstruction Your Digital Avatar from Monocular Video. (arXiv:2201.12792v2 [cs.CV] UPDATED)
118. Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v2 [eess.IV] UPDATED)
119. Adversarial Detection without Model Information. (arXiv:2202.04271v2 [cs.CV] UPDATED)
120. On the Complementarity of Images and Text for the Expression of Emotions in Social Media. (arXiv:2202.07427v2 [cs.CV] UPDATED)
121. MSSNet: Multi-Scale-Stage Network for Single Image Deblurring. (arXiv:2202.09652v3 [cs.CV] UPDATED)
122. Protecting Celebrities from DeepFake with Identity Consistency Transformer. (arXiv:2203.01318v3 [cs.CV] UPDATED)
123. S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular Image. (arXiv:2203.07732v2 [cs.CV] UPDATED)
124. ImageNet Challenging Classification with the Raspberry Pi: An Incremental Local Stochastic Gradient Descent Algorithm. (arXiv:2203.11853v2 [cs.CV] UPDATED)
125. Probing Representation Forgetting in Supervised and Unsupervised Continual Learning. (arXiv:2203.13381v2 [cs.LG] UPDATED)
126. Intelligent Masking: Deep Q-Learning for Context Encoding in Medical Image Analysis. (arXiv:2203.13865v2 [cs.CV] UPDATED)
127. Sylph: A Hypernetwork Framework for Incremental Few-shot Object Detection. (arXiv:2203.13903v2 [cs.CV] UPDATED)
128. Learning to Answer Questions in Dynamic Audio-Visual Scenarios. (arXiv:2203.14072v2 [cs.CV] UPDATED)
129. Towards Discriminative Representation: Multi-view Trajectory Contrastive Learning for Online Multi-object Tracking. (arXiv:2203.14208v2 [cs.CV] UPDATED)
130. Uni6D: A Unified CNN Framework without Projection Breakdown for 6D Pose Estimation. (arXiv:2203.14531v2 [cs.CV] UPDATED)
131. UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v3 [cs.CV] UPDATED)
132. Text2Pos: Text-to-Point-Cloud Cross-Modal Localization. (arXiv:2203.15125v2 [cs.CV] UPDATED)
133. Generalizing Few-Shot NAS with Gradient Matching. (arXiv:2203.15207v2 [cs.CV] UPDATED)
134. Semi-Supervised Learning of Semantic Correspondence with Pseudo-Labels. (arXiv:2203.16038v2 [cs.CV] UPDATED)
135. Large-Scale Pre-training for Person Re-identification with Noisy Labels. (arXiv:2203.16533v2 [cs.CV] UPDATED)
136. UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
137. Progressive Minimal Path Method with Embedded CNN. (arXiv:2204.00944v2 [cs.CV] UPDATED)
138. Adjusting for Bias with Procedural Data. (arXiv:2204.01108v2 [cs.CV] UPDATED)
139. Unsupervised Change Detection Based on Image Reconstruction Loss. (arXiv:2204.01200v2 [cs.CV] UPDATED)
140. Revisiting Document Image Dewarping by Grid Regularization. (arXiv:2203.16850v1 [eess.IV] CROSS LISTED)
## eess.IV
---
**30** new papers in eess.IV:-) 
1. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v1 [eess.IV])
2. Data and Physics Driven Learning Models for Fast MRI -- Fundamentals and Methodologies from CNN, GAN to Attention and Transformers. (arXiv:2204.01706v1 [eess.IV])
3. MRI-based Multi-task Decoupling Learning for Alzheimer's Disease Detection and MMSE Score Prediction: A Multi-site Validation. (arXiv:2204.01708v1 [eess.IV])
4. Single Image Internal Distribution Measurement Using Non-Local Variational Autoencoder. (arXiv:2204.01711v1 [eess.IV])
5. Histogram of Oriented Gradients Meet Deep Learning: A Novel Multi-task Deep Network for Medical Image Semantic Segmentation. (arXiv:2204.01712v1 [eess.IV])
6. Exemplar Learning for Medical Image Segmentation. (arXiv:2204.01713v1 [eess.IV])
7. Estimating Fine-Grained Noise Model via Contrastive Learning. (arXiv:2204.01716v1 [eess.IV])
8. RestoreX-AI: A Contrastive Approach towards Guiding Image **Restoration** via Explainable AI Systems. (arXiv:2204.01719v1 [eess.IV])
9. Generalized Zero Shot Learning For Medical Image Classification. (arXiv:2204.01728v1 [eess.IV])
10. Analyzing the Effects of Handling Data Imbalance on Learned Features from Medical Images by Looking Into the Models. (arXiv:2204.01729v1 [eess.IV])
11. Transient motion classification through turbid volumes via parallelized single-photon detection and deep contrastive embedding. (arXiv:2204.01733v1 [eess.IV])
12. Tracking Urbanization in Developing Regions with Remote Sensing Spatial-Temporal Super-Resolution. (arXiv:2204.01736v1 [eess.IV])
13. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v1 [eess.IV])
14. Face Recognition In Children: A Longitudinal Study. (arXiv:2204.01760v1 [cs.CV])
15. The First Principles of Deep Learning and Compression. (arXiv:2204.01782v1 [eess.IV])
16. Lightweight **HDR** Camera ISP for Robust Perception in Dynamic Illumination Conditions via Fourier Adversarial Networks. (arXiv:2204.01795v1 [cs.CV])
17. Multi-Weight Respecification of Scan-specific Learning for Parallel Imaging. (arXiv:2204.01979v1 [eess.IV])
18. Split Hierarchical Variational Compression. (arXiv:2204.02071v1 [eess.IV])
19. **Real-time** Online Multi-Object Tracking in Compressed Domain. (arXiv:2204.02081v1 [cs.CV])
20. **Real-time** Hyperspectral Imaging in Hardware via Trained Metasurface Encoders. (arXiv:2204.02084v1 [cs.CV])
21. Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets. (arXiv:2204.02275v1 [eess.IV])
22. digHolo : High-speed library for off-axis digital holography and Hermite-Gaussian decomposition. (arXiv:2204.02348v1 [eess.IV])
23. VerSe: A Vertebrae Labelling and Segmentation Benchmark for Multi-detector CT Images. (arXiv:2001.09193v6 [cs.CV] UPDATED)
24. Common Limitations of Image Processing Metrics: A Picture Story. (arXiv:2104.05642v3 [cs.CV] UPDATED)
25. Styleformer: Transformer based Generative Adversarial Networks with Style Vector. (arXiv:2106.07023v3 [cs.CV] UPDATED)
26. Blindly Assess Quality of In-the-Wild Videos via Quality-aware Pre-training and Motion Perception. (arXiv:2108.08505v2 [eess.IV] UPDATED)
27. Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v2 [eess.IV] UPDATED)
28. Restoring Vision through Retinal Implants -- A Systematic Literature Review. (arXiv:2203.17200v2 [q-bio.NC] UPDATED)
29. UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
30. Unsupervised Change Detection Based on Image Reconstruction Loss. (arXiv:2204.01200v2 [cs.CV] UPDATED)
## cs.LG
---
**183** new papers in cs.LG:-) 
1. QuadraLib: A Performant Quadratic Neural Network Library for Architecture Optimization and Design Exploration. (arXiv:2204.01701v1 [cs.LG])
2. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v1 [eess.IV])
3. Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v1 [cs.LG])
4. Heterogeneous Autoencoder Empowered by Quadratic Neurons. (arXiv:2204.01707v1 [cs.NE])
5. Forestry digital twin with machine learning in Landsat 7 data. (arXiv:2204.01709v1 [cs.LG])
6. Convolutional Neural Networks for Image Spam Detection. (arXiv:2204.01710v1 [cs.CV])
7. Exemplar Learning for Medical Image Segmentation. (arXiv:2204.01713v1 [eess.IV])
8. BigDL 2.0: Seamless Scaling of AI Pipelines from Laptops to Distributed Cluster. (arXiv:2204.01715v1 [cs.LG])
9. Meta-Learning Approaches for a One-Shot Collective-Decision Aggregation: Correctly Choosing how to Choose Correctly. (arXiv:2204.01721v1 [cs.LG])
10. Forward Signal Propagation Learning. (arXiv:2204.01723v1 [cs.LG])
11. Generalized Zero Shot Learning For Medical Image Classification. (arXiv:2204.01728v1 [eess.IV])
12. Analyzing the Effects of Handling Data Imbalance on Learned Features from Medical Images by Looking Into the Models. (arXiv:2204.01729v1 [eess.IV])
13. Gan-Based Joint Activity Detection and Channel Estimation For Grant-free Random Access. (arXiv:2204.01731v1 [cs.LG])
14. A high-order tensor completion algorithm based on Fully-Connected Tensor Network weighted optimization. (arXiv:2204.01732v1 [cs.LG])
15. Robust Stuttering Detection via Multi-task and Adversarial Learning. (arXiv:2204.01735v1 [eess.AS])
16. Feature robustness and sex differences in medical imaging: a case study in MRI-based Alzheimer's disease detection. (arXiv:2204.01737v1 [eess.IV])
17. Experimental quantum adversarial learning with programmable superconducting qubits. (arXiv:2204.01738v1 [quant-ph])
18. Deep learning for the rare-event rational design of 3D printed multi-material mechanical metamaterials. (arXiv:2204.01769v1 [cond-mat.mtrl-sci])
19. The First Principles of Deep Learning and Compression. (arXiv:2204.01782v1 [eess.IV])
20. The Fast Johnson-Lindenstrauss Transform is Even Faster. (arXiv:2204.01800v1 [cs.DS])
21. Towards Infield Navigation: leveraging simulated data for crop row detection. (arXiv:2204.01811v1 [cs.CV])
22. A Unit-Consistent Tensor Completion with Applications in Recommender Systems. (arXiv:2204.01815v1 [cs.IR])
23. Achieving Long-Term Fairness in Sequential Decision Making. (arXiv:2204.01819v1 [cs.LG])
24. Lifelong Self-Adaptation: Self-Adaptation Meets Lifelong Machine Learning. (arXiv:2204.01834v1 [cs.SE])
25. Deep Q-learning of global optimizer of multiply model parameters for viscoelastic imaging. (arXiv:2204.01844v1 [cs.LG])
26. Compliance Checking with NLI: Privacy Policies vs. Regulations. (arXiv:2204.01845v1 [cs.CL])
27. Probabilistic Embeddings with Laplacian Graph Priors. (arXiv:2204.01846v1 [cs.CL])
28. Bayesian Sequential Stacking Algorithm for Concurrently Designing Molecules and Synthetic Reaction Networks. (arXiv:2204.01847v1 [q-bio.BM])
29. Multilingual Abusiveness Identification on Code-Mixed Social Media Text. (arXiv:2204.01848v1 [cs.CL])
30. Automatic Text Summarization Methods: A Comprehensive Review. (arXiv:2204.01849v1 [cs.CL])
31. Robust Portfolio Design and Stock Price Prediction Using an Optimized LSTM Model. (arXiv:2204.01850v1 [q-fin.PM])
32. Dual Quaternion Ambisonics Array for Six-Degree-of-Freedom Acoustic Representation. (arXiv:2204.01851v1 [eess.AS])
33. A Data-Driven Framework for Identifying Investment Opportunities in Private Equity. (arXiv:2204.01852v1 [cs.LG])
34. A Survey on Graph Representation Learning Methods. (arXiv:2204.01855v1 [cs.LG])
35. Models and Mechanisms for Fairness in Location Data Processing. (arXiv:2204.01880v1 [cs.DB])
36. Policy Learning with Competing Agents. (arXiv:2204.01884v1 [stat.ML])
37. MonoTrack: Shuttle trajectory reconstruction from monocular badminton video. (arXiv:2204.01899v1 [cs.CV])
38. Learning to Adapt to Domain Shifts with Few-shot Samples in Anomalous Sound Detection. (arXiv:2204.01905v1 [cs.SD])
39. An Exploration of Active Learning for Affective Digital Phenotyping. (arXiv:2204.01915v1 [cs.LG])
40. Domain-Aware Contrastive Knowledge Transfer for Multi-domain Imbalanced Data. (arXiv:2204.01916v1 [cs.LG])
41. Online No-regret Model-Based Meta RL for Personalized Navigation. (arXiv:2204.01925v1 [cs.LG])
42. Nonlocal optimization of binary neural networks. (arXiv:2204.01935v1 [cs.LG])
43. Fault-Tolerant Deep Learning: A Hierarchical Perspective. (arXiv:2204.01942v1 [cs.AR])
44. Digital Twin Virtualization with Machine Learning for IoT and Beyond 5G Networks: Research Directions for Security and Optimal Control. (arXiv:2204.01950v1 [cs.NI])
45. GAIL-PT: A Generic Intelligent Penetration Testing Framework with Generative Adversarial Imitation Learning. (arXiv:2204.01975v1 [cs.CR])
46. Bimodal Distributed Binarized Neural Networks. (arXiv:2204.02004v1 [cs.LG])
47. Fact Checking with Insufficient Evidence. (arXiv:2204.02007v1 [cs.CL])
48. LatentGAN Autoencoder: Learning Disentangled Latent Distribution. (arXiv:2204.02010v1 [cs.CV])
49. RL4ReAl: Reinforcement Learning for Register Allocation. (arXiv:2204.02013v1 [cs.LG])
50. A Survey on Dropout Methods and Experimental Verification in Recommendation. (arXiv:2204.02027v1 [cs.LG])
51. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v1 [physics.ao-ph])
52. Automating Reinforcement Learning with Example-based Resets. (arXiv:2204.02041v1 [cs.LG])
53. Spread Spurious Attribute: Improving Worst-group Accuracy with Spurious Attribute Estimation. (arXiv:2204.02070v1 [cs.LG])
54. Split Hierarchical Variational Compression. (arXiv:2204.02071v1 [eess.IV])
55. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v1 [cs.LG])
56. P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior. (arXiv:2204.02091v1 [cs.CV])
57. A machine learning-based framework for high resolution mapping of PM2.5 in Tehran, Iran, using MAIAC AOD data. (arXiv:2204.02093v1 [cs.LG])
58. Self-supervised learning -- A way to minimize time and effort for precision agriculture?. (arXiv:2204.02100v1 [cs.LG])
59. GP-BART: a novel Bayesian additive regression trees approach using Gaussian processes. (arXiv:2204.02112v1 [stat.ME])
60. MetaAudio: A Few-Shot Audio Classification Benchmark. (arXiv:2204.02121v1 [cs.SD])
61. SemanticCAP: Chromatin Accessibility Prediction Enhanced by Features Learning from a Language Model. (arXiv:2204.02130v1 [q-bio.GN])
62. Positive and Negative Critiquing for VAE-based Recommenders. (arXiv:2204.02162v1 [cs.IR])
63. Hybrid Predictive Coding: Inferring, Fast and Slow. (arXiv:2204.02169v1 [q-bio.NC])
64. Optimising Communication Overhead in Federated Learning Using NSGA-II. (arXiv:2204.02183v1 [cs.NE])
65. Penalised FTRL With Time-Varying Constraints. (arXiv:2204.02197v1 [cs.LG])
66. Abstractive summarization of hospitalisation histories with transformer networks. (arXiv:2204.02208v1 [cs.CL])
67. Model Based Meta Learning of Critics for Policy Gradients. (arXiv:2204.02210v1 [cs.LG])
68. SNUG: Self-Supervised Neural Dynamic Garments. (arXiv:2204.02219v1 [cs.CV])
69. Neural Computing with Coherent Laser Networks. (arXiv:2204.02224v1 [physics.optics])
70. A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions. (arXiv:2204.02241v1 [cs.LG])
71. Normalizing Flow-based Day-Ahead Wind Power Scenario Generation for Profitable and Reliable Delivery Commitments by Wind Farm Operators. (arXiv:2204.02242v1 [math.OC])
72. Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization. (arXiv:2204.02246v1 [cs.LG])
73. Improving Generalizability in Implicitly Abusive Language Detection with Concept Activation Vectors. (arXiv:2204.02261v1 [cs.CL])
74. Multilingual and Multimodal Abuse Detection. (arXiv:2204.02263v1 [eess.AS])
75. Multi-Agent Distributed Reinforcement Learning for Making Decentralized Offloading Decisions. (arXiv:2204.02267v1 [cs.MA])
76. Learning to Bid Long-Term: Multi-Agent Reinforcement Learning with Long-Term and Sparse Reward in Repeated Auction Games. (arXiv:2204.02268v1 [cs.LG])
77. Deep surrogate accelerated delayed-acceptance HMC for Bayesian inference of spatio-temporal heat fluxes in rotating disc systems. (arXiv:2204.02272v1 [math.NA])
78. Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets. (arXiv:2204.02275v1 [eess.IV])
79. Cancer Subtyping via Embedded Unsupervised Learning on Transcriptomics Data. (arXiv:2204.02278v1 [cs.LG])
80. Design Guidelines for Inclusive Speaker Verification Evaluation Datasets. (arXiv:2204.02281v1 [eess.AS])
81. Lost in Latent Space: Disentangled Models and the Challenge of Combinatorial Generalisation. (arXiv:2204.02283v1 [cs.LG])
82. SwapMix: Diagnosing and Regularizing the Over-Reliance on Visual Context in Visual Question Answering. (arXiv:2204.02285v1 [cs.CV])
83. Aggregating distribution forecasts from deep ensembles. (arXiv:2204.02291v1 [stat.ML])
84. Is it worth the effort? Understanding and contextualizing physical metrics in soccer. (arXiv:2204.02313v1 [stat.ML])
85. Learning new physics efficiently with nonparametric methods. (arXiv:2204.02317v1 [hep-ph])
86. Learning Generalizable Dexterous Manipulation from Human Grasp Affordance. (arXiv:2204.02320v1 [cs.RO])
87. SAFARI: Sparsity enabled Federated Learning with Limited and Unreliable Communications. (arXiv:2204.02321v1 [cs.DC])
88. Nearly minimax robust estimator of the mean vector by iterative spectral dimension reduction. (arXiv:2204.02323v1 [math.ST])
89. A lightweight and accurate YOLO-like network for small target detection in Aerial Imagery. (arXiv:2204.02325v1 [cs.CV])
90. Can language models learn from explanations in context?. (arXiv:2204.02329v1 [cs.CL])
91. Multi-Scale Representation Learning on Proteins. (arXiv:2204.02337v1 [cs.LG])
92. MGDCF: Distance Learning via Markov Graph Diffusion for Neural Collaborative Filtering. (arXiv:2204.02338v1 [cs.SI])
93. IFTT-PIN: Demonstrating the Self-Calibration Paradigm on a PIN-Entry Task. (arXiv:2204.02341v1 [cs.HC])
94. Test Against High-Dimensional Uncertainties: Accelerated Evaluation of Autonomous Vehicles with Deep Importance Sampling. (arXiv:2204.02351v1 [cs.LG])
95. Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs. (arXiv:2204.02362v1 [cs.AI])
96. Too Big to Fail? Active Few-Shot Learning Guided Logic Synthesis. (arXiv:2204.02368v1 [cs.LG])
97. Jump-Start Reinforcement Learning. (arXiv:2204.02372v1 [cs.LG])
98. Data-driven Influence Based Clustering of Dynamical Systems. (arXiv:2204.02373v1 [eess.SY])
99. Hear No Evil: Towards Adversarial Robustness of Automatic Speech Recognition via Multi-Task Learning. (arXiv:2204.02381v1 [eess.AS])
100. Learning Speech Emotion Representations in the Quaternion Domain. (arXiv:2204.02385v1 [eess.AS])
101. ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer. (arXiv:2204.02389v1 [cs.CV])
102. Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower. (arXiv:2204.02390v1 [cs.RO])
103. Action-Conditioned Contrastive Policy Pretraining. (arXiv:2204.02393v1 [cs.CV])
104. SE(3)-Equivariant Attention Networks for Shape Reconstruction in Function Space. (arXiv:2204.02394v1 [cs.CV])
105. Predict then Propagate: Graph Neural Networks meet Personalized PageRank. (arXiv:1810.05997v6 [cs.LG] UPDATED)
106. Online Learning with Continuous Variations: Dynamic Regret and Reductions. (arXiv:1902.07286v4 [cs.LG] UPDATED)
107. Graph Transfer Learning via Adversarial Domain Adaptation with Graph Convolution. (arXiv:1909.01541v3 [cs.LG] UPDATED)
108. Diffusion Improves Graph Learning. (arXiv:1911.05485v6 [cs.SI] UPDATED)
109. CDPA: Common and Distinctive Pattern Analysis between High-dimensional Datasets. (arXiv:1912.09989v4 [stat.ML] UPDATED)
110. Zeroth-Order Algorithms for Nonconvex Minimax Problems with Improved Complexities. (arXiv:2001.07819v2 [stat.ML] UPDATED)
111. Directional Message Passing for Molecular Graphs. (arXiv:2003.03123v2 [cs.LG] UPDATED)
112. A Survey of Adversarial Learning on Graphs. (arXiv:2003.05730v3 [cs.LG] UPDATED)
113. Stochastic Shortest Path with Adversarially Changing Costs. (arXiv:2006.11561v4 [cs.LG] UPDATED)
114. Scaling Graph Neural Networks with Approximate PageRank. (arXiv:2007.01570v2 [cs.LG] UPDATED)
115. Domain Generalization via Optimal Transport with Metric Similarity Learning. (arXiv:2007.10573v2 [cs.CV] UPDATED)
116. Deciding Fast and Slow: The Role of Cognitive Biases in AI-assisted Decision-making. (arXiv:2010.07938v2 [cs.HC] UPDATED)
117. Fast and Uncertainty-Aware Directional Message Passing for Non-Equilibrium Molecules. (arXiv:2011.14115v3 [cs.LG] UPDATED)
118. Scalable Verification of Quantized Neural Networks (Technical Report). (arXiv:2012.08185v2 [cs.AI] UPDATED)
119. DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning. (arXiv:2102.11492v3 [cs.LG] UPDATED)
120. Enhanced Isotropy Maximization Loss: Seamless and High-Performance Out-of-Distribution Detection Simply Replacing the SoftMax Loss. (arXiv:2105.14399v10 [cs.LG] UPDATED)
121. GemNet: Universal Directional Graph Neural Networks for Molecules. (arXiv:2106.08903v9 [physics.comp-ph] UPDATED)
122. Pruning Randomly Initialized Neural Networks with Iterative Randomization. (arXiv:2106.09269v2 [cs.LG] UPDATED)
123. Scalable Optimal Transport in High Dimensions for Graph Distances, Embedding Alignment, and More. (arXiv:2107.06876v2 [cs.LG] UPDATED)
124. Robust Online Control with Model Misspecification. (arXiv:2107.07732v2 [math.OC] UPDATED)
125. "Adversarial Examples" for Proof-of-Learning. (arXiv:2108.09454v3 [cs.CR] UPDATED)
126. Impact of Evaluation Methodologies on Code Summarization. (arXiv:2108.09619v2 [cs.SE] UPDATED)
127. Modeling time evolving COVID-19 uncertainties with density dependent asymptomatic infections and social reinforcement. (arXiv:2108.10029v2 [stat.ML] UPDATED)
128. LightAutoML: AutoML Solution for a Large Financial Services Ecosystem. (arXiv:2109.01528v2 [cs.LG] UPDATED)
129. YAHPO Gym -- An Efficient Multi-Objective Multi-Fidelity Benchmark for Hyperparameter Optimization. (arXiv:2109.03670v3 [cs.LG] UPDATED)
130. An automatic differentiation system for the age of differential privacy. (arXiv:2109.10573v2 [cs.LG] UPDATED)
131. Recurrent Neural Networks for Partially Observed Dynamical Systems. (arXiv:2109.11629v2 [cs.LG] UPDATED)
132. Learning to Superoptimize Real-world Programs. (arXiv:2109.13498v2 [cs.LG] UPDATED)
133. Efficient Identification of Butterfly Sparse Matrix Factorizations. (arXiv:2110.01230v3 [cs.LG] UPDATED)
134. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v4 [cs.CV] UPDATED)
135. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v2 [cs.LG] UPDATED)
136. Graph Neural Network Guided Local Search for the Traveling Salesperson Problem. (arXiv:2110.05291v3 [cs.LG] UPDATED)
137. Representational Continuity for Unsupervised Continual Learning. (arXiv:2110.06976v3 [cs.LG] UPDATED)
138. SpecSinGAN: Sound Effect Variation Synthesis Using Single-Image GANs. (arXiv:2110.07311v2 [cs.SD] UPDATED)
139. Data-driven intrinsic localized mode detection and classification in one-dimensional crystal lattice model. (arXiv:2110.12870v2 [cond-mat.mtrl-sci] UPDATED)
140. Towards a theory of quantum gravity from neural networks. (arXiv:2111.00903v3 [cs.LG] UPDATED)
141. DVS: Deep Visibility Series and its Application in Construction Cost Index Forecasting. (arXiv:2111.04071v2 [cs.LG] UPDATED)
142. Directional Message Passing on Molecular Graphs via Synthetic Coordinates. (arXiv:2111.04718v4 [cs.LG] UPDATED)
143. DeepGuard: A Framework for Safeguarding Autonomous Driving Systems from Inconsistent Behavior. (arXiv:2111.09533v2 [cs.LG] UPDATED)
144. A Multi-Stage model based on YOLOv3 for defect detection in PV panels based on IR and Visible Imaging by Unmanned Aerial Vehicle. (arXiv:2111.11709v2 [cs.CV] UPDATED)
145. LDE-Net: L\'evy Induced Stochastic Differential Equation Equipped with Neural Network for Time Series Forecasting. (arXiv:2111.13164v4 [cs.LG] UPDATED)
146. Impact of classification difficulty on the weight matrices spectra in Deep Learning and application to early-stopping. (arXiv:2111.13331v2 [cs.LG] UPDATED)
147. Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective. (arXiv:2111.14820v4 [cs.LG] UPDATED)
148. VisRuler: Visual Analytics for Extracting Decision Rules from Bagged and Boosted Decision Trees. (arXiv:2112.00334v2 [cs.LG] UPDATED)
149. Structural Sieves. (arXiv:2112.01377v2 [econ.EM] UPDATED)
150. GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v2 [cs.CV] UPDATED)
151. A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v2 [eess.SY] UPDATED)
152. Directed Speech Separation for Automatic Speech Recognition of Long Form Conversational Speech. (arXiv:2112.05863v2 [eess.AS] UPDATED)
153. Tackling the Generative Learning Trilemma with Denoising Diffusion GANs. (arXiv:2112.07804v2 [cs.LG] UPDATED)
154. Empirical Evaluation of Deep Learning Models for Knowledge Tracing: Of Hyperparameters and Metrics on Performance and Replicability. (arXiv:2112.15072v4 [cs.LG] UPDATED)
155. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v2 [cs.CV] UPDATED)
156. TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data. (arXiv:2201.07284v4 [cs.LG] UPDATED)
157. FedComm: Federated Learning as a Medium for Covert Communication. (arXiv:2201.08786v2 [cs.CR] UPDATED)
158. Using a Novel COVID-19 Calculator to Measure Positive U.S. Socio-Economic Impact of a COVID-19 Pre-Screening Solution (AI/ML). (arXiv:2201.11109v2 [cs.AI] UPDATED)
159. Deep learning fluid flow reconstruction around arbitrary two-dimensional objects from sparse sensors using conformal mappings. (arXiv:2202.03798v2 [physics.flu-dyn] UPDATED)
160. Adversarial Graph Contrastive Learning with Information Regularization. (arXiv:2202.06491v3 [cs.LG] UPDATED)
161. Understanding and Improving Graph Injection Attack by Promoting Unnoticeability. (arXiv:2202.08057v2 [cs.LG] UPDATED)
162. Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients. (arXiv:2202.08132v2 [cs.LG] UPDATED)
163. Benchmarking Generative Latent Variable Models for Speech. (arXiv:2202.12707v2 [eess.AS] UPDATED)
164. S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular Image. (arXiv:2203.07732v2 [cs.CV] UPDATED)
165. ImageNet Challenging Classification with the Raspberry Pi: An Incremental Local Stochastic Gradient Descent Algorithm. (arXiv:2203.11853v2 [cs.CV] UPDATED)
166. Probing Representation Forgetting in Supervised and Unsupervised Continual Learning. (arXiv:2203.13381v2 [cs.LG] UPDATED)
167. Intelligent Masking: Deep Q-Learning for Context Encoding in Medical Image Analysis. (arXiv:2203.13865v2 [cs.CV] UPDATED)
168. UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v3 [cs.CV] UPDATED)
169. On-the-fly Feature Based Speaker Adaptation for Dysarthric and Elderly Speech Recognition. (arXiv:2203.14593v2 [eess.AS] UPDATED)
170. Text2Pos: Text-to-Point-Cloud Cross-Modal Localization. (arXiv:2203.15125v2 [cs.CV] UPDATED)
171. Generalizing Few-Shot NAS with Gradient Matching. (arXiv:2203.15207v2 [cs.CV] UPDATED)
172. Towards Spatio-Temporal Aware Traffic Time Series Forecasting--Full Version. (arXiv:2203.15737v3 [cs.LG] UPDATED)
173. PerfectDou: Dominating DouDizhu with Perfect Information Distillation. (arXiv:2203.16406v2 [cs.AI] UPDATED)
174. Recent improvements of ASR models in the face of adversarial attacks. (arXiv:2203.16536v2 [cs.CR] UPDATED)
175. Training strategy for a lightweight countermeasure model for automatic speaker verification. (arXiv:2203.17031v2 [cs.SD] UPDATED)
176. UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
177. A Reinforcement Learning Approach to Sensing Design in Resource-Constrained Wireless Networked Control Systems. (arXiv:2204.00703v2 [eess.SY] UPDATED)
178. Taking ROCKET on an Efficiency Mission: Multivariate Time Series Classification with LightWaveS. (arXiv:2204.01379v2 [cs.LG] UPDATED)
179. Aligned Weight Regularizers for Pruning Pretrained Neural Networks. (arXiv:2204.01385v2 [cs.CL] UPDATED)
180. A single Long Short-Term Memory network for enhancing the prediction of path-dependent plasticity with material heterogeneity and anisotropy. (arXiv:2204.01466v2 [cond-mat.dis-nn] UPDATED)
181. Matrix Completion with Sparse Noisy Rows. (arXiv:2204.01530v2 [cs.LG] UPDATED)
182. Survey of Matrix Completion Algorithms. (arXiv:2204.01532v2 [cs.LG] UPDATED)
183. Nonsmooth Implicit Differentiation for Machine Learning and Optimization. (arXiv:2106.04350v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**78** new papers in cs.AI:-) 
1. Meta-Learning Approaches for a One-Shot Collective-Decision Aggregation: Correctly Choosing how to Choose Correctly. (arXiv:2204.01721v1 [cs.LG])
2. Lip to Speech Synthesis with Visual Context Attentional GAN. (arXiv:2204.01726v1 [cs.CV])
3. Experimental quantum adversarial learning with programmable superconducting qubits. (arXiv:2204.01738v1 [quant-ph])
4. Reducing SAT to Max2XOR. (arXiv:2204.01774v1 [cs.AI])
5. Achieving Long-Term Fairness in Sequential Decision Making. (arXiv:2204.01819v1 [cs.LG])
6. Coarse-to-Fine Sparse Sequential Recommendation. (arXiv:2204.01839v1 [cs.IR])
7. Applying Automatic Text Summarization for Fake News Detection. (arXiv:2204.01841v1 [cs.CL])
8. A Data-Driven Framework for Identifying Investment Opportunities in Private Equity. (arXiv:2204.01852v1 [cs.LG])
9. Dynatask: A Framework for Creating Dynamic AI Benchmark Tasks. (arXiv:2204.01906v1 [cs.CL])
10. Domain-Aware Contrastive Knowledge Transfer for Multi-domain Imbalanced Data. (arXiv:2204.01916v1 [cs.LG])
11. Fault-Tolerant Deep Learning: A Hierarchical Perspective. (arXiv:2204.01942v1 [cs.AR])
12. Data Augmentation for Intent Classification with Off-the-shelf Large Language Models. (arXiv:2204.01959v1 [cs.CL])
13. FaceSigns: Semi-Fragile Neural Watermarks for Media Authentication and Countering Deepfakes. (arXiv:2204.01960v1 [cs.CV])
14. Non-Local Latent Relation Distillation for Self-Adaptive 3D Human Pose Estimation. (arXiv:2204.01971v1 [cs.CV])
15. An End-to-End Integrated Computation and Communication Architecture for Goal-oriented Networking: A Perspective on Live Surveillance Video. (arXiv:2204.01987v1 [cs.NI])
16. ELECRec: Training Sequential Recommenders as Discriminators. (arXiv:2204.02011v1 [cs.AI])
17. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v1 [physics.ao-ph])
18. $\textit{latent}$-GLAT: Glancing at Latent Variables for Parallel Text Generation. (arXiv:2204.02030v1 [cs.CL])
19. HyperBox: A Supervised Approach for Hypernym Discovery using Box Embeddings. (arXiv:2204.02058v1 [cs.CL])
20. Design considerations for a hierarchical semantic compositional framework for medical natural language understanding. (arXiv:2204.02067v1 [cs.CL])
21. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v1 [cs.LG])
22. P3Depth: Monocular Depth Estimation with a Piecewise Planarity Prior. (arXiv:2204.02091v1 [cs.CV])
23. Collective control of modular soft robots via embodied Spiking Neural Cellular Automata. (arXiv:2204.02099v1 [cs.RO])
24. Positive and Negative Critiquing for VAE-based Recommenders. (arXiv:2204.02162v1 [cs.IR])
25. Hybrid Predictive Coding: Inferring, Fast and Slow. (arXiv:2204.02169v1 [q-bio.NC])
26. Multilinguals at SemEval-2022 Task 11: Transformer Based Architecture for Complex NER. (arXiv:2204.02173v1 [cs.CL])
27. Towards Power-Efficient Design of Myoelectric Controller based on Evolutionary Computation. (arXiv:2204.02179v1 [cs.NE])
28. Optimising Communication Overhead in Federated Learning Using NSGA-II. (arXiv:2204.02183v1 [cs.NE])
29. Automating Staged Rollout with Reinforcement Learning. (arXiv:2204.02189v1 [cs.SE])
30. Abstractive summarization of hospitalisation histories with transformer networks. (arXiv:2204.02208v1 [cs.CL])
31. Model Based Meta Learning of Critics for Policy Gradients. (arXiv:2204.02210v1 [cs.LG])
32. When Sparsity Meets Dynamic Convolution. (arXiv:2204.02227v1 [cs.CV])
33. A Set Membership Approach to Discovering Feature Relevance and Explaining Neural Classifier Decisions. (arXiv:2204.02241v1 [cs.LG])
34. Continuously Discovering Novel Strategies via Reward-Switching Policy Optimization. (arXiv:2204.02246v1 [cs.LG])
35. Sufficient Reasons for A Zero-Day Intrusion Detection Artificial Immune System. (arXiv:2204.02255v1 [cs.AI])
36. Deep Clustering via Center-Oriented Margin Free-Triplet Loss for Skin Lesion Detection in Highly Imbalanced Datasets. (arXiv:2204.02275v1 [eess.IV])
37. Lost in Latent Space: Disentangled Models and the Challenge of Combinatorial Generalisation. (arXiv:2204.02283v1 [cs.LG])
38. ZETAR: Modeling and Computational Design of Strategic and Adaptive Compliance Policies. (arXiv:2204.02294v1 [cs.GT])
39. Improving Human-AI Partnerships in Child Welfare: Understanding Worker Practices, Challenges, and Desires for Algorithmic Decision Support. (arXiv:2204.02310v1 [cs.HC])
40. Can language models learn from explanations in context?. (arXiv:2204.02329v1 [cs.CL])
41. Multi-Scale Representation Learning on Proteins. (arXiv:2204.02337v1 [cs.LG])
42. IFTT-PIN: Demonstrating the Self-Calibration Paradigm on a PIN-Entry Task. (arXiv:2204.02341v1 [cs.HC])
43. Scientometric Review of Artificial Intelligence for Operations & Maintenance of Wind Turbines: The Past, Present and Future. (arXiv:2204.02360v1 [cs.AI])
44. Challenges and Opportunities of Edge AI for Next-Generation Implantable BMIs. (arXiv:2204.02362v1 [cs.AI])
45. Too Big to Fail? Active Few-Shot Learning Guided Logic Synthesis. (arXiv:2204.02368v1 [cs.LG])
46. Learning Pneumatic Non-Prehensile Manipulation with a Mobile Blower. (arXiv:2204.02390v1 [cs.RO])
47. Deep Interactive Motion Prediction and Planning: Playing Games with Motion Prediction Models. (arXiv:2204.02392v1 [cs.RO])
48. Diffusion Improves Graph Learning. (arXiv:1911.05485v6 [cs.SI] UPDATED)
49. A Survey of Adversarial Learning on Graphs. (arXiv:2003.05730v3 [cs.LG] UPDATED)
50. Scalable Verification of Quantized Neural Networks (Technical Report). (arXiv:2012.08185v2 [cs.AI] UPDATED)
51. DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning. (arXiv:2102.11492v3 [cs.LG] UPDATED)
52. Enhanced Isotropy Maximization Loss: Seamless and High-Performance Out-of-Distribution Detection Simply Replacing the SoftMax Loss. (arXiv:2105.14399v10 [cs.LG] UPDATED)
53. Pruning Randomly Initialized Neural Networks with Iterative Randomization. (arXiv:2106.09269v2 [cs.LG] UPDATED)
54. MarIA: Spanish Language Models. (arXiv:2107.07253v5 [cs.CL] UPDATED)
55. "Adversarial Examples" for Proof-of-Learning. (arXiv:2108.09454v3 [cs.CR] UPDATED)
56. Fusing task-oriented and open-domain dialogues in conversational agents. (arXiv:2109.04137v3 [cs.CL] UPDATED)
57. Learning to Superoptimize Real-world Programs. (arXiv:2109.13498v2 [cs.LG] UPDATED)
58. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v4 [cs.CV] UPDATED)
59. Transform2Act: Learning a Transform-and-Control Policy for Efficient Agent Design. (arXiv:2110.03659v2 [cs.LG] UPDATED)
60. DVS: Deep Visibility Series and its Application in Construction Cost Index Forecasting. (arXiv:2111.04071v2 [cs.LG] UPDATED)
61. Deep Attention-guided Graph Clustering with Dual Self-supervision. (arXiv:2111.05548v2 [cs.CV] UPDATED)
62. DeepGuard: A Framework for Safeguarding Autonomous Driving Systems from Inconsistent Behavior. (arXiv:2111.09533v2 [cs.LG] UPDATED)
63. Towards Robust and Adaptive Motion Forecasting: A Causal Representation Perspective. (arXiv:2111.14820v4 [cs.LG] UPDATED)
64. Gradient and Projection Free Distributed Online Min-Max Resource Optimization. (arXiv:2112.03896v2 [cs.IT] UPDATED)
65. A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v2 [eess.SY] UPDATED)
66. Language-Agnostic Website Embedding and Classification. (arXiv:2201.03677v2 [cs.CL] UPDATED)
67. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v2 [cs.CV] UPDATED)
68. Using a Novel COVID-19 Calculator to Measure Positive U.S. Socio-Economic Impact of a COVID-19 Pre-Screening Solution (AI/ML). (arXiv:2201.11109v2 [cs.AI] UPDATED)
69. Benchmarking Generative Latent Variable Models for Speech. (arXiv:2202.12707v2 [eess.AS] UPDATED)
70. Continual Sequence Generation with Adaptive Compositional Modules. (arXiv:2203.10652v2 [cs.CL] UPDATED)
71. Probing Representation Forgetting in Supervised and Unsupervised Continual Learning. (arXiv:2203.13381v2 [cs.LG] UPDATED)
72. CICERO: A Dataset for Contextualized Commonsense Inference in Dialogues. (arXiv:2203.13926v2 [cs.CL] UPDATED)
73. On-the-fly Feature Based Speaker Adaptation for Dysarthric and Elderly Speech Recognition. (arXiv:2203.14593v2 [eess.AS] UPDATED)
74. PerfectDou: Dominating DouDizhu with Perfect Information Distillation. (arXiv:2203.16406v2 [cs.AI] UPDATED)
75. Recent improvements of ASR models in the face of adversarial attacks. (arXiv:2203.16536v2 [cs.CR] UPDATED)
76. UNetFormer: A Unified Vision Transformer Model and Pre-Training Framework for 3D Medical Image Segmentation. (arXiv:2204.00631v2 [eess.IV] UPDATED)
77. Pragmatic constraints and pronoun reference disambiguation: the possible and the impossible. (arXiv:2204.01166v2 [cs.CL] UPDATED)
78. Nonsmooth Implicit Differentiation for Machine Learning and Optimization. (arXiv:2106.04350v2 [cs.LG] CROSS LISTED)

