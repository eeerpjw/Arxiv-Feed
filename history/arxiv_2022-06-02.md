# Your interest papers
---
## cs.CV
---
### Intensity Mapping Functions For **HDR** Panorama Imaging: Weighted Histogram Averaging. (arXiv:2111.07283v3 [cs.CV] UPDATED)
- Authors : Yilun Xu, Zhengguo Li, Weihai Chen, Changyun Wen
- Link : [http://arxiv.org/abs/2111.07283](http://arxiv.org/abs/2111.07283)
> ABSTRACT  :  It is challenging to stitch multiple images with different **exposure**s due to possible color distortion and loss of details in the brightest and **dark**est regions of input images. In this paper, a novel intensity mapping algorithm is first proposed by introducing a new concept of weighted histogram averaging (WHA). The proposed WHA algorithm leverages the correspondence between the histogram bins of two images which are built up by using the non-decreasing property of the intensity mapping functions (IMFs). The WHA algorithm is then adopted to synthesize a set of differently exposed panorama images. The intermediate panorama images are finally fused via a state-of-the-art multi-scale **exposure** fusion (MEF) algorithm to produce the final panorama image. Extensive experiments indicate that the proposed WHA algorithm significantly surpasses the related state-of-the-art intensity mapping methods. The proposed **high dynamic range** (**HDR**) stitching algorithm also preserves details in the brightest and **dark**est regions of the input images well. The related materials will be publicly accessible at https://github.com/yilun-xu/WHA for reproducible research.  
### GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v2 [cs.CV] UPDATED)
- Authors : Peng Zheng, Huazhu Fu, Ping Fan, Qi Fan, Jie Qin, Luc Van
- Link : [http://arxiv.org/abs/2205.15469](http://arxiv.org/abs/2205.15469)
> ABSTRACT  :  In this paper, we present a novel end-to-end group collaborative learning network, termed GCoNet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. The proposed GCoNet+ achieves the new state-of-the-art performance for co-salient object detection (CoSOD) through mining consensus representations based on the following two essential criteria: 1) intra-group compactness to better formulate the consistency among co-salient objects by capturing their inherent shared attributes using our novel group affinity module (GAM); 2) inter-group separability to effectively suppress the influence of noisy objects on the output by introducing our new group collaborating module (GCM) conditioning on the inconsistent consensus. To further improve the accuracy, we design a series of simple yet effective components as follows: i) a recurrent auxiliary classification module (RACM) promoting the model learning at the semantic level; ii) a confidence **enhancement** module (CEM) helping the model to improve the quality of the final predictions; and iii) a group-based symmetric triplet (GST) loss guiding the model to learn more discriminative features. Extensive experiments on three challenging benchmarks, i.e., CoCA, CoSOD3k, and CoSal2015, demonstrate that our GCoNet+ outperforms the existing 12 cutting-edge models. Code has been released at https://github.com/ZhengPeng7/GCoNet_plus.  
### D$^2$**NeRF**: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video. (arXiv:2205.15838v2 [cs.CV] UPDATED)
- Authors : Tianhao Wu, Fangcheng Zhong, Andrea Tagliasacchi, Forrester Cole, Cengiz Oztireli
- Link : [http://arxiv.org/abs/2205.15838](http://arxiv.org/abs/2205.15838)
> ABSTRACT  :  Given a monocular video, segmenting and decoupling dynamic objects while recovering the static environment is a widely studied problem in machine intelligence. Existing solutions usually approach this problem in the image domain, limiting their performance and understanding of the environment. We introduce Decoupled Dynamic Neural Radiance Field (D$^2$**NeRF**), a self-supervised approach that takes a monocular video and learns a 3D scene representation which decouples moving objects, including their shadows, from the static background. Our method represents the moving objects and the static background by two separate neural radiance fields with only one allowing for temporal changes. A naive implementation of this approach leads to the dynamic component taking over the static one as the representation of the former is inherently more general and prone to overfitting. To this end, we propose a novel loss to promote correct separation of phenomena. We further propose a shadow field network to detect and decouple dynamically moving shadows. We introduce a new dataset containing various dynamic objects and shadows and demonstrate that our method can achieve better performance than state-of-the-art approaches in decoupling dynamic and static 3D objects, occlusion and shadow removal, and image segmentation for moving objects.  
## eess.IV
---
## cs.LG
---
### CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences. (arXiv:2206.00145v1 [cs.CR])
- Authors : Shang Wang, Yansong Gao, Anmin Fu, Zhi Zhang, Yuqing Zhang, Willy Susilo
- Link : [http://arxiv.org/abs/2206.00145](http://arxiv.org/abs/2206.00145)
> ABSTRACT  :  Backdoor attacks have been a critical threat to deep neural network (DNN). However, most existing countermeasures focus on source-agnostic backdoor attacks (SABAs) and fail to defeat source-specific backdoor attacks (SSBAs). Compared to an SABA, an SSBA activates a backdoor when an input from attacker-chosen class(es) is stamped with an attacker-specified trigger, making itself stealthier and thus evade most existing backdoor mitigation. Nonetheless, existing SSBAs have trade-offs on attack success rate (ASR, a backdoor is activated by a trigger input from a source class as expected) and false positive rate (FPR, a backdoor is activated unexpectedly by a trigger input from a non-source class). Significantly, they can still be effectively detected by the state-of-the-art (SOTA) countermeasures targeting SSBAs. This work overcomes efficiency and effectiveness deficiencies of existing SSBAs, thus bypassing the SOTA defences. The key insight is to construct desired poisoned and cover data during backdoor training by characterising SSBAs in-depth. Both data are samples with triggers: the cover/poisoned data from non-source/source class(es) holds ground-truth/target labels. Therefore, two cover/poisoned data **enhancement**s are developed from trigger style and content, respectively, coined CASSOCK. First, we leverage trigger patterns with discrepant transparency to craft cover/poisoned data, enforcing triggers with heterogeneous sensitivity on different classes. The second **enhancement** chooses the target class features as triggers to craft these samples, entangling trigger features with the target class heavily. Compared with existing SSBAs, CASSOCK-based attacks have higher ASR and low FPR on four popular tasks: MNIST, CIFAR10, GTSRB, and LFW. More importantly, CASSOCK has effectively evaded three defences (SCAn, Februus and extended Neural Cleanse) already defeat existing SSBAs effectively.  
### One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label **Enhancement**. (arXiv:2206.00517v1 [cs.LG])
- Authors : Ning Xu, Congyu Qiao, Jiaqi Lv, Xin Geng, Ling Zhang
- Link : [http://arxiv.org/abs/2206.00517](http://arxiv.org/abs/2206.00517)
> ABSTRACT  :  Multi-label learning (MLL) learns from the examples each associated with multiple labels simultaneously, where the high cost of annotating all relevant labels for each training example is challenging for real-world applications. To cope with the challenge, we investigate single-positive multi-label learning (SPMLL) where each example is annotated with only one relevant label and show that one can successfully learn a theoretically grounded multi-label classifier for the problem. In this paper, a novel SPMLL method named {\proposed}, i.e., Single-positive MultI-label learning with Label **Enhancement**, is proposed. Specifically, an unbiased risk estimator is derived, which could be guaranteed to approximately converge to the optimal risk minimizer of fully supervised learning and shows that one positive label of each instance is sufficient to train the predictive model. Then, the corresponding empirical risk estimator is established via recovering the latent soft label as a label **enhancement** process, where the posterior density of the latent soft labels is approximate to the variational Beta density parameterized by an inference model. Experiments on benchmark datasets validate the effectiveness of the proposed method.  
### Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v2 [cs.AI] UPDATED)
- Authors : Ailing Zeng, Muxi Chen, **Lei Zhang**, Qiang Xu
- Link : [http://arxiv.org/abs/2205.13504](http://arxiv.org/abs/2205.13504)
> ABSTRACT  :  Recently, there has been a surge of Transformer-based solutions for the time series forecasting (TSF) task, especially for the challenging long-term TSF problem. Transformer architecture relies on self-attention mechanisms to effectively extract the semantic correlations between paired elements in a long sequence, which is permutation-invariant and anti-ordering to some extent. However, in time series modeling, we are to extract the temporal relations among an ordering set of continuous points. Consequently, whether Transformer-based techniques are the right solutions for long-term time series forecasting is an interesting problem to investigate, despite the performance improvements shown in these studies. In this work, we question the validity of Transformer-based TSF solutions. In their experiments, the compared (non-Transformer) baselines are mainly autoregressive forecasting solutions, which usually have a poor long-term prediction capability due to inevitable error accumulation effects. In contrast, we use an embarrassingly simple architecture named DLinear that conducts direct multi-step (DMS) forecasting for comparison. DLinear decomposes the time series into a trend and a remainder series and employs two one-layer linear networks to model these two series for the forecasting task. Surprisingly, it outperforms existing complex Transformer-based models in most cases by a large margin. Therefore, we conclude that the relatively higher long-term forecasting accuracy of Transformer-based TSF solutions shown in existing works has little to do with the temporal relation extraction capabilities of the Transformer architecture. Instead, it is mainly due to the non-autoregressive DMS forecasting strategy used in them. We hope this study also advocates revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future.  
## cs.AI
---
### Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v3 [cs.CR] UPDATED)
- Authors : Mikhail Kazdagli, Mohit Tiwari, Akshat Kumar
- Link : [http://arxiv.org/abs/2205.01240](http://arxiv.org/abs/2205.01240)
> ABSTRACT  :  Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing **dark** permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances.  
### Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v2 [cs.AI] UPDATED)
- Authors : Ailing Zeng, Muxi Chen, **Lei Zhang**, Qiang Xu
- Link : [http://arxiv.org/abs/2205.13504](http://arxiv.org/abs/2205.13504)
> ABSTRACT  :  Recently, there has been a surge of Transformer-based solutions for the time series forecasting (TSF) task, especially for the challenging long-term TSF problem. Transformer architecture relies on self-attention mechanisms to effectively extract the semantic correlations between paired elements in a long sequence, which is permutation-invariant and anti-ordering to some extent. However, in time series modeling, we are to extract the temporal relations among an ordering set of continuous points. Consequently, whether Transformer-based techniques are the right solutions for long-term time series forecasting is an interesting problem to investigate, despite the performance improvements shown in these studies. In this work, we question the validity of Transformer-based TSF solutions. In their experiments, the compared (non-Transformer) baselines are mainly autoregressive forecasting solutions, which usually have a poor long-term prediction capability due to inevitable error accumulation effects. In contrast, we use an embarrassingly simple architecture named DLinear that conducts direct multi-step (DMS) forecasting for comparison. DLinear decomposes the time series into a trend and a remainder series and employs two one-layer linear networks to model these two series for the forecasting task. Surprisingly, it outperforms existing complex Transformer-based models in most cases by a large margin. Therefore, we conclude that the relatively higher long-term forecasting accuracy of Transformer-based TSF solutions shown in existing works has little to do with the temporal relation extraction capabilities of the Transformer architecture. Instead, it is mainly due to the non-autoregressive DMS forecasting strategy used in them. We hope this study also advocates revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future.  
# Paper List
---
## cs.CV
---
**105** new papers in cs.CV:-) 
1. Calibrated Bagging Deep Learning for Image Semantic Segmentation: A Case Study on COVID-19 Chest X-ray Image. (arXiv:2206.00002v1 [eess.IV])
2. Characterization of 3D Printers and X-Ray Computerized Tomography. (arXiv:2206.00041v1 [eess.IV])
3. PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs. (arXiv:2206.00048v1 [cs.CV])
4. Comparing feature fusion strategies for Deep Learning-based kidney stone identification. (arXiv:2206.00069v1 [cs.CV])
5. FHIST: A Benchmark for Few-shot Classification of Histological Images. (arXiv:2206.00092v1 [cs.CV])
6. VALHALLA: Visual Hallucination for Machine Translation. (arXiv:2206.00100v1 [cs.CV])
7. Deep learning pipeline for image classification on mobile phones. (arXiv:2206.00105v1 [eess.IV])
8. Glo-In-One: Holistic Glomerular Detection, Segmentation, and Lesion Characterization with Large-scale Web Image Mining. (arXiv:2206.00123v1 [cs.CV])
9. Hands-Up: Leveraging Synthetic Data for Hands-On-Wheel Detection. (arXiv:2206.00148v1 [cs.CV])
10. PAGER: Progressive Attribute-Guided Extendable Robust Image Generation. (arXiv:2206.00162v1 [cs.CV])
11. Discovering the Hidden Vocabulary of DALLE-2. (arXiv:2206.00169v1 [cs.LG])
12. Learning Sequential Contexts using Transformer for 3D Hand Pose Estimation. (arXiv:2206.00171v1 [cs.CV])
13. Labeling Where Adapting Fails: Cross-Domain Semantic Segmentation with Point Supervision via Active Selection. (arXiv:2206.00181v1 [cs.CV])
14. Differentiable Soft-Masked Attention. (arXiv:2206.00182v1 [cs.CV])
15. CAFA: Class-Aware Feature Alignment for Test-Time Adaptation. (arXiv:2206.00205v1 [cs.CV])
16. LiDAR-MIMO: Efficient Uncertainty Estimation for LiDAR-based 3D Object Detection. (arXiv:2206.00214v1 [cs.CV])
17. Cross-domain Detection Transformer based on Spatial-aware and Semantic-aware Token Alignment. (arXiv:2206.00222v1 [cs.CV])
18. Rethinking the Augmentation Module in Contrastive Learning: Learning Hierarchical Augmentation Invariance with Expanded Views. (arXiv:2206.00227v1 [cs.CV])
19. Fair Comparison between Efficient Attentions. (arXiv:2206.00244v1 [cs.CV])
20. Interpretable Deep Learning Classifier by Detection of Prototypical Parts on Kidney Stones Images. (arXiv:2206.00252v1 [cs.CV])
21. PaGO-LOAM: Robust Ground-Optimized LiDAR Odometry. (arXiv:2206.00266v1 [cs.RO])
22. Vision GNN: An Image is Worth Graph of Nodes. (arXiv:2206.00272v1 [cs.CV])
23. Point-Teaching: Weakly Semi-Supervised Object Detection with Point Annotations. (arXiv:2206.00274v1 [cs.CV])
24. Automatic Bounding Box Annotation with Small Training Data Sets for Industrial Manufacturing. (arXiv:2206.00280v1 [cs.CV])
25. Needle In A Haystack, Fast: Benchmarking Image Perceptual Similarity Metrics At Scale. (arXiv:2206.00282v1 [cs.CV])
26. Efficient Multi-Purpose Cross-Attention Based Image Alignment Block for Edge Devices. (arXiv:2206.00291v1 [cs.CV])
27. Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images Using a Convolutional Neural Network and Transfer Learning. (arXiv:2206.00305v1 [eess.IV])
28. Label-Efficient Online Continual Object Detection in Streaming Video. (arXiv:2206.00309v1 [cs.CV])
29. MaskOCR: Text Recognition with Masked Encoder-Decoder Pretraining. (arXiv:2206.00311v1 [cs.CV])
30. CellCentroidFormer: Combining Self-attention and Convolution for Cell Detection. (arXiv:2206.00338v1 [eess.IV])
31. Towards view-invariant vehicle speed detection from driving simulator images. (arXiv:2206.00343v1 [cs.CV])
32. Self-Supervised Learning as a Means To Reduce the Need for Labeled Data in Medical Image Analysis. (arXiv:2206.00344v1 [cs.CV])
33. A Survey on Deep Learning for Skin Lesion Segmentation. (arXiv:2206.00356v1 [eess.IV])
34. DeepCluE: Enhanced Image Clustering via Multi-layer Ensembles in Deep Neural Networks. (arXiv:2206.00359v1 [cs.CV])
35. Elucidating the Design Space of Diffusion-Based Generative Models. (arXiv:2206.00364v1 [cs.CV])
36. Strongly Augmented Contrastive Clustering. (arXiv:2206.00380v1 [cs.LG])
37. A Generalized Supervised Contrastive Learning Framework. (arXiv:2206.00384v1 [cs.CV])
38. DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder. (arXiv:2206.00386v1 [cs.CV])
39. A comparative study between vision transformers and CNNs in digital pathology. (arXiv:2206.00389v1 [eess.IV])
40. Towards Generalisable Audio Representations for Audio-Visual Navigation. (arXiv:2206.00393v1 [cs.SD])
41. Learning Invariant Visual Representations for Compositional Zero-Shot Learning. (arXiv:2206.00415v1 [cs.CV])
42. Evaluating Gaussian Grasp Maps for Generative Grasping Models. (arXiv:2206.00432v1 [cs.RO])
43. CD$^2$: Fine-grained 3D Mesh Reconstruction with Twice Chamfer Distance. (arXiv:2206.00447v1 [cs.CV])
44. A robust and lightweight deep attention multiple instance learning algorithm for predicting genetic alterations. (arXiv:2206.00455v1 [q-bio.QM])
45. PanopticDepth: A Unified Framework for Depth-aware Panoptic Segmentation. (arXiv:2206.00468v1 [cs.CV])
46. Contrastive Principal Component Learning: Modeling Similarity by Augmentation Overlap. (arXiv:2206.00471v1 [cs.LG])
47. Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer. (arXiv:2206.00481v1 [cs.CV])
48. Attack-Agnostic Adversarial Detection. (arXiv:2206.00489v1 [cs.CV])
49. Semantic Room Wireframe Detection from a Single View. (arXiv:2206.00491v1 [cs.CV])
50. Proximally Sensitive Error for Anomaly Detection and Feature Learning. (arXiv:2206.00506v1 [cs.CV])
51. Landslide4Sense: Reference Benchmark Data and Deep Learning Models for Landslide Detection. (arXiv:2206.00515v1 [cs.CV])
52. Amodal Cityscapes: A New Dataset, its Generation, and an Amodal Semantic Segmentation Challenge Baseline. (arXiv:2206.00527v1 [cs.CV])
53. Deepfake Caricatures: Amplifying attention to artifacts increases deepfake detection by humans and machines. (arXiv:2206.00535v1 [cs.CV])
54. Impact of loss function in Deep Learning methods for accurate retinal vessel segmentation. (arXiv:2206.00536v1 [eess.IV])
55. The Fully Convolutional Transformer for Medical Image Segmentation. (arXiv:2206.00566v1 [eess.IV])
56. Dog nose print matching with dual global descriptor based on Contrastive Learning. (arXiv:2206.00580v1 [cs.CV])
57. Higher-Order Attention Networks. (arXiv:2206.00606v1 [cs.LG])
58. On the Choice of Data for Efficient Training and Validation of End-to-End Driving Models. (arXiv:2206.00608v1 [cs.CV])
59. Dual-stream spatiotemporal networks with feature sharing for monitoring animals in the home cage. (arXiv:2206.00614v1 [cs.CV])
60. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. (arXiv:2206.00621v1 [cs.CL])
61. CLIP4IDC: CLIP for Image Difference Captioning. (arXiv:2206.00629v1 [cs.CV])
62. Unifying Voxel-based Representation with Transformer for 3D Object Detection. (arXiv:2206.00630v1 [cs.CV])
63. Extreme Floorplan Reconstruction by Structure-Hallucinating Transformer Cascades. (arXiv:2206.00645v1 [cs.CV])
64. MonoSDF: Exploring Monocular Geometric Cues for Neural Implicit Surface Reconstruction. (arXiv:2206.00665v1 [cs.CV])
65. Anchor Pruning for Object Detection. (arXiv:2104.00432v3 [cs.CV] UPDATED)
66. Convolutions for Spatial Interaction Modeling. (arXiv:2104.07182v2 [cs.CV] UPDATED)
67. FoveaTer: Foveated Transformer for Image Classification. (arXiv:2105.14173v2 [cs.CV] UPDATED)
68. Fishr: Invariant Gradient Variances for Out-of-Distribution Generalization. (arXiv:2109.02934v3 [cs.LG] UPDATED)
69. GoG: Relation-aware Graph-over-Graph Network for Visual Dialog. (arXiv:2109.08475v3 [cs.CL] UPDATED)
70. BiC-Net: Learning Efficient Spatio-Temporal Relation for Text-Video Retrieval. (arXiv:2110.15609v3 [cs.CV] UPDATED)
71. Intensity Mapping Functions For **HDR** Panorama Imaging: Weighted Histogram Averaging. (arXiv:2111.07283v3 [cs.CV] UPDATED)
72. Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts. (arXiv:2111.08276v3 [cs.CL] UPDATED)
73. BA-Net: Bridge Attention for Deep Convolutional Neural Networks. (arXiv:2112.04150v3 [cs.CV] UPDATED)
74. Forensic Analysis of Synthetically Generated Western Blot Images. (arXiv:2112.08739v3 [cs.CV] UPDATED)
75. Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis. (arXiv:2112.10325v3 [eess.IV] UPDATED)
76. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v4 [cs.CV] UPDATED)
77. Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment. (arXiv:2112.15011v2 [eess.IV] UPDATED)
78. Using Self-Supervised Pretext Tasks for Active Learning. (arXiv:2201.07459v2 [cs.CV] UPDATED)
79. Neural Dual Contouring. (arXiv:2202.01999v3 [cs.CV] UPDATED)
80. OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework. (arXiv:2202.03052v2 [cs.CV] UPDATED)
81. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v2 [eess.IV] UPDATED)
82. Depth Completion using Geometry-Aware Embedding. (arXiv:2203.10912v2 [cs.CV] UPDATED)
83. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v3 [cs.LG] UPDATED)
84. Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene Graphs with Language Structures via Dependency Relationships. (arXiv:2203.14260v3 [cs.CV] UPDATED)
85. Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation. (arXiv:2203.15177v3 [cs.CV] UPDATED)
86. Semi-supervised Semantic Segmentation with Error Localization Network. (arXiv:2204.02078v3 [cs.CV] UPDATED)
87. Self-supervised Vision Transformers for Joint SAR-optical Representation Learning. (arXiv:2204.05381v3 [cs.CV] UPDATED)
88. Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors. (arXiv:2204.08612v2 [cs.CV] UPDATED)
89. A Simple Structure For Building A Robust Model. (arXiv:2204.11596v2 [cs.CV] UPDATED)
90. CNNs are Myopic. (arXiv:2205.10760v3 [cs.CV] UPDATED)
91. Contrastive Learning with Boosted Memorization. (arXiv:2205.12693v3 [cs.CV] UPDATED)
92. Matryoshka Representations for Adaptive Deployment. (arXiv:2205.13147v2 [cs.LG] UPDATED)
93. Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN. (arXiv:2205.13943v2 [cs.CV] UPDATED)
94. GIT: A Generative Image-to-text Transformer for Vision and Language. (arXiv:2205.14100v2 [cs.CV] UPDATED)
95. Multimodal Masked Autoencoders Learn Transferable Representations. (arXiv:2205.14204v2 [cs.CV] UPDATED)
96. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v2 [cs.CV] UPDATED)
97. Cervical Glandular Cell Detection from Whole Slide Image with Out-Of-Distribution Data. (arXiv:2205.14625v2 [cs.CV] UPDATED)
98. Revisiting Audio Pattern Recognition for Asthma Medication Adherence: Evaluation with the RDA Benchmark Suite. (arXiv:2205.15360v2 [cs.SD] UPDATED)
99. Gator: Customizable Channel Pruning of Neural Networks with Gating. (arXiv:2205.15404v2 [cs.CV] UPDATED)
100. GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v2 [cs.CV] UPDATED)
101. Self-Supervised Learning for Building Damage Assessment from Large-scale xBD Satellite Imagery Benchmark Datasets. (arXiv:2205.15688v2 [cs.CV] UPDATED)
102. Non-Iterative Recovery from Nonlinear Observations using Generative Models. (arXiv:2205.15749v2 [cs.LG] UPDATED)
103. SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v2 [cs.CV] UPDATED)
104. D$^2$**NeRF**: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video. (arXiv:2205.15838v2 [cs.CV] UPDATED)
105. A Competitive Method for Dog Nose-print Re-identification. (arXiv:2205.15934v2 [cs.CV] UPDATED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. Calibrated Bagging Deep Learning for Image Semantic Segmentation: A Case Study on COVID-19 Chest X-ray Image. (arXiv:2206.00002v1 [eess.IV])
2. Characterization of 3D Printers and X-Ray Computerized Tomography. (arXiv:2206.00041v1 [eess.IV])
3. Deep learning pipeline for image classification on mobile phones. (arXiv:2206.00105v1 [eess.IV])
4. A Class of Low-complexity DCT-like Transforms for Image and Video Coding. (arXiv:2206.00122v1 [eess.IV])
5. Low-complexity Three-dimensional Discrete Hartley Transform Approximations for Medical Image Compression. (arXiv:2206.00124v1 [eess.SP])
6. PAGER: Progressive Attribute-Guided Extendable Robust Image Generation. (arXiv:2206.00162v1 [cs.CV])
7. Efficient Multi-Purpose Cross-Attention Based Image Alignment Block for Edge Devices. (arXiv:2206.00291v1 [cs.CV])
8. Supervised Denoising of Diffusion-Weighted Magnetic Resonance Images Using a Convolutional Neural Network and Transfer Learning. (arXiv:2206.00305v1 [eess.IV])
9. Temporal Characterization of VR Traffic for Network Slicing Requirement Definition. (arXiv:2206.00317v1 [cs.NI])
10. CellCentroidFormer: Combining Self-attention and Convolution for Cell Detection. (arXiv:2206.00338v1 [eess.IV])
11. A Survey on Deep Learning for Skin Lesion Segmentation. (arXiv:2206.00356v1 [eess.IV])
12. A comparative study between vision transformers and CNNs in digital pathology. (arXiv:2206.00389v1 [eess.IV])
13. Physics-based neural network for non-invasive control of coherent light in scattering media. (arXiv:2206.00487v1 [physics.optics])
14. Landslide4Sense: Reference Benchmark Data and Deep Learning Models for Landslide Detection. (arXiv:2206.00515v1 [cs.CV])
15. Impact of loss function in Deep Learning methods for accurate retinal vessel segmentation. (arXiv:2206.00536v1 [eess.IV])
16. The Fully Convolutional Transformer for Medical Image Segmentation. (arXiv:2206.00566v1 [eess.IV])
17. Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis. (arXiv:2112.10325v3 [eess.IV] UPDATED)
18. Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment. (arXiv:2112.15011v2 [eess.IV] UPDATED)
19. Total variation-based reconstruction and phase retrieval for diffraction tomography. (arXiv:2201.11579v2 [math.NA] UPDATED)
20. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v2 [eess.IV] UPDATED)
21. Min-Max Similarity: A Contrastive Semi-Supervised Deep Learning Network for Surgical Tools Segmentation. (arXiv:2203.15177v3 [cs.CV] UPDATED)
## cs.LG
---
**211** new papers in cs.LG:-) 
1. Weight Set Decomposition for Weighted Rank Aggregation: An interpretable and visual decision support tool. (arXiv:2206.00001v1 [cs.IR])
2. Calibrated Bagging Deep Learning for Image Semantic Segmentation: A Case Study on COVID-19 Chest X-ray Image. (arXiv:2206.00002v1 [eess.IV])
3. Are classical neural networks quantum?. (arXiv:2206.00005v1 [cs.LG])
4. COIN: Co-Cluster Infomax for Bipartite Graphs. (arXiv:2206.00006v1 [cs.LG])
5. A Cross-City Federated Transfer Learning Framework: A Case Study on Urban Region Profiling. (arXiv:2206.00007v1 [cs.LG])
6. Online PAC-Bayes Learning. (arXiv:2206.00024v1 [cs.LG])
7. Evolving Domain Generalization. (arXiv:2206.00047v1 [cs.LG])
8. PandA: Unsupervised Learning of Parts and Appearances in the Feature Maps of GANs. (arXiv:2206.00048v1 [cs.CV])
9. FiLM-Ensemble: Probabilistic Deep Learning via Feature-wise Linear Modulation. (arXiv:2206.00050v1 [cs.LG])
10. Learning Instance-Specific Data Augmentations. (arXiv:2206.00051v1 [cs.LG])
11. Asynchronous Hierarchical Federated Learning. (arXiv:2206.00054v1 [cs.LG])
12. Distributed Graph Neural Network Training with Periodic Historical Embedding Synchronization. (arXiv:2206.00057v1 [cs.LG])
13. Universal Early Warning Signals of Phase Transitions in Climate Systems. (arXiv:2206.00060v1 [physics.ao-ph])
14. FELARE: Fair Scheduling of Machine Learning Applications on Heterogeneous Edge Systems. (arXiv:2206.00065v1 [cs.DC])
15. On Analyzing Generative and Denoising Capabilities of Diffusion-based Deep Generative Models. (arXiv:2206.00070v1 [cs.LG])
16. Generative Models with Information-Theoretic Protection Against Membership Inference Attacks. (arXiv:2206.00071v1 [cs.LG])
17. To the Fairness Frontier and Beyond: Identifying, Quantifying, and Optimizing the Fairness-Accuracy Pareto Frontier. (arXiv:2206.00074v1 [stat.ML])
18. Semantically-enhanced Topic Recommendation System for Software Projects. (arXiv:2206.00085v1 [cs.SE])
19. Extensive Study of Multiple Deep Neural Networks for Complex Random Telegraph Signals. (arXiv:2206.00086v1 [physics.app-ph])
20. Easy Variational Inference for Categorical Models via an Independent Binary Approximation. (arXiv:2206.00093v1 [stat.ML])
21. Provably and Practically Efficient Neural Contextual Bandits. (arXiv:2206.00099v1 [stat.ML])
22. MAD-EN: Microarchitectural Attack Detection through System-wide Energy Consumption. (arXiv:2206.00101v1 [cs.CR])
23. Deep learning pipeline for image classification on mobile phones. (arXiv:2206.00105v1 [eess.IV])
24. Mario Plays on a Manifold: Generating Functional Content in Latent Space through Differential Geometry. (arXiv:2206.00106v1 [cs.LG])
25. Principle of Relevant Information for Graph Sparsification. (arXiv:2206.00118v1 [cs.LG])
26. Decentralized Competing Bandits in Non-Stationary Matching Markets. (arXiv:2206.00120v1 [stat.ML])
27. Near-Optimal Collaborative Learning in Bandits. (arXiv:2206.00121v1 [cs.LG])
28. Communication-efficient distributed eigenspace estimation with arbitrary node failures. (arXiv:2206.00127v1 [stat.ML])
29. ForestPrune: Compact Depth-Controlled Tree Ensembles. (arXiv:2206.00128v1 [stat.ML])
30. Fairness Transferability Subject to Bounded Distribution Shift. (arXiv:2206.00129v1 [cs.LG])
31. Pre-training via Denoising for Molecular Property Prediction. (arXiv:2206.00133v1 [cs.LG])
32. AVIDA: Alternating method for Visualizing and Integrating Data. (arXiv:2206.00135v1 [q-bio.QM])
33. End-to-end Optimization of Machine Learning Prediction Queries. (arXiv:2206.00136v1 [cs.DB])
34. Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria. (arXiv:2206.00137v1 [cs.LG])
35. IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents. (arXiv:2206.00142v1 [cs.LG])
36. CASSOCK: Viable Backdoor Attacks against DNN in The Wall of Source-Specific Backdoor Defences. (arXiv:2206.00145v1 [cs.CR])
37. Hands-Up: Leveraging Synthetic Data for Hands-On-Wheel Detection. (arXiv:2206.00148v1 [cs.CV])
38. A Kernelised Stein Statistic for Assessing Implicit Generative Models. (arXiv:2206.00149v1 [stat.ML])
39. Provably Efficient Offline Multi-agent Reinforcement Learning via Strategy-wise Bonus. (arXiv:2206.00159v1 [cs.LG])
40. PAGER: Progressive Attribute-Guided Extendable Robust Image Generation. (arXiv:2206.00162v1 [cs.CV])
41. A Theoretical Framework for Inference Learning. (arXiv:2206.00164v1 [cs.NE])
42. Byzantine-Robust Online and Offline Distributed Reinforcement Learning. (arXiv:2206.00165v1 [cs.LG])
43. Discovering the Hidden Vocabulary of DALLE-2. (arXiv:2206.00169v1 [cs.LG])
44. Learning Sparse Nonlinear Dynamics via Mixed-Integer Optimization. (arXiv:2206.00176v1 [cs.LG])
45. On Gap-dependent Bounds for Offline Reinforcement Learning. (arXiv:2206.00177v1 [cs.LG])
46. DisPFL: Towards Communication-Efficient Personalized Federated Learning via Decentralized Sparse Training. (arXiv:2206.00187v1 [cs.LG])
47. Transformer with Fourier Integral Attentions. (arXiv:2206.00206v1 [cs.LG])
48. Adaptive Online Learning of Quantum States. (arXiv:2206.00220v1 [cs.LG])
49. Lower and Upper Bounds for Numbers of Linear Regions of Graph Convolutional Networks. (arXiv:2206.00228v1 [cs.LG])
50. DM$^2$: Distributed Multi-Agent Reinforcement Learning for Distribution Matching. (arXiv:2206.00233v1 [cs.MA])
51. Continuous Prediction with Experts' Advice. (arXiv:2206.00236v1 [cs.LG])
52. Transferable Reward Learning by Dynamics-Agnostic Discriminator Ensemble. (arXiv:2206.00238v1 [cs.LG])
53. Privacy for Free: How does Dataset Condensation Help Privacy?. (arXiv:2206.00240v1 [cs.CR])
54. Asymptotic Properties for Bayesian Neural Network in Besov Space. (arXiv:2206.00241v1 [stat.ML])
55. Fair Comparison between Efficient Attentions. (arXiv:2206.00244v1 [cs.CV])
56. Interpretable Deep Learning Classifier by Detection of Prototypical Parts on Kidney Stones Images. (arXiv:2206.00252v1 [cs.CV])
57. Star algorithm for NN ensembling. (arXiv:2206.00255v1 [cs.LG])
58. CoNSoLe: Convex Neural Symbolic Learning. (arXiv:2206.00257v1 [cs.LG])
59. IDANI: Inference-time Domain Adaptation via Neuron-level Interventions. (arXiv:2206.00259v1 [cs.CL])
60. Multi-block Min-max Bilevel Optimization with Applications in Multi-task Deep AUC Maximization. (arXiv:2206.00260v1 [math.OC])
61. Self-supervised Learning for Label Sparsity in Computational Drug Repositioning. (arXiv:2206.00262v1 [cs.LG])
62. Provably Efficient Lifelong Reinforcement Learning with Linear Function Approximation. (arXiv:2206.00270v1 [cs.LG])
63. Task-Specific Expert Pruning for Sparse Mixture-of-Experts. (arXiv:2206.00277v1 [cs.LG])
64. On the Perils of Cascading Robust Classifiers. (arXiv:2206.00278v1 [cs.LG])
65. Stochastic Gradient Methods with Preconditioned Updates. (arXiv:2206.00285v1 [math.OC])
66. Multi-Complexity-Loss DNAS for Energy-Efficient and Memory-Constrained Deep Neural Networks. (arXiv:2206.00302v1 [cs.LG])
67. Predecessor Features. (arXiv:2206.00303v1 [cs.LG])
68. Federated Learning in Satellite Constellations. (arXiv:2206.00307v1 [cs.IT])
69. Contextual Bandits with Knapsacks for a Conversion Model. (arXiv:2206.00314v1 [cs.LG])
70. Model Generation with Provable Coverability for Offline Reinforcement Learning. (arXiv:2206.00316v1 [cs.LG])
71. On Layer Normalizations and Residual Connections in Transformers. (arXiv:2206.00330v1 [cs.LG])
72. Control of Two-way Coupled Fluid Systems with Differentiable Solvers. (arXiv:2206.00342v1 [cs.LG])
73. Support Vector Machines under Adversarial Label Contamination. (arXiv:2206.00352v1 [cs.LG])
74. A Survey on Deep Learning for Skin Lesion Segmentation. (arXiv:2206.00356v1 [eess.IV])
75. DeepCluE: Enhanced Image Clustering via Multi-layer Ensembles in Deep Neural Networks. (arXiv:2206.00359v1 [cs.CV])
76. Augmenting Message Passing by Retrieving Similar Graphs. (arXiv:2206.00362v1 [cs.LG])
77. Bring Your Own Algorithm for Optimal Differentially Private Stochastic Minimax Optimization. (arXiv:2206.00363v1 [cs.LG])
78. Elucidating the Design Space of Diffusion-Based Generative Models. (arXiv:2206.00364v1 [cs.CV])
79. Strongly Augmented Contrastive Clustering. (arXiv:2206.00380v1 [cs.LG])
80. Neural Improvement Heuristics for Preference Ranking. (arXiv:2206.00383v1 [cs.AI])
81. A Generalized Supervised Contrastive Learning Framework. (arXiv:2206.00384v1 [cs.CV])
82. Transfer without Forgetting. (arXiv:2206.00388v1 [cs.LG])
83. A comparative study between vision transformers and CNNs in digital pathology. (arXiv:2206.00389v1 [eess.IV])
84. Attention-embedded Quadratic Network (Qttention) for Effective and Interpretable Bearing Fault Diagnosis. (arXiv:2206.00390v1 [cs.LG])
85. Towards Generalisable Audio Representations for Audio-Visual Navigation. (arXiv:2206.00393v1 [cs.SD])
86. Optimization with access to auxiliary information. (arXiv:2206.00395v1 [cs.LG])
87. Predicting Political Ideology from Digital Footprints. (arXiv:2206.00397v1 [econ.GN])
88. NeuroUnlock: Unlocking the Architecture of Obfuscated Deep Neural Networks. (arXiv:2206.00402v1 [cs.CR])
89. In the Eye of the Beholder: Robust Prediction with Causal User Modeling. (arXiv:2206.00416v1 [cs.LG])
90. Open Environment Machine Learning. (arXiv:2206.00423v1 [cs.LG])
91. Semantic Probabilistic Layers for Neuro-Symbolic Learning. (arXiv:2206.00426v1 [cs.LG])
92. Evaluating Gaussian Grasp Maps for Generative Grasping Models. (arXiv:2206.00432v1 [cs.RO])
93. Top-down inference in an early visual cortex inspired hierarchical Variational Autoencoder. (arXiv:2206.00436v1 [q-bio.NC])
94. Algorithmic Foundation of Deep X-Risk Optimization. (arXiv:2206.00439v1 [cs.LG])
95. Ultrahyperbolic Knowledge Graph Embeddings. (arXiv:2206.00449v1 [cs.LG])
96. Towards Context-Aware Neural Performance-Score Synchronisation. (arXiv:2206.00454v1 [cs.SD])
97. A robust and lightweight deep attention multiple instance learning algorithm for predicting genetic alterations. (arXiv:2206.00455v1 [q-bio.QM])
98. Automatic differentiation of nonsmooth iterative algorithms. (arXiv:2206.00457v1 [math.OC])
99. An $\alpha$-No-Regret Algorithm For Graphical Bilinear Bandits. (arXiv:2206.00466v1 [cs.LG])
100. Good Intentions: Adaptive Parameter Servers via Intent Signaling. (arXiv:2206.00470v1 [cs.LG])
101. Contrastive Principal Component Learning: Modeling Similarity by Augmentation Overlap. (arXiv:2206.00471v1 [cs.LG])
102. Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer. (arXiv:2206.00481v1 [cs.CV])
103. DEP-RL: Embodied Exploration for Reinforcement Learning in Overactuated and Musculoskeletal Systems. (arXiv:2206.00484v1 [cs.RO])
104. Rotate the ReLU to implicitly sparsify deep networks. (arXiv:2206.00488v1 [cs.LG])
105. Incentivizing Combinatorial Bandit Exploration. (arXiv:2206.00494v1 [cs.LG])
106. Realistic Deep Learning May Not Fit Benignly. (arXiv:2206.00501v1 [cs.LG])
107. Proximally Sensitive Error for Anomaly Detection and Feature Learning. (arXiv:2206.00506v1 [cs.CV])
108. Convergence of Stein Variational Gradient Descent under a Weaker Smoothness Condition. (arXiv:2206.00508v1 [math.ST])
109. Differentially Private Shapley Values for Data Evaluation. (arXiv:2206.00511v1 [cs.LG])
110. Neural Network Verification with Proof Production. (arXiv:2206.00512v1 [cs.LO])
111. The robust way to stack and bag: the local Lipschitz way. (arXiv:2206.00513v1 [cs.LG])
112. Feature Selection for Discovering Distributional Treatment Effect Modifiers. (arXiv:2206.00516v1 [cs.LG])
113. One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label **Enhancement**. (arXiv:2206.00517v1 [cs.LG])
114. Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning. (arXiv:2206.00518v1 [cs.LG])
115. Deep Learning Opacity in Scientific Discovery. (arXiv:2206.00520v1 [cs.AI])
116. Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social Media Streaming Data. (arXiv:2206.00524v1 [cs.CL])
117. Variance Reduction is an Antidote to Byzantines: Better Rates, Weaker Assumptions and Communication Compression as a Cherry on the Top. (arXiv:2206.00529v1 [cs.LG])
118. FETA: Fairness Enforced Verifying, Training, and Predicting Algorithms for Neural Networks. (arXiv:2206.00553v1 [cs.LG])
119. A Near-Optimal Best-of-Both-Worlds Algorithm for Online Learning with Feedback Graphs. (arXiv:2206.00557v1 [cs.LG])
120. RMT-Net: Reject-aware Multi-Task Network for Modeling Missing-not-at-random Data in Financial Credit Scoring. (arXiv:2206.00568v1 [cs.LG])
121. Calibrate and Debias Layer-wise Sampling for Graph Convolutional Networks. (arXiv:2206.00583v1 [cs.LG])
122. Multi-Armed Bandit Problem with Temporally-Partitioned Rewards: When Partial Feedback Counts. (arXiv:2206.00586v1 [cs.LG])
123. Higher-Order Attention Networks. (arXiv:2206.00606v1 [cs.LG])
124. On the Choice of Data for Efficient Training and Validation of End-to-End Driving Models. (arXiv:2206.00608v1 [cs.CV])
125. Graph Machine Learning for Design of High-Octane Fuels. (arXiv:2206.00619v1 [cs.LG])
126. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. (arXiv:2206.00621v1 [cs.CL])
127. Computing the Variance of Shuffling Stochastic Gradient Algorithms via Power Spectral Density Analysis. (arXiv:2206.00632v1 [math.OC])
128. Graph Neural Networks with Precomputed Node Features. (arXiv:2206.00637v1 [cs.LG])
129. A multimodal model with Twitter FinBERT embeddings for extreme price movement prediction of Bitcoin. (arXiv:2206.00648v1 [q-fin.ST])
130. Differentiable programming for functional connectomics. (arXiv:2206.00649v1 [q-bio.NC])
131. Learning-Augmented Algorithms for Online TSP on the Line. (arXiv:2206.00655v1 [cs.DS])
132. Hopular: Modern Hopfield Networks for Tabular Data. (arXiv:2206.00664v1 [cs.LG])
133. Fine Timing and Frequency Synchronization for MIMO-OFDM: An Extreme Learning Approach. (arXiv:2007.09248v5 [eess.SP] UPDATED)
134. High-Throughput Approach to Modeling Healthcare Costs Using Electronic Healthcare Records. (arXiv:2011.09497v2 [cs.LG] UPDATED)
135. Normalization effects on shallow neural networks and related asymptotic expansions. (arXiv:2011.10487v3 [stat.ML] UPDATED)
136. Reinforcement Learning with Algorithms from Probabilistic Structure Estimation. (arXiv:2103.08241v2 [cs.LG] UPDATED)
137. Physics-Informed Neural Nets for Control of Dynamical Systems. (arXiv:2104.02556v3 [cs.LG] UPDATED)
138. A Hybrid Architecture for Federated and Centralized Learning. (arXiv:2105.03288v3 [cs.LG] UPDATED)
139. Learning a performance metric of Buchberger's algorithm. (arXiv:2106.03676v2 [math.AC] UPDATED)
140. Optimal Accounting of Differential Privacy via Characteristic Function. (arXiv:2106.08567v3 [cs.LG] UPDATED)
141. The Dimpled Manifold Model of Adversarial Examples in Machine Learning. (arXiv:2106.10151v2 [cs.LG] UPDATED)
142. Asymptotics of Network Embeddings Learned via Subsampling. (arXiv:2107.02363v2 [stat.ML] UPDATED)
143. From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers. (arXiv:2107.07999v4 [cs.LG] UPDATED)
144. Sparse Bayesian Deep Learning for Dynamic System Identification. (arXiv:2107.12910v2 [eess.SY] UPDATED)
145. Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model. (arXiv:2108.07467v3 [cs.SD] UPDATED)
146. GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain. (arXiv:2109.02555v2 [cs.CL] UPDATED)
147. Fishr: Invariant Gradient Variances for Out-of-Distribution Generalization. (arXiv:2109.02934v3 [cs.LG] UPDATED)
148. Algorithmic Fairness Verification with Graphical Models. (arXiv:2109.09447v2 [cs.LG] UPDATED)
149. Learning from Small Samples: Transformation-Invariant SVMs with Composition and Locality at Multiple Scales. (arXiv:2109.12784v4 [cs.LG] UPDATED)
150. Adversarial Attacks on Gaussian Process Bandits. (arXiv:2110.08449v2 [stat.ML] UPDATED)
151. Sampling from Log-Concave Distributions with Infinity-Distance Guarantees. (arXiv:2111.04089v2 [cs.DS] UPDATED)
152. A Comparative Analysis of Machine Learning Techniques for IoT Intrusion Detection. (arXiv:2111.13149v3 [cs.CR] UPDATED)
153. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v4 [cs.LG] UPDATED)
154. The Representation Jensen-R\'enyi Divergence. (arXiv:2112.01583v4 [cs.LG] UPDATED)
155. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v4 [cs.CV] UPDATED)
156. Asymptotics of $\ell_2$ Regularized Network Embeddings. (arXiv:2201.01689v2 [stat.ML] UPDATED)
157. Verified Probabilistic Policies for Deep Reinforcement Learning. (arXiv:2201.03698v2 [cs.AI] UPDATED)
158. Optimisation of Structured Neural Controller Based on Continuous-Time Policy Gradient. (arXiv:2201.06262v3 [cs.LG] UPDATED)
159. Consistent Collaborative Filtering via Tensor Decomposition. (arXiv:2201.11936v2 [cs.IR] UPDATED)
160. An Indirect Rate-Distortion Characterization for Semantic Sources: General Model and the Case of Gaussian Observation. (arXiv:2201.12477v2 [cs.IT] UPDATED)
161. A Comparison of Different Approaches to Dynamic Origin-Destination Matrix Estimation in Urban Traffic. (arXiv:2202.00099v2 [math.OC] UPDATED)
162. Neural Dual Contouring. (arXiv:2202.01999v3 [cs.CV] UPDATED)
163. Graph Self-supervised Learning with Accurate Discrepancy Learning. (arXiv:2202.02989v3 [cs.LG] UPDATED)
164. Conformal prediction for the design problem. (arXiv:2202.03613v4 [cs.LG] UPDATED)
165. Width is Less Important than Depth in ReLU Neural Networks. (arXiv:2202.03841v2 [cs.LG] UPDATED)
166. Generative multitask learning mitigates target-causing confounding. (arXiv:2202.04136v2 [cs.LG] UPDATED)
167. Online Learning for Min Sum Set Cover and Pandora's Box. (arXiv:2202.04870v2 [cs.LG] UPDATED)
168. Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness. (arXiv:2202.08821v2 [cs.CY] UPDATED)
169. Exploratory Methods for Relation Discovery in Archival Data. (arXiv:2202.11361v2 [cs.LG] UPDATED)
170. TEE-based decentralized recommender systems: The raw data sharing redemption. (arXiv:2202.11655v2 [cs.DC] UPDATED)
171. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v2 [eess.IV] UPDATED)
172. Bounding Membership Inference. (arXiv:2202.12232v2 [cs.LG] UPDATED)
173. Can Mean Field Control (MFC) Approximate Cooperative Multi Agent Reinforcement Learning (MARL) with Non-Uniform Interaction?. (arXiv:2203.00035v2 [cs.LG] UPDATED)
174. Bayesian Optimisation for Robust Model Predictive Control under Model Parameter Uncertainty. (arXiv:2203.00551v3 [cs.RO] UPDATED)
175. Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization. (arXiv:2203.02214v2 [cs.LG] UPDATED)
176. AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators. (arXiv:2203.03673v2 [stat.ML] UPDATED)
177. Convolutional-Recurrent Neural Network Proxy for Robust Optimization and Closed-Loop Reservoir Management. (arXiv:2203.07524v2 [cs.LG] UPDATED)
178. Local Stochastic Factored Gradient Descent for Distributed Quantum State Tomography. (arXiv:2203.11579v2 [quant-ph] UPDATED)
179. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v3 [cs.LG] UPDATED)
180. Graph Neural Networks are Dynamic Programmers. (arXiv:2203.15544v2 [cs.LG] UPDATED)
181. Decompositional Generation Process for Instance-Dependent Partial Label Learning. (arXiv:2204.03845v2 [cs.LG] UPDATED)
182. Physical Modeling using Recurrent Neural Networks with Fast Convolutional Layers. (arXiv:2204.10125v2 [cs.SD] UPDATED)
183. A Simple Structure For Building A Robust Model. (arXiv:2204.11596v2 [cs.CV] UPDATED)
184. Operational Adaptation of DNN Classifiers using Elastic Weight Consolidation. (arXiv:2205.00147v2 [cs.LG] UPDATED)
185. Growing Isotropic Neural Cellular Automata. (arXiv:2205.01681v3 [cs.NE] UPDATED)
186. Framework for inferring empirical causal graphs from binary data to support multidimensional poverty analysis. (arXiv:2205.06131v2 [stat.ME] UPDATED)
187. Online Nonsubmodular Minimization with Delayed Costs: From Full Information to Bandit Feedback. (arXiv:2205.07217v2 [cs.LG] UPDATED)
188. A model aggregation approach for high-dimensional large-scale optimization. (arXiv:2205.07525v2 [cs.LG] UPDATED)
189. Taming Continuous Posteriors for Latent Variational Dialogue Policies. (arXiv:2205.07633v2 [cs.CL] UPDATED)
190. Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training. (arXiv:2205.10471v2 [cs.CL] UPDATED)
191. CNNs are Myopic. (arXiv:2205.10760v3 [cs.CV] UPDATED)
192. Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy, Challenges and Vision. (arXiv:2205.11913v3 [cs.DC] UPDATED)
193. Federated Self-supervised Learning for Heterogeneous Clients. (arXiv:2205.12493v3 [cs.LG] UPDATED)
194. Matryoshka Representations for Adaptive Deployment. (arXiv:2205.13147v2 [cs.LG] UPDATED)
195. Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v2 [cs.AI] UPDATED)
196. Fairness in Recommendation: A Survey. (arXiv:2205.13619v4 [cs.IR] UPDATED)
197. A Unified Analysis of Federated Learning with Arbitrary Client Participation. (arXiv:2205.13648v2 [cs.LG] UPDATED)
198. Generalization Bounds for Gradient Methods via Discrete and Continuous Prior. (arXiv:2205.13799v2 [cs.LG] UPDATED)
199. Bayesian Robust Graph Contrastive Learning. (arXiv:2205.14109v2 [cs.LG] UPDATED)
200. Will Bilevel Optimizers Benefit from Loops. (arXiv:2205.14224v3 [cs.LG] UPDATED)
201. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v2 [cs.CV] UPDATED)
202. Temporal Multiresolution Graph Neural Networks For Epidemic Prediction. (arXiv:2205.14831v2 [cs.LG] UPDATED)
203. OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs. (arXiv:2205.15117v2 [cs.LG] UPDATED)
204. Associative Learning Mechanism for Drug-Target Interaction Prediction. (arXiv:2205.15364v2 [q-bio.BM] UPDATED)
205. Differentiable Invariant Causal Discovery. (arXiv:2205.15638v2 [cs.LG] UPDATED)
206. Multilingual Transformers for Product Matching -- Experiments and a New Benchmark in Polish. (arXiv:2205.15712v2 [cs.CL] UPDATED)
207. Non-Iterative Recovery from Nonlinear Observations using Generative Models. (arXiv:2205.15749v2 [cs.LG] UPDATED)
208. SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v2 [cs.CV] UPDATED)
209. Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An Application of Gradient Boosted Decision Trees to the S&P 100. (arXiv:2205.15853v2 [econ.EM] UPDATED)
210. FedWalk: Communication Efficient Federated Unsupervised Node Embedding with Differential Privacy. (arXiv:2205.15896v2 [cs.DC] UPDATED)
211. Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of Movie Dialogues. (arXiv:2205.15951v2 [cs.CL] UPDATED)
## cs.AI
---
**93** new papers in cs.AI:-) 
1. Weight Set Decomposition for Weighted Rank Aggregation: An interpretable and visual decision support tool. (arXiv:2206.00001v1 [cs.IR])
2. COIN: Co-Cluster Infomax for Bipartite Graphs. (arXiv:2206.00006v1 [cs.LG])
3. A Cross-City Federated Transfer Learning Framework: A Case Study on Urban Region Profiling. (arXiv:2206.00007v1 [cs.LG])
4. A Mixture-of-Expert Approach to RL-based Dialogue Management. (arXiv:2206.00059v1 [cs.CL])
5. Comparing feature fusion strategies for Deep Learning-based kidney stone identification. (arXiv:2206.00069v1 [cs.CV])
6. BRExIt: On Opponent Modelling in Expert Iteration. (arXiv:2206.00113v1 [cs.AI])
7. IGLU Gridworld: Simple and Fast Environment for Embodied Dialog Agents. (arXiv:2206.00142v1 [cs.LG])
8. Human-AI Shared Control via Frequency-based Policy Dissection. (arXiv:2206.00152v1 [cs.RO])
9. Provably Efficient Offline Multi-agent Reinforcement Learning via Strategy-wise Bonus. (arXiv:2206.00159v1 [cs.LG])
10. PAGER: Progressive Attribute-Guided Extendable Robust Image Generation. (arXiv:2206.00162v1 [cs.CV])
11. On Gap-dependent Bounds for Offline Reinforcement Learning. (arXiv:2206.00177v1 [cs.LG])
12. Order-sensitive Shapley Values for Evaluating Conceptual Soundness of NLP Models. (arXiv:2206.00192v1 [cs.CL])
13. Lower and Upper Bounds for Numbers of Linear Regions of Graph Convolutional Networks. (arXiv:2206.00228v1 [cs.LG])
14. Multi-Object Grasping in the Plane. (arXiv:2206.00229v1 [cs.RO])
15. DM$^2$: Distributed Multi-Agent Reinforcement Learning for Distribution Matching. (arXiv:2206.00233v1 [cs.MA])
16. Interpretable Deep Learning Classifier by Detection of Prototypical Parts on Kidney Stones Images. (arXiv:2206.00252v1 [cs.CV])
17. CoNSoLe: Convex Neural Symbolic Learning. (arXiv:2206.00257v1 [cs.LG])
18. IDANI: Inference-time Domain Adaptation via Neuron-level Interventions. (arXiv:2206.00259v1 [cs.CL])
19. Multi-block Min-max Bilevel Optimization with Applications in Multi-task Deep AUC Maximization. (arXiv:2206.00260v1 [math.OC])
20. Task-Specific Expert Pruning for Sparse Mixture-of-Experts. (arXiv:2206.00277v1 [cs.LG])
21. MORE: A Metric Learning Based Framework for Open-domain Relation Extraction. (arXiv:2206.00289v1 [cs.CL])
22. Predecessor Features. (arXiv:2206.00303v1 [cs.LG])
23. Perception-Intention-Action Cycle in Human-Robot Collaborative Tasks. (arXiv:2206.00304v1 [cs.RO])
24. Putting AI Ethics into Practice: The Hourglass Model of Organizational AI Governance. (arXiv:2206.00335v1 [cs.AI])
25. Towards view-invariant vehicle speed detection from driving simulator images. (arXiv:2206.00343v1 [cs.CV])
26. Augmenting Message Passing by Retrieving Similar Graphs. (arXiv:2206.00362v1 [cs.LG])
27. Elucidating the Design Space of Diffusion-Based Generative Models. (arXiv:2206.00364v1 [cs.CV])
28. Neural Improvement Heuristics for Preference Ranking. (arXiv:2206.00383v1 [cs.AI])
29. DiVAE: Photorealistic Images Synthesis with Denoising Diffusion Decoder. (arXiv:2206.00386v1 [cs.CV])
30. Generalized Delayed Feedback Model with Post-Click Information in Recommender Systems. (arXiv:2206.00407v1 [cs.IR])
31. The Use of NLP-Based Text Representation Techniques to Support Requirement Engineering Tasks: A Systematic Mapping Review. (arXiv:2206.00421v1 [cs.SE])
32. Semantic Probabilistic Layers for Neuro-Symbolic Learning. (arXiv:2206.00426v1 [cs.LG])
33. Algorithmic Foundation of Deep X-Risk Optimization. (arXiv:2206.00439v1 [cs.LG])
34. Ultrahyperbolic Knowledge Graph Embeddings. (arXiv:2206.00449v1 [cs.LG])
35. Towards Context-Aware Neural Performance-Score Synchronisation. (arXiv:2206.00454v1 [cs.SD])
36. A robust and lightweight deep attention multiple instance learning algorithm for predicting genetic alterations. (arXiv:2206.00455v1 [q-bio.QM])
37. Towards Responsible AI: A Design Space Exploration of Human-Centered Artificial Intelligence User Interfaces to Investigate Fairness. (arXiv:2206.00474v1 [cs.AI])
38. Realistic Deep Learning May Not Fit Benignly. (arXiv:2206.00501v1 [cs.LG])
39. Proximally Sensitive Error for Anomaly Detection and Feature Learning. (arXiv:2206.00506v1 [cs.CV])
40. Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning. (arXiv:2206.00518v1 [cs.LG])
41. Deep Learning Opacity in Scientific Discovery. (arXiv:2206.00520v1 [cs.AI])
42. Vietnamese Hate and Offensive Detection using PhoBERT-CNN and Social Media Streaming Data. (arXiv:2206.00524v1 [cs.CL])
43. Multi-Armed Bandit Problem with Temporally-Partitioned Rewards: When Partial Feedback Counts. (arXiv:2206.00586v1 [cs.LG])
44. Logic-Based Ethical Planning. (arXiv:2206.00595v1 [cs.AI])
45. Cross-View Language Modeling: Towards Unified Cross-Lingual Cross-Modal Pre-training. (arXiv:2206.00621v1 [cs.CL])
46. Speech Artifact Removal from EEG Recordings of Spoken Word Production with Tensor Decomposition. (arXiv:2206.00635v1 [cs.SD])
47. A modular architecture for creating multimodal agents. (arXiv:2206.00636v1 [cs.AI])
48. Extreme Floorplan Reconstruction by Structure-Hallucinating Transformer Cascades. (arXiv:2206.00645v1 [cs.CV])
49. Efficiently Embedding Dynamic Knowledge Graphs. (arXiv:1910.06708v2 [cs.DB] UPDATED)
50. From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers. (arXiv:2107.07999v4 [cs.LG] UPDATED)
51. Improving Social Meaning Detection with Pragmatic Masking and Surrogate Fine-Tuning. (arXiv:2108.00356v4 [cs.CL] UPDATED)
52. GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain. (arXiv:2109.02555v2 [cs.CL] UPDATED)
53. Fishr: Invariant Gradient Variances for Out-of-Distribution Generalization. (arXiv:2109.02934v3 [cs.LG] UPDATED)
54. Algorithmic Fairness Verification with Graphical Models. (arXiv:2109.09447v2 [cs.LG] UPDATED)
55. A modified gravity model based on network efficiency for vital nodes identification in complex networks. (arXiv:2111.01526v2 [cs.SI] UPDATED)
56. Topological and Algebraic Structures of Atanassov's Intuitionistic Fuzzy-Values Space. (arXiv:2111.12677v2 [cs.AI] UPDATED)
57. A Comparative Analysis of Machine Learning Techniques for IoT Intrusion Detection. (arXiv:2111.13149v3 [cs.CR] UPDATED)
58. Improving Customer Service Chatbots with Attention-based Transfer Learning. (arXiv:2111.14621v2 [cs.HC] UPDATED)
59. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v4 [cs.LG] UPDATED)
60. BA-Net: Bridge Attention for Deep Convolutional Neural Networks. (arXiv:2112.04150v3 [cs.CV] UPDATED)
61. Forensic Analysis of Synthetically Generated Western Blot Images. (arXiv:2112.08739v3 [cs.CV] UPDATED)
62. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v4 [cs.CV] UPDATED)
63. Verified Probabilistic Policies for Deep Reinforcement Learning. (arXiv:2201.03698v2 [cs.AI] UPDATED)
64. A Knowledge Graph Embeddings based Approach for Author Name Disambiguation using Literals. (arXiv:2201.09555v3 [cs.AI] UPDATED)
65. Chain of Thought Prompting Elicits Reasoning in Large Language Models. (arXiv:2201.11903v3 [cs.CL] UPDATED)
66. Efficient Policy Space Response Oracles. (arXiv:2202.00633v4 [cs.GT] UPDATED)
67. Graph Self-supervised Learning with Accurate Discrepancy Learning. (arXiv:2202.02989v3 [cs.LG] UPDATED)
68. Generative multitask learning mitigates target-causing confounding. (arXiv:2202.04136v2 [cs.LG] UPDATED)
69. Bayesian Optimisation for Robust Model Predictive Control under Model Parameter Uncertainty. (arXiv:2203.00551v3 [cs.RO] UPDATED)
70. Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization. (arXiv:2203.02214v2 [cs.LG] UPDATED)
71. Efficient Language Modeling with Sparse all-MLP. (arXiv:2203.06850v3 [cs.CL] UPDATED)
72. WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition. (arXiv:2203.06925v3 [cs.CL] UPDATED)
73. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v3 [cs.LG] UPDATED)
74. Graph Neural Networks are Dynamic Programmers. (arXiv:2203.15544v2 [cs.LG] UPDATED)
75. Planning for Temporally Extended Goals in Pure-Past Linear Temporal Logic: A Polynomial Reduction to Standard Planning. (arXiv:2204.09960v3 [cs.AI] UPDATED)
76. A Simple Structure For Building A Robust Model. (arXiv:2204.11596v2 [cs.CV] UPDATED)
77. Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v3 [cs.CR] UPDATED)
78. A Meta-Analysis of the Utility of Explainable Artificial Intelligence in Human-AI Decision-Making. (arXiv:2205.05126v2 [cs.HC] UPDATED)
79. Taming Continuous Posteriors for Latent Variational Dialogue Policies. (arXiv:2205.07633v2 [cs.CL] UPDATED)
80. Dialog Inpainting: Turning Documents into Dialogs. (arXiv:2205.09073v2 [cs.CL] UPDATED)
81. LAGr: Label Aligned Graphs for Better Systematic Generalization in Semantic Parsing. (arXiv:2205.09607v2 [cs.CL] UPDATED)
82. Retrieval-Augmented Multilingual Keyphrase Generation with Retriever-Generator Iterative Training. (arXiv:2205.10471v2 [cs.CL] UPDATED)
83. CNNs are Myopic. (arXiv:2205.10760v3 [cs.CV] UPDATED)
84. Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy, Challenges and Vision. (arXiv:2205.11913v3 [cs.DC] UPDATED)
85. Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v2 [cs.AI] UPDATED)
86. Fairness in Recommendation: A Survey. (arXiv:2205.13619v4 [cs.IR] UPDATED)
87. Architecture-Agnostic Masked Image Modeling -- From ViT back to CNN. (arXiv:2205.13943v2 [cs.CV] UPDATED)
88. WaveMix-Lite: A Resource-efficient Neural Network for Image Analysis. (arXiv:2205.14375v2 [cs.CV] UPDATED)
89. Temporal Multiresolution Graph Neural Networks For Epidemic Prediction. (arXiv:2205.14831v2 [cs.LG] UPDATED)
90. OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs. (arXiv:2205.15117v2 [cs.LG] UPDATED)
91. Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking. (arXiv:2205.15503v2 [cs.CL] UPDATED)
92. Self-Supervised Learning for Building Damage Assessment from Large-scale xBD Satellite Imagery Benchmark Datasets. (arXiv:2205.15688v2 [cs.CV] UPDATED)
93. A Competitive Method for Dog Nose-print Re-identification. (arXiv:2205.15934v2 [cs.CV] UPDATED)

