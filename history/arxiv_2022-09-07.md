# Your interest papers
---
## cs.CV
---
### vieCap4H-VLSP 2021: Vietnamese Image Captioning for Healthcare Domain using **Swin** Transformer and Attention-based LSTM. (arXiv:2209.01304v1 [cs.CV])
- Authors : Thanh Tin, Nhat Truong, Liu Tai, Van Huong, Hai Nguyen, Ngoc Duy
- Link : [http://arxiv.org/abs/2209.01304](http://arxiv.org/abs/2209.01304)
> ABSTRACT  :  This study presents our approach on the automatic Vietnamese image captioning for healthcare domain in text processing tasks of Vietnamese Language and Speech Processing (VLSP) Challenge 2021, as shown in Figure 1. In recent years, image captioning often employs a convolutional neural network-based architecture as an encoder and a long short-term memory (LSTM) as a decoder to generate sentences. These models perform remarkably well in different datasets. Our proposed model also has an encoder and a decoder, but we instead use a **Swin** Transformer in the encoder, and a LSTM combined with an attention module in the decoder. The study presents our training experiments and techniques used during the competition. Our model achieves a BLEU4 score of 0.293 on the vietCap4H dataset, and the score is ranked the 3$^{rd}$ place on the private leaderboard. Our code can be found at \url{https://git.io/JDdJm}.  
### DualCam: A Novel Benchmark Dataset for Fine-grained **Real-time** Traffic Light Detection. (arXiv:2209.01357v1 [cs.CV])
- Authors : Harindu Jayarathne, Tharindu Samarakoon, Hasara Koralege, Asitha Divisekara, Ranga Rodrigo, Peshala Jayasekara
- Link : [http://arxiv.org/abs/2209.01357](http://arxiv.org/abs/2209.01357)
> ABSTRACT  :  Traffic light detection is essential for self-driving cars to navigate safely in urban areas. Publicly available traffic light datasets are inadequate for the development of algorithms for detecting distant traffic lights that provide important navigation information. We introduce a novel benchmark traffic light dataset captured using a synchronized pair of narrow-angle and wide-angle cameras covering urban and semi-urban roads. We provide 1032 images for training and 813 synchronized image pairs for testing. Additionally, we provide synchronized video pairs for qualitative analysis. The dataset includes images of resolution 1920$\times$1080 covering 10 different classes. Furthermore, we propose a post-processing algorithm for combining outputs from the two cameras. Results show that our technique can strike a balance between speed and accuracy, compared to the conventional approach of using a single camera frame.  
### TogetherNet: Bridging Image **Restoration** and Object Detection Together via Dynamic **Enhancement** Learning. (arXiv:2209.01373v1 [cs.CV])
- Authors : Yongzhen Wang, Xuefeng Yan, Kaiwen Zhang, Lina Gong, Haoran Xie, Fu Lee, Mingqiang Wei
- Link : [http://arxiv.org/abs/2209.01373](http://arxiv.org/abs/2209.01373)
> ABSTRACT  :  Adverse weather conditions such as haze, rain, and snow often impair the quality of captured images, causing detection networks trained on normal images to generalize poorly in these scenarios. In this paper, we raise an intriguing question - if the combination of image **restoration** and object detection, can boost the performance of cutting-edge detectors in adverse weather conditions. To answer it, we propose an effective yet unified detection paradigm that bridges these two subtasks together via dynamic **enhancement** learning to discern objects in adverse weather conditions, called TogetherNet. Different from existing efforts that intuitively apply image dehazing/deraining as a pre-processing step, TogetherNet considers a multi-task joint learning problem. Following the joint learning scheme, clean features produced by the **restoration** network can be shared to learn better object detection in the detection network, thus helping TogetherNet enhance the detection capacity in adverse weather conditions. Besides the joint learning architecture, we design a new Dynamic Transformer Feature **Enhancement** module to improve the feature extraction and representation capabilities of TogetherNet. Extensive experiments on both synthetic and real-world datasets demonstrate that our TogetherNet outperforms the state-of-the-art detection approaches by a large margin both quantitatively and qualitatively. Source code is available at https://github.com/yz-wang/TogetherNet.  
### A Variational Approach for Joint Image Recovery and Features Extraction Based on Spatially Varying Generalised Gaussian Models. (arXiv:2209.01375v1 [cs.CV])
- Authors : Emilie Chouzenoux, Caroline Corbineau, Christophe Pesquet, Gabriele Scrivanti
- Link : [http://arxiv.org/abs/2209.01375](http://arxiv.org/abs/2209.01375)
> ABSTRACT  :  The joint problem of reconstruction / feature extraction is a challenging task in image processing. It consists in performing, in a joint manner, the **restoration** of an image and the extraction of its features. In this work, we firstly propose a novel nonsmooth and nonconvex variational formulation of the problem. For this purpose, we introduce a versatile generalised Gaussian prior whose parameters, including its exponent, are space-variant. Secondly, we design an alternating proximal-based optimisation algorithm that efficiently exploits the structure of the proposed nonconvex objective function. We also analyze the convergence of this algorithm. As shown in numerical experiments conducted on joint segmentation/deblurring tasks, the proposed method provides high-quality results.  
### Boosting Salient Object Detection with Transformer-based Asymmetric **Bilateral** U-Net. (arXiv:2108.07851v5 [cs.CV] UPDATED)
- Authors : Yu Qiu, Yun Liu, Le Zhang, Jing Xu
- Link : [http://arxiv.org/abs/2108.07851](http://arxiv.org/abs/2108.07851)
> ABSTRACT  :  Existing salient object detection (SOD) methods mainly rely on U-shaped convolution neural networks (CNNs) with skip connections to combine the global contexts and local spatial details that are crucial for locating salient objects and refining object details, respectively. Despite great successes, the ability of CNNs in learning global contexts is limited. Recently, the vision transformer has achieved revolutionary progress in computer vision owing to its powerful modeling of global dependencies. However, directly applying the transformer to SOD is suboptimal because the transformer lacks the ability to learn local spatial representations. To this end, this paper explores the combination of transformers and CNNs to learn both global and local representations for SOD. We propose a transformer-based Asymmetric **Bilateral** U-Net (ABiU-Net). The asymmetric **bilateral** encoder has a transformer path and a lightweight CNN path, where the two paths communicate at each encoder stage to learn complementary global contexts and local spatial details, respectively. The asymmetric **bilateral** decoder also consists of two paths to process features from the transformer and CNN encoder paths, with communication at each decoder stage for decoding coarse salient object locations and fine-grained object details, respectively. Such communication between the two encoder/decoder paths enables AbiU-Net to learn complementary global and local representations, taking advantage of the natural properties of transformers and CNNs, respectively. Hence, ABiU-Net provides a new perspective for transformer-based SOD. Extensive experiments demonstrate that ABiU-Net performs favorably against previous state-of-the-art SOD methods. The code is available at https://github.com/yuqiuyuqiu/ABiU-Net.  
### Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on Complex Urban Driving Scenes. (arXiv:2111.12264v6 [cs.CV] UPDATED)
- Authors : Yu Tian, Yuyuan Liu, Guansong Pang, Fengbei Liu, Yuanhong Chen, Gustavo Carneiro
- Link : [http://arxiv.org/abs/2111.12264](http://arxiv.org/abs/2111.12264)
> ABSTRACT  :  State-of-the-art (SOTA) anomaly segmentation approaches on complex urban driving scenes explore pixel-wise classification uncertainty learned from outlier **exposure**, or external reconstruction models. However, previous uncertainty approaches that directly associate high uncertainty to anomaly may sometimes lead to incorrect anomaly predictions, and external reconstruction models tend to be too inefficient for real-time self-driving embedded systems. In this paper, we propose a new anomaly segmentation method, named pixel-wise energy-biased abstention learning (PEBAL), that explores pixel-wise abstention learning (AL) with a model that learns an adaptive pixel-level anomaly class, and an energy-based model (EBM) that learns inlier pixel distribution. More specifically, PEBAL is based on a non-trivial joint training of EBM and AL, where EBM is trained to output high-energy for anomaly pixels (from outlier **exposure**) and AL is trained such that these high-energy pixels receive adaptive low penalty for being included to the anomaly class. We extensively evaluate PEBAL against the SOTA and show that it achieves the best performance across four benchmarks. Code is available at https://github.com/tianyu0207/PEBAL.  
### Q-ViT: Fully Differentiable Quantization for Vision Transformer. (arXiv:2201.07703v2 [cs.CV] UPDATED)
- Authors : Zhexin Li, Tong Yang, Peisong Wang, Jian Cheng
- Link : [http://arxiv.org/abs/2201.07703](http://arxiv.org/abs/2201.07703)
> ABSTRACT  :  In this paper, we propose a fully differentiable quantization method for vision transformer (ViT) named as Q-ViT, in which both of the quantization scales and bit-widths are learnable parameters. Specifically, based on our observation that heads in ViT display different quantization robustness, we leverage head-wise bit-width to squeeze the size of Q-ViT while preserving performance. In addition, we propose a novel technique named switchable scale to resolve the convergence problem in the joint training of quantization scales and bit-widths. In this way, Q-ViT pushes the limits of ViT quantization to 3-bit without heavy performance drop. Moreover, we analyze the quantization robustness of every architecture component of ViT and show that the Multi-head Self-Attention (MSA) and the Gaussian Error Linear Units (GELU) are the key aspects for ViT quantization. This study provides some insights for further research about ViT quantization. Extensive experiments on different ViT models, such as DeiT and **Swin** Transformer show the effectiveness of our quantization method. In particular, our method outperforms the state-of-the-art uniform quantization method by 1.5% on DeiT-Tiny.  
### Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v4 [cs.CV] UPDATED)
- Authors : Penglei Gao, Xi Yang, Rui Zhang, Kaizhu Huang, Yujie Geng, Yuyao Yan
- Link : [http://arxiv.org/abs/2201.11403](http://arxiv.org/abs/2201.11403)
> ABSTRACT  :  While most present image outpainting conducts horizontal extrapolation, we study the generalised image outpainting problem that extrapolates visual context all-side around a given image. To this end, we develop a novel transformer-based generative adversarial network called U-Transformer able to extend image borders with plausible structure and details even for complicated scenery images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular **Swin** Transformer blocks. As such, our novel framework can better cope with image long-range dependencies which are crucially important for generalised image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor network to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.  
### An Empirical Study on Activity Recognition in Long Surgical Videos. (arXiv:2205.02805v2 [cs.CV] UPDATED)
- Authors : Zhuohong He, Ali Mottaghi, Aidean Sharghi, Muhammad Abdullah, Omid Mohareri
- Link : [http://arxiv.org/abs/2205.02805](http://arxiv.org/abs/2205.02805)
> ABSTRACT  :  Activity recognition in surgical videos is a key research area for developing next-generation devices and workflow monitoring systems. Since surgeries are long processes with highly-variable lengths, deep learning models used for surgical videos often consist of a two-stage setup using a backbone and temporal sequence model. In this paper, we investigate many state-of-the-art backbones and temporal models to find architectures that yield the strongest performance for surgical activity recognition. We first benchmark the models performance on a large-scale activity recognition dataset containing over 800 surgery videos captured in multiple clinical operating rooms. We further evaluate the models on the two smaller public datasets, the Cholec80 and Cataract-101 datasets, containing only 80 and 101 videos respectively. We empirically found that **Swin**-Transformer+BiGRU temporal model yielded strong performance on both datasets. Finally, we investigate the adaptability of the model to new domains by fine-tuning models to a new hospital and experimenting with a recent unsupervised domain adaptation approach.  
### EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition. (arXiv:2205.14756v2 [cs.CV] UPDATED)
- Authors : Han Cai, Chuang Gan, Muyan Hu, Song Han
- Link : [http://arxiv.org/abs/2205.14756](http://arxiv.org/abs/2205.14756)
> ABSTRACT  :  Vision Transformer (ViT) has achieved remarkable performance in many vision tasks. However, ViT is inferior to convolutional neural networks (CNNs) when targeting high-resolution mobile vision applications. The key computational bottleneck of ViT is the softmax attention module which has quadratic computational complexity with the input resolution. It is essential to reduce the cost of ViT to deploy it on edge devices. Existing methods (e.g., **Swin**, PVT) restrict the softmax attention within local windows or reduce the resolution of key/value tensors to reduce the cost, which sacrifices ViT's core advantages on global feature extractions. In this work, we present EfficientViT, an efficient ViT architecture for high-resolution low-computation visual recognition. Instead of restricting the softmax attention, we propose to replace softmax attention with linear attention while enhancing its local feature extraction ability with depthwise convolution. EfficientViT maintains global and local feature extraction capability while enjoying linear computational complexity. Extensive experiments on COCO object detection and Cityscapes semantic segmentation demonstrate the effectiveness of our method. On the COCO dataset, EfficientViT achieves 42.6 AP with 4.4G MACs, surpassing EfficientDet-D1 by 2.4 AP while having 27.9% fewer MACs. On Cityscapes, EfficientViT reaches 78.7 mIoU with 19.1G MACs, outperforming SegFormer by 2.5 mIoU while requiring less than 1/3 the computational cost. On Qualcomm Snapdragon 855 CPU, EfficientViT is 3x faster than EfficientNet while achieving higher ImageNet accuracy.  
### CLONeR: Camera-Lidar Fusion for Occupancy Grid-aided Neural Representations. (arXiv:2209.01194v2 [cs.CV] UPDATED)
- Authors : Alexandra Carlson, Manikandasriram Srinivasan, Nathan Tseng, Matthew Johnson, Ram Vasudevan
- Link : [http://arxiv.org/abs/2209.01194](http://arxiv.org/abs/2209.01194)
> ABSTRACT  :  Recent advances in neural radiance fields (**NeRF**s) achieve state-of-the-art novel view synthesis and facilitate dense estimation of scene properties. However, **NeRF**s often fail for large, unbounded scenes that are captured under very sparse views with the scene content concentrated far away from the camera, as is typical for field robotics applications. In particular, **NeRF**-style algorithms perform poorly: (1) when there are insufficient views with little pose diversity, (2) when scenes contain saturation and shadows, and (3) when finely sampling large unbounded scenes with fine structures becomes computationally intensive.    This paper proposes CLONeR, which significantly improves upon **NeRF** by allowing it to model large outdoor driving scenes that are observed from sparse input sensor views. This is achieved by decoupling occupancy and color learning within the **NeRF** framework into separate Multi-Layer Perceptrons (MLPs) trained using LiDAR and camera data, respectively. In addition, this paper proposes a novel method to build differentiable 3D Occupancy Grid Maps (OGM) alongside the **NeRF** model, and leverage this occupancy grid for improved sampling of points along a ray for volumetric rendering in metric space.    Through extensive quantitative and qualitative experiments on scenes from the KITTI dataset, this paper demonstrates that the proposed method outperforms state-of-the-art **NeRF** models on both novel view synthesis and dense depth prediction tasks when trained on sparse input data.  
## eess.IV
---
### 4D LUT: Learnable Context-Aware 4D Lookup Table for Image **Enhancement**. (arXiv:2209.01749v1 [eess.IV])
- Authors : Chengxu Liu, Huan Yang, Jianlong Fu, Xueming Qian
- Link : [http://arxiv.org/abs/2209.01749](http://arxiv.org/abs/2209.01749)
> ABSTRACT  :  Image **enhancement** aims at improving the aesthetic visual quality of photos by retouching the color and tone, and is an essential technology for professional digital photography. Recent years deep learning-based image **enhancement** algorithms have achieved promising performance and attracted increasing popularity. However, typical efforts attempt to construct a uniform enhancer for all pixels' color transformation. It ignores the pixel differences between different content (e.g., sky, ocean, etc.) that are significant for photographs, causing unsatisfactory results. In this paper, we propose a novel learnable context-aware 4-dimensional lookup table (4D LUT), which achieves content-dependent **enhancement** of different contents in each image via adaptively learning of photo context. In particular, we first introduce a lightweight context encoder and a parameter encoder to learn a context map for the pixel-level category and a group of image-adaptive coefficients, respectively. Then, the context-aware 4D LUT is generated by integrating multiple basis 4D LUTs via the coefficients. Finally, the enhanced image can be obtained by feeding the source image and context map into fused context-aware 4D~LUT via quadrilinear interpolation. Compared with traditional 3D LUT, i.e., RGB mapping to RGB, which is usually used in camera imaging pipeline systems or tools, 4D LUT, i.e., RGBC(RGB+Context) mapping to RGB, enables finer control of color transformations for pixels with different content in each image, even though they have the same RGB values. Experimental results demonstrate that our method outperforms other state-of-the-art methods in widely-used benchmarks.  
### UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v1 [eess.IV])
- Authors : Xina Liu, Jinfan Hu, Xiangyu Chen, Chao Dong
- Link : [http://arxiv.org/abs/2209.01809](http://arxiv.org/abs/2209.01809)
> ABSTRACT  :  Under-Display Camera (UDC) has been widely exploited to help smartphones realize full screen display. However, as the screen could inevitably affect the light propagation process, the images captured by the UDC system usually contain flare, haze, blur, and noise. Particularly, flare and blur in UDC images could severely deteriorate the user experience in **high dynamic range** (**HDR**) scenes. In this paper, we propose a new deep model, namely UDC-UNet, to address the UDC image **restoration** problem with the known Point Spread Function (PSF) in **HDR** scenes. On the premise that Point Spread Function (PSF) of the UDC system is known, we treat UDC image **restoration** as a non-blind image **restoration** problem and propose a novel learning-based approach. Our network consists of three parts, including a U-shape base network to utilize multi-scale information, a condition branch to perform spatially variant modulation, and a kernel branch to provide the prior knowledge of the given PSF. According to the characteristics of **HDR** data, we additionally design a tone mapping loss to stabilize network optimization and achieve better visual quality. Experimental results show that the proposed UDC-UNet outperforms the state-of-the-art methods in quantitative and qualitative comparisons. Our approach won the second place in the UDC image **restoration** track of MIPI challenge. Codes will be publicly available.  
### LRT: An Efficient **Low-Light** **Restoration** Transformer for **Dark** Light Field Images. (arXiv:2209.02197v1 [cs.CV])
- Authors : Shansi Zhang, Nan Meng
- Link : [http://arxiv.org/abs/2209.02197](http://arxiv.org/abs/2209.02197)
> ABSTRACT  :  Light field (LF) images with the multi-view property have many applications, which can be severely affected by the **low-light** imaging. Recent learning-based methods for **low-light** **enhancement** have their own disadvantages, such as no noise suppression, complex training process and poor performance in extremely **low-light** conditions. Targeted on solving these deficiencies while fully utilizing the multi-view information, we propose an efficient **Low-light** **Restoration** Transformer (LRT) for LF images, with multiple heads to perform specific intermediate tasks, including denoising, luminance adjustment, refinement and detail **enhancement**, within a single network, achieving progressive **restoration** from small scale to full scale. We design an angular transformer block with a view-token scheme to model the global angular relationship efficiently, and a multi-scale window-based transformer block to encode the multi-scale local and global spatial information. To solve the problem of insufficient training data, we formulate a synthesis pipeline by simulating the major noise with the estimated noise parameters of LF camera. Experimental results demonstrate that our method can achieve superior performance on the **restoration** of extremely **low-light** and noisy LF images with high efficiency.  
### **High Dynamic Range** Image Quality Assessment Based on Frequency Disparity. (arXiv:2209.02285v1 [cs.CV])
- Authors : Yue Liu, Zhangkai Ni, Shiqi Wang, Hanli Wang, Sam Kwong
- Link : [http://arxiv.org/abs/2209.02285](http://arxiv.org/abs/2209.02285)
> ABSTRACT  :  In this paper, a novel and effective image quality assessment (IQA) algorithm based on frequency disparity for **high dynamic range** (**HDR**) images is proposed, termed as local-global frequency feature-based model (LGFM). Motivated by the assumption that the human visual system is highly adapted for extracting structural information and partial frequencies when perceiving the visual scene, the Gabor and the Butterworth filters are applied to the luminance of the **HDR** image to extract local and global frequency features, respectively. The similarity measurement and feature pooling are sequentially performed on the frequency features to obtain the predicted quality score. The experiments evaluated on four widely used benchmarks demonstrate that the proposed LGFM can provide a higher consistency with the subjective perception compared with the state-of-the-art **HDR** IQA methods. Our code is available at: \url{https://github.com/eezkni/LGFM}.  
### Multi-task **Swin** Transformer for Motion Artifacts Classification and Cardiac Magnetic Resonance Image Segmentation. (arXiv:2209.02470v1 [eess.IV])
- Authors : Arkadiusz Sitek
- Link : [http://arxiv.org/abs/2209.02470](http://arxiv.org/abs/2209.02470)
> ABSTRACT  :  Cardiac Magnetic Resonance Imaging is commonly used for the assessment of the cardiac anatomy and function. The delineations of left and right ventricle blood pools and left ventricular myocardium are important for the diagnosis of cardiac diseases. Unfortunately, the movement of a patient during the CMR acquisition procedure may result in motion artifacts appearing in the final image. Such artifacts decrease the diagnostic quality of CMR images and force redoing of the procedure. In this paper, we present a Multi-task **Swin** UNEt TRansformer network for simultaneous solving of two tasks in the CMRxMotion challenge: CMR segmentation and motion artifacts classification. We utilize both segmentation and classification as a multi-task learning approach which allows us to determine the diagnostic quality of CMR and generate masks at the same time. CMR images are classified into three diagnostic quality classes, whereas, all samples with non-severe motion artifacts are being segmented. Ensemble of five networks trained using 5-Fold Cross-validation achieves segmentation performance of DICE coefficient of 0.871 and classification accuracy of 0.595.  
### MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation. (arXiv:2209.02498v1 [eess.IV])
- Authors : Justin Sonneck, Jianxu Chen
- Link : [http://arxiv.org/abs/2209.02498](http://arxiv.org/abs/2209.02498)
> ABSTRACT  :  The deep learning research in computer vision has been growing extremely fast in the past decade, many of which have been translated into novel image analysis methods for biomedical problems. Broadly speaking, many deep learning based biomedical image analysis methods can be considered as a general image-to-image transformation framework. In this work, we introduce a new open source python package MMV_Im2Im for image-to-image transformation in bioimaging applications. The overall package is designed with a generic image-to-image transformation framework, which could be directly used for semantic segmentation, instance segmentation, image **restoration**, image generation, etc.. The implementation takes advantage of the state-of-the-art machine learning engineering techniques for users to focus on the research without worrying about the engineering details. We demonstrate the effectiveness of MMV_Im2Im in more than ten different biomedical problems. For biomedical machine learning researchers, we hope this new package could serve as the starting point for their specific problems to stimulate new biomedical image analysis or machine learning methods. For experimental biomedical researchers, we hope this work can provide a holistic view of the image-to-image transformation concept with diverse examples, so that deep learning based image-to-image transformation could be further integrated into the assay development process and permit new biomedical studies that can hardly be done only with traditional experimental methods. Source code can be found at https://github.com/MMV-Lab/mmv_im2im.  
## cs.LG
---
### FedAR+: A Federated Learning Approach to Appliance Recognition with Mislabeled Data in Residential Buildings. (arXiv:2209.01338v1 [cs.LG])
- Authors : Ashish Gupta, Hari Prabhat
- Link : [http://arxiv.org/abs/2209.01338](http://arxiv.org/abs/2209.01338)
> ABSTRACT  :  With the **enhancement** of people's living standards and rapid growth of communication technologies, residential environments are becoming smart and well-connected, increasing overall energy consumption substantially. As household appliances are the primary energy consumers, their recognition becomes crucial to avoid unattended usage, thereby conserving energy and making smart environments more sustainable. An appliance recognition model is traditionally trained at a central server (service provider) by collecting electricity consumption data, recorded via smart plugs, from the clients (consumers), causing a privacy breach. Besides that, the data are susceptible to noisy labels that may appear when an appliance gets connected to a non-designated smart plug. While addressing these issues jointly, we propose a novel federated learning approach to appliance recognition, called FedAR+, enabling decentralized model training across clients in a privacy preserving way even with mislabeled training data. FedAR+ introduces an adaptive noise handling method, essentially a joint loss function incorporating weights and label distribution, to empower the appliance recognition model against noisy labels. By deploying smart plugs in an apartment complex, we collect a labeled dataset that, along with two existing datasets, are utilized to evaluate the performance of FedAR+. Experimental results show that our approach can effectively handle up to $30\%$ concentration of noisy labels while outperforming the prior solutions by a large margin on accuracy.  
### Analysis of Digitalized ECG Signals Based on Artificial Intelligence and Spectral Analysis Methods Specialized in ARVC. (arXiv:2203.00504v4 [eess.SP] UPDATED)
- Authors : Thomas Zegkos, Georgios Efthimiadis, George Tsaklidis
- Link : [http://arxiv.org/abs/2203.00504](http://arxiv.org/abs/2203.00504)
> ABSTRACT  :  Arrhythmogenic right ventricular cardiomyopathy (ARVC) is an inherited heart muscle disease that appears between the second and forth decade of a patient's life, being responsible for 20% of sudden cardiac deaths before the age of 35. The effective and punctual diagnosis of this disease based on Electrocardiograms (ECGs) could have a vital role in reducing premature cardiovascular mortality. In our analysis, we firstly outline the digitalization process of paper - based ECG signals enhanced by a spatial filter aiming to eliminate **dark** regions in the dataset's images that do not correspond to ECG waveform, producing undesirable noise. Next, we propose the utilization of a low - complexity convolutional neural network for the detection of an arrhythmogenic heart disease, that has not been studied through the usage of deep learning methodology to date, achieving high classification accuracy, namely 99.98% training and 98.6% testing accuracy, on a disease the major identification criterion of which are infinitesimal millivolt variations in the ECG's morphology, in contrast with other arrhythmogenic abnormalities. Finally, by performing spectral analysis we investigate significant differentiations in the field of frequencies between normal ECGs and ECGs corresponding to patients suffering from ARVC. In 16 out of the 18 frequencies where we encounter statistically significant differentiations, the normal ECGs are characterized by greater normalized amplitudes compared to the abnormal ones. The overall research carried out in this article highlights the importance of integrating mathematical methods into the examination and effective diagnosis of various diseases, aiming to a substantial contribution to their successful treatment.  
### **Real-time** Neural-MPC: Deep Learning Model Predictive Control for Quadrotors and Agile Robotic Platforms. (arXiv:2203.07747v2 [cs.RO] UPDATED)
- Authors : Tim Salzmann, Elia Kaufmann, Jon Arrizabalaga, Marco Pavone, Davide Scaramuzza, Markus Ryll
- Link : [http://arxiv.org/abs/2203.07747](http://arxiv.org/abs/2203.07747)
> ABSTRACT  :  Model Predictive Control (MPC) has become a popular framework in embedded control for high-performance autonomous systems. However, to achieve good control performance using MPC, an accurate dynamics model is key. To maintain real-time operation, the dynamics models used on embedded systems have been limited to simple first-principle models, which substantially limits their representative power. In contrast to such simple models, machine learning approaches, specifically neural networks, have been shown to accurately model even complex dynamic effects, but their large computational complexity hindered combination with fast real-time iteration loops. With this work, we present **Real-time** Neural MPC, a framework to efficiently integrate large, complex neural network architectures as dynamics models within a model-predictive control pipeline.Our experiments, performed in simulation and the real world onboard a highly agile quadrotor platform, demonstrate the capabilities of the described system to run learned models with, previously infeasible, large modeling capacity using gradient-based online optimization MPC. Compared to prior implementations of neural networks in online optimization MPC we can leverage models of over 4000 times larger parametric capacity in a 50Hz real-time window on an embedded platform. Further, we show the feasibility of our framework on real-world problems by reducing the positional tracking error by up to 82% when compared to state-of-the-art MPC approaches without neural network dynamics.  
### Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v3 [cs.CL] UPDATED)
- Authors : Gati Aher, Adam Tauman
- Link : [http://arxiv.org/abs/2208.10264](http://arxiv.org/abs/2208.10264)
> ABSTRACT  :  We propose a method for using a large language model, such as GPT-3, to simulate responses of different humans in a given context. We test our method by attempting to reproduce well-established economic, psycholinguistic, and social experiments. The method requires prompt templates for each experiment. Simulations are run by varying the (hypothetical) subject details, such as name, and analyzing the text generated by the language model. To validate our methodology, we use GPT-3 to simulate the Ultimatum Game, garden path sentences, risk aversion, and the Milgram Shock experiments. In order to address concerns of **exposure** to these studies in training data, we also evaluate simulations on novel variants of these studies. We show that it is possible to simulate responses of different people and that their responses are largely consistent with prior human studies from the literature. Using large language models as simulators offers advantages but also poses risks. Our use of a language model for simulation is contrasted with anthropomorphic views of a language model as having its own behavior.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v2 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedure and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm on improving the performance of diffusion model. In this article, we present a first comprehensive review of existing variants of the diffusion models. Specifically, we provide a first taxonomy of diffusion models and categorize them variants to three types, namely sampling-acceleration **enhancement**, likelihood-maximization **enhancement** and data-generalization **enhancement**. We also introduce in detail other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models), and clarify the connections between diffusion models and these generative models. Then we make a thorough investigation into the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## cs.AI
---
### vieCap4H-VLSP 2021: Vietnamese Image Captioning for Healthcare Domain using **Swin** Transformer and Attention-based LSTM. (arXiv:2209.01304v1 [cs.CV])
- Authors : Thanh Tin, Nhat Truong, Liu Tai, Van Huong, Hai Nguyen, Ngoc Duy
- Link : [http://arxiv.org/abs/2209.01304](http://arxiv.org/abs/2209.01304)
> ABSTRACT  :  This study presents our approach on the automatic Vietnamese image captioning for healthcare domain in text processing tasks of Vietnamese Language and Speech Processing (VLSP) Challenge 2021, as shown in Figure 1. In recent years, image captioning often employs a convolutional neural network-based architecture as an encoder and a long short-term memory (LSTM) as a decoder to generate sentences. These models perform remarkably well in different datasets. Our proposed model also has an encoder and a decoder, but we instead use a **Swin** Transformer in the encoder, and a LSTM combined with an attention module in the decoder. The study presents our training experiments and techniques used during the competition. Our model achieves a BLEU4 score of 0.293 on the vietCap4H dataset, and the score is ranked the 3$^{rd}$ place on the private leaderboard. Our code can be found at \url{https://git.io/JDdJm}.  
### DualCam: A Novel Benchmark Dataset for Fine-grained **Real-time** Traffic Light Detection. (arXiv:2209.01357v1 [cs.CV])
- Authors : Harindu Jayarathne, Tharindu Samarakoon, Hasara Koralege, Asitha Divisekara, Ranga Rodrigo, Peshala Jayasekara
- Link : [http://arxiv.org/abs/2209.01357](http://arxiv.org/abs/2209.01357)
> ABSTRACT  :  Traffic light detection is essential for self-driving cars to navigate safely in urban areas. Publicly available traffic light datasets are inadequate for the development of algorithms for detecting distant traffic lights that provide important navigation information. We introduce a novel benchmark traffic light dataset captured using a synchronized pair of narrow-angle and wide-angle cameras covering urban and semi-urban roads. We provide 1032 images for training and 813 synchronized image pairs for testing. Additionally, we provide synchronized video pairs for qualitative analysis. The dataset includes images of resolution 1920$\times$1080 covering 10 different classes. Furthermore, we propose a post-processing algorithm for combining outputs from the two cameras. Results show that our technique can strike a balance between speed and accuracy, compared to the conventional approach of using a single camera frame.  
### Do Large Language Models know what humans know?. (arXiv:2209.01515v1 [cs.CL])
- Authors : Sean Trott, Cameron Jones, Tyler Chang, James Michaelov, Benjamin Bergen
- Link : [http://arxiv.org/abs/2209.01515](http://arxiv.org/abs/2209.01515)
> ABSTRACT  :  Humans can attribute mental states to others, a capacity known as Theory of Mind. However, it is unknown to what extent this ability results from an innate biological endowment or from experience accrued through child development, particularly **exposure** to language describing others' mental states. We test the viability of the language **exposure** hypothesis by assessing whether models exposed to large quantities of human language develop evidence of Theory of Mind. In a pre-registered analysis, we present a linguistic version of the False Belief Task, widely used to assess Theory of Mind, to both human participants and a state-of-the-art Large Language Model, GPT-3. Both are sensitive to others' beliefs, but the language model does not perform as well as the humans, nor does it explain the full extent of their behavior, despite being exposed to more language than a human would in a lifetime. This suggests that while language **exposure** may in part explain how humans develop Theory of Mind, other mechanisms are also responsible.  
### Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v3 [cs.CL] UPDATED)
- Authors : Gati Aher, Adam Tauman
- Link : [http://arxiv.org/abs/2208.10264](http://arxiv.org/abs/2208.10264)
> ABSTRACT  :  We propose a method for using a large language model, such as GPT-3, to simulate responses of different humans in a given context. We test our method by attempting to reproduce well-established economic, psycholinguistic, and social experiments. The method requires prompt templates for each experiment. Simulations are run by varying the (hypothetical) subject details, such as name, and analyzing the text generated by the language model. To validate our methodology, we use GPT-3 to simulate the Ultimatum Game, garden path sentences, risk aversion, and the Milgram Shock experiments. In order to address concerns of **exposure** to these studies in training data, we also evaluate simulations on novel variants of these studies. We show that it is possible to simulate responses of different people and that their responses are largely consistent with prior human studies from the literature. Using large language models as simulators offers advantages but also poses risks. Our use of a language model for simulation is contrasted with anthropomorphic views of a language model as having its own behavior.  
# Paper List
---
## cs.CV
---
**128** new papers in cs.CV:-) 
1. Cross-Camera Deep Colorization. (arXiv:2209.01211v1 [cs.CV])
2. AutoPET Challenge 2022: Automatic Segmentation of Whole-body Tumor Lesion Based on Deep Learning and FDG PET/CT. (arXiv:2209.01212v1 [eess.IV])
3. Person Monitoring by Full Body Tracking in Uniform Crowd Environment. (arXiv:2209.01274v1 [cs.CV])
4. Source-Free Unsupervised Domain Adaptation with Norm and Shape Constraints for Medical Image Segmentation. (arXiv:2209.01300v1 [eess.IV])
5. vieCap4H-VLSP 2021: Vietnamese Image Captioning for Healthcare Domain using **Swin** Transformer and Attention-based LSTM. (arXiv:2209.01304v1 [cs.CV])
6. Multimodal and Crossmodal AI for Smart Data Analysis. (arXiv:2209.01308v1 [cs.AI])
7. A Novel Self-Knowledge Distillation Approach with Siamese Representation Learning for Action Recognition. (arXiv:2209.01311v1 [cs.CV])
8. Label Structure Preserving Contrastive Embedding for Multi-Label Learning with Missing Labels. (arXiv:2209.01314v1 [cs.CV])
9. Synthesizing Photorealistic Virtual Humans Through Cross-modal Disentanglement. (arXiv:2209.01320v1 [cs.CV])
10. Continual Learning for Steganalysis. (arXiv:2209.01326v1 [cs.CV])
11. Semi-Supervised Semantic Segmentation with Cross Teacher Training. (arXiv:2209.01327v1 [cs.CV])
12. Class-Specific Channel Attention for Few-Shot Learning. (arXiv:2209.01332v1 [cs.CV])
13. DSE-GAN: Dynamic Semantic Evolution Generative Adversarial Network for Text-to-Image Generation. (arXiv:2209.01339v1 [cs.CV])
14. Semantic Segmentation in Learned Compressed Domain. (arXiv:2209.01355v1 [cs.CV])
15. Masked Sinogram Model with Transformer for ill-Posed Computed Tomography Reconstruction: a Preliminary Study. (arXiv:2209.01356v1 [eess.IV])
16. DualCam: A Novel Benchmark Dataset for Fine-grained **Real-time** Traffic Light Detection. (arXiv:2209.01357v1 [cs.CV])
17. TogetherNet: Bridging Image **Restoration** and Object Detection Together via Dynamic **Enhancement** Learning. (arXiv:2209.01373v1 [cs.CV])
18. A Variational Approach for Joint Image Recovery and Features Extraction Based on Spatially Varying Generalised Gaussian Models. (arXiv:2209.01375v1 [cs.CV])
19. Classification of Breast Tumours Based on Histopathology Images Using Deep Features and Ensemble of Gradient Boosting Methods. (arXiv:2209.01380v1 [eess.IV])
20. Training Strategies for Improved Lip-reading. (arXiv:2209.01383v1 [cs.CV])
21. Vision Transformers and YoloV5 based Driver Drowsiness Detection Framework. (arXiv:2209.01401v1 [cs.CV])
22. Deep learning automates bidimensional and volumetric tumor burden measurement from MRI in pre- and post-operative glioblastoma patients. (arXiv:2209.01402v1 [eess.IV])
23. Towards Accurate Binary Neural Networks via Modeling Contextual Dependencies. (arXiv:2209.01404v1 [cs.CV])
24. Deep Live Video Ad Placement on the 5G Edge. (arXiv:2209.01421v1 [cs.MM])
25. Dynamic Spatio-Temporal Specialization Learning for Fine-Grained Action Recognition. (arXiv:2209.01425v1 [cs.CV])
26. A comprehensive survey on recent deep learning-based methods applied to surgical data. (arXiv:2209.01435v1 [cs.CV])
27. Neural Sign Reenactor: Deep Photorealistic Sign Language Retargeting. (arXiv:2209.01470v1 [cs.CV])
28. Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions. (arXiv:2209.01501v1 [cs.CV])
29. Joint Prediction of Meningioma Grade and Brain Invasion via Task-Aware Contrastive Learning. (arXiv:2209.01517v1 [cs.CV])
30. Data-Driven Deep Supervision for Skin Lesion Classification. (arXiv:2209.01527v1 [cs.CV])
31. Multi-modal Masked Autoencoders Learn Compositional Histopathological Representations. (arXiv:2209.01534v1 [cs.CV])
32. ArcFace: Additive Angular Margin Loss for Deep Face Recognition. (arXiv:1801.07698v4 [cs.CV] UPDATED)
33. Weakly Supervised Silhouette-based Semantic Scene Change Detection. (arXiv:1811.11985v3 [cs.CV] UPDATED)
34. DC-SPP-YOLO: Dense Connection and Spatial Pyramid Pooling Based YOLO for Object Detection. (arXiv:1903.08589v2 [cs.CV] UPDATED)
35. A Closed-Form Uncertainty Propagation in Non-Rigid Structure from Motion. (arXiv:2005.04810v5 [cs.CV] UPDATED)
36. Learnable Descent Algorithm for Nonsmooth Nonconvex Image Reconstruction. (arXiv:2007.11245v5 [cs.CV] UPDATED)
37. Uncertainty Sets for Image Classifiers using Conformal Prediction. (arXiv:2009.14193v5 [cs.CV] UPDATED)
38. Normalized Weighting Schemes for Image Interpolation Algorithms. (arXiv:2011.08559v3 [cs.GR] UPDATED)
39. Towards Better Accuracy-efficiency Trade-offs: Divide and Co-training. (arXiv:2011.14660v4 [cs.CV] UPDATED)
40. MalNet: A Large-Scale Image Database of Malicious Software. (arXiv:2102.01072v2 [cs.CR] UPDATED)
41. Focal Inverse Distance Transform Maps for Crowd Localization. (arXiv:2102.07925v3 [cs.CV] UPDATED)
42. A Comprehensive Review of Deep Learning-based Single Image Super-resolution. (arXiv:2102.09351v3 [cs.CV] UPDATED)
43. MOGAN: Morphologic-structure-aware Generative Learning from a Single Image. (arXiv:2103.02997v3 [cs.CV] UPDATED)
44. LongReMix: Robust Learning with High Confidence Samples in a Noisy Label Environment. (arXiv:2103.04173v2 [cs.CV] UPDATED)
45. Challenges of 3D Surface Reconstruction in Capsule Endoscopy. (arXiv:2103.10390v2 [cs.CV] UPDATED)
46. ECLIPSE : Envisioning CLoud Induced Perturbations in Solar Energy. (arXiv:2104.12419v3 [cs.CV] UPDATED)
47. An overview of deep learning techniques for epileptic seizures detection and prediction based on neuroimaging modalities: Methods, challenges, and future works. (arXiv:2105.14278v3 [cs.LG] UPDATED)
48. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v5 [cs.CV] UPDATED)
49. BEiT: BERT Pre-Training of Image Transformers. (arXiv:2106.08254v2 [cs.CV] UPDATED)
50. VidHarm: A Clip Based Dataset for Harmful Content Detection. (arXiv:2106.08323v4 [cs.CV] UPDATED)
51. Boosting Salient Object Detection with Transformer-based Asymmetric **Bilateral** U-Net. (arXiv:2108.07851v5 [cs.CV] UPDATED)
52. Construction material classification on imbalanced datasets using Vision Transformer (ViT) architecture. (arXiv:2108.09527v2 [cs.CV] UPDATED)
53. ProtoMIL: Multiple Instance Learning with Prototypical Parts for Whole-Slide Image Classification. (arXiv:2108.10612v2 [cs.LG] UPDATED)
54. Joint Debiased Representation Learning and Imbalanced Data Clustering. (arXiv:2109.05232v2 [cs.CV] UPDATED)
55. TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models. (arXiv:2109.10282v5 [cs.CL] UPDATED)
56. Domain generalization in deep learning for contrast-enhanced imaging. (arXiv:2110.07360v3 [eess.IV] UPDATED)
57. TransMorph: Transformer for unsupervised medical image registration. (arXiv:2111.10480v5 [eess.IV] UPDATED)
58. Many Heads but One Brain: Fusion Brain -- a Competition and a Single Multimodal Multitask Architecture. (arXiv:2111.10974v3 [cs.CV] UPDATED)
59. Pixel-wise Energy-biased Abstention Learning for Anomaly Segmentation on Complex Urban Driving Scenes. (arXiv:2111.12264v6 [cs.CV] UPDATED)
60. TriStereoNet: A Trinocular Framework for Multi-baseline Disparity Estimation. (arXiv:2111.12502v2 [cs.CV] UPDATED)
61. Pyramid Adversarial Training Improves ViT Performance. (arXiv:2111.15121v2 [cs.CV] UPDATED)
62. SegDiff: Image Segmentation with Diffusion Probabilistic Models. (arXiv:2112.00390v2 [cs.CV] UPDATED)
63. How to Synthesize a Large-Scale and Trainable Micro-Expression Dataset?. (arXiv:2112.01730v6 [cs.CV] UPDATED)
64. Interpretable Image Classification with Differentiable Prototypes Assignment. (arXiv:2112.02902v2 [cs.CV] UPDATED)
65. Deep ViT Features as Dense Visual Descriptors. (arXiv:2112.05814v2 [cs.CV] UPDATED)
66. Vision Transformer Based Video Hashing Retrieval for Tracing the Source of Fake Videos. (arXiv:2112.08117v2 [cs.CV] UPDATED)
67. Q-ViT: Fully Differentiable Quantization for Vision Transformer. (arXiv:2201.07703v2 [cs.CV] UPDATED)
68. Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v4 [cs.CV] UPDATED)
69. StRegA: Unsupervised Anomaly Detection in Brain MRIs using a Compact Context-encoding Variational Autoencoder. (arXiv:2201.13271v3 [eess.IV] UPDATED)
70. Towards 3D Scene Reconstruction from Locally Scale-Aligned Monocular Video Depth. (arXiv:2202.01470v3 [cs.CV] UPDATED)
71. Video Violence Recognition and Localization Using a Semi-Supervised Hard Attention Model. (arXiv:2202.02212v4 [cs.CV] UPDATED)
72. Analyzing Human Observer Ability in Morphing Attack Detection -- Where Do We Stand?. (arXiv:2202.12426v4 [cs.CV] UPDATED)
73. Extracting Effective Subnetworks with Gumebel-Softmax. (arXiv:2202.12986v3 [cs.CV] UPDATED)
74. A Principled Design of Image Representation: Towards Forensic Tasks. (arXiv:2203.00913v2 [cs.CV] UPDATED)
75. CD-GAN: a robust fusion-based generative adversarial network for unsupervised change detection between heterogeneous images. (arXiv:2203.00948v2 [eess.IV] UPDATED)
76. Disentangling Architecture and Training for Optical Flow. (arXiv:2203.10712v2 [cs.CV] UPDATED)
77. TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers. (arXiv:2203.10726v4 [eess.IV] UPDATED)
78. Generating natural images with direct Patch Distributions Matching. (arXiv:2203.11862v3 [cs.CV] UPDATED)
79. CLIP-Mesh: Generating textured meshes from text using pretrained image-text models. (arXiv:2203.13333v2 [cs.CV] UPDATED)
80. Recognition of polar lows in Sentinel-1 SAR images with deep learning. (arXiv:2203.16401v4 [cs.CV] UPDATED)
81. Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification. (arXiv:2204.02399v3 [cs.LG] UPDATED)
82. Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models. (arXiv:2204.02446v2 [cs.CR] UPDATED)
83. Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer. (arXiv:2204.03638v3 [cs.CV] UPDATED)
84. Beyond Cross-view Image Retrieval: Highly Accurate Vehicle Localization Using Satellite Image. (arXiv:2204.04752v2 [cs.CV] UPDATED)
85. VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance. (arXiv:2204.08583v2 [cs.CV] UPDATED)
86. Tensorial tomographic differential phase-contrast microscopy. (arXiv:2204.11397v2 [physics.optics] UPDATED)
87. DFC: Anatomically Informed Fiber Clustering with Self-supervised Deep Learning for Fast and Effective Tractography Parcellation. (arXiv:2205.00627v2 [cs.CV] UPDATED)
88. Joint Image Compression and Denoising via Latent-Space Scalability. (arXiv:2205.01874v2 [eess.IV] UPDATED)
89. Self-Supervised Learning for Invariant Representations from Multi-Spectral and SAR Images. (arXiv:2205.02049v2 [cs.CV] UPDATED)
90. An Empirical Study on Activity Recognition in Long Surgical Videos. (arXiv:2205.02805v2 [cs.CV] UPDATED)
91. Learning to Count Anything: Reference-less Class-agnostic Counting with Weak Supervision. (arXiv:2205.10203v2 [cs.CV] UPDATED)
92. Mind The Gap: Alleviating Local Imbalance for Unsupervised Cross-Modality Medical Image Segmentation. (arXiv:2205.11888v2 [cs.CV] UPDATED)
93. MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning. (arXiv:2205.13137v3 [cs.CV] UPDATED)
94. EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition. (arXiv:2205.14756v2 [cs.CV] UPDATED)
95. VL-BEiT: Generative Vision-Language Pretraining. (arXiv:2206.01127v2 [cs.CV] UPDATED)
96. Guiding Visual Attention in Deep Convolutional Neural Networks Based on Human Eye Movements. (arXiv:2206.10587v2 [cs.CV] UPDATED)
97. UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior. (arXiv:2206.13389v3 [cs.CV] UPDATED)
98. ProSelfLC: Progressive Self Label Correction Towards A Low-Temperature Entropy State. (arXiv:2207.00118v2 [cs.LG] UPDATED)
99. ReLER@ZJU-Alibaba Submission to the Ego4D Natural Language Queries Challenge 2022. (arXiv:2207.00383v2 [cs.CV] UPDATED)
100. Can Language Understand Depth?. (arXiv:2207.01077v3 [cs.CV] UPDATED)
101. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v4 [eess.IV] UPDATED)
102. PatchZero: Defending against Adversarial Patch Attacks by Detecting and Zeroing the Patch. (arXiv:2207.01795v3 [cs.CV] UPDATED)
103. Domain Knowledge Driven 3D Dose Prediction Using Moment-Based Loss Function. (arXiv:2207.03414v2 [cs.CV] UPDATED)
104. Symmetry-Aware Transformer-based Mirror Detection. (arXiv:2207.06332v3 [cs.CV] UPDATED)
105. Riemannian Geometry Approach for Minimizing Distortion and its Applications. (arXiv:2207.12038v5 [cs.CV] UPDATED)
106. Equivariance and Invariance Inductive Bias for Learning from Insufficient Data. (arXiv:2207.12258v2 [cs.CV] UPDATED)
107. KinePose: A temporally optimized inverse kinematics technique for 6DOF human pose estimation with biomechanical constraints. (arXiv:2207.12841v2 [cs.CV] UPDATED)
108. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v3 [cs.LG] UPDATED)
109. Multimodal Neural Machine Translation with Search Engine Based Image Retrieval. (arXiv:2208.00767v2 [cs.CV] UPDATED)
110. $\textrm{D}^3\textrm{Former}$: Debiased Dual Distilled Transformer for Incremental Learning. (arXiv:2208.00777v2 [cs.CV] UPDATED)
111. The Face of Affective Disorders. (arXiv:2208.01369v3 [cs.CV] UPDATED)
112. Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter. (arXiv:2208.01489v3 [cs.CV] UPDATED)
113. An Efficient Person Clustering Algorithm for Open Checkout-free Groceries. (arXiv:2208.02973v2 [cs.CV] UPDATED)
114. TransMatting: Enhancing Transparent Objects Matting with Transformers. (arXiv:2208.03007v3 [cs.CV] UPDATED)
115. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v2 [cs.CV] UPDATED)
116. Neural Mesh-Based Graphics. (arXiv:2208.05785v3 [cs.CV] UPDATED)
117. Medical image analysis based on transformer: A Review. (arXiv:2208.06643v2 [eess.IV] UPDATED)
118. Autonomous Resource Management in Construction Companies Using Deep Reinforcement Learning Based on IoT. (arXiv:2208.08087v2 [cs.LG] UPDATED)
119. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v3 [cs.LG] UPDATED)
120. A Study on the Impact of Data Augmentation for Training Convolutional Neural Networks in the Presence of Noisy Labels. (arXiv:2208.11176v2 [cs.CV] UPDATED)
121. LAB-Net: LAB Color-Space Oriented Lightweight Network for Shadow Removal. (arXiv:2208.13039v2 [cs.CV] UPDATED)
122. Towards Accurate Reconstruction of 3D Scene Shape from A Single Monocular Image. (arXiv:2208.13241v2 [cs.CV] UPDATED)
123. Effective Image Tampering Localization via Semantic Segmentation Network. (arXiv:2208.13739v3 [cs.CV] UPDATED)
124. Public Parking Spot Detection And Geo-localization Using Transfer Learning. (arXiv:2209.00213v2 [cs.CV] UPDATED)
125. Mapping the ocular surface from monocular videos with an application to dry eye disease grading. (arXiv:2209.00886v2 [cs.CV] UPDATED)
126. Detection of diabetic retinopathy using longitudinal self-supervised learning. (arXiv:2209.00915v2 [cs.CV] UPDATED)
127. Multimodal Information Fusion for Glaucoma and DR Classification. (arXiv:2209.00979v2 [eess.IV] UPDATED)
128. CLONeR: Camera-Lidar Fusion for Occupancy Grid-aided Neural Representations. (arXiv:2209.01194v2 [cs.CV] UPDATED)
## eess.IV
---
**54** new papers in eess.IV:-) 
1. Cross-Camera Deep Colorization. (arXiv:2209.01211v1 [cs.CV])
2. AutoPET Challenge 2022: Automatic Segmentation of Whole-body Tumor Lesion Based on Deep Learning and FDG PET/CT. (arXiv:2209.01212v1 [eess.IV])
3. Source-Free Unsupervised Domain Adaptation with Norm and Shape Constraints for Medical Image Segmentation. (arXiv:2209.01300v1 [eess.IV])
4. Quasi-supervised Learning for Super-resolution PET. (arXiv:2209.01325v1 [eess.IV])
5. Semantic Segmentation in Learned Compressed Domain. (arXiv:2209.01355v1 [cs.CV])
6. Masked Sinogram Model with Transformer for ill-Posed Computed Tomography Reconstruction: a Preliminary Study. (arXiv:2209.01356v1 [eess.IV])
7. Classification of Breast Tumours Based on Histopathology Images Using Deep Features and Ensemble of Gradient Boosting Methods. (arXiv:2209.01380v1 [eess.IV])
8. Deep learning automates bidimensional and volumetric tumor burden measurement from MRI in pre- and post-operative glioblastoma patients. (arXiv:2209.01402v1 [eess.IV])
9. Joint Demosaicing and Fusion of Multiresolution Compressed Acquisitions: Image Formation and Reconstruction Methods. (arXiv:2209.01455v1 [eess.IV])
10. StreamNet: A WAE for White Matter Streamline Analysis. (arXiv:2209.01498v1 [q-bio.QM])
11. Single-pixel tracking and imaging of a high-speed moving object. (arXiv:2209.01554v1 [physics.optics])
12. Spatial-Temporal Transformer for Video Snapshot Compressive Imaging. (arXiv:2209.01578v1 [cs.CV])
13. A systematic study of race and sex bias in CNN-based cardiac MR segmentation. (arXiv:2209.01627v1 [eess.IV])
14. Time-distance vision transformers in lung cancer diagnosis from longitudinal computed tomography. (arXiv:2209.01676v1 [eess.IV])
15. A Multi-scale Video Denoising Algorithm for Raw Image. (arXiv:2209.01740v1 [eess.IV])
16. 4D LUT: Learnable Context-Aware 4D Lookup Table for Image **Enhancement**. (arXiv:2209.01749v1 [eess.IV])
17. REQA: Coarse-to-fine Assessment of Image Quality to Alleviate the Range Effect. (arXiv:2209.01760v1 [eess.IV])
18. Uformer-ICS: A Specialized U-Shaped Transformer for Image Compressive Sensing. (arXiv:2209.01763v1 [eess.IV])
19. B-CANF: Adaptive B-frame Coding with Conditional Augmented Normalizing Flows. (arXiv:2209.01769v1 [eess.IV])
20. Representation Learning for Non-Melanoma Skin Cancer using a Latent Autoencoder. (arXiv:2209.01779v1 [eess.IV])
21. UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v1 [eess.IV])
22. HealthyGAN: Learning from Unannotated Medical Images to Detect Anomalies Associated with Human Disease. (arXiv:2209.01822v1 [eess.IV])
23. Multi-frequency PolSAR Image Fusion Classification Based on Semantic Interactive Information and Topological Structure. (arXiv:2209.01921v1 [eess.IV])
24. Supervised Contrastive Learning to Classify Paranasal Anomalies in the Maxillary Sinus. (arXiv:2209.01937v1 [eess.IV])
25. Volumetric video streaming: Current approaches and implementations. (arXiv:2209.01982v1 [cs.MM])
26. Mesh-based 3D Motion Tracking in Cardiac MRI using Deep Learning. (arXiv:2209.02004v1 [eess.IV])
27. Robust machine learning segmentation for large-scale analysis of heterogeneous clinical brain MRI datasets. (arXiv:2209.02032v1 [eess.IV])
28. Fuzzy Attention Neural Network to Tackle Discontinuity in Airway Segmentation. (arXiv:2209.02048v1 [eess.IV])
29. Domain Generalization for Prostate Segmentation in Transrectal Ultrasound Images: A Multi-center Study. (arXiv:2209.02126v1 [eess.IV])
30. Morphological variations to a ptychographic algorithm. (arXiv:2209.02148v1 [physics.optics])
31. Impact analysis of recovery cases due to COVID19 using LSTM deep learning model. (arXiv:2209.02173v1 [cs.LG])
32. LRT: An Efficient **Low-Light** **Restoration** Transformer for **Dark** Light Field Images. (arXiv:2209.02197v1 [cs.CV])
33. Learning to Predict on Octree for Scalable Point Cloud Geometry Coding. (arXiv:2209.02226v1 [eess.IV])
34. An evaluation of U-Net in Renal Structure Segmentation. (arXiv:2209.02247v1 [eess.IV])
35. **High Dynamic Range** Image Quality Assessment Based on Frequency Disparity. (arXiv:2209.02285v1 [cs.CV])
36. On Effectively Predicting Autism Spectrum Disorder Using an Ensemble of Classifiers. (arXiv:2209.02395v1 [cs.LG])
37. Multi-task **Swin** Transformer for Motion Artifacts Classification and Cardiac Magnetic Resonance Image Segmentation. (arXiv:2209.02470v1 [eess.IV])
38. Novel Method for More Efficient Optimizing the Knowledge-Based Planning: Specific Voxels of each Structure Influenced by Dominant Beamlets (SVSIDB). (arXiv:2209.02490v1 [physics.med-ph])
39. MMV_Im2Im: An Open Source Microscopy Machine Vision Toolbox for Image-to-Image Transformation. (arXiv:2209.02498v1 [eess.IV])
40. Cross Modal Compression: Towards Human-comprehensible Semantic Compression. (arXiv:2209.02574v1 [eess.IV])
41. Deep filter bank regression for super-resolution of anisotropic MR brain images. (arXiv:2209.02611v1 [eess.IV])
42. A Comprehensive Review of Deep Learning-based Single Image Super-resolution. (arXiv:2102.09351v3 [cs.CV] UPDATED)
43. Domain generalization in deep learning for contrast-enhanced imaging. (arXiv:2110.07360v3 [eess.IV] UPDATED)
44. TransMorph: Transformer for unsupervised medical image registration. (arXiv:2111.10480v5 [eess.IV] UPDATED)
45. StRegA: Unsupervised Anomaly Detection in Brain MRIs using a Compact Context-encoding Variational Autoencoder. (arXiv:2201.13271v3 [eess.IV] UPDATED)
46. CD-GAN: a robust fusion-based generative adversarial network for unsupervised change detection between heterogeneous images. (arXiv:2203.00948v2 [eess.IV] UPDATED)
47. TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers. (arXiv:2203.10726v4 [eess.IV] UPDATED)
48. Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification. (arXiv:2204.02399v3 [cs.LG] UPDATED)
49. Joint Image Compression and Denoising via Latent-Space Scalability. (arXiv:2205.01874v2 [eess.IV] UPDATED)
50. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v4 [eess.IV] UPDATED)
51. The Face of Affective Disorders. (arXiv:2208.01369v3 [cs.CV] UPDATED)
52. Medical image analysis based on transformer: A Review. (arXiv:2208.06643v2 [eess.IV] UPDATED)
53. Semantic Communications with Discrete-time Analog Transmission: A PAPR Perspective. (arXiv:2208.08342v2 [cs.IT] UPDATED)
54. Multimodal Information Fusion for Glaucoma and DR Classification. (arXiv:2209.00979v2 [eess.IV] UPDATED)
## cs.LG
---
**194** new papers in cs.LG:-) 
1. Exploiting Fairness to Enhance Sensitive Attributes Reconstruction. (arXiv:2209.01215v1 [cs.LG])
2. A Method for Discovering Novel Classes in Tabular Data. (arXiv:2209.01217v1 [cs.LG])
3. A Framework for Extracting and Encoding Features from Object-Centric Event Data. (arXiv:2209.01219v1 [cs.LG])
4. Cubic-Regularized Newton for Spectral Constrained Matrix Optimization and its Application to Fairness. (arXiv:2209.01229v1 [math.OC])
5. A PDE approach for regret bounds under partial monitoring. (arXiv:2209.01256v1 [math.PR])
6. Feature diversity in self-supervised learning. (arXiv:2209.01275v1 [cs.LG])
7. Learning Practical Communication Strategies in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2209.01288v1 [cs.AI])
8. Are Attribute Inference Attacks Just Imputation?. (arXiv:2209.01292v1 [cs.CR])
9. Geometry of EM and related iterative algorithms. (arXiv:2209.01301v1 [stat.ML])
10. TransPolymer: a Transformer-based Language Model for Polymer Property Predictions. (arXiv:2209.01307v1 [cs.LG])
11. Label Structure Preserving Contrastive Embedding for Multi-Label Learning with Missing Labels. (arXiv:2209.01314v1 [cs.CV])
12. Deep Stable Representation Learning on Electronic Health Records. (arXiv:2209.01321v1 [cs.LG])
13. Classifying Spatial Trajectories. (arXiv:2209.01322v1 [cs.CG])
14. Noise-Robust Bidirectional Learning with Dynamic Sample Reweighting. (arXiv:2209.01334v1 [cs.LG])
15. FedAR+: A Federated Learning Approach to Appliance Recognition with Mislabeled Data in Residential Buildings. (arXiv:2209.01338v1 [cs.LG])
16. Federated XGBoost on Sample-Wise Non-IID Data. (arXiv:2209.01340v1 [cs.LG])
17. Generative Modeling via Tree Tensor Network States. (arXiv:2209.01341v1 [stat.ML])
18. Semi-supervised Training for Knowledge Base Graph Self-attention Networks on Link Prediction. (arXiv:2209.01350v1 [cs.AI])
19. Masked Sinogram Model with Transformer for ill-Posed Computed Tomography Reconstruction: a Preliminary Study. (arXiv:2209.01356v1 [eess.IV])
20. Sharp bounds on the price of bandit feedback for several models of mistake-bounded online learning. (arXiv:2209.01366v1 [cs.LG])
21. Identify The Beehive Sound Using Deep Learning. (arXiv:2209.01374v1 [cs.SD])
22. Tree-Based Learning in RNNs for Power Consumption Forecasting. (arXiv:2209.01378v1 [cs.LG])
23. Training Strategies for Improved Lip-reading. (arXiv:2209.01383v1 [cs.CV])
24. SaleNet: A low-power end-to-end CNN accelerator for sustained attention level evaluation using EEG. (arXiv:2209.01386v1 [cs.AR])
25. Hypergraph convolutional neural network-based clustering technique. (arXiv:2209.01391v1 [cs.LG])
26. Disconnected Emerging Knowledge Graph Oriented Inductive Link Prediction. (arXiv:2209.01397v1 [cs.LG])
27. Optimizing Partial Area Under the Top-k Curve: Theory and Practice. (arXiv:2209.01398v1 [cs.LG])
28. Negative Selection Approach to support Formal Verification and Validation of BlackBox Models' Input Constraints. (arXiv:2209.01411v1 [cs.LG])
29. Suppressing Noise from Built Environment Datasets to Reduce Communication Rounds for Convergence of Federated Learning. (arXiv:2209.01417v1 [cs.LG])
30. From Monte Carlo to neural networks approximations of boundary value problems. (arXiv:2209.01432v1 [math.PR])
31. Phishing URL Detection: A Network-based Approach Robust to Evasion. (arXiv:2209.01454v1 [cs.CR])
32. Machine learning for dynamically predicting the onset of renal replacement therapy in chronic kidney disease patients using claims data. (arXiv:2209.01469v1 [cs.LG])
33. Learning the Dynamics of Particle-based Systems with Lagrangian Graph Neural Networks. (arXiv:2209.01476v1 [cs.LG])
34. Equivariant Self-Supervision for Musical Tempo Estimation. (arXiv:2209.01478v1 [cs.SD])
35. Learning Differential Operators for Interpretable Time Series Modeling. (arXiv:2209.01491v1 [cs.LG])
36. StreamNet: A WAE for White Matter Streamline Analysis. (arXiv:2209.01498v1 [q-bio.QM])
37. Meta-Learning with Less Forgetting on Large-Scale Non-Stationary Task Distributions. (arXiv:2209.01501v1 [cs.CV])
38. Neural Networks for Chess. (arXiv:2209.01506v1 [cs.LG])
39. Low-Power Hardware-Based Deep-Learning Diagnostics Support Case Study. (arXiv:2209.01507v1 [cs.LG])
40. Transfer Learning of an Ensemble of DNNs for SSVEP BCI Spellers without User-Specific Training. (arXiv:2209.01511v1 [cs.LG])
41. A Novel Nearest Neighbors Algorithm Based on Power Muirhead Mean. (arXiv:2209.01514v1 [cs.LG])
42. Quantitative Stopword Generation for Sentiment Analysis via Recursive and Iterative Deletion. (arXiv:2209.01519v1 [cs.CL])
43. Symplectically Integrated Symbolic Regression of Hamiltonian Dynamical Systems. (arXiv:2209.01521v1 [cs.LG])
44. Multi-modal Masked Autoencoders Learn Compositional Histopathological Representations. (arXiv:2209.01534v1 [cs.CV])
45. Natural Compression for Distributed Deep Learning. (arXiv:1905.10988v3 [cs.LG] UPDATED)
46. Software Engineering Practices for Machine Learning. (arXiv:1906.10366v2 [cs.SE] UPDATED)
47. PageRank algorithm for Directed Hypergraph. (arXiv:1909.01132v3 [cs.SI] UPDATED)
48. Intelligent Resource Scheduling for Co-located Latency-critical Services: A Multi-Model Collaborative Learning Approach. (arXiv:1911.13208v3 [cs.DC] UPDATED)
49. Estimating heterogeneous treatment effects with right-censored data via causal survival forests. (arXiv:2001.09887v4 [stat.ME] UPDATED)
50. A Multi-Agent Reinforcement Learning Approach For Safe and Efficient Behavior Planning Of Connected Autonomous Vehicles. (arXiv:2003.04371v3 [cs.AI] UPDATED)
51. FastDTW is approximate and Generally Slower than the Algorithm it Approximates. (arXiv:2003.11246v5 [cs.LG] UPDATED)
52. A Kernel Two-sample Test for Dynamical Systems. (arXiv:2004.11098v3 [stat.ML] UPDATED)
53. Computational Humor Using BERT Sentence Embedding in Parallel Neural Networks. (arXiv:2004.12765v6 [cs.CL] UPDATED)
54. Dimensions of Diversity in Human Perceptions of Algorithmic Fairness. (arXiv:2005.00808v3 [cs.CY] UPDATED)
55. A Deterministic Approximation to Neural SDEs. (arXiv:2006.08973v5 [cs.LG] UPDATED)
56. AI-based Monitoring and Response System for Hospital Preparedness towards COVID-19 in Southeast Asia. (arXiv:2007.15619v2 [cs.CY] UPDATED)
57. Directed hypergraph neural network. (arXiv:2008.03626v3 [stat.ML] UPDATED)
58. Congested Urban Networks Tend to Be Insensitive to Signal Settings: Implications for Learning-Based Control. (arXiv:2008.10989v2 [cs.LG] UPDATED)
59. Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress. (arXiv:2009.13807v5 [cs.LG] UPDATED)
60. Detection of data drift and outliers affecting machine learning model performance over time. (arXiv:2012.09258v3 [stat.AP] UPDATED)
61. A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v12 [cs.LG] UPDATED)
62. MalNet: A Large-Scale Image Database of Malicious Software. (arXiv:2102.01072v2 [cs.CR] UPDATED)
63. Noise-robust classification with hypergraph neural network. (arXiv:2102.01934v3 [stat.ML] UPDATED)
64. Neural Termination Analysis. (arXiv:2102.03824v4 [cs.LG] UPDATED)
65. A Comprehensive Review of Deep Learning-based Single Image Super-resolution. (arXiv:2102.09351v3 [cs.CV] UPDATED)
66. When is Early Classification of Time Series Meaningful?. (arXiv:2102.11487v3 [cs.LG] UPDATED)
67. Error Estimates for the Deep Ritz Method with Boundary Penalty. (arXiv:2103.01007v4 [math.NA] UPDATED)
68. Causal Reinforcement Learning: An Instrumental Variable Approach. (arXiv:2103.04021v2 [stat.ML] UPDATED)
69. A non-asymptotic approach for model selection via penalization in high-dimensional mixture of experts models. (arXiv:2104.02640v3 [math.ST] UPDATED)
70. ECLIPSE : Envisioning CLoud Induced Perturbations in Solar Energy. (arXiv:2104.12419v3 [cs.CV] UPDATED)
71. An overview of deep learning techniques for epileptic seizures detection and prediction based on neuroimaging modalities: Methods, challenges, and future works. (arXiv:2105.14278v3 [cs.LG] UPDATED)
72. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v5 [cs.CV] UPDATED)
73. On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v3 [cs.LG] UPDATED)
74. Query Embedding on Hyper-relational Knowledge Graphs. (arXiv:2106.08166v3 [cs.AI] UPDATED)
75. BEiT: BERT Pre-Training of Image Transformers. (arXiv:2106.08254v2 [cs.CV] UPDATED)
76. BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models. (arXiv:2106.10199v5 [cs.LG] UPDATED)
77. BanditMF: Multi-Armed Bandit Based Matrix Factorization Recommender System. (arXiv:2106.10898v3 [cs.IR] UPDATED)
78. The Role of "Live" in Livestreaming Markets: Evidence Using Orthogonal Random Forest. (arXiv:2107.01629v2 [stat.ML] UPDATED)
79. Least-Squares Linear Dilation-Erosion Regressor Trained using a Convex-Concave Procedure. (arXiv:2107.05682v2 [cs.LG] UPDATED)
80. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v5 [cs.LG] UPDATED)
81. Top-label calibration and multiclass-to-binary reductions. (arXiv:2107.08353v4 [cs.LG] UPDATED)
82. Learning Risk-aware Costmaps for Traversability in Challenging Environments. (arXiv:2107.11722v2 [cs.RO] UPDATED)
83. Convergence of Deep ReLU Networks. (arXiv:2107.12530v2 [cs.LG] UPDATED)
84. Supervised Learning and the Finite-Temperature String Method for Computing Committor Functions and Reaction Rates. (arXiv:2107.13522v2 [cond-mat.stat-mech] UPDATED)
85. How to avoid machine learning pitfalls: a guide for academic researchers. (arXiv:2108.02497v2 [cs.LG] UPDATED)
86. ProtoMIL: Multiple Instance Learning with Prototypical Parts for Whole-Slide Image Classification. (arXiv:2108.10612v2 [cs.LG] UPDATED)
87. Graph-guided random forest for gene set selection. (arXiv:2108.11674v3 [cs.AI] UPDATED)
88. Student Surpasses Teacher: Imitation Attack for Black-Box NLP APIs. (arXiv:2108.13873v2 [cs.CR] UPDATED)
89. Achieving Model Fairness in Vertical Federated Learning. (arXiv:2109.08344v3 [cs.LG] UPDATED)
90. Quantum algorithms for group convolution, cross-correlation, and equivariant transformations. (arXiv:2109.11330v2 [quant-ph] UPDATED)
91. Hitting the Target: Stopping Active Learning at the Cost-Based Optimum. (arXiv:2110.03802v2 [cs.LG] UPDATED)
92. UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning. (arXiv:2110.07577v3 [cs.CL] UPDATED)
93. Generalization in quantum machine learning from few training data. (arXiv:2111.05292v2 [quant-ph] UPDATED)
94. Eluding Secure Aggregation in Federated Learning via Model Inconsistency. (arXiv:2111.07380v5 [cs.LG] UPDATED)
95. Policy Gradient Approach to Compilation of Variational Quantum Circuits. (arXiv:2111.10227v3 [quant-ph] UPDATED)
96. A Practical guide on Explainable AI Techniques applied on Biomedical use case applications. (arXiv:2111.14260v2 [cs.LG] UPDATED)
97. Approximate Spectral Decomposition of Fisher Information Matrix for Simple ReLU Networks. (arXiv:2111.15256v3 [cs.LG] UPDATED)
98. Text classification problems via BERT embedding method and graph convolutional neural network. (arXiv:2111.15379v3 [cs.CL] UPDATED)
99. SegDiff: Image Segmentation with Diffusion Probabilistic Models. (arXiv:2112.00390v2 [cs.CV] UPDATED)
100. SHAPr: An Efficient and Versatile Membership Privacy Risk Metric for Machine Learning. (arXiv:2112.02230v2 [cs.CR] UPDATED)
101. Interpretable Image Classification with Differentiable Prototypes Assignment. (arXiv:2112.02902v2 [cs.CV] UPDATED)
102. Directed Speech Separation for Automatic Speech Recognition of Long Form Conversational Speech. (arXiv:2112.05863v3 [eess.AS] UPDATED)
103. Analysis and Evaluation of Synchronous and Asynchronous FLchain. (arXiv:2112.07938v3 [cs.LG] UPDATED)
104. Adherence Forecasting for Guided Internet-Delivered Cognitive Behavioral Therapy: A Minimally Data-Sensitive Approach. (arXiv:2201.04967v3 [cs.LG] UPDATED)
105. Identifying a Training-Set Attack's Target Using Renormalized Influence Estimation. (arXiv:2201.10055v2 [cs.LG] UPDATED)
106. HEAT: Hyperedge Attention Networks. (arXiv:2201.12113v2 [cs.LG] UPDATED)
107. N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. (arXiv:2201.12886v5 [cs.LG] UPDATED)
108. StRegA: Unsupervised Anomaly Detection in Brain MRIs using a Compact Context-encoding Variational Autoencoder. (arXiv:2201.13271v3 [eess.IV] UPDATED)
109. Transport Score Climbing: Variational Inference Using Forward KL and Adaptive Neural Transport. (arXiv:2202.01841v3 [stat.ML] UPDATED)
110. A Unified Training Process for Fake News Detection based on Fine-Tuned BERT Model. (arXiv:2202.01907v2 [cs.LG] UPDATED)
111. Video Violence Recognition and Localization Using a Semi-Supervised Hard Attention Model. (arXiv:2202.02212v4 [cs.CV] UPDATED)
112. Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience. (arXiv:2202.03407v2 [physics.geo-ph] UPDATED)
113. RECOVER: sequential model optimization platform for combination drug repurposing identifies novel synergistic compounds in vitro. (arXiv:2202.04202v2 [q-bio.QM] UPDATED)
114. Benchmarking Online Sequence-to-Sequence and Character-based Handwriting Recognition from IMU-Enhanced Pens. (arXiv:2202.07036v2 [cs.LG] UPDATED)
115. Artificial Intelligence-Based Analytics for Impacts of COVID-19 and Online Learning on College Students' Mental Health. (arXiv:2202.07441v3 [cs.CY] UPDATED)
116. PLSSVM: A (multi-)GPGPU-accelerated Least Squares Support Vector Machine. (arXiv:2202.12674v3 [cs.LG] UPDATED)
117. Explainability for identification of vulnerable groups in machine learning models. (arXiv:2203.00317v2 [cs.LG] UPDATED)
118. Analysis of Digitalized ECG Signals Based on Artificial Intelligence and Spectral Analysis Methods Specialized in ARVC. (arXiv:2203.00504v4 [eess.SP] UPDATED)
119. CD-GAN: a robust fusion-based generative adversarial network for unsupervised change detection between heterogeneous images. (arXiv:2203.00948v2 [eess.IV] UPDATED)
120. IAE-Net: Integral Autoencoders for Discretization-Invariant Learning. (arXiv:2203.05142v3 [cs.LG] UPDATED)
121. No Free Lunch Theorem for Security and Utility in Federated Learning. (arXiv:2203.05816v3 [cs.LG] UPDATED)
122. **Real-time** Neural-MPC: Deep Learning Model Predictive Control for Quadrotors and Agile Robotic Platforms. (arXiv:2203.07747v2 [cs.RO] UPDATED)
123. Bayesian Low-rank Matrix Completion with Dual-graph Embedding: Prior Analysis and Tuning-free Inference. (arXiv:2203.10044v2 [cs.LG] UPDATED)
124. Modelling continual learning in humans with Hebbian context gating and exponentially decaying task signals. (arXiv:2203.11560v2 [q-bio.NC] UPDATED)
125. Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing. (arXiv:2203.12026v2 [cs.SE] UPDATED)
126. CLIP-Mesh: Generating textured meshes from text using pretrained image-text models. (arXiv:2203.13333v2 [cs.CV] UPDATED)
127. Using Probabilistic Machine Learning to Better Model Temporal Patterns in Parameterizations: a case study with the Lorenz 96 model. (arXiv:2203.14814v2 [cs.LG] UPDATED)
128. Capturing positive network attributes during the estimation of recursive logit models: A prism-based approach. (arXiv:2204.01215v2 [econ.EM] UPDATED)
129. Multi-Modal Hypergraph Diffusion Network with Dual Prior for Alzheimer Classification. (arXiv:2204.02399v3 [cs.LG] UPDATED)
130. Dimensionality Expansion of Load Monitoring Time Series and Transfer Learning for EMS. (arXiv:2204.02802v2 [cs.LG] UPDATED)
131. Transformer-Based Language Models for Software Vulnerability Detection. (arXiv:2204.03214v2 [cs.CR] UPDATED)
132. FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning by Penalizing KL Divergence. (arXiv:2204.08125v2 [cs.LG] UPDATED)
133. Dynamical simulation via quantum machine learning with provable generalization. (arXiv:2204.10269v3 [quant-ph] UPDATED)
134. SoftEdge: Regularizing Graph Classification with Random Soft Edges. (arXiv:2204.10390v2 [cs.LG] UPDATED)
135. Nonbacktracking spectral clustering of nonuniform hypergraphs. (arXiv:2204.13586v2 [cs.SI] UPDATED)
136. An Extensive Data Processing Pipeline for MIMIC-IV. (arXiv:2204.13841v3 [cs.LG] UPDATED)
137. Shape complexity in cluster analysis. (arXiv:2205.08046v3 [cs.LG] UPDATED)
138. Position Aided Beam Prediction in the Real World: How Useful GPS Locations Actually Are?. (arXiv:2205.09054v4 [eess.SP] UPDATED)
139. All You Need Is Logs: Improving Code Completion by Learning from Anonymous IDE Usage Logs. (arXiv:2205.10692v2 [cs.SE] UPDATED)
140. How Powerful are K-hop Message Passing Graph Neural Networks. (arXiv:2205.13328v2 [cs.LG] UPDATED)
141. Neuro-Symbolic Causal Language Planning with Commonsense Prompting. (arXiv:2206.02928v2 [cs.CL] UPDATED)
142. Group privacy for personalized federated learning. (arXiv:2206.03396v2 [cs.LG] UPDATED)
143. FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v2 [cs.LG] UPDATED)
144. I'm Me, We're Us, and I'm Us: Tri-directional Contrastive Learning on Hypergraphs. (arXiv:2206.04739v2 [cs.LG] UPDATED)
145. Semi-Supervised Hierarchical Graph Classification. (arXiv:2206.05416v2 [cs.SI] UPDATED)
146. Explainable expected goal models for performance analysis in football analytics. (arXiv:2206.07212v2 [cs.LG] UPDATED)
147. Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting. (arXiv:2206.09112v4 [cs.LG] UPDATED)
148. Compression and Data Similarity: Combination of Two Techniques for Communication-Efficient Solving of Distributed Variational Inequalities. (arXiv:2206.09446v2 [math.OC] UPDATED)
149. GACT: Activation Compressed Training for Generic Network Architectures. (arXiv:2206.11357v4 [cs.LG] UPDATED)
150. ProSelfLC: Progressive Self Label Correction Towards A Low-Temperature Entropy State. (arXiv:2207.00118v2 [cs.LG] UPDATED)
151. Patient-specific modelling, simulation and real-time processing for respiratory diseases. (arXiv:2207.01082v4 [eess.IV] UPDATED)
152. PatchZero: Defending against Adversarial Patch Attacks by Detecting and Zeroing the Patch. (arXiv:2207.01795v3 [cs.CV] UPDATED)
153. Algebraic and machine learning approach to hierarchical triple-star stability. (arXiv:2207.03151v2 [astro-ph.SR] UPDATED)
154. A Baselined Gated Attention Recurrent Network for Request Prediction in Ridesharing. (arXiv:2207.04709v2 [cs.LG] UPDATED)
155. Boosting Heterogeneous Catalyst Discovery by Structurally Constrained Deep Learning Models. (arXiv:2207.05013v2 [cond-mat.mtrl-sci] UPDATED)
156. A Transfer Learning Based Model for Text Readability Assessment in German. (arXiv:2207.06265v2 [cs.CL] UPDATED)
157. Seeking the Truth Beyond the Data. An Unsupervised Machine Learning Approach. (arXiv:2207.06949v2 [stat.ML] UPDATED)
158. FLOWGEN: Fast and slow graph generation. (arXiv:2207.07656v3 [cs.LG] UPDATED)
159. On the Study of Sample Complexity for Polynomial Neural Networks. (arXiv:2207.08896v2 [cs.LG] UPDATED)
160. Holistic Robust Data-Driven Decisions. (arXiv:2207.09560v2 [stat.ML] UPDATED)
161. A Priority Map for Vision-and-Language Navigation with Trajectory Plans and Feature-Location Cues. (arXiv:2207.11717v2 [cs.LG] UPDATED)
162. Equivariance and Invariance Inductive Bias for Learning from Insufficient Data. (arXiv:2207.12258v2 [cs.CV] UPDATED)
163. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v3 [cs.LG] UPDATED)
164. A Gradient Smoothed Functional Algorithm with Truncated Cauchy Random Perturbations for Stochastic Optimization. (arXiv:2208.00290v2 [math.OC] UPDATED)
165. $\textrm{D}^3\textrm{Former}$: Debiased Dual Distilled Transformer for Incremental Learning. (arXiv:2208.00777v2 [cs.CV] UPDATED)
166. Neural network layers as parametric spans. (arXiv:2208.00809v2 [math.CT] UPDATED)
167. Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter. (arXiv:2208.01489v3 [cs.CV] UPDATED)
168. Interpretable Uncertainty Quantification in AI for HEP. (arXiv:2208.03284v3 [hep-ex] UPDATED)
169. A high-resolution dynamical view on momentum methods for over-parameterized neural networks. (arXiv:2208.03941v2 [cs.LG] UPDATED)
170. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v2 [cs.CV] UPDATED)
171. On the Activation Function Dependence of the Spectral Bias of Neural Networks. (arXiv:2208.04924v3 [cs.LG] UPDATED)
172. Partition Pooling for Convolutional Graph Network Applications in Particle Physics. (arXiv:2208.05952v2 [hep-ex] UPDATED)
173. Autonomous Resource Management in Construction Companies Using Deep Reinforcement Learning Based on IoT. (arXiv:2208.08087v2 [cs.LG] UPDATED)
174. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v3 [cs.LG] UPDATED)
175. Metric Residual Networks for Sample Efficient Goal-Conditioned Reinforcement Learning. (arXiv:2208.08133v2 [cs.LG] UPDATED)
176. Shallow neural network representation of polynomials. (arXiv:2208.08138v6 [stat.ML] UPDATED)
177. DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular Simulation. (arXiv:2208.08236v3 [physics.chem-ph] UPDATED)
178. Semantic Communications with Discrete-time Analog Transmission: A PAPR Perspective. (arXiv:2208.08342v2 [cs.IT] UPDATED)
179. Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v3 [cs.CL] UPDATED)
180. RGB-D Scene Recognition based on Object-Scene Relation. (arXiv:2208.10833v3 [cs.SE] UPDATED)
181. Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost. (arXiv:2208.10842v2 [cs.LG] UPDATED)
182. Multi-Modal Representation Learning with Self-Adaptive Thresholds for Commodity Verification. (arXiv:2208.11064v3 [cs.LG] UPDATED)
183. Causal Bandits for Linear Structural Equation Models. (arXiv:2208.12764v2 [stat.ML] UPDATED)
184. Normalized Activation Function: Toward Better Convergence. (arXiv:2208.13315v2 [cs.LG] UPDATED)
185. Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents. (arXiv:2208.14244v2 [cs.CL] UPDATED)
186. Trading Off Privacy, Utility and Efficiency in Federated Learning. (arXiv:2209.00230v2 [cs.LG] UPDATED)
187. Monotonic Gaussian process for physics-constrained machine learning with materials science applications. (arXiv:2209.00628v2 [cs.LG] UPDATED)
188. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v2 [cs.LG] UPDATED)
189. Detection of diabetic retinopathy using longitudinal self-supervised learning. (arXiv:2209.00915v2 [cs.CV] UPDATED)
190. Multimodal Information Fusion for Glaucoma and DR Classification. (arXiv:2209.00979v2 [eess.IV] UPDATED)
191. Physics-informed MTA-UNet: Prediction of Thermal Stress and Thermal Deformation of Satellites. (arXiv:2209.01009v2 [cs.LG] UPDATED)
192. Can an NN model plainly learn planar layouts?. (arXiv:2209.01075v2 [cs.CG] UPDATED)
193. Neighborhood-aware Scalable Temporal Network Representation Learning. (arXiv:2209.01084v2 [cs.LG] UPDATED)
194. AutoQML: Automatic Generation and Training of Robust Quantum-Inspired Classifiers by Using Genetic Algorithms on Grayscale Images. (arXiv:2208.13246v1 [quant-ph] CROSS LISTED)
## cs.AI
---
**98** new papers in cs.AI:-) 
1. AutoPET Challenge 2022: Automatic Segmentation of Whole-body Tumor Lesion Based on Deep Learning and FDG PET/CT. (arXiv:2209.01212v1 [eess.IV])
2. Exploiting Fairness to Enhance Sensitive Attributes Reconstruction. (arXiv:2209.01215v1 [cs.LG])
3. A Framework for Extracting and Encoding Features from Object-Centric Event Data. (arXiv:2209.01219v1 [cs.LG])
4. Better Peer Grading through Bayesian Inference. (arXiv:2209.01242v1 [cs.AI])
5. Object-based active inference. (arXiv:2209.01258v1 [cs.AI])
6. Feature diversity in self-supervised learning. (arXiv:2209.01275v1 [cs.LG])
7. Learning Practical Communication Strategies in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2209.01288v1 [cs.AI])
8. vieCap4H-VLSP 2021: Vietnamese Image Captioning for Healthcare Domain using **Swin** Transformer and Attention-based LSTM. (arXiv:2209.01304v1 [cs.CV])
9. Multimodal and Crossmodal AI for Smart Data Analysis. (arXiv:2209.01308v1 [cs.AI])
10. A Novel Self-Knowledge Distillation Approach with Siamese Representation Learning for Action Recognition. (arXiv:2209.01311v1 [cs.CV])
11. Continual Learning for Steganalysis. (arXiv:2209.01326v1 [cs.CV])
12. Noise-Robust Bidirectional Learning with Dynamic Sample Reweighting. (arXiv:2209.01334v1 [cs.LG])
13. Federated XGBoost on Sample-Wise Non-IID Data. (arXiv:2209.01340v1 [cs.LG])
14. HammingMesh: A Network Topology for Large-Scale Deep Learning. (arXiv:2209.01346v1 [cs.DC])
15. Semi-supervised Training for Knowledge Base Graph Self-attention Networks on Link Prediction. (arXiv:2209.01350v1 [cs.AI])
16. DualCam: A Novel Benchmark Dataset for Fine-grained **Real-time** Traffic Light Detection. (arXiv:2209.01357v1 [cs.CV])
17. Optimizing Partial Area Under the Top-k Curve: Theory and Practice. (arXiv:2209.01398v1 [cs.LG])
18. Explainability via Short Formulas: the Case of Propositional Logic with Implementation. (arXiv:2209.01403v1 [cs.AI])
19. Closed-Loop View of the Regulation of AI: Equal Impact across Repeated Interactions. (arXiv:2209.01410v1 [cs.AI])
20. MMKGR: Multi-hop Multi-modal Knowledge Graph Reasoning. (arXiv:2209.01416v1 [cs.AI])
21. From Monte Carlo to neural networks approximations of boundary value problems. (arXiv:2209.01432v1 [math.PR])
22. Reinforcement Learning with Prior Policy Guidance for Motion Planning of Dual-Arm Free-Floating Space Robot. (arXiv:2209.01434v1 [cs.RO])
23. Machine learning for dynamically predicting the onset of renal replacement therapy in chronic kidney disease patients using claims data. (arXiv:2209.01469v1 [cs.LG])
24. Equivariant Self-Supervision for Musical Tempo Estimation. (arXiv:2209.01478v1 [cs.SD])
25. A Novel Knowledge-Based Genetic Algorithm for Robot Path Planning in Complex Environments. (arXiv:2209.01482v1 [cs.RO])
26. A Hybrid Tracking Control Strategy for an Unmanned Underwater Vehicle Aided with Bioinspired Neural Dynamics. (arXiv:2209.01484v1 [cs.RO])
27. Model-Free Deep Reinforcement Learning in Software-Defined Networks. (arXiv:2209.01490v1 [cs.AI])
28. Neural Networks for Chess. (arXiv:2209.01506v1 [cs.LG])
29. A Novel Nearest Neighbors Algorithm Based on Power Muirhead Mean. (arXiv:2209.01514v1 [cs.LG])
30. Do Large Language Models know what humans know?. (arXiv:2209.01515v1 [cs.CL])
31. A Scalable Data-Driven Technique for Joint Evacuation Routing and Scheduling Problems. (arXiv:2209.01535v1 [cs.AI])
32. A Multi-Agent Reinforcement Learning Approach For Safe and Efficient Behavior Planning Of Connected Autonomous Vehicles. (arXiv:2003.04371v3 [cs.AI] UPDATED)
33. MalNet: A Large-Scale Image Database of Malicious Software. (arXiv:2102.01072v2 [cs.CR] UPDATED)
34. Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings. (arXiv:2103.06459v2 [cs.CL] UPDATED)
35. A non-asymptotic approach for model selection via penalization in high-dimensional mixture of experts models. (arXiv:2104.02640v3 [math.ST] UPDATED)
36. Signal Processing and Machine Learning Techniques for Terahertz Sensing: An Overview. (arXiv:2104.06309v2 [eess.SP] UPDATED)
37. ECLIPSE : Envisioning CLoud Induced Perturbations in Solar Energy. (arXiv:2104.12419v3 [cs.CV] UPDATED)
38. Network and Physical Layer Attacks and countermeasures to AI-Enabled 6G O-RAN. (arXiv:2106.02494v2 [cs.CR] UPDATED)
39. On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v3 [cs.LG] UPDATED)
40. Query Embedding on Hyper-relational Knowledge Graphs. (arXiv:2106.08166v3 [cs.AI] UPDATED)
41. Least-Squares Linear Dilation-Erosion Regressor Trained using a Convex-Concave Procedure. (arXiv:2107.05682v2 [cs.LG] UPDATED)
42. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v5 [cs.LG] UPDATED)
43. Top-label calibration and multiclass-to-binary reductions. (arXiv:2107.08353v4 [cs.LG] UPDATED)
44. Learning Risk-aware Costmaps for Traversability in Challenging Environments. (arXiv:2107.11722v2 [cs.RO] UPDATED)
45. ProtoMIL: Multiple Instance Learning with Prototypical Parts for Whole-Slide Image Classification. (arXiv:2108.10612v2 [cs.LG] UPDATED)
46. Graph-guided random forest for gene set selection. (arXiv:2108.11674v3 [cs.AI] UPDATED)
47. Algorithmic Information Design in Multi-Player Games: Possibility and Limits in Singleton Congestion. (arXiv:2109.12445v3 [cs.GT] UPDATED)
48. Text-based automatic personality prediction: A bibliographic review. (arXiv:2110.01186v3 [cs.CL] UPDATED)
49. UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning. (arXiv:2110.07577v3 [cs.CL] UPDATED)
50. Phish-Defence: Phishing Detection Using Deep Recurrent Neural Networks. (arXiv:2110.13424v4 [cs.CR] UPDATED)
51. TransMorph: Transformer for unsupervised medical image registration. (arXiv:2111.10480v5 [eess.IV] UPDATED)
52. Many Heads but One Brain: Fusion Brain -- a Competition and a Single Multimodal Multitask Architecture. (arXiv:2111.10974v3 [cs.CV] UPDATED)
53. Learning to Search in Task and Motion Planning with Streams. (arXiv:2111.13144v3 [cs.RO] UPDATED)
54. A Practical guide on Explainable AI Techniques applied on Biomedical use case applications. (arXiv:2111.14260v2 [cs.LG] UPDATED)
55. SegDiff: Image Segmentation with Diffusion Probabilistic Models. (arXiv:2112.00390v2 [cs.CV] UPDATED)
56. Interpretable Image Classification with Differentiable Prototypes Assignment. (arXiv:2112.02902v2 [cs.CV] UPDATED)
57. Visualizing Ensemble Predictions of Music Mood. (arXiv:2112.07627v2 [eess.AS] UPDATED)
58. N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. (arXiv:2201.12886v5 [cs.LG] UPDATED)
59. Investigating the fidelity of explainable artificial intelligence methods for applications of convolutional neural networks in geoscience. (arXiv:2202.03407v2 [physics.geo-ph] UPDATED)
60. Voltage-Dependent Synaptic Plasticity (VDSP): Unsupervised probabilistic Hebbian plasticity rule based on neurons membrane potential. (arXiv:2203.11022v5 [cs.NE] UPDATED)
61. Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing. (arXiv:2203.12026v2 [cs.SE] UPDATED)
62. Word Discovery in Visually Grounded, Self-Supervised Speech Models. (arXiv:2203.15081v4 [eess.AS] UPDATED)
63. Detecting Cloud-Based Phishing Attacks by Combining Deep Learning Models. (arXiv:2204.02446v2 [cs.CR] UPDATED)
64. Transformer-Based Language Models for Software Vulnerability Detection. (arXiv:2204.03214v2 [cs.CR] UPDATED)
65. Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer. (arXiv:2204.03638v3 [cs.CV] UPDATED)
66. Autonomous Mobile Clinics: Empowering Affordable Anywhere Anytime Healthcare Access. (arXiv:2204.04841v3 [cs.CY] UPDATED)
67. DRAGON (Differentiable Graph Execution) : A suite of Hardware Simulation and Optimization tools for Modern AI/Non-AI Workloads. (arXiv:2204.06676v6 [cs.AR] UPDATED)
68. SoftEdge: Regularizing Graph Classification with Random Soft Edges. (arXiv:2204.10390v2 [cs.LG] UPDATED)
69. Shape complexity in cluster analysis. (arXiv:2205.08046v3 [cs.LG] UPDATED)
70. How Powerful are K-hop Message Passing Graph Neural Networks. (arXiv:2205.13328v2 [cs.LG] UPDATED)
71. Understanding Self-Directed Learning in an Online Laboratory. (arXiv:2206.02742v2 [cs.HC] UPDATED)
72. Neuro-Symbolic Causal Language Planning with Commonsense Prompting. (arXiv:2206.02928v2 [cs.CL] UPDATED)
73. Group privacy for personalized federated learning. (arXiv:2206.03396v2 [cs.LG] UPDATED)
74. FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v2 [cs.LG] UPDATED)
75. Semi-Supervised Hierarchical Graph Classification. (arXiv:2206.05416v2 [cs.SI] UPDATED)
76. Rectifying Mono-Label Boolean Classifiers. (arXiv:2206.08758v2 [cs.AI] UPDATED)
77. UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior. (arXiv:2206.13389v3 [cs.CV] UPDATED)
78. Link the World: Improving Open-domain Conversation with Dynamic Spatiotemporal-aware Knowledge. (arXiv:2206.14000v2 [cs.CL] UPDATED)
79. ProSelfLC: Progressive Self Label Correction Towards A Low-Temperature Entropy State. (arXiv:2207.00118v2 [cs.LG] UPDATED)
80. gym-DSSAT: a crop model turned into a Reinforcement Learning environment. (arXiv:2207.03270v3 [cs.AI] UPDATED)
81. A Transfer Learning Based Model for Text Readability Assessment in German. (arXiv:2207.06265v2 [cs.CL] UPDATED)
82. FLOWGEN: Fast and slow graph generation. (arXiv:2207.07656v3 [cs.LG] UPDATED)
83. Equivariance and Invariance Inductive Bias for Learning from Insufficient Data. (arXiv:2207.12258v2 [cs.CV] UPDATED)
84. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v3 [cs.LG] UPDATED)
85. Multimodal Neural Machine Translation with Search Engine Based Image Retrieval. (arXiv:2208.00767v2 [cs.CV] UPDATED)
86. Evolutionary bagging for ensemble learning. (arXiv:2208.02400v3 [cs.NE] UPDATED)
87. A high-resolution dynamical view on momentum methods for over-parameterized neural networks. (arXiv:2208.03941v2 [cs.LG] UPDATED)
88. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v2 [cs.CV] UPDATED)
89. Metric Residual Networks for Sample Efficient Goal-Conditioned Reinforcement Learning. (arXiv:2208.08133v2 [cs.LG] UPDATED)
90. UnCommonSense: Informative Negative Knowledge about Everyday Concepts. (arXiv:2208.09292v3 [cs.AI] UPDATED)
91. Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v3 [cs.CL] UPDATED)
92. RGB-D Scene Recognition based on Object-Scene Relation. (arXiv:2208.10833v3 [cs.SE] UPDATED)
93. Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost. (arXiv:2208.10842v2 [cs.LG] UPDATED)
94. Normalized Activation Function: Toward Better Convergence. (arXiv:2208.13315v2 [cs.LG] UPDATED)
95. Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents. (arXiv:2208.14244v2 [cs.CL] UPDATED)
96. Mapping the ocular surface from monocular videos with an application to dry eye disease grading. (arXiv:2209.00886v2 [cs.CV] UPDATED)
97. Detection of diabetic retinopathy using longitudinal self-supervised learning. (arXiv:2209.00915v2 [cs.CV] UPDATED)
98. AutoQML: Automatic Generation and Training of Robust Quantum-Inspired Classifiers by Using Genetic Algorithms on Grayscale Images. (arXiv:2208.13246v1 [quant-ph] CROSS LISTED)

