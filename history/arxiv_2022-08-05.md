# Your interest papers
---
## cs.CV
---
### H2-Stereo: High-Speed, High-Resolution Stereoscopic Video System. (arXiv:2208.02436v1 [cs.CV])
- Authors : Ming Cheng, Yiling Xu, Wang Shen, Salman Asif, Chao Ma, Jun Sun, Zhan Ma
- Link : [http://arxiv.org/abs/2208.02436](http://arxiv.org/abs/2208.02436)
> ABSTRACT  :  High-speed, high-resolution stereoscopic (H2-Stereo) video allows us to perceive dynamic 3D content at fine granularity. The acquisition of H2-Stereo video, however, remains challenging with commodity cameras. Existing spatial super-resolution or temporal frame interpolation methods provide compromised solutions that lack temporal or spatial details, respectively. To alleviate this problem, we propose a dual camera system, in which one camera captures high-spatial-resolution low-frame-rate (HSR-LFR) videos with rich spatial details, and the other captures low-spatial-resolution high-frame-rate (LSR-HFR) videos with smooth temporal details. We then devise a Learned Information Fusion network (LIFnet) that exploits the cross-camera redundancies to enhance both camera views to high spatiotemporal resolution (HSTR) for reconstructing the H2-Stereo video effectively. We utilize a disparity network to transfer spatiotemporal information across views even in large disparity scenes, based on which, we propose disparity-guided flow-based warping for LSR-HFR view and complementary warping for HSR-LFR view. A multi-scale fusion method in feature domain is proposed to minimize occlusion-induced warping ghosts and holes in HSR-LFR view. The LIFnet is trained in an end-to-end manner using our collected high-quality Stereo Video dataset from YouTube. Extensive experiments demonstrate that our model outperforms existing state-of-the-art methods for both views on synthetic data and camera-captured real data with large disparity. Ablation studies explore various aspects, including spatiotemporal resolution, camera baseline, camera desynchronization, long/short **exposure**s and applications, of our system to fully understand its capability for potential applications.  
### Multi-scale Sampling and Aggregation Network For **High Dynamic Range** Imaging. (arXiv:2208.02448v1 [cs.CV])
- Authors : Jun Xiao, Qian Ye, Tianshan Liu, Cong Zhang, Man Lam
- Link : [http://arxiv.org/abs/2208.02448](http://arxiv.org/abs/2208.02448)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is a fundamental problem in image processing, which aims to generate well-exposed images, even in the presence of varying illumination in the scenes. In recent years, multi-**exposure** fusion methods have achieved remarkable results, which merge multiple low dynamic range (LDR) images, captured with different **exposure**s, to generate corresponding **HDR** images. However, synthesizing **HDR** images in dynamic scenes is still challenging and in high demand. There are two challenges in producing **HDR** images: 1). Object motion between LDR images can easily cause undesirable ghosting artifacts in the generated results. 2). Under and overexposed regions often contain distorted image content, because of insufficient compensation for these regions in the merging stage. In this paper, we propose a multi-scale sampling and aggregation network for **HDR** imaging in dynamic scenes. To effectively alleviate the problems caused by small and large motions, our method implicitly aligns LDR images by sampling and aggregating high-correspondence features in a coarse-to-fine manner. Furthermore, we propose a densely connected network based on discrete wavelet transform for performance improvement, which decomposes the input into several non-overlapping frequency subbands and adaptively performs compensation in the wavelet domain. Experiments show that our proposed method can achieve state-of-the-art performances under diverse scenes, compared to other promising **HDR** imaging methods. In addition, the **HDR** images generated by our method contain cleaner and more detailed content, with fewer distortions, leading to better visual quality.  
### Learning Modal-Invariant and Temporal-Memory for Video-based Visible-Infrared Person Re-Identification. (arXiv:2208.02450v1 [cs.CV])
- Authors : Xinyu Lin, Jinxing Li, Zeyu Ma, Huafeng Li, Shuang Li, Kaixiong Xu, Guangming Lu, David Zhang
- Link : [http://arxiv.org/abs/2208.02450](http://arxiv.org/abs/2208.02450)
> ABSTRACT  :  Thanks for the cross-modal retrieval techniques, visible-infrared (RGB-IR) person re-identification (Re-ID) is achieved by projecting them into a common space, allowing person Re-ID in 24-hour surveillance systems. However, with respect to the probe-to-gallery, almost all existing RGB-IR based cross-modal person Re-ID methods focus on image-to-image matching, while the video-to-video matching which contains much richer spatial- and temporal-information remains under-explored. In this paper, we primarily study the video-based cross-modal person Re-ID method. To achieve this task, a video-based RGB-IR dataset is constructed, in which 927 valid identities with 463,259 frames and 21,863 tracklets captured by 12 RGB/IR cameras are collected. Based on our constructed dataset, we prove that with the increase of frames in a tracklet, the performance does meet more **enhancement**, demonstrating the significance of video-to-video matching in RGB-IR person Re-ID. Additionally, a novel method is further proposed, which not only projects two modalities to a modal-invariant subspace, but also extracts the temporal-memory for motion-invariant. Thanks to these two strategies, much better results are achieved on our video-based cross-modal person Re-ID. The code and dataset are released at: https://github.com/VCMproject233/MITML.  
### Online Video Super-Resolution with Convolutional Kernel Bypass Graft. (arXiv:2208.02470v1 [cs.CV])
- Authors : Jun Xiao, Xinyang Jiang, Ningxin Zheng, Huan Yang, Yifan Yang, Yuqing Yang, Dongsheng Li, Man Lam
- Link : [http://arxiv.org/abs/2208.02470](http://arxiv.org/abs/2208.02470)
> ABSTRACT  :  Deep learning-based models have achieved remarkable performance in video super-resolution (VSR) in recent years, but most of these models are less applicable to online video applications. These methods solely consider the distortion quality and ignore crucial requirements for online applications, e.g., low latency and low model complexity. In this paper, we focus on online video transmission, in which VSR algorithms are required to generate high-resolution video sequences frame by frame in **real time**. To address such challenges, we propose an extremely low-latency VSR algorithm based on a novel kernel knowledge transfer method, named convolutional kernel bypass graft (CKBG). First, we design a lightweight network structure that does not require future frames as inputs and saves extra time costs for caching these frames. Then, our proposed CKBG method enhances this lightweight base model by bypassing the original network with ``kernel grafts'', which are extra convolutional kernels containing the prior knowledge of external pretrained image SR models. In the testing phase, we further accelerate the grafted multi-branch network by converting it into a simple single-path structure. Experiment results show that our proposed method can process online video sequences up to 110 FPS, with very low model complexity and competitive SR performance.  
### Scalable Video Coding for Humans and Machines. (arXiv:2208.02512v1 [eess.IV])
- Authors : Hyomin Choi
- Link : [http://arxiv.org/abs/2208.02512](http://arxiv.org/abs/2208.02512)
> ABSTRACT  :  Video content is watched not only by humans, but increasingly also by machines. For example, machine learning models analyze surveillance video for security and traffic monitoring, search through YouTube videos for inappropriate content, and so on. In this paper, we propose a scalable video coding framework that supports machine vision (specifically, object detection) through its base layer bitstream and human vision via its **enhancement** layer bitstream. The proposed framework includes components from both conventional and Deep Neural Network (DNN)-based video coding. The results show that on object detection, the proposed framework achieves 13-19% bit savings compared to state-of-the-art video codecs, while remaining competitive in terms of MS-SSIM on the human vision task.  
### 360Roam: Real-Time Indoor Roaming Using Geometry-Aware ${360^\circ}$ Radiance Fields. (arXiv:2208.02705v1 [cs.CV])
- Authors : Huajian Huang, Yingshu Chen, Tianjian Zhang, Kit Yeung
- Link : [http://arxiv.org/abs/2208.02705](http://arxiv.org/abs/2208.02705)
> ABSTRACT  :  Neural radiance field (**NeRF**) has recently achieved impressive results in novel view synthesis. However, previous works on **NeRF** mainly focus on object-centric scenarios. In this work, we propose 360Roam, a novel scene-level **NeRF** system that can synthesize images of large-scale indoor scenes in **real time** and support VR roaming. Our system first builds an omnidirectional neural radiance field 360**NeRF** from multiple input $360^\circ$ images. Using 360**NeRF**, we then progressively estimate a 3D probabilistic occupancy map which represents the scene geometry in the form of spacial density. Skipping empty spaces and upsampling occupied voxels essentially allows us to accelerate volume rendering by using 360**NeRF** in a geometry-aware fashion. Furthermore, we use an adaptive divide-and-conquer strategy to slim and fine-tune the radiance fields for further improvement. The floorplan of the scene extracted from the occupancy map can provide guidance for ray sampling and facilitate a realistic roaming experience. To show the efficacy of our system, we collect a $360^\circ$ image dataset in a large variety of scenes and conduct extensive experiments. Quantitative and qualitative comparisons among baselines illustrated our predominant performance in novel view synthesis for complex indoor scenes.  
### Expanding Language-Image Pretrained Models for General Video Recognition. (arXiv:2208.02816v1 [cs.CV])
- Authors : Bolin Ni, Houwen Peng, Minghao Chen, Songyang Zhang, Gaofeng Meng, Jianlong Fu, Shiming Xiang, Haibin Ling
- Link : [http://arxiv.org/abs/2208.02816](http://arxiv.org/abs/2208.02816)
> ABSTRACT  :  Contrastive language-image pretraining has shown great success in learning visual-textual joint representation from web-scale data, demonstrating remarkable "zero-shot" generalization ability for various image tasks. However, how to effectively expand such new language-image pretraining methods to video domains is still an open problem. In this work, we present a simple yet effective approach that adapts the pretrained language-image models to video recognition directly, instead of pretraining a new model from scratch. More concretely, to capture the long-range dependencies of frames along the temporal dimension, we propose a cross-frame attention mechanism that explicitly exchanges information across frames. Such module is lightweight and can be plugged into pretrained language-image models seamlessly. Moreover, we propose a video-specific prompting scheme, which leverages video content information for generating discriminative textual prompts. Extensive experiments demonstrate that our approach is effective and can be generalized to different video recognition scenarios. In particular, under fully-supervised settings, our approach achieves a top-1 accuracy of 87.1% on Kinectics-400, while using 12 times fewer FLOPs compared with **Swin**-L and ViViT-H. In zero-shot experiments, our approach surpasses the current state-of-the-art methods by +7.6% and +14.9% in terms of top-1 accuracy under two popular protocols. In few-shot scenarios, our approach outperforms previous best methods by +32.1% and +23.1% when the labeled data is extremely limited. Code and models are available at https://aka.ms/X-CLIP  
### On the Connection between Local Attention and Dynamic Depth-wise Convolution. (arXiv:2106.04263v5 [cs.CV] UPDATED)
- Authors : Qi Han, Zejia Fan, Qi Dai, Lei Sun, Ming Cheng, **Jiaying Liu**, Jingdong Wang
- Link : [http://arxiv.org/abs/2106.04263](http://arxiv.org/abs/2106.04263)
> ABSTRACT  :  Vision Transformer (ViT) attains state-of-the-art performance in visual recognition, and the variant, Local Vision Transformer, makes further improvements. The major component in Local Vision Transformer, local attention, performs the attention separately over small local windows. We rephrase local attention as a channel-wise locally-connected layer and analyze it from two network regularization manners, sparse connectivity and weight sharing, as well as weight computation. Sparse connectivity: there is no connection across channels, and each position is connected to the positions within a small local window. Weight sharing: the connection weights for one position are shared across channels or within each group of channels. Dynamic weight: the connection weights are dynamically predicted according to each image instance. We point out that local attention resembles depth-wise convolution and its dynamic version in sparse connectivity. The main difference lies in weight sharing - depth-wise convolution shares connection weights (kernel weights) across spatial positions. We empirically observe that the models based on depth-wise convolution and the dynamic variant with lower computation complexity perform on-par with or sometimes slightly better than **Swin** Transformer, an instance of Local Vision Transformer, for ImageNet classification, COCO object detection and ADE semantic segmentation. These observations suggest that Local Vision Transformer takes advantage of two regularization forms and dynamic weight to increase the network capacity. Code is available at https://github.com/Atten4Vis/DemystifyLocalViT.  
### YOLO-FaceV2: A Scale and Occlusion Aware Face Detector. (arXiv:2208.02019v2 [cs.CV] UPDATED)
- Authors : Ziping Yu, Hongbo Huang, Weijun Chen, Yongxin Su, Yahui Liu, Xiuying Wang
- Link : [http://arxiv.org/abs/2208.02019](http://arxiv.org/abs/2208.02019)
> ABSTRACT  :  In recent years, face detection algorithms based on deep learning have made great progress. These algorithms can be generally divided into two categories, i.e. two-stage detector like Faster R-CNN and one-stage detector like YOLO. Because of the better balance between accuracy and speed, one-stage detectors have been widely used in many applications. In this paper, we propose a real-time face detector based on the one-stage detector YOLOv5, named YOLO-FaceV2. We design a Receptive Field **Enhancement** module called RFE to enhance receptive field of small face, and use NWD Loss to make up for the sensitivity of IoU to the location deviation of tiny objects. For face occlusion, we present an attention module named SEAM and introduce Repulsion Loss to solve it. Moreover, we use a weight function Slide to solve the imbalance between easy and hard samples and use the information of the effective receptive field to design the anchor. The experimental results on WiderFace dataset show that our face detector outperforms YOLO and its variants can be find in all easy, medium and hard subsets. Source code in https://github.com/Krasjet-Yu/YOLO-FaceV2  
### GPPF: A General Perception Pre-training Framework via Sparsely Activated Multi-Task Learning. (arXiv:2208.02148v2 [cs.CV] UPDATED)
- Authors : Benyuan Sun, Jin Dai, Zihao Liang, Congying Liu, Yi Yang, Bo Bai
- Link : [http://arxiv.org/abs/2208.02148](http://arxiv.org/abs/2208.02148)
> ABSTRACT  :  Pre-training over mixtured multi-task, multi-domain, and multi-modal data remains an open challenge in vision perception pre-training. In this paper, we propose GPPF, a General Perception Pre-training Framework, that pre-trains a task-level dynamic network, which is composed by knowledge "legos" in each layers, on labeled multi-task and multi-domain datasets. By inspecting humans' innate ability to learn in complex environment, we recognize and transfer three critical elements to deep networks: (1) simultaneous **exposure** to diverse cross-task and cross-domain information in each batch. (2) partitioned knowledge storage in separate lego units driven by knowledge sharing. (3) sparse activation of a subset of lego units for both pre-training and downstream tasks. Noteworthy, the joint training of disparate vision tasks is non-trivial due to their differences in input shapes, loss functions, output formats, data distributions, etc. Therefore, we innovatively develop a plug-and-play multi-task training algorithm, which supports Single Iteration Multiple Tasks (SIMT) concurrently training. SIMT lays the foundation of pre-training with large-scale multi-task multi-domain datasets and is proved essential for stable training in our GPPF experiments. Excitingly, the exhaustive experiments show that, our GPPF-R50 model achieves significant improvements of 2.5-5.8 over a strong baseline of the 8 pre-training tasks in GPPF-15M and harvests a range of SOTAs over the 22 downstream tasks with similar computation budgets. We also validate the generalization ability of GPPF to SOTA vision transformers with consistent improvements. These solid experimental results fully prove the effective knowledge learning, storing, sharing, and transfer provided by our novel GPPF framework.  
## eess.IV
---
### Multi-scale Sampling and Aggregation Network For **High Dynamic Range** Imaging. (arXiv:2208.02448v1 [cs.CV])
- Authors : Jun Xiao, Qian Ye, Tianshan Liu, Cong Zhang, Man Lam
- Link : [http://arxiv.org/abs/2208.02448](http://arxiv.org/abs/2208.02448)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is a fundamental problem in image processing, which aims to generate well-exposed images, even in the presence of varying illumination in the scenes. In recent years, multi-**exposure** fusion methods have achieved remarkable results, which merge multiple low dynamic range (LDR) images, captured with different **exposure**s, to generate corresponding **HDR** images. However, synthesizing **HDR** images in dynamic scenes is still challenging and in high demand. There are two challenges in producing **HDR** images: 1). Object motion between LDR images can easily cause undesirable ghosting artifacts in the generated results. 2). Under and overexposed regions often contain distorted image content, because of insufficient compensation for these regions in the merging stage. In this paper, we propose a multi-scale sampling and aggregation network for **HDR** imaging in dynamic scenes. To effectively alleviate the problems caused by small and large motions, our method implicitly aligns LDR images by sampling and aggregating high-correspondence features in a coarse-to-fine manner. Furthermore, we propose a densely connected network based on discrete wavelet transform for performance improvement, which decomposes the input into several non-overlapping frequency subbands and adaptively performs compensation in the wavelet domain. Experiments show that our proposed method can achieve state-of-the-art performances under diverse scenes, compared to other promising **HDR** imaging methods. In addition, the **HDR** images generated by our method contain cleaner and more detailed content, with fewer distortions, leading to better visual quality.  
### Scalable Video Coding for Humans and Machines. (arXiv:2208.02512v1 [eess.IV])
- Authors : Hyomin Choi
- Link : [http://arxiv.org/abs/2208.02512](http://arxiv.org/abs/2208.02512)
> ABSTRACT  :  Video content is watched not only by humans, but increasingly also by machines. For example, machine learning models analyze surveillance video for security and traffic monitoring, search through YouTube videos for inappropriate content, and so on. In this paper, we propose a scalable video coding framework that supports machine vision (specifically, object detection) through its base layer bitstream and human vision via its **enhancement** layer bitstream. The proposed framework includes components from both conventional and Deep Neural Network (DNN)-based video coding. The results show that on object detection, the proposed framework achieves 13-19% bit savings compared to state-of-the-art video codecs, while remaining competitive in terms of MS-SSIM on the human vision task.  
## cs.LG
---
## cs.AI
---
# Paper List
---
## cs.CV
---
**87** new papers in cs.CV:-) 
1. Unsupervised Flow Refinement near Motion Boundaries. (arXiv:2208.02305v1 [cs.CV])
2. Counterfactual Image Synthesis for Discovery of Personalized Predictive Image Markers. (arXiv:2208.02311v1 [cs.CV])
3. Image-based Detection of Surface Defects in Concrete during Construction. (arXiv:2208.02313v1 [cs.CV])
4. Towards Generating Large Synthetic Phytoplankton Datasets for Efficient Monitoring of Harmful Algal Blooms. (arXiv:2208.02332v1 [cs.CV])
5. Estimating Visual Information From Audio Through Manifold Learning. (arXiv:2208.02337v1 [cs.CV])
6. Word-Level Fine-Grained Story Visualization. (arXiv:2208.02341v1 [cs.CV])
7. Graph Neural Networks Extract High-Resolution Cultivated Land Maps from Sentinel-2 Image Series. (arXiv:2208.02349v1 [cs.CV])
8. A Multibranch Convolutional Neural Network for Hyperspectral Unmixing. (arXiv:2208.02361v1 [cs.CV])
9. End-to-end deep learning for directly estimating grape yield from ground-based imagery. (arXiv:2208.02394v1 [cs.CV])
10. Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing. (arXiv:2208.02397v1 [cs.CV])
11. Deep Semi-Supervised and Self-Supervised Learning for Diabetic Retinopathy Detection. (arXiv:2208.02408v1 [cs.CV])
12. NIR-to-VIS Face Recognition via Embedding Relations and Coordinates of the Pairwise Features. (arXiv:2208.02417v1 [cs.CV])
13. A New Kind of Adversarial Example. (arXiv:2208.02430v1 [cs.CV])
14. Image-based Contextual Pill Recognition with Medical Knowledge Graph Assistance. (arXiv:2208.02432v1 [cs.CV])
15. H2-Stereo: High-Speed, High-Resolution Stereoscopic Video System. (arXiv:2208.02436v1 [cs.CV])
16. FedDRL: Deep Reinforcement Learning-based Adaptive Aggregation for Non-IID Data in Federated Learning. (arXiv:2208.02442v1 [cs.LG])
17. Multi-scale Sampling and Aggregation Network For **High Dynamic Range** Imaging. (arXiv:2208.02448v1 [cs.CV])
18. Learning Modal-Invariant and Temporal-Memory for Video-based Visible-Infrared Person Re-Identification. (arXiv:2208.02450v1 [cs.CV])
19. Privacy-Preserving Action Recognition via Motion Difference Quantization. (arXiv:2208.02459v1 [cs.CV])
20. Online Video Super-Resolution with Convolutional Kernel Bypass Graft. (arXiv:2208.02470v1 [cs.CV])
21. CFARnet: deep learning for target detection with constant false alarm rate. (arXiv:2208.02474v1 [cs.LG])
22. Privacy Safe Representation Learning via Frequency Filtering Encoder. (arXiv:2208.02482v1 [cs.CV])
23. Semantic Segmentation of Fruits on Multi-sensor Fused Data in Natural Orchards. (arXiv:2208.02483v1 [cs.CV])
24. RAZE: Region Guided Self-Supervised Gaze Representation Learning. (arXiv:2208.02485v1 [cs.CV])
25. Heart rate estimation in intense exercise videos. (arXiv:2208.02509v1 [cs.CV])
26. Scalable Video Coding for Humans and Machines. (arXiv:2208.02512v1 [eess.IV])
27. Fine-Grained Semantically Aligned Vision-Language Pre-Training. (arXiv:2208.02515v1 [cs.CV])
28. IPDAE: Improved Patch-Based Deep Autoencoder for Lossy Point Cloud Geometry Compression. (arXiv:2208.02519v1 [cs.CV])
29. Metadata-enhanced contrastive learning from retinal optical coherence tomography images. (arXiv:2208.02529v1 [cs.CV])
30. MVSFormer: Learning Robust Image Representations via Transformers and Temperature-based Depth for Multi-View Stereo. (arXiv:2208.02541v1 [cs.CV])
31. Multi-modal volumetric concept activation to explain detection and classification of metastatic prostate cancer on PSMA-PET/CT. (arXiv:2208.02555v1 [eess.IV])
32. Privacy-Preserving Image Classification Using ConvMixer with Adaptive Permutation Matrix. (arXiv:2208.02556v1 [cs.CV])
33. Constructing Balance from Imbalance for Long-tailed Image Recognition. (arXiv:2208.02567v1 [cs.CV])
34. SOMPT22: A Surveillance Oriented Multi-Pedestrian Tracking Dataset. (arXiv:2208.02580v1 [cs.CV])
35. Surgical Skill Assessment via Video Semantic Aggregation. (arXiv:2208.02611v1 [cs.CV])
36. Semantic Interleaving Global Channel Attention for Multilabel Remote Sensing Image Classification. (arXiv:2208.02613v1 [cs.CV])
37. ACSGRegNet: A Deep Learning-based Framework for Unsupervised Joint Affine and Diffeomorphic Registration of Lumbar Spine CT via Cross- and Self-Attention Fusion. (arXiv:2208.02642v1 [cs.CV])
38. DropKey. (arXiv:2208.02646v1 [cs.CV])
39. ZeroMesh: Zero-shot Single-view 3D Mesh Reconstruction. (arXiv:2208.02676v1 [cs.CV])
40. Relict landslide detection in rainforest areas using a combination of k-means clustering algorithm and Deep-Learning semantic segmentation models. (arXiv:2208.02693v1 [cs.CV])
41. 360Roam: Real-Time Indoor Roaming Using Geometry-Aware ${360^\circ}$ Radiance Fields. (arXiv:2208.02705v1 [cs.CV])
42. Standardizing and Centralizing Datasets to Enable Efficient Training of Agricultural Deep Learning Models. (arXiv:2208.02707v1 [cs.CV])
43. Globally Consistent Video Depth and Pose Estimation with Efficient Test-Time Training. (arXiv:2208.02709v1 [cs.CV])
44. Artificial Image Tampering Distorts Spatial Distribution of Texture Landmarks and Quality Characteristics. (arXiv:2208.02710v1 [cs.CV])
45. UTOPIC: Uncertainty-aware Overlap Prediction Network for Partial Point Cloud Registration. (arXiv:2208.02712v1 [cs.CV])
46. IT/IST/IPLeiria Response to the Call for Proposals on JPEG Pleno Point Cloud Coding. (arXiv:2208.02716v1 [eess.IV])
47. 1st Place Solution to ECCV 2022 Challenge on Out of Vocabulary Scene Text Understanding: Cropped Word Recognition. (arXiv:2208.02747v1 [cs.CV])
48. OCFR 2022: Competition on Occluded Face Recognition From Synthetically Generated Structure-Aware Occlusions. (arXiv:2208.02760v1 [cs.CV])
49. Open-world Contrastive Learning. (arXiv:2208.02764v1 [cs.LG])
50. Vision-Centric BEV Perception: A Survey. (arXiv:2208.02797v1 [cs.CV])
51. Transformers as Meta-Learners for Implicit Neural Representations. (arXiv:2208.02801v1 [cs.LG])
52. Automatic dense annotation of large-vocabulary sign language videos. (arXiv:2208.02802v1 [cs.CV])
53. Cluster-to-adapt: Few Shot Domain Adaptation for Semantic Segmentation across Disjoint Labels. (arXiv:2208.02804v1 [cs.CV])
54. Leveraging the HW/SW Optimizations and Ecosystems that Drive the AI Revolution. (arXiv:2208.02808v1 [cs.LG])
55. P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting. (arXiv:2208.02812v1 [cs.CV])
56. Expanding Language-Image Pretrained Models for General Video Recognition. (arXiv:2208.02816v1 [cs.CV])
57. Occupancy Planes for Single-view RGB-D Human Reconstruction. (arXiv:2208.02817v1 [cs.CV])
58. Generating Image Adversarial Examples by Embedding Digital Watermarks. (arXiv:2009.05107v2 [cs.CV] UPDATED)
59. Unsupervised Video Anomaly Detection via Normalizing Flows with Implicit Latent Features. (arXiv:2010.07524v3 [cs.CV] UPDATED)
60. Semi-supervised Cardiac Image Segmentation via Label Propagation and Style Transfer. (arXiv:2012.14785v2 [eess.IV] UPDATED)
61. Fully Automated 2D and 3D Convolutional Neural Networks Pipeline for Video Segmentation and Myocardial Infarction Detection in Echocardiography. (arXiv:2103.14734v2 [eess.IV] UPDATED)
62. Rethinking Annotation Granularity for Overcoming Shortcuts in Deep Learning-based Radiograph Diagnosis: A Multicenter Study. (arXiv:2104.10553v3 [eess.IV] UPDATED)
63. On the Connection between Local Attention and Dynamic Depth-wise Convolution. (arXiv:2106.04263v5 [cs.CV] UPDATED)
64. Soccer line mark segmentation and classification with stochastic watershed transform. (arXiv:2108.06432v2 [cs.CV] UPDATED)
65. Evolving Transferable Neural Pruning Functions. (arXiv:2110.10876v2 [cs.CV] UPDATED)
66. Implicit Neural Representations for Image Compression. (arXiv:2112.04267v2 [eess.IV] UPDATED)
67. Glance and Focus Networks for Dynamic Visual Recognition. (arXiv:2201.03014v2 [cs.CV] UPDATED)
68. Explore-And-Match: Bridging Proposal-Based and Proposal-Free With Transformer for Sentence Grounding in Videos. (arXiv:2201.10168v4 [cs.CV] UPDATED)
69. An Efficient End-to-End 3D Voxel Reconstruction based on Neural Architecture Search. (arXiv:2202.13313v3 [cs.CV] UPDATED)
70. Recent Advances in Vision Transformer: A Survey for Different Domains. (arXiv:2203.01536v3 [cs.CV] UPDATED)
71. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v2 [cs.CV] UPDATED)
72. Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification. (arXiv:2203.09860v2 [eess.IV] UPDATED)
73. Bidirectional Self-Training with Multiple Anisotropic Prototypes for Domain Adaptive Semantic Segmentation. (arXiv:2204.07730v2 [cs.CV] UPDATED)
74. Absolute Triangulation Algorithms for Space Exploration. (arXiv:2205.12197v2 [cs.CV] UPDATED)
75. mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation. (arXiv:2206.02425v2 [eess.IV] UPDATED)
76. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v3 [cs.LG] UPDATED)
77. PS$^2$F: Polarized Spiral Point Spread Function for Single-Shot 3D Sensing. (arXiv:2207.00945v2 [eess.IV] UPDATED)
78. On the Learnability of Physical Concepts: Can a Neural Network Understand What's Real?. (arXiv:2207.12186v2 [cs.LG] UPDATED)
79. COCOA: Cross Modality Contrastive Learning for Sensor Data. (arXiv:2208.00467v2 [cs.CV] UPDATED)
80. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v2 [cs.CV] UPDATED)
81. Interaction Mix and Match: Synthesizing Close Interaction using Conditional Hierarchical GAN with Multi-Hot Class Embedding. (arXiv:2208.00774v2 [cs.GR] UPDATED)
82. OmniCity: Omnipotent City Understanding with Multi-level and Multi-view Images. (arXiv:2208.00928v2 [cs.CV] UPDATED)
83. The Face of Affective Disorders. (arXiv:2208.01369v2 [cs.CV] UPDATED)
84. Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoising. (arXiv:2208.01948v2 [cs.CV] UPDATED)
85. YOLO-FaceV2: A Scale and Occlusion Aware Face Detector. (arXiv:2208.02019v2 [cs.CV] UPDATED)
86. SC6D: Symmetry-agnostic and Correspondence-free 6D Object Pose Estimation. (arXiv:2208.02129v2 [cs.CV] UPDATED)
87. GPPF: A General Perception Pre-training Framework via Sparsely Activated Multi-Task Learning. (arXiv:2208.02148v2 [cs.CV] UPDATED)
## eess.IV
---
**20** new papers in eess.IV:-) 
1. Towards Generating Large Synthetic Phytoplankton Datasets for Efficient Monitoring of Harmful Algal Blooms. (arXiv:2208.02332v1 [cs.CV])
2. Graph Neural Networks Extract High-Resolution Cultivated Land Maps from Sentinel-2 Image Series. (arXiv:2208.02349v1 [cs.CV])
3. Spatio-Temporal U-Net for Cerebral Artery and Vein Segmentation in Digital Subtraction Angiography. (arXiv:2208.02355v1 [eess.IV])
4. A Multibranch Convolutional Neural Network for Hyperspectral Unmixing. (arXiv:2208.02361v1 [cs.CV])
5. Multi-scale Sampling and Aggregation Network For **High Dynamic Range** Imaging. (arXiv:2208.02448v1 [cs.CV])
6. Scalable Video Coding for Humans and Machines. (arXiv:2208.02512v1 [eess.IV])
7. IPDAE: Improved Patch-Based Deep Autoencoder for Lossy Point Cloud Geometry Compression. (arXiv:2208.02519v1 [cs.CV])
8. Multi-modal volumetric concept activation to explain detection and classification of metastatic prostate cancer on PSMA-PET/CT. (arXiv:2208.02555v1 [eess.IV])
9. Relict landslide detection in rainforest areas using a combination of k-means clustering algorithm and Deep-Learning semantic segmentation models. (arXiv:2208.02693v1 [cs.CV])
10. IT/IST/IPLeiria Response to the Call for Proposals on JPEG Pleno Point Cloud Coding. (arXiv:2208.02716v1 [eess.IV])
11. Semi-supervised Cardiac Image Segmentation via Label Propagation and Style Transfer. (arXiv:2012.14785v2 [eess.IV] UPDATED)
12. Fully Automated 2D and 3D Convolutional Neural Networks Pipeline for Video Segmentation and Myocardial Infarction Detection in Echocardiography. (arXiv:2103.14734v2 [eess.IV] UPDATED)
13. Rethinking Annotation Granularity for Overcoming Shortcuts in Deep Learning-based Radiograph Diagnosis: A Multicenter Study. (arXiv:2104.10553v3 [eess.IV] UPDATED)
14. Implicit Neural Representations for Image Compression. (arXiv:2112.04267v2 [eess.IV] UPDATED)
15. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v2 [cs.CV] UPDATED)
16. Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification. (arXiv:2203.09860v2 [eess.IV] UPDATED)
17. mmFormer: Multimodal Medical Transformer for Incomplete Multimodal Learning of Brain Tumor Segmentation. (arXiv:2206.02425v2 [eess.IV] UPDATED)
18. PS$^2$F: Polarized Spiral Point Spread Function for Single-Shot 3D Sensing. (arXiv:2207.00945v2 [eess.IV] UPDATED)
19. The Face of Affective Disorders. (arXiv:2208.01369v2 [cs.CV] UPDATED)
20. Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoising. (arXiv:2208.01948v2 [cs.CV] UPDATED)
## cs.LG
---
**122** new papers in cs.LG:-) 
1. Reinforcement Learning for Joint V2I Network Selection and Autonomous Driving Policies. (arXiv:2208.02249v1 [cs.LG])
2. GROWN+UP: A Graph Representation Of a Webpage Network Utilizing Pre-training. (arXiv:2208.02252v1 [cs.LG])
3. LaneSNNs: Spiking Neural Networks for Lane Detection on the Loihi Neuromorphic Processor. (arXiv:2208.02253v1 [cs.NE])
4. Dynamic Planning in Open-Ended Dialogue using Reinforcement Learning. (arXiv:2208.02294v1 [cs.CL])
5. HiCu: Leveraging Hierarchy for Curriculum Learning in Automated ICD Coding. (arXiv:2208.02301v1 [cs.LG])
6. How Much Privacy Does Federated Learning with Secure Aggregation Guarantee?. (arXiv:2208.02304v1 [cs.LG])
7. Design of secure and robust cognitive system for malware detection. (arXiv:2208.02310v1 [cs.CR])
8. Counterfactual Image Synthesis for Discovery of Personalized Predictive Image Markers. (arXiv:2208.02311v1 [cs.CV])
9. Image-based Detection of Surface Defects in Concrete during Construction. (arXiv:2208.02313v1 [cs.CV])
10. Differentiable Predictive Control with Safety Guarantees: A Control Barrier Function Approach. (arXiv:2208.02319v1 [eess.SY])
11. Visual Analysis and Detection of Contrails in Aircraft Engine Simulations. (arXiv:2208.02321v1 [cs.HC])
12. Towards Generating Large Synthetic Phytoplankton Datasets for Efficient Monitoring of Harmful Algal Blooms. (arXiv:2208.02332v1 [cs.CV])
13. Word-Level Fine-Grained Story Visualization. (arXiv:2208.02341v1 [cs.CV])
14. Graph Neural Networks Extract High-Resolution Cultivated Land Maps from Sentinel-2 Image Series. (arXiv:2208.02349v1 [cs.CV])
15. Bayesian regularization of empirical MDPs. (arXiv:2208.02362v1 [cs.LG])
16. AACC: Asymmetric Actor-Critic in Contextual Reinforcement Learning. (arXiv:2208.02376v1 [cs.LG])
17. Improving Meta-Learning Generalization with Activation-Based Early-Stopping. (arXiv:2208.02377v1 [cs.LG])
18. Risk-Aware Linear Bandits: Theory and Applications in Smart Order Routing. (arXiv:2208.02389v1 [cs.LG])
19. Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing. (arXiv:2208.02397v1 [cs.CV])
20. Fusing Sentence Embeddings Into LSTM-based Autoregressive Language Models. (arXiv:2208.02402v1 [cs.CL])
21. Adaptive Latent Factor Analysis via Generalized Momentum-Incorporated Particle Swarm Optimization. (arXiv:2208.02423v1 [cs.NE])
22. Transferable Multi-Agent Reinforcement Learning with Dynamic Participating Agents. (arXiv:2208.02424v1 [cs.LG])
23. A New Kind of Adversarial Example. (arXiv:2208.02430v1 [cs.CV])
24. Simulation and application of COVID-19 compartment model using physic-informed neural network. (arXiv:2208.02433v1 [q-bio.QM])
25. Backward Imitation and Forward Reinforcement Learning via Bi-directional Model Rollouts. (arXiv:2208.02434v1 [cs.LG])
26. Node Copying: A Random Graph Model for Effective Graph Sampling. (arXiv:2208.02435v1 [stat.ML])
27. FedDRL: Deep Reinforcement Learning-based Adaptive Aggregation for Non-IID Data in Federated Learning. (arXiv:2208.02442v1 [cs.LG])
28. DL-DRL: A double-layer deep reinforcement learning approach for large-scale task scheduling of multi-UAV. (arXiv:2208.02447v1 [cs.LG])
29. CFARnet: deep learning for target detection with constant false alarm rate. (arXiv:2208.02474v1 [cs.LG])
30. Reliability analysis of discrete-state performance functions via adaptive sequential sampling with detection of failure surfaces. (arXiv:2208.02475v1 [cs.CE])
31. Communication Beyond Transmitting Bits: Semantics-Guided Source and Channel Coding. (arXiv:2208.02481v1 [cs.IT])
32. Privacy Safe Representation Learning via Frequency Filtering Encoder. (arXiv:2208.02482v1 [cs.CV])
33. Customs Import Declaration Datasets. (arXiv:2208.02484v1 [cs.LG])
34. Tokyo Kion-On: Query-Based Generative Sonification of Atmospheric Data. (arXiv:2208.02494v1 [cs.SD])
35. ZeroFL: Efficient On-Device Training for Federated Learning with Local Sparsity. (arXiv:2208.02507v1 [cs.LG])
36. A Nonlinear PID-Enhanced Adaptive Latent Factor Analysis Model. (arXiv:2208.02513v1 [cs.LG])
37. Constructing Balance from Imbalance for Long-tailed Image Recognition. (arXiv:2208.02567v1 [cs.CV])
38. Neuro-symbolic computing with spiking neural networks. (arXiv:2208.02576v1 [cs.NE])
39. Privacy-Preserving Chaotic Extreme Learning Machine with Fully Homomorphic Encryption. (arXiv:2208.02587v1 [cs.LG])
40. Edge-centric Optimization of Multi-modal ML-driven eHealth Applications. (arXiv:2208.02597v1 [cs.LG])
41. Unifying physical systems' inductive biases in neural ODE using dynamics constraints. (arXiv:2208.02632v1 [cs.LG])
42. Neural network accelerator for quantum control. (arXiv:2208.02645v1 [quant-ph])
43. Visually Evaluating Generative Adversarial Networks Using Itself under Multivariate Time Series. (arXiv:2208.02649v1 [cs.LG])
44. Invariant Representations with Stochastically Quantized Neural Networks. (arXiv:2208.02656v1 [cs.LG])
45. A Benchmark and Empirical Analysis for Replay Strategies in Continual Learning. (arXiv:2208.02660v1 [cs.LG])
46. Development and Validation of ML-DQA -- a Machine Learning Data Quality Assurance Framework for Healthcare. (arXiv:2208.02670v1 [stat.ML])
47. Impact Makes a Sound and Sound Makes an Impact: Sound Guides Representations and Explorations. (arXiv:2208.02680v1 [cs.RO])
48. Explaining Classifiers Trained on Raw Hierarchical Multiple-Instance Data. (arXiv:2208.02694v1 [stat.ML])
49. Bayesian Optimization with Informative Covariance. (arXiv:2208.02704v1 [cs.LG])
50. Agnostic Learning of General ReLU Activation Using Gradient Descent. (arXiv:2208.02711v1 [cs.LG])
51. Unsupervised Graph Spectral Feature Denoising for Crop Yield Prediction. (arXiv:2208.02714v1 [cs.LG])
52. Disentangled Representation Learning for RF Fingerprint Extraction under Unknown Channel Statistics. (arXiv:2208.02724v1 [eess.SP])
53. Neural-network preconditioners for solving the Dirac equation in lattice gauge theory. (arXiv:2208.02728v1 [hep-lat])
54. Learning Interaction Variables and Kernels from Observations of Agent-Based Systems. (arXiv:2208.02758v1 [cs.LG])
55. OCFR 2022: Competition on Occluded Face Recognition From Synthetically Generated Structure-Aware Occlusions. (arXiv:2208.02760v1 [cs.CV])
56. Open-world Contrastive Learning. (arXiv:2208.02764v1 [cs.LG])
57. QC-ODKLA: Quantized and Communication-Censored Online Decentralized Kernel Learning via Linearized ADMM. (arXiv:2208.02777v1 [cs.LG])
58. Modular Grammatical Evolution for the Generation of Artificial Neural Networks. (arXiv:2208.02787v1 [cs.NE])
59. Feature selection with gradient descent on two-layer networks in low-rotation regimes. (arXiv:2208.02789v1 [cs.LG])
60. Transformers as Meta-Learners for Implicit Neural Representations. (arXiv:2208.02801v1 [cs.LG])
61. Implicit Semantic Augmentation for Distance Metric Learning in Domain Generalization. (arXiv:2208.02803v1 [cs.LG])
62. Cluster-to-adapt: Few Shot Domain Adaptation for Semantic Segmentation across Disjoint Labels. (arXiv:2208.02804v1 [cs.CV])
63. Leveraging the HW/SW Optimizations and Ecosystems that Drive the AI Revolution. (arXiv:2208.02808v1 [cs.LG])
64. Analyzing Data-Centric Properties for Contrastive Learning on Graphs. (arXiv:2208.02810v1 [cs.LG])
65. P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting. (arXiv:2208.02812v1 [cs.CV])
66. Towards Understanding Mixture of Experts in Deep Learning. (arXiv:2208.02813v1 [cs.LG])
67. Conformal Risk Control. (arXiv:2208.02814v1 [stat.ME])
68. A Robust graph attention network with dynamic adjusted Graph. (arXiv:2009.13038v3 [cs.LG] UPDATED)
69. A similarity-based Bayesian mixture-of-experts model. (arXiv:2012.02130v4 [stat.ML] UPDATED)
70. Distilling Knowledge from Reader to Retriever for Question Answering. (arXiv:2012.04584v2 [cs.CL] UPDATED)
71. A new class of generative classifiers based on staged tree models. (arXiv:2012.13798v2 [cs.AI] UPDATED)
72. Max-Affine Spline Insights Into Deep Network Pruning. (arXiv:2101.02338v3 [cs.LG] UPDATED)
73. A first look into the carbon footprint of federated learning. (arXiv:2102.07627v5 [cs.LG] UPDATED)
74. DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R. (arXiv:2103.09603v3 [stat.ML] UPDATED)
75. Fully Automated 2D and 3D Convolutional Neural Networks Pipeline for Video Segmentation and Myocardial Infarction Detection in Echocardiography. (arXiv:2103.14734v2 [eess.IV] UPDATED)
76. A Class of Dimension-free Metrics for the Convergence of Empirical Measures. (arXiv:2104.12036v3 [math.PR] UPDATED)
77. Degenerate Gaussian factors for probabilistic inference. (arXiv:2104.15010v2 [cs.LG] UPDATED)
78. NoiLIn: Improving Adversarial Training and Correcting Stereotype of Noisy Labels. (arXiv:2105.14676v2 [cs.LG] UPDATED)
79. Risk-sensitive Reinforcement Learning via Distortion Risk Measures. (arXiv:2107.04422v5 [cs.LG] UPDATED)
80. Robust Adaptive Submodular Maximization. (arXiv:2107.11333v3 [cs.DS] UPDATED)
81. Sparse Continuous Distributions and Fenchel-Young Losses. (arXiv:2108.01988v2 [cs.LG] UPDATED)
82. Local versions of sum-of-norms clustering. (arXiv:2109.09589v3 [cs.LG] UPDATED)
83. Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme. (arXiv:2109.13821v2 [cs.SD] UPDATED)
84. Hydra: A System for Large Multi-Model Deep Learning. (arXiv:2110.08633v7 [cs.DC] UPDATED)
85. Membership Inference Attacks Against Self-supervised Speech Models. (arXiv:2111.05113v3 [cs.CR] UPDATED)
86. Benchmark Static API Call Datasets for Malware Family Classification. (arXiv:2111.15205v2 [cs.CR] UPDATED)
87. Implicit Neural Representations for Image Compression. (arXiv:2112.04267v2 [eess.IV] UPDATED)
88. Risk and optimal policies in bandit experiments. (arXiv:2112.06363v8 [econ.EM] UPDATED)
89. Data Collection and Quality Challenges in Deep Learning: A Data-Centric AI Perspective. (arXiv:2112.06409v2 [cs.LG] UPDATED)
90. Glance and Focus Networks for Dynamic Visual Recognition. (arXiv:2201.03014v2 [cs.CV] UPDATED)
91. Generalization Analysis of Message Passing Neural Networks on Large Random Graphs. (arXiv:2202.00645v6 [cs.LG] UPDATED)
92. Membership Inference Attacks and Defenses in Neural Network Pruning. (arXiv:2202.03335v2 [cs.CR] UPDATED)
93. A Lightweight, Efficient and Explainable-by-Design Convolutional Neural Network for Internet Traffic Classification. (arXiv:2202.05535v2 [cs.LG] UPDATED)
94. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v2 [cs.CV] UPDATED)
95. A Hybrid Framework for Sequential Data Prediction with End-to-End Optimization. (arXiv:2203.13787v2 [stat.ML] UPDATED)
96. Improving Personalised Physical Activity Recommendation on the mHealth Information Service Using Deep Reinforcement Learning. (arXiv:2204.00961v2 [cs.LG] UPDATED)
97. DDOS: A MOS Prediction Framework utilizing Domain Adaptive Pre-training and Distribution of Opinion Scores. (arXiv:2204.03219v2 [eess.AS] UPDATED)
98. PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v3 [stat.ML] UPDATED)
99. Learning Green's functions associated with time-dependent partial differential equations. (arXiv:2204.12789v2 [math.NA] UPDATED)
100. Neural Network Optimal Feedback Control with Guaranteed Local Stability. (arXiv:2205.00394v2 [math.OC] UPDATED)
101. Serving and Optimizing Machine Learning Workflows on Heterogeneous Infrastructures. (arXiv:2205.04713v2 [cs.LG] UPDATED)
102. Topological Signal Processing using the Weighted Ordinal Partition Network. (arXiv:2205.08349v2 [stat.ML] UPDATED)
103. Theoretical Analysis of Primal-Dual Algorithm for Non-Convex Stochastic Decentralized Optimization. (arXiv:2205.11979v2 [math.OC] UPDATED)
104. On Gap-dependent Bounds for Offline Reinforcement Learning. (arXiv:2206.00177v2 [cs.LG] UPDATED)
105. Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning. (arXiv:2206.02629v3 [cs.LG] UPDATED)
106. Using Mixed-Effects Models to Learn Bayesian Networks from Related Data Sets. (arXiv:2206.03743v2 [stat.ML] UPDATED)
107. Noise-aware Physics-informed Machine Learning for Robust PDE Discovery. (arXiv:2206.12901v5 [math.NA] UPDATED)
108. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v3 [cs.LG] UPDATED)
109. Context-sensitive neocortical neurons transform the effectiveness and efficiency of neural information processing. (arXiv:2207.07338v2 [cs.NE] UPDATED)
110. Exploration of Parameter Spaces Assisted by Machine Learning. (arXiv:2207.09959v2 [hep-ph] UPDATED)
111. Gradient-based Bi-level Optimization for Deep Learning: A Survey. (arXiv:2207.11719v2 [cs.LG] UPDATED)
112. On the Learnability of Physical Concepts: Can a Neural Network Understand What's Real?. (arXiv:2207.12186v2 [cs.LG] UPDATED)
113. A Theoretical Framework for Inference and Learning in Predictive Coding Networks. (arXiv:2207.12316v2 [cs.NE] UPDATED)
114. Multi-Objective Provisioning of Network Slices using Deep Reinforcement Learning. (arXiv:2207.13821v2 [cs.NI] UPDATED)
115. Model selection with Gini indices under auto-calibration. (arXiv:2207.14372v2 [cs.LG] UPDATED)
116. Model Reduction for Nonlinear Systems by Balanced Truncation of State and Gradient Covariance. (arXiv:2207.14387v2 [eess.SY] UPDATED)
117. Eco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI. (arXiv:2208.00406v2 [cs.LG] UPDATED)
118. COCOA: Cross Modality Contrastive Learning for Sensor Data. (arXiv:2208.00467v2 [cs.CV] UPDATED)
119. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v2 [cs.CV] UPDATED)
120. CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA). (arXiv:2208.01040v2 [cs.LG] UPDATED)
121. Exploring Generative Neural Temporal Point Process. (arXiv:2208.01874v2 [cs.LG] UPDATED)
122. On-Demand Resource Management for 6G Wireless Networks Using Knowledge-Assisted Dynamic Neural Networks. (arXiv:2208.01785v1 [eess.SY] CROSS LISTED)
## cs.AI
---
**51** new papers in cs.AI:-) 
1. Adversarial Attacks on ASR Systems: An Overview. (arXiv:2208.02250v1 [cs.SD])
2. Deep VULMAN: A Deep Reinforcement Learning-Enabled Cyber Vulnerability Management Framework. (arXiv:2208.02369v1 [cs.AI])
3. Improving Meta-Learning Generalization with Activation-Based Early-Stopping. (arXiv:2208.02377v1 [cs.LG])
4. Evolutionary bagged ensemble learning. (arXiv:2208.02400v1 [cs.NE])
5. Transferable Multi-Agent Reinforcement Learning with Dynamic Participating Agents. (arXiv:2208.02424v1 [cs.LG])
6. A New Kind of Adversarial Example. (arXiv:2208.02430v1 [cs.CV])
7. Credal Valuation Networks for Machine Reasoning Under Uncertainty. (arXiv:2208.02443v1 [cs.AI])
8. Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking. (arXiv:2208.02462v1 [cs.CL])
9. Communication Beyond Transmitting Bits: Semantics-Guided Source and Channel Coding. (arXiv:2208.02481v1 [cs.IT])
10. Customs Import Declaration Datasets. (arXiv:2208.02484v1 [cs.LG])
11. Core Challenge 2022: Solver and Graph Descriptions. (arXiv:2208.02495v1 [cs.AI])
12. TunaOil: A Tuning Algorithm Strategy for Reservoir Simulation Workloads. (arXiv:2208.02606v1 [cs.CE])
13. ACSGRegNet: A Deep Learning-based Framework for Unsupervised Joint Affine and Diffeomorphic Registration of Lumbar Spine CT via Cross- and Self-Attention Fusion. (arXiv:2208.02642v1 [cs.CV])
14. Invariant Representations with Stochastically Quantized Neural Networks. (arXiv:2208.02656v1 [cs.LG])
15. Development of fully intuitionistic fuzzy data envelopment analysis model with missing data: an application to Indian police sector. (arXiv:2208.02675v1 [cs.AI])
16. Proceedings 38th International Conference on Logic Programming. (arXiv:2208.02685v1 [cs.LO])
17. Analyzing social media with crowdsourcing in Crowd4SDG. (arXiv:2208.02689v1 [cs.CY])
18. Integrating Knowledge Graph embedding and pretrained Language Models in Hypercomplex Spaces. (arXiv:2208.02743v1 [cs.CL])
19. Keyword Spotting System and Evaluation of Pruning and Quantization Methods on Low-power Edge Microcontrollers. (arXiv:2208.02765v1 [cs.SD])
20. The Role of Environmental Variations in Evolutionary Robotics: Maximizing Performance and Robustness. (arXiv:2208.02809v1 [cs.NE])
21. MAGPIE: Machine Automated General Performance Improvement via Evolution of Software. (arXiv:2208.02811v1 [cs.SE])
22. P2P: Tuning Pre-trained Image Models for Point Cloud Analysis with Point-to-Pixel Prompting. (arXiv:2208.02812v1 [cs.CV])
23. Towards Understanding Mixture of Experts in Deep Learning. (arXiv:2208.02813v1 [cs.LG])
24. Conformal Risk Control. (arXiv:2208.02814v1 [stat.ME])
25. Occupancy Planes for Single-view RGB-D Human Reconstruction. (arXiv:2208.02817v1 [cs.CV])
26. Understanding the QuickXPlain Algorithm: Simple Explanation and Formal Proof. (arXiv:2001.01835v3 [cs.AI] UPDATED)
27. On Expert Behaviors and Question Types for Efficient Query-Based Ontology Fault Localization. (arXiv:2001.05952v2 [cs.AI] UPDATED)
28. The Scheduling Job-Set Optimization Problem: A Model-Based Diagnosis Approach. (arXiv:2009.11142v2 [cs.AI] UPDATED)
29. Do We Really Sample Right In Model-Based Diagnosis?. (arXiv:2009.12178v2 [cs.AI] UPDATED)
30. Sound, Complete, Linear-Space, Best-First Diagnosis Search. (arXiv:2009.12190v2 [cs.AI] UPDATED)
31. A new class of generative classifiers based on staged tree models. (arXiv:2012.13798v2 [cs.AI] UPDATED)
32. Max-Affine Spline Insights Into Deep Network Pruning. (arXiv:2101.02338v3 [cs.LG] UPDATED)
33. Spatiotemporal Pattern Recognition in Single Mixed-Signal VLSI Neurons with Heterogeneous Dynamic Synapses. (arXiv:2106.05686v2 [cs.NE] UPDATED)
34. Sparse Continuous Distributions and Fenchel-Young Losses. (arXiv:2108.01988v2 [cs.LG] UPDATED)
35. AI Descartes: Combining Data and Theory for Derivable Scientific Discovery. (arXiv:2109.01634v3 [cs.AI] UPDATED)
36. Benchmark Static API Call Datasets for Malware Family Classification. (arXiv:2111.15205v2 [cs.CR] UPDATED)
37. Glance and Focus Networks for Dynamic Visual Recognition. (arXiv:2201.03014v2 [cs.CV] UPDATED)
38. Augmented Business Process Management Systems: A Research Manifesto. (arXiv:2201.12855v3 [cs.AI] UPDATED)
39. Generalization Analysis of Message Passing Neural Networks on Large Random Graphs. (arXiv:2202.00645v6 [cs.LG] UPDATED)
40. Recent Advances in Vision Transformer: A Survey for Different Domains. (arXiv:2203.01536v3 [cs.CV] UPDATED)
41. Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning. (arXiv:2203.01855v3 [cs.RO] UPDATED)
42. On Gap-dependent Bounds for Offline Reinforcement Learning. (arXiv:2206.00177v2 [cs.LG] UPDATED)
43. Automatically Drafting Ontologies from Competency Questions with FrODO. (arXiv:2206.02485v2 [cs.AI] UPDATED)
44. Backpropagation at the Infinitesimal Inference Limit of Energy-Based Models: Unifying Predictive Coding, Equilibrium Propagation, and Contrastive Hebbian Learning. (arXiv:2206.02629v3 [cs.LG] UPDATED)
45. Noise-aware Physics-informed Machine Learning for Robust PDE Discovery. (arXiv:2206.12901v5 [math.NA] UPDATED)
46. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v3 [cs.LG] UPDATED)
47. Context-sensitive neocortical neurons transform the effectiveness and efficiency of neural information processing. (arXiv:2207.07338v2 [cs.NE] UPDATED)
48. On the Learnability of Physical Concepts: Can a Neural Network Understand What's Real?. (arXiv:2207.12186v2 [cs.LG] UPDATED)
49. A Theoretical Framework for Inference and Learning in Predictive Coding Networks. (arXiv:2207.12316v2 [cs.NE] UPDATED)
50. Eco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI. (arXiv:2208.00406v2 [cs.LG] UPDATED)
51. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v2 [cs.CV] UPDATED)

