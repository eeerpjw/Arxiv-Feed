# Your interest papers
---
## cs.CV
---
### Minimal Feature Analysis for Isolated Digit Recognition for varying encoding rates in noisy environments. (arXiv:2208.13100v1 [cs.CL])
- Authors : Muskan Garg, Naveen Aggarwal
- Link : [http://arxiv.org/abs/2208.13100](http://arxiv.org/abs/2208.13100)
> ABSTRACT  :  This research work is about recent development made in speech recognition. In this research work, analysis of isolated digit recognition in the presence of different bit rates and at different noise levels has been performed. This research work has been carried using audacity and HTK toolkit. Hidden Markov Model (HMM) is the recognition model which was used to perform this experiment. The feature extraction techniques used are Mel Frequency Cepstrum coefficient (MFCC), Linear Predictive Coding (LPC), perceptual linear predictive (PLP), mel spectrum (MELSPEC), filter bank (FBANK). There were three types of different noise levels which have been considered for testing of data. These include random noise, fan noise and random noise in **real time** environment. This was done to analyse the best environment which can used for **real time** applications. Further, five different types of commonly used bit rates at different sampling rates were considered to find out the most optimum bit rate.  
### Efficient Motion Modelling with Variable-sized blocks from Hierarchical Cuboidal Partitioning. (arXiv:2208.13137v1 [cs.CV])
- Authors : Priyabrata Karmakar, Manzur Murshed, Manoranjan Paul, David Taubman
- Link : [http://arxiv.org/abs/2208.13137](http://arxiv.org/abs/2208.13137)
> ABSTRACT  :  Motion modelling with block-based architecture has been widely used in video coding where a frame is divided into fixed-sized blocks that are motion compensated independently. This often leads to coding inefficiency as fixed-sized blocks hardly align with the object boundaries. Although hierarchical block-partitioning has been introduced to address this, the increased number of motion vectors limits the benefit. Recently, approximate segmentation of images with cuboidal partitioning has gained popularity. Not only are the variable-sized rectangular segments (cuboids) readily amenable to block-based image/video coding techniques, but they are also capable of aligning well with the object boundaries. This is because cuboidal partitioning is based on a homogeneity constraint, minimising the sum of squared errors (SSE). In this paper, we have investigated the potential of cuboids in motion modelling against the fixed-sized blocks used in scalable video coding. Specifically, we have constructed motion-compensated current frame using the cuboidal partitioning information of the anchor frame in a group-of-picture (GOP). The predicted current frame has then been used as the base layer while encoding the current frame as an **enhancement** layer using the scalable HEVC encoder. Experimental results confirm 6.71%-10.90% bitrate savings on 4K video sequences.  
### Towards Real-World Video Deblurring by Exploring Blur Formation Process. (arXiv:2208.13184v1 [cs.CV])
- Authors : Mingdeng Cao, Zhihang Zhong, Yanbo Fan, Jiahao Wang, Yong Zhang, Jue Wang, Yujiu Yang, Yinqiang Zheng
- Link : [http://arxiv.org/abs/2208.13184](http://arxiv.org/abs/2208.13184)
> ABSTRACT  :  This paper aims at exploring how to synthesize close-to-real blurs that existing video deblurring models trained on them can generalize well to real-world blurry videos. In recent years, deep learning-based approaches have achieved promising success on video deblurring task. However, the models trained on existing synthetic datasets still suffer from generalization problems over real-world blurry scenarios with undesired artifacts. The factors accounting for the failure remain unknown. Therefore, we revisit the classical blur synthesis pipeline and figure out the possible reasons, including shooting parameters, blur formation space, and image signal processor~(ISP). To analyze the effects of these potential factors, we first collect an ultra-high frame-rate (940 FPS) RAW video dataset as the data basis to synthesize various kinds of blurs. Then we propose a novel realistic blur synthesis pipeline termed as RAW-Blur by leveraging blur formation cues. Through numerous experiments, we demonstrate that synthesizing blurs in the RAW space and adopting the same ISP as the real-world testing data can effectively eliminate the negative effects of synthetic data. Furthermore, the shooting parameters of the synthesized blurry video, e.g., **exposure** time and frame-rate play significant roles in improving the performance of deblurring models. Impressively, the models trained on the blurry data synthesized by the proposed RAW-Blur pipeline can obtain more than 5dB PSNR gain against those trained on the existing synthetic blur datasets. We believe the novel realistic synthesis pipeline and the corresponding RAW video dataset can help the community to easily construct customized blur datasets to improve real-world video deblurring performance largely, instead of laboriously collecting real data pairs.  
### Real-Time Mask Detection Based on SSD-MobileNetV2. (arXiv:2208.13333v1 [cs.CV])
- Authors : Chen Cheng
- Link : [http://arxiv.org/abs/2208.13333](http://arxiv.org/abs/2208.13333)
> ABSTRACT  :  After the outbreak of COVID-19, mask detection, as the most convenient and effective means of prevention, plays a crucial role in epidemic prevention and control. An excellent automatic real-time mask detection system can reduce a lot of work pressure for relevant staff. However, by analyzing the existing mask detection approaches, we find that they are mostly resource-intensive and do not achieve a good balance between speed and accuracy. And there is no perfect face mask dataset at present. In this paper, we propose a new architecture for mask detection. Our system uses SSD as the mask locator and classifier, and further replaces VGG-16 with MobileNetV2 to extract the features of the image and reduce a lot of parameters. Therefore, our system can be deployed on embedded devices. Transfer learning methods are used to transfer pre-trained models from other domains to our model. Data **enhancement** methods in our system such as MixUp effectively prevent overfitting. It also effectively reduces the dependence on large-scale datasets. By doing experiments in practical scenarios, the results demonstrate that our system performed well in real-time mask detection.  
### CIRCLe: Color Invariant Representation Learning for Unbiased Classification of Skin Lesions. (arXiv:2208.13528v1 [cs.CV])
- Authors : Arezou Pakzad, Kumar Abhishek, Ghassan Hamarneh
- Link : [http://arxiv.org/abs/2208.13528](http://arxiv.org/abs/2208.13528)
> ABSTRACT  :  While deep learning based approaches have demonstrated expert-level performance in dermatological diagnosis tasks, they have also been shown to exhibit biases toward certain demographic attributes, particularly skin types (e.g., light versus **dark**), a fairness concern that must be addressed. We propose CIRCLe, a skin color invariant deep representation learning method for improving fairness in skin lesion classification. CIRCLe is trained to classify images by utilizing a regularization loss that encourages images with the same diagnosis but different skin types to have similar latent representations. Through extensive evaluation and ablation studies, we demonstrate CIRCLe's superior performance over the state-of-the-art when evaluated on 16k+ images spanning 6 Fitzpatrick skin types and 114 diseases, using classification accuracy, equal opportunity difference (for light versus **dark** groups), and normalized accuracy range, a new measure we propose to assess fairness on multiple skin type groups.  
### Frame Averaging for Equivariant Shape Space Learning. (arXiv:2112.01741v2 [cs.CV] UPDATED)
- Authors : Matan Atzmon, Koki Nagano, Sanja Fidler, Sameh Khamis, Yaron Lipman
- Link : [http://arxiv.org/abs/2112.01741](http://arxiv.org/abs/2112.01741)
> ABSTRACT  :  The task of shape space learning involves mapping a train set of shapes to and from a latent representation space with good generalization properties. Often, real-world collections of shapes have symmetries, which can be defined as transformations that do not change the essence of the shape. A natural way to incorporate symmetries in shape space learning is to ask that the mapping to the shape space (encoder) and mapping from the shape space (decoder) are equivariant to the relevant symmetries.    In this paper, we present a framework for incorporating equivariance in encoders and decoders by introducing two contributions: (i) adapting the recent Frame Averaging (FA) framework for building generic, efficient, and maximally expressive Equivariant autoencoders; and (ii) constructing autoencoders equivariant to piecewise Euclidean motions applied to different parts of the shape. To the best of our knowledge, this is the first fully piecewise Euclidean equivariant autoencoder construction. Training our framework is simple: it uses standard reconstruction losses and does not require the introduction of new losses. Our architectures are built of standard (backbone) architectures with the appropriate frame averaging to make them equivariant. Testing our framework on both rigid shapes dataset using **implicit neural representation**s, and articulated shape datasets using mesh-based neural networks show state-of-the-art generalization to unseen test shapes, improving relevant baselines by a large margin. In particular, our method demonstrates significant improvement in generalizing to unseen articulated poses.  
### Deep Decomposition and Bilinear Pooling Network for Blind **Night**-Time Image Quality Evaluation. (arXiv:2205.05880v2 [cs.MM] UPDATED)
- Authors : Qiuping Jiang, Jiawu Xu, Yudong Mao, Wei Zhou, Xiongkuo Min, Guangtao Zhai
- Link : [http://arxiv.org/abs/2205.05880](http://arxiv.org/abs/2205.05880)
> ABSTRACT  :  Blind image quality assessment (BIQA), which aims to accurately predict the image quality without any pristine reference information, has been extensively concerned in the past decades. Especially, with the help of deep neural networks, great progress has been achieved. However, it remains less investigated on BIQA for **night**-time images (NTIs) which usually suffers from complicated authentic distortions such as reduced visibility, low contrast, additive noises, and color distortions. These diverse authentic degradations particularly challenges the design of effective deep neural network for blind NTI quality evaluation (NTIQE). In this paper, we propose a novel deep decomposition and bilinear pooling network (DDB-Net) to better address this issue. The DDB-Net contains three modules, i.e., an image decomposition module, a feature encoding module, and a bilinear pooling module. The image decomposition module is inspired by the Retinex theory and involves decoupling the input NTI into an illumination layer component responsible for illumination information and a reflection layer component responsible for content information. Then, the feature encoding module involves learning feature representations of degradations that are rooted in the two decoupled components separately. Finally, by modeling illumination-related and content-related degradations as two-factor variations, the two feature sets are bilinearly pooled together to form a unified representation for quality prediction. The superiority of the proposed DDB-Net has been well validated by extensive experiments on several benchmark datasets. The source code will be made available soon.  
### KinD-LCE Curve Estimation And Retinex Fusion On **Low-Light** Image. (arXiv:2207.09210v2 [cs.CV] UPDATED)
- Authors : Xiaochun Lei, Junlin Xie, Zetao Jiang, Weiliang Mai, Zhaoting Gong, Chang Lu, Linjun Lu, Ziqi Shan
- Link : [http://arxiv.org/abs/2207.09210](http://arxiv.org/abs/2207.09210)
> ABSTRACT  :  The problems of **low light** image noise and chromatic aberration is a challenging problem for tasks such as object detection, semantic segmentation, instance segmentation, etc. In this paper, we propose the algorithm for low illumination **enhancement**. KinD-LCE uses the light curve estimation module in the network structure to enhance the illumination map in the Retinex decomposed image, which improves the image brightness; we proposed the illumination map and reflection map fusion module to restore the restored image details and reduce the detail loss. Finally, we included a total variation loss function to eliminate noise. Our method uses the GladNet dataset as the training set, and the LOL dataset as the test set and is validated using Ex**Dark** as the dataset for downstream tasks. Extensive Experiments on the benchmarks demonstrate the advantages of our method and are close to the state-of-the-art results, which achieve a PSNR of 19.7216 and SSIM of 0.8213 in terms of metrics.  
### An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition using a Novel Transformers-based Model and an Innovative 270 Million-Words Multi-Font Corpus of Classical Arabic with Diacritics. (arXiv:2208.11484v2 [cs.CV] UPDATED)
- Authors : Aly Mostafa, Omar Mohamed, Ali Ashraf, Ahmed Elbehery, Salma Jamal, Anas Salah
- Link : [http://arxiv.org/abs/2208.11484](http://arxiv.org/abs/2208.11484)
> ABSTRACT  :  This research is the second phase in a series of investigations on developing an Optical Character Recognition (OCR) of Arabic historical documents and examining how different modeling procedures interact with the problem. The first research studied the effect of Transformers on our custom-built Arabic dataset. One of the downsides of the first research was the size of the training data, a mere 15000 images from our 30 million images, due to lack of resources. Also, we add an image **enhancement** layer, time and space optimization, and Post-Correction layer to aid the model in predicting the correct word for the correct context. Notably, we propose an end-to-end text recognition approach using Vision Transformers as an encoder, namely BEIT, and vanilla Transformer as a decoder, eliminating CNNs for feature extraction and reducing the model's complexity. The experiments show that our end-to-end model outperforms Convolutions Backbones. The model attained a CER of 4.46%.  
## eess.IV
---
## cs.LG
---
### Uncovering **dark** matter density profiles in dwarf galaxies with graph neural networks. (arXiv:2208.12825v1 [astro-ph.CO])
- Authors : Tri Nguyen, Siddharth Mishra, Reuel Williams, Lina Necib
- Link : [http://arxiv.org/abs/2208.12825](http://arxiv.org/abs/2208.12825)
> ABSTRACT  :  Dwarf galaxies are small, **dark** matter-dominated galaxies, some of which are embedded within the Milky Way. Their lack of baryonic matter (e.g., stars and gas) makes them perfect test beds for probing the properties of **dark** matter -- understanding the spatial **dark** matter distribution in these systems can be used to constrain microphysical **dark** matter interactions that influence the formation and evolution of structures in our Universe. We introduce a new method that leverages simulation-based inference and graph-based machine learning in order to infer the **dark** matter density profiles of dwarf galaxies from observable kinematics of stars gravitationally bound to these systems. Our approach aims to address some of the limitations of established methods based on dynamical Jeans modeling. We show that this novel method can place stronger constraints on **dark** matter profiles and, consequently, has the potential to weigh in on some of the ongoing puzzles associated with the small-scale structure of **dark** matter halos, such as the core-cusp discrepancy.  
### Improving the Efficiency of Gradient Descent Algorithms Applied to Optimization Problems with Dynamical Constraints. (arXiv:2208.12834v1 [cs.LG])
- Authors : Ion Matei, Maksym Zhenirovskyy, Johan de, John Maxwell
- Link : [http://arxiv.org/abs/2208.12834](http://arxiv.org/abs/2208.12834)
> ABSTRACT  :  We introduce two block coordinate descent algorithms for solving optimization problems with ordinary differential equations (ODEs) as dynamical constraints. The algorithms do not need to implement direct or adjoint sensitivity analysis methods to evaluate loss function gradients. They results from reformulation of the original problem as an equivalent optimization problem with equality constraints. The algorithms naturally follow from steps aimed at recovering the gradient-decent algorithm based on ODE solvers that explicitly account for sensitivity of the ODE solution. In our first proposed algorithm we avoid explicitly solving the ODE by integrating the ODE solver as a sequence of implicit constraints. In our second algorithm, we use an ODE solver to reset the ODE solution, but no direct are adjoint sensitivity analysis methods are used. Both algorithm accepts mini-batch implementations and show significant efficiency benefits from GPU-based parallelization. We demonstrate the performance of the algorithms when applied to learning the parameters of the Cucker-Smale model. The algorithms are compared with gradient descent algorithms based on ODE solvers endowed with sensitivity analysis capabilities, for various number of state size, using Pytorch and Jax implementations. The experimental results demonstrate that the proposed algorithms are at least 4x faster than the Pytorch implementations, and at least 16x faster than Jax implementations. For large versions of the Cucker-Smale model, the Jax implementation is thousands of times faster than the sensitivity analysis-based implementation. In addition, our algorithms generate more accurate results both on training and test data. Such gains in computational efficiency is paramount for algorithms that implement **real time** parameter estimations, such as diagnosis algorithms.  
### Minute ventilation measurement using Plethysmographic Imaging and lighting parameters. (arXiv:2208.13319v1 [cs.LG])
- Authors : Daniel Minati, Ludwik Sams, Karen Li, Bo Ji, Krishna Vardhan
- Link : [http://arxiv.org/abs/2208.13319](http://arxiv.org/abs/2208.13319)
> ABSTRACT  :  Breathing disorders such as sleep apnea is a critical disorder that affects a large number of individuals due to the insufficient capacity of the lungs to contain/exchange oxygen and carbon dioxide to ensure that the body is in the stable state of homeostasis. Respiratory Measurements such as minute ventilation can be used in correlation with other physiological measurements such as heart rate and heart rate variability for remote monitoring of health and detecting symptoms of such breathing related disorders. In this work, we formulate a deep learning based approach to measure remote ventilation on a private dataset. The dataset will be made public upon acceptance of this work. We use two versions of a deep neural network to estimate the minute ventilation from data streams obtained through wearable heart rate and respiratory devices. We demonstrate that the simple design of our pipeline - which includes lightweight deep neural networks - can be easily incorporate into **real time** health monitoring systems.  
### fMBN-E: Efficient Unsupervised Network Structure Ensemble and Selection for Clustering. (arXiv:2107.02071v5 [cs.LG] UPDATED)
- Authors : **Lei Zhang**
- Link : [http://arxiv.org/abs/2107.02071](http://arxiv.org/abs/2107.02071)
> ABSTRACT  :  It is known that unsupervised nonlinear dimensionality reduction and clustering is sensitive to the selection of hyperparameters, particularly for deep learning based methods, which hinders its practical use. How to select a proper network structure that may be dramatically different in different applications is a hard issue for deep models, given little prior knowledge of data. In this paper, we aim to automatically determine the optimal network structure of a deep model, named multilayer bootstrap networks (MBN), via simple ensemble learning and selection techniques. Specifically, we first propose an MBN ensemble (MBN-E) algorithm which concatenates the sparse outputs of a set of MBN base models with different network structures into a new representation. Then, we take the new representation produced by MBN-E as a reference for selecting the optimal MBN base models. Moreover, we propose a fast version of MBN-E (fMBN-E), which is not only theoretically even faster than a single standard MBN but also does not increase the estimation error of MBN-E. Importantly, MBN-E and its ensemble selection techniques maintain the simple formulation of MBN that is based on one-nearest-neighbor learning. Empirically, comparing to a number of advanced deep clustering methods and as many as 20 representative unsupervised ensemble learning and selection methods, the proposed methods reach the state-of-the-art performance without manual hyperparameter tuning. fMBN-E is empirically even hundreds of times faster than MBN-E without suffering performance degradation. The applications to image segmentation and graph data mining further demonstrate the advantage of the proposed methods.  
### Frame Averaging for Equivariant Shape Space Learning. (arXiv:2112.01741v2 [cs.CV] UPDATED)
- Authors : Matan Atzmon, Koki Nagano, Sanja Fidler, Sameh Khamis, Yaron Lipman
- Link : [http://arxiv.org/abs/2112.01741](http://arxiv.org/abs/2112.01741)
> ABSTRACT  :  The task of shape space learning involves mapping a train set of shapes to and from a latent representation space with good generalization properties. Often, real-world collections of shapes have symmetries, which can be defined as transformations that do not change the essence of the shape. A natural way to incorporate symmetries in shape space learning is to ask that the mapping to the shape space (encoder) and mapping from the shape space (decoder) are equivariant to the relevant symmetries.    In this paper, we present a framework for incorporating equivariance in encoders and decoders by introducing two contributions: (i) adapting the recent Frame Averaging (FA) framework for building generic, efficient, and maximally expressive Equivariant autoencoders; and (ii) constructing autoencoders equivariant to piecewise Euclidean motions applied to different parts of the shape. To the best of our knowledge, this is the first fully piecewise Euclidean equivariant autoencoder construction. Training our framework is simple: it uses standard reconstruction losses and does not require the introduction of new losses. Our architectures are built of standard (backbone) architectures with the appropriate frame averaging to make them equivariant. Testing our framework on both rigid shapes dataset using **implicit neural representation**s, and articulated shape datasets using mesh-based neural networks show state-of-the-art generalization to unseen test shapes, improving relevant baselines by a large margin. In particular, our method demonstrates significant improvement in generalizing to unseen articulated poses.  
### Neural **Enhancement** of Factor Graph-based Symbol Detection. (arXiv:2203.03333v2 [cs.IT] UPDATED)
- Authors : Luca Schmid, Laurent Schmalen
- Link : [http://arxiv.org/abs/2203.03333](http://arxiv.org/abs/2203.03333)
> ABSTRACT  :  We study the application of the factor graph framework for symbol detection on linear inter-symbol interference channels. Cyclic factor graphs have the potential to yield low-complexity symbol detectors, but are suboptimal if the ubiquitous sum-product algorithm is applied. In this paper, we present and evaluate strategies to improve the performance of cyclic factor graph-based symbol detection algorithms by means of neural **enhancement**. In particular, we apply neural belief propagation as an effective way to counteract the effect of cycles within the factor graph. We further propose the application and optimization of a linear preprocessor of the channel output. By modifying the observation model, the preprocessing can effectively change the underlying factor graph, thereby significantly improving the detection performance as well as reducing the complexity.  
### Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v2 [cs.CL] UPDATED)
- Authors : Gati Aher, Adam Tauman
- Link : [http://arxiv.org/abs/2208.10264](http://arxiv.org/abs/2208.10264)
> ABSTRACT  :  We propose a method for using a large language model, such as GPT-3, to simulate responses of different humans in a given context. We test our method by attempting to reproduce well-established economic, psycholinguistic, and social experiments. The method requires prompt templates for each experiment. Simulations are run by varying the (hypothetical) subject details, such as name, and analyzing the text generated by the language model. To validate our methodology, we use GPT-3 to simulate the Ultimatum Game, garden path sentences, risk aversion, and the Milgram Shock experiments. In order to address concerns of **exposure** to these studies in training data, we also evaluate simulations on novel variants of these studies. We show that it is possible to simulate responses of different people and that their responses are consistent with prior human studies from the literature. Across all studies, the distributions generated by larger language models better align with prior experimental results, suggesting a trend that future language models may be used for even more faithful simulations of human responses. Our use of a language model for simulation is contrasted with anthropomorphic views of a language model as having its own behavior.  
### An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition using a Novel Transformers-based Model and an Innovative 270 Million-Words Multi-Font Corpus of Classical Arabic with Diacritics. (arXiv:2208.11484v2 [cs.CV] UPDATED)
- Authors : Aly Mostafa, Omar Mohamed, Ali Ashraf, Ahmed Elbehery, Salma Jamal, Anas Salah
- Link : [http://arxiv.org/abs/2208.11484](http://arxiv.org/abs/2208.11484)
> ABSTRACT  :  This research is the second phase in a series of investigations on developing an Optical Character Recognition (OCR) of Arabic historical documents and examining how different modeling procedures interact with the problem. The first research studied the effect of Transformers on our custom-built Arabic dataset. One of the downsides of the first research was the size of the training data, a mere 15000 images from our 30 million images, due to lack of resources. Also, we add an image **enhancement** layer, time and space optimization, and Post-Correction layer to aid the model in predicting the correct word for the correct context. Notably, we propose an end-to-end text recognition approach using Vision Transformers as an encoder, namely BEIT, and vanilla Transformer as a decoder, eliminating CNNs for feature extraction and reducing the model's complexity. The experiments show that our end-to-end model outperforms Convolutions Backbones. The model attained a CER of 4.46%.  
## cs.AI
---
### Effective approaches to disaster evacuation during a COVID-like pandemic. (arXiv:2208.13326v1 [q-bio.PE])
- Authors : Lin Tsai, Jason Wang, Department of, Civil and, Environmental Engineering, Stanford University, Department of, Engineering Science, National University, of Singapore, Department of, Imperial College, Department of, Stanford University, School of, Department of, Health Policy, Stanford University, School of, Woods Institute, for the, Stanford University, Stanford University, Institute for, Computational and, Mathematical Engineering, Stanford University, Department of, Stanford University, Department of, Earth System, Stanford University, Interdisciplinary Environmental, Studies Program, Stanford University
- Link : [http://arxiv.org/abs/2208.13326](http://arxiv.org/abs/2208.13326)
> ABSTRACT  :  Since COVID-19 vaccines became available, no studies have quantified how different disaster evacuation strategies can mitigate pandemic risks in shelters. Therefore, we applied an age-structured epidemiological model, known as the Susceptible-Exposed-Infectious-Recovered (SEIR) model, to investigate to what extent different vaccine uptake levels and the Diversion protocol implemented in Taiwan decrease infections and delay pandemic peak occurrences. Taiwan's Diversion protocol involves diverting those in self-quarantine due to **exposure**, thus preventing them from mingling with the general public at a congregate shelter. The Diversion protocol, combined with sufficient vaccine uptake, can decrease the maximum number of infections and delay outbreaks relative to scenarios without such strategies. When the diversion of all exposed people is not possible, or vaccine uptake is insufficient, the Diversion protocol is still valuable. Furthermore, a group of evacuees that consists primarily of a young adult population tends to experience pandemic peak occurrences sooner and have up to 180% more infections than does a majority elderly group when the Diversion protocol is implemented. However, when the Diversion protocol is not enforced, the majority elderly group suffers from up to 20% more severe cases than the majority young adult group.  
### Detecting Surprising Situations in Event Data. (arXiv:2208.13515v1 [cs.AI])
- Authors : Christian Kohlschmidt, Mahnaz Sadat, van der
- Link : [http://arxiv.org/abs/2208.13515](http://arxiv.org/abs/2208.13515)
> ABSTRACT  :  Process mining is a set of techniques that are used by organizations to understand and improve their operational processes. The first essential step in designing any process reengineering procedure is to find process improvement opportunities. In existing work, it is usually assumed that the set of problematic process instances in which an undesirable outcome occurs is known prior or is easily detectable. So the process **enhancement** procedure involves finding the root causes and the treatments for the problem in those process instances. For example, the set of problematic instances is considered as those with outlier values or with values smaller/bigger than a given threshold in one of the process features. However, on various occasions, using this approach, many process **enhancement** opportunities, not captured by these problematic process instances, are missed. To overcome this issue, we formulate finding the process **enhancement** areas as a context-sensitive anomaly/outlier detection problem. We define a process **enhancement** area as a set of situations (process instances or prefixes of process instances) where the process performance is surprising. We aim to characterize those situations where process performance/outcome is significantly different from what was expected considering its performance/outcome in similar situations. To evaluate the validity and relevance of the proposed approach, we have implemented and evaluated it on several real-life event logs.  
### Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v2 [cs.CL] UPDATED)
- Authors : Gati Aher, Adam Tauman
- Link : [http://arxiv.org/abs/2208.10264](http://arxiv.org/abs/2208.10264)
> ABSTRACT  :  We propose a method for using a large language model, such as GPT-3, to simulate responses of different humans in a given context. We test our method by attempting to reproduce well-established economic, psycholinguistic, and social experiments. The method requires prompt templates for each experiment. Simulations are run by varying the (hypothetical) subject details, such as name, and analyzing the text generated by the language model. To validate our methodology, we use GPT-3 to simulate the Ultimatum Game, garden path sentences, risk aversion, and the Milgram Shock experiments. In order to address concerns of **exposure** to these studies in training data, we also evaluate simulations on novel variants of these studies. We show that it is possible to simulate responses of different people and that their responses are consistent with prior human studies from the literature. Across all studies, the distributions generated by larger language models better align with prior experimental results, suggesting a trend that future language models may be used for even more faithful simulations of human responses. Our use of a language model for simulation is contrasted with anthropomorphic views of a language model as having its own behavior.  
# Paper List
---
## cs.CV
---
**130** new papers in cs.CV:-) 
1. Riesz-Quincunx-UNet Variational Auto-Encoder for Satellite Image Denoising. (arXiv:2208.12810v1 [eess.IV])
2. A Path Towards Clinical Adaptation of Accelerated MRI. (arXiv:2208.12835v1 [eess.IV])
3. Region-guided CycleGANs for Stain Transfer in Whole Slide Images. (arXiv:2208.12847v1 [eess.IV])
4. Domain Adaptation with Adversarial Training on Penultimate Activations. (arXiv:2208.12853v1 [cs.LG])
5. Local Context-Aware Active Domain Adaptation. (arXiv:2208.12856v1 [cs.LG])
6. Ammunition Component Classification Using Deep Learning. (arXiv:2208.12863v1 [cs.CV])
7. Neuromorphic Visual Scene Understanding with Resonator Networks. (arXiv:2208.12880v1 [cs.CV])
8. Multi-Modality Cardiac Image Computing: A Survey. (arXiv:2208.12881v1 [eess.IV])
9. Constraining Pseudo-label in Self-training Unsupervised Domain Adaptation with Energy-based Model. (arXiv:2208.12885v1 [cs.CV])
10. Neural Camera Models. (arXiv:2208.12903v1 [cs.CV])
11. RepParser: End-to-End Multiple Human Parsing with Representative Parts. (arXiv:2208.12908v1 [cs.CV])
12. xCloth: Extracting Template-free Textured 3D Clothes from a Monocular Image. (arXiv:2208.12934v1 [cs.CV])
13. Actor-identified Spatiotemporal Action Detection -- Detecting Who Is Doing What in Videos. (arXiv:2208.12940v1 [cs.CV])
14. Anti-Retroactive Interference for Lifelong Learning. (arXiv:2208.12967v1 [cs.CV])
15. 6D Robotic Assembly Based on RGB-only Object Pose Estimation. (arXiv:2208.12986v1 [cs.RO])
16. A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges. (arXiv:2208.12996v1 [cs.CV])
17. Weakly and Semi-Supervised Detection, Segmentation and Tracking of Table Grapes with Limited and Noisy Data. (arXiv:2208.13001v1 [cs.CV])
18. AesUST: Towards Aesthetic-Enhanced Universal Style Transfer. (arXiv:2208.13016v1 [cs.CV])
19. Multi-Outputs Is All You Need For Deblur. (arXiv:2208.13029v1 [cs.CV])
20. LAB-Net: LAB Color-Space Oriented Lightweight Network for Shadow Removal. (arXiv:2208.13039v1 [cs.CV])
21. YOLOX-PAI: An Improved YOLOX Version by PAI. (arXiv:2208.13040v1 [cs.CV])
22. CrackSeg9k: A Collection and Benchmark for Crack Segmentation Datasets and Frameworks. (arXiv:2208.13054v1 [cs.CV])
23. Lossy Image Compression with Quantized Hierarchical VAEs. (arXiv:2208.13056v1 [eess.IV])
24. On GANs perpetuating biases for face verification. (arXiv:2208.13061v1 [cs.CV])
25. Self-Supervised Face Presentation Attack Detection with Dynamic Grayscale Snippets. (arXiv:2208.13070v1 [cs.CV])
26. Minimal Feature Analysis for Isolated Digit Recognition for varying encoding rates in noisy environments. (arXiv:2208.13100v1 [cs.CL])
27. Accurate and Robust Lesion RECIST Diameter Prediction and Segmentation with Transformers. (arXiv:2208.13113v1 [eess.IV])
28. Delving into the Continuous Domain Adaptation. (arXiv:2208.13121v1 [cs.CV])
29. Removing Rain Streaks via Task Transfer Learning. (arXiv:2208.13133v1 [cs.CV])
30. An Access Control Method with Secret Key for Semantic Segmentation Models. (arXiv:2208.13135v1 [cs.CV])
31. Efficient Motion Modelling with Variable-sized blocks from Hierarchical Cuboidal Partitioning. (arXiv:2208.13137v1 [cs.CV])
32. ClusTR: Exploring Efficient Self-attention via Clustering for Vision Transformers. (arXiv:2208.13138v1 [cs.CV])
33. Generative Modelling of the Ageing Heart with Cross-Sectional Imaging and Clinical Data. (arXiv:2208.13146v1 [eess.IV])
34. Face Anti-Spoofing from the Perspective of Data Sampling. (arXiv:2208.13164v1 [cs.CV])
35. Towards Real-World Video Deblurring by Exploring Blur Formation Process. (arXiv:2208.13184v1 [cs.CV])
36. Grounded Affordance from Exocentric View. (arXiv:2208.13196v1 [cs.CV])
37. Leachable Component Clustering. (arXiv:2208.13217v1 [cs.LG])
38. Visualizing high-dimensional loss landscapes with Hessian directions. (arXiv:2208.13219v1 [cs.LG])
39. Deep Learning for automatic head and neck lymph node level delineation. (arXiv:2208.13224v1 [eess.IV])
40. Towards Accurate Reconstruction of 3D Scene Shape from A Single Monocular Image. (arXiv:2208.13241v1 [cs.CV])
41. FFCNN: Fast FPGA based Acceleration for Convolution neural network inference. (arXiv:2208.13250v1 [cs.LG])
42. Detection and Classification of Brain tumors Using Deep Convolutional Neural Networks. (arXiv:2208.13264v1 [eess.IV])
43. JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents. (arXiv:2208.13266v1 [cs.AI])
44. Efficient liver segmentation with 3D CNN using computed tomography scans. (arXiv:2208.13271v1 [eess.IV])
45. Unsupervised diffeomorphic cardiac image registration using parameterization of the deformation field. (arXiv:2208.13275v1 [eess.IV])
46. Fluorescence molecular optomic signatures improve identification of tumors in head and neck specimens. (arXiv:2208.13314v1 [cs.LG])
47. Real-Time Mask Detection Based on SSD-MobileNetV2. (arXiv:2208.13333v1 [cs.CV])
48. Label Propagation for 3D Carotid Vessel Wall Segmentation and Atherosclerosis Diagnosis. (arXiv:2208.13337v1 [eess.IV])
49. Boundary-Aware Network for Kidney Parsing. (arXiv:2208.13338v1 [eess.IV])
50. Artificial Neural Networks for Finger Vein Recognition: A Survey. (arXiv:2208.13341v1 [cs.CV])
51. Long-Tailed Classification of Thorax Diseases on Chest X-Ray: A New Benchmark Study. (arXiv:2208.13365v1 [cs.CV])
52. Confidence Estimation for Object Detection in Document Images. (arXiv:2208.13391v1 [cs.CV])
53. Towards Explaining Demographic Bias through the Eyes of Face Recognition Models. (arXiv:2208.13400v1 [cs.CV])
54. Progressive Self-Distillation for Ground-to-Aerial Perception Knowledge Transfer. (arXiv:2208.13404v1 [cs.CV])
55. PV-RCNN++: Semantical Point-Voxel Feature Interaction for 3D Object Detection. (arXiv:2208.13414v1 [cs.CV])
56. Light-YOLOv5: A Lightweight Algorithm for Improved YOLOv5 in Complex Fire Scenarios. (arXiv:2208.13422v1 [cs.CV])
57. Towards In-distribution Compatibility in Out-of-distribution Detection. (arXiv:2208.13433v1 [cs.CV])
58. Joint Learning Content and Degradation Aware Feature for Blind Super-Resolution. (arXiv:2208.13436v1 [cs.CV])
59. Rethinking Skip Connections in Encoder-decoder Networks for Monocular Depth Estimation. (arXiv:2208.13441v1 [cs.CV])
60. Federated Zero-Shot Learning with Mid-Level Semantic Knowledge Transfer. (arXiv:2208.13465v1 [cs.CV])
61. Prompt Tuning with Soft Context Sharing for Vision-Language Models. (arXiv:2208.13474v1 [cs.CV])
62. A Practical Calibration Method for RGB Micro-Grid Polarimetric Cameras. (arXiv:2208.13485v1 [cs.CV])
63. Semantic Clustering of a Sequence of Satellite Images. (arXiv:2208.13504v1 [cs.CV])
64. LogicRank: Logic Induced Reranking for Generative Text-to-Image Systems. (arXiv:2208.13518v1 [cs.AI])
65. CIRCLe: Color Invariant Representation Learning for Unbiased Classification of Skin Lesions. (arXiv:2208.13528v1 [cs.CV])
66. Explainability of Deep Learning models for Urban Space perception. (arXiv:2208.13555v1 [cs.CV])
67. Chosen methods of improving object recognition of small objects with weak recognizable features. (arXiv:2208.13591v1 [cs.CV])
68. Towards Robust Face Recognition with Comprehensive Search. (arXiv:2208.13600v1 [cs.CV])
69. CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous Multi-Agent Reinforcement Learning. (arXiv:2208.13626v1 [cs.AI])
70. Efficient Vision-Language Pretraining with Visual Concepts and Hierarchical Alignment. (arXiv:2208.13628v1 [cs.CV])
71. How to Teach: Learning Data-Free Knowledge Distillation from Curriculum. (arXiv:2208.13648v1 [cs.CV])
72. Learning Binary and Sparse Permutation-Invariant Representations for Fast and Memory Efficient Whole Slide Image Search. (arXiv:2208.13653v1 [cs.CV])
73. Latent Heterogeneous Graph Network for Incomplete Multi-View Learning. (arXiv:2208.13669v1 [cs.LG])
74. Comprehensive study of good model training for prostate segmentation in volumetric MRI. (arXiv:2208.13671v1 [eess.IV])
75. Deformable Image Registration using Unsupervised Deep Learning for CBCT-guided Abdominal Radiotherapy. (arXiv:2208.13686v1 [eess.IV])
76. SphereDepth: Panorama Depth Estimation from Spherical Domain. (arXiv:2208.13714v1 [cs.CV])
77. StableFace: Analyzing and Improving Motion Stability for Talking Face Generation. (arXiv:2208.13717v1 [cs.CV])
78. CounTR: Transformer-based Generalised Visual Counting. (arXiv:2208.13721v1 [cs.CV])
79. Open-Set Semi-Supervised Object Detection. (arXiv:2208.13722v1 [cs.CV])
80. Unsupervised Scale-Invariant Multispectral Shape Matching. (arXiv:2012.10685v2 [cs.CV] UPDATED)
81. Towards Both Accurate and Robust Neural Networks without Extra Data. (arXiv:2103.13124v2 [cs.CV] UPDATED)
82. Self-Supervised Adversarial Example Detection by Disentangled Representation. (arXiv:2105.03689v4 [cs.CV] UPDATED)
83. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v3 [cs.LG] UPDATED)
84. Social Processes: Self-Supervised Meta-Learning over Conversational Groups for Forecasting Nonverbal Social Cues. (arXiv:2107.13576v3 [cs.LG] UPDATED)
85. Adversarial Relighting Against Face Recognition. (arXiv:2108.07920v4 [cs.CV] UPDATED)
86. RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place Recognition Network. (arXiv:2108.12790v3 [cs.CV] UPDATED)
87. Zero-shot Object Detection Through Vision-Language Embedding Alignment. (arXiv:2109.12066v2 [cs.CV] UPDATED)
88. Generic tool for numerical simulation of transformation-diffusion processes in complex volume geometric shapes: application to microbial decomposition of organic matter. (arXiv:2110.03130v3 [eess.IV] UPDATED)
89. PL-Net: Progressive Learning Network for Medical Image Segmentation. (arXiv:2110.14484v2 [eess.IV] UPDATED)
90. Mesa: A Memory-saving Training Framework for Transformers. (arXiv:2111.11124v3 [cs.CV] UPDATED)
91. Frame Averaging for Equivariant Shape Space Learning. (arXiv:2112.01741v2 [cs.CV] UPDATED)
92. SPTS: Single-Point Text Spotting. (arXiv:2112.07917v6 [cs.CV] UPDATED)
93. Comparison and Analysis of Image-to-Image Generative Adversarial Networks: A Survey. (arXiv:2112.12625v2 [cs.CV] UPDATED)
94. ActionFormer: Localizing Moments of Actions with Transformers. (arXiv:2202.07925v2 [cs.CV] UPDATED)
95. TransCG: A Large-Scale Real-World Dataset for Transparent Object Depth Completion and a Grasping Baseline. (arXiv:2202.08471v2 [cs.RO] UPDATED)
96. Plant Species Recognition with Optimized 3D Polynomial Neural Networks and Variably Overlapping Time-Coherent Sliding Window. (arXiv:2203.02611v2 [cs.CV] UPDATED)
97. Where Does the Performance Improvement Come From? -- A Reproducibility Concern about Image-Text Retrieval. (arXiv:2203.03853v3 [cs.IR] UPDATED)
98. SPA-VAE: Similar-Parts-Assignment for Unsupervised 3D Point Cloud Generation. (arXiv:2203.07825v2 [cs.CV] UPDATED)
99. Graph Flow: Cross-layer Graph Flow Distillation for Dual Efficient Medical Image Segmentation. (arXiv:2203.08667v5 [cs.CV] UPDATED)
100. FlowFormer: A Transformer Architecture for Optical Flow. (arXiv:2203.16194v3 [cs.CV] UPDATED)
101. Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image. (arXiv:2204.01586v2 [cs.CV] UPDATED)
102. Interpretable Saliency Maps And Self-Supervised Learning For Generalized Zero Shot Medical Image Classification. (arXiv:2204.01728v2 [eess.IV] UPDATED)
103. Mixup-based Deep Metric Learning Approaches for Incomplete Supervision. (arXiv:2204.13572v3 [cs.LG] UPDATED)
104. Compound virtual screening by learning-to-rank with gradient boosting decision tree and enrichment-based cumulative gain. (arXiv:2205.02169v2 [q-bio.BM] UPDATED)
105. Deep Depth Completion from Extremely Sparse Data: A Survey. (arXiv:2205.05335v3 [cs.CV] UPDATED)
106. Deep Decomposition and Bilinear Pooling Network for Blind **Night**-Time Image Quality Evaluation. (arXiv:2205.05880v2 [cs.MM] UPDATED)
107. Equivariant Mesh Attention Networks. (arXiv:2205.10662v2 [cs.LG] UPDATED)
108. Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v2 [cs.LG] UPDATED)
109. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v5 [cs.CV] UPDATED)
110. Efficient Human Pose Estimation via 3D Event Point Cloud. (arXiv:2206.04511v2 [cs.CV] UPDATED)
111. Efficient Adaptive Ensembling for Image Classification. (arXiv:2206.07394v2 [cs.CV] UPDATED)
112. Not Just Streaks: Towards Ground Truth for Single Image Deraining. (arXiv:2206.10779v2 [cs.CV] UPDATED)
113. Stain Based Contrastive Co-training for Histopathological Image Analysis. (arXiv:2206.12505v2 [cs.CV] UPDATED)
114. Learning to segment from object sizes. (arXiv:2207.00289v2 [cs.CV] UPDATED)
115. TopicFM: Robust and Interpretable Topic-Assisted Feature Matching. (arXiv:2207.00328v2 [cs.CV] UPDATED)
116. Transformer based Models for Unsupervised Anomaly Segmentation in Brain MR Images. (arXiv:2207.02059v2 [eess.IV] UPDATED)
117. DeepSolar tracker: towards unsupervised assessment with open-source data of the accuracy of deep learning-based distributed PV mapping. (arXiv:2207.07466v2 [cs.CV] UPDATED)
118. Instance-Aware Observer Network for Out-of-Distribution Object Segmentation. (arXiv:2207.08782v3 [cs.CV] UPDATED)
119. KinD-LCE Curve Estimation And Retinex Fusion On **Low-Light** Image. (arXiv:2207.09210v2 [cs.CV] UPDATED)
120. UTOPIC: Uncertainty-aware Overlap Prediction Network for Partial Point Cloud Registration. (arXiv:2208.02712v5 [cs.CV] UPDATED)
121. Distinctive Image Captioning via CLIP Guided Group Optimization. (arXiv:2208.04254v5 [cs.CV] UPDATED)
122. One-shot Generative Prior Learned from Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v2 [eess.IV] UPDATED)
123. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v2 [cs.LG] UPDATED)
124. LWA-HAND: Lightweight Attention Hand for Interacting Hand Reconstruction. (arXiv:2208.09815v3 [cs.CV] UPDATED)
125. Depth-Assisted ResiDualGAN for Cross-Domain Aerial Images Semantic Segmentation. (arXiv:2208.09823v2 [cs.CV] UPDATED)
126. An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition using a Novel Transformers-based Model and an Innovative 270 Million-Words Multi-Font Corpus of Classical Arabic with Diacritics. (arXiv:2208.11484v2 [cs.CV] UPDATED)
127. Improving video retrieval using multilingual knowledge transfer. (arXiv:2208.11553v3 [cs.CV] UPDATED)
128. Multiresolution Neural Networks for Imaging. (arXiv:2208.11813v2 [cs.CV] UPDATED)
129. Uncertainty Guided Depth Fusion for Spike Camera. (arXiv:2208.12653v2 [cs.CV] UPDATED)
130. Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction. (arXiv:2208.12697v2 [cs.CV] UPDATED)
## eess.IV
---
**30** new papers in eess.IV:-) 
1. Riesz-Quincunx-UNet Variational Auto-Encoder for Satellite Image Denoising. (arXiv:2208.12810v1 [eess.IV])
2. A Path Towards Clinical Adaptation of Accelerated MRI. (arXiv:2208.12835v1 [eess.IV])
3. Region-guided CycleGANs for Stain Transfer in Whole Slide Images. (arXiv:2208.12847v1 [eess.IV])
4. Digital Image Processing Applied To Object Segmentation By Intensity And Motion. (arXiv:2208.12870v1 [eess.IV])
5. Neuromorphic Visual Scene Understanding with Resonator Networks. (arXiv:2208.12880v1 [cs.CV])
6. Multi-Modality Cardiac Image Computing: A Survey. (arXiv:2208.12881v1 [eess.IV])
7. Constraining Pseudo-label in Self-training Unsupervised Domain Adaptation with Energy-based Model. (arXiv:2208.12885v1 [cs.CV])
8. Pipeline-Invariant Representation Learning for Neuroimaging. (arXiv:2208.12909v1 [cs.LG])
9. Uniformly Sampled Polar and Cylindrical Grid Approach for 2D, 3D Image Reconstruction using Algebraic Algorithm. (arXiv:2208.12964v1 [eess.IV])
10. Lossy Image Compression with Quantized Hierarchical VAEs. (arXiv:2208.13056v1 [eess.IV])
11. Accurate and Robust Lesion RECIST Diameter Prediction and Segmentation with Transformers. (arXiv:2208.13113v1 [eess.IV])
12. Generative Modelling of the Ageing Heart with Cross-Sectional Imaging and Clinical Data. (arXiv:2208.13146v1 [eess.IV])
13. Deep Learning for automatic head and neck lymph node level delineation. (arXiv:2208.13224v1 [eess.IV])
14. Detection and Classification of Brain tumors Using Deep Convolutional Neural Networks. (arXiv:2208.13264v1 [eess.IV])
15. Efficient liver segmentation with 3D CNN using computed tomography scans. (arXiv:2208.13271v1 [eess.IV])
16. Unsupervised diffeomorphic cardiac image registration using parameterization of the deformation field. (arXiv:2208.13275v1 [eess.IV])
17. Slice estimation in diffusion MRI of neonatal and fetal brains in image and spherical harmonics domains using autoencoders. (arXiv:2208.13328v1 [eess.IV])
18. Label Propagation for 3D Carotid Vessel Wall Segmentation and Atherosclerosis Diagnosis. (arXiv:2208.13337v1 [eess.IV])
19. Boundary-Aware Network for Kidney Parsing. (arXiv:2208.13338v1 [eess.IV])
20. Comprehensive study of good model training for prostate segmentation in volumetric MRI. (arXiv:2208.13671v1 [eess.IV])
21. Deformable Image Registration using Unsupervised Deep Learning for CBCT-guided Abdominal Radiotherapy. (arXiv:2208.13686v1 [eess.IV])
22. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v3 [cs.LG] UPDATED)
23. Generic tool for numerical simulation of transformation-diffusion processes in complex volume geometric shapes: application to microbial decomposition of organic matter. (arXiv:2110.03130v3 [eess.IV] UPDATED)
24. PL-Net: Progressive Learning Network for Medical Image Segmentation. (arXiv:2110.14484v2 [eess.IV] UPDATED)
25. GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis. (arXiv:2203.09034v3 [cs.LG] UPDATED)
26. Interpretable Saliency Maps And Self-Supervised Learning For Generalized Zero Shot Medical Image Classification. (arXiv:2204.01728v2 [eess.IV] UPDATED)
27. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v5 [cs.CV] UPDATED)
28. Integration of Physics-Based and Data-Driven Models for Hyperspectral Image Unmixing. (arXiv:2206.05508v2 [eess.SP] UPDATED)
29. Transformer based Models for Unsupervised Anomaly Segmentation in Brain MR Images. (arXiv:2207.02059v2 [eess.IV] UPDATED)
30. One-shot Generative Prior Learned from Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v2 [eess.IV] UPDATED)
## cs.LG
---
**195** new papers in cs.LG:-) 
1. Towards Federated Learning against Noisy Labels via Local Self-Regularization. (arXiv:2208.12807v1 [cs.LG])
2. Adaptively-weighted Integral Space for Fast Multiview Clustering. (arXiv:2208.12808v1 [cs.LG])
3. Incrementality Bidding and Attribution. (arXiv:2208.12809v1 [cs.LG])
4. Riesz-Quincunx-UNet Variational Auto-Encoder for Satellite Image Denoising. (arXiv:2208.12810v1 [eess.IV])
5. PRIME: Uncovering Circadian Oscillation Patterns and Associations with AD in Untimed Genome-wide Gene Expression across Multiple Brain Regions. (arXiv:2208.12811v1 [q-bio.GN])
6. Speech Emotion Recognition using Supervised Deep Recurrent System for Mental Health Monitoring. (arXiv:2208.12812v1 [eess.AS])
7. Abnormal Local Clustering in Federated Learning. (arXiv:2208.12813v1 [cs.LG])
8. Interpretable (not just posthoc-explainable) medical claims modeling for discharge placement to prevent avoidable all-cause readmissions or death. (arXiv:2208.12814v1 [cs.CY])
9. What Does the Gradient Tell When Attacking the Graph Structure. (arXiv:2208.12815v1 [cs.LG])
10. Complexity-Driven CNN Compression for Resource-constrained Edge AI. (arXiv:2208.12816v1 [cs.LG])
11. Uncovering **dark** matter density profiles in dwarf galaxies with graph neural networks. (arXiv:2208.12825v1 [astro-ph.CO])
12. Mixtures of Gaussian Process Experts with SMC$^2$. (arXiv:2208.12830v1 [stat.ML])
13. Improving the Efficiency of Gradient Descent Algorithms Applied to Optimization Problems with Dynamical Constraints. (arXiv:2208.12834v1 [cs.LG])
14. A Path Towards Clinical Adaptation of Accelerated MRI. (arXiv:2208.12835v1 [eess.IV])
15. Domain Adaptation with Adversarial Training on Penultimate Activations. (arXiv:2208.12853v1 [cs.LG])
16. Local Context-Aware Active Domain Adaptation. (arXiv:2208.12856v1 [cs.LG])
17. Reducing Computational Complexity of Neural Networks in Optical Channel Equalization: From Concepts to Implementation. (arXiv:2208.12866v1 [eess.SP])
18. DETERRENT: Detecting Trojans using Reinforcement Learning. (arXiv:2208.12878v1 [cs.LG])
19. Constraining Pseudo-label in Self-training Unsupervised Domain Adaptation with Energy-based Model. (arXiv:2208.12885v1 [cs.CV])
20. Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers. (arXiv:2208.12886v1 [cs.CL])
21. ATTRITION: Attacking Static Hardware Trojan Detection Techniques Using Reinforcement Learning. (arXiv:2208.12897v1 [cs.CR])
22. A Comprehensive Review of Digital Twin -- Part 2: Roles of Uncertainty Quantification and Optimization, a Battery Digital Twin, and Perspectives. (arXiv:2208.12904v1 [cs.LG])
23. Pipeline-Invariant Representation Learning for Neuroimaging. (arXiv:2208.12909v1 [cs.LG])
24. Network-Level Adversaries in Federated Learning. (arXiv:2208.12911v1 [cs.CR])
25. Quantifying French Document Complexity. (arXiv:2208.12924v1 [cs.CL])
26. Overparameterized (robust) models from computational constraints. (arXiv:2208.12926v1 [cs.LG])
27. A scalable pipeline for COVID-19: the case study of Germany, Czechia and Poland. (arXiv:2208.12928v1 [cs.DB])
28. BOBA: Byzantine-Robust Federated Learning with Label Skewness. (arXiv:2208.12932v1 [cs.LG])
29. Consistency between ordering and clustering methods for graphs. (arXiv:2208.12933v1 [cs.LG])
30. Virtual Control Group: Measuring Hidden Performance Metrics. (arXiv:2208.12941v1 [cs.LG])
31. Tensor Decomposition based Personalized Federated Learning. (arXiv:2208.12959v1 [cs.LG])
32. Deep Kernel Learning of Dynamical Models from High-Dimensional Noisy Data. (arXiv:2208.12975v1 [cs.LG])
33. Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo. (arXiv:2208.12991v1 [cs.NE])
34. A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges. (arXiv:2208.12996v1 [cs.CV])
35. Neural Observer with Lyapunov Stability Guarantee for Uncertain Nonlinear Systems. (arXiv:2208.13006v1 [math.OC])
36. Improving debris flow evacuation alerts in Taiwan using machine learning. (arXiv:2208.13027v1 [cs.LG])
37. RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for low latency IoT systems. (arXiv:2208.13032v1 [cs.LG])
38. TrojViT: Trojan Insertion in Vision Transformers. (arXiv:2208.13049v1 [cs.LG])
39. Lossy Image Compression with Quantized Hierarchical VAEs. (arXiv:2208.13056v1 [eess.IV])
40. Adversarial Robustness for Tabular Data through Cost and Utility Awareness. (arXiv:2208.13058v1 [cs.LG])
41. On GANs perpetuating biases for face verification. (arXiv:2208.13061v1 [cs.CV])
42. Improving Electricity Market Economy via Closed-Loop Predict-and-Optimize. (arXiv:2208.13065v1 [math.OC])
43. SupervisorBot: NLP-Annotated Real-Time Recommendations of Psychotherapy Treatment Strategies with Deep Reinforcement Learning. (arXiv:2208.13077v1 [cs.CL])
44. Geometrical Homogeneous Clustering for Image Data Reduction. (arXiv:2208.13079v1 [cs.LG])
45. Information FOMO: The unhealthy fear of missing out on information. A method for removing misleading data for healthier models. (arXiv:2208.13080v1 [cs.LG])
46. Label-Efficient Self-Training for Attribute Extraction from Semi-Structured Web Documents. (arXiv:2208.13086v1 [cs.IR])
47. Federated Sparse Training: Lottery Aware Model Compression for Resource Constrained Edge. (arXiv:2208.13092v1 [cs.LG])
48. An Empirical Study on the Usage of Automated Machine Learning Tools. (arXiv:2208.13116v1 [cs.SE])
49. Normality-Guided Distributional Reinforcement Learning for Continuous Control. (arXiv:2208.13125v1 [cs.LG])
50. Learning Clinical Concepts for Predicting Risk of Progression to Severe COVID-19. (arXiv:2208.13126v1 [cs.LG])
51. An Access Control Method with Secret Key for Semantic Segmentation Models. (arXiv:2208.13135v1 [cs.CV])
52. Federated Learning of Large Models at the Edge via Principal Sub-Model Training. (arXiv:2208.13141v1 [cs.LG])
53. Generative Modelling of the Ageing Heart with Cross-Sectional Imaging and Clinical Data. (arXiv:2208.13146v1 [eess.IV])
54. Asynchronous Training Schemes in Distributed Learning with Time Delay. (arXiv:2208.13154v1 [cs.LG])
55. RUAD: unsupervised anomaly detection in HPC systems. (arXiv:2208.13169v1 [cs.LG])
56. Learning Heterogeneous Interaction Strengths by Trajectory Prediction with Graph Neural Network. (arXiv:2208.13179v1 [cs.LG])
57. Cross-domain Cross-architecture Black-box Attacks on Fine-tuned Models with Transferred Evolutionary Strategies. (arXiv:2208.13182v1 [cs.LG])
58. IDP-PGFE: An Interpretable Disruption Predictor based on Physics-Guided Feature Extraction. (arXiv:2208.13197v1 [physics.plasm-ph])
59. Leachable Component Clustering. (arXiv:2208.13217v1 [cs.LG])
60. Visualizing high-dimensional loss landscapes with Hessian directions. (arXiv:2208.13219v1 [cs.LG])
61. AutoQML: Automatic Generation and Training of Robust Quantum-Inspired Classifiers by Using Genetic Algorithms on Grayscale Images. (arXiv:2208.13246v1 [quant-ph])
62. FFCNN: Fast FPGA based Acceleration for Convolution neural network inference. (arXiv:2208.13250v1 [cs.LG])
63. MANDO: Multi-Level Heterogeneous Graph Embeddings for Fine-Grained Detection of Smart Contract Vulnerabilities. (arXiv:2208.13252v1 [cs.SE])
64. Efficient liver segmentation with 3D CNN using computed tomography scans. (arXiv:2208.13271v1 [eess.IV])
65. A Hybrid Iterative Numerical Transferable Solver (HINTS) for PDEs Based on Deep Operator Network and Relaxation Methods. (arXiv:2208.13273v1 [math.NA])
66. Unsupervised diffeomorphic cardiac image registration using parameterization of the deformation field. (arXiv:2208.13275v1 [eess.IV])
67. Computing with Hypervectors for Efficient Speaker Identification. (arXiv:2208.13285v1 [cs.SD])
68. Contrastive Feature Learning for Fault Detection and Diagnostics in Railway Applications. (arXiv:2208.13288v1 [cs.LG])
69. Statistical Inverse Problems in Hilbert Scales. (arXiv:2208.13289v1 [math.ST])
70. Domain Adaptation Principal Component Analysis: base linear method for learning with out-of-distribution data. (arXiv:2208.13290v1 [cs.LG])
71. Goal-Conditioned Q-Learning as Knowledge Distillation. (arXiv:2208.13298v1 [cs.LG])
72. Predicting IMDb Rating of TV Series with Deep Learning: The Case of Arrow. (arXiv:2208.13302v1 [cs.LG])
73. Neural Network Approximation of Lipschitz Functions in High Dimensions with Applications to Inverse Problems. (arXiv:2208.13305v1 [stat.ML])
74. Fluorescence molecular optomic signatures improve identification of tumors in head and neck specimens. (arXiv:2208.13314v1 [cs.LG])
75. Normalized Activation Function: Toward Better Convergence. (arXiv:2208.13315v1 [cs.LG])
76. Minute ventilation measurement using Plethysmographic Imaging and lighting parameters. (arXiv:2208.13319v1 [cs.LG])
77. Time-aware Self-Attention Meets Logic Reasoning in Recommender Systems. (arXiv:2208.13330v1 [cs.IR])
78. Billion-user Customer Lifetime Value Prediction: An Industrial-scale Solution from Kuaishou. (arXiv:2208.13358v1 [cs.LG])
79. Survey: Exploiting Data Redundancy for Optimization of Deep Learning. (arXiv:2208.13363v1 [cs.LG])
80. Affective Manifolds: Modeling Machine's Mind to Like, Dislike, Enjoy, Suffer, Worry, Fear, and Feel Like A Human. (arXiv:2208.13386v1 [cs.LG])
81. Interpreting Black-box Machine Learning Models for High Dimensional Datasets. (arXiv:2208.13405v1 [cs.LG])
82. The PWLR Graph Representation: A Persistent Weisfeiler-Lehman scheme with Random Walks for Graph Classification. (arXiv:2208.13427v1 [cs.LG])
83. Towards In-distribution Compatibility in Out-of-distribution Detection. (arXiv:2208.13433v1 [cs.CV])
84. A Missing Value Filling Model Based on Feature Fusion Enhanced Autoencoder. (arXiv:2208.13495v1 [cs.LG])
85. Generalization In Multi-Objective Machine Learning. (arXiv:2208.13499v1 [cs.LG])
86. Semantic Clustering of a Sequence of Satellite Images. (arXiv:2208.13504v1 [cs.CV])
87. Lateral Movement Detection Using User Behavioral Analysis. (arXiv:2208.13524v1 [cs.CR])
88. Stock Market Prediction using Natural Language Processing -- A Survey. (arXiv:2208.13564v1 [q-fin.ST])
89. PECAN: A Product-Quantized Content Addressable Memory Network. (arXiv:2208.13571v1 [cs.LG])
90. Shaken, and Stirred: Long-Range Dependencies Enable Robust Outlier Detection with PixelCNN++. (arXiv:2208.13579v1 [cs.LG])
91. Spatio-Temporal Wind Speed Forecasting using Graph Networks and Novel Transformer Architectures. (arXiv:2208.13585v1 [cs.LG])
92. Smooth Monotone Stochastic Variational Inequalities and Saddle Point Problems -- Survey. (arXiv:2208.13592v1 [math.OC])
93. Combating high variance in Data-Scarce Implicit Hate Speech Classification. (arXiv:2208.13595v1 [cs.CL])
94. Approach of variable clustering and compression for learning large Bayesian networks. (arXiv:2208.13605v1 [stat.ML])
95. Neural Tangent Kernel: A Survey. (arXiv:2208.13614v1 [cs.LG])
96. Decentralized Coordination in Partially Observable Queueing Networks. (arXiv:2208.13621v1 [cs.LG])
97. Towards Reliable Simulation-Based Inference with Balanced Neural Ratio Estimation. (arXiv:2208.13624v1 [stat.ML])
98. CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous Multi-Agent Reinforcement Learning. (arXiv:2208.13626v1 [cs.AI])
99. Efficient Vision-Language Pretraining with Visual Concepts and Hierarchical Alignment. (arXiv:2208.13628v1 [cs.CV])
100. A Variance-Reduced Stochastic Gradient Tracking Algorithm for Decentralized Optimization with Orthogonality Constraints. (arXiv:2208.13643v1 [math.OC])
101. Understanding the Limits of Poisoning Attacks in Episodic Reinforcement Learning. (arXiv:2208.13663v1 [cs.LG])
102. Latent Heterogeneous Graph Network for Incomplete Multi-View Learning. (arXiv:2208.13669v1 [cs.LG])
103. Comprehensive study of good model training for prostate segmentation in volumetric MRI. (arXiv:2208.13671v1 [eess.IV])
104. FedEgo: Privacy-preserving Personalized Federated Graph Learning with Ego-graphs. (arXiv:2208.13685v1 [cs.LG])
105. Empirical Gateaux Derivatives for Causal Inference. (arXiv:2208.13701v1 [stat.ME])
106. Online Bidding Algorithms for Return-on-Spend Constrained Advertisers. (arXiv:2208.13713v1 [cs.LG])
107. Open-Set Semi-Supervised Object Detection. (arXiv:2208.13722v1 [cs.CV])
108. Bayesian Continual Learning via Spiking Neural Networks. (arXiv:2208.13723v1 [cs.NE])
109. A Hitchhiker's Guide to Statistical Comparisons of Reinforcement Learning Algorithms. (arXiv:1904.06979v2 [stat.ME] UPDATED)
110. Invertible Gaussian Reparameterization: Revisiting the Gumbel-Softmax. (arXiv:1912.09588v5 [stat.ML] UPDATED)
111. Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network. (arXiv:2004.13821v3 [cs.CL] UPDATED)
112. Rethinking and Improving Natural Language Generation with Layer-Wise Multi-View Decoding. (arXiv:2005.08081v7 [cs.CL] UPDATED)
113. Online Learning in Iterated Prisoner's Dilemma to Mimic Human Behavior. (arXiv:2006.06580v3 [cs.GT] UPDATED)
114. HGKT: Introducing Hierarchical Exercise Graph for Knowledge Tracing. (arXiv:2006.16915v6 [cs.CY] UPDATED)
115. Variance Reduced EXTRA and DIGing and Their Optimal Acceleration for Strongly Convex Decentralized Optimization. (arXiv:2009.04373v3 [math.OC] UPDATED)
116. Unsupervised Scale-Invariant Multispectral Shape Matching. (arXiv:2012.10685v2 [cs.CV] UPDATED)
117. Optimising Placement of Pollution Sensors in Windy Environments. (arXiv:2012.10770v2 [cs.LG] UPDATED)
118. Maximum-Likelihood Quantum State Tomography by Soft-Bayes. (arXiv:2012.15498v3 [cs.LG] UPDATED)
119. On the Universal Transformation of Data-Driven Models to Control Systems. (arXiv:2102.04722v2 [math.OC] UPDATED)
120. Online Learning via Offline Greedy Algorithms: Applications in Market Design and Optimization. (arXiv:2102.11050v3 [cs.LG] UPDATED)
121. GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention. (arXiv:2104.05914v3 [cs.LG] UPDATED)
122. Reinforcement Learning for Ridesharing: An Extended Survey. (arXiv:2105.01099v7 [cs.LG] UPDATED)
123. Self-Supervised Adversarial Example Detection by Disentangled Representation. (arXiv:2105.03689v4 [cs.CV] UPDATED)
124. IM-META: Influence Maximization Using Node Metadata in Networks With Unknown Topology. (arXiv:2106.02926v2 [cs.SI] UPDATED)
125. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v3 [cs.LG] UPDATED)
126. Dealing with Expert Bias in Collective Decision-Making. (arXiv:2106.13539v2 [cs.AI] UPDATED)
127. fMBN-E: Efficient Unsupervised Network Structure Ensemble and Selection for Clustering. (arXiv:2107.02071v5 [cs.LG] UPDATED)
128. High-Dimensional Distribution Generation Through Deep Neural Networks. (arXiv:2107.12466v3 [cs.LG] UPDATED)
129. Social Processes: Self-Supervised Meta-Learning over Conversational Groups for Forecasting Nonverbal Social Cues. (arXiv:2107.13576v3 [cs.LG] UPDATED)
130. Continual Semi-Supervised Learning through Contrastive Interpolation Consistency. (arXiv:2108.06552v3 [stat.ML] UPDATED)
131. Scenario generation for market risk models using generative neural networks. (arXiv:2109.10072v4 [cs.LG] UPDATED)
132. PL-Net: Progressive Learning Network for Medical Image Segmentation. (arXiv:2110.14484v2 [eess.IV] UPDATED)
133. OpenFWI: Large-Scale Multi-Structural Benchmark Datasets for Seismic Full Waveform Inversion. (arXiv:2111.02926v4 [cs.LG] UPDATED)
134. Mesa: A Memory-saving Training Framework for Transformers. (arXiv:2111.11124v3 [cs.CV] UPDATED)
135. Node-Level Differentially Private Graph Neural Networks. (arXiv:2111.15521v3 [cs.LG] UPDATED)
136. Frame Averaging for Equivariant Shape Space Learning. (arXiv:2112.01741v2 [cs.CV] UPDATED)
137. Bayesian Graph Contrastive Learning. (arXiv:2112.07823v4 [cs.LG] UPDATED)
138. Robust Distributed Bayesian Learning with Stragglers via Consensus Monte Carlo. (arXiv:2112.09794v2 [cs.LG] UPDATED)
139. Learning with Proper Partial Labels. (arXiv:2112.12303v2 [cs.LG] UPDATED)
140. Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction. (arXiv:2112.15445v2 [cs.LG] UPDATED)
141. Predicting Wind-Driven Spatial Deposition through Simulated Color Images using Deep Autoencoders. (arXiv:2202.01762v2 [cs.LG] UPDATED)
142. A Graph-based U-Net Model for Predicting Traffic in unseen Cities. (arXiv:2202.06725v4 [cs.LG] UPDATED)
143. Survey of Machine Learning Based Intrusion Detection Methods for Internet of Medical Things. (arXiv:2202.09657v2 [cs.CR] UPDATED)
144. Theoretical Analysis of Deep Neural Networks in Physical Layer Communication. (arXiv:2202.09954v2 [eess.SP] UPDATED)
145. Quantum Differential Privacy: An Information Theory Perspective. (arXiv:2202.10717v2 [quant-ph] UPDATED)
146. A Dynamic Mode Decomposition Approach for Decentralized Spectral Clustering of Graphs. (arXiv:2203.00004v2 [cs.LG] UPDATED)
147. Transfer Learning of High-Fidelity Opacity Spectra in Autoencoders and Surrogate Models. (arXiv:2203.00853v2 [physics.plasm-ph] UPDATED)
148. Plant Species Recognition with Optimized 3D Polynomial Neural Networks and Variably Overlapping Time-Coherent Sliding Window. (arXiv:2203.02611v2 [cs.CV] UPDATED)
149. Neural **Enhancement** of Factor Graph-based Symbol Detection. (arXiv:2203.03333v2 [cs.IT] UPDATED)
150. Assessing Phenotype Definitions for Algorithmic Fairness. (arXiv:2203.05174v2 [q-bio.OT] UPDATED)
151. Comparing two samples through stochastic dominance: a graphical approach. (arXiv:2203.07889v3 [stat.ML] UPDATED)
152. GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis. (arXiv:2203.09034v3 [cs.LG] UPDATED)
153. Low-degree learning and the metric entropy of polynomials. (arXiv:2203.09659v2 [cs.LG] UPDATED)
154. An Offset-Free Nonlinear MPC scheme for systems learned by Neural NARX models. (arXiv:2203.16290v2 [eess.SY] UPDATED)
155. Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning. (arXiv:2203.16464v2 [cs.LG] UPDATED)
156. Interpretable Saliency Maps And Self-Supervised Learning For Generalized Zero Shot Medical Image Classification. (arXiv:2204.01728v2 [eess.IV] UPDATED)
157. Learning High-Dimensional McKean-Vlasov Forward-Backward Stochastic Differential Equations with General Distribution Dependence. (arXiv:2204.11924v2 [math.OC] UPDATED)
158. Mixup-based Deep Metric Learning Approaches for Incomplete Supervision. (arXiv:2204.13572v3 [cs.LG] UPDATED)
159. Learning to Get Up. (arXiv:2205.00307v2 [cs.GR] UPDATED)
160. Compound virtual screening by learning-to-rank with gradient boosting decision tree and enrichment-based cumulative gain. (arXiv:2205.02169v2 [q-bio.BM] UPDATED)
161. Equivariant Mesh Attention Networks. (arXiv:2205.10662v2 [cs.LG] UPDATED)
162. PrivFairFL: Privacy-Preserving Group Fairness in Federated Learning. (arXiv:2205.11584v2 [cs.LG] UPDATED)
163. Personalized PageRank Graph Attention Networks. (arXiv:2205.14259v2 [cs.LG] UPDATED)
164. Neural Network Verification with Proof Production. (arXiv:2206.00512v2 [cs.LO] UPDATED)
165. Developing hierarchical anticipations via neural network-based event segmentation. (arXiv:2206.02042v2 [cs.LG] UPDATED)
166. Robust Fine-Tuning of Deep Neural Networks with Hessian-based Generalization Guarantees. (arXiv:2206.02659v2 [cs.LG] UPDATED)
167. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v5 [cs.CV] UPDATED)
168. Sum-of-Squares Relaxations for Information Theory and Variational Inference. (arXiv:2206.13285v2 [cs.IT] UPDATED)
169. Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump ODEs. (arXiv:2206.14284v2 [stat.ML] UPDATED)
170. Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs. (arXiv:2207.00956v2 [cs.DS] UPDATED)
171. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v6 [eess.SY] UPDATED)
172. Lagrangian Method for Q-Function Learning (with Applications to Machine Translation). (arXiv:2207.11161v2 [cs.LG] UPDATED)
173. Variance estimation in graphs with the fused lasso. (arXiv:2207.12638v2 [math.ST] UPDATED)
174. Improved and Interpretable Defense to Transferred Adversarial Examples by Jacobian Norm with Selective Input Gradient Regularization. (arXiv:2207.13036v3 [cs.LG] UPDATED)
175. CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA). (arXiv:2208.01040v3 [cs.LG] UPDATED)
176. Post-hoc Interpretability based Parameter Selection for Data Oriented Nuclear Reactor Accident Diagnosis System. (arXiv:2208.01805v2 [eess.SY] UPDATED)
177. The Influence of Network Structural Preference on Node Classification and Link Prediction. (arXiv:2208.03712v3 [cs.LG] UPDATED)
178. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v2 [cs.LG] UPDATED)
179. SYNTHESIS: A Semi-Asynchronous Path-Integrated Stochastic Gradient Method for Distributed Learning in Computing Clusters. (arXiv:2208.08425v2 [cs.LG] UPDATED)
180. Memory and Capacity of Graph Embedding Methods. (arXiv:2208.08769v2 [stat.ML] UPDATED)
181. Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v2 [cs.CL] UPDATED)
182. A semantic web approach to uplift decentralized household energy data. (arXiv:2208.10265v2 [cs.AI] UPDATED)
183. An intelligent algorithmic trading based on a risk-return reinforcement learning algorithm. (arXiv:2208.10707v2 [cs.LG] UPDATED)
184. Graph Embeddings via Tensor Products and Approximately Orthonormal Codes. (arXiv:2208.10917v2 [cs.SI] UPDATED)
185. Preprocessing Source Code Comments for Linguistic Models. (arXiv:2208.11235v2 [cs.SE] UPDATED)
186. Psychophysical Machine Learning. (arXiv:2208.11236v2 [cs.LG] UPDATED)
187. Automatic music mixing with deep learning and out-of-domain data. (arXiv:2208.11428v2 [eess.AS] UPDATED)
188. An End-to-End OCR Framework for Robust Arabic-Handwriting Recognition using a Novel Transformers-based Model and an Innovative 270 Million-Words Multi-Font Corpus of Classical Arabic with Diacritics. (arXiv:2208.11484v2 [cs.CV] UPDATED)
189. FedOS: using open-set learning to stabilize training in federated learning. (arXiv:2208.11512v2 [stat.ML] UPDATED)
190. Multiresolution Neural Networks for Imaging. (arXiv:2208.11813v2 [cs.CV] UPDATED)
191. A Compact Pretraining Approach for Neural Language Models. (arXiv:2208.12367v2 [cs.CL] UPDATED)
192. Symbolic Explanation of Affinity-Based Reinforcement Learning Agents with Markov Models. (arXiv:2208.12627v2 [cs.LG] UPDATED)
193. Algebraically Explainable Controllers: Decision Trees and Support Vector Machines Join Forces. (arXiv:2208.12804v2 [cs.LG] UPDATED)
194. Geometrical versus time-series representation of data in quantum control learning. (arXiv:1803.05169v2 [quant-ph] CROSS LISTED)
195. Approximation of quantum control correction scheme using deep neural networks. (arXiv:1803.05193v2 [quant-ph] CROSS LISTED)
## cs.AI
---
**87** new papers in cs.AI:-) 
1. Towards Federated Learning against Noisy Labels via Local Self-Regularization. (arXiv:2208.12807v1 [cs.LG])
2. Adaptively-weighted Integral Space for Fast Multiview Clustering. (arXiv:2208.12808v1 [cs.LG])
3. PRIME: Uncovering Circadian Oscillation Patterns and Associations with AD in Untimed Genome-wide Gene Expression across Multiple Brain Regions. (arXiv:2208.12811v1 [q-bio.GN])
4. Abnormal Local Clustering in Federated Learning. (arXiv:2208.12813v1 [cs.LG])
5. Interpretable (not just posthoc-explainable) medical claims modeling for discharge placement to prevent avoidable all-cause readmissions or death. (arXiv:2208.12814v1 [cs.CY])
6. What Does the Gradient Tell When Attacking the Graph Structure. (arXiv:2208.12815v1 [cs.LG])
7. Complexity-Driven CNN Compression for Resource-constrained Edge AI. (arXiv:2208.12816v1 [cs.LG])
8. What Do NLP Researchers Believe? Results of the NLP Community Metasurvey. (arXiv:2208.12852v1 [cs.CL])
9. DETERRENT: Detecting Trojans using Reinforcement Learning. (arXiv:2208.12878v1 [cs.LG])
10. Neuromorphic Visual Scene Understanding with Resonator Networks. (arXiv:2208.12880v1 [cs.CV])
11. Constraining Pseudo-label in Self-training Unsupervised Domain Adaptation with Energy-based Model. (arXiv:2208.12885v1 [cs.CV])
12. Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers. (arXiv:2208.12886v1 [cs.CL])
13. ATTRITION: Attacking Static Hardware Trojan Detection Techniques Using Reinforcement Learning. (arXiv:2208.12897v1 [cs.CR])
14. Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo. (arXiv:2208.12991v1 [cs.NE])
15. Object Goal Navigation using Data Regularized Q-Learning. (arXiv:2208.13009v1 [cs.RO])
16. On Unsupervised Training of Link Grammar Based Language Models. (arXiv:2208.13021v1 [cs.CL])
17. Improving debris flow evacuation alerts in Taiwan using machine learning. (arXiv:2208.13027v1 [cs.LG])
18. Spatial Relation Graph and Graph Convolutional Network for Object Goal Navigation. (arXiv:2208.13031v1 [cs.RO])
19. RL-DistPrivacy: Privacy-Aware Distributed Deep Inference for low latency IoT systems. (arXiv:2208.13032v1 [cs.LG])
20. On GANs perpetuating biases for face verification. (arXiv:2208.13061v1 [cs.CV])
21. A Diversity-Aware Domain Development Methodology. (arXiv:2208.13064v1 [cs.AI])
22. SupervisorBot: NLP-Annotated Real-Time Recommendations of Psychotherapy Treatment Strategies with Deep Reinforcement Learning. (arXiv:2208.13077v1 [cs.CL])
23. An Empirical Study on the Usage of Automated Machine Learning Tools. (arXiv:2208.13116v1 [cs.SE])
24. Normality-Guided Distributional Reinforcement Learning for Continuous Control. (arXiv:2208.13125v1 [cs.LG])
25. Federated Learning of Large Models at the Edge via Principal Sub-Model Training. (arXiv:2208.13141v1 [cs.LG])
26. Opinion Leader Detection in Online Social Networks Based on Output and Input Links. (arXiv:2208.13161v1 [cs.SI])
27. Influence Maximization (IM) in Complex Networks with Limited Visibility Using Statistical Methods. (arXiv:2208.13166v1 [cs.SI])
28. RUAD: unsupervised anomaly detection in HPC systems. (arXiv:2208.13169v1 [cs.LG])
29. Towards Disentangled Speech Representations. (arXiv:2208.13191v1 [cs.SD])
30. IDP-PGFE: An Interpretable Disruption Predictor based on Physics-Guided Feature Extraction. (arXiv:2208.13197v1 [physics.plasm-ph])
31. FFCNN: Fast FPGA based Acceleration for Convolution neural network inference. (arXiv:2208.13250v1 [cs.LG])
32. Bayesian Neural Network Language Modeling for Speech Recognition. (arXiv:2208.13259v1 [cs.CL])
33. JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents. (arXiv:2208.13266v1 [cs.AI])
34. Adapting the LodView RDF Browser for Navigation over the Multilingual Linguistic Linked Open Data Cloud. (arXiv:2208.13295v1 [cs.CL])
35. Normalized Activation Function: Toward Better Convergence. (arXiv:2208.13315v1 [cs.LG])
36. Multi-dimensional Racism Classification during COVID-19: Stigmatization, Offensiveness, Blame, and Exclusion. (arXiv:2208.13318v1 [cs.CY])
37. Effective approaches to disaster evacuation during a COVID-like pandemic. (arXiv:2208.13326v1 [q-bio.PE])
38. Time-aware Self-Attention Meets Logic Reasoning in Recommender Systems. (arXiv:2208.13330v1 [cs.IR])
39. Affective Manifolds: Modeling Machine's Mind to Like, Dislike, Enjoy, Suffer, Worry, Fear, and Feel Like A Human. (arXiv:2208.13386v1 [cs.LG])
40. Unified Bayesian Frameworks for Multi-criteria Decision-making. (arXiv:2208.13390v1 [cs.AI])
41. Rethinking Skip Connections in Encoder-decoder Networks for Monocular Depth Estimation. (arXiv:2208.13441v1 [cs.CV])
42. Generalization In Multi-Objective Machine Learning. (arXiv:2208.13499v1 [cs.LG])
43. Detecting Surprising Situations in Event Data. (arXiv:2208.13515v1 [cs.AI])
44. LogicRank: Logic Induced Reranking for Generative Text-to-Image Systems. (arXiv:2208.13518v1 [cs.AI])
45. PECAN: A Product-Quantized Content Addressable Memory Network. (arXiv:2208.13571v1 [cs.LG])
46. Spatio-Temporal Wind Speed Forecasting using Graph Networks and Novel Transformer Architectures. (arXiv:2208.13585v1 [cs.LG])
47. Chosen methods of improving object recognition of small objects with weak recognizable features. (arXiv:2208.13591v1 [cs.CV])
48. CH-MARL: A Multimodal Benchmark for Cooperative, Heterogeneous Multi-Agent Reinforcement Learning. (arXiv:2208.13626v1 [cs.AI])
49. Categorical semantics of compositional reinforcement learning. (arXiv:2208.13687v1 [cs.AI])
50. Bayesian Continual Learning via Spiking Neural Networks. (arXiv:2208.13723v1 [cs.NE])
51. Fine-tuning Multi-hop Question Answering with Hierarchical Graph Network. (arXiv:2004.13821v3 [cs.CL] UPDATED)
52. Online Learning in Iterated Prisoner's Dilemma to Mimic Human Behavior. (arXiv:2006.06580v3 [cs.GT] UPDATED)
53. HGKT: Introducing Hierarchical Exercise Graph for Knowledge Tracing. (arXiv:2006.16915v6 [cs.CY] UPDATED)
54. Causality and independence in perfectly adapted dynamical systems. (arXiv:2101.11885v2 [cs.AI] UPDATED)
55. GSA-Forecaster: Forecasting Graph-Based Time-Dependent Data with Graph Sequence Attention. (arXiv:2104.05914v3 [cs.LG] UPDATED)
56. Reinforcement Learning for Ridesharing: An Extended Survey. (arXiv:2105.01099v7 [cs.LG] UPDATED)
57. Pervasive AI for IoT applications: A Survey on Resource-efficient Distributed Artificial Intelligence. (arXiv:2105.01798v2 [cs.DC] UPDATED)
58. IM-META: Influence Maximization Using Node Metadata in Networks With Unknown Topology. (arXiv:2106.02926v2 [cs.SI] UPDATED)
59. Dealing with Expert Bias in Collective Decision-Making. (arXiv:2106.13539v2 [cs.AI] UPDATED)
60. Fast and scalable neuroevolution deep learning architecture search for multivariate anomaly detection. (arXiv:2112.05640v6 [cs.NE] UPDATED)
61. Unsupervised Dense Information Retrieval with Contrastive Learning. (arXiv:2112.09118v4 [cs.IR] UPDATED)
62. Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction. (arXiv:2112.15445v2 [cs.LG] UPDATED)
63. Strategyproofing Peer Assessment via Partitioning: The Price in Terms of Evaluators' Expertise. (arXiv:2201.10631v3 [cs.GT] UPDATED)
64. A Graph-based U-Net Model for Predicting Traffic in unseen Cities. (arXiv:2202.06725v4 [cs.LG] UPDATED)
65. Assessing Phenotype Definitions for Algorithmic Fairness. (arXiv:2203.05174v2 [q-bio.OT] UPDATED)
66. Towards Interpretable Deep Reinforcement Learning Models via Inverse Reinforcement Learning. (arXiv:2203.16464v2 [cs.LG] UPDATED)
67. Learning Implicit Priors for Motion Optimization. (arXiv:2204.05369v2 [cs.RO] UPDATED)
68. Developing hierarchical anticipations via neural network-based event segmentation. (arXiv:2206.02042v2 [cs.LG] UPDATED)
69. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v5 [cs.CV] UPDATED)
70. Worldwide AI Ethics: a review of 200 guidelines and recommendations for AI governance. (arXiv:2206.11922v3 [cs.CY] UPDATED)
71. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v6 [eess.SY] UPDATED)
72. Lagrangian Method for Q-Function Learning (with Applications to Machine Translation). (arXiv:2207.11161v2 [cs.LG] UPDATED)
73. Improved and Interpretable Defense to Transferred Adversarial Examples by Jacobian Norm with Selective Input Gradient Regularization. (arXiv:2207.13036v3 [cs.LG] UPDATED)
74. Chinese grammatical error correction based on knowledge distillation. (arXiv:2208.00351v3 [cs.CL] UPDATED)
75. Post-hoc Interpretability based Parameter Selection for Data Oriented Nuclear Reactor Accident Diagnosis System. (arXiv:2208.01805v2 [eess.SY] UPDATED)
76. The Influence of Network Structural Preference on Node Classification and Link Prediction. (arXiv:2208.03712v3 [cs.LG] UPDATED)
77. The History of AI Rights Research. (arXiv:2208.04714v2 [cs.CY] UPDATED)
78. Probabilistic Variational Causal Effect as A new Theory for Causal Reasoning. (arXiv:2208.06269v2 [cs.AI] UPDATED)
79. I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning. (arXiv:2208.09828v2 [cs.CL] UPDATED)
80. Using Large Language Models to Simulate Multiple Humans. (arXiv:2208.10264v2 [cs.CL] UPDATED)
81. A semantic web approach to uplift decentralized household energy data. (arXiv:2208.10265v2 [cs.AI] UPDATED)
82. K-MHaS: A Multi-label Hate Speech Detection Dataset in Korean Online News Comment. (arXiv:2208.10684v2 [cs.CL] UPDATED)
83. Psychophysical Machine Learning. (arXiv:2208.11236v2 [cs.LG] UPDATED)
84. Concept-Based Techniques for "Musicologist-friendly" Explanations in a Deep Music Classifier. (arXiv:2208.12485v2 [cs.SD] UPDATED)
85. GRASP: Guiding model with RelAtional Semantics using Prompt. (arXiv:2208.12494v2 [cs.CL] UPDATED)
86. Symbolic Explanation of Affinity-Based Reinforcement Learning Agents with Markov Models. (arXiv:2208.12627v2 [cs.LG] UPDATED)
87. Algebraically Explainable Controllers: Decision Trees and Support Vector Machines Join Forces. (arXiv:2208.12804v2 [cs.LG] UPDATED)

