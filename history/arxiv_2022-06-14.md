# Your interest papers
---
## cs.CV
---
### Generalizable Neural Radiance Fields for Novel View Synthesis with Transformer. (arXiv:2206.05375v1 [cs.CV])
- Authors : Dan Wang, Xinrui Cui, Septimiu Salcudean, Jane Wang
- Link : [http://arxiv.org/abs/2206.05375](http://arxiv.org/abs/2206.05375)
> ABSTRACT  :  We propose a Transformer-based **NeRF** (Trans**NeRF**) to learn a generic neural radiance field conditioned on observed-view images for the novel view synthesis task. By contrast, existing MLP-based **NeRF**s are not able to directly receive observed views with an arbitrary number and require an auxiliary pooling-based operation to fuse source-view information, resulting in the missing of complicated relationships between source views and the target rendering view. Furthermore, current approaches process each 3D point individually and ignore the local consistency of a radiance field scene representation. These limitations potentially can reduce their performance in challenging real-world applications where large differences between source views and a novel rendering view may exist. To address these challenges, our Trans**NeRF** utilizes the attention mechanism to naturally decode deep associations of an arbitrary number of source views into a coordinate-based scene representation. Local consistency of shape and appearance are considered in the ray-cast space and the surrounding-view space within a unified Transformer network. Experiments demonstrate that our Trans**NeRF**, trained on a wide variety of scenes, can achieve better performance in comparison to state-of-the-art image-based neural rendering methods in both scene-agnostic and per-scene finetuning scenarios especially when there is a considerable gap between source views and a rendering view.  
### Luminance-Guided Chrominance Image **Enhancement** for HEVC Intra Coding. (arXiv:2206.05432v1 [cs.CV])
- Authors : Hewei Liu, Renwei Yang, Shuyuan Zhu, Xing Wen, Bing Zeng
- Link : [http://arxiv.org/abs/2206.05432](http://arxiv.org/abs/2206.05432)
> ABSTRACT  :  In this paper, we propose a luminance-guided chrominance image **enhancement** convolutional neural network for HEVC intra coding. Specifically, we firstly develop a gated recursive asymmetric-convolution block to restore each degraded chrominance image, which generates an intermediate output. Then, guided by the luminance image, the quality of this intermediate output is further improved, which finally produces the high-quality chrominance image. When our proposed method is adopted in the compression of color images with HEVC intra coding, it achieves 28.96% and 16.74% BD-rate gains over HEVC for the U and V images, respectively, which accordingly demonstrate its superiority.  
### Toward Real-world Single Image Deraining: A New Benchmark and Beyond. (arXiv:2206.05514v1 [cs.CV])
- Authors : Wei Li, Qiming Zhang, Jing Zhang, Zhen Huang, Xinmei Tian, Dacheng Tao
- Link : [http://arxiv.org/abs/2206.05514](http://arxiv.org/abs/2206.05514)
> ABSTRACT  :  Single image deraining (SID) in real scenarios attracts increasing attention in recent years. Due to the difficulty in obtaining real-world rainy/clean image pairs, previous real datasets suffer from low-resolution images, homogeneous rain streaks, limited background variation, and even misalignment of image pairs, resulting in incomprehensive evaluation of SID methods. To address these issues, we establish a new high-quality dataset named RealRain-1k, consisting of $1,120$ high-resolution paired clean and rainy images with low- and high-density rain streaks, respectively. Images in RealRain-1k are automatically generated from a large number of real-world rainy video clips through a simple yet effective rain density-controllable filtering method, and have good properties of high image resolution, background diversity, rain streaks variety, and strict spatial alignment. RealRain-1k also provides abundant rain streak layers as a byproduct, enabling us to build a large-scale synthetic dataset named SynRain-13k by pasting the rain streak layers on abundant natural images. Based on them and existing datasets, we benchmark more than 10 representative SID methods on three tracks: (1) fully supervised learning on RealRain-1k, (2) domain generalization to real datasets, and (3) syn-to-real transfer learning. The experimental results (1) show the difference of representative methods in image **restoration** performance and model complexity, (2) validate the significance of the proposed datasets for model generalization, and (3) provide useful insights on the superiority of learning from diverse domains and shed lights on the future research on real-world SID. The datasets will be released at https://github.com/hiker-lw/RealRain-1k  
### A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal. (arXiv:2206.05520v1 [cs.CV])
- Authors : Renwei Yang, YiKe Liu
- Link : [http://arxiv.org/abs/2206.05520](http://arxiv.org/abs/2206.05520)
> ABSTRACT  :  There are several previous methods based on neural network can have great performance in denoising salt and pepper noise. However, those methods are based on a hypothesis that the value of salt and pepper noise is exactly 0 and 255. It is not true in the real world. The result of those methods deviate sharply when the value is different from 0 and 255. To overcome this weakness, our method aims at designing a convolutional neural network to detect the noise pixels in a wider range of value and then a filter is used to modify pixel value to 0, which is beneficial for further filtering. Additionally, another convolutional neural network is used to conduct the denoising and **restoration** work.  
### Efficiency Comparison of AI classification algorithms for Image Detection and Recognition in **Real-time**. (arXiv:2206.05842v1 [cs.CV])
- Authors : Musarrat Saberin, Rejwan Bin, Amer Kareem
- Link : [http://arxiv.org/abs/2206.05842](http://arxiv.org/abs/2206.05842)
> ABSTRACT  :  Face detection and identification is the most difficult and often used task in Artificial Intelligence systems. The goal of this study is to present and compare the results of several face detection and recognition algorithms used in the system. This system begins with a training image of a human, then continues on to the test image, identifying the face, comparing it to the trained face, and finally classifying it using OpenCV classifiers. This research will discuss the most effective and successful tactics used in the system, which are implemented using Python, OpenCV, and Matplotlib. It may also be used in locations with CCTV, such as public spaces, shopping malls, and ATM booths.  
### Salient Object Detection via Integrity Learning. (arXiv:2101.07663v7 [cs.CV] UPDATED)
- Authors : Mingchen Zhuge, Ping Fan, Nian Liu, Dingwen Zhang, Dong Xu, Ling Shao
- Link : [http://arxiv.org/abs/2101.07663](http://arxiv.org/abs/2101.07663)
> ABSTRACT  :  Although current salient object detection (SOD) works have achieved significant progress, they are limited when it comes to the integrity of the predicted salient regions. We define the concept of integrity at both a micro and macro level. Specifically, at the micro level, the model should highlight all parts that belong to a certain salient object. Meanwhile, at the macro level, the model needs to discover all salient objects in a given image. To facilitate integrity learning for SOD, we design a novel Integrity Cognition Network (ICON), which explores three important components for learning strong integrity features. 1) Unlike existing models, which focus more on feature discriminability, we introduce a diverse feature aggregation (DFA) component to aggregate features with various receptive fields (i.e., kernel shape and context) and increase feature diversity. Such diversity is the foundation for mining the integral salient objects. 2) Based on the DFA features, we introduce an integrity channel **enhancement** (ICE) component with the goal of enhancing feature channels that highlight the integral salient objects, while suppressing the other distracting ones. 3) After extracting the enhanced features, the part-whole verification (PWV) method is employed to determine whether the part and whole object features have strong agreement. Such part-whole agreements can further improve the micro-level integrity for each salient object. To demonstrate the effectiveness of our ICON, comprehensive experiments are conducted on seven challenging benchmarks. Our ICON outperforms the baseline methods in terms of a wide range of metrics. Notably, our ICON achieves about 10% relative improvement over the previous best model in terms of average false negative ratio (FNR), on six datasets. Codes and results are available at: https://github.com/mczhuge/ICON.  
### Content-aware Directed Propagation Network with Pixel Adaptive Kernel Attention. (arXiv:2107.13144v2 [cs.CV] UPDATED)
- Authors : Cheol Sagong, Jae Yeo, Won Jung, Jea Ko
- Link : [http://arxiv.org/abs/2107.13144](http://arxiv.org/abs/2107.13144)
> ABSTRACT  :  Convolutional neural networks (CNNs) have been not only widespread but also achieved noticeable results on numerous applications including image classification, **restoration**, and generation. Although the weight-sharing property of convolutions makes them widely adopted in various tasks, its content-agnostic characteristic can also be considered a major drawback. To solve this problem, in this paper, we propose a novel operation, called pixel adaptive kernel attention (PAKA). PAKA provides directivity to the filter weights by multiplying spatially varying attention from learnable features. The proposed method infers pixel-adaptive attention maps along the channel and spatial directions separately to address the decomposed model with fewer parameters. Our method is trainable in an end-to-end manner and applicable to any CNN-based models. In addition, we propose an improved information aggregation module with PAKA, called the hierarchical PAKA module (HPM). We demonstrate the superiority of our HPM by presenting state-of-the-art performance on semantic segmentation compared to the conventional information aggregation modules. We validate the proposed method through additional ablation studies and visualizing the effect of PAKA providing directivity to the weights of convolutions. We also show the generalizability of the proposed method by applying it to multi-modal tasks especially color-guided depth map super-resolution.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v6 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
### MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v4 [eess.IV] UPDATED)
- Authors : Xinyi Ying, Yingqian Wang, Longguang Wang, Weidong Sheng, Li Liu, Zaiping Lin, Shilin Zhou
- Link : [http://arxiv.org/abs/2201.01014](http://arxiv.org/abs/2201.01014)
> ABSTRACT  :  Infrared small target super-resolution (SR) aims to recover reliable and detailed high-resolution image with highcontrast targets from its low-resolution counterparts. Since the infrared small target lacks color and fine structure information, it is significant to exploit the supplementary information among sequence images to enhance the target. In this paper, we propose the first infrared small target SR method named local motion and contrast prior driven deep network (MoCoPnet) to integrate the domain knowledge of infrared small target into deep network, which can mitigate the intrinsic feature scarcity of infrared small targets. Specifically, motivated by the local motion prior in the spatio-temporal dimension, we propose a local spatiotemporal attention module to perform implicit frame alignment and incorporate the local spatio-temporal information to enhance the local features (especially for small targets). Motivated by the local contrast prior in the spatial dimension, we propose a central difference residual group to incorporate the central difference convolution into the feature extraction backbone, which can achieve center-oriented gradient-aware feature extraction to further improve the target contrast. Extensive experiments have demonstrated that our method can recover accurate spatial dependency and improve the target contrast. Comparative results show that MoCoPnet can outperform the state-of-the-art video SR and single image SR methods in terms of both SR performance and target **enhancement**. Based on the SR results, we further investigate the influence of SR on infrared small target detection and the experimental results demonstrate that MoCoPnet promotes the detection performance. The code is available at https://github.com/XinyiYing/MoCoPnet.  
### COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
- Authors : Emilien Dupont, Hrushikesh Loya, Milad Alizadeh, Adam Goli, Yee Whye, Arnaud Doucet
- Link : [http://arxiv.org/abs/2201.12904](http://arxiv.org/abs/2201.12904)
> ABSTRACT  :  Neural compression algorithms are typically based on autoencoders that require specialized encoder and decoder architectures for different data modalities. In this paper, we propose COIN++, a neural compression framework that seamlessly handles a wide range of data modalities. Our approach is based on converting data to **implicit neural representation**s, i.e. neural functions that map coordinates (such as pixel locations) to features (such as RGB values). Then, instead of storing the weights of the **implicit neural representation** directly, we store modulations applied to a meta-learned base network as a compressed code for the data. We further quantize and entropy code these modulations, leading to large compression gains while reducing encoding time by two orders of magnitude compared to baselines. We empirically demonstrate the effectiveness of our method by compressing various data modalities, from images and audio to medical and climate data.  
### Rotation-Equivariant Conditional Spherical Neural Fields for Learning a Natural Illumination Prior. (arXiv:2206.03858v2 [cs.CV] UPDATED)
- Authors : Bernhard Egger
- Link : [http://arxiv.org/abs/2206.03858](http://arxiv.org/abs/2206.03858)
> ABSTRACT  :  Inverse rendering is an ill-posed problem. Previous work has sought to resolve this by focussing on priors for object or scene shape or appearance. In this work, we instead focus on a prior for natural illuminations. Current methods rely on spherical harmonic lighting or other generic representations and, at best, a simplistic prior on the parameters. We propose a conditional neural field representation based on a variational auto-decoder with a SIREN network and, extending Vector Neurons, build equivariance directly into the network. Using this we develop a rotation-equivariant, **high dynamic range** (**HDR**) neural illumination model that is compact and able to express complex, high-frequency features of natural environment maps. Training our model on a curated dataset of 1.6K **HDR** environment maps of natural scenes, we compare it against traditional representations, demonstrate its applicability for an inverse rendering task and show environment map completion from partial observations. A PyTorch implementation, our dataset and trained models can be found at jadgardner.github.io/RENI.  
### RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
- Authors : Qing Lu, Xiaowei Xu, Shunjie Dong, Cong Hao, Lei Yang, Cheng Zhuo, Yiyu Shi
- Link : [http://arxiv.org/abs/2206.04682](http://arxiv.org/abs/2206.04682)
> ABSTRACT  :  Accurately segmenting temporal frames of cine magnetic resonance imaging (MRI) is a crucial step in various real-time MRI guided cardiac interventions. To achieve fast and accurate visual assistance, there are strict requirements on the maximum latency and minimum throughput of the segmentation framework. State-of-the-art neural networks on this task are mostly hand-crafted to satisfy these constraints while achieving high accuracy. On the other hand, while existing literature have demonstrated the power of neural architecture search (NAS) in automatically identifying the best neural architectures for various medical applications, they are mostly guided by accuracy, sometimes with computation complexity, and the importance of real-time constraints are overlooked. A major challenge is that such constraints are non-differentiable and are thus not compatible with the widely used differentiable NAS frameworks. In this paper, we present a strategy that directly handles real-time constraints in a differentiable NAS framework named RT-DNAS. Experiments on extended 2017 MICCAI ACDC dataset show that compared with state-of-the-art manually and automatically designed architectures, RT-DNAS is able to identify ones with better accuracy while satisfying the real-time constraints.  
## eess.IV
---
### Luminance-Guided Chrominance Image **Enhancement** for HEVC Intra Coding. (arXiv:2206.05432v1 [cs.CV])
- Authors : Hewei Liu, Renwei Yang, Shuyuan Zhu, Xing Wen, Bing Zeng
- Link : [http://arxiv.org/abs/2206.05432](http://arxiv.org/abs/2206.05432)
> ABSTRACT  :  In this paper, we propose a luminance-guided chrominance image **enhancement** convolutional neural network for HEVC intra coding. Specifically, we firstly develop a gated recursive asymmetric-convolution block to restore each degraded chrominance image, which generates an intermediate output. Then, guided by the luminance image, the quality of this intermediate output is further improved, which finally produces the high-quality chrominance image. When our proposed method is adopted in the compression of color images with HEVC intra coding, it achieves 28.96% and 16.74% BD-rate gains over HEVC for the U and V images, respectively, which accordingly demonstrate its superiority.  
### Robust full-pose-parameter estimation for the LED array in Fourier ptychographic microscopy. (arXiv:2206.05451v1 [physics.optics])
- Authors : Chuanjian Zheng, Shaohui Zhang, Delong Yang, Guocheng Zhou, Yao Hu, Qun Hao
- Link : [http://arxiv.org/abs/2206.05451](http://arxiv.org/abs/2206.05451)
> ABSTRACT  :  Fourier ptychographic microscopy (FPM) can achieve quantitative phase imaging with a large space-bandwidth product by synthesizing a set of low-resolution intensity images captured under angularly varying illuminations. Determining accurate illumination angles is critical because the consistency between actual systematic parameters and those used in the recovery algorithm is essential for high-quality imaging. This paper presents a full-pose-parameter and physics-based method for calibrating illumination angles. Using a physics-based model constructed with general knowledge of the employed microscope and the brightfield-to-**dark**field boundaries inside captured images, we can solve for the full-pose parameters of misplaced LED array, which consist of the distance between the sample and the LED array, two orthogonal lateral shifts, one in-plane rotation angle, and two tilt angles, to correct illumination angles precisely. The feasibility and effectiveness of the proposed method for recovering random or remarkable pose parameters have been demonstrated by both qualitative and quantitative experiments. Due to the completeness of the pose parameters, the clarity of the physical model, and the high robustness for arbitrary misalignments, our method can significantly facilitate the design, implementation, and application of concise and robust FPM platforms.  
### A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal. (arXiv:2206.05520v1 [cs.CV])
- Authors : Renwei Yang, YiKe Liu
- Link : [http://arxiv.org/abs/2206.05520](http://arxiv.org/abs/2206.05520)
> ABSTRACT  :  There are several previous methods based on neural network can have great performance in denoising salt and pepper noise. However, those methods are based on a hypothesis that the value of salt and pepper noise is exactly 0 and 255. It is not true in the real world. The result of those methods deviate sharply when the value is different from 0 and 255. To overcome this weakness, our method aims at designing a convolutional neural network to detect the noise pixels in a wider range of value and then a filter is used to modify pixel value to 0, which is beneficial for further filtering. Additionally, another convolutional neural network is used to conduct the denoising and **restoration** work.  
### One Size Fits All: Hypernetwork for Tunable Image **Restoration**. (arXiv:2206.05970v1 [cs.CV])
- Authors : Shai Aharon, Gil Ben
- Link : [http://arxiv.org/abs/2206.05970](http://arxiv.org/abs/2206.05970)
> ABSTRACT  :  We introduce a novel approach for tunable image **restoration** that achieves the accuracy of multiple models, each optimized for a different level of degradation, with exactly the same number of parameters as a single model. Our model can be optimized to restore as many degradation levels as required with a constant number of parameters and for various image **restoration** tasks. Experiments on real-world datasets show that our approach achieves state-of-the art results in denoising, DeJPEG and super-resolution with respect to existing tunable models, allowing smoother and more accurate fitting over a wider range of degradation levels.  
### Annular Computational Imaging: Capture Clear Panoramic Images through Simple Lens. (arXiv:2206.06070v1 [eess.IV])
- Authors : Qi Jiang, Hao Shi, Lei Sun, Shaohua Gao, Kailun Yang, Kaiwei Wang
- Link : [http://arxiv.org/abs/2206.06070](http://arxiv.org/abs/2206.06070)
> ABSTRACT  :  Panoramic Annular Lens (PAL), composed of few lenses, has great potential in panoramic surrounding sensing tasks for mobile and wearable devices because of its tiny size and large Field of View (FoV). However, the image quality of tiny-volume PAL confines to optical limit due to the lack of lenses for aberration correction. In this paper, we propose an Annular Computational Imaging (ACI) framework to break the optical limit of light-weight PAL design. To facilitate learning-based image **restoration**, we introduce a wave-based simulation pipeline for panoramic imaging and tackle the synthetic-to-real gap through multiple data distributions. The proposed pipeline can be easily adapted to any PAL with design parameters and is suitable for loose-tolerance designs. Furthermore, we design the Physics Informed Image **Restoration** Network (PI2RNet), considering the physical priors of panoramic imaging and physics-informed learning. At the dataset level, we create the DIVPano dataset and the extensive experiments on it illustrate that our proposed network sets the new state of the art in the panoramic image **restoration** under spatially-variant degradation. In addition, the evaluation of the proposed ACI on a simple PAL with only 3 spherical lenses reveals the delicate balance between high-quality panoramic imaging and compact design. To the best of our knowledge, we are the first to explore Computational Imaging (CI) in PAL. Code and datasets will be made publicly available at https://github.com/zju-jiangqi/ACI-PI2RNet.  
### AR-**NeRF**: Unsupervised Learning of Depth and Defocus Effects from Natural Images with Aperture Rendering Neural Radiance Fields. (arXiv:2206.06100v1 [cs.CV])
- Authors : Takuhiro Kaneko
- Link : [http://arxiv.org/abs/2206.06100](http://arxiv.org/abs/2206.06100)
> ABSTRACT  :  Fully unsupervised 3D representation learning has gained attention owing to its advantages in data collection. A successful approach involves a viewpoint-aware approach that learns an image distribution based on generative models (e.g., generative adversarial networks (GANs)) while generating various view images based on 3D-aware models (e.g., neural radiance fields (**NeRF**s)). However, they require images with various views for training, and consequently, their application to datasets with few or limited viewpoints remains a challenge. As a complementary approach, an aperture rendering GAN (AR-GAN) that employs a defocus cue was proposed. However, an AR-GAN is a CNN-based model and represents a defocus independently from a viewpoint change despite its high correlation, which is one of the reasons for its performance. As an alternative to an AR-GAN, we propose an aperture rendering **NeRF** (AR-**NeRF**), which can utilize viewpoint and defocus cues in a unified manner by representing both factors in a common ray-tracing framework. Moreover, to learn defocus-aware and defocus-independent representations in a disentangled manner, we propose aperture randomized training, for which we learn to generate images while randomizing the aperture size and latent codes independently. During our experiments, we applied AR-**NeRF** to various natural image datasets, including flower, bird, and face images, the results of which demonstrate the utility of AR-**NeRF** for unsupervised learning of the depth and defocus effects.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v6 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
### **Exposure**-Referred Signal-to-Noise Ratio for Digital Image Sensors. (arXiv:2112.05817v2 [eess.IV] UPDATED)
- Authors : Abhiram Gnanasambandam
- Link : [http://arxiv.org/abs/2112.05817](http://arxiv.org/abs/2112.05817)
> ABSTRACT  :  The signal-to-noise ratio (SNR) is a fundamental tool to measure the performance of an image sensor. However, confusions sometimes arise between the two types of SNRs. The first one is the output-referred SNR which measures the ratio between the signal and the noise seen at the sensor's output. This SNR is easy to compute, and it is linear in the log-log scale for most image sensors. The second SNR is the **exposure**-referred SNR, also known as the input-referred SNR. This SNR considers the noise at the input by including a derivative term to the output-referred SNR. The two SNRs have similar behaviors for sensors with a large full-well capacity. However, for sensors with a small full-well capacity, the **exposure**-referred SNR can capture some behaviors that the output-referred SNR cannot.    While the **exposure**-referred SNR has been known and used by the industry for a long time, a theoretically rigorous derivation from a signal processing perspective is lacking. In particular, while various equations can be found in different sources of the literature, there is currently no paper that attempts to assemble, derive, and organize these equations in one place. This paper aims to fill the gap by answering four questions: (1) How is the **exposure**-referred SNR derived from first principles? (2) Is the output-referred SNR a special case of the **exposure**-referred SNR, or are they completely different? (3) How to compute the SNR efficiently? (4) What utilities can the SNR bring to solving imaging tasks? New theoretical results are derived for image sensors of any bit-depth and full-well capacity.  
### MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v4 [eess.IV] UPDATED)
- Authors : Xinyi Ying, Yingqian Wang, Longguang Wang, Weidong Sheng, Li Liu, Zaiping Lin, Shilin Zhou
- Link : [http://arxiv.org/abs/2201.01014](http://arxiv.org/abs/2201.01014)
> ABSTRACT  :  Infrared small target super-resolution (SR) aims to recover reliable and detailed high-resolution image with highcontrast targets from its low-resolution counterparts. Since the infrared small target lacks color and fine structure information, it is significant to exploit the supplementary information among sequence images to enhance the target. In this paper, we propose the first infrared small target SR method named local motion and contrast prior driven deep network (MoCoPnet) to integrate the domain knowledge of infrared small target into deep network, which can mitigate the intrinsic feature scarcity of infrared small targets. Specifically, motivated by the local motion prior in the spatio-temporal dimension, we propose a local spatiotemporal attention module to perform implicit frame alignment and incorporate the local spatio-temporal information to enhance the local features (especially for small targets). Motivated by the local contrast prior in the spatial dimension, we propose a central difference residual group to incorporate the central difference convolution into the feature extraction backbone, which can achieve center-oriented gradient-aware feature extraction to further improve the target contrast. Extensive experiments have demonstrated that our method can recover accurate spatial dependency and improve the target contrast. Comparative results show that MoCoPnet can outperform the state-of-the-art video SR and single image SR methods in terms of both SR performance and target **enhancement**. Based on the SR results, we further investigate the influence of SR on infrared small target detection and the experimental results demonstrate that MoCoPnet promotes the detection performance. The code is available at https://github.com/XinyiYing/MoCoPnet.  
### COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
- Authors : Emilien Dupont, Hrushikesh Loya, Milad Alizadeh, Adam Goli, Yee Whye, Arnaud Doucet
- Link : [http://arxiv.org/abs/2201.12904](http://arxiv.org/abs/2201.12904)
> ABSTRACT  :  Neural compression algorithms are typically based on autoencoders that require specialized encoder and decoder architectures for different data modalities. In this paper, we propose COIN++, a neural compression framework that seamlessly handles a wide range of data modalities. Our approach is based on converting data to **implicit neural representation**s, i.e. neural functions that map coordinates (such as pixel locations) to features (such as RGB values). Then, instead of storing the weights of the **implicit neural representation** directly, we store modulations applied to a meta-learned base network as a compressed code for the data. We further quantize and entropy code these modulations, leading to large compression gains while reducing encoding time by two orders of magnitude compared to baselines. We empirically demonstrate the effectiveness of our method by compressing various data modalities, from images and audio to medical and climate data.  
### RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
- Authors : Qing Lu, Xiaowei Xu, Shunjie Dong, Cong Hao, Lei Yang, Cheng Zhuo, Yiyu Shi
- Link : [http://arxiv.org/abs/2206.04682](http://arxiv.org/abs/2206.04682)
> ABSTRACT  :  Accurately segmenting temporal frames of cine magnetic resonance imaging (MRI) is a crucial step in various real-time MRI guided cardiac interventions. To achieve fast and accurate visual assistance, there are strict requirements on the maximum latency and minimum throughput of the segmentation framework. State-of-the-art neural networks on this task are mostly hand-crafted to satisfy these constraints while achieving high accuracy. On the other hand, while existing literature have demonstrated the power of neural architecture search (NAS) in automatically identifying the best neural architectures for various medical applications, they are mostly guided by accuracy, sometimes with computation complexity, and the importance of real-time constraints are overlooked. A major challenge is that such constraints are non-differentiable and are thus not compatible with the widely used differentiable NAS frameworks. In this paper, we present a strategy that directly handles real-time constraints in a differentiable NAS framework named RT-DNAS. Experiments on extended 2017 MICCAI ACDC dataset show that compared with state-of-the-art manually and automatically designed architectures, RT-DNAS is able to identify ones with better accuracy while satisfying the real-time constraints.  
## cs.LG
---
### **Bilateral** Dependency Optimization: Defending Against Model-inversion Attacks. (arXiv:2206.05483v1 [cs.LG])
- Authors : Xiong Peng, Feng Liu, Jingfen Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han
- Link : [http://arxiv.org/abs/2206.05483](http://arxiv.org/abs/2206.05483)
> ABSTRACT  :  Through using only a well-trained classifier, model-inversion (MI) attacks can recover the data used for training the classifier, leading to the privacy leakage of the training data. To defend against MI attacks, previous work utilizes a unilateral dependency optimization strategy, i.e., minimizing the dependency between inputs (i.e., features) and outputs (i.e., labels) during training the classifier. However, such a minimization process conflicts with minimizing the supervised loss that aims to maximize the dependency between inputs and outputs, causing an explicit trade-off between model robustness against MI attacks and model utility on classification tasks. In this paper, we aim to minimize the dependency between the latent representations and the inputs while maximizing the dependency between latent representations and the outputs, named a **bilateral** dependency optimization (BiDO) strategy. In particular, we use the dependency constraints as a universally applicable regularizer in addition to commonly used losses for deep neural networks (e.g., cross-entropy), which can be instantiated with appropriate dependency criteria according to different tasks. To verify the efficacy of our strategy, we propose two implementations of BiDO, by using two different dependency measures: BiDO with constrained covariance (BiDO-COCO) and BiDO with Hilbert-Schmidt Independence Criterion (BiDO-HSIC). Experiments show that BiDO achieves the state-of-the-art defense performance for a variety of datasets, classifiers, and MI attacks while suffering a minor classification-accuracy drop compared to the well-trained classifier with no defense, which lights up a novel road to defend against MI attacks.  
### A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games. (arXiv:2206.05825v1 [cs.LG])
- Authors : Samuel Sokota, Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas, Noam Brown, Christian Kroer
- Link : [http://arxiv.org/abs/2206.05825](http://arxiv.org/abs/2206.05825)
> ABSTRACT  :  Algorithms designed for single-agent reinforcement learning (RL) generally fail to converge to equilibria in two-player zero-sum (2p0s) games. Conversely, game-theoretic algorithms for approximating Nash and quantal response equilibria (QREs) in 2p0s games are not typically competitive for RL and can be difficult to scale. As a result, algorithms for these two cases are generally developed and evaluated separately. In this work, we show that a single algorithm -- a simple extension to mirror descent with proximal regularization that we call magnetic mirror descent (MMD) -- can produce strong results in both settings, despite their fundamental differences. From a theoretical standpoint, we prove that MMD converges linearly to QREs in extensive-form games -- this is the first time linear convergence has been proven for a first order solver. Moreover, applied as a tabular Nash equilibrium solver via self-play, we show empirically that MMD produces results competitive with CFR in both normal-form and extensive-form games with full feedback (this is the first time that a standard RL algorithm has done so) and also that MMD empirically converges in black-box feedback settings. Furthermore, for single-agent deep RL, on a small collection of Atari and Mujoco games, we show that MMD can produce results competitive with those of PPO. Lastly, for multi-agent deep RL, we show MMD can outperform NFSP in 3x3 Abrupt **Dark** Hex.  
### Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms. (arXiv:2106.02979v2 [stat.ML] UPDATED)
- Authors : Qin Ding, Yue Kang, Wei Liu, Jui Hsieh, James Sharpnack
- Link : [http://arxiv.org/abs/2106.02979](http://arxiv.org/abs/2106.02979)
> ABSTRACT  :  The stochastic contextual bandit problem, which models the trade-off between exploration and exploitation, has many real applications, including recommender systems, online advertising and clinical trials. As many other machine learning algorithms, contextual bandit algorithms often have one or more hyper-parameters. As an example, in most optimal stochastic contextual bandit algorithms, there is an unknown exploration parameter which controls the trade-off between exploration and exploitation. A proper choice of the hyper-parameters is essential for contextual bandit algorithms to perform well. However, it is infeasible to use offline tuning methods to select hyper-parameters in contextual bandit environment since there is no pre-collected dataset and the decisions have to be made in **real time**. To tackle this problem, we first propose a two-layer bandit structure for auto tuning the exploration parameter and further generalize it to the Syndicated Bandits framework which can learn multiple hyper-parameters dynamically in contextual bandit environment. We derive the regret bounds of our proposed Syndicated Bandits framework and show it can avoid its regret dependent exponentially in the number of hyper-parameters to be tuned. Moreover, it achieves optimal regret bounds under certain scenarios. Syndicated Bandits framework is general enough to handle the tuning tasks in many popular contextual bandit algorithms, such as LinUCB, LinTS, UCB-GLM, etc. Experiments on both synthetic and real datasets validate the effectiveness of our proposed framework.  
### COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
- Authors : Emilien Dupont, Hrushikesh Loya, Milad Alizadeh, Adam Goli, Yee Whye, Arnaud Doucet
- Link : [http://arxiv.org/abs/2201.12904](http://arxiv.org/abs/2201.12904)
> ABSTRACT  :  Neural compression algorithms are typically based on autoencoders that require specialized encoder and decoder architectures for different data modalities. In this paper, we propose COIN++, a neural compression framework that seamlessly handles a wide range of data modalities. Our approach is based on converting data to **implicit neural representation**s, i.e. neural functions that map coordinates (such as pixel locations) to features (such as RGB values). Then, instead of storing the weights of the **implicit neural representation** directly, we store modulations applied to a meta-learned base network as a compressed code for the data. We further quantize and entropy code these modulations, leading to large compression gains while reducing encoding time by two orders of magnitude compared to baselines. We empirically demonstrate the effectiveness of our method by compressing various data modalities, from images and audio to medical and climate data.  
### RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
- Authors : Qing Lu, Xiaowei Xu, Shunjie Dong, Cong Hao, Lei Yang, Cheng Zhuo, Yiyu Shi
- Link : [http://arxiv.org/abs/2206.04682](http://arxiv.org/abs/2206.04682)
> ABSTRACT  :  Accurately segmenting temporal frames of cine magnetic resonance imaging (MRI) is a crucial step in various real-time MRI guided cardiac interventions. To achieve fast and accurate visual assistance, there are strict requirements on the maximum latency and minimum throughput of the segmentation framework. State-of-the-art neural networks on this task are mostly hand-crafted to satisfy these constraints while achieving high accuracy. On the other hand, while existing literature have demonstrated the power of neural architecture search (NAS) in automatically identifying the best neural architectures for various medical applications, they are mostly guided by accuracy, sometimes with computation complexity, and the importance of real-time constraints are overlooked. A major challenge is that such constraints are non-differentiable and are thus not compatible with the widely used differentiable NAS frameworks. In this paper, we present a strategy that directly handles real-time constraints in a differentiable NAS framework named RT-DNAS. Experiments on extended 2017 MICCAI ACDC dataset show that compared with state-of-the-art manually and automatically designed architectures, RT-DNAS is able to identify ones with better accuracy while satisfying the real-time constraints.  
## cs.AI
---
### A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games. (arXiv:2206.05825v1 [cs.LG])
- Authors : Samuel Sokota, Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas, Noam Brown, Christian Kroer
- Link : [http://arxiv.org/abs/2206.05825](http://arxiv.org/abs/2206.05825)
> ABSTRACT  :  Algorithms designed for single-agent reinforcement learning (RL) generally fail to converge to equilibria in two-player zero-sum (2p0s) games. Conversely, game-theoretic algorithms for approximating Nash and quantal response equilibria (QREs) in 2p0s games are not typically competitive for RL and can be difficult to scale. As a result, algorithms for these two cases are generally developed and evaluated separately. In this work, we show that a single algorithm -- a simple extension to mirror descent with proximal regularization that we call magnetic mirror descent (MMD) -- can produce strong results in both settings, despite their fundamental differences. From a theoretical standpoint, we prove that MMD converges linearly to QREs in extensive-form games -- this is the first time linear convergence has been proven for a first order solver. Moreover, applied as a tabular Nash equilibrium solver via self-play, we show empirically that MMD produces results competitive with CFR in both normal-form and extensive-form games with full feedback (this is the first time that a standard RL algorithm has done so) and also that MMD empirically converges in black-box feedback settings. Furthermore, for single-agent deep RL, on a small collection of Atari and Mujoco games, we show that MMD can produce results competitive with those of PPO. Lastly, for multi-agent deep RL, we show MMD can outperform NFSP in 3x3 Abrupt **Dark** Hex.  
### Efficiency Comparison of AI classification algorithms for Image Detection and Recognition in **Real-time**. (arXiv:2206.05842v1 [cs.CV])
- Authors : Musarrat Saberin, Rejwan Bin, Amer Kareem
- Link : [http://arxiv.org/abs/2206.05842](http://arxiv.org/abs/2206.05842)
> ABSTRACT  :  Face detection and identification is the most difficult and often used task in Artificial Intelligence systems. The goal of this study is to present and compare the results of several face detection and recognition algorithms used in the system. This system begins with a training image of a human, then continues on to the test image, identifying the face, comparing it to the trained face, and finally classifying it using OpenCV classifiers. This research will discuss the most effective and successful tactics used in the system, which are implemented using Python, OpenCV, and Matplotlib. It may also be used in locations with CCTV, such as public spaces, shopping malls, and ATM booths.  
### Content-aware Directed Propagation Network with Pixel Adaptive Kernel Attention. (arXiv:2107.13144v2 [cs.CV] UPDATED)
- Authors : Cheol Sagong, Jae Yeo, Won Jung, Jea Ko
- Link : [http://arxiv.org/abs/2107.13144](http://arxiv.org/abs/2107.13144)
> ABSTRACT  :  Convolutional neural networks (CNNs) have been not only widespread but also achieved noticeable results on numerous applications including image classification, **restoration**, and generation. Although the weight-sharing property of convolutions makes them widely adopted in various tasks, its content-agnostic characteristic can also be considered a major drawback. To solve this problem, in this paper, we propose a novel operation, called pixel adaptive kernel attention (PAKA). PAKA provides directivity to the filter weights by multiplying spatially varying attention from learnable features. The proposed method infers pixel-adaptive attention maps along the channel and spatial directions separately to address the decomposed model with fewer parameters. Our method is trainable in an end-to-end manner and applicable to any CNN-based models. In addition, we propose an improved information aggregation module with PAKA, called the hierarchical PAKA module (HPM). We demonstrate the superiority of our HPM by presenting state-of-the-art performance on semantic segmentation compared to the conventional information aggregation modules. We validate the proposed method through additional ablation studies and visualizing the effect of PAKA providing directivity to the weights of convolutions. We also show the generalizability of the proposed method by applying it to multi-modal tasks especially color-guided depth map super-resolution.  
### Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v4 [cs.CR] UPDATED)
- Authors : Mikhail Kazdagli, Mohit Tiwari, Akshat Kumar
- Link : [http://arxiv.org/abs/2205.01240](http://arxiv.org/abs/2205.01240)
> ABSTRACT  :  Modern software systems rely on mining insights from business sensitive data stored in public clouds. A data breach usually incurs significant (monetary) loss for a commercial organization. Conceptually, cloud security heavily relies on Identity Access Management (IAM) policies that IT admins need to properly configure and periodically update. Security negligence and human errors often lead to misconfiguring IAM policies which may open a backdoor for attackers. To address these challenges, first, we develop a novel framework that encodes generating optimal IAM policies using constraint programming (CP). We identify reducing **dark** permissions of cloud users as an optimality criterion, which intuitively implies minimizing unnecessary datastore access permissions. Second, to make IAM policies interpretable, we use graph representation learning applied to historical access patterns of users to augment our CP model with similarity constraints: similar users should be grouped together and share common IAM policies. Third, we describe multiple attack models and show that our optimized IAM policies significantly reduce the impact of security attacks using real data from 8 commercial organizations, and synthetic instances.  
# Paper List
---
## cs.CV
---
**143** new papers in cs.CV:-) 
1. Spatial-temporal Concept based Explanation of 3D ConvNets. (arXiv:2206.05275v1 [cs.CV])
2. Superresolution and Segmentation of OCT scans using Multi-Stage adversarial Guided Attention Training. (arXiv:2206.05277v1 [eess.IV])
3. Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality Registration of Cardiac SPECT and CT. (arXiv:2206.05278v1 [eess.IV])
4. PILC: Practical Image Lossless Compression with an End-to-end GPU Oriented Neural Framework. (arXiv:2206.05279v1 [eess.IV])
5. Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model. (arXiv:2206.05281v1 [cs.CV])
6. Learning to Estimate Shapley Values with Vision Transformers. (arXiv:2206.05282v1 [cs.CV])
7. Poissonian Blurred Image Deconvolution by Framelet based Local Minimal Prior. (arXiv:2206.05283v1 [eess.IV])
8. Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation. (arXiv:2206.05284v1 [eess.IV])
9. From Labels to Priors in Capsule Endoscopy: A Prior Guided Approach for Improving Generalization with Few Labels. (arXiv:2206.05288v1 [eess.IV])
10. Localized adversarial artifacts for compressed sensing MRI. (arXiv:2206.05289v1 [eess.IV])
11. ProActive: Self-Attentive Temporal Point Process Flows for Activity Sequences. (arXiv:2206.05291v1 [cs.CV])
12. EigenFairing: 3D Model Fairing using Image Coherence. (arXiv:2206.05309v1 [cs.CV])
13. Object Instance Identification in Dynamic Environments. (arXiv:2206.05319v1 [cs.CV])
14. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v1 [cs.LG])
15. Differentiable Rendering of Neural SDFs through Reparameterization. (arXiv:2206.05344v1 [cs.GR])
16. Object Detection, Recognition, Deep Learning, and the Universal Law of Generalization. (arXiv:2206.05365v1 [cs.LG])
17. Generalizable Neural Radiance Fields for Novel View Synthesis with Transformer. (arXiv:2206.05375v1 [cs.CV])
18. Fast building segmentation from satellite imagery and few local labels. (arXiv:2206.05377v1 [cs.CV])
19. A Benchmark for Compositional Visual Reasoning. (arXiv:2206.05379v1 [cs.CV])
20. Transformer-based Self-Supervised Fish Segmentation in Underwater Videos. (arXiv:2206.05390v1 [cs.CV])
21. Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey. (arXiv:2206.05394v1 [cs.CV])
22. E$^2$PN: Efficient SE(3)-Equivariant Point Network. (arXiv:2206.05398v1 [cs.CV])
23. High-Definition Map Generation Technologies For Autonomous Driving: A Review. (arXiv:2206.05400v1 [cs.RO])
24. VAC2: Visual Analysis of Combined Causality in Event Sequences. (arXiv:2206.05420v1 [cs.CV])
25. Access Control of Semantic Segmentation Models Using Encrypted Feature Maps. (arXiv:2206.05422v1 [cs.CV])
26. Precise Affordance Annotation for Egocentric Action Video Datasets. (arXiv:2206.05424v1 [cs.CV])
27. Learned reconstruction with convergence guarantees. (arXiv:2206.05431v1 [cs.CV])
28. Luminance-Guided Chrominance Image **Enhancement** for HEVC Intra Coding. (arXiv:2206.05432v1 [cs.CV])
29. Differentiable Projection from Optical Coherence Tomography B-Scan without Retinal Layer Segmentation Supervision. (arXiv:2206.05472v1 [eess.IV])
30. Kaggle Kinship Recognition Challenge: Introduction of Convolution-Free Model to boost conventional. (arXiv:2206.05488v1 [cs.CV])
31. An Evaluation of OCR on Egocentric Data. (arXiv:2206.05496v1 [cs.CV])
32. A Review of Causality for Learning Algorithms in Medical Image Analysis. (arXiv:2206.05498v1 [cs.CV])
33. Toward Real-world Single Image Deraining: A New Benchmark and Beyond. (arXiv:2206.05514v1 [cs.CV])
34. Deep Learning-Based MR Image Re-parameterization. (arXiv:2206.05516v1 [eess.IV])
35. A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal. (arXiv:2206.05520v1 [cs.CV])
36. A Simplified Un-Supervised Learning Based Approach for Ink Mismatch Detection in Handwritten Hyper-Spectral Document Images. (arXiv:2206.05539v1 [cs.CV])
37. Surround-View Cameras based Holistic Visual Perception for Automated Driving. (arXiv:2206.05542v1 [cs.CV])
38. A Unified Continuous Learning Framework for Multi-modal Knowledge Discovery and Pre-training. (arXiv:2206.05555v1 [cs.CL])
39. MammoDL: Mammographic Breast Density Estimation using Federated Learning. (arXiv:2206.05575v1 [eess.IV])
40. Machine learning approaches for COVID-19 detection from chest X-ray imaging: A Systematic Review. (arXiv:2206.05615v1 [eess.IV])
41. Federated Learning with Research Prototypes for Multi-Center MRI-based Detection of Prostate Cancer with Diverse Histopathology. (arXiv:2206.05617v1 [cs.CV])
42. Synthetic PET via Domain Translation of 3D MRI. (arXiv:2206.05618v1 [physics.med-ph])
43. Deep Learning Models for Automated Classification of Dog Emotional States from Facial Expressions. (arXiv:2206.05619v1 [cs.CV])
44. A Review on Plastic Artificial Neural Networks: Exploring the Intersection between Neural Architecture Search and Continual Learning. (arXiv:2206.05625v1 [cs.AI])
45. An Unsupervised Deep-Learning Method for Bone Age Assessment. (arXiv:2206.05641v1 [cs.CV])
46. A Fast Alternating Minimization Algorithm for Coded Aperture Snapshot Spectral Imaging Based on Sparsity and Deep Image Priors. (arXiv:2206.05647v1 [eess.IV])
47. Indirect-Instant Attention Optimization for Crowd Counting in Dense Scenes. (arXiv:2206.05648v1 [cs.CV])
48. TileGen: Tileable, Controllable Material Generation and Capture. (arXiv:2206.05649v1 [cs.GR])
49. Preprocessing Enhanced Image Compression for Machine Vision. (arXiv:2206.05650v1 [eess.IV])
50. STD-NET: Search of Image Steganalytic Deep-learning Architecture via Hierarchical Tensor Decomposition. (arXiv:2206.05651v1 [cs.CV])
51. APT-36K: A Large-scale Benchmark for Animal Pose Estimation and Tracking. (arXiv:2206.05683v1 [cs.CV])
52. DRNet: Decomposition and Reconstruction Network for Remote Physiological Measurement. (arXiv:2206.05687v1 [cs.HC])
53. PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model. (arXiv:2206.05695v1 [eess.IV])
54. DPCN++: Differentiable Phase Correlation Network for Versatile Pose Registration. (arXiv:2206.05707v1 [cs.CV])
55. Narrowing the Gap: Improved Detector Training with Noisy Location Annotations. (arXiv:2206.05708v1 [cs.CV])
56. Graph-based Spatial Transformer with Memory Replay for Multi-future Pedestrian Trajectory Prediction. (arXiv:2206.05712v1 [cs.CV])
57. Crowd Localization from Gaussian Mixture Scoped Knowledge and Scoped Teacher. (arXiv:2206.05717v1 [cs.CV])
58. Object Occlusion Of Adding New Category In Objection Detection. (arXiv:2206.05730v1 [cs.CV])
59. SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse views. (arXiv:2206.05737v1 [cs.CV])
60. Multimodal Fake News Detection with Adaptive Unimodal Representation Aggregation. (arXiv:2206.05741v1 [cs.CV])
61. Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation. (arXiv:2206.05751v1 [cs.LG])
62. SeATrans: Learning Segmentation-Assisted diagnosis model via Transforme. (arXiv:2206.05763v1 [cs.CV])
63. A Semantic Consistency Feature Alignment Object Detection Model Based on Mixed-Class Distribution Metrics. (arXiv:2206.05765v1 [cs.CV])
64. Revisiting Whole-Slide Image Pyramids for Cancer Prognosis via Dual-Stream Networks. (arXiv:2206.05782v1 [eess.IV])
65. Analysis of Branch Specialization and its Application in Image Decomposition. (arXiv:2206.05810v1 [cs.CV])
66. COLD Fusion: Calibrated and Ordinal Latent Distribution Fusion for Uncertainty-Aware Multimodal Emotion Recognition. (arXiv:2206.05833v1 [cs.CV])
67. GLIPv2: Unifying Localization and Vision-Language Understanding. (arXiv:2206.05836v1 [cs.CV])
68. NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape Representation. (arXiv:2206.05837v1 [cs.CV])
69. Efficiency Comparison of AI classification algorithms for Image Detection and Recognition in **Real-time**. (arXiv:2206.05842v1 [cs.CV])
70. FisheyeEX: Polar Outpainting for Extending the FoV of Fisheye Lens. (arXiv:2206.05844v1 [cs.CV])
71. InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness. (arXiv:2206.05846v1 [cs.CV])
72. Modeling Generalized Specialist Approach To Train Quality Resilient Snapshot Ensemble. (arXiv:2206.05853v1 [cs.CV])
73. A Directed-Evolution Method for Sparsification and Compression of Neural Networks with Application to Object Identification and Segmentation and considerations of optimal quantization using small number of bits. (arXiv:2206.05859v1 [cs.LG])
74. TC-SfM: Robust Track-Community-Based Structure-from-Motion. (arXiv:2206.05866v1 [cs.CV])
75. Quantification and Analysis of Layer-wise and Pixel-wise Information Discarding. (arXiv:1906.04109v2 [cs.LG] UPDATED)
76. Recognizing License Plates in Real-Time. (arXiv:1906.04376v5 [cs.CV] UPDATED)
77. Universal, transferable and targeted adversarial attacks. (arXiv:1908.11332v4 [cs.LG] UPDATED)
78. Detached Error Feedback for Distributed SGD with Random Sparsification. (arXiv:2004.05298v3 [cs.LG] UPDATED)
79. Image-Based Sorghum Head Counting When You Only Look Once. (arXiv:2009.11929v3 [cs.CV] UPDATED)
80. Reconstructing A Large Scale 3D Face Dataset for Deep 3D Face Identification. (arXiv:2010.08391v2 [cs.CV] UPDATED)
81. SPU-Net: Self-Supervised Point Cloud Upsampling by Coarse-to-Fine Reconstruction with Self-Projection Optimization. (arXiv:2012.04439v2 [cs.CV] UPDATED)
82. Salient Object Detection via Integrity Learning. (arXiv:2101.07663v7 [cs.CV] UPDATED)
83. Eliminate Deviation with Deviation for Data Augmentation and a General Multi-modal Data Learning Method. (arXiv:2101.08533v5 [cs.CV] UPDATED)
84. GANav: Efficient Terrain Segmentation for Robot Navigation in Unstructured Outdoor Environments. (arXiv:2103.04233v4 [cs.RO] UPDATED)
85. VGNMN: Video-grounded Neural Module Network to Video-Grounded Language Tasks. (arXiv:2104.07921v2 [cs.CV] UPDATED)
86. Regularized Deep Linear Discriminant Analysis. (arXiv:2105.07129v2 [cs.CV] UPDATED)
87. An Overview of Deep Learning Techniques for Epileptic Seizures Detection and Prediction Based on Neuroimaging Modalities: Methods, Challenges, and Future Works. (arXiv:2105.14278v2 [cs.LG] UPDATED)
88. Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v4 [eess.IV] UPDATED)
89. End-to-end Temporal Action Detection with Transformer. (arXiv:2106.10271v3 [cs.CV] UPDATED)
90. Bayesian Statistics Guided Label Refurbishment Mechanism: Mitigating Label Noise in Medical Image Classification. (arXiv:2106.12284v2 [cs.CV] UPDATED)
91. Imaging dynamics beneath turbid media via parallelized single-photon detection. (arXiv:2107.01422v4 [physics.optics] UPDATED)
92. MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis. (arXiv:2107.06149v3 [cs.CV] UPDATED)
93. Weighted Intersection over Union (wIoU): A New Evaluation Metric for Image Segmentation. (arXiv:2107.09858v2 [cs.CV] UPDATED)
94. Few Shots Are All You Need: A Progressive Few Shot Learning Approach for Low Resource Handwritten Text Recognition. (arXiv:2107.10064v3 [cs.CV] UPDATED)
95. Content-aware Directed Propagation Network with Pixel Adaptive Kernel Attention. (arXiv:2107.13144v2 [cs.CV] UPDATED)
96. Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting Spatio-Temporal Sparsity. (arXiv:2108.02297v5 [cs.AR] UPDATED)
97. Transfer Learning Gaussian Anomaly Detection by Fine-tuning Representations. (arXiv:2108.04116v2 [cs.CV] UPDATED)
98. A MIMO Radar-based Few-Shot Learning Approach for Human-ID. (arXiv:2110.08595v2 [eess.SP] UPDATED)
99. CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP. (arXiv:2110.11316v3 [cs.LG] UPDATED)
100. Robust Person Re-identification with Multi-Modal Joint Defence. (arXiv:2111.09571v3 [cs.CV] UPDATED)
101. XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For Convolutional Neural Networks. (arXiv:2111.10854v2 [cs.CV] UPDATED)
102. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v6 [cs.CV] UPDATED)
103. PSI: A Pedestrian Behavior Dataset for Socially Intelligent Autonomous Car. (arXiv:2112.02604v2 [cs.CV] UPDATED)
104. Self-Paced Deep Regression Forests with Consideration of Ranking Fairness. (arXiv:2112.06455v8 [cs.CV] UPDATED)
105. Looking Outside the Box to Ground Language in 3D Scenes. (arXiv:2112.08879v4 [cs.CV] UPDATED)
106. Multispectral image fusion by super pixel statistics. (arXiv:2112.11329v2 [cs.CV] UPDATED)
107. MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v4 [eess.IV] UPDATED)
108. NeuralMLS: Geometry-Aware Control Point Deformation. (arXiv:2201.01873v2 [cs.GR] UPDATED)
109. A Novel Mix-normalization Method for Generalizable Multi-source Person Re-identification. (arXiv:2201.09846v2 [cs.CV] UPDATED)
110. Self-Supervised Moving Vehicle Detection from Audio-Visual Cues. (arXiv:2201.12771v2 [cs.CV] UPDATED)
111. COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
112. Network-level Safety Metrics for Overall Traffic Safety Assessment: A Case Study. (arXiv:2201.13229v2 [cs.CV] UPDATED)
113. On-Sensor Binarized Fully Convolutional Neural Network with A Pixel Processor Array. (arXiv:2202.00836v2 [cs.CV] UPDATED)
114. Benchmarking and Analyzing Point Cloud Classification under Corruptions. (arXiv:2202.03377v2 [cs.CV] UPDATED)
115. Class Distance Weighted Cross-Entropy Loss for Ulcerative Colitis Severity Estimation. (arXiv:2202.05167v2 [eess.IV] UPDATED)
116. Opinions Vary? Diagnosis First!. (arXiv:2202.06505v2 [eess.IV] UPDATED)
117. Disentangling Light Fields for Super-Resolution and Disparity Estimation. (arXiv:2202.10603v2 [eess.IV] UPDATED)
118. Voice-Face Homogeneity Tells Deepfake. (arXiv:2203.02195v3 [cs.CV] UPDATED)
119. Learning Optical Flow, Depth, and Scene Flow without Real-World Labels. (arXiv:2203.15089v2 [cs.CV] UPDATED)
120. EResFD: Rediscovery of the Effectiveness of Standard Convolution for Lightweight Face Detection. (arXiv:2204.01209v2 [cs.CV] UPDATED)
121. "This is my unicorn, Fluffy": Personalizing frozen vision-language representations. (arXiv:2204.01694v2 [cs.CV] UPDATED)
122. Transient motion classification through turbid volumes via parallelized single-photon detection and deep contrastive embedding. (arXiv:2204.01733v2 [eess.IV] UPDATED)
123. Object Permanence Emerges in a Random Walk along Memory. (arXiv:2204.01784v2 [cs.CV] UPDATED)
124. Multi-Frame Self-Supervised Depth with Transformers. (arXiv:2204.07616v2 [cs.CV] UPDATED)
125. SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification. (arXiv:2204.09826v3 [cs.CV] UPDATED)
126. Visual Attention Emerges from Recurrent Sparse Reconstruction. (arXiv:2204.10962v3 [cs.CV] UPDATED)
127. RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning. (arXiv:2204.11167v2 [cs.CV] UPDATED)
128. Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework. (arXiv:2205.03860v4 [cs.CV] UPDATED)
129. Anatomy-aware Self-supervised Learning for Anomaly Detection in Chest Radiographs. (arXiv:2205.04282v2 [cs.CV] UPDATED)
130. Explainable Deep Learning Methods in Medical Imaging Diagnosis: A Survey. (arXiv:2205.04766v2 [eess.IV] UPDATED)
131. PSO-Convolutional Neural Networks with Heterogeneous Learning Rate. (arXiv:2205.10456v2 [cs.CV] UPDATED)
132. Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering. (arXiv:2205.11506v2 [cs.LG] UPDATED)
133. Towards Model Generalization for Monocular 3D Object Detection. (arXiv:2205.11664v4 [cs.CV] UPDATED)
134. Exploring Map-based Features for Efficient Attention-based Vehicle Motion Prediction. (arXiv:2205.13071v2 [cs.RO] UPDATED)
135. Learning Sequential Contexts using Transformer for 3D Hand Pose Estimation. (arXiv:2206.00171v2 [cs.CV] UPDATED)
136. Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography. (arXiv:2206.02225v2 [eess.IV] UPDATED)
137. JigsawHSI: a network for Hyperspectral Image classification. (arXiv:2206.02327v2 [cs.CV] UPDATED)
138. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v3 [cs.CV] UPDATED)
139. Rotation-Equivariant Conditional Spherical Neural Fields for Learning a Natural Illumination Prior. (arXiv:2206.03858v2 [cs.CV] UPDATED)
140. Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners. (arXiv:2206.04046v2 [cs.CV] UPDATED)
141. Simple Cues Lead to a Strong Multi-Object Tracker. (arXiv:2206.04656v3 [cs.CV] UPDATED)
142. RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
143. AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging. (arXiv:2206.04732v2 [eess.IV] UPDATED)
## eess.IV
---
**54** new papers in eess.IV:-) 
1. Superresolution and Segmentation of OCT scans using Multi-Stage adversarial Guided Attention Training. (arXiv:2206.05277v1 [eess.IV])
2. Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality Registration of Cardiac SPECT and CT. (arXiv:2206.05278v1 [eess.IV])
3. PILC: Practical Image Lossless Compression with an End-to-end GPU Oriented Neural Framework. (arXiv:2206.05279v1 [eess.IV])
4. Poissonian Blurred Image Deconvolution by Framelet based Local Minimal Prior. (arXiv:2206.05283v1 [eess.IV])
5. Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation. (arXiv:2206.05284v1 [eess.IV])
6. From Labels to Priors in Capsule Endoscopy: A Prior Guided Approach for Improving Generalization with Few Labels. (arXiv:2206.05288v1 [eess.IV])
7. Localized adversarial artifacts for compressed sensing MRI. (arXiv:2206.05289v1 [eess.IV])
8. Access Control of Semantic Segmentation Models Using Encrypted Feature Maps. (arXiv:2206.05422v1 [cs.CV])
9. Luminance-Guided Chrominance Image **Enhancement** for HEVC Intra Coding. (arXiv:2206.05432v1 [cs.CV])
10. Robust full-pose-parameter estimation for the LED array in Fourier ptychographic microscopy. (arXiv:2206.05451v1 [physics.optics])
11. Differentiable Projection from Optical Coherence Tomography B-Scan without Retinal Layer Segmentation Supervision. (arXiv:2206.05472v1 [eess.IV])
12. Integration of Physics-Based and Data-Driven Models for Hyperspectral Image Unmixing. (arXiv:2206.05508v1 [eess.SP])
13. Deep Learning-Based MR Image Re-parameterization. (arXiv:2206.05516v1 [eess.IV])
14. A Two-stage Method for Non-extreme Value Salt-and-Pepper Noise Removal. (arXiv:2206.05520v1 [cs.CV])
15. MammoDL: Mammographic Breast Density Estimation using Federated Learning. (arXiv:2206.05575v1 [eess.IV])
16. Convex quantization preserves logconcavity. (arXiv:2206.05598v1 [eess.SP])
17. Machine learning approaches for COVID-19 detection from chest X-ray imaging: A Systematic Review. (arXiv:2206.05615v1 [eess.IV])
18. An Unsupervised Deep-Learning Method for Bone Age Assessment. (arXiv:2206.05641v1 [cs.CV])
19. A Fast Alternating Minimization Algorithm for Coded Aperture Snapshot Spectral Imaging Based on Sparsity and Deep Image Priors. (arXiv:2206.05647v1 [eess.IV])
20. Preprocessing Enhanced Image Compression for Machine Vision. (arXiv:2206.05650v1 [eess.IV])
21. DRNet: Decomposition and Reconstruction Network for Remote Physiological Measurement. (arXiv:2206.05687v1 [cs.HC])
22. PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model. (arXiv:2206.05695v1 [eess.IV])
23. Revisiting Whole-Slide Image Pyramids for Cancer Prognosis via Dual-Stream Networks. (arXiv:2206.05782v1 [eess.IV])
24. FisheyeEX: Polar Outpainting for Extending the FoV of Fisheye Lens. (arXiv:2206.05844v1 [cs.CV])
25. Intra Encoding Complexity Control with a Time-Cost Model for Versatile Video Coding. (arXiv:2206.05889v1 [eess.IV])
26. GradICON: Approximate Diffeomorphisms via Gradient Inverse Consistency. (arXiv:2206.05897v1 [cs.CV])
27. Fluorescence angiography classification in colorectal surgery -- A preliminary report. (arXiv:2206.05935v1 [eess.IV])
28. One Size Fits All: Hypernetwork for Tunable Image **Restoration**. (arXiv:2206.05970v1 [cs.CV])
29. Deep ensemble learning for segmenting tuberculosis-consistent manifestations in chest radiographs. (arXiv:2206.06065v1 [eess.IV])
30. Annular Computational Imaging: Capture Clear Panoramic Images through Simple Lens. (arXiv:2206.06070v1 [eess.IV])
31. AR-**NeRF**: Unsupervised Learning of Depth and Defocus Effects from Natural Images with Aperture Rendering Neural Radiance Fields. (arXiv:2206.06100v1 [cs.CV])
32. SyntheX: Scaling Up Learning-based X-ray Image Analysis Through In Silico Experiments. (arXiv:2206.06127v1 [eess.IV])
33. Learning a Degradation-Adaptive Network for Light Field Image Super-Resolution. (arXiv:2206.06214v1 [cs.CV])
34. Prostate Cancer Malignancy Detection and localization from mpMRI using auto-Deep Learning: One Step Closer to Clinical Utilization. (arXiv:2206.06235v1 [eess.IV])
35. RPLHR-CT Dataset and Transformer Baseline for Volumetric Super-Resolution from CT Scans. (arXiv:2206.06253v1 [eess.IV])
36. Automatic Polyp Segmentation with Multiple Kernel Dilated Convolution Network. (arXiv:2206.06264v1 [eess.IV])
37. MMMNA-Net for Overall Survival Time Prediction of Brain Tumor Patients. (arXiv:2206.06267v1 [eess.IV])
38. Unsupervised inter-frame motion correction for whole-body dynamic PET using convolutional long short-term memory in a convolutional neural network. (arXiv:2206.06341v1 [eess.IV])
39. Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v4 [eess.IV] UPDATED)
40. Imaging dynamics beneath turbid media via parallelized single-photon detection. (arXiv:2107.01422v4 [physics.optics] UPDATED)
41. Efficient approximation of Jacobian matrices involving a non-uniform fast Fourier transform (NUFFT). (arXiv:2111.02912v2 [eess.IV] UPDATED)
42. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v6 [cs.CV] UPDATED)
43. **Exposure**-Referred Signal-to-Noise Ratio for Digital Image Sensors. (arXiv:2112.05817v2 [eess.IV] UPDATED)
44. MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v4 [eess.IV] UPDATED)
45. COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
46. Class Distance Weighted Cross-Entropy Loss for Ulcerative Colitis Severity Estimation. (arXiv:2202.05167v2 [eess.IV] UPDATED)
47. Opinions Vary? Diagnosis First!. (arXiv:2202.06505v2 [eess.IV] UPDATED)
48. Disentangling Light Fields for Super-Resolution and Disparity Estimation. (arXiv:2202.10603v2 [eess.IV] UPDATED)
49. Transient motion classification through turbid volumes via parallelized single-photon detection and deep contrastive embedding. (arXiv:2204.01733v2 [eess.IV] UPDATED)
50. Explainable Deep Learning Methods in Medical Imaging Diagnosis: A Survey. (arXiv:2205.04766v2 [eess.IV] UPDATED)
51. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v2 [eess.IV] UPDATED)
52. Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography. (arXiv:2206.02225v2 [eess.IV] UPDATED)
53. RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
54. AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging. (arXiv:2206.04732v2 [eess.IV] UPDATED)
## cs.LG
---
**251** new papers in cs.LG:-) 
1. CONTINUER: Maintaining Distributed DNN Services During Edge Failures. (arXiv:2206.05267v1 [cs.DC])
2. Less Is More: Linear Layers on CLIP Features as Powerful VizWiz Model. (arXiv:2206.05281v1 [cs.CV])
3. Learning to Estimate Shapley Values with Vision Transformers. (arXiv:2206.05282v1 [cs.CV])
4. Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation. (arXiv:2206.05284v1 [eess.IV])
5. From Labels to Priors in Capsule Endoscopy: A Prior Guided Approach for Improving Generalization with Few Labels. (arXiv:2206.05288v1 [eess.IV])
6. Localized adversarial artifacts for compressed sensing MRI. (arXiv:2206.05289v1 [eess.IV])
7. ProActive: Self-Attentive Temporal Point Process Flows for Activity Sequences. (arXiv:2206.05291v1 [cs.CV])
8. Large-Scale Retrieval for Reinforcement Learning. (arXiv:2206.05314v1 [cs.LG])
9. Intrinsic dimensionality and generalization properties of the $\mathcal{R}$-norm inductive bias. (arXiv:2206.05317v1 [cs.LG])
10. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v1 [cs.LG])
11. Synthetic Over-sampling for Imbalanced Node Classification with Graph Neural Networks. (arXiv:2206.05335v1 [cs.LG])
12. Cross-TOP: Zero-Shot Cross-Schema Task-Oriented Parsing. (arXiv:2206.05352v1 [cs.CL])
13. Anchor-Changing Regularized Natural Policy Gradient for Multi-Objective Reinforcement Learning. (arXiv:2206.05357v1 [cs.LG])
14. Object Detection, Recognition, Deep Learning, and the Universal Law of Generalization. (arXiv:2206.05365v1 [cs.LG])
15. An application of neural networks to a problem in knot theory and group theory (untangling braids). (arXiv:2206.05373v1 [math.GT])
16. Fast building segmentation from satellite imagery and few local labels. (arXiv:2206.05377v1 [cs.CV])
17. Learning Imbalanced Datasets with Maximum Margin Loss. (arXiv:2206.05380v1 [cs.LG])
18. Feature Selection using e-values. (arXiv:2206.05391v1 [stat.ML])
19. Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits. (arXiv:2206.05404v1 [stat.ML])
20. Rethinking the Defense Against Free-rider Attack From the Perspective of Model Weight Evolving Frequency. (arXiv:2206.05406v1 [cs.LG])
21. Multi-instrument Music Synthesis with Spectrogram Diffusion. (arXiv:2206.05408v1 [cs.SD])
22. Semi-Supervised Hierarchical Graph Classification. (arXiv:2206.05416v1 [cs.SI])
23. Learned reconstruction with convergence guarantees. (arXiv:2206.05431v1 [cs.CV])
24. ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition. (arXiv:2206.05437v1 [cs.LG])
25. A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams. (arXiv:2206.05442v1 [cs.LG])
26. Enhancing Explainability of Hyperparameter Optimization via Bayesian Algorithm Execution. (arXiv:2206.05447v1 [cs.LG])
27. A General framework for PAC-Bayes Bounds for Meta-Learning. (arXiv:2206.05454v1 [cs.LG])
28. Hierarchical Conditional Variational Autoencoder Based Acoustic Anomaly Detection. (arXiv:2206.05460v1 [cs.LG])
29. Svadhyaya system for the Second Diagnosing COVID-19 using Acoustics Challenge 2021. (arXiv:2206.05462v1 [eess.AS])
30. Reducing Capacity Gap in Knowledge Distillation with Review Mechanism for Crowd Counting. (arXiv:2206.05475v1 [cs.LG])
31. Monitoring and Proactive Management of QoS Levels in Pervasive Applications. (arXiv:2206.05478v1 [cs.DC])
32. **Bilateral** Dependency Optimization: Defending Against Model-inversion Attacks. (arXiv:2206.05483v1 [cs.LG])
33. Scientific Inference With Interpretable Machine Learning: Analyzing Models to Learn About Real-World Phenomena. (arXiv:2206.05487v1 [stat.ML])
34. Discovery and density estimation of latent confounders in Bayesian networks with evidence lower bound. (arXiv:2206.05490v1 [cs.LG])
35. DRAformer: Differentially Reconstructed Attention Transformer for Time-Series Forecasting. (arXiv:2206.05495v1 [cs.LG])
36. Learning to Generate Levels by Imitating Evolution. (arXiv:2206.05497v1 [cs.AI])
37. Soft-mask: Adaptive Substructure Extractions for Graph Neural Networks. (arXiv:2206.05499v1 [cs.LG])
38. Federated Learning with GAN-based Data Synthesis for Non-IID Clients. (arXiv:2206.05507v1 [cs.LG])
39. Model-based Offline Imitation Learning with Non-expert Data. (arXiv:2206.05521v1 [cs.LG])
40. Memorization-Dilation: Modeling Neural Collapse Under Noise. (arXiv:2206.05530v1 [cs.LG])
41. Rare event failure test case generation in Learning-Enabled-Controllers. (arXiv:2206.05533v1 [cs.LG])
42. A Simplified Un-Supervised Learning Based Approach for Ink Mismatch Detection in Handwritten Hyper-Spectral Document Images. (arXiv:2206.05539v1 [cs.CV])
43. Communication-Efficient Robust Federated Learning with Noisy Labels. (arXiv:2206.05558v1 [cs.LG])
44. Parameter Convex Neural Networks. (arXiv:2206.05562v1 [cs.LG])
45. gDDIM: Generalized denoising diffusion implicit models. (arXiv:2206.05564v1 [cs.LG])
46. NeuGuard: Lightweight Neuron-Guided Defense against Membership Inference Attacks. (arXiv:2206.05565v1 [cs.CR])
47. MammoDL: Mammographic Breast Density Estimation using Federated Learning. (arXiv:2206.05575v1 [eess.IV])
48. Optimal Solutions for Joint Beamforming and Antenna Selection: From Branch and Bound to Machine Learning. (arXiv:2206.05576v1 [eess.SP])
49. Federated Offline Reinforcement Learning. (arXiv:2206.05581v1 [stat.ML])
50. RadNet: Incident Prediction in Spatio-Temporal Road Graph Networks Using Traffic Forecasting. (arXiv:2206.05602v1 [cs.LG])
51. A Theoretical Understanding of Neural Network Compression from Sparse Linear Approximation. (arXiv:2206.05604v1 [stat.ML])
52. Gradient Boosting Performs Low-Rank Gaussian Process Inference. (arXiv:2206.05608v1 [cs.LG])
53. Machine learning approaches for COVID-19 detection from chest X-ray imaging: A Systematic Review. (arXiv:2206.05615v1 [eess.IV])
54. Federated Learning with Research Prototypes for Multi-Center MRI-based Detection of Prostate Cancer with Diverse Histopathology. (arXiv:2206.05617v1 [cs.CV])
55. Mathematical Theory of Bayesian Statistics for Unknown Information Source. (arXiv:2206.05630v1 [cs.LG])
56. An Unsupervised Deep-Learning Method for Bone Age Assessment. (arXiv:2206.05641v1 [cs.CV])
57. Density Regression and Uncertainty Quantification with Bayesian Deep Noise Neural Networks. (arXiv:2206.05643v1 [cs.LG])
58. Dealing with Sparse Rewards in Continuous Control Robotics via Heavy-Tailed Policies. (arXiv:2206.05652v1 [cs.LG])
59. Variational Bayes Deep Operator Network: A data-driven Bayesian solver for parametric differential equations. (arXiv:2206.05655v1 [stat.ML])
60. An Efficient Method for Sample Adversarial Perturbations against Nonlinear Support Vector Machines. (arXiv:2206.05664v1 [cs.LG])
61. Federated Learning on Riemannian Manifolds. (arXiv:2206.05668v1 [cs.LG])
62. Universality and approximation bounds for echo state networks with random weights. (arXiv:2206.05669v1 [cs.LG])
63. A Survey on Uncertainty Reasoning and Quantification for Decision Making: Belief Theory Meets Deep Learning. (arXiv:2206.05675v1 [cs.AI])
64. Balancing Bias and Variance for Active Weakly Supervised Learning. (arXiv:2206.05682v1 [cs.LG])
65. tBDFS: Temporal Graph Neural Network Leveraging DFS. (arXiv:2206.05692v1 [cs.LG])
66. A Functional Information Perspective on Model Interpretation. (arXiv:2206.05700v1 [cs.LG])
67. PAC-Net: A Model Pruning Approach to Inductive Transfer Learning. (arXiv:2206.05703v1 [cs.LG])
68. Machine learning based surrogate modeling with SVD enabled training for nonlinear civil structures subject to dynamic loading. (arXiv:2206.05720v1 [stat.ML])
69. Finite-Time Analysis of Fully Decentralized Single-Timescale Actor-Critic. (arXiv:2206.05733v1 [cs.LG])
70. Learning to Detect with Constant False Alarm Rate. (arXiv:2206.05747v1 [cs.LG])
71. Regularization Penalty Optimization for Addressing Data Quality Variance in OoD Algorithms. (arXiv:2206.05749v1 [cs.LG])
72. Matching options to tasks using Option-Indexed Hierarchical Reinforcement Learning. (arXiv:2206.05750v1 [cs.LG])
73. Consistent Attack: Universal Adversarial Perturbation on Embodied Vision Navigation. (arXiv:2206.05751v1 [cs.LG])
74. Mining Multi-Label Samples from Single Positive Labels. (arXiv:2206.05764v1 [cs.LG])
75. Distributed Differential Privacy in Multi-Armed Bandits. (arXiv:2206.05772v1 [cs.LG])
76. The Rough Topology for Numerical Data. (arXiv:2206.05776v1 [cs.IT])
77. Learning-Based Data Storage [Vision] (Technical Report). (arXiv:2206.05778v1 [cs.DB])
78. Revisiting Whole-Slide Image Pyramids for Cancer Prognosis via Dual-Stream Networks. (arXiv:2206.05782v1 [eess.IV])
79. SGD Noise and Implicit Low-Rank Bias in Deep Neural Networks. (arXiv:2206.05794v1 [cs.LG])
80. Self-critiquing models for assisting human evaluators. (arXiv:2206.05802v1 [cs.CL])
81. Geometric Policy Iteration for Markov Decision Processes. (arXiv:2206.05809v1 [cs.LG])
82. Analysis of Branch Specialization and its Application in Image Decomposition. (arXiv:2206.05810v1 [cs.CV])
83. An Industry 4.0 example: real-time quality control for steel-based mass production using Machine Learning on non-invasive sensor data. (arXiv:2206.05818v1 [cs.LG])
84. Science through Machine Learning: Quantification of Poststorm Thermospheric Cooling. (arXiv:2206.05824v1 [physics.space-ph])
85. A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games. (arXiv:2206.05825v1 [cs.LG])
86. Case-Based Inverse Reinforcement Learning Using Temporal Coherence. (arXiv:2206.05827v1 [cs.LG])
87. Bounding and Approximating Intersectional Fairness through Marginal Fairness. (arXiv:2206.05828v1 [stat.ML])
88. Stochastic Gradient Descent without Full Data Shuffle. (arXiv:2206.05830v1 [cs.LG])
89. Deep Reinforcement Learning for Optimal Investment and Saving Strategy Selection in Heterogeneous Profiles: Intelligent Agents working towards retirement. (arXiv:2206.05835v1 [q-fin.PM])
90. GLIPv2: Unifying Localization and Vision-Language Understanding. (arXiv:2206.05836v1 [cs.CV])
91. GAN based Data Augmentation to Resolve Class Imbalance. (arXiv:2206.05840v1 [cs.LG])
92. InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness. (arXiv:2206.05846v1 [cs.CV])
93. Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm. (arXiv:2206.05850v1 [cs.LG])
94. ChordMixer: A Scalable Neural Attention Model for Sequences with Different Lengths. (arXiv:2206.05852v1 [cs.LG])
95. A Directed-Evolution Method for Sparsification and Compression of Neural Networks with Application to Object Identification and Segmentation and considerations of optimal quantization using small number of bits. (arXiv:2206.05859v1 [cs.LG])
96. IGN : Implicit Generative Networks. (arXiv:2206.05860v1 [cs.LG])
97. On the Convergence to a Global Solution of Shuffling-Type Gradient Algorithms. (arXiv:2206.05869v1 [cs.LG])
98. Description and Discussion on DCASE 2022 Challenge Task 2: Unsupervised Anomalous Sound Detection for Machine Condition Monitoring Applying Domain Generalization Techniques. (arXiv:2206.05876v1 [cs.SD])
99. A view of Estimation of Distribution Algorithms through the lens of Expectation-Maximization. (arXiv:1905.10474v11 [cs.LG] UPDATED)
100. Quantification and Analysis of Layer-wise and Pixel-wise Information Discarding. (arXiv:1906.04109v2 [cs.LG] UPDATED)
101. Universal, transferable and targeted adversarial attacks. (arXiv:1908.11332v4 [cs.LG] UPDATED)
102. Empirical and Instance-Dependent Estimation of Markov Chain and Mixing Time. (arXiv:1912.06845v2 [math.PR] UPDATED)
103. AI for Social Impact: Learning and Planning in the Data-to-Deployment Pipeline. (arXiv:2001.00088v2 [cs.CY] UPDATED)
104. Maximal Closed Set and Half-Space Separations in Finite Closure Systems. (arXiv:2001.04417v3 [cs.AI] UPDATED)
105. The Price of Incentivizing Exploration: A Characterization via Thompson Sampling and Sample Complexity. (arXiv:2002.00558v6 [cs.GT] UPDATED)
106. Deep Reinforcement Learning with Weighted Q-Learning. (arXiv:2003.09280v3 [cs.LG] UPDATED)
107. Detached Error Feedback for Distributed SGD with Random Sparsification. (arXiv:2004.05298v3 [cs.LG] UPDATED)
108. A cognitive based Intrusion detection system. (arXiv:2005.09436v2 [cs.LG] UPDATED)
109. Feature Purification: How Adversarial Training Performs Robust Deep Learning. (arXiv:2005.10190v4 [cs.LG] UPDATED)
110. The Mean-Squared Error of Double Q-Learning. (arXiv:2007.05034v2 [cs.LG] UPDATED)
111. Understanding and Mitigating the Limitations of Prioritized Experience Replay. (arXiv:2007.09569v3 [cs.AI] UPDATED)
112. DeepVOX: Discovering Features from Raw Audio for Speaker Recognition in Non-ideal Audio Signals. (arXiv:2008.11668v2 [eess.AS] UPDATED)
113. Bayesian Inverse Reinforcement Learning for Collective Animal Movement. (arXiv:2009.04003v3 [cs.LG] UPDATED)
114. LAAT: Locally Aligned Ant Technique for discovering multiple faint low dimensional structures of varying density. (arXiv:2009.08326v2 [cs.LG] UPDATED)
115. Image-Based Sorghum Head Counting When You Only Look Once. (arXiv:2009.11929v3 [cs.CV] UPDATED)
116. Identifying Exoplanets with Deep Learning. IV. Removing Stellar Activity Signals from Radial Velocity Measurements Using Neural Networks. (arXiv:2011.00003v3 [astro-ph.EP] UPDATED)
117. Dominant Z-Eigenpairs of Tensor Kronecker Products are Decoupled and Applications to Higher-Order Graph Matching. (arXiv:2011.08837v2 [cs.SI] UPDATED)
118. Stochastic Variance Reduction for Variational Inequality Methods. (arXiv:2102.08352v2 [math.OC] UPDATED)
119. Monte Carlo Tree Search: A Review of Recent Modifications and Applications. (arXiv:2103.04931v4 [cs.AI] UPDATED)
120. Neural Network Attribution Methods for Problems in Geoscience: A Novel Synthetic Benchmark Dataset. (arXiv:2103.10005v2 [physics.geo-ph] UPDATED)
121. Graph Representation Learning in Biomedicine. (arXiv:2104.04883v3 [cs.LG] UPDATED)
122. VGNMN: Video-grounded Neural Module Network to Video-Grounded Language Tasks. (arXiv:2104.07921v2 [cs.CV] UPDATED)
123. CASA: Bridging the Gap between Policy Improvement and Policy Evaluation with Conflict Averse Policy Iteration. (arXiv:2105.03923v4 [cs.LG] UPDATED)
124. Transferable Deep Reinforcement Learning Framework for Autonomous Vehicles with Joint Radar-Data Communications. (arXiv:2105.13670v2 [cs.LG] UPDATED)
125. An Overview of Deep Learning Techniques for Epileptic Seizures Detection and Prediction Based on Neuroimaging Modalities: Methods, Challenges, and Future Works. (arXiv:2105.14278v2 [cs.LG] UPDATED)
126. Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v4 [eess.IV] UPDATED)
127. Consensus Multiplicative Weights Update: Learning to Learn using Projector-based Game Signatures. (arXiv:2106.02615v3 [cs.GT] UPDATED)
128. Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms. (arXiv:2106.02979v2 [stat.ML] UPDATED)
129. Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v5 [cs.LG] UPDATED)
130. How does Heterophily Impact Robustness of Graph Neural Networks? Theoretical Connections and Practical Implications. (arXiv:2106.07767v3 [cs.LG] UPDATED)
131. Transflower: probabilistic autoregressive dance generation with multimodal attention. (arXiv:2106.13871v3 [cs.SD] UPDATED)
132. Concentration of Contractive Stochastic Approximation and Reinforcement Learning. (arXiv:2106.14308v4 [cs.LG] UPDATED)
133. Preconditioning for Scalable Gaussian Process Hyperparameter Optimization. (arXiv:2107.00243v4 [cs.LG] UPDATED)
134. Universal approximation and model compression for radial neural networks. (arXiv:2107.02550v2 [cs.LG] UPDATED)
135. Prioritized training on points that are learnable, worth learning, and not yet learned (workshop version). (arXiv:2107.02565v2 [cs.LG] UPDATED)
136. Globally Convergent Multilevel Training of Deep Residual Networks. (arXiv:2107.07572v2 [cs.LG] UPDATED)
137. Learning to Limit Data Collection via Scaling Laws: A Computational Interpretation for the Legal Principle of Data Minimization. (arXiv:2107.08096v2 [cs.LG] UPDATED)
138. Trade When Opportunity Comes: Price Movement Forecasting via Locality-Aware Attention and Iterative Refinement Labeling. (arXiv:2107.11972v2 [cs.LG] UPDATED)
139. Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting Spatio-Temporal Sparsity. (arXiv:2108.02297v5 [cs.AR] UPDATED)
140. NIAPU: network-informed adaptive positive-unlabelled learning for disease genes identification. (arXiv:2108.06158v2 [cs.LG] UPDATED)
141. Comparing Classes of Estimators: When does Gradient Descent Beat Ridge Regression in Linear Models?. (arXiv:2108.11872v2 [math.ST] UPDATED)
142. Multiple Hypothesis Testing Framework for Spatial Signals. (arXiv:2108.12314v3 [eess.SP] UPDATED)
143. Learning through atypical "phase transitions" in overparameterized neural networks. (arXiv:2110.00683v2 [cs.LG] UPDATED)
144. Hierarchical Primitive Composition: Simultaneous Activation of Skills with Inconsistent Action Dimensions in Multiple Hierarchies. (arXiv:2110.01833v3 [cs.LG] UPDATED)
145. Cycle Representation Learning for Inductive Relation Prediction. (arXiv:2110.02510v3 [cs.LG] UPDATED)
146. Neural Tangent Kernel Empowered Federated Learning. (arXiv:2110.03681v3 [cs.LG] UPDATED)
147. NNK-Means: Data summarization using dictionary learning with non-negative kernel regression. (arXiv:2110.08212v2 [cs.LG] UPDATED)
148. Improving Transformers with Probabilistic Attention Keys. (arXiv:2110.08678v2 [cs.LG] UPDATED)
149. Generating Symbolic Reasoning Problems with Transformer GANs. (arXiv:2110.10054v2 [cs.LG] UPDATED)
150. CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP. (arXiv:2110.11316v3 [cs.LG] UPDATED)
151. Tight and Robust Private Mean Estimation with Few Users. (arXiv:2110.11876v2 [cs.DS] UPDATED)
152. Machine learning spectral functions in lattice QCD. (arXiv:2110.13521v2 [hep-lat] UPDATED)
153. A Concentration Bound for LSPE($\lambda$). (arXiv:2111.02644v3 [cs.LG] UPDATED)
154. Hard Negative Sampling via Regularized Optimal Transport for Contrastive Representation Learning. (arXiv:2111.03169v2 [cs.LG] UPDATED)
155. Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits. (arXiv:2111.03917v2 [cs.LG] UPDATED)
156. Interactive Inverse Reinforcement Learning for Cooperative Games. (arXiv:2111.04698v2 [cs.LG] UPDATED)
157. XnODR and XnIDR: Two Accurate and Fast Fully Connected Layers For Convolutional Neural Networks. (arXiv:2111.10854v2 [cs.CV] UPDATED)
158. Anti-Jamming Games in Multi-Band Wireless Ad Hoc Networks. (arXiv:2111.11178v3 [cs.IT] UPDATED)
159. A note on stabilizing reinforcement learning. (arXiv:2111.12316v2 [math.DS] UPDATED)
160. On the (In)Tractability of Reinforcement Learning for LTL Objectives. (arXiv:2111.12679v2 [cs.AI] UPDATED)
161. Generalizing electrocardiogram delineation -- Training convolutional neural networks with synthetic data augmentation. (arXiv:2111.12996v2 [cs.LG] UPDATED)
162. Associative Memories Using Complex-Valued Hopfield Networks Based on Spin-Torque Oscillator Arrays. (arXiv:2112.03358v2 [cs.ET] UPDATED)
163. SCR: Training Graph Neural Networks with Consistency Regularization. (arXiv:2112.04319v2 [cs.SI] UPDATED)
164. Channel Parameter Estimation in the Presence of Phase Noise Based on Maximum Correntropy Criterion. (arXiv:2112.07955v2 [cs.IT] UPDATED)
165. On the Adversarial Robustness of Causal Algorithmic Recourse. (arXiv:2112.11313v2 [cs.LG] UPDATED)
166. Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization. (arXiv:2112.12376v5 [cs.LG] UPDATED)
167. Causal Attention for Interpretable and Generalizable Graph Classification. (arXiv:2112.15089v2 [cs.LG] UPDATED)
168. What is Event Knowledge Graph: A Survey. (arXiv:2112.15280v2 [cs.LG] UPDATED)
169. NeuralMLS: Geometry-Aware Control Point Deformation. (arXiv:2201.01873v2 [cs.GR] UPDATED)
170. Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v9 [cs.CR] UPDATED)
171. Nearest Class-Center Simplification through Intermediate Layers. (arXiv:2201.08924v2 [cs.LG] UPDATED)
172. Adaptive Best-of-Both-Worlds Algorithm for Heavy-Tailed Multi-Armed Bandits. (arXiv:2201.11921v2 [cs.LG] UPDATED)
173. Zeroth-Order Actor-Critic. (arXiv:2201.12518v3 [cs.LG] UPDATED)
174. AutoSNN: Towards Energy-Efficient Spiking Neural Networks. (arXiv:2201.12738v3 [cs.NE] UPDATED)
175. COIN++: Neural Compression Across Modalities. (arXiv:2201.12904v2 [cs.LG] UPDATED)
176. Inverse design of photonic devices with strict foundry fabrication constraints. (arXiv:2201.12965v2 [cs.ET] UPDATED)
177. Network-level Safety Metrics for Overall Traffic Safety Assessment: A Case Study. (arXiv:2201.13229v2 [cs.CV] UPDATED)
178. Improving Screening Processes via Calibrated Subset Selection. (arXiv:2202.01147v3 [cs.LG] UPDATED)
179. Imitation Learning by Estimating Expertise of Demonstrators. (arXiv:2202.01288v2 [cs.LG] UPDATED)
180. A Temporal-Difference Approach to Policy Gradient Estimation. (arXiv:2202.02396v2 [cs.LG] UPDATED)
181. Structure-Aware Transformer for Graph Representation Learning. (arXiv:2202.03036v3 [stat.ML] UPDATED)
182. Nesterov Accelerated Shuffling Gradient Method for Convex Optimization. (arXiv:2202.03525v2 [math.OC] UPDATED)
183. On Unbalanced Optimal Transport: Gradient Methods, Sparsity and Approximation Error. (arXiv:2202.03618v2 [math.OC] UPDATED)
184. Fast Rates in Pool-Based Batch Active Learning. (arXiv:2202.05448v2 [cs.LG] UPDATED)
185. Support Vectors and Gradient Dynamics of Single-Neuron ReLU Networks. (arXiv:2202.05510v2 [cs.LG] UPDATED)
186. Opinions Vary? Diagnosis First!. (arXiv:2202.06505v2 [eess.IV] UPDATED)
187. Quantum Lazy Training. (arXiv:2202.08232v3 [quant-ph] UPDATED)
188. Data-SUITE: Data-centric identification of in-distribution incongruous examples. (arXiv:2202.08836v3 [cs.LG] UPDATED)
189. Adaptivity and Confounding in Multi-Armed Bandit Experiments. (arXiv:2202.09036v3 [cs.LG] UPDATED)
190. Learning Low Degree Hypergraphs. (arXiv:2202.09989v2 [cs.DS] UPDATED)
191. Sequential asset ranking in nonstationary time series. (arXiv:2202.12186v2 [cs.CE] UPDATED)
192. Bridging the Gap Between Patient-specific and Patient-independent Seizure Prediction via Knowledge Distillation. (arXiv:2202.12598v2 [cs.LG] UPDATED)
193. Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity. (arXiv:2202.13890v2 [cs.LG] UPDATED)
194. Generative Modeling for Low Dimensional Speech Attributes with Neural Spline Flows. (arXiv:2203.01786v3 [cs.SD] UPDATED)
195. Interventions, Where and How? Experimental Design for Causal Models at Scale. (arXiv:2203.02016v2 [cs.LG] UPDATED)
196. Zero-shot Transfer Learning on Heterogeneous Graphs via Knowledge Transfer Networks. (arXiv:2203.02018v2 [cs.LG] UPDATED)
197. Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits. (arXiv:2203.06803v3 [cs.LG] UPDATED)
198. Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective. (arXiv:2203.06865v2 [q-fin.MF] UPDATED)
199. On Suspicious Coincidences and Pointwise Mutual Information. (arXiv:2203.08089v2 [cs.LG] UPDATED)
200. Practical Conditional Neural Processes Via Tractable Dependent Predictions. (arXiv:2203.08775v2 [stat.ML] UPDATED)
201. Data-Lean Evolutionary Reinforcement Learning by Multitasking with Importance Sampling. (arXiv:2203.10844v2 [cs.NE] UPDATED)
202. Combining Evolution and Deep Reinforcement Learning for Policy Search: a Survey. (arXiv:2203.14009v5 [cs.LG] UPDATED)
203. Learning Optical Flow, Depth, and Scene Flow without Real-World Labels. (arXiv:2203.15089v2 [cs.CV] UPDATED)
204. "This is my unicorn, Fluffy": Personalizing frozen vision-language representations. (arXiv:2204.01694v2 [cs.CV] UPDATED)
205. BERTuit: Understanding Spanish language in Twitter through a native transformer. (arXiv:2204.03465v2 [cs.CL] UPDATED)
206. Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v3 [cs.LG] UPDATED)
207. Ultra-marginal Feature Importance. (arXiv:2204.09938v2 [stat.ML] UPDATED)
208. Visual Attention Emerges from Recurrent Sparse Reconstruction. (arXiv:2204.10962v3 [cs.CV] UPDATED)
209. RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning. (arXiv:2204.11167v2 [cs.CV] UPDATED)
210. Machine learning identification of organic compounds using visible light. (arXiv:2204.11832v2 [cs.LG] UPDATED)
211. NeuralEF: Deconstructing Kernels by Deep Neural Networks. (arXiv:2205.00165v2 [cs.LG] UPDATED)
212. Fast Continuous and Integer L-shaped Heuristics Through Supervised Learning. (arXiv:2205.00897v2 [math.OC] UPDATED)
213. Explainable Deep Learning Methods in Medical Imaging Diagnosis: A Survey. (arXiv:2205.04766v2 [eess.IV] UPDATED)
214. Generalization error bounds for DECONET: a deep unfolding network for analysis Compressive Sensing. (arXiv:2205.07050v3 [cs.IT] UPDATED)
215. Trajectory Inference via Mean-field Langevin in Path Space. (arXiv:2205.07146v3 [math.OC] UPDATED)
216. An Invariant Matching Property for Distribution Generalization under Intervened Response. (arXiv:2205.09162v2 [stat.ME] UPDATED)
217. Metrics of calibration for probabilistic predictions. (arXiv:2205.09680v2 [math.ST] UPDATED)
218. FIND:Explainable Framework for Meta-learning. (arXiv:2205.10362v2 [cs.LG] UPDATED)
219. PSO-Convolutional Neural Networks with Heterogeneous Learning Rate. (arXiv:2205.10456v2 [cs.CV] UPDATED)
220. Personalized Federated Learning with Server-Side Information. (arXiv:2205.11044v2 [cs.LG] UPDATED)
221. Orchestra: Unsupervised Federated Learning via Globally Consistent Clustering. (arXiv:2205.11506v2 [cs.LG] UPDATED)
222. Multi-Agent Collaborative Inference via DNN Decoupling: Intermediate Feature Compression and Edge Learning. (arXiv:2205.11854v2 [cs.LG] UPDATED)
223. Machine learning method for return direction forecasting of Exchange Traded Funds using classification and regression models. (arXiv:2205.12746v2 [q-fin.CP] UPDATED)
224. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v2 [eess.IV] UPDATED)
225. Teaching Models to Express Their Uncertainty in Words. (arXiv:2205.14334v2 [cs.CL] UPDATED)
226. Lepton Flavour Violation Identification in Tau Decay ($\tau^{-} \rightarrow \mu^{-}\mu^{-}\mu^{+}$) Using Artificial Intelligence. (arXiv:2205.14828v2 [hep-ph] UPDATED)
227. Minimax Optimal Online Imitation Learning via Replay Estimation. (arXiv:2205.15397v3 [cs.LG] UPDATED)
228. Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games. (arXiv:2205.15879v2 [cs.AI] UPDATED)
229. Feature Selection for Discovering Distributional Treatment Effect Modifiers. (arXiv:2206.00516v3 [cs.LG] UPDATED)
230. Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code. (arXiv:2206.01335v2 [cs.SE] UPDATED)
231. Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank. (arXiv:2206.01702v2 [cs.IR] UPDATED)
232. Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning. (arXiv:2206.01888v2 [cs.LG] UPDATED)
233. Stochastic Multiple Target Sampling Gradient Descent. (arXiv:2206.01934v2 [cs.LG] UPDATED)
234. Geodesic Properties of a Generalized Wasserstein Embedding for Time Series Analysis. (arXiv:2206.01984v2 [cs.LG] UPDATED)
235. JigsawHSI: a network for Hyperspectral Image classification. (arXiv:2206.02327v2 [cs.CV] UPDATED)
236. On Efficient Approximate Queries over Machine Learning Models. (arXiv:2206.02845v2 [cs.DB] UPDATED)
237. On the Convergence of Optimizing Persistent-Homology-Based Losses. (arXiv:2206.02946v2 [cs.LG] UPDATED)
238. Concentration bounds for SSP Q-learning for average cost MDPs. (arXiv:2206.03328v2 [cs.LG] UPDATED)
239. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v3 [cs.CV] UPDATED)
240. Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners. (arXiv:2206.04046v2 [cs.CV] UPDATED)
241. RT-DNAS: **Real-time** Constrained Differentiable Neural Architecture Search for 3D Cardiac Cine MRI Segmentation. (arXiv:2206.04682v2 [eess.IV] UPDATED)
242. A Resilient Distributed Boosting Algorithm. (arXiv:2206.04713v2 [cs.LG] UPDATED)
243. COSTA: Covariance-Preserving Feature Augmentation for Graph Contrastive Learning. (arXiv:2206.04726v2 [cs.LG] UPDATED)
244. AI-MIA: COVID-19 Detection & Severity Analysis through Medical Imaging. (arXiv:2206.04732v2 [eess.IV] UPDATED)
245. The Slingshot Mechanism: An Empirical Study of Adaptive Optimizers and the Grokking Phenomenon. (arXiv:2206.04817v2 [cs.LG] UPDATED)
246. In Defense of Core-set: A Density-aware Core-set Selection for Active Learning. (arXiv:2206.04838v2 [cs.LG] UPDATED)
247. Neural Laplace: Learning diverse classes of differential equations in the Laplace domain. (arXiv:2206.04843v2 [cs.LG] UPDATED)
248. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v2 [cs.AI] UPDATED)
249. Fast Deep Autoencoder for Federated learning. (arXiv:2206.05136v2 [cs.LG] UPDATED)
250. Sharp-MAML: Sharpness-Aware Model-Agnostic Meta Learning. (arXiv:2206.03996v2 [cs.LG] CROSS LISTED)
251. Provably efficient variational generative modeling of quantum many-body systems via quantum-probabilistic information geometry. (arXiv:2206.04663v1 [quant-ph] CROSS LISTED)
## cs.AI
---
**115** new papers in cs.AI:-) 
1. A heuristic method for data allocation and task scheduling on heterogeneous multiprocessor systems under memory constraints. (arXiv:2206.05268v1 [cs.DC])
2. A General Framework for the Representation of Function and Affordance: A Cognitive, Causal, and Grounded Approach, and a Step Toward AGI. (arXiv:2206.05273v1 [cs.AI])
3. Spatial-temporal Concept based Explanation of 3D ConvNets. (arXiv:2206.05275v1 [cs.CV])
4. Dual-Branch Squeeze-Fusion-Excitation Module for Cross-Modality Registration of Cardiac SPECT and CT. (arXiv:2206.05278v1 [eess.IV])
5. Decoupling Predictions in Distributed Learning for Multi-Center Left Atrial MRI Segmentation. (arXiv:2206.05284v1 [eess.IV])
6. From Labels to Priors in Capsule Endoscopy: A Prior Guided Approach for Improving Generalization with Few Labels. (arXiv:2206.05288v1 [eess.IV])
7. Graph-in-Graph Network for Automatic Gene Ontology Description Generation. (arXiv:2206.05311v1 [cs.AI])
8. Large-Scale Retrieval for Reinforcement Learning. (arXiv:2206.05314v1 [cs.LG])
9. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v1 [cs.LG])
10. Social Practices for Social Driven Conversations in Serious Games. (arXiv:2206.05355v1 [cs.AI])
11. Object Detection, Recognition, Deep Learning, and the Universal Law of Generalization. (arXiv:2206.05365v1 [cs.LG])
12. A multi-objective constrained POMDP model for breast cancer screening. (arXiv:2206.05370v1 [cs.AI])
13. A Benchmark for Compositional Visual Reasoning. (arXiv:2206.05379v1 [cs.CV])
14. Learning Imbalanced Datasets with Maximum Margin Loss. (arXiv:2206.05380v1 [cs.LG])
15. Why is constrained neural language generation particularly challenging?. (arXiv:2206.05395v1 [cs.CL])
16. E$^2$PN: Efficient SE(3)-Equivariant Point Network. (arXiv:2206.05398v1 [cs.CV])
17. Rethinking the Defense Against Free-rider Attack From the Perspective of Model Weight Evolving Frequency. (arXiv:2206.05406v1 [cs.LG])
18. Semi-Supervised Hierarchical Graph Classification. (arXiv:2206.05416v1 [cs.SI])
19. SAIBench: Benchmarking AI for Science. (arXiv:2206.05418v1 [cs.AI])
20. Greedy Relaxations of the Sparsest Permutation Algorithm. (arXiv:2206.05421v1 [cs.AI])
21. ACMP: Allen-Cahn Message Passing for Graph Neural Networks with Particle Phase Transition. (arXiv:2206.05437v1 [cs.LG])
22. Hierarchical Conditional Variational Autoencoder Based Acoustic Anomaly Detection. (arXiv:2206.05460v1 [cs.LG])
23. CodeS: A Distribution Shift Benchmark Dataset for Source Code Learning. (arXiv:2206.05480v1 [cs.SE])
24. Kaggle Kinship Recognition Challenge: Introduction of Convolution-Free Model to boost conventional. (arXiv:2206.05488v1 [cs.CV])
25. DRAformer: Differentially Reconstructed Attention Transformer for Time-Series Forecasting. (arXiv:2206.05495v1 [cs.LG])
26. Learning to Generate Levels by Imitating Evolution. (arXiv:2206.05497v1 [cs.AI])
27. A Review of Causality for Learning Algorithms in Medical Image Analysis. (arXiv:2206.05498v1 [cs.CV])
28. Bridging the Gap Between Training and Inference of Bayesian Controllable Language Models. (arXiv:2206.05519v1 [cs.CL])
29. Model-based Offline Imitation Learning with Non-expert Data. (arXiv:2206.05521v1 [cs.LG])
30. Detecting Context-Aware Deviations in Process Executions. (arXiv:2206.05532v1 [cs.AI])
31. Parameter Convex Neural Networks. (arXiv:2206.05562v1 [cs.LG])
32. NeuGuard: Lightweight Neuron-Guided Defense against Membership Inference Attacks. (arXiv:2206.05565v1 [cs.CR])
33. A Review on Plastic Artificial Neural Networks: Exploring the Intersection between Neural Architecture Search and Continual Learning. (arXiv:2206.05625v1 [cs.AI])
34. A Survey on Uncertainty Reasoning and Quantification for Decision Making: Belief Theory Meets Deep Learning. (arXiv:2206.05675v1 [cs.AI])
35. Knowledge as Fruits of Ignorance: A global Free Energy Principle of our way of thinking. (arXiv:2206.05684v1 [cs.AI])
36. RL-EA: A Reinforcement Learning-Based Evolutionary Algorithm Framework for Electromagnetic Detection Satellite Scheduling Problem. (arXiv:2206.05694v1 [cs.NE])
37. PD-DWI: Predicting response to neoadjuvant chemotherapy in invasive breast cancer with Physiologically-Decomposed Diffusion-Weighted MRI machine-learning model. (arXiv:2206.05695v1 [eess.IV])
38. PAC-Net: A Model Pruning Approach to Inductive Transfer Learning. (arXiv:2206.05703v1 [cs.LG])
39. Human Mobility Prediction with Causal and Spatial-constrained Multi-task Network. (arXiv:2206.05731v1 [cs.AI])
40. Finite-Time Analysis of Fully Decentralized Single-Timescale Actor-Critic. (arXiv:2206.05733v1 [cs.LG])
41. A Semantic Consistency Feature Alignment Object Detection Model Based on Mixed-Class Distribution Metrics. (arXiv:2206.05765v1 [cs.CV])
42. Geometric Policy Iteration for Markov Decision Processes. (arXiv:2206.05809v1 [cs.LG])
43. A Unified Approach to Reinforcement Learning, Quantal Response Equilibria, and Two-Player Zero-Sum Games. (arXiv:2206.05825v1 [cs.LG])
44. GLIPv2: Unifying Localization and Vision-Language Understanding. (arXiv:2206.05836v1 [cs.CV])
45. GAN based Data Augmentation to Resolve Class Imbalance. (arXiv:2206.05840v1 [cs.LG])
46. Efficiency Comparison of AI classification algorithms for Image Detection and Recognition in **Real-time**. (arXiv:2206.05842v1 [cs.CV])
47. InBiaseD: Inductive Bias Distillation to Improve Generalization and Robustness through Shape-awareness. (arXiv:2206.05846v1 [cs.CV])
48. Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm. (arXiv:2206.05850v1 [cs.LG])
49. Modeling Generalized Specialist Approach To Train Quality Resilient Snapshot Ensemble. (arXiv:2206.05853v1 [cs.CV])
50. IGN : Implicit Generative Networks. (arXiv:2206.05860v1 [cs.LG])
51. X-Risk Analysis for AI Research. (arXiv:2206.05862v1 [cs.CY])
52. Causal Inference-Based Root Cause Analysis for Online Service Systems with Intervention Recognition. (arXiv:2206.05871v1 [cs.SE])
53. Maximal Closed Set and Half-Space Separations in Finite Closure Systems. (arXiv:2001.04417v3 [cs.AI] UPDATED)
54. Introducing the diagrammatic semiotic mode. (arXiv:2001.11224v2 [cs.CL] UPDATED)
55. Deep Reinforcement Learning with Weighted Q-Learning. (arXiv:2003.09280v3 [cs.LG] UPDATED)
56. A cognitive based Intrusion detection system. (arXiv:2005.09436v2 [cs.LG] UPDATED)
57. Understanding and Mitigating the Limitations of Prioritized Experience Replay. (arXiv:2007.09569v3 [cs.AI] UPDATED)
58. Reconstructing A Large Scale 3D Face Dataset for Deep 3D Face Identification. (arXiv:2010.08391v2 [cs.CV] UPDATED)
59. A Conflict-Based Search Framework for Multi-Objective Multi-Agent Path Finding. (arXiv:2101.03805v5 [cs.AI] UPDATED)
60. Monte Carlo Tree Search: A Review of Recent Modifications and Applications. (arXiv:2103.04931v4 [cs.AI] UPDATED)
61. VGNMN: Video-grounded Neural Module Network to Video-Grounded Language Tasks. (arXiv:2104.07921v2 [cs.CV] UPDATED)
62. Formula RL: Deep Reinforcement Learning for Autonomous Racing using Telemetry Data. (arXiv:2104.11106v2 [cs.AI] UPDATED)
63. CASA: Bridging the Gap between Policy Improvement and Policy Evaluation with Conflict Averse Policy Iteration. (arXiv:2105.03923v4 [cs.LG] UPDATED)
64. Profitable Strategy Design for Trades on Cryptocurrency Markets with Machine Learning Techniques. (arXiv:2105.06827v3 [q-fin.TR] UPDATED)
65. Soft Truncation: A Universal Training Technique of Score-based Diffusion Model for High Precision Score Estimation. (arXiv:2106.05527v5 [cs.LG] UPDATED)
66. Bayesian Statistics Guided Label Refurbishment Mechanism: Mitigating Label Noise in Medical Image Classification. (arXiv:2106.12284v2 [cs.CV] UPDATED)
67. Demystifying the Draft EU Artificial Intelligence Act. (arXiv:2107.03721v4 [cs.CY] UPDATED)
68. Communicating via Markov Decision Processes. (arXiv:2107.08295v2 [cs.AI] UPDATED)
69. Trade When Opportunity Comes: Price Movement Forecasting via Locality-Aware Attention and Iterative Refinement Labeling. (arXiv:2107.11972v2 [cs.LG] UPDATED)
70. Content-aware Directed Propagation Network with Pixel Adaptive Kernel Attention. (arXiv:2107.13144v2 [cs.CV] UPDATED)
71. Spartus: A 9.4 TOp/s FPGA-based LSTM Accelerator Exploiting Spatio-Temporal Sparsity. (arXiv:2108.02297v5 [cs.AR] UPDATED)
72. Hierarchical Primitive Composition: Simultaneous Activation of Skills with Inconsistent Action Dimensions in Multiple Hierarchies. (arXiv:2110.01833v3 [cs.LG] UPDATED)
73. Neural Tangent Kernel Empowered Federated Learning. (arXiv:2110.03681v3 [cs.LG] UPDATED)
74. Optimal and Efficient Dynamic Regret Algorithms for Non-Stationary Dueling Bandits. (arXiv:2111.03917v2 [cs.LG] UPDATED)
75. On the (In)Tractability of Reinforcement Learning for LTL Objectives. (arXiv:2111.12679v2 [cs.AI] UPDATED)
76. Generalizing electrocardiogram delineation -- Training convolutional neural networks with synthetic data augmentation. (arXiv:2111.12996v2 [cs.LG] UPDATED)
77. PSI: A Pedestrian Behavior Dataset for Socially Intelligent Autonomous Car. (arXiv:2112.02604v2 [cs.CV] UPDATED)
78. A Review for Deep Reinforcement Learning in Atari:Benchmarks, Challenges, and Solutions. (arXiv:2112.04145v3 [cs.AI] UPDATED)
79. Causal Attention for Interpretable and Generalizable Graph Classification. (arXiv:2112.15089v2 [cs.LG] UPDATED)
80. What is Event Knowledge Graph: A Survey. (arXiv:2112.15280v2 [cs.LG] UPDATED)
81. Zeroth-Order Actor-Critic. (arXiv:2201.12518v3 [cs.LG] UPDATED)
82. AutoSNN: Towards Energy-Efficient Spiking Neural Networks. (arXiv:2201.12738v3 [cs.NE] UPDATED)
83. Network-level Safety Metrics for Overall Traffic Safety Assessment: A Case Study. (arXiv:2201.13229v2 [cs.CV] UPDATED)
84. A Temporal-Difference Approach to Policy Gradient Estimation. (arXiv:2202.02396v2 [cs.LG] UPDATED)
85. Class Distance Weighted Cross-Entropy Loss for Ulcerative Colitis Severity Estimation. (arXiv:2202.05167v2 [eess.IV] UPDATED)
86. Support Vectors and Gradient Dynamics of Single-Neuron ReLU Networks. (arXiv:2202.05510v2 [cs.LG] UPDATED)
87. Learning to Mitigate AI Collusion on Economic Platforms. (arXiv:2202.07106v2 [cs.MA] UPDATED)
88. Data-SUITE: Data-centric identification of in-distribution incongruous examples. (arXiv:2202.08836v3 [cs.LG] UPDATED)
89. Bridging the Gap Between Patient-specific and Patient-independent Seizure Prediction via Knowledge Distillation. (arXiv:2202.12598v2 [cs.LG] UPDATED)
90. Interventions, Where and How? Experimental Design for Causal Models at Scale. (arXiv:2203.02016v2 [cs.LG] UPDATED)
91. Voice-Face Homogeneity Tells Deepfake. (arXiv:2203.02195v3 [cs.CV] UPDATED)
92. Learning Markov Games with Adversarial Opponents: Efficient Algorithms and Fundamental Limits. (arXiv:2203.06803v3 [cs.LG] UPDATED)
93. Calibration of Derivative Pricing Models: a Multi-Agent Reinforcement Learning Perspective. (arXiv:2203.06865v2 [q-fin.MF] UPDATED)
94. WCL-BBCD: A Contrastive Learning and Knowledge Graph Approach to Named Entity Recognition. (arXiv:2203.06925v4 [cs.CL] UPDATED)
95. SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification. (arXiv:2204.09826v3 [cs.CV] UPDATED)
96. RelViT: Concept-guided Vision Transformer for Visual Relational Reasoning. (arXiv:2204.11167v2 [cs.CV] UPDATED)
97. Using Constraint Programming and Graph Representation Learning for Generating Interpretable Cloud Security Policies. (arXiv:2205.01240v4 [cs.CR] UPDATED)
98. Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework. (arXiv:2205.03860v4 [cs.CV] UPDATED)
99. Explainable Deep Learning Methods in Medical Imaging Diagnosis: A Survey. (arXiv:2205.04766v2 [eess.IV] UPDATED)
100. FIND:Explainable Framework for Meta-learning. (arXiv:2205.10362v2 [cs.LG] UPDATED)
101. Personalized Federated Learning with Server-Side Information. (arXiv:2205.11044v2 [cs.LG] UPDATED)
102. Teaching Models to Express Their Uncertainty in Words. (arXiv:2205.14334v2 [cs.CL] UPDATED)
103. Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games. (arXiv:2205.15879v2 [cs.AI] UPDATED)
104. Learning Distributed and Fair Policies for Network Load Balancing as Markov Potential Game. (arXiv:2206.01451v2 [cs.AI] UPDATED)
105. Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank. (arXiv:2206.01702v2 [cs.IR] UPDATED)
106. Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning. (arXiv:2206.01888v2 [cs.LG] UPDATED)
107. Stochastic Multiple Target Sampling Gradient Descent. (arXiv:2206.01934v2 [cs.LG] UPDATED)
108. Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography. (arXiv:2206.02225v2 [eess.IV] UPDATED)
109. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v3 [cs.CV] UPDATED)
110. Sparse Fusion Mixture-of-Experts are Domain Generalizable Learners. (arXiv:2206.04046v2 [cs.CV] UPDATED)
111. TwiBot-22: Towards Graph-Based Twitter Bot Detection. (arXiv:2206.04564v2 [cs.SI] UPDATED)
112. COSTA: Covariance-Preserving Feature Augmentation for Graph Contrastive Learning. (arXiv:2206.04726v2 [cs.LG] UPDATED)
113. In Defense of Core-set: A Density-aware Core-set Selection for Active Learning. (arXiv:2206.04838v2 [cs.LG] UPDATED)
114. Neural Laplace: Learning diverse classes of differential equations in the Laplace domain. (arXiv:2206.04843v2 [cs.LG] UPDATED)
115. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v2 [cs.AI] UPDATED)

