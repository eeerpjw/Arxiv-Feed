# Your interest papers
---
## cs.CV
---
### On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v1 [physics.med-ph])
- Authors : Nicholas Hindley, Neha Koonjoo, Christopher Chiu, Tess Reynolds, Bo Zhu, Danyal Bhutto, Chiara Paganelli
- Link : [http://arxiv.org/abs/2202.05267](http://arxiv.org/abs/2202.05267)
> ABSTRACT  :  MRI-guidance techniques that dynamically adapt radiation beams to follow tumor motion in real-time will lead to more accurate cancer treatments and reduced collateral healthy tissue damage. The gold-standard for reconstruction of undersampled MR data is compressed sensing (CS) which is computationally slow and limits the rate that images can be available for real-time adaptation. Here, we demonstrate the use of automated transform by manifold approximation (AUTOMAP), a generalized framework that maps raw MR signal to the target image domain, to rapidly reconstruct images from undersampled radial k-space data. The AUTOMAP neural network was trained to reconstruct images from a golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on lung cancer patient data and generic images from ImageNet. Model training was subsequently augmented with motion-encoded k-space data derived from videos in the YouTube-8M dataset to encourage motion robust reconstruction. We find that AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with much shorter processing times after initial fine-tuning on retrospectively acquired lung cancer patient data. Validation of motion-trained models with a virtual dynamic lung tumor phantom showed that the generalized motion properties learned from YouTube lead to improved target tracking accuracy. Our work shows that AUTOMAP can achieve real-time, accurate reconstruction of radial data. These findings imply that neural-network-based reconstruction is potentially superior to existing approaches for real-time image guidance applications.  
### Unsupervised **HDR** Imaging: What Can Be Learned from a Single 8-bit Video?. (arXiv:2202.05522v1 [cs.GR])
- Authors : Francesco Banterle, Demetris Marnerides, Kurt Debattista, Thomas Bashford
- Link : [http://arxiv.org/abs/2202.05522](http://arxiv.org/abs/2202.05522)
> ABSTRACT  :  Recently, Deep Learning-based methods for inverse tone-mapping standard dynamic range (SDR) images to obtain **high dynamic range** (**HDR**) images have become very popular. These methods manage to fill over-exposed areas convincingly both in terms of details and dynamic range. Typically, these methods, to be effective, need to learn from large datasets and to transfer this knowledge to the network weights. In this work, we tackle this problem from a completely different perspective. What can we learn from a single SDR video? With the presented zero-shot approach, we show that, in many cases, a single SDR video is sufficient to be able to generate an **HDR** video of the same quality or better than other state-of-the-art methods.  
### A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
- Authors : Pascal Peter
- Link : [http://arxiv.org/abs/2202.05623](http://arxiv.org/abs/2202.05623)
> ABSTRACT  :  Classic image inpainting is a **restoration** method that reconstructs missing image parts. However, a carefully selected mask of known pixels that yield a high quality inpainting can also act as a sparse image representation. This challenging spatial optimisation problem is essential for practical applications such as compression. So far, it has been almost exclusively addressed by model-based approaches. First attempts with neural networks seem promising, but are tailored towards specific inpainting operators or require postprocessing. To address this issue, we propose the first generative adversarial network for spatial inpainting data optimisation. In contrast to previous approaches, it allows joint training of an inpainting generator and a corresponding mask optimisation network. With a Wasserstein distance, we ensure that our inpainting results accurately reflect the statistics of natural images. This yields significant improvements in visual quality and speed over conventional stochastic models and also outperforms current spatial optimisation networks.  
### NITI: Training Integer Neural Networks Using Integer-only Arithmetic. (arXiv:2009.13108v2 [cs.CV] UPDATED)
- Authors : Maolin Wang, Seyedramin Rasoulinezhad
- Link : [http://arxiv.org/abs/2009.13108](http://arxiv.org/abs/2009.13108)
> ABSTRACT  :  While integer arithmetic has been widely adopted for improved performance in deep quantized neural network inference, training remains a task primarily executed using floating point arithmetic. This is because both **high dynamic range** and numerical accuracy are central to the success of most modern training algorithms. However, due to its potential for computational, storage and energy advantages in hardware accelerators, neural network training methods that can be implemented with low precision integer-only arithmetic remains an active research challenge. In this paper, we present NITI, an efficient deep neural network training framework that stores all parameters and intermediate values as integers, and computes exclusively with integer arithmetic. A pseudo stochastic rounding scheme that eliminates the need for external random number generation is proposed to facilitate conversion from wider intermediate results to low precision storage. Furthermore, a cross-entropy loss backpropagation scheme computed with integer-only arithmetic is proposed. A proof-of-concept open-source software implementation of NITI that utilizes native 8-bit integer operations in modern GPUs to achieve end-to-end training is presented. When compared with an equivalent training setup implemented with floating point storage and arithmetic, NITI achieves negligible accuracy degradation on the MNIST and CIFAR10 datasets using 8-bit integer storage and computation. On ImageNet, 16-bit integers are needed for weight accumulation with an 8-bit datapath. This achieves training results comparable to all-floating-point implementations.  
### Cross-Camera Convolutional **Color Constancy**. (arXiv:2011.11890v6 [cs.CV] UPDATED)
- Authors : **Mahmoud Afifi**, Chloe LeGendre, Ta Tsai, Francois Bleibel
- Link : [http://arxiv.org/abs/2011.11890](http://arxiv.org/abs/2011.11890)
> ABSTRACT  :  We present "Cross-Camera Convolutional **Color Constancy**" (C5), a learning-based method, trained on images from multiple cameras, that accurately estimates a scene's illuminant color from raw images captured by a new camera previously unseen during training. C5 is a hypernetwork-like extension of the convolutional **color constancy** (CCC) approach: C5 learns to generate the weights of a CCC model that is then evaluated on the input image, with the CCC weights dynamically adapted to different input content. Unlike prior cross-camera **color constancy** models, which are usually designed to be agnostic to the spectral properties of test-set images from unobserved cameras, C5 approaches this problem through the lens of transductive inference: additional unlabeled images are provided as input to the model at test time, which allows the model to calibrate itself to the spectral properties of the test-set camera during inference. C5 achieves state-of-the-art accuracy for cross-camera **color constancy** on several datasets, is fast to evaluate (~7 and ~90 ms per image on a GPU or CPU, respectively), and requires little memory (~2 MB), and thus is a practical solution to the problem of calibration-free automatic white balance for mobile photography.  
## eess.IV
---
### On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v1 [physics.med-ph])
- Authors : Nicholas Hindley, Neha Koonjoo, Christopher Chiu, Tess Reynolds, Bo Zhu, Danyal Bhutto, Chiara Paganelli
- Link : [http://arxiv.org/abs/2202.05267](http://arxiv.org/abs/2202.05267)
> ABSTRACT  :  MRI-guidance techniques that dynamically adapt radiation beams to follow tumor motion in real-time will lead to more accurate cancer treatments and reduced collateral healthy tissue damage. The gold-standard for reconstruction of undersampled MR data is compressed sensing (CS) which is computationally slow and limits the rate that images can be available for real-time adaptation. Here, we demonstrate the use of automated transform by manifold approximation (AUTOMAP), a generalized framework that maps raw MR signal to the target image domain, to rapidly reconstruct images from undersampled radial k-space data. The AUTOMAP neural network was trained to reconstruct images from a golden-angle radial acquisition, a benchmark for motion-sensitive imaging, on lung cancer patient data and generic images from ImageNet. Model training was subsequently augmented with motion-encoded k-space data derived from videos in the YouTube-8M dataset to encourage motion robust reconstruction. We find that AUTOMAP-reconstructed radial k-space has equivalent accuracy to CS but with much shorter processing times after initial fine-tuning on retrospectively acquired lung cancer patient data. Validation of motion-trained models with a virtual dynamic lung tumor phantom showed that the generalized motion properties learned from YouTube lead to improved target tracking accuracy. Our work shows that AUTOMAP can achieve real-time, accurate reconstruction of radial data. These findings imply that neural-network-based reconstruction is potentially superior to existing approaches for real-time image guidance applications.  
### Structured light **dark**-field microscope. (arXiv:2202.05357v1 [eess.IV])
- Authors : Shaobai Li, Bofan Song, Rongguang Liang
- Link : [http://arxiv.org/abs/2202.05357](http://arxiv.org/abs/2202.05357)
> ABSTRACT  :  A resolution-enhanced **dark**-field microscope by structured light illumination is proposed to improve resolution and contrast. A set of phase-shifted fringes are projected to the sample plane at large angle to capture modulated **dark**-field images, from which resolution- and contrast-enhanced **dark**-field image, as well as sectioned **dark**-field image, can be obtained. Human tissue samples are tested to demonstrate the resolution and contrast **enhancement**. The system can be implemented in transmission-mode and reflectance-mode, with potential applications ranging from defect detection to biomedical imaging.  
### Unsupervised **HDR** Imaging: What Can Be Learned from a Single 8-bit Video?. (arXiv:2202.05522v1 [cs.GR])
- Authors : Francesco Banterle, Demetris Marnerides, Kurt Debattista, Thomas Bashford
- Link : [http://arxiv.org/abs/2202.05522](http://arxiv.org/abs/2202.05522)
> ABSTRACT  :  Recently, Deep Learning-based methods for inverse tone-mapping standard dynamic range (SDR) images to obtain **high dynamic range** (**HDR**) images have become very popular. These methods manage to fill over-exposed areas convincingly both in terms of details and dynamic range. Typically, these methods, to be effective, need to learn from large datasets and to transfer this knowledge to the network weights. In this work, we tackle this problem from a completely different perspective. What can we learn from a single SDR video? With the presented zero-shot approach, we show that, in many cases, a single SDR video is sufficient to be able to generate an **HDR** video of the same quality or better than other state-of-the-art methods.  
### A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
- Authors : Pascal Peter
- Link : [http://arxiv.org/abs/2202.05623](http://arxiv.org/abs/2202.05623)
> ABSTRACT  :  Classic image inpainting is a **restoration** method that reconstructs missing image parts. However, a carefully selected mask of known pixels that yield a high quality inpainting can also act as a sparse image representation. This challenging spatial optimisation problem is essential for practical applications such as compression. So far, it has been almost exclusively addressed by model-based approaches. First attempts with neural networks seem promising, but are tailored towards specific inpainting operators or require postprocessing. To address this issue, we propose the first generative adversarial network for spatial inpainting data optimisation. In contrast to previous approaches, it allows joint training of an inpainting generator and a corresponding mask optimisation network. With a Wasserstein distance, we ensure that our inpainting results accurately reflect the statistics of natural images. This yields significant improvements in visual quality and speed over conventional stochastic models and also outperforms current spatial optimisation networks.  
## cs.LG
---
### Explainable Machine Learning for Breakdown Prediction in High Gradient RF Cavities. (arXiv:2202.05610v1 [physics.acc-ph])
- Authors : Christoph Obermair, Thomas Cartier, Andrea Apollonio, William Millar, Lukas Felsberger, Lorenz Fischl, Holger Severin, Daniel Wollmann, Walter Wuensch, Nuria Catalan, Franz Pernkopf, Graeme Burt
- Link : [http://arxiv.org/abs/2202.05610](http://arxiv.org/abs/2202.05610)
> ABSTRACT  :  Radio Frequency (RF) breakdowns are one of the most prevalent limiting factors in RF cavities for particle accelerators. During a breakdown, field **enhancement** associated with small deformations on the cavity surface results in electrical arcs. Such arcs lead to beam aborts, reduce machine availability and can cause irreparable damage on the RF cavity surface. In this paper, we propose a machine learning strategy to discover breakdown precursors in CERN's Compact Linear Collider (CLIC) accelerating structures. By interpreting the parameters of the learned models with explainable Artificial Intelligence (AI), we reverse-engineer physical properties for deriving fast, reliable, and simple rule based models. Based on 6 months of historical data and dedicated experiments, our models show fractions of data with high influence on the occurrence of breakdowns. Specifically, it is shown that in many cases a rise of the vacuum pressure is observed before a breakdown is detected with the current interlock sensors.  
### A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
- Authors : Pascal Peter
- Link : [http://arxiv.org/abs/2202.05623](http://arxiv.org/abs/2202.05623)
> ABSTRACT  :  Classic image inpainting is a **restoration** method that reconstructs missing image parts. However, a carefully selected mask of known pixels that yield a high quality inpainting can also act as a sparse image representation. This challenging spatial optimisation problem is essential for practical applications such as compression. So far, it has been almost exclusively addressed by model-based approaches. First attempts with neural networks seem promising, but are tailored towards specific inpainting operators or require postprocessing. To address this issue, we propose the first generative adversarial network for spatial inpainting data optimisation. In contrast to previous approaches, it allows joint training of an inpainting generator and a corresponding mask optimisation network. With a Wasserstein distance, we ensure that our inpainting results accurately reflect the statistics of natural images. This yields significant improvements in visual quality and speed over conventional stochastic models and also outperforms current spatial optimisation networks.  
### A Novel Speech Intelligibility **Enhancement** Model based on CanonicalCorrelation and Deep Learning. (arXiv:2202.05756v1 [cs.SD])
- Authors : Tassadaq Hussain, Muhammad Diyan, Mandar Gogate, Kia Dashtipour, Ahsan Adeel, Yu Tsao, Amir Hussain
- Link : [http://arxiv.org/abs/2202.05756](http://arxiv.org/abs/2202.05756)
> ABSTRACT  :  Current deep learning (DL) based approaches to speech intelligibility **enhancement** in noisy environments are often trained to minimise the feature distance between noise-free speech and enhanced speech signals. Despite improving the speech quality, such approaches do not deliver required levels of speech intelligibility in everyday noisy environments . Intelligibility-oriented (I-O) loss functions have recently been developed to train DL approaches for robust speech **enhancement**. Here, we formulate, for the first time, a novel canonical correlation based I-O loss function to more effectively train DL algorithms. Specifically, we present a canonical-correlation based short-time objective intelligibility (CC-STOI) cost function to train a fully convolutional neural network (FCN) model. We carry out comparative simulation experiments to show that our CC-STOI based speech **enhancement** framework outperforms state-of-the-art DL models trained with conventional distance-based and STOI-based loss functions, using objective and subjective evaluation measures for case of both unseen speakers and noises. Ongoing future work is evaluating the proposed approach for design of robust hearing-assistive technology.  
## cs.AI
---
# Paper List
---
## cs.CV
---
**78** new papers in cs.CV:-) 
1. On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v1 [physics.med-ph])
2. HNF-Netv2 for Brain Tumor Segmentation using multi-modal MR Imaging. (arXiv:2202.05268v1 [eess.IV])
3. A Plug-and-Play Approach to Multiparametric Quantitative MRI: Image Reconstruction using Pre-Trained Deep Denoisers. (arXiv:2202.05269v1 [eess.IV])
4. A Deep Learning Approach for Digital ColorReconstruction of Lenticular Films. (arXiv:2202.05270v1 [eess.IV])
5. A Field of Experts Prior for Adapting Neural Networks at Test Time. (arXiv:2202.05271v1 [cs.CV])
6. Towards a Guideline for Evaluation Metrics in Medical Image Segmentation. (arXiv:2202.05273v1 [eess.IV])
7. Motion Puzzle: Arbitrary Motion Style Transfer by Body Part. (arXiv:2202.05274v1 [cs.GR])
8. Face Beneath the Ink: Synthetic Data and Tattoo Removal with Application to Face Recognition. (arXiv:2202.05297v1 [cs.CV])
9. Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks. (arXiv:2202.05306v1 [cs.LG])
10. Mining the manifolds of deep generative models for multiple data-consistent solutions of ill-posed tomographic imaging problems. (arXiv:2202.05311v1 [eess.IV])
11. Describing image focused in cognitive and visual details for visually impaired people: An approach to generating inclusive paragraphs. (arXiv:2202.05331v1 [cs.CV])
12. Learning the Pedestrian-Vehicle Interaction for Pedestrian Trajectory Prediction. (arXiv:2202.05334v1 [cs.CV])
13. Dynamic Background Subtraction by Generative Neural Networks. (arXiv:2202.05336v1 [eess.IV])
14. Coded ResNeXt: a network for designing disentangled information paths. (arXiv:2202.05343v1 [cs.CV])
15. Domain Adversarial Training: A Game Perspective. (arXiv:2202.05352v1 [cs.LG])
16. Optimal Transport for Super Resolution Applied to Astronomy Imaging. (arXiv:2202.05354v1 [eess.IV])
17. The MeLa BitChute Dataset. (arXiv:2202.05364v1 [cs.SI])
18. Give me a knee radiograph, I will tell you where the knee joint area is: a deep convolutional neural network adventure. (arXiv:2202.05382v1 [eess.IV])
19. Including Facial Expressions in Contextual Embeddings for Sign Language Generation. (arXiv:2202.05383v1 [cs.CL])
20. Incremental Learning of Structured Memory via Closed-Loop Transcription. (arXiv:2202.05411v1 [cs.CV])
21. ACORT: A Compact Object Relation Transformer for Parameter Efficient Image Captioning. (arXiv:2202.05451v1 [cs.CV])
22. WAD-CMSN: Wasserstein Distance based Cross-Modal Semantic Network for Zero-Shot Sketch-Based Image Retrieval. (arXiv:2202.05465v1 [cs.CV])
23. Bench-Marking And Improving Arabic Automatic Image Captioning Through The Use Of Multi-Task Learning Paradigm. (arXiv:2202.05474v1 [cs.CV])
24. Exemplar-free Online Continual Learning. (arXiv:2202.05491v1 [cs.CV])
25. Entroformer: A Transformer-based Entropy Model for Learned Image Compression. (arXiv:2202.05492v1 [eess.IV])
26. Multi-Modal Fusion for Sensorimotor Coordination in Steering Angle Prediction. (arXiv:2202.05500v1 [cs.CV])
27. Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer. (arXiv:2202.05508v1 [cs.CV])
28. Dilated convolutional neural network-based deep reference picture generation for video compression. (arXiv:2202.05514v1 [eess.IV])
29. Unsupervised **HDR** Imaging: What Can Be Learned from a Single 8-bit Video?. (arXiv:2202.05522v1 [cs.GR])
30. Video-driven Neural Physically-based Facial Asset for Production. (arXiv:2202.05592v1 [cs.CV])
31. A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
32. Artemis: Articulated Neural Pets with Appearance and Motion synthesis. (arXiv:2202.05628v1 [cs.GR])
33. Vehicle and License Plate Recognition with Novel Dataset for Toll Collection. (arXiv:2202.05631v1 [eess.IV])
34. Tiny Object Tracking: A Large-scale Dataset and A Baseline. (arXiv:2202.05659v1 [cs.CV])
35. SuperCon: Supervised Contrastive Learning for Imbalanced Skin Lesion Classification. (arXiv:2202.05685v1 [cs.CV])
36. Towards Adversarially Robust Deepfake Detection: An Ensemble Approach. (arXiv:2202.05687v1 [cs.LG])
37. Deep soccer captioning with transformer: dataset, semantics-related losses, and multi-level evaluation. (arXiv:2202.05728v1 [cs.CV])
38. Patch-NetVLAD+: Learned patch descriptor and weighted matching strategy for place recognition. (arXiv:2202.05738v1 [cs.CV])
39. Borrowing from yourself: Faster future video segmentation with partial channel update. (arXiv:2202.05748v1 [cs.CV])
40. Assessing Privacy Risks from Feature Vector Reconstruction Attacks. (arXiv:2202.05760v1 [cs.CR])
41. Multi-Modal Knowledge Graph Construction and Application: A Survey. (arXiv:2202.05786v1 [cs.AI])
42. Meta-learning with GANs for anomaly detection, with deployment in high-speed rail inspection system. (arXiv:2202.05795v1 [cs.LG])
43. CLIPasso: Semantically-Aware Object Sketching. (arXiv:2202.05822v1 [cs.GR])
44. SafePicking: Learning Safe Object Extraction via Object-Level Mapping. (arXiv:2202.05832v1 [cs.RO])
45. Multiple Object Tracking: A Literature Review. (arXiv:1409.7618v5 [cs.CV] UPDATED)
46. Filter Pruning by Switching to Neighboring CNNs with Good Attributes. (arXiv:1904.03961v2 [cs.CV] UPDATED)
47. Puzzle-AE: Novelty Detection in Images through Solving Puzzles. (arXiv:2008.12959v5 [cs.CV] UPDATED)
48. NITI: Training Integer Neural Networks Using Integer-only Arithmetic. (arXiv:2009.13108v2 [cs.CV] UPDATED)
49. Cross-Camera Convolutional **Color Constancy**. (arXiv:2011.11890v6 [cs.CV] UPDATED)
50. Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v3 [cs.LG] UPDATED)
51. Mitigating Bias in Calibration Error Estimation. (arXiv:2012.08668v3 [cs.LG] UPDATED)
52. Single Model Deep Learning on Imbalanced Small Datasets for Skin Lesion Classification. (arXiv:2102.01284v2 [cs.CV] UPDATED)
53. Graph-based Facial Affect Analysis: A Review. (arXiv:2103.15599v6 [cs.CV] UPDATED)
54. Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion Prediction. (arXiv:2104.00563v3 [cs.RO] UPDATED)
55. Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection. (arXiv:2106.01483v2 [cs.CV] UPDATED)
56. End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB. (arXiv:2107.05287v2 [cs.CV] UPDATED)
57. PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows. (arXiv:2107.05893v3 [cs.CV] UPDATED)
58. Perception-and-Regulation Network for Salient Object Detection. (arXiv:2107.12560v2 [cs.CV] UPDATED)
59. Are socially-aware trajectory prediction models really socially-aware?. (arXiv:2108.10879v2 [cs.CV] UPDATED)
60. YOLOP: You Only Look Once for Panoptic Driving Perception. (arXiv:2108.11250v6 [cs.CV] UPDATED)
61. A Decidability-Based Loss Function. (arXiv:2109.05524v2 [cs.CV] UPDATED)
62. UMPNet: Universal Manipulation Policy Network for Articulated Objects. (arXiv:2109.05668v4 [cs.CV] UPDATED)
63. Holistic Semi-Supervised Approaches for EEG Representation Learning. (arXiv:2109.11732v2 [cs.LG] UPDATED)
64. Camera Calibration through Camera Projection Loss. (arXiv:2110.03479v3 [cs.CV] UPDATED)
65. EchoVPR: Echo State Networks for Visual Place Recognition. (arXiv:2110.05572v3 [cs.CV] UPDATED)
66. CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP. (arXiv:2110.11316v2 [cs.LG] UPDATED)
67. Longitudinal Analysis of Mask and No-Mask on Child Face Recognition. (arXiv:2111.00121v4 [cs.CV] UPDATED)
68. Frequency-Aware Physics-Inspired Degradation Model for Real-World Image Super-Resolution. (arXiv:2111.03301v2 [eess.IV] UPDATED)
69. Imagine by Reasoning: A Reasoning-Based Implicit Semantic Data Augmentation for Long-Tailed Classification. (arXiv:2112.07928v2 [cs.CV] UPDATED)
70. A New Deep Hybrid Boosted and Ensemble Learning-based Brain Tumor Analysis using MRI. (arXiv:2201.05373v2 [eess.IV] UPDATED)
71. Eikonal Fields for Refractive Novel-View Synthesis. (arXiv:2202.00948v2 [cs.GR] UPDATED)
72. Weakly Supervised Nuclei Segmentation via Instance Learning. (arXiv:2202.01564v2 [eess.IV] UPDATED)
73. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v2 [cs.CV] UPDATED)
74. Integrated Multiscale Domain Adaptive YOLO. (arXiv:2202.03527v2 [cs.CV] UPDATED)
75. Towards the automated large-scale reconstruction of past road networks from historical maps. (arXiv:2202.04883v2 [cs.CV] UPDATED)
76. Spherical Transformer. (arXiv:2202.04942v2 [cs.CV] UPDATED)
77. Feature-level augmentation to improve robustness of deep neural networks to affine transformations. (arXiv:2202.05152v2 [cs.CV] UPDATED)
78. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v2 [cs.RO] UPDATED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. On **Real-time** Image Reconstruction with Neural Networks for MRI-guided Radiotherapy. (arXiv:2202.05267v1 [physics.med-ph])
2. HNF-Netv2 for Brain Tumor Segmentation using multi-modal MR Imaging. (arXiv:2202.05268v1 [eess.IV])
3. A Plug-and-Play Approach to Multiparametric Quantitative MRI: Image Reconstruction using Pre-Trained Deep Denoisers. (arXiv:2202.05269v1 [eess.IV])
4. A Deep Learning Approach for Digital ColorReconstruction of Lenticular Films. (arXiv:2202.05270v1 [eess.IV])
5. A Field of Experts Prior for Adapting Neural Networks at Test Time. (arXiv:2202.05271v1 [cs.CV])
6. Towards a Guideline for Evaluation Metrics in Medical Image Segmentation. (arXiv:2202.05273v1 [eess.IV])
7. Mining the manifolds of deep generative models for multiple data-consistent solutions of ill-posed tomographic imaging problems. (arXiv:2202.05311v1 [eess.IV])
8. Dynamic Background Subtraction by Generative Neural Networks. (arXiv:2202.05336v1 [eess.IV])
9. Optimal Transport for Super Resolution Applied to Astronomy Imaging. (arXiv:2202.05354v1 [eess.IV])
10. DDoS-UNet: Incorporating temporal information using Dynamic Dual-channel UNet for enhancing super-resolution of dynamic MRI. (arXiv:2202.05355v1 [physics.med-ph])
11. Structured light **dark**-field microscope. (arXiv:2202.05357v1 [eess.IV])
12. Give me a knee radiograph, I will tell you where the knee joint area is: a deep convolutional neural network adventure. (arXiv:2202.05382v1 [eess.IV])
13. Entroformer: A Transformer-based Entropy Model for Learned Image Compression. (arXiv:2202.05492v1 [eess.IV])
14. Dilated convolutional neural network-based deep reference picture generation for video compression. (arXiv:2202.05514v1 [eess.IV])
15. Unsupervised **HDR** Imaging: What Can Be Learned from a Single 8-bit Video?. (arXiv:2202.05522v1 [cs.GR])
16. A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
17. Vehicle and License Plate Recognition with Novel Dataset for Toll Collection. (arXiv:2202.05631v1 [eess.IV])
18. Cross-Block Difference Guided Fast CU Partition for VVC Intra Coding. (arXiv:2202.05677v1 [eess.IV])
19. Frequency-Aware Physics-Inspired Degradation Model for Real-World Image Super-Resolution. (arXiv:2111.03301v2 [eess.IV] UPDATED)
20. A New Deep Hybrid Boosted and Ensemble Learning-based Brain Tumor Analysis using MRI. (arXiv:2201.05373v2 [eess.IV] UPDATED)
21. Weakly Supervised Nuclei Segmentation via Instance Learning. (arXiv:2202.01564v2 [eess.IV] UPDATED)
## cs.LG
---
**171** new papers in cs.LG:-) 
1. Towards a Guideline for Evaluation Metrics in Medical Image Segmentation. (arXiv:2202.05273v1 [eess.IV])
2. Translation and Rotation Equivariant Normalizing Flow (TRENF) for Optimal Cosmological Analysis. (arXiv:2202.05282v1 [astro-ph.CO])
3. On One-Bit Quantization. (arXiv:2202.05292v1 [cs.IT])
4. Universal Learning Waveform Selection Strategies for Adaptive Target Tracking. (arXiv:2202.05294v1 [cs.IT])
5. Trust in AI: Interpretability is not necessary or sufficient, while black-box interaction is necessary and sufficient. (arXiv:2202.05302v1 [cs.LG])
6. Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks. (arXiv:2202.05306v1 [cs.LG])
7. Personalization Improves Privacy-Accuracy Tradeoffs in Federated Optimization. (arXiv:2202.05318v1 [stat.ML])
8. Describing image focused in cognitive and visual details for visually impaired people: An approach to generating inclusive paragraphs. (arXiv:2202.05331v1 [cs.CV])
9. Factored World Models for Zero-Shot Generalization in Robotic Manipulation. (arXiv:2202.05333v1 [cs.RO])
10. Dynamic Background Subtraction by Generative Neural Networks. (arXiv:2202.05336v1 [eess.IV])
11. Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning. (arXiv:2202.05338v1 [cs.CY])
12. Coded ResNeXt: a network for designing disentangled information paths. (arXiv:2202.05343v1 [cs.CV])
13. Development and Validation of an AI-Driven Model for the La Rance Tidal Barrage: A Generalisable Case Study. (arXiv:2202.05347v1 [cs.LG])
14. Domain Adversarial Training: A Game Perspective. (arXiv:2202.05352v1 [cs.LG])
15. DDoS-UNet: Incorporating temporal information using Dynamic Dual-channel UNet for enhancing super-resolution of dynamic MRI. (arXiv:2202.05355v1 [physics.med-ph])
16. Including Facial Expressions in Contextual Embeddings for Sign Language Generation. (arXiv:2202.05383v1 [cs.CL])
17. Robust, Deep, and Reinforcement Learning for Management of Communication and Power Networks. (arXiv:2202.05395v1 [cs.LG])
18. Enhancing ASR for Stuttered Speech with Limited Data Using Detect and Pass. (arXiv:2202.05396v1 [eess.AS])
19. Neural Architecture Search for Energy Efficient Always-on Audio Models. (arXiv:2202.05397v1 [eess.AS])
20. PARSE: Pairwise Alignment of Representations in Semi-Supervised EEG Learning for Emotion Recognition. (arXiv:2202.05400v1 [cs.LG])
21. Do People Engage Cognitively with AI? Impact of AI Assistance on Incidental Learning. (arXiv:2202.05402v1 [cs.HC])
22. Learning Temporal Rules from Noisy Timeseries Data. (arXiv:2202.05403v1 [cs.LG])
23. Regularized Q-learning. (arXiv:2202.05404v1 [cs.LG])
24. A Machine-Learning-Aided Visual Analysis Workflow for Investigating Air Pollution Data. (arXiv:2202.05413v1 [cs.LG])
25. A Characterization of Semi-Supervised Adversarially-Robust PAC Learnability. (arXiv:2202.05420v1 [cs.LG])
26. Posterior Consistency for Bayesian Relevance Vector Machines. (arXiv:2202.05422v1 [stat.ML])
27. Understanding Curriculum Learning in Policy Optimization for Solving Combinatorial Optimization Problems. (arXiv:2202.05423v1 [cs.LG])
28. A Survey on Programmatic Weak Supervision. (arXiv:2202.05433v1 [cs.LG])
29. Dual Task Framework for Debiasing Persona-grounded Dialogue Dataset. (arXiv:2202.05435v1 [cs.CL])
30. Minimax Regret Optimization for Robust Machine Learning under Distribution Shift. (arXiv:2202.05436v1 [cs.LG])
31. Invariance Principle Meets Out-of-Distribution Generalization on Graphs. (arXiv:2202.05441v1 [cs.LG])
32. Computational-Statistical Gaps in Reinforcement Learning. (arXiv:2202.05444v1 [cs.LG])
33. Achieving Minimax Rates in Pool-Based Batch Active Learning. (arXiv:2202.05448v1 [cs.LG])
34. ACORT: A Compact Object Relation Transformer for Parameter Efficient Image Captioning. (arXiv:2202.05451v1 [cs.CV])
35. Robust estimation algorithms don't need to know the corruption level. (arXiv:2202.05453v1 [cs.LG])
36. Conditional Contrastive Learning with Kernel. (arXiv:2202.05458v1 [cs.LG])
37. Reduced order modeling with Barlow Twins self-supervised learning: Navigating the space between linear and nonlinear solution manifolds. (arXiv:2202.05460v1 [cs.CE])
38. Jigsaw Puzzle: Selective Backdoor Attack to Subvert Malware Classifiers. (arXiv:2202.05470v1 [cs.CR])
39. Concurrent Training of a Control Policy and a State Estimator for Dynamic and Robust Legged Locomotion. (arXiv:2202.05481v1 [cs.RO])
40. Noise Augmentation Is All You Need For FGSM Fast Adversarial Training: Catastrophic Overfitting And Robust Overfitting Require Different Augmentation. (arXiv:2202.05488v1 [cs.LG])
41. Fast and Robust Sparsity Learning over Networks: A Decentralized Surrogate Median Regression Approach. (arXiv:2202.05498v1 [stat.ML])
42. Towards Weakly-Supervised Text Spotting using a Multi-Task Transformer. (arXiv:2202.05508v1 [cs.CV])
43. Support Vectors and Gradient Dynamics for Implicit Bias in ReLU Networks. (arXiv:2202.05510v1 [cs.LG])
44. Electricity Consumption Forecasting for Out-of-distribution Time-of-Use Tariffs. (arXiv:2202.05517v1 [cs.LG])
45. What Does it Mean for a Language Model to Preserve Privacy?. (arXiv:2202.05520v1 [stat.ML])
46. From Unsupervised to Few-shot Graph Anomaly Detection: A Multi-scale Contrastive Learning Approach. (arXiv:2202.05525v1 [cs.LG])
47. Cyclical Curriculum Learning. (arXiv:2202.05531v1 [cs.LG])
48. A Lightweight, Efficient and Explainable-by-Design Convolutional Neural Network for Internet Traffic Classification. (arXiv:2202.05535v1 [cs.LG])
49. Hybridization of Capsule and LSTM Networks for unsupervised anomaly detection on multivariate data. (arXiv:2202.05538v1 [cs.LG])
50. Controlling Confusion via Generalisation Bounds. (arXiv:2202.05560v1 [stat.ML])
51. Shuffle Private Linear Contextual Bandits. (arXiv:2202.05567v1 [cs.LG])
52. On change of measure inequalities for $f$-divergences. (arXiv:2202.05568v1 [stat.ML])
53. Similarity learning for wells based on logging data. (arXiv:2202.05583v1 [cs.LG])
54. Predicting Fuel Consumption in Power Generation Plants using Machine Learning and Neural Networks. (arXiv:2202.05591v1 [cs.LG])
55. The Shapley Value in Machine Learning. (arXiv:2202.05594v1 [cs.LG])
56. Online Decision Transformer. (arXiv:2202.05607v1 [cs.LG])
57. Explainable Machine Learning for Breakdown Prediction in High Gradient RF Cavities. (arXiv:2202.05610v1 [physics.acc-ph])
58. Inference and FDR Control for Simulated Ising Models in High-dimension. (arXiv:2202.05612v1 [stat.ML])
59. CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep Learning. (arXiv:2202.05613v1 [cs.LG])
60. Measuring dissimilarity with diffeomorphism invariance. (arXiv:2202.05614v1 [stat.ML])
61. Long-Time Convergence and Propagation of Chaos for Nonlinear MCMC. (arXiv:2202.05621v1 [stat.ML])
62. A Wasserstein GAN for Joint Learning of Inpainting and its Spatial Optimisation. (arXiv:2202.05623v1 [eess.IV])
63. Scale-free Unconstrained Online Learning for Curved Losses. (arXiv:2202.05630v1 [cs.LG])
64. Efficient Kernel UCB for Contextual Bandits. (arXiv:2202.05638v1 [cs.LG])
65. Bernstein Flows for Flexible Posteriors in Variational Bayes. (arXiv:2202.05650v1 [stat.ML])
66. InterpretTime: a new approach for the systematic evaluation of neural-network interpretability in time series classification. (arXiv:2202.05656v1 [cs.LG])
67. Predictive modeling of microbiological seawater quality classification in karst region using cascade model. (arXiv:2202.05664v1 [cs.LG])
68. Deep artificial neural network for prediction of atrial fibrillation through the analysis of 12-leads standard ECG. (arXiv:2202.05676v1 [eess.SP])
69. Rethinking Graph Convolutional Networks in Knowledge Graph Completion. (arXiv:2202.05679v1 [cs.AI])
70. SuperCon: Supervised Contrastive Learning for Imbalanced Skin Lesion Classification. (arXiv:2202.05685v1 [cs.CV])
71. Graphon-aided Joint Estimation of Multiple Graphs. (arXiv:2202.05686v1 [stat.ML])
72. Towards Adversarially Robust Deepfake Detection: An Ensemble Approach. (arXiv:2202.05687v1 [cs.LG])
73. Continual Learning with Invertible Generative Models. (arXiv:2202.05694v1 [cs.LG])
74. Positive-Unlabeled Domain Adaptation. (arXiv:2202.05695v1 [cs.LG])
75. Machine Learning for Stock Prediction Based on Fundamental Analysis. (arXiv:2202.05702v1 [q-fin.ST])
76. Molecule Generation from Input-Attributions over Graph Convolutional Networks. (arXiv:2202.05703v1 [q-bio.BM])
77. Semi-Supervised GCN for learning Molecular Structure-Activity Relationships. (arXiv:2202.05704v1 [q-bio.BM])
78. Cross Domain Few-Shot Learning via Meta Adversarial Training. (arXiv:2202.05713v1 [cs.LG])
79. Modeling Reservoir Release Using Pseudo-Prospective Learning and Physical Simulations to Predict Water Temperature. (arXiv:2202.05714v1 [cs.LG])
80. Choices, Risks, and Reward Reports: Charting Public Policy for Reinforcement Learning Systems. (arXiv:2202.05716v1 [cs.LG])
81. Audio Defect Detection in Music with Deep Networks. (arXiv:2202.05718v1 [cs.SD])
82. Recovering Stochastic Dynamics via Gaussian Schr\"odinger Bridges. (arXiv:2202.05722v1 [cs.LG])
83. On the Detection of Adaptive Adversarial Attacks in Speaker Verification Systems. (arXiv:2202.05725v1 [cs.CR])
84. SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography. (arXiv:2202.05735v1 [cs.LG])
85. Improving Generalization via Uncertainty Driven Perturbations. (arXiv:2202.05737v1 [cs.LG])
86. Bounded nonlinear forecasts of partially observed geophysical systems with physics-constrained deep learning. (arXiv:2202.05750v1 [stat.ML])
87. A Novel Speech Intelligibility **Enhancement** Model based on CanonicalCorrelation and Deep Learning. (arXiv:2202.05756v1 [cs.SD])
88. Using Random Perturbations to Mitigate Adversarial Attacks on Sentiment Analysis Models. (arXiv:2202.05758v1 [cs.CL])
89. Learning via nonlinear conjugate gradients and depth-varying neural ODEs. (arXiv:2202.05766v1 [cs.LG])
90. A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v1 [cs.LG])
91. Inference of Multiscale Gaussian Graphical Model. (arXiv:2202.05775v1 [stat.ML])
92. A Modern Self-Referential Weight Matrix That Learns to Modify Itself. (arXiv:2202.05780v1 [cs.LG])
93. The Power of Adaptivity in SGD: Self-Tuning Step Sizes with Unbounded Gradients and Affine Variance. (arXiv:2202.05791v1 [stat.ML])
94. Meta-learning with GANs for anomaly detection, with deployment in high-speed rail inspection system. (arXiv:2202.05795v1 [cs.LG])
95. Distributionally Robust Data Join. (arXiv:2202.05797v1 [cs.LG])
96. The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention. (arXiv:2202.05798v1 [cs.LG])
97. Rate-matching the regret lower-bound in the linear quadratic regulator with unknown dynamics. (arXiv:2202.05799v1 [cs.LG])
98. A Newton-type algorithm for federated learning based on incremental Hessian eigenvector sharing. (arXiv:2202.05800v1 [cs.LG])
99. Investigating Power laws in Deep Representation Learning. (arXiv:2202.05808v1 [cs.LG])
100. Distributed saddle point problems for strongly concave-convex functions. (arXiv:2202.05812v1 [math.OC])
101. PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v1 [cs.LG])
102. End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking. (arXiv:2202.05826v1 [cs.LG])
103. Automated Architecture Search for Brain-inspired Hyperdimensional Computing. (arXiv:2202.05827v1 [cs.LG])
104. Learning Fast Samplers for Diffusion Models by Differentiating Through Sample Quality. (arXiv:2202.05830v1 [cs.LG])
105. SafePicking: Learning Safe Object Extraction via Object-Level Mapping. (arXiv:2202.05832v1 [cs.RO])
106. Active Privacy-Utility Trade-off Against Inference in Time-Series Data Sharing. (arXiv:2202.05833v1 [cs.IT])
107. Predicting Out-of-Distribution Error with the Projection Norm. (arXiv:2202.05834v1 [cs.LG])
108. ProMP: Proximal Meta-Policy Search. (arXiv:1810.06784v4 [cs.LG] UPDATED)
109. Error-feedback stochastic modeling strategy for time series forecasting with convolutional neural networks. (arXiv:2002.00717v2 [cs.LG] UPDATED)
110. Multi Type Mean Field Reinforcement Learning. (arXiv:2002.02513v5 [cs.MA] UPDATED)
111. Reducing the Feeder Effect in Public School Admissions: A Bias-aware Analysis for Targeted Interventions. (arXiv:2004.10846v3 [cs.CY] UPDATED)
112. SoK: Certified Robustness for Deep Neural Networks. (arXiv:2009.04131v6 [cs.LG] UPDATED)
113. Contextual Latent-Movements Off-Policy Optimization for Robotic Manipulation Skills. (arXiv:2010.13766v3 [cs.RO] UPDATED)
114. Matrix-wise $\ell_0$-constrained Sparse Nonnegative Least Squares. (arXiv:2011.11066v3 [cs.LG] UPDATED)
115. Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v3 [cs.LG] UPDATED)
116. TACTO: A Fast, Flexible, and Open-source Simulator for High-Resolution Vision-based Tactile Sensors. (arXiv:2012.08456v2 [cs.RO] UPDATED)
117. Mitigating Bias in Calibration Error Estimation. (arXiv:2012.08668v3 [cs.LG] UPDATED)
118. Single Model Deep Learning on Imbalanced Small Datasets for Skin Lesion Classification. (arXiv:2102.01284v2 [cs.CV] UPDATED)
119. A Single-Timescale Method for Stochastic Bilevel Optimization. (arXiv:2102.04671v3 [math.OC] UPDATED)
120. A Witness Two-Sample Test. (arXiv:2102.05573v3 [cs.LG] UPDATED)
121. A nonlinear diffusion method for semi-supervised learning on hypergraphs. (arXiv:2103.14867v2 [cs.LG] UPDATED)
122. Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion Prediction. (arXiv:2104.00563v3 [cs.RO] UPDATED)
123. Model Selection for Time Series Forecasting: Empirical Analysis of Different Estimators. (arXiv:2104.00584v2 [stat.ML] UPDATED)
124. Artificial Neural Network Modeling for Airline Disruption Management. (arXiv:2104.02032v3 [cs.AI] UPDATED)
125. Intuitive Physics Guided Exploration for Sample Efficient Sim2real Transfer. (arXiv:2104.08795v2 [cs.LG] UPDATED)
126. Pairwise Fairness for Ordinal Regression. (arXiv:2105.03153v2 [stat.ML] UPDATED)
127. Reverse Engineering the Neural Tangent Kernel. (arXiv:2106.03186v3 [cs.LG] UPDATED)
128. Policy Finetuning: Bridging Sample-Efficient Offline and Online Reinforcement Learning. (arXiv:2106.04895v2 [cs.LG] UPDATED)
129. DECORE: Deep Compression with Reinforcement Learning. (arXiv:2106.06091v2 [cs.LG] UPDATED)
130. Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v4 [cs.LG] UPDATED)
131. Meta-Interpretive Learning as Metarule Specialisation. (arXiv:2106.07464v6 [cs.LG] UPDATED)
132. On Generalization of Adversarial Imitation Learning and Beyond. (arXiv:2106.10424v3 [cs.LG] UPDATED)
133. Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks. (arXiv:2107.07455v3 [cs.LG] UPDATED)
134. Decentralized Federated Learning: Balancing Communication and Computing Costs. (arXiv:2107.12048v4 [cs.LG] UPDATED)
135. Sparse Communication via Mixed Distributions. (arXiv:2108.02658v2 [cs.LG] UPDATED)
136. Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v3 [cs.CL] UPDATED)
137. Novel split quality measures for stratified multilabel Cross Validation with application to large and sparse gene ontology datasets. (arXiv:2109.01425v2 [cs.LG] UPDATED)
138. Fixed Support Tree-Sliced Wasserstein Barycenter. (arXiv:2109.03431v2 [cs.AI] UPDATED)
139. Desiderata for Representation Learning: A Causal Perspective. (arXiv:2109.03795v2 [stat.ML] UPDATED)
140. Holistic Semi-Supervised Approaches for EEG Representation Learning. (arXiv:2109.11732v2 [cs.LG] UPDATED)
141. EE-Net: Exploitation-Exploration Neural Networks in Contextual Bandits. (arXiv:2110.03177v4 [cs.LG] UPDATED)
142. EchoVPR: Echo State Networks for Visual Place Recognition. (arXiv:2110.05572v3 [cs.CV] UPDATED)
143. Rank-based loss for learning hierarchical representations. (arXiv:2110.05941v2 [cs.LG] UPDATED)
144. Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy Gradient Methods with Entropy Regularization. (arXiv:2110.10117v2 [cs.LG] UPDATED)
145. Collaboration Challenges in Building ML-Enabled Systems: Communication, Documentation, Engineering, and Process. (arXiv:2110.10234v4 [cs.SE] UPDATED)
146. CLOOB: Modern Hopfield Networks with InfoLOOB Outperform CLIP. (arXiv:2110.11316v2 [cs.LG] UPDATED)
147. Self-Initiated Open World Learning for Autonomous AI Agents. (arXiv:2110.11385v2 [cs.AI] UPDATED)
148. SVD-Embedded Deep Autoencoder for MIMO Communications. (arXiv:2111.02359v2 [cs.IT] UPDATED)
149. Unified Group Fairness on Federated Learning. (arXiv:2111.04986v2 [cs.LG] UPDATED)
150. Bayesian Learning via Neural Schr\"odinger-F\"ollmer Flows. (arXiv:2111.10510v7 [stat.ML] UPDATED)
151. Training Robust Zero-Shot Voice Conversion Models with Self-supervised Features. (arXiv:2112.04424v2 [cs.SD] UPDATED)
152. Batch Label Inference and Replacement Attacks in Black-Boxed Vertical Federated Learning. (arXiv:2112.05409v2 [cs.LG] UPDATED)
153. Analyzing a Caching Model. (arXiv:2112.06989v2 [cs.LG] UPDATED)
154. Confidence-Aware Multi-Teacher Knowledge Distillation. (arXiv:2201.00007v2 [cs.LG] UPDATED)
155. Best Arm Identification with a Fixed Budget under a Small Gap. (arXiv:2201.04469v5 [stat.ML] UPDATED)
156. A New Deep Hybrid Boosted and Ensemble Learning-based Brain Tumor Analysis using MRI. (arXiv:2201.05373v2 [eess.IV] UPDATED)
157. Generative Trees: Adversarial and Copycat. (arXiv:2201.11205v2 [cs.LG] UPDATED)
158. NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy. (arXiv:2201.13396v2 [cs.LG] UPDATED)
159. Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning. (arXiv:2202.00907v2 [cs.RO] UPDATED)
160. Understanding Knowledge Integration in Language Models with Graph Convolutions. (arXiv:2202.00964v3 [cs.CL] UPDATED)
161. Decoupling Local and Global Representations of Time Series. (arXiv:2202.02262v2 [cs.LG] UPDATED)
162. SimGRACE: A Simple Framework for Graph Contrastive Learning without Data Augmentation. (arXiv:2202.03104v2 [cs.LG] UPDATED)
163. Conformal prediction for the design problem. (arXiv:2202.03613v3 [cs.LG] UPDATED)
164. A Data-Driven Approach to Robust Hypothesis Testing Using Sinkhorn Uncertainty Sets. (arXiv:2202.04258v2 [stat.ML] UPDATED)
165. Offline Reinforcement Learning with Realizability and Single-policy Concentrability. (arXiv:2202.04634v2 [cs.LG] UPDATED)
166. Learning Latent Causal Dynamics. (arXiv:2202.04828v2 [stat.ML] UPDATED)
167. PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty. (arXiv:2202.05063v2 [cs.LG] UPDATED)
168. Feature-level augmentation to improve robustness of deep neural networks to affine transformations. (arXiv:2202.05152v2 [cs.CV] UPDATED)
169. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v2 [cs.RO] UPDATED)
170. Hierarchical Risk Parity and Minimum Variance Portfolio Design on NIFTY 50 Stocks. (arXiv:2202.02728v1 [q-fin.PM] CROSS LISTED)
171. Discovering Quantum Phase Transitions with Fermionic Neural Networks. (arXiv:2202.05183v1 [physics.comp-ph] CROSS LISTED)
## cs.AI
---
**70** new papers in cs.AI:-) 
1. Trust in AI: Interpretability is not necessary or sufficient, while black-box interaction is necessary and sufficient. (arXiv:2202.05302v1 [cs.LG])
2. Integrating Testing and Operation-related Quantitative Evidences in Assurance Cases to Argue Safety of Data-Driven AI/ML Components. (arXiv:2202.05313v1 [cs.AI])
3. Describing image focused in cognitive and visual details for visually impaired people: An approach to generating inclusive paragraphs. (arXiv:2202.05331v1 [cs.CV])
4. Learning the Pedestrian-Vehicle Interaction for Pedestrian Trajectory Prediction. (arXiv:2202.05334v1 [cs.CV])
5. Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning. (arXiv:2202.05338v1 [cs.CY])
6. Closure operators: Complexity and applications to classification and decision-making. (arXiv:2202.05339v1 [econ.TH])
7. Give me a knee radiograph, I will tell you where the knee joint area is: a deep convolutional neural network adventure. (arXiv:2202.05382v1 [eess.IV])
8. Do People Engage Cognitively with AI? Impact of AI Assistance on Incidental Learning. (arXiv:2202.05402v1 [cs.HC])
9. Learning Temporal Rules from Noisy Timeseries Data. (arXiv:2202.05403v1 [cs.LG])
10. A Survey on Programmatic Weak Supervision. (arXiv:2202.05433v1 [cs.LG])
11. Dual Task Framework for Debiasing Persona-grounded Dialogue Dataset. (arXiv:2202.05435v1 [cs.CL])
12. Computational-Statistical Gaps in Reinforcement Learning. (arXiv:2202.05444v1 [cs.LG])
13. Privacy-preserving Generative Framework Against Membership Inference Attacks. (arXiv:2202.05469v1 [cs.CR])
14. Noise Augmentation Is All You Need For FGSM Fast Adversarial Training: Catastrophic Overfitting And Robust Overfitting Require Different Augmentation. (arXiv:2202.05488v1 [cs.LG])
15. On the preferred extensions of argumentation frameworks: bijections with naive extensions. (arXiv:2202.05506v1 [math.CO])
16. Support Vectors and Gradient Dynamics for Implicit Bias in ReLU Networks. (arXiv:2202.05510v1 [cs.LG])
17. Inference with System W Satisfies Syntax Splitting. (arXiv:2202.05511v1 [cs.AI])
18. MusIAC: An extensible generative framework for Music Infilling Applications with multi-level Control. (arXiv:2202.05528v1 [cs.AI])
19. Cyclical Curriculum Learning. (arXiv:2202.05531v1 [cs.LG])
20. The Shapley Value in Machine Learning. (arXiv:2202.05594v1 [cs.LG])
21. ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization. (arXiv:2202.05599v1 [cs.CL])
22. Online Decision Transformer. (arXiv:2202.05607v1 [cs.LG])
23. Vehicle and License Plate Recognition with Novel Dataset for Toll Collection. (arXiv:2202.05631v1 [eess.IV])
24. InterpretTime: a new approach for the systematic evaluation of neural-network interpretability in time series classification. (arXiv:2202.05656v1 [cs.LG])
25. A Multi-Domain VNE Algorithm based on Load Balancing in the IoT networks. (arXiv:2202.05667v1 [cs.NI])
26. Rethinking Graph Convolutional Networks in Knowledge Graph Completion. (arXiv:2202.05679v1 [cs.AI])
27. Conservative Extensions for Existential Rules. (arXiv:2202.05689v1 [cs.DB])
28. Self-adjusting optimization algorithm for solving the setunion knapsack problem. (arXiv:2202.05698v1 [cs.NE])
29. Axiomatizing consciousness, with applications. (arXiv:2202.05700v1 [cs.LO])
30. Molecule Generation from Input-Attributions over Graph Convolutional Networks. (arXiv:2202.05703v1 [q-bio.BM])
31. Semi-Supervised GCN for learning Molecular Structure-Activity Relationships. (arXiv:2202.05704v1 [q-bio.BM])
32. Cross Domain Few-Shot Learning via Meta Adversarial Training. (arXiv:2202.05713v1 [cs.LG])
33. Deep soccer captioning with transformer: dataset, semantics-related losses, and multi-level evaluation. (arXiv:2202.05728v1 [cs.CV])
34. Patch-NetVLAD+: Learned patch descriptor and weighted matching strategy for place recognition. (arXiv:2202.05738v1 [cs.CV])
35. Constrained Optimization with Dynamic Bound-scaling for Effective NLPBackdoor Defense. (arXiv:2202.05749v1 [cs.CL])
36. Visualising Multiplayer Game Spaces. (arXiv:2202.05773v1 [cs.AI])
37. Multi-Modal Knowledge Graph Construction and Application: A Survey. (arXiv:2202.05786v1 [cs.AI])
38. Answer Set Planning: A Survey. (arXiv:2202.05793v1 [cs.AI])
39. Meta-learning with GANs for anomaly detection, with deployment in high-speed rail inspection system. (arXiv:2202.05795v1 [cs.LG])
40. A Newton-type algorithm for federated learning based on incremental Hessian eigenvector sharing. (arXiv:2202.05800v1 [cs.LG])
41. Investigating Power laws in Deep Representation Learning. (arXiv:2202.05808v1 [cs.LG])
42. The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis. (arXiv:2202.05817v1 [cs.SD])
43. PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v1 [cs.LG])
44. CLIPasso: Semantically-Aware Object Sketching. (arXiv:2202.05822v1 [cs.GR])
45. End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking. (arXiv:2202.05826v1 [cs.LG])
46. SafePicking: Learning Safe Object Extraction via Object-Level Mapping. (arXiv:2202.05832v1 [cs.RO])
47. Multi Type Mean Field Reinforcement Learning. (arXiv:2002.02513v5 [cs.MA] UPDATED)
48. Handling Noisy Labels via One-Step Abductive Multi-Target Learning: An Application to Helicobacter Pylori Segmentation. (arXiv:2011.14956v3 [cs.LG] UPDATED)
49. Mitigating Bias in Calibration Error Estimation. (arXiv:2012.08668v3 [cs.LG] UPDATED)
50. Latent Variable Sequential Set Transformers For Joint Multi-Agent Motion Prediction. (arXiv:2104.00563v3 [cs.RO] UPDATED)
51. Artificial Neural Network Modeling for Airline Disruption Management. (arXiv:2104.02032v3 [cs.AI] UPDATED)
52. DECORE: Deep Compression with Reinforcement Learning. (arXiv:2106.06091v2 [cs.LG] UPDATED)
53. Bellman-consistent Pessimism for Offline Reinforcement Learning. (arXiv:2106.06926v4 [cs.LG] UPDATED)
54. Meta-Interpretive Learning as Metarule Specialisation. (arXiv:2106.07464v6 [cs.LG] UPDATED)
55. On Generalization of Adversarial Imitation Learning and Beyond. (arXiv:2106.10424v3 [cs.LG] UPDATED)
56. On the Evaluation of Neural Code Summarization. (arXiv:2107.07112v2 [cs.SE] UPDATED)
57. Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks. (arXiv:2107.07455v3 [cs.LG] UPDATED)
58. Fixed Support Tree-Sliced Wasserstein Barycenter. (arXiv:2109.03431v2 [cs.AI] UPDATED)
59. SSAST: Self-Supervised Audio Spectrogram Transformer. (arXiv:2110.09784v2 [cs.SD] UPDATED)
60. Self-Initiated Open World Learning for Autonomous AI Agents. (arXiv:2110.11385v2 [cs.AI] UPDATED)
61. Diagnosing Data from ICTs to Provide Focused Assistance in Agricultural Adoptions. (arXiv:2111.00052v2 [cs.CY] UPDATED)
62. Assessing the Fairness of AI Systems: AI Practitioners' Processes, Challenges, and Needs for Support. (arXiv:2112.05675v2 [cs.AI] UPDATED)
63. A First Mathematical Runtime Analysis of the Non-Dominated Sorting Genetic Algorithm II (NSGA-II). (arXiv:2112.08581v2 [cs.NE] UPDATED)
64. Confidence-Aware Multi-Teacher Knowledge Distillation. (arXiv:2201.00007v2 [cs.LG] UPDATED)
65. NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy. (arXiv:2201.13396v2 [cs.LG] UPDATED)
66. Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning. (arXiv:2202.00907v2 [cs.RO] UPDATED)
67. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v2 [cs.CV] UPDATED)
68. Improving short-term bike sharing demand forecast through an irregular convolutional neural network. (arXiv:2202.04376v2 [cs.AI] UPDATED)
69. Learning Latent Causal Dynamics. (arXiv:2202.04828v2 [stat.ML] UPDATED)
70. Visual Servoing for Pose Control of Soft Continuum Arm in a Structured Environment. (arXiv:2202.05200v2 [cs.RO] UPDATED)

