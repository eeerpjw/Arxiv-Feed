# Your interest papers
---
## cs.CV
---
### BATMAN: **Bilateral** Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation. (arXiv:2208.01159v1 [cs.CV])
- Authors : Ye Yu, Jialin Yuan, Gaurav Mittal, Li Fuxin, Mei Chen
- Link : [http://arxiv.org/abs/2208.01159](http://arxiv.org/abs/2208.01159)
> ABSTRACT  :  Video Object Segmentation (VOS) is fundamental to video understanding. Transformer-based methods show significant performance improvement on semi-supervised VOS. However, existing work faces challenges segmenting visually similar objects in close proximity of each other. In this paper, we propose a novel **Bilateral** Attention Transformer in Motion-Appearance Neighboring space (BATMAN) for semi-supervised VOS. It captures object motion in the video via a novel optical flow calibration module that fuses the segmentation mask with optical flow estimation to improve within-object optical flow smoothness and reduce noise at object boundaries. This calibrated optical flow is then employed in our novel **bilateral** attention, which computes the correspondence between the query and reference frames in the neighboring **bilateral** space considering both motion and appearance. Extensive experiments validate the effectiveness of BATMAN architecture by outperforming all existing state-of-the-art on all four popular VOS benchmarks: Youtube-VOS 2019 (85.0%), Youtube-VOS 2018 (85.3%), DAVIS 2017Val/Testdev (86.2%/82.2%), and DAVIS 2016 (92.5%).  
### Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions. (arXiv:2208.01166v1 [cs.CV])
- Authors : Youya Xia, Yurong You, Jose Nino, Junan Chen, Josephine Monica, Xiangyu Chen, Katie Luo, Yan Wang, Marc Emond, Lun Chao, Bharath Hariharan, Mark Campbell, Cornell University, The Ohio, State University
- Link : [http://arxiv.org/abs/2208.01166](http://arxiv.org/abs/2208.01166)
> ABSTRACT  :  Advances in perception for self-driving cars have accelerated in recent years due to the availability of large-scale datasets, typically collected at specific locations and under nice weather conditions. Yet, to achieve the high safety requirement, these perceptual systems must operate robustly under a wide variety of weather conditions including snow and rain. In this paper, we present a new dataset to enable robust autonomous driving via a novel data collection process - data is repeatedly recorded along a 15 km route under diverse scene (urban, highway, rural, campus), weather (snow, rain, sun), time (day/**night**), and traffic conditions (pedestrians, cyclists and cars). The dataset includes images and point clouds from cameras and LiDAR sensors, along with high-precision GPS/INS to establish correspondence across routes. The dataset includes road and object annotations using amodal masks to capture partial occlusions and 3D bounding boxes. We demonstrate the uniqueness of this dataset by analyzing the performance of baselines in amodal segmentation of road and objects, depth estimation, and 3D object detection. The repeated routes opens new research directions in object discovery, continual learning, and anomaly detection. Link to Ithaca365: https://ithaca365.mae.cornell.edu/  
### A Novel Transformer Network with Shifted Window Cross-Attention for Spatiotemporal Weather Forecasting. (arXiv:2208.01252v1 [cs.CV])
- Authors : Alabi Bojesomo, Hasan Al, Panos Liatsis
- Link : [http://arxiv.org/abs/2208.01252](http://arxiv.org/abs/2208.01252)
> ABSTRACT  :  Earth Observatory is a growing research area that can capitalize on the powers of AI for short time forecasting, a Now-casting scenario. In this work, we tackle the challenge of weather forecasting using a video transformer network. Vision transformer architectures have been explored in various applications, with major constraints being the computational complexity of Attention and the data hungry training. To address these issues, we propose the use of Video **Swin**-Transformer, coupled with a dedicated augmentation scheme. Moreover, we employ gradual spatial reduction on the encoder side and cross-attention on the decoder. The proposed approach is tested on the Weather4Cast2021 weather forecasting challenge data, which requires the prediction of 8 hours ahead future frames (4 per hour) from an hourly weather product sequence. The dataset was normalized to 0-1 to facilitate using the evaluation metrics across different datasets. The model results in an MSE score of 0.4750 when provided with training data, and 0.4420 during transfer learning without using training data, respectively.  
### T4DT: Tensorizing Time for Learning Temporal 3D Visual Data. (arXiv:2208.01421v1 [cs.CV])
- Authors : Mikhail Usvyatsov, Rafael Ballester, Lina Bashaeva, Konrad Schindler, Gonzalo Ferrer, Ivan Oseledets
- Link : [http://arxiv.org/abs/2208.01421](http://arxiv.org/abs/2208.01421)
> ABSTRACT  :  Unlike 2D raster images, there is no single dominant representation for 3D visual data processing. Different formats like point clouds, meshes, or implicit functions each have their strengths and weaknesses. Still, grid representations such as signed distance functions have attractive properties also in 3D. In particular, they offer constant-time random access and are eminently suitable for modern machine learning. Unfortunately, the storage size of a grid grows exponentially with its dimension. Hence they often exceed memory limits even at moderate resolution. This work explores various low-rank tensor formats, including the Tucker, tensor train, and quantics tensor train decompositions, to compress time-varying 3D data. Our method iteratively computes, voxelizes, and compresses each frame's truncated signed distance function and applies tensor rank truncation to condense all frames into a single, compressed tensor that represents the entire 4D scene. We show that low-rank tensor compression is extremely compact to store and query time-varying signed distance functions. It significantly reduces the memory footprint of 4D scenes while surprisingly preserving their geometric quality. Unlike existing iterative learning-based approaches like DeepSDF and **NeRF**, our method uses a closed-form algorithm with theoretical guarantees.  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
### K-means segmentation based-on lab color space for embryo detection in incubated egg. (arXiv:2103.02288v2 [cs.CV] UPDATED)
- Authors : Shoffan Saifullah, Rafal Drezewski, Alin Khaliduzzaman, Lean Karlo, Rabbimov Ilyos
- Link : [http://arxiv.org/abs/2103.02288](http://arxiv.org/abs/2103.02288)
> ABSTRACT  :  The quality of the hatching process influences the success of the hatch rate besides the inherent egg factors. Eliminating infertile or dead eggs and monitoring embryonic growth are very important factors in efficient hatchery practices. This process aims to sort eggs that only have embryos to remain in the incubator until the end of the hatching process. This process aims to sort eggs with embryos to remain hatched until the end. Maximum checking is done the first week in the hatching period. This study aims to detect the presence of embryos in eggs and processed by segmentation. Egg images are segmented using the K-means algorithm based on Lab color images. The results of the image acquisition are converted into Lab color space images. The results of Lab color space images are processed using K-means for each color. The K-means process uses cluster k=3 and divides into three parts: background, eggs, and yolk. Egg yolks are part of eggs that have embryonic characteristics. This study applies the concept of color in the initial segmentation and grayscale in the final stages. The initial phase results show that the image segmentation results using k-means clustering based on Lab color space provide a grouping of three parts. At the grayscale image processing stage, the results of color image segmentation are processed with grayscaling, image **enhancement**, and morphology. Thus, it seems clear that the yolk segmented shows the presence of egg embryos. Based on this results, the initial stages of the embryo detection process used K-means segmentation based on Lab color space. The evaluation uses MSE and MSSIM, with values of 0.0486 and 0.9979; this can be used to reference that the results obtained can detect embryos in egg yolk. This protocol could be used in a non-destructive quantitative study on embryos and their morphology in a precision poultry production system in the future.  
### Identity-guided Face Generation with Multi-modal Contour Conditions. (arXiv:2110.04854v2 [cs.CV] UPDATED)
- Authors : Qingyan Bai, Weihao Xia, Fei Yin, Yujiu Yang
- Link : [http://arxiv.org/abs/2110.04854](http://arxiv.org/abs/2110.04854)
> ABSTRACT  :  Recent face generation methods have tried to synthesize faces based on the given contour condition, like a low-resolution image or sketch. However, the problem of identity ambiguity remains unsolved, which usually occurs when the contour is too vague to provide reliable identity information (e.g., when its resolution is extremely low). Thus feasible solutions of image **restoration** could be infinite. In this work, we propose a novel framework that takes the contour and an extra image specifying the identity as the inputs, where the contour can be of various modalities, including the low-resolution image, sketch, and semantic label map. Concretely, we propose a novel dual-encoder architecture, in which an identity encoder extracts the identity-related feature, accompanied by a main encoder to obtain the rough contour information and further fuse all the information together. The encoder output is iteratively fed into a pre-trained StyleGAN generator until getting a satisfying result. To the best of our knowledge, this is the first work that achieves identity-guided face generation conditioned on multi-modal contour images. Moreover, our method can produce photo-realistic results with 1024$\times$1024 resolution.  
### Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v4 [eess.IV] UPDATED)
- Authors : Xiaojie Chu, Liangyu Chen, Chengpeng Chen, Xin Lu
- Link : [http://arxiv.org/abs/2112.04491](http://arxiv.org/abs/2112.04491)
> ABSTRACT  :  Global operations, such as global average pooling, are widely used in top-performance image restorers. They aggregate global information from input features along entire spatial dimensions but behave differently during training and inference in image **restoration** tasks: they are based on different regions, namely the cropped patches (from images) and the full-resolution images. This paper revisits global information aggregation and finds that the image-based features during inference have a different distribution than the patch-based features during training. This train-test inconsistency negatively impacts the performance of models, which is severely overlooked by previous works. To reduce the inconsistency and improve test-time performance, we propose a simple method called Test-time Local Converter (TLC). Our TLC converts global operations to local ones only during inference so that they aggregate features within local spatial regions rather than the entire large images. The proposed method can be applied to various global modules (e.g., normalization, channel and spatial attention) with negligible costs. Without the need for any fine-tuning, TLC improves state-of-the-art results on several image **restoration** tasks, including single-image motion deblurring, video deblurring, defocus deblurring, and image denoising. In particular, with TLC, our Restormer-Local improves the state-of-the-art result in single image deblurring from 32.92 dB to 33.57 dB on GoPro dataset. The code is available at https://github.com/megvii-research/tlc.  
### ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v2 [cs.CV] UPDATED)
- Authors : Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.10016](http://arxiv.org/abs/2203.10016)
> ABSTRACT  :  Retrieving accurate semantic information in challenging **high dynamic range** (**HDR**) and high-speed conditions remains an open challenge for image-based algorithms due to severe image degradations. Event cameras promise to address these challenges since they feature a much higher dynamic range and are resilient to motion blur. Nonetheless, semantic segmentation with event cameras is still in its infancy which is chiefly due to the lack of high-quality, labeled datasets. In this work, we introduce ESS (Event-based Semantic Segmentation), which tackles this problem by directly transferring the semantic segmentation task from existing labeled image datasets to unlabeled events via unsupervised domain adaptation (UDA). Compared to existing UDA methods, our approach aligns recurrent, motion-invariant event embeddings with image embeddings. For this reason, our method neither requires video data nor per-pixel alignment between images and events and, crucially, does not need to hallucinate motion from still images. Additionally, we introduce DSEC-Semantic, the first large-scale event-based dataset with fine-grained labels. We show that using image labels alone, ESS outperforms existing UDA approaches, and when combined with event labels, it even outperforms state-of-the-art supervised approaches on both DDD17 and DSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount of existing labeled image datasets and paves the way for new and exciting research directions in new fields previously inaccessible for event cameras.  
### Simple Baselines for Image **Restoration**. (arXiv:2204.04676v4 [cs.CV] UPDATED)
- Authors : Liangyu Chen, Xiaojie Chu, Xiangyu Zhang, Jian Sun
- Link : [http://arxiv.org/abs/2204.04676](http://arxiv.org/abs/2204.04676)
> ABSTRACT  :  Although there have been significant advances in the field of image **restoration** recently, the system complexity of the state-of-the-art (SOTA) methods is increasing as well, which may hinder the convenient analysis and comparison of methods. In this paper, we propose a simple baseline that exceeds the SOTA methods and is computationally efficient. To further simplify the baseline, we reveal that the nonlinear activation functions, e.g. Sigmoid, ReLU, GELU, Softmax, etc. are not necessary: they could be replaced by multiplication or removed. Thus, we derive a Nonlinear Activation Free Network, namely NAFNet, from the baseline. SOTA results are achieved on various challenging benchmarks, e.g. 33.69 dB PSNR on GoPro (for image deblurring), exceeding the previous SOTA 0.38 dB with only 8.4% of its computational costs; 40.30 dB PSNR on SIDD (for image denoising), exceeding the previous SOTA 0.28 dB with less than half of its computational costs. The code and the pre-trained models are released at https://github.com/megvii-research/NAFNet.  
### MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v2 [eess.IV] UPDATED)
- Authors : Haseeb Nazki, Ognjen Arandjelovi, InHwa Um, David Harrison
- Link : [http://arxiv.org/abs/2204.09782](http://arxiv.org/abs/2204.09782)
> ABSTRACT  :  Histopathology relies on the analysis of microscopic tissue images to diagnose disease. A crucial part of tissue preparation is staining whereby a dye is used to make the salient tissue components more distinguishable. However, differences in laboratory protocols and scanning devices result in significant confounding appearance variation in the corresponding images. This variation increases both human error and the inter-rater variability, as well as hinders the performance of automatic or semi-automatic methods. In the present paper we introduce an unsupervised adversarial network to translate (and hence normalize) whole slide images across multiple data acquisition domains. Our key contributions are: (i) an adversarial architecture which learns across multiple domains with a single generator-discriminator network using an information flow branch which optimizes for perceptual loss, and (ii) the inclusion of an additional feature extraction network during training which guides the transformation network to keep all the structural features in the tissue image intact. We: (i) demonstrate the effectiveness of the proposed method firstly on H\&amp;E slides of 120 cases of kidney cancer, as well as (ii) show the benefits of the approach on more general problems, such as flexible illumination based natural image **enhancement** and light source adaptation.  
## eess.IV
---
### **Enhancement** of CASSI by a zero-order image employing a single detector. (arXiv:2208.01308v1 [physics.optics])
- Authors : Jiri Hlubucek, Jakub Lukes, Jan Vaclavik, Karel Zidek
- Link : [http://arxiv.org/abs/2208.01308](http://arxiv.org/abs/2208.01308)
> ABSTRACT  :  Coded aperture snapshot spectral imaging (CASSI) makes it possible to recover 3D hyperspectral data from a single 2D image. However, the reconstruction problem is severely underdetermined and efforts to improve the compression ratio typically make the imaging system more complex and cause a significant loss of incoming light intensity. In this paper, we propose a novel approach to CASSI which enables capturing both spectrally sheared and integrated image of a scene with a single camera. We performed hyperspectral imaging of three different testing scenes in the spectral range of 500-900 nm. We demonstrate the prominent effect of using the non-diffracted image on the reconstruction of data from our camera. The use of the spectrally integrated image improves the reconstruction quality and we observed an approx. fivefold reduction in reconstruction time.  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
### K-means segmentation based-on lab color space for embryo detection in incubated egg. (arXiv:2103.02288v2 [cs.CV] UPDATED)
- Authors : Shoffan Saifullah, Rafal Drezewski, Alin Khaliduzzaman, Lean Karlo, Rabbimov Ilyos
- Link : [http://arxiv.org/abs/2103.02288](http://arxiv.org/abs/2103.02288)
> ABSTRACT  :  The quality of the hatching process influences the success of the hatch rate besides the inherent egg factors. Eliminating infertile or dead eggs and monitoring embryonic growth are very important factors in efficient hatchery practices. This process aims to sort eggs that only have embryos to remain in the incubator until the end of the hatching process. This process aims to sort eggs with embryos to remain hatched until the end. Maximum checking is done the first week in the hatching period. This study aims to detect the presence of embryos in eggs and processed by segmentation. Egg images are segmented using the K-means algorithm based on Lab color images. The results of the image acquisition are converted into Lab color space images. The results of Lab color space images are processed using K-means for each color. The K-means process uses cluster k=3 and divides into three parts: background, eggs, and yolk. Egg yolks are part of eggs that have embryonic characteristics. This study applies the concept of color in the initial segmentation and grayscale in the final stages. The initial phase results show that the image segmentation results using k-means clustering based on Lab color space provide a grouping of three parts. At the grayscale image processing stage, the results of color image segmentation are processed with grayscaling, image **enhancement**, and morphology. Thus, it seems clear that the yolk segmented shows the presence of egg embryos. Based on this results, the initial stages of the embryo detection process used K-means segmentation based on Lab color space. The evaluation uses MSE and MSSIM, with values of 0.0486 and 0.9979; this can be used to reference that the results obtained can detect embryos in egg yolk. This protocol could be used in a non-destructive quantitative study on embryos and their morphology in a precision poultry production system in the future.  
### Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v4 [eess.IV] UPDATED)
- Authors : Xiaojie Chu, Liangyu Chen, Chengpeng Chen, Xin Lu
- Link : [http://arxiv.org/abs/2112.04491](http://arxiv.org/abs/2112.04491)
> ABSTRACT  :  Global operations, such as global average pooling, are widely used in top-performance image restorers. They aggregate global information from input features along entire spatial dimensions but behave differently during training and inference in image **restoration** tasks: they are based on different regions, namely the cropped patches (from images) and the full-resolution images. This paper revisits global information aggregation and finds that the image-based features during inference have a different distribution than the patch-based features during training. This train-test inconsistency negatively impacts the performance of models, which is severely overlooked by previous works. To reduce the inconsistency and improve test-time performance, we propose a simple method called Test-time Local Converter (TLC). Our TLC converts global operations to local ones only during inference so that they aggregate features within local spatial regions rather than the entire large images. The proposed method can be applied to various global modules (e.g., normalization, channel and spatial attention) with negligible costs. Without the need for any fine-tuning, TLC improves state-of-the-art results on several image **restoration** tasks, including single-image motion deblurring, video deblurring, defocus deblurring, and image denoising. In particular, with TLC, our Restormer-Local improves the state-of-the-art result in single image deblurring from 32.92 dB to 33.57 dB on GoPro dataset. The code is available at https://github.com/megvii-research/tlc.  
### MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v2 [eess.IV] UPDATED)
- Authors : Haseeb Nazki, Ognjen Arandjelovi, InHwa Um, David Harrison
- Link : [http://arxiv.org/abs/2204.09782](http://arxiv.org/abs/2204.09782)
> ABSTRACT  :  Histopathology relies on the analysis of microscopic tissue images to diagnose disease. A crucial part of tissue preparation is staining whereby a dye is used to make the salient tissue components more distinguishable. However, differences in laboratory protocols and scanning devices result in significant confounding appearance variation in the corresponding images. This variation increases both human error and the inter-rater variability, as well as hinders the performance of automatic or semi-automatic methods. In the present paper we introduce an unsupervised adversarial network to translate (and hence normalize) whole slide images across multiple data acquisition domains. Our key contributions are: (i) an adversarial architecture which learns across multiple domains with a single generator-discriminator network using an information flow branch which optimizes for perceptual loss, and (ii) the inclusion of an additional feature extraction network during training which guides the transformation network to keep all the structural features in the tissue image intact. We: (i) demonstrate the effectiveness of the proposed method firstly on H\&amp;E slides of 120 cases of kidney cancer, as well as (ii) show the benefits of the approach on more general problems, such as flexible illumination based natural image **enhancement** and light source adaptation.  
### Photon-Limited Blind Deconvolution using Unsupervised Iterative Kernel Estimation. (arXiv:2208.00451v2 [eess.IV] UPDATED)
- Authors : Yash Sanghvi, Abhiram Gnanasambandam, Zhiyuan Mao
- Link : [http://arxiv.org/abs/2208.00451](http://arxiv.org/abs/2208.00451)
> ABSTRACT  :  Blind deconvolution in **low-light** is one of the more challenging problems in image **restoration** because of the photon shot noise. However, existing algorithms -- both classical and deep-learning based -- are not designed for this condition. When the shot noise is strong, conventional deconvolution methods fail because (1) the presence of noise makes the estimation of the blur kernel difficult; (2) generic deep-**restoration** models rarely model the forward process explicitly; (3) there are currently no iterative strategies to incorporate a non-blind solver in a kernel estimation stage. This paper addresses these challenges by presenting an unsupervised blind deconvolution method. At the core of this method is a reformulation of the general blind deconvolution framework from the conventional image-kernel alternating minimization to a purely kernel-based minimization. This kernel-based minimization leads to a new iterative scheme that backpropagates an unsupervised loss through a pre-trained non-blind solver to update the blur kernel. Experimental results show that the proposed framework achieves superior results than state-of-the-art blind deconvolution algorithms in **low-light** conditions.  
## cs.LG
---
### Voice Analysis for Stress Detection and Application in Virtual Reality to Improve Public Speaking in **Real-time**: A Review. (arXiv:2208.01041v1 [eess.AS])
- Authors : Roberto Dillon, Ai Ni, Denise Dillon
- Link : [http://arxiv.org/abs/2208.01041](http://arxiv.org/abs/2208.01041)
> ABSTRACT  :  Stress during public speaking is common and adversely affects performance and self-confidence. Extensive research has been carried out to develop various models to recognize emotional states. However, minimal research has been conducted to detect stress during public speaking in **real time** using voice analysis. In this context, the current review showed that the application of algorithms was not properly explored and helped identify the main obstacles in creating a suitable testing environment while accounting for current complexities and limitations. In this paper, we present our main idea and propose a stress detection computational algorithmic model that could be integrated into a Virtual Reality (VR) application to create an intelligent virtual audience for improving public speaking skills. The developed model, when integrated with VR, will be able to detect excessive stress in **real time** by analysing voice features correlated to physiological parameters indicative of stress and help users gradually control excessive stress and improve public speaking performance  
### Flood Prediction Using Machine Learning Models. (arXiv:2208.01234v1 [cs.LG])
- Authors : Miah Mohammad, Asif Syeed, Maisha Farzana, Ishadie Namir, Ipshita Ishrar, Meherin Hossain, Tanvir Rahman
- Link : [http://arxiv.org/abs/2208.01234](http://arxiv.org/abs/2208.01234)
> ABSTRACT  :  Floods are one of nature's most catastrophic calamities which cause irreversible and immense damage to human life, agriculture, infrastructure and socio-economic system. Several studies on flood catastrophe management and flood forecasting systems have been conducted. The accurate prediction of the onset and progression of floods in **real time** is challenging. To estimate water levels and velocities across a large area, it is necessary to combine data with computationally demanding flood propagation models. This paper aims to reduce the extreme risks of this natural disaster and also contributes to policy suggestions by providing a prediction for floods using different machine learning models. This research will use Binary Logistic Regression, K-Nearest Neighbor (KNN), Support Vector Classifier (SVC) and Decision tree Classifier to provide an accurate prediction. With the outcome, a comparative analysis will be conducted to understand which model delivers a better accuracy.  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
### Data-Driven Discovery of Molecular Photoswitches with Multioutput Gaussian Processes. (arXiv:2008.03226v2 [physics.chem-ph] UPDATED)
- Authors : Rhys Griffiths, Anthony Bourached, Penelope Jones, William McCorkindale, Fuchter Alpha
- Link : [http://arxiv.org/abs/2008.03226](http://arxiv.org/abs/2008.03226)
> ABSTRACT  :  Photoswitchable molecules display two or more isomeric forms that may be accessed using light. Separating the electronic absorption bands of these isomers is key to selectively addressing a specific isomer and achieving high photostationary states whilst overall red-shifting the absorption bands serves to limit material damage due to UV-**exposure** and increases penetration depth in photopharmacological applications. Engineering these properties into a system through synthetic design however, remains a challenge. Here, we present a data-driven discovery pipeline for molecular photoswitches underpinned by dataset curation and multitask learning with Gaussian processes. In the prediction of electronic transition wavelengths, we demonstrate that a multioutput Gaussian process (MOGP) trained using labels from four photoswitch transition wavelengths yields the strongest predictive performance relative to single-task models as well as operationally outperforming time-dependent density functional theory (TD-DFT) in terms of the wall-clock time for prediction. We validate our proposed approach experimentally by screening a library of commercially available photoswitchable molecules. Through this screen, we identified several motifs that displayed separated electronic absorption bands of their isomers, exhibited red-shifted absorptions, and are suited for information transfer and photopharmacological applications. Our curated dataset, code, as well as all models are made available at https://github.com/Ryan-Rhys/The-Photoswitch-Dataset  
### ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v2 [cs.CV] UPDATED)
- Authors : Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.10016](http://arxiv.org/abs/2203.10016)
> ABSTRACT  :  Retrieving accurate semantic information in challenging **high dynamic range** (**HDR**) and high-speed conditions remains an open challenge for image-based algorithms due to severe image degradations. Event cameras promise to address these challenges since they feature a much higher dynamic range and are resilient to motion blur. Nonetheless, semantic segmentation with event cameras is still in its infancy which is chiefly due to the lack of high-quality, labeled datasets. In this work, we introduce ESS (Event-based Semantic Segmentation), which tackles this problem by directly transferring the semantic segmentation task from existing labeled image datasets to unlabeled events via unsupervised domain adaptation (UDA). Compared to existing UDA methods, our approach aligns recurrent, motion-invariant event embeddings with image embeddings. For this reason, our method neither requires video data nor per-pixel alignment between images and events and, crucially, does not need to hallucinate motion from still images. Additionally, we introduce DSEC-Semantic, the first large-scale event-based dataset with fine-grained labels. We show that using image labels alone, ESS outperforms existing UDA approaches, and when combined with event labels, it even outperforms state-of-the-art supervised approaches on both DDD17 and DSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount of existing labeled image datasets and paves the way for new and exciting research directions in new fields previously inaccessible for event cameras.  
## cs.AI
---
### Towards Psychologically-Grounded Dynamic Preference Models. (arXiv:2208.01534v1 [cs.IR])
- Authors : Mihaela Curmei, Andreas Haupt, Benjamin Recht, Dylan Hadfield
- Link : [http://arxiv.org/abs/2208.01534](http://arxiv.org/abs/2208.01534)
> ABSTRACT  :  Designing recommendation systems that serve content aligned with time varying preferences requires proper accounting of the feedback effects of recommendations on human behavior and psychological condition. We argue that modeling the influence of recommendations on people's preferences must be grounded in psychologically plausible models. We contribute a methodology for developing grounded dynamic preference models. We demonstrate this method with models that capture three classic effects from the psychology literature: Mere-**Exposure**, Operant Conditioning, and Hedonic Adaptation. We conduct simulation-based studies to show that the psychological models manifest distinct behaviors that can inform system design. Our study has two direct implications for dynamic user modeling in recommendation systems. First, the methodology we outline is broadly applicable for psychologically grounding dynamic preference models. It allows us to critique recent contributions based on their limited discussion of psychological foundation and their implausible predictions. Second, we discuss implications of dynamic preference models for recommendation systems evaluation and design. In an example, we show that engagement and diversity metrics may be unable to capture desirable recommendation system performance.  
# Paper List
---
## cs.CV
---
**79** new papers in cs.CV:-) 
1. Learning to estimate a surrogate respiratory signal from cardiac motion by signal-to-signal translation. (arXiv:2208.01034v1 [eess.IV])
2. Face-to-Face Contrastive Learning for Social Intelligence Question-Answering. (arXiv:2208.01036v1 [cs.LG])
3. A knee cannot have lung disease: out-of-distribution detection with in-distribution voting using the medical example of chest X-ray classification. (arXiv:2208.01077v1 [eess.IV])
4. Dyadic Movement Synchrony Estimation Under Privacy-preserving Conditions. (arXiv:2208.01100v1 [cs.CV])
5. Exploring the GLIDE model for Human Action-effect Prediction. (arXiv:2208.01136v1 [cs.CV])
6. A Feasibility Study on Image Inpainting for Non-cleft Lip Generation from Patients with Cleft Lip. (arXiv:2208.01149v1 [cs.CV])
7. Mitigating Shadows in Lidar Scan Matching using Spherical Voxels. (arXiv:2208.01150v1 [cs.RO])
8. BATMAN: **Bilateral** Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation. (arXiv:2208.01159v1 [cs.CV])
9. Pose Uncertainty Aware Movement Synchrony Estimation via Spatial-Temporal Graph Transformer. (arXiv:2208.01161v1 [cs.CV])
10. Ithaca365: Dataset and Driving Perception under Repeated and Challenging Weather Conditions. (arXiv:2208.01166v1 [cs.CV])
11. MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network. (arXiv:2208.01172v1 [cs.CV])
12. Curved Geometric Networks for Visual Anomaly Recognition. (arXiv:2208.01188v1 [cs.CV])
13. Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation. (arXiv:2208.01195v1 [cs.CV])
14. Making a Spiking Net Work: Robust brain-like unsupervised machine learning. (arXiv:2208.01204v1 [cs.NE])
15. A Novel Transformer Network with Shifted Window Cross-Attention for Spatiotemporal Weather Forecasting. (arXiv:2208.01252v1 [cs.CV])
16. A Robust Morphological Approach for Semantic Segmentation of Very High Resolution Images. (arXiv:2208.01254v1 [cs.CV])
17. Explicit Use of Fourier Spectrum in Generative Adversarial Networks. (arXiv:2208.01265v1 [cs.CV])
18. In-Hand Pose Estimation and Pin Inspection for Insertion of Through-Hole Components. (arXiv:2208.01284v1 [cs.CV])
19. Multiview Regenerative Morphing with Dual Flows. (arXiv:2208.01287v1 [cs.CV])
20. Overlooked Poses Actually Make Sense: Distilling Privileged Knowledge for Human Motion Prediction. (arXiv:2208.01302v1 [cs.CV])
21. Unified Normalization for Accelerating and Stabilizing Transformers. (arXiv:2208.01313v1 [cs.CV])
22. Self-Supervised Traversability Prediction by Learning to Reconstruct Safe Terrain. (arXiv:2208.01329v1 [cs.RO])
23. What can we Learn by Predicting Accuracy?. (arXiv:2208.01358v1 [cs.LG])
24. The Face of Affective Disorders. (arXiv:2208.01369v1 [cs.CV])
25. GaitGL: Learning Discriminative Global-Local Feature Representations for Gait Recognition. (arXiv:2208.01380v1 [cs.CV])
26. A New Probabilistic V-Net Model with Hierarchical Spatial Feature Transform for Efficient Abdominal Multi-Organ Segmentation. (arXiv:2208.01382v1 [eess.IV])
27. T4DT: Tensorizing Time for Learning Temporal 3D Visual Data. (arXiv:2208.01421v1 [cs.CV])
28. Connection Reduction Is All You Need. (arXiv:2208.01424v1 [cs.CV])
29. IterMiUnet: A lightweight architecture for automatic blood vessel segmentation. (arXiv:2208.01485v1 [eess.IV])
30. Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter. (arXiv:2208.01489v1 [cs.CV])
31. A Multi-body Tracking Framework -- From Rigid Objects to Kinematic Structures. (arXiv:2208.01502v1 [cs.CV])
32. DSR -- A dual subspace re-projection network for surface anomaly detection. (arXiv:2208.01521v1 [cs.CV])
33. ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries. (arXiv:2208.01582v1 [cs.CV])
34. Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization. (arXiv:2208.01587v1 [cs.CV])
35. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
36. An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion. (arXiv:2208.01618v1 [cs.CV])
37. Prompt-to-Prompt Image Editing with Cross Attention Control. (arXiv:2208.01626v1 [cs.CV])
38. UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture. (arXiv:2208.01633v1 [cs.CV])
39. Asymmetric Gained Deep Image Compression With Continuous Rate Adaptation. (arXiv:2003.02012v3 [eess.IV] UPDATED)
40. K-means segmentation based-on lab color space for embryo detection in incubated egg. (arXiv:2103.02288v2 [cs.CV] UPDATED)
41. Diffusion-Based Representation Learning. (arXiv:2105.14257v3 [cs.LG] UPDATED)
42. On Anytime Learning at Macroscale. (arXiv:2106.09563v5 [cs.LG] UPDATED)
43. Identity-guided Face Generation with Multi-modal Contour Conditions. (arXiv:2110.04854v2 [cs.CV] UPDATED)
44. Co-segmentation Inspired Attention Module for Video-based Computer Vision Tasks. (arXiv:2111.07370v3 [cs.CV] UPDATED)
45. MegBA: A GPU-Based Distributed Library for Large-Scale Bundle Adjustment. (arXiv:2112.01349v3 [cs.CV] UPDATED)
46. Deep residential representations: Using unsupervised learning to unlock elevation data for geo-demographic prediction. (arXiv:2112.01421v2 [cs.LG] UPDATED)
47. Variance-Aware Weight Initialization for Point Convolutional Neural Networks. (arXiv:2112.03777v2 [cs.CV] UPDATED)
48. Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v4 [eess.IV] UPDATED)
49. Free-Viewpoint RGB-D Human Performance Capture and Rendering. (arXiv:2112.13889v4 [cs.CV] UPDATED)
50. ProgressLabeller: Visual Data Stream Annotation for Training Object-Centric 3D Perception. (arXiv:2203.00283v2 [cs.RO] UPDATED)
51. ParaPose: Parameter and Domain Randomization Optimization for Pose Estimation using Synthetic Data. (arXiv:2203.00945v2 [cs.CV] UPDATED)
52. ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v2 [cs.CV] UPDATED)
53. WayFAST: Navigation with Predictive Traversability in the Field. (arXiv:2203.12071v2 [cs.RO] UPDATED)
54. Texture based Prototypical Network for Few-Shot Semantic Segmentation of Forest Cover: Generalizing for Different Geographical Regions. (arXiv:2203.15687v2 [cs.CV] UPDATED)
55. VI-IKD: High-Speed Accurate Off-Road Navigation using Learned Visual-Inertial Inverse Kinodynamics. (arXiv:2203.15983v2 [cs.RO] UPDATED)
56. "This is my unicorn, Fluffy": Personalizing frozen vision-language representations. (arXiv:2204.01694v3 [cs.CV] UPDATED)
57. ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound. (arXiv:2204.02874v3 [cs.CV] UPDATED)
58. Simple Baselines for Image **Restoration**. (arXiv:2204.04676v4 [cs.CV] UPDATED)
59. Learned Monocular Depth Priors in Visual-Inertial Initialization. (arXiv:2204.09171v2 [cs.RO] UPDATED)
60. MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v2 [eess.IV] UPDATED)
61. Causal Reasoning Meets Visual Representation Learning: A Prospective Study. (arXiv:2204.12037v6 [cs.CV] UPDATED)
62. In Defense of Image Pre-Training for Spatiotemporal Recognition. (arXiv:2205.01721v2 [cs.CV] UPDATED)
63. Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition. (arXiv:2205.01782v2 [cs.CV] UPDATED)
64. Long-tailed Recognition by Learning from Latent Categories. (arXiv:2206.01010v2 [cs.CV] UPDATED)
65. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v4 [cs.CV] UPDATED)
66. SparseNeuS: Fast Generalizable Neural Surface Reconstruction from Sparse Views. (arXiv:2206.05737v2 [cs.CV] UPDATED)
67. Perceptual Conversational Head Generation with Regularized Driver and Enhanced Renderer. (arXiv:2206.12837v2 [cs.CV] UPDATED)
68. Timestamp-Supervised Action Segmentation with Graph Convolutional Networks. (arXiv:2206.15031v4 [cs.CV] UPDATED)
69. OSFormer: One-Stage Camouflaged Instance Segmentation with Transformers. (arXiv:2207.02255v3 [cs.CV] UPDATED)
70. A new database of Houma Alliance Book ancient handwritten characters and classifier fusion approach. (arXiv:2207.05993v3 [cs.CV] UPDATED)
71. DeepIPC: Deeply Integrated Perception and Control for Mobile Robot in Real Environments. (arXiv:2207.09934v2 [cs.RO] UPDATED)
72. OpenFilter: A Framework to Democratize Research Access to Social Media AR Filters. (arXiv:2207.12319v2 [cs.CV] UPDATED)
73. Group DETR: Fast DETR Training with Group-Wise One-to-Many Assignment. (arXiv:2207.13085v2 [cs.CV] UPDATED)
74. A Semi-automatic Cell Tracking Process Towards Completing the 4D Atlas of C. elegans Development. (arXiv:2207.13611v2 [cs.CV] UPDATED)
75. Look at Adjacent Frames: Video Anomaly Detection without Offline Training. (arXiv:2207.13798v2 [cs.CV] UPDATED)
76. Simplex Clustering via sBeta with Applications to Online Adjustment of Black-Box Predictions. (arXiv:2208.00287v2 [cs.CV] UPDATED)
77. FixMatchSeg: Fixing FixMatch for Semi-Supervised Semantic Segmentation. (arXiv:2208.00400v2 [cs.CV] UPDATED)
78. Generative Bias for Visual Question Answering. (arXiv:2208.00690v2 [cs.CV] UPDATED)
79. Visual correspondence-based explanations improve AI robustness and human-AI team accuracy. (arXiv:2208.00780v2 [cs.CV] UPDATED)
## eess.IV
---
**15** new papers in eess.IV:-) 
1. Learning to estimate a surrogate respiratory signal from cardiac motion by signal-to-signal translation. (arXiv:2208.01034v1 [eess.IV])
2. A knee cannot have lung disease: out-of-distribution detection with in-distribution voting using the medical example of chest X-ray classification. (arXiv:2208.01077v1 [eess.IV])
3. **Enhancement** of CASSI by a zero-order image employing a single detector. (arXiv:2208.01308v1 [physics.optics])
4. Differential Coded Aperture Single-Snapshot Spectral Imaging. (arXiv:2208.01309v1 [physics.optics])
5. The Face of Affective Disorders. (arXiv:2208.01369v1 [cs.CV])
6. A New Probabilistic V-Net Model with Hierarchical Spatial Feature Transform for Efficient Abdominal Multi-Organ Segmentation. (arXiv:2208.01382v1 [eess.IV])
7. IterMiUnet: A lightweight architecture for automatic blood vessel segmentation. (arXiv:2208.01485v1 [eess.IV])
8. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
9. Stochastic Primal-Dual Three Operator Splitting with Arbitrary Sampling and Preconditioning. (arXiv:2208.01631v1 [math.OC])
10. Asymmetric Gained Deep Image Compression With Continuous Rate Adaptation. (arXiv:2003.02012v3 [eess.IV] UPDATED)
11. K-means segmentation based-on lab color space for embryo detection in incubated egg. (arXiv:2103.02288v2 [cs.CV] UPDATED)
12. Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v4 [eess.IV] UPDATED)
13. MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v2 [eess.IV] UPDATED)
14. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v4 [cs.CV] UPDATED)
15. Photon-Limited Blind Deconvolution using Unsupervised Iterative Kernel Estimation. (arXiv:2208.00451v2 [eess.IV] UPDATED)
## cs.LG
---
**129** new papers in cs.LG:-) 
1. Learning to estimate a surrogate respiratory signal from cardiac motion by signal-to-signal translation. (arXiv:2208.01034v1 [eess.IV])
2. Face-to-Face Contrastive Learning for Social Intelligence Question-Answering. (arXiv:2208.01036v1 [cs.LG])
3. CircuitNet: An Open-Source Dataset for Machine Learning Applications in Electronic Design Automation (EDA). (arXiv:2208.01040v1 [cs.LG])
4. Voice Analysis for Stress Detection and Application in Virtual Reality to Improve Public Speaking in **Real-time**: A Review. (arXiv:2208.01041v1 [eess.AS])
5. ASTA: Learning Analytical Semantics over Tables for Intelligent Data Analysis and Visualization. (arXiv:2208.01043v1 [cs.DB])
6. What Can Transformers Learn In-Context? A Case Study of Simple Function Classes. (arXiv:2208.01066v1 [cs.CL])
7. Efficient Personalized Learning for Wearable Health Applications using HyperDimensional Computing. (arXiv:2208.01095v1 [cs.LG])
8. Dyadic Movement Synchrony Estimation Under Privacy-preserving Conditions. (arXiv:2208.01100v1 [cs.CV])
9. VacciNet: Towards a Smart Framework for Learning the Distribution Chain Optimization of Vaccines for a Pandemic. (arXiv:2208.01112v1 [cs.LG])
10. On the Evaluation of User Privacy in Deep Neural Networks using Timing Side Channel. (arXiv:2208.01113v1 [cs.CR])
11. Disparate Censorship & Undertesting: A Source of Label Bias in Clinical Machine Learning. (arXiv:2208.01127v1 [cs.LG])
12. Improving the Trainability of Deep Neural Networks through Layerwise Batch-Entropy Regularization. (arXiv:2208.01134v1 [cs.LG])
13. SampleMatch: Drum Sample Retrieval by Musical Context. (arXiv:2208.01141v1 [cs.SD])
14. Vertical GaN Diode BV Maximization through Rapid TCAD Simulation and ML-enabled Surrogate Model. (arXiv:2208.01142v1 [cs.LG])
15. Short-term Load Forecasting with Distributed Long Short-Term Memory. (arXiv:2208.01147v1 [cs.LG])
16. Boosted Off-Policy Learning. (arXiv:2208.01148v1 [cs.LG])
17. Interpretable Time Series Clustering Using Local Explanations. (arXiv:2208.01152v1 [cs.LG])
18. Patents Phrase to Phrase Semantic Matching Dataset. (arXiv:2208.01171v1 [cs.CL])
19. MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network. (arXiv:2208.01172v1 [cs.CV])
20. Bayesian Variable Selection in a Million Dimensions. (arXiv:2208.01180v1 [stat.ME])
21. Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning. (arXiv:2208.01182v1 [cs.LG])
22. A Note on Zeroth-Order Optimization on the Simplex. (arXiv:2208.01185v1 [cs.LG])
23. Implicit Two-Tower Policies. (arXiv:2208.01191v1 [cs.LG])
24. Late Fusion Multi-view Clustering via Global and Local Alignment Maximization. (arXiv:2208.01198v1 [cs.LG])
25. Analog Gated Recurrent Neural Network for Detecting Chewing Events. (arXiv:2208.01201v1 [cs.LG])
26. Making a Spiking Net Work: Robust brain-like unsupervised machine learning. (arXiv:2208.01204v1 [cs.NE])
27. Fast Kernel Density Estimation with Density Matrices and Random Fourier Features. (arXiv:2208.01206v1 [cs.LG])
28. Audio Deepfake Detection Based on a Combination of F0 Information and Real Plus Imaginary Spectrogram Features. (arXiv:2208.01214v1 [cs.SD])
29. PAN: Pulse Ansatz on NISQ Machines. (arXiv:2208.01215v1 [quant-ph])
30. Mobility-Aware Cooperative Caching in Vehicular Edge Computing Based on Asynchronous Federated and Deep Reinforcement Learning. (arXiv:2208.01219v1 [cs.DC])
31. GeoECG: Data Augmentation via Wasserstein Geodesic Perturbation for Robust Electrocardiogram Prediction. (arXiv:2208.01220v1 [stat.ML])
32. Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks. (arXiv:2208.01221v1 [cs.NI])
33. A Multifaceted Benchmarking of Synthetic Electronic Health Record Generation Models. (arXiv:2208.01230v1 [cs.LG])
34. Flood Prediction Using Machine Learning Models. (arXiv:2208.01234v1 [cs.LG])
35. Are Cluster Validity Measures (In)valid?. (arXiv:2208.01261v1 [stat.ML])
36. Explicit Use of Fourier Spectrum in Generative Adversarial Networks. (arXiv:2208.01265v1 [cs.CV])
37. Automatic Classification of Bug Reports Based on Multiple Text Information and Reports' Intention. (arXiv:2208.01274v1 [cs.SE])
38. Understanding the classes better with class-specific and rule-specific feature selection, and redundancy control in a fuzzy rule based framework. (arXiv:2208.01294v1 [cs.LG])
39. Compound Density Networks for Risk Prediction using Electronic Health Records. (arXiv:2208.01320v1 [cs.LG])
40. A Comparative Study on COVID-19 Fake News Detection Using Different Transformer Based Models. (arXiv:2208.01355v1 [cs.CL])
41. What can we Learn by Predicting Accuracy?. (arXiv:2208.01358v1 [cs.LG])
42. Detecting Individual Decision-Making Style: Exploring Behavioral Stylometry in Chess. (arXiv:2208.01366v1 [cs.AI])
43. DAPDAG: Domain Adaptation via Perturbed DAG Reconstruction. (arXiv:2208.01373v1 [cs.LG])
44. A Deep Generative Model for Feasible and Diverse Population Synthesis. (arXiv:2208.01403v1 [stat.ML])
45. Replacing Backpropagation with Biological Plausible Top-down Credit Assignment in Deep Neural Networks Training. (arXiv:2208.01416v1 [cs.NE])
46. Predicting Future Mosquito Habitats Using Time Series Climate Forecasting and Deep Learning. (arXiv:2208.01436v1 [cs.LG])
47. Unsupervised machine learning framework for discriminating major variants of concern during COVID-19. (arXiv:2208.01439v1 [q-bio.OT])
48. AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model. (arXiv:2208.01448v1 [cs.CL])
49. A comment on Guo et al. [arXiv:2206.11228]. (arXiv:2208.01456v1 [q-bio.NC])
50. Physics-informed Deep Super-resolution for Spatiotemporal Data. (arXiv:2208.01462v1 [cs.LG])
51. IterMiUnet: A lightweight architecture for automatic blood vessel segmentation. (arXiv:2208.01485v1 [eess.IV])
52. Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter. (arXiv:2208.01489v1 [cs.CV])
53. s-LIME: Reconciling Locality and Fidelity in Linear Explanations. (arXiv:2208.01510v1 [cs.LG])
54. Unimodal Mono-Partite Matching in a Bandit Setting. (arXiv:2208.01511v1 [cs.LG])
55. UniRank: Unimodal Bandit Algorithm for Online Ranking. (arXiv:2208.01515v1 [cs.LG])
56. MT-SNN: Spiking Neural Network that Enables Single-Tasking of Multiple Tasks. (arXiv:2208.01522v1 [cs.NE])
57. CIPCaD-Bench: Continuous Industrial Process datasets for benchmarking Causal Discovery methods. (arXiv:2208.01529v1 [cs.LG])
58. The Curse of Low Task Diversity: On the Failure of Transfer Learning to Outperform MAML and Their Empirical Equivalence. (arXiv:2208.01545v1 [cs.LG])
59. Low-complexity CNNs for Acoustic Scene Classification. (arXiv:2208.01555v1 [eess.AS])
60. An Online Sparse Streaming Feature Selection Algorithm. (arXiv:2208.01562v1 [cs.LG])
61. Approximate Bayesian Neural Operators: Uncertainty Quantification for Parametric PDEs. (arXiv:2208.01565v1 [cs.LG])
62. Stochastic Deep Networks with Linear Competing Units for Model-Agnostic Meta-Learning. (arXiv:2208.01573v1 [cs.LG])
63. Cluster Weighted Model Based on TSNE algorithm for High-Dimensional Data. (arXiv:2208.01579v1 [stat.ML])
64. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v1 [eess.IV])
65. Enabling scalable clinical interpretation of ML-based phenotypes using real world data. (arXiv:2208.01607v1 [cs.LG])
66. An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion. (arXiv:2208.01618v1 [cs.CV])
67. Prompt-to-Prompt Image Editing with Cross Attention Control. (arXiv:2208.01626v1 [cs.CV])
68. Stochastic Primal-Dual Three Operator Splitting with Arbitrary Sampling and Preconditioning. (arXiv:2208.01631v1 [math.OC])
69. Generalization Bounds in the Predict-then-Optimize Framework. (arXiv:1905.11488v3 [cs.LG] UPDATED)
70. Unsupervised and Supervised Principal Component Analysis: Tutorial. (arXiv:1906.03148v2 [stat.ML] UPDATED)
71. Fisher and Kernel Fisher Discriminant Analysis: Tutorial. (arXiv:1906.09436v2 [stat.ML] UPDATED)
72. Data-Driven Discovery of Molecular Photoswitches with Multioutput Gaussian Processes. (arXiv:2008.03226v2 [physics.chem-ph] UPDATED)
73. Improving Few-Shot Learning through Multi-task Representation Learning Theory. (arXiv:2010.01992v3 [cs.LG] UPDATED)
74. Q4EDA: A Novel Strategy for Textual Information Retrieval Based on User Interactions with Visual Representations of Time Series. (arXiv:2101.08655v2 [cs.HC] UPDATED)
75. Word-level Text Highlighting of Medical Texts for Telehealth Services. (arXiv:2105.10400v2 [cs.LG] UPDATED)
76. Diffusion-Based Representation Learning. (arXiv:2105.14257v3 [cs.LG] UPDATED)
77. On Anytime Learning at Macroscale. (arXiv:2106.09563v5 [cs.LG] UPDATED)
78. Residual Tensor Train: A Quantum-inspired Approach for Learning Multiple Multilinear Correlations. (arXiv:2108.08659v2 [cs.LG] UPDATED)
79. Knowledge mining of unstructured information: application to cyber-domain. (arXiv:2109.03848v3 [cs.CR] UPDATED)
80. Anti-Neuron Watermarking: Protecting Personal Data Against Unauthorized Neural Networks. (arXiv:2109.09023v2 [cs.CR] UPDATED)
81. ENERO: Efficient Real-Time WAN Routing Optimization with Deep Reinforcement Learning. (arXiv:2109.10883v3 [cs.NI] UPDATED)
82. Learning of Parameters in Behavior Trees for Movement Skills. (arXiv:2109.13050v2 [cs.RO] UPDATED)
83. Neural Stochastic PDEs: Resolution-Invariant Learning of Continuous Spatiotemporal Dynamics. (arXiv:2110.10249v7 [cs.LG] UPDATED)
84. Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of Audio Signals. (arXiv:2110.14434v4 [cs.SD] UPDATED)
85. Binary Independent Component Analysis: A Non-stationarity-based Approach. (arXiv:2111.15431v2 [cs.LG] UPDATED)
86. Deep residential representations: Using unsupervised learning to unlock elevation data for geo-demographic prediction. (arXiv:2112.01421v2 [cs.LG] UPDATED)
87. Cadence: A Practical Time-series Partitioning Algorithm for Unlabeled IoT Sensor Streams. (arXiv:2112.03360v2 [cs.LG] UPDATED)
88. Variance-Aware Weight Initialization for Point Convolutional Neural Networks. (arXiv:2112.03777v2 [cs.CV] UPDATED)
89. Accoustate: Auto-annotation of IMU-generated Activity Signatures under Smart Infrastructure. (arXiv:2112.06651v2 [eess.SP] UPDATED)
90. A Survey of Natural Language Generation. (arXiv:2112.11739v2 [cs.CL] UPDATED)
91. Correlated-informed neural networks: a new machine learning framework to predict pressure drop in micro-channels. (arXiv:2201.07835v2 [cs.LG] UPDATED)
92. Politics, Sentiment and Virality: A Large-Scale Multilingual Twitter Analysis in Greece, Spain and United Kingdom. (arXiv:2202.00396v2 [cs.CL] UPDATED)
93. Systematically and efficiently improving existing $k$-means initialization algorithms by pairwise-nearest-neighbor smoothing. (arXiv:2202.03949v2 [cs.LG] UPDATED)
94. Learning Invariant Weights in Neural Networks. (arXiv:2202.12439v2 [stat.ML] UPDATED)
95. Graph-based Reinforcement Learning meets Mixed Integer Programs: An application to 3D robot assembly discovery. (arXiv:2203.04120v2 [cs.RO] UPDATED)
96. How to Learn from Risk: Explicit Risk-Utility Reinforcement Learning for Efficient and Safe Driving Strategies. (arXiv:2203.08409v2 [cs.LG] UPDATED)
97. Context-Aware Drift Detection. (arXiv:2203.08644v2 [stat.ML] UPDATED)
98. ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v2 [cs.CV] UPDATED)
99. WayFAST: Navigation with Predictive Traversability in the Field. (arXiv:2203.12071v2 [cs.RO] UPDATED)
100. Gaussian Control Barrier Functions : A Non-Parametric Paradigm to Safety. (arXiv:2203.15474v2 [eess.SY] UPDATED)
101. VI-IKD: High-Speed Accurate Off-Road Navigation using Learned Visual-Inertial Inverse Kinodynamics. (arXiv:2203.15983v2 [cs.RO] UPDATED)
102. Certified machine learning: A posteriori error estimation for physics-informed neural networks. (arXiv:2203.17055v3 [cs.LG] UPDATED)
103. "This is my unicorn, Fluffy": Personalizing frozen vision-language representations. (arXiv:2204.01694v3 [cs.CV] UPDATED)
104. Effects of Graph Convolutions in Multi-layer Networks. (arXiv:2204.09297v2 [cs.LG] UPDATED)
105. A Unifying Framework for Combining Complementary Strengths of Humans and ML toward Better Predictive Decision-Making. (arXiv:2204.10806v2 [cs.HC] UPDATED)
106. Causal Reasoning Meets Visual Representation Learning: A Prospective Study. (arXiv:2204.12037v6 [cs.CV] UPDATED)
107. Bridging Differential Privacy and Byzantine-Robustness via Model Aggregation. (arXiv:2205.00107v2 [cs.LG] UPDATED)
108. Optimizing Mixture of Experts using Dynamic Recompilations. (arXiv:2205.01848v2 [cs.LG] UPDATED)
109. Spiking Graph Convolutional Networks. (arXiv:2205.02767v2 [cs.LG] UPDATED)
110. Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v5 [cs.AI] UPDATED)
111. GINK: Graph-based Interaction-aware Kinodynamic Planning via Reinforcement Learning for Autonomous Driving. (arXiv:2206.01488v2 [cs.RO] UPDATED)
112. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v4 [cs.CV] UPDATED)
113. Trimmed Maximum Likelihood Estimation for Robust Learning in Generalized Linear Models. (arXiv:2206.04777v2 [cs.LG] UPDATED)
114. Mutation Models: Learning to Generate Levels by Imitating Evolution. (arXiv:2206.05497v2 [cs.AI] UPDATED)
115. Classifying Unstructured Clinical Notes via Automatic Weak Supervision. (arXiv:2206.12088v2 [cs.CL] UPDATED)
116. Market Making with Scaled Beta Policies. (arXiv:2207.03352v3 [q-fin.TR] UPDATED)
117. A developmental approach for training deep belief networks. (arXiv:2207.05473v2 [cs.LG] UPDATED)
118. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v4 [eess.SY] UPDATED)
119. Research Trends and Applications of Data Augmentation Algorithms. (arXiv:2207.08817v2 [cs.LG] UPDATED)
120. Benchmark time series data sets for PyTorch -- the torchtime package. (arXiv:2207.12503v2 [cs.LG] UPDATED)
121. Quantum Data Center: Theories and Applications. (arXiv:2207.14336v2 [quant-ph] UPDATED)
122. Lower bounds for learning quantum states with single-copy measurements. (arXiv:2207.14438v2 [quant-ph] UPDATED)
123. Building Trust: Lessons from the Technion-Rambam Machine Learning in Healthcare Datathon Event. (arXiv:2207.14638v2 [cs.DB] UPDATED)
124. A Data-driven Latent Semantic Analysis for Automatic Text Summarization using LDA Topic Modelling. (arXiv:2207.14687v3 [cs.IR] UPDATED)
125. Simplex Clustering via sBeta with Applications to Online Adjustment of Black-Box Predictions. (arXiv:2208.00287v2 [cs.CV] UPDATED)
126. Convex duality for stochastic shortest path problems in known and unknown environments. (arXiv:2208.00330v2 [cs.LG] UPDATED)
127. Generative Bias for Visual Question Answering. (arXiv:2208.00690v2 [cs.CV] UPDATED)
128. Visual correspondence-based explanations improve AI robustness and human-AI team accuracy. (arXiv:2208.00780v2 [cs.CV] UPDATED)
129. Self-supervised Group Meiosis Contrastive Learning for EEG-Based Emotion Recognition. (arXiv:2208.00877v2 [eess.SP] UPDATED)
## cs.AI
---
**61** new papers in cs.AI:-) 
1. Learning to estimate a surrogate respiratory signal from cardiac motion by signal-to-signal translation. (arXiv:2208.01034v1 [eess.IV])
2. Face-to-Face Contrastive Learning for Social Intelligence Question-Answering. (arXiv:2208.01036v1 [cs.LG])
3. EBOCA: Evidences for BiOmedical Concepts Association Ontology. (arXiv:2208.01093v1 [cs.AI])
4. Efficient Personalized Learning for Wearable Health Applications using HyperDimensional Computing. (arXiv:2208.01095v1 [cs.LG])
5. VacciNet: Towards a Smart Framework for Learning the Distribution Chain Optimization of Vaccines for a Pandemic. (arXiv:2208.01112v1 [cs.LG])
6. Exploring the GLIDE model for Human Action-effect Prediction. (arXiv:2208.01136v1 [cs.CV])
7. Hierarchical Reinforcement Learning for Precise Soccer Shooting Skills using a Quadrupedal Robot. (arXiv:2208.01160v1 [cs.RO])
8. Patents Phrase to Phrase Semantic Matching Dataset. (arXiv:2208.01171v1 [cs.CL])
9. MV6D: Multi-View 6D Pose Estimation on RGB-D Frames Using a Deep Point-wise Voting Network. (arXiv:2208.01172v1 [cs.CV])
10. TextWorldExpress: Simulating Text Games at One Million Steps Per Second. (arXiv:2208.01174v1 [cs.CL])
11. Mitigating Biases in Student Performance Prediction via Attention-Based Personalized Federated Learning. (arXiv:2208.01182v1 [cs.LG])
12. Implicit Two-Tower Policies. (arXiv:2208.01191v1 [cs.LG])
13. Making a Spiking Net Work: Robust brain-like unsupervised machine learning. (arXiv:2208.01204v1 [cs.NE])
14. Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks. (arXiv:2208.01221v1 [cs.NI])
15. Optimal and Bounded-Suboptimal Multi-Goal Task Assignment and Path Finding. (arXiv:2208.01222v1 [cs.AI])
16. Multi-Goal Multi-Agent Pickup and Delivery. (arXiv:2208.01223v1 [cs.AI])
17. A Multifaceted Benchmarking of Synthetic Electronic Health Record Generation Models. (arXiv:2208.01230v1 [cs.LG])
18. Multilingual Coreference Resolution in Multiparty Dialogue. (arXiv:2208.01307v1 [cs.CL])
19. Joint Learning-based Causal Relation Extraction from Biomedical Literature. (arXiv:2208.01316v1 [cs.CL])
20. Detecting Individual Decision-Making Style: Exploring Behavioral Stylometry in Chess. (arXiv:2208.01366v1 [cs.AI])
21. DAPDAG: Domain Adaptation via Perturbed DAG Reconstruction. (arXiv:2208.01373v1 [cs.LG])
22. BERT4Loc: BERT for Location -- POI Recommender System. (arXiv:2208.01375v1 [cs.IR])
23. Active entailment encoding for explanation tree construction using parsimonious generation of hard negatives. (arXiv:2208.01376v1 [cs.CL])
24. Bounding Counterfactuals under Selection Bias. (arXiv:2208.01417v1 [stat.ML])
25. Unravelling Interlanguage Facts via Explainable Machine Learning. (arXiv:2208.01468v1 [cs.CL])
26. MEMO: Coverage-guided Model Generation For Deep Learning Library Testing. (arXiv:2208.01508v1 [cs.SE])
27. CIPCaD-Bench: Continuous Industrial Process datasets for benchmarking Causal Discovery methods. (arXiv:2208.01529v1 [cs.LG])
28. Towards Psychologically-Grounded Dynamic Preference Models. (arXiv:2208.01534v1 [cs.IR])
29. Improving Few-Shot Learning through Multi-task Representation Learning Theory. (arXiv:2010.01992v3 [cs.LG] UPDATED)
30. Accoustate: Auto-annotation of IMU-generated Activity Signatures under Smart Infrastructure. (arXiv:2112.06651v2 [eess.SP] UPDATED)
31. A Survey of Natural Language Generation. (arXiv:2112.11739v2 [cs.CL] UPDATED)
32. FAT: An In-Memory Accelerator with Fast Addition for Ternary Weight Neural Networks. (arXiv:2201.07634v2 [cs.AR] UPDATED)
33. Correlated-informed neural networks: a new machine learning framework to predict pressure drop in micro-channels. (arXiv:2201.07835v2 [cs.LG] UPDATED)
34. Efficient Spatial Representation and Routing of Deformable One-Dimensional Objects for Manipulation. (arXiv:2202.06172v3 [cs.RO] UPDATED)
35. Inference of Affordances and Active Motor Control in Simulated Agents. (arXiv:2202.11532v3 [cs.AI] UPDATED)
36. Teaching Robots to Span the Space of Functional Expressive Motion. (arXiv:2203.02091v2 [cs.RO] UPDATED)
37. Graph-based Reinforcement Learning meets Mixed Integer Programs: An application to 3D robot assembly discovery. (arXiv:2203.04120v2 [cs.RO] UPDATED)
38. Tactile-Sensitive NewtonianVAE for High-Accuracy Industrial Connector Insertion. (arXiv:2203.05955v2 [cs.RO] UPDATED)
39. An Introduction to Multi-Agent Reinforcement Learning and Review of its Application to Autonomous Mobility. (arXiv:2203.07676v2 [cs.AI] UPDATED)
40. WayFAST: Navigation with Predictive Traversability in the Field. (arXiv:2203.12071v2 [cs.RO] UPDATED)
41. VI-IKD: High-Speed Accurate Off-Road Navigation using Learned Visual-Inertial Inverse Kinodynamics. (arXiv:2203.15983v2 [cs.RO] UPDATED)
42. ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound. (arXiv:2204.02874v3 [cs.CV] UPDATED)
43. Causal Reasoning Meets Visual Representation Learning: A Prospective Study. (arXiv:2204.12037v6 [cs.CV] UPDATED)
44. Learning Multi-dimensional Edge Feature-based AU Relation Graph for Facial Action Unit Recognition. (arXiv:2205.01782v2 [cs.CV] UPDATED)
45. Spiking Graph Convolutional Networks. (arXiv:2205.02767v2 [cs.LG] UPDATED)
46. Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v5 [cs.AI] UPDATED)
47. Computable Artificial General Intelligence. (arXiv:2205.10513v4 [cs.AI] UPDATED)
48. GINK: Graph-based Interaction-aware Kinodynamic Planning via Reinforcement Learning for Autonomous Driving. (arXiv:2206.01488v2 [cs.RO] UPDATED)
49. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v4 [cs.CV] UPDATED)
50. Mutation Models: Learning to Generate Levels by Imitating Evolution. (arXiv:2206.05497v2 [cs.AI] UPDATED)
51. Market Making with Scaled Beta Policies. (arXiv:2207.03352v3 [q-fin.TR] UPDATED)
52. A new database of Houma Alliance Book ancient handwritten characters and classifier fusion approach. (arXiv:2207.05993v3 [cs.CV] UPDATED)
53. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v4 [eess.SY] UPDATED)
54. DeepIPC: Deeply Integrated Perception and Control for Mobile Robot in Real Environments. (arXiv:2207.09934v2 [cs.RO] UPDATED)
55. OpenFilter: A Framework to Democratize Research Access to Social Media AR Filters. (arXiv:2207.12319v2 [cs.CV] UPDATED)
56. 20 years of network community detection. (arXiv:2208.00111v2 [physics.soc-ph] UPDATED)
57. Simplex Clustering via sBeta with Applications to Online Adjustment of Black-Box Predictions. (arXiv:2208.00287v2 [cs.CV] UPDATED)
58. A Particle-Based Algorithm for Distributional Optimization on \textit{Constrained Domains} via Variational Transport and Mirror Descent. (arXiv:2208.00587v2 [math.OC] UPDATED)
59. Generative Bias for Visual Question Answering. (arXiv:2208.00690v2 [cs.CV] UPDATED)
60. Visual correspondence-based explanations improve AI robustness and human-AI team accuracy. (arXiv:2208.00780v2 [cs.CV] UPDATED)
61. Self-supervised Group Meiosis Contrastive Learning for EEG-Based Emotion Recognition. (arXiv:2208.00877v2 [eess.SP] UPDATED)

