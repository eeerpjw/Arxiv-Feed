# Your interest papers
---
## cs.CV
---
### Points2**NeRF**: Generating Neural Radiance Fields from 3D point cloud. (arXiv:2206.01290v1 [cs.CV])
- Authors : 
- Link : [http://arxiv.org/abs/2206.01290](http://arxiv.org/abs/2206.01290)
> ABSTRACT  :  Contemporary registration devices for 3D visual information, such as LIDARs and various depth cameras, capture data as 3D point clouds. In turn, such clouds are challenging to be processed due to their size and complexity. Existing methods address this problem by fitting a mesh to the point cloud and rendering it instead. This approach, however, leads to the reduced fidelity of the resulting visualization and misses color information of the objects crucial in computer graphics applications. In this work, we propose to mitigate this challenge by representing 3D objects as Neural Radiance Fields (**NeRF**s). We leverage a hypernetwork paradigm and train the model to take a 3D point cloud with the associated color values and return a **NeRF** network's weights that reconstruct 3D objects from input 2D images. Our method provides efficient 3D object representation and offers several advantages over the existing approaches, including the ability to condition **NeRF**s and improved generalization beyond objects seen in training. The latter we also confirmed in the results of our empirical evaluation.  
### RELAY: Robotic EyeLink AnalYsis of the EyeLink 1000 using an Artificial Eye. (arXiv:2206.01327v1 [cs.CV])
- Authors : Maria Fel, Dominykas Strazdas
- Link : [http://arxiv.org/abs/2206.01327](http://arxiv.org/abs/2206.01327)
> ABSTRACT  :  There is a widespread assumption that the peak velocities of visually guided saccades in the **dark** are up to 10~\% slower than those made in the light. Studies that questioned the impact of the surrounding brightness conditions, come to differing conclusions, whether they have an influence or not and if so, in which manner. The problem is of a complex nature as the illumination condition itself may not contribute to different measured peak velocities solely but in combination with the estimation of the pupil size due to its deformation during saccades or different gaze positions. Even the measurement technique of video-based eye tracking itself could play a significant role. To investigate this issue, we constructed a stepper motor driven artificial eye with fixed pupil size to mimic human saccades with predetermined peak velocity \&amp; amplitudes under three different brightness conditions with the EyeLink 1000, one of the most common used eye trackers. The aim was to control the pupil and brightness. With our device, an overall good accuracy and precision of the EyeLink 1000 could be confirmed. Furthermore, we could find that there is no artifact for pupil based eye tracking in relation to changing brightness conditions, neither for the pupil size nor for the peak velocities. What we found, was a systematic, small, yet significant change of the measured pupil sizes as a function of different gaze directions.  
### Long Scale Error Control in **Low Light** Image and Video **Enhancement** Using Equivariance. (arXiv:2206.01334v1 [cs.CV])
- Authors : Sara Aghajanzadeh, David Forsyth
- Link : [http://arxiv.org/abs/2206.01334](http://arxiv.org/abs/2206.01334)
> ABSTRACT  :  Image frames obtained in **dark**ness are special. Just multiplying by a constant doesn't restore the image. Shot noise, quantization effects and camera non-linearities mean that colors and relative light levels are estimated poorly. Current methods learn a mapping using real **dark**-bright image pairs. These are very hard to capture. A recent paper has shown that simulated data pairs produce real improvements in **restoration**, likely because huge volumes of simulated data are easy to obtain. In this paper, we show that respecting equivariance -- the color of a restored pixel should be the same, however the image is cropped -- produces real improvements over the state of the art for **restoration**. We show that a scale selection mechanism can be used to improve reconstructions. Finally, we show that our approach produces improvements on video **restoration** as well. Our methods are evaluated both quantitatively and qualitatively.  
### LenslessPiCam: A Hardware and Software Platform for Lensless Computational Imaging with a Raspberry Pi. (arXiv:2206.01430v1 [eess.IV])
- Authors : Eric Bezzam, Sepand Kashani, Martin Vetterli, Matthieu Simeoni
- Link : [http://arxiv.org/abs/2206.01430](http://arxiv.org/abs/2206.01430)
> ABSTRACT  :  Lensless imaging seeks to replace/remove the lens in a conventional imaging system. The earliest cameras were in fact lensless, relying on long **exposure** times to form images on the other end of a small aperture in a **dark**ened room/container (camera obscura). The introduction of a lens allowed for more light throughput and therefore shorter **exposure** times, while retaining sharp focus. The incorporation of digital sensors readily enabled the use of computational imaging techniques to post-process and enhance raw images (e.g. via deblurring, inpainting, denoising, sharpening). Recently, imaging scientists have started leveraging computational imaging as an integral part of lensless imaging systems, allowing them to form viewable images from the highly multiplexed raw measurements of lensless cameras (see [5] and references therein for a comprehensive treatment of lensless imaging). This represents a real paradigm shift in camera system design as there is more flexibility to cater the hardware to the application at hand (e.g. lightweight or flat designs). This increased flexibility comes however at the price of a more demanding post-processing of the raw digital recordings and a tighter integration of sensing and computation, often difficult to achieve in practice due to inefficient interactions between the various communities of scientists involved. With LenslessPiCam, we provide an easily accessible hardware and software framework to enable researchers, hobbyists, and students to implement and explore practical and computational aspects of lensless imaging. We also provide detailed guides and exercises so that LenslessPiCam can be used as an educational resource, and point to results from our graduate-level signal processing course.  
### Distributional loss for convolutional neural network regression and application to GNSS multi-path estimation. (arXiv:2206.01473v1 [cs.CV])
- Authors : Thomas Gonzalez, Antoine Blais, Nicolas Cou, Christian Ruiz
- Link : [http://arxiv.org/abs/2206.01473](http://arxiv.org/abs/2206.01473)
> ABSTRACT  :  Convolutional Neural Network (CNN) have been widely used in image classification. Over the years, they have also benefited from various **enhancement**s and they are now considered as state of the art techniques for image like data. However, when they are used for regression to estimate some function value from images, fewer recommendations are available. In this study, a novel CNN regression model is proposed. It combines convolutional neural layers to extract high level features representations from images with a soft labelling technique. More specifically, as the deep regression task is challenging, the idea is to account for some uncertainty in the targets that are seen as distributions around their mean. The estimations are carried out by the model in the form of distributions. Building from earlier work, a specific histogram loss function based on the Kullback-Leibler (KL) divergence is applied during training. The model takes advantage of the CNN feature representation and is able to carry out estimation from multi-channel input images. To assess and illustrate the technique, the model is applied to Global Navigation Satellite System (GNSS) multi-path estimation where multi-path signal parameters have to be estimated from correlator output images from the I and Q channels. The multi-path signal delay, magnitude, Doppler shift frequency and phase parameters are estimated from synthetically generated datasets of satellite signals. Experiments are conducted under various receiving conditions and various input images resolutions to test the estimation performances quality and robustness. The results show that the proposed soft labelling CNN technique using distributional loss outperforms classical CNN regression under all conditions. Furthermore, the extra learning performance achieved by the model allows the reduction of input image resolution from 80x80 down to 40x40 or sometimes 20x20.  
### YOLOv5s-GTB: light-weighted and improved YOLOv5s for bridge crack detection. (arXiv:2206.01498v1 [cs.CV])
- Authors : Xiao Ruiqiang
- Link : [http://arxiv.org/abs/2206.01498](http://arxiv.org/abs/2206.01498)
> ABSTRACT  :  In response to the situation that the conventional bridge crack manual detection method has a large amount of human and material resources wasted, this study is aimed to propose a light-weighted, high-precision, deep learning-based bridge apparent crack recognition model that can be deployed in mobile devices' scenarios. In order to enhance the performance of YOLOv5, firstly, the data augmentation methods are supplemented, and then the YOLOv5 series algorithm is trained to select a suitable basic framework. The YOLOv5s is identified as the basic framework for the light-weighted crack detection model through experiments for comparison and validation.By replacing the traditional **Dark**Net backbone network of YOLOv5s with GhostNet backbone network, introducing Transformer multi-headed self-attention mechanism and bi-directional feature pyramid network (BiFPN) to replace the commonly used feature pyramid network, the improved model not only has 42% fewer parameters and faster inference response, but also significantly outperforms the original model in terms of accuracy and mAP (8.5% and 1.1% improvement, respectively). Luckily each improved part has a positive impact on the result. This paper provides a feasible idea to establish a digital operation management system in the field of highway and bridge in the future and to implement the whole life cycle structure health monitoring of civil infrastructure in China.  
### Reinforcement Learning with Neural Radiance Fields. (arXiv:2206.01634v1 [cs.LG])
- Authors : Danny Driess, Ingmar Schubert, Pete Florence, Yunzhu Li, Marc Toussaint
- Link : [http://arxiv.org/abs/2206.01634](http://arxiv.org/abs/2206.01634)
> ABSTRACT  :  It is a long-standing problem to find effective representations for training reinforcement learning (RL) agents. This paper demonstrates that learning state representations with supervision from Neural Radiance Fields (**NeRF**s) can improve the performance of RL compared to other learned representations or even low-dimensional, hand-engineered state information. Specifically, we propose to train an encoder that maps multiple image observations to a latent space describing the objects in the scene. The decoder built from a latent-conditioned **NeRF** serves as the supervision signal to learn the latent space. An RL algorithm then operates on the learned latent space as its state representation. We call this **NeRF**-RL. Our experiments indicate that **NeRF** as supervision leads to a latent space better suited for the downstream RL tasks involving robotic object manipulations like hanging mugs on hooks, pushing objects, or opening doors. Video: https://dannydriess.github.io/nerf-rl  
### Augmented Equivariant Attention Networks for Microscopy Image Reconstruction. (arXiv:2011.03633v4 [cs.CV] UPDATED)
- Authors : Yaochen Xie, Yu Ding, Shuiwang Ji
- Link : [http://arxiv.org/abs/2011.03633](http://arxiv.org/abs/2011.03633)
> ABSTRACT  :  It is time-consuming and expensive to take high-quality or high-resolution electron microscopy (EM) and fluorescence microscopy (FM) images. Taking these images could be even invasive to samples and may damage certain subtleties in the samples after long or intense **exposure**s, often necessary for achieving high-quality or high resolution in the first place. Advances in deep learning enable us to perform image-to-image transformation tasks for various types of microscopy image reconstruction, computationally producing high-quality images from the physically acquired low-quality ones. When training image-to-image transformation models on pairs of experimentally acquired microscopy images, prior models suffer from performance loss due to their inability to capture inter-image dependencies and common features shared among images. Existing methods that take advantage of shared features in image classification tasks cannot be properly applied to image reconstruction tasks because they fail to preserve the equivariance property under spatial permutations, something essential in image-to-image transformation. To address these limitations, we propose the augmented equivariant attention networks (AEANets) with better capability to capture inter-image dependencies, while preserving the equivariance property. The proposed AEANets captures inter-image dependencies and shared features via two augmentations on the attention mechanism, which are the shared references and the batch-aware attention during training. We theoretically derive the equivariance property of the proposed augmented attention model and experimentally demonstrate its consistent superiority in both quantitative and visual results over the baseline methods.  
### A Novel Transformer Based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images. (arXiv:2104.12137v6 [cs.CV] UPDATED)
- Authors : Libo Wang, Rui Li, Chenxi Duan, Ce Zhang, Xiaoliang Meng, Shenghui Fang
- Link : [http://arxiv.org/abs/2104.12137](http://arxiv.org/abs/2104.12137)
> ABSTRACT  :  The fully convolutional network (FCN) with an encoder-decoder architecture has been the standard paradigm for semantic segmentation. The encoder-decoder architecture utilizes an encoder to capture multilevel feature maps, which are incorporated into the final prediction by a decoder. As the context is crucial for precise segmentation, tremendous effort has been made to extract such information in an intelligent fashion, including employing dilated/atrous convolutions or inserting attention modules. However, these endeavors are all based on the FCN architecture with ResNet or other backbones, which cannot fully exploit the context from the theoretical concept. By contrast, we introduce the **Swin** Transformer as the backbone to extract the context information and design a novel decoder of densely connected feature aggregation module (DCFAM) to restore the resolution and produce the segmentation map. The experimental results on two remotely sensed semantic segmentation datasets demonstrate the effectiveness of the proposed scheme.Code is available at https://github.com/WangLibo1995/GeoSeg  
### Transformer Meets Convolution: A **Bilateral** Awareness Network for Semantic Segmentation of Very Fine Resolution Urban Scene Images. (arXiv:2106.12413v2 [cs.CV] UPDATED)
- Authors : Libo Wang, Rui Li, Dongzhi Wang, Chenxi Duan, Teng Wang, Xiaoliang Meng
- Link : [http://arxiv.org/abs/2106.12413](http://arxiv.org/abs/2106.12413)
> ABSTRACT  :  Semantic segmentation from very fine resolution (VFR) urban scene images plays a significant role in several application scenarios including autonomous driving, land cover classification, and urban planning, etc. However, the tremendous details contained in the VFR image, especially the considerable variations in scale and appearance of objects, severely limit the potential of the existing deep learning approaches. Addressing such issues represents a promising research field in the remote sensing community, which paves the way for scene-level landscape pattern analysis and decision making. In this paper, we propose a **Bilateral** Awareness Network which contains a dependency path and a texture path to fully capture the long-range relationships and fine-grained details in VFR images. Specifically, the dependency path is conducted based on the ResT, a novel Transformer backbone with memory-efficient multi-head self-attention, while the texture path is built on the stacked convolution operation. Besides, using the linear attention mechanism, a feature aggregation module is designed to effectively fuse the dependency features and texture features. Extensive experiments conducted on the three large-scale urban scene image segmentation datasets, i.e., ISPRS Vaihingen dataset, ISPRS Potsdam dataset, and UAVid dataset, demonstrate the effectiveness of our BANet. Specifically, a 64.6% mIoU is achieved on the UAVid dataset. Code is available at https://github.com/WangLibo1995/GeoSeg.  
### Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction. (arXiv:2111.11215v2 [cs.CV] UPDATED)
- Authors : Cheng Sun, Min Sun, Tzong Chen
- Link : [http://arxiv.org/abs/2111.11215](http://arxiv.org/abs/2111.11215)
> ABSTRACT  :  We present a super-fast convergence approach to reconstructing the per-scene radiance field from a set of images that capture the scene with known poses. This task, which is often applied to novel view synthesis, is recently revolutionized by Neural Radiance Field (**NeRF**) for its state-of-the-art quality and flexibility. However, **NeRF** and its variants require a lengthy training time ranging from hours to days for a single scene. In contrast, our approach achieves **NeRF**-comparable quality and converges rapidly from scratch in less than 15 minutes with a single GPU. We adopt a representation consisting of a density voxel grid for scene geometry and a feature voxel grid with a shallow network for complex view-dependent appearance. Modeling with explicit and discretized volume representations is not new, but we propose two simple yet non-trivial techniques that contribute to fast convergence speed and high-quality output. First, we introduce the post-activation interpolation on voxel density, which is capable of producing sharp surfaces in lower grid resolution. Second, direct voxel density optimization is prone to suboptimal geometry solutions, so we robustify the optimization process by imposing several priors. Finally, evaluation on five inward-facing benchmarks shows that our method matches, if not surpasses, **NeRF**'s quality, yet it only takes about 15 minutes to train from scratch for a new scene.  
### Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives. (arXiv:2206.01136v2 [cs.CV] UPDATED)
- Authors : Jun Li, Junyu Chen, Yucheng Tang, Ce Wang, Kevin Zhou
- Link : [http://arxiv.org/abs/2206.01136](http://arxiv.org/abs/2206.01136)
> ABSTRACT  :  Transformer, the latest technological advance of deep learning, has gained prevalence in natural language processing or computer vision. Since medical imaging bear some resemblance to computer vision, it is natural to inquire about the status quo of Transformers in medical imaging and ask the question: can the Transformer models transform medical imaging? In this paper, we attempt to make a response to the inquiry. After a brief introduction of the fundamentals of Transformers, especially in comparison with convolutional neural networks (CNNs), and highlighting key defining properties that characterize the Transformers, we offer a comprehensive review of the state-of-the-art Transformer-based approaches for medical imaging and exhibit current research progresses made in the areas of medical image segmentation, recognition, detection, registration, reconstruction, **enhancement**, etc. In particular, what distinguishes our review lies in its organization based on the Transformer's key defining properties, which are mostly derived from comparing the Transformer and CNN, and its type of architecture, which specifies the manner in which the Transformer and CNN are combined, all helping the readers to best understand the rationale behind the reviewed approaches. We conclude with discussions of future perspectives.  
## eess.IV
---
### Multifocus microscopy with optically sectioned axial superresolution. (arXiv:2206.01257v1 [physics.optics])
- Authors : Florian Str, Daniel Henry, Mireia Nager, sa Birna
- Link : [http://arxiv.org/abs/2206.01257](http://arxiv.org/abs/2206.01257)
> ABSTRACT  :  Multifocus microscopy enables recording of entire volumes in a single camera **exposure**. In dense samples, multifocus microscopy is severely hampered by background haze. Here, we introduce a scalable multifocus method that incorporates optical sectioning and offers axial superresolution capabilities. In our method, a dithered oblique light-sheet scans the sample volume during a single **exposure**, while generated fluorescence is linearised onto the camera with a multifocus optical element. A synchronised rolling shutter readout realised optical sectioning. We describe the technique theoretically and verify its optical sectioning and superresolution capabilities. We demonstrate a prototype system with a multifocus beam splitter cascade and record monolayers of endothelial cells at 35 volumes per second. We furthermore image uncleared engineered human heart tissue and visualise the distribution of mitochondria at axial superresolution. Our method manages to capture sub-diffraction sized mitochondria-derived vesicles up to 30 um deep into the tissue.  
### LenslessPiCam: A Hardware and Software Platform for Lensless Computational Imaging with a Raspberry Pi. (arXiv:2206.01430v1 [eess.IV])
- Authors : Eric Bezzam, Sepand Kashani, Martin Vetterli, Matthieu Simeoni
- Link : [http://arxiv.org/abs/2206.01430](http://arxiv.org/abs/2206.01430)
> ABSTRACT  :  Lensless imaging seeks to replace/remove the lens in a conventional imaging system. The earliest cameras were in fact lensless, relying on long **exposure** times to form images on the other end of a small aperture in a **dark**ened room/container (camera obscura). The introduction of a lens allowed for more light throughput and therefore shorter **exposure** times, while retaining sharp focus. The incorporation of digital sensors readily enabled the use of computational imaging techniques to post-process and enhance raw images (e.g. via deblurring, inpainting, denoising, sharpening). Recently, imaging scientists have started leveraging computational imaging as an integral part of lensless imaging systems, allowing them to form viewable images from the highly multiplexed raw measurements of lensless cameras (see [5] and references therein for a comprehensive treatment of lensless imaging). This represents a real paradigm shift in camera system design as there is more flexibility to cater the hardware to the application at hand (e.g. lightweight or flat designs). This increased flexibility comes however at the price of a more demanding post-processing of the raw digital recordings and a tighter integration of sensing and computation, often difficult to achieve in practice due to inefficient interactions between the various communities of scientists involved. With LenslessPiCam, we provide an easily accessible hardware and software framework to enable researchers, hobbyists, and students to implement and explore practical and computational aspects of lensless imaging. We also provide detailed guides and exercises so that LenslessPiCam can be used as an educational resource, and point to results from our graduate-level signal processing course.  
## cs.LG
---
### Deep Learning Architecture Based Approach For 2D-Simulation of Microwave Plasma Interaction. (arXiv:2206.01263v1 [physics.comp-ph])
- Authors : Mihir Desai, Pratik Ghosh, Ahlad Kumar, Bhaskar Chaudhury
- Link : [http://arxiv.org/abs/2206.01263](http://arxiv.org/abs/2206.01263)
> ABSTRACT  :  This paper presents a convolutional neural network (CNN)-based deep learning model, inspired from UNet with series of encoder and decoder units with skip connections, for the simulation of microwave-plasma interaction. The microwave propagation characteristics in complex plasma medium pertaining to transmission, absorption and reflection primarily depends on the ratio of electromagnetic (EM) wave frequency and electron plasma frequency, and the plasma density profile. The scattering of a plane EM wave with fixed frequency (1 GHz) and amplitude incident on a plasma medium with different gaussian density profiles (in the range of $1\times 10^{17}-1\times 10^{22}{m^{-3}}$) have been considered. The training data associated with microwave-plasma interaction has been generated using 2D-FDTD (Finite Difference Time Domain) based simulations. The trained deep learning model is then used to reproduce the scattered electric field values for the 1GHz incident microwave on different plasma profiles with error margin of less than 2\%. We propose a complete deep learning (DL) based pipeline to train, validate and evaluate the model. We compare the results of the network, using various metrics like SSIM index, average percent error and mean square error, with the physical data obtained from well-established FDTD based EM solvers. To the best of our knowledge, this is the first effort towards exploring a DL based approach for the simulation of complex microwave plasma interaction. The deep learning technique proposed in this work is significantly fast as compared to the existing computational techniques, and can be used as a new, prospective and alternative computational approach for investigating microwave-plasma interaction in a **real time** scenario.  
### A High-Performance Customer Churn Prediction System based on Self-Attention. (arXiv:2206.01523v1 [cs.LG])
- Authors : Haotian Wu
- Link : [http://arxiv.org/abs/2206.01523](http://arxiv.org/abs/2206.01523)
> ABSTRACT  :  Customer churn prediction is a challenging domain of research that contributes to customer retention strategy. The predictive performance of existing machine learning models, which are often adopted by churn communities, appear to be at a bottleneck, partly due to models' poor feature extraction capability. Therefore, a novel algorithm, a hybrid neural network with self-attention **enhancement** (HNNSAE), is proposed in this paper to improve the efficiency of feature screening and feature extraction, consequently improving the model's predictive performance. This model consists of three main blocks. The first block is the entity embedding layer, which is employed to process the categorical variables transformed into 0-1 code. The second block is the feature extractor, which extracts the significant features through the multi-head self-attention mechanism. In addition, to improve the feature extraction effect, we stack the residual connection neural network on multi-head self-attention modules. The third block is a classifier, which is a three-layer multilayer perceptron. This work conducts experiments on publicly available dataset related to commercial bank customers. The result demonstrates that HNNSAE significantly outperforms the other Individual Machine Learning (IML), Ensemble Machine Learning (EML), and Deep Learning (DL) methods tested in this paper. Furthermore, we compare the performance of the feature extractor proposed in this paper with that of other three feature extractors and find that the method proposed in this paper significantly outperforms other methods. In addition, four hypotheses about model prediction performance and overfitting risk are tested on the publicly available dataset.  
### Accelerating hydrodynamic simulations of urban drainage systems with physics-guided machine learning. (arXiv:2206.01538v1 [cs.LG])
- Authors : Rocco Palmitessa, Morten Grum, Allan Peter
- Link : [http://arxiv.org/abs/2206.01538](http://arxiv.org/abs/2206.01538)
> ABSTRACT  :  We propose and demonstrate a new approach for fast and accurate surrogate modelling of urban drainage system hydraulics based on physics-guided machine learning. The surrogates are trained against a limited set of simulation results from a hydrodynamic (HiFi) model. Our approach reduces simulation times by one to two orders of magnitude compared to a HiFi model. It is thus slower than e.g. conceptual hydrological models, but it enables simulations of water levels, flows and surcharges in all nodes and links of a drainage network and thus largely preserves the level of detail provided by HiFi models. Comparing time series simulated by the surrogate and the HiFi model, R2 values in the order of 0.9 are achieved. Surrogate training times are currently in the order of one hour. However, they can likely be reduced through the application of transfer learning and graph neural networks. Our surrogate approach will be useful for interactive workshops in initial design phases of urban drainage systems, as well as for **real time** applications. In addition, our model formulation is generic and future research should investigate its application for simulating other water systems.  
### Reinforcement Learning with Neural Radiance Fields. (arXiv:2206.01634v1 [cs.LG])
- Authors : Danny Driess, Ingmar Schubert, Pete Florence, Yunzhu Li, Marc Toussaint
- Link : [http://arxiv.org/abs/2206.01634](http://arxiv.org/abs/2206.01634)
> ABSTRACT  :  It is a long-standing problem to find effective representations for training reinforcement learning (RL) agents. This paper demonstrates that learning state representations with supervision from Neural Radiance Fields (**NeRF**s) can improve the performance of RL compared to other learned representations or even low-dimensional, hand-engineered state information. Specifically, we propose to train an encoder that maps multiple image observations to a latent space describing the objects in the scene. The decoder built from a latent-conditioned **NeRF** serves as the supervision signal to learn the latent space. An RL algorithm then operates on the learned latent space as its state representation. We call this **NeRF**-RL. Our experiments indicate that **NeRF** as supervision leads to a latent space better suited for the downstream RL tasks involving robotic object manipulations like hanging mugs on hooks, pushing objects, or opening doors. Video: https://dannydriess.github.io/nerf-rl  
## cs.AI
---
# Paper List
---
## cs.CV
---
**77** new papers in cs.CV:-) 
1. What Are Expected Queries in End-to-End Object Detection?. (arXiv:2206.01232v1 [cs.CV])
2. Real-Time Portrait Stylization on the Edge. (arXiv:2206.01244v1 [cs.CV])
3. Expressiveness and Learnability: A Unifying View for Evaluating Self-Supervised Learning. (arXiv:2206.01251v1 [cs.LG])
4. PETRv2: A Unified Framework for 3D Perception from Multi-Camera Images. (arXiv:2206.01256v1 [cs.CV])
5. Points2**NeRF**: Generating Neural Radiance Fields from 3D point cloud. (arXiv:2206.01290v1 [cs.CV])
6. Lossless Compression of Point Cloud Sequences Using Sequence Optimized CNN Models. (arXiv:2206.01297v1 [cs.CV])
7. H-EMD: A Hierarchical Earth Mover's Distance Method for Instance Segmentation. (arXiv:2206.01309v1 [cs.CV])
8. Learning Unbiased Transferability for Domain Adaptation by Uncertainty Modeling. (arXiv:2206.01319v1 [cs.CV])
9. Improving Fairness in Large-Scale Object Recognition by CrowdSourced Demographic Information. (arXiv:2206.01326v1 [cs.CV])
10. RELAY: Robotic EyeLink AnalYsis of the EyeLink 1000 using an Artificial Eye. (arXiv:2206.01327v1 [cs.CV])
11. Long Scale Error Control in **Low Light** Image and Video **Enhancement** Using Equivariance. (arXiv:2206.01334v1 [cs.CV])
12. Detecting Pulmonary Embolism from Computed Tomography Using Convolutional Neural Network. (arXiv:2206.01344v1 [eess.IV])
13. Adversarial Attacks on Human Vision. (arXiv:2206.01365v1 [cs.CV])
14. Supernet Training for Federated Image Classification under System Heterogeneity. (arXiv:2206.01366v1 [cs.LG])
15. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v1 [cs.CV])
16. Slot Order Matters for Compositional Scene Understanding. (arXiv:2206.01370v1 [cs.CV])
17. CF-YOLO: Cross Fusion YOLO for Object Detection in Adverse Weather with a High-quality Real Snow Dataset. (arXiv:2206.01381v1 [cs.CV])
18. Falconn++: A Locality-sensitive Filtering Approach for Approximate Nearest Neighbor Search. (arXiv:2206.01382v1 [cs.DS])
19. End-to-End 3D Hand Pose Estimation from Stereo Cameras. (arXiv:2206.01384v1 [cs.CV])
20. Dynamic Structured Illumination Microscopy with a Neural Space-time Model. (arXiv:2206.01397v1 [physics.optics])
21. MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models. (arXiv:2206.01408v1 [cs.CV])
22. Learning an Adaptation Function to Assess Image Visual Similarities. (arXiv:2206.01417v1 [cs.CV])
23. Learning rich optical embeddings for privacy-preserving lensless image classification. (arXiv:2206.01429v1 [cs.CV])
24. LenslessPiCam: A Hardware and Software Platform for Lensless Computational Imaging with a Raspberry Pi. (arXiv:2206.01430v1 [eess.IV])
25. Exploring Transformers for Behavioural Biometrics: A Case Study in Gait Recognition. (arXiv:2206.01441v1 [cs.CV])
26. Zero-Shot Bird Species Recognition by Learning from Field Guides. (arXiv:2206.01466v1 [cs.CV])
27. Evaluating Transfer-based Targeted Adversarial Perturbations against Real-World Computer Vision Systems based on Human Judgments. (arXiv:2206.01467v1 [cs.CV])
28. Distributional loss for convolutional neural network regression and application to GNSS multi-path estimation. (arXiv:2206.01473v1 [cs.CV])
29. YOLOv5s-GTB: light-weighted and improved YOLOv5s for bridge crack detection. (arXiv:2206.01498v1 [cs.CV])
30. Anomaly detection in surveillance videos using transformer based attention model. (arXiv:2206.01524v1 [cs.CV])
31. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v1 [cs.LG])
32. Pruning for Interpretable, Feature-Preserving Circuits in CNNs. (arXiv:2206.01627v1 [cs.CV])
33. Reinforcement Learning with Neural Radiance Fields. (arXiv:2206.01634v1 [cs.LG])
34. Mirror modular cloning and fast quantum associative retrieval. (arXiv:2206.01644v1 [quant-ph])
35. Rethinking Positive Sampling for Contrastive Learning with Kernel. (arXiv:2206.01646v1 [cs.CV])
36. D'ARTAGNAN: Counterfactual Video Generation. (arXiv:2206.01651v1 [cs.CV])
37. Metrics reloaded: Pitfalls and recommendations for image analysis validation. (arXiv:2206.01653v1 [cs.CV])
38. Identification via Retinal Vessels Combining LBP and HOG. (arXiv:2206.01658v1 [cs.CV])
39. Style-Content Disentanglement in Language-Image Pretraining Representations for Zero-Shot Sketch-to-Image Synthesis. (arXiv:2206.01661v1 [cs.CV])
40. Egocentric Video-Language Pretraining. (arXiv:2206.01670v1 [cs.CV])
41. Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning. (arXiv:2206.01690v1 [cs.LG])
42. Gradient Obfuscation Checklist Test Gives a False Sense of Security. (arXiv:2206.01705v1 [cs.CV])
43. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v1 [cs.CV])
44. A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge. (arXiv:2206.01718v1 [cs.CV])
45. Revisiting the "Video" in Video-Language Understanding. (arXiv:2206.01720v1 [cs.CV])
46. SNAKE: Shape-aware Neural 3D Keypoint Field. (arXiv:2206.01724v1 [cs.CV])
47. GASP, a generalized framework for agglomerative clustering of signed graphs and its application to Instance Segmentation. (arXiv:1906.11713v2 [cs.CV] UPDATED)
48. Augmented Equivariant Attention Networks for Microscopy Image Reconstruction. (arXiv:2011.03633v4 [cs.CV] UPDATED)
49. A Novel Transformer Based Semantic Segmentation Scheme for Fine-Resolution Remote Sensing Images. (arXiv:2104.12137v6 [cs.CV] UPDATED)
50. Weakly Supervised Volumetric Image Segmentation with Deformed Templates. (arXiv:2106.03987v3 [cs.CV] UPDATED)
51. Source Data-Free Cross-Domain Semantic Segmentation: Align, Teach and Propagate. (arXiv:2106.11653v4 [cs.CV] UPDATED)
52. Multiband VAE: Latent Space Alignment for Knowledge Consolidation in Continual Learning. (arXiv:2106.12196v2 [cs.LG] UPDATED)
53. Transformer Meets Convolution: A **Bilateral** Awareness Network for Semantic Segmentation of Very Fine Resolution Urban Scene Images. (arXiv:2106.12413v2 [cs.CV] UPDATED)
54. An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Location Deep Features. (arXiv:2106.15113v3 [cs.CV] UPDATED)
55. NanoBatch Privacy: Enabling fast Differentially Private learning on the IPU. (arXiv:2109.12191v2 [cs.LG] UPDATED)
56. KITTI-360: A Novel Dataset and Benchmarks for Urban Scene Understanding in 2D and 3D. (arXiv:2109.13410v2 [cs.CV] UPDATED)
57. Direct Voxel Grid Optimization: Super-fast Convergence for Radiance Fields Reconstruction. (arXiv:2111.11215v2 [cs.CV] UPDATED)
58. MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection. (arXiv:2111.13336v2 [cs.CV] UPDATED)
59. PTCT: Patches with 3D-Temporal Convolutional Transformer Network for Precipitation Nowcasting. (arXiv:2112.01085v2 [cs.CV] UPDATED)
60. What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods. (arXiv:2112.04417v2 [cs.CV] UPDATED)
61. MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image Manipulation Detection. (arXiv:2112.08935v2 [cs.CV] UPDATED)
62. A Novel Framework to Jointly Compress and Index Remote Sensing Images for Efficient Content-Based Retrieval. (arXiv:2201.06459v2 [cs.CV] UPDATED)
63. Understanding Deep Contrastive Learning via Coordinate-wise Optimization. (arXiv:2201.12680v4 [cs.LG] UPDATED)
64. Compositional Scene Representation Learning via Reconstruction: A Survey. (arXiv:2202.07135v2 [cs.LG] UPDATED)
65. UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography. (arXiv:2202.10847v2 [eess.IV] UPDATED)
66. Edge Augmentation for Large-Scale Sketch Recognition without Sketches. (arXiv:2202.13164v2 [cs.CV] UPDATED)
67. Depth-SIMS: Semi-Parametric Image and Depth Synthesis. (arXiv:2203.03405v2 [cs.CV] UPDATED)
68. Towards End-to-End Unified Scene Text Detection and Layout Analysis. (arXiv:2203.15143v2 [cs.CV] UPDATED)
69. End-to-end Document Recognition and Understanding with Dessurt. (arXiv:2203.16618v2 [cs.CV] UPDATED)
70. Exploring Visual Prompts for Adapting Large-Scale Models. (arXiv:2203.17274v2 [cs.CV] UPDATED)
71. Powering Finetuning in Few-Shot Learning: Domain-Agnostic Bias Reduction with Selected Sampling. (arXiv:2204.03749v2 [cs.CV] UPDATED)
72. Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding. (arXiv:2204.08129v2 [cs.CV] UPDATED)
73. HierAttn: Effectively Learn Representations from Stage Attention and Branch Attention for Skin Lesions Diagnosis. (arXiv:2205.04326v5 [eess.IV] UPDATED)
74. Gender and Racial Bias in Visual Question Answering Datasets. (arXiv:2205.08148v3 [cs.CV] UPDATED)
75. Contrastive Learning with Boosted Memorization. (arXiv:2205.12693v5 [cs.CV] UPDATED)
76. Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning. (arXiv:2206.01088v2 [eess.IV] UPDATED)
77. Transforming medical imaging with Transformers? A comparative review of key properties, current progresses, and future perspectives. (arXiv:2206.01136v2 [cs.CV] UPDATED)
## eess.IV
---
**15** new papers in eess.IV:-) 
1. Real-Time Portrait Stylization on the Edge. (arXiv:2206.01244v1 [cs.CV])
2. Multifocus microscopy with optically sectioned axial superresolution. (arXiv:2206.01257v1 [physics.optics])
3. Lossless Compression of Point Cloud Sequences Using Sequence Optimized CNN Models. (arXiv:2206.01297v1 [cs.CV])
4. Detecting Pulmonary Embolism from Computed Tomography Using Convolutional Neural Network. (arXiv:2206.01344v1 [eess.IV])
5. Beta Generalized Normal Distribution with an Application for SAR Image Processing. (arXiv:2206.01357v1 [math.ST])
6. Adversarial Attacks on Human Vision. (arXiv:2206.01365v1 [cs.CV])
7. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v1 [cs.CV])
8. Dynamic Structured Illumination Microscopy with a Neural Space-time Model. (arXiv:2206.01397v1 [physics.optics])
9. MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models. (arXiv:2206.01408v1 [cs.CV])
10. Learning rich optical embeddings for privacy-preserving lensless image classification. (arXiv:2206.01429v1 [cs.CV])
11. LenslessPiCam: A Hardware and Software Platform for Lensless Computational Imaging with a Raspberry Pi. (arXiv:2206.01430v1 [eess.IV])
12. A tissue-fraction estimation-based segmentation method for quantitative dopamine transporter SPECT. (arXiv:2101.06729v3 [physics.med-ph] UPDATED)
13. UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography. (arXiv:2202.10847v2 [eess.IV] UPDATED)
14. HierAttn: Effectively Learn Representations from Stage Attention and Branch Attention for Skin Lesions Diagnosis. (arXiv:2205.04326v5 [eess.IV] UPDATED)
15. Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning. (arXiv:2206.01088v2 [eess.IV] UPDATED)
## cs.LG
---
**158** new papers in cs.LG:-) 
1. Snow Mountain: Dataset of Audio Recordings of The Bible in Low Resource Languages. (arXiv:2206.01205v1 [eess.AS])
2. Positive Unlabeled Contrastive Learning. (arXiv:2206.01206v1 [cs.LG])
3. RACA: Relation-Aware Credit Assignment for Ad-Hoc Cooperation in Multi-Agent Deep Reinforcement Learning. (arXiv:2206.01207v1 [cs.LG])
4. Accelerated first-order methods for convex optimization with locally Lipschitz continuous gradient. (arXiv:2206.01209v1 [math.OC])
5. Equivariant Reinforcement Learning for Quadrotor UAV. (arXiv:2206.01233v1 [cs.LG])
6. Stochastic gradient descent introduces an effective landscape-dependent regularization favoring flat solutions. (arXiv:2206.01246v1 [cond-mat.dis-nn])
7. Expressiveness and Learnability: A Unifying View for Evaluating Self-Supervised Learning. (arXiv:2206.01251v1 [cs.LG])
8. Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations. (arXiv:2206.01254v1 [cs.LG])
9. Compressive Fourier collocation methods for high-dimensional diffusion equations with periodic boundary conditions. (arXiv:2206.01255v1 [math.NA])
10. Entangled Residual Mappings. (arXiv:2206.01261v1 [cs.LG])
11. Deep Learning Architecture Based Approach For 2D-Simulation of Microwave Plasma Interaction. (arXiv:2206.01263v1 [physics.comp-ph])
12. Exponential Separations in Symmetric Neural Networks. (arXiv:2206.01266v1 [cs.LG])
13. Algorithmic Stability of Heavy-Tailed Stochastic Gradient Descent on Least Squares. (arXiv:2206.01274v1 [stat.ML])
14. Lottery Tickets on a Data Diet: Finding Initializations with Sparse Trainable Networks. (arXiv:2206.01278v1 [cs.LG])
15. Sequential Permutation Testing of Random Forest Variable Importance Measures. (arXiv:2206.01284v1 [stat.ME])
16. Decentralized Training of Foundation Models in Heterogeneous Environments. (arXiv:2206.01288v1 [cs.DC])
17. Incrementality Bidding via Reinforcement Learning under Mixed and Delayed Rewards. (arXiv:2206.01293v1 [cs.LG])
18. Rashomon Capacity: A Metric for Predictive Multiplicity in Probabilistic Classification. (arXiv:2206.01295v1 [cs.LG])
19. PNODE: A memory-efficient neural ODE framework based on high-level adjoint differentiation. (arXiv:2206.01298v1 [cs.LG])
20. Fine-tuning Language Models over Slow Networks using Activation Compression with Guarantees. (arXiv:2206.01299v1 [cs.LG])
21. Learning a Restricted Boltzmann Machine using biased Monte Carlo sampling. (arXiv:2206.01310v1 [cs.LG])
22. Learning Soft Constraints From Constrained Expert Demonstrations. (arXiv:2206.01311v1 [cs.LG])
23. A New Security Boundary of Component Differentially Challenged XOR PUFs Against Machine Learning Modeling Attacks. (arXiv:2206.01314v1 [cs.CR])
24. Sample-Efficient Reinforcement Learning of Partially Observable Markov Games. (arXiv:2206.01315v1 [cs.LG])
25. SPD domain-specific batch normalization to crack interpretable unsupervised domain adaptation in EEG. (arXiv:2206.01323v1 [cs.LG])
26. Improving Fairness in Large-Scale Object Recognition by CrowdSourced Demographic Information. (arXiv:2206.01326v1 [cs.CV])
27. Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v1 [stat.ML])
28. Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code. (arXiv:2206.01335v1 [cs.SE])
29. Equipping Black-Box Policies with Model-Based Advice for Stable Nonlinear Control. (arXiv:2206.01341v1 [cs.LG])
30. Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning. (arXiv:2206.01342v1 [cs.LG])
31. HEX: Human-in-the-loop Explainability via Deep Reinforcement Learning. (arXiv:2206.01343v1 [cs.LG])
32. Detecting Pulmonary Embolism from Computed Tomography Using Convolutional Neural Network. (arXiv:2206.01344v1 [eess.IV])
33. MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data. (arXiv:2206.01347v1 [cs.AI])
34. On the Privacy Properties of GAN-generated Samples. (arXiv:2206.01349v1 [cs.LG])
35. Supernet Training for Federated Image Classification under System Heterogeneity. (arXiv:2206.01366v1 [cs.LG])
36. Adversarial Unlearning: Reducing Confidence Along Adversarial Directions. (arXiv:2206.01367v1 [cs.LG])
37. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v1 [cs.CV])
38. Slot Order Matters for Compositional Scene Understanding. (arXiv:2206.01370v1 [cs.CV])
39. Completion Time Minimization of Fog-RAN-Assisted Federated Learning With Rate-Splitting Transmission. (arXiv:2206.01373v1 [eess.SP])
40. Regularization-wise double descent: Why it occurs and how to eliminate it. (arXiv:2206.01378v1 [cs.LG])
41. Instant Graph Neural Networks for Dynamic Graphs. (arXiv:2206.01379v1 [cs.LG])
42. Generalization for multiclass classification with overparameterized linear models. (arXiv:2206.01399v1 [cs.LG])
43. MetaLR: Layer-wise Learning Rate based on Meta-Learning for Adaptively Fine-tuning Medical Pre-trained Models. (arXiv:2206.01408v1 [cs.CV])
44. Hybrid Models for Mixed Variables in Bayesian Optimization. (arXiv:2206.01409v1 [cs.LG])
45. Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain. (arXiv:2206.01410v1 [cs.LG])
46. Impact of the composition of feature extraction and class sampling in medicare fraud detection. (arXiv:2206.01413v1 [cs.LG])
47. Rate-Optimal Online Convex Optimization in Adaptive Linear Control. (arXiv:2206.01426v1 [cs.LG])
48. On the Generalization of Wasserstein Robust Federated Learning. (arXiv:2206.01432v1 [cs.LG])
49. Modeling electronic health record data using a knowledge-graph-embedded topic model. (arXiv:2206.01436v1 [cs.LG])
50. XPASC: Measuring Generalization in Weak Supervision. (arXiv:2206.01444v1 [cs.LG])
51. Indirect Active Learning. (arXiv:2206.01454v1 [math.ST])
52. Safety Certification for Stochastic Systems via Neural Barrier Functions. (arXiv:2206.01463v1 [eess.SY])
53. PAC Statistical Model Checking of Mean Payoff in Discrete- and Continuous-Time MDP. (arXiv:2206.01465v1 [eess.SY])
54. Zero-Shot Bird Species Recognition by Learning from Field Guides. (arXiv:2206.01466v1 [cs.CV])
55. Evaluating Transfer-based Targeted Adversarial Perturbations against Real-World Computer Vision Systems based on Human Judgments. (arXiv:2206.01467v1 [cs.CV])
56. Offline Reinforcement Learning with Causal Structured World Models. (arXiv:2206.01474v1 [cs.LG])
57. Functional Connectivity Methods for EEG-based Biometrics on a Large, Heterogeneous Dataset. (arXiv:2206.01475v1 [eess.SP])
58. Finding Rule-Interpretable Non-Negative Data Representation. (arXiv:2206.01483v1 [cs.LG])
59. Transferring Studies Across Embodiments: A Case Study in Confusion Detection. (arXiv:2206.01493v1 [cs.HC])
60. Constraining Gaussian processes for physics-informed acoustic emission mapping. (arXiv:2206.01495v1 [cs.LG])
61. Causality Learning With Wasserstein Generative Adversarial Networks. (arXiv:2206.01496v1 [cs.LG])
62. Can Hybrid Geometric Scattering Networks Help Solve the Maximal Clique Problem?. (arXiv:2206.01506v1 [cs.LG])
63. Can Requirements Engineering Support Explainable Artificial Intelligence? Towards a User-Centric Approach for Explainability Requirements. (arXiv:2206.01507v1 [cs.SE])
64. Canonical convolutional neural networks. (arXiv:2206.01509v1 [cs.LG])
65. Latent Topology Induction for Understanding Contextualized Representations. (arXiv:2206.01512v1 [cs.CL])
66. Understanding deep learning via decision boundary. (arXiv:2206.01515v1 [cs.LG])
67. A Survey on Surrogate-assisted Efficient Neural Architecture Search. (arXiv:2206.01520v1 [cs.LG])
68. A High-Performance Customer Churn Prediction System based on Self-Attention. (arXiv:2206.01523v1 [cs.LG])
69. Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination. (arXiv:2206.01535v1 [cs.LG])
70. Accelerating hydrodynamic simulations of urban drainage systems with physics-guided machine learning. (arXiv:2206.01538v1 [cs.LG])
71. Detecting the Severity of Major Depressive Disorder from Speech: A Novel HARD-Training Methodology. (arXiv:2206.01542v1 [cs.SD])
72. Beyond Opinion Mining: Summarizing Opinions of Customer Reviews. (arXiv:2206.01543v1 [cs.CL])
73. Truly Mesh-free Physics-Informed Neural Networks. (arXiv:2206.01545v1 [cs.LG])
74. Is an encoder within reach?. (arXiv:2206.01552v1 [cs.LG])
75. Disentangling Epistemic and Aleatoric Uncertainty in Reinforcement Learning. (arXiv:2206.01558v1 [cs.LG])
76. Prescriptive maintenance with causal machine learning. (arXiv:2206.01562v1 [econ.GN])
77. Optimal Weak to Strong Learning. (arXiv:2206.01563v1 [cs.LG])
78. On Calibration of Graph Neural Networks for Node Classification. (arXiv:2206.01570v1 [cs.LG])
79. Decentralized Optimistic Hyperpolicy Mirror Descent: Provably No-Regret Learning in Markov Games. (arXiv:2206.01588v1 [cs.LG])
80. MCD: Marginal Contrastive Discrimination for conditional density estimation. (arXiv:2206.01592v1 [stat.ML])
81. Non-Intrusive Reduced Models based on Operator Inference for Chaotic Systems. (arXiv:2206.01604v1 [cs.LG])
82. Excess risk analysis for epistemic uncertainty with application to variational inference. (arXiv:2206.01606v1 [stat.ML])
83. A Comparative Study on Energy Consumption Models for Drones. (arXiv:2206.01609v1 [cs.RO])
84. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v1 [cs.LG])
85. Learning programs by combining programs. (arXiv:2206.01614v1 [cs.LG])
86. Beyond Tabula Rasa: Reincarnating Reinforcement Learning. (arXiv:2206.01626v1 [cs.LG])
87. Pruning for Interpretable, Feature-Preserving Circuits in CNNs. (arXiv:2206.01627v1 [cs.CV])
88. Reinforcement Learning with Neural Radiance Fields. (arXiv:2206.01634v1 [cs.LG])
89. PROMISSING: Pruning Missing Values in Neural Networks. (arXiv:2206.01640v1 [cs.LG])
90. Neural Differential Equations for Learning to Program Neural Nets Through Continuous Learning Rules. (arXiv:2206.01649v1 [cs.LG])
91. Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning. (arXiv:2206.01663v1 [cs.LG])
92. BaCaDI: Bayesian Causal Discovery with Unknown Interventions. (arXiv:2206.01665v1 [cs.LG])
93. Algorithm for Constrained Markov Decision Process with Linear Convergence. (arXiv:2206.01666v1 [math.OC])
94. Dynamic Kernel Selection for Improved Generalization and Memory Efficiency in Meta-learning. (arXiv:2206.01690v1 [cs.LG])
95. Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals. (arXiv:2206.01691v1 [cs.CY])
96. Three-dimensional microstructure generation using generative adversarial neural networks in the context of continuum micromechanics. (arXiv:2206.01693v1 [cond-mat.mtrl-sci])
97. Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19 Patients with a Large Feature Set in 2021 BARDA Data Challenge. (arXiv:2206.01696v1 [cs.LG])
98. Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank. (arXiv:2206.01702v1 [cs.IR])
99. KCRL: Krasovskii-Constrained Reinforcement Learning with Guaranteed Stability in Nonlinear Dynamical Systems. (arXiv:2206.01704v1 [cs.LG])
100. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v1 [cs.CV])
101. Towards Evading the Limits of Randomized Smoothing: A Theoretical Analysis. (arXiv:2206.01715v1 [cs.LG])
102. A Theoretical Analysis on Feature Learning in Neural Networks: Emergence from Inputs and Advantage over Fixed Features. (arXiv:2206.01717v1 [cs.LG])
103. Revisiting the "Video" in Video-Language Understanding. (arXiv:2206.01720v1 [cs.CV])
104. A Learning-Based Method for Automatic Operator Selection in the Fanoos XAI System. (arXiv:2206.01722v1 [cs.LG])
105. ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero. (arXiv:1902.04522v5 [cs.AI] UPDATED)
106. Alternating Synthetic and Real Gradients for Neural Language Modeling. (arXiv:1902.10630v2 [cs.LG] UPDATED)
107. GASP, a generalized framework for agglomerative clustering of signed graphs and its application to Instance Segmentation. (arXiv:1906.11713v2 [cs.CV] UPDATED)
108. Rethinking Class-Prior Estimation for Positive-Unlabeled Learning. (arXiv:2002.03673v2 [cs.LG] UPDATED)
109. Reinforcement Learning with Fast Stabilization in Linear Dynamical Systems. (arXiv:2007.12291v2 [cs.LG] UPDATED)
110. The geometry of integration in text classification RNNs. (arXiv:2010.15114v2 [cs.LG] UPDATED)
111. Towards Accelerating Training of Batch Normalization: A Manifold Perspective. (arXiv:2101.02916v2 [cs.LG] UPDATED)
112. Pay attention to your loss: understanding misconceptions about 1-Lipschitz neural networks. (arXiv:2104.05097v5 [cs.LG] UPDATED)
113. Scalable Multirobot Planning for Informed Spatial Sampling. (arXiv:2105.10018v3 [cs.RO] UPDATED)
114. Distributional Reinforcement Learning with Unconstrained Monotonic Neural Networks. (arXiv:2106.03228v2 [cs.LG] UPDATED)
115. Multiband VAE: Latent Space Alignment for Knowledge Consolidation in Continual Learning. (arXiv:2106.12196v2 [cs.LG] UPDATED)
116. Global Self-Attention as a Replacement for Graph Convolution. (arXiv:2108.03348v3 [cs.LG] UPDATED)
117. Instance-dependent Label-noise Learning under a Structural Causal Model. (arXiv:2109.02986v3 [stat.ML] UPDATED)
118. NanoBatch Privacy: Enabling fast Differentially Private learning on the IPU. (arXiv:2109.12191v2 [cs.LG] UPDATED)
119. One-Bit Matrix Completion with Differential Privacy. (arXiv:2110.00719v3 [cs.CR] UPDATED)
120. Hydra: A System for Large Multi-Model Deep Learning. (arXiv:2110.08633v6 [cs.DC] UPDATED)
121. Continuous Control with Action Quantization from Demonstrations. (arXiv:2110.10149v2 [cs.LG] UPDATED)
122. Learning with convolution and pooling operations in kernel methods. (arXiv:2111.08308v2 [stat.ML] UPDATED)
123. Meta-Auto-Decoder for Solving Parametric Partial Differential Equations. (arXiv:2111.08823v2 [cs.LG] UPDATED)
124. What I Cannot Predict, I Do Not Understand: A Human-Centered Evaluation Framework for Explainability Methods. (arXiv:2112.04417v2 [cs.CV] UPDATED)
125. Central-Smoothing Hypergraph Neural Networks for Predicting Drug-Drug Interactions. (arXiv:2112.07837v3 [cs.LG] UPDATED)
126. CodedPaddedFL and CodedSecAgg: Straggler Mitigation and Secure Aggregation in Federated Learning. (arXiv:2112.08909v2 [cs.LG] UPDATED)
127. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v8 [cs.LG] UPDATED)
128. OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v6 [q-bio.BM] UPDATED)
129. Alpa: Automating Inter- and Intra-Operator Parallelism for Distributed Deep Learning. (arXiv:2201.12023v2 [cs.LG] UPDATED)
130. Understanding Deep Contrastive Learning via Coordinate-wise Optimization. (arXiv:2201.12680v4 [cs.LG] UPDATED)
131. Approximation of Images via Generalized Higher Order Singular Value Decomposition over Finite-dimensional Commutative Semisimple Algebra. (arXiv:2202.00450v7 [cs.LG] UPDATED)
132. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v4 [cs.CL] UPDATED)
133. Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?. (arXiv:2202.02812v2 [cs.LG] UPDATED)
134. Game of Privacy: Towards Better Federated Platform Collaboration under Privacy Restriction. (arXiv:2202.05139v3 [cs.LG] UPDATED)
135. Compositional Scene Representation Learning via Reconstruction: A Survey. (arXiv:2202.07135v2 [cs.LG] UPDATED)
136. Robust Multi-Objective Bayesian Optimization Under Input Noise. (arXiv:2202.07549v4 [cs.LG] UPDATED)
137. An alternative approach to train neural networks using monotone variational inequality. (arXiv:2202.08876v2 [stat.ML] UPDATED)
138. UncertaINR: Uncertainty Quantification of End-to-End Implicit Neural Representations for Computed Tomography. (arXiv:2202.10847v2 [eess.IV] UPDATED)
139. A Fair Empirical Risk Minimization with Generalized Entropy. (arXiv:2202.11966v2 [cs.LG] UPDATED)
140. BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves Biomedical Machine Reading Comprehension Task. (arXiv:2202.13174v2 [cs.CL] UPDATED)
141. On the Benefits of Large Learning Rates for Kernel Methods. (arXiv:2202.13733v2 [stat.ML] UPDATED)
142. A Fast and Convergent Proximal Algorithm for Regularized Nonconvex and Nonsmooth Bi-level Optimization. (arXiv:2203.16615v2 [cs.LG] UPDATED)
143. Causal Transformer for Estimating Counterfactual Outcomes. (arXiv:2204.07258v2 [cs.LG] UPDATED)
144. It's DONE: Direct ONE-shot learning with Hebbian weight imprinting. (arXiv:2204.13361v2 [cs.LG] UPDATED)
145. Differentially Private Multivariate Time Series Forecasting of Aggregated Human Mobility With Deep Learning: Input or Gradient Perturbation?. (arXiv:2205.00436v2 [cs.LG] UPDATED)
146. Nonstationary Bandit Learning via Predictive Sampling. (arXiv:2205.01970v2 [cs.LG] UPDATED)
147. HierAttn: Effectively Learn Representations from Stage Attention and Branch Attention for Skin Lesions Diagnosis. (arXiv:2205.04326v5 [eess.IV] UPDATED)
148. An Introduction to Quantum Machine Learning for Engineers. (arXiv:2205.09510v3 [quant-ph] UPDATED)
149. Linear Connectivity Reveals Generalization Strategies. (arXiv:2205.12411v2 [cs.LG] UPDATED)
150. Linear Algorithms for Nonparametric Multiclass Probability Estimation. (arXiv:2205.12460v2 [stat.ME] UPDATED)
151. Self-supervised Pretraining and Transfer Learning Enable Flu and COVID-19 Predictions in Small Mobile Sensing Datasets. (arXiv:2205.13607v2 [cs.LG] UPDATED)
152. Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer. (arXiv:2205.13947v2 [cs.LG] UPDATED)
153. Bayesian Robust Graph Contrastive Learning. (arXiv:2205.14109v3 [cs.LG] UPDATED)
154. Adaptive Learning for Discovery. (arXiv:2205.14829v2 [stat.ML] UPDATED)
155. Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning. (arXiv:2206.00518v2 [cs.LG] UPDATED)
156. Machine Learning-based Lung and Colon Cancer Detection using Deep Feature Extraction and Ensemble Learning. (arXiv:2206.01088v2 [eess.IV] UPDATED)
157. Measuring Unintended Memorisation of Unique Private Features in Neural Networks. (arXiv:2202.08099v1 [cs.LG] CROSS LISTED)
158. Transformer-Based Self-Supervised Learning for Emotion Recognition. (arXiv:2204.05103v2 [q-bio.NC] CROSS LISTED)
## cs.AI
---
**70** new papers in cs.AI:-) 
1. Positive Unlabeled Contrastive Learning. (arXiv:2206.01206v1 [cs.LG])
2. RACA: Relation-Aware Credit Assignment for Ad-Hoc Cooperation in Multi-Agent Deep Reinforcement Learning. (arXiv:2206.01207v1 [cs.LG])
3. Fuzzy granular approximation classifier. (arXiv:2206.01240v1 [cs.AI])
4. Expressiveness and Learnability: A Unifying View for Evaluating Self-Supervised Learning. (arXiv:2206.01251v1 [cs.LG])
5. Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations. (arXiv:2206.01254v1 [cs.LG])
6. Entangled Residual Mappings. (arXiv:2206.01261v1 [cs.LG])
7. Data-Driven Linear Koopman Embedding for Model-Predictive Power System Control. (arXiv:2206.01272v1 [eess.SY])
8. Lottery Tickets on a Data Diet: Finding Initializations with Sparse Trainable Networks. (arXiv:2206.01278v1 [cs.LG])
9. Deceptive Planning for Resource Allocation. (arXiv:2206.01306v1 [math.OC])
10. Sample-Efficient Reinforcement Learning of Partially Observable Markov Games. (arXiv:2206.01315v1 [cs.LG])
11. Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v1 [stat.ML])
12. Understanding the Role of Nonlinearity in Training Dynamics of Contrastive Learning. (arXiv:2206.01342v1 [cs.LG])
13. MultiHiertt: Numerical Reasoning over Multi Hierarchical Tabular and Textual Data. (arXiv:2206.01347v1 [cs.AI])
14. On the Privacy Properties of GAN-generated Samples. (arXiv:2206.01349v1 [cs.LG])
15. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v1 [cs.CV])
16. Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain. (arXiv:2206.01410v1 [cs.LG])
17. One-shot Learning for Autonomous Aerial Manipulation. (arXiv:2206.01411v1 [cs.RO])
18. Learning Distributed and Fair Policies for Network Load Balancing as Markov Potentia Game. (arXiv:2206.01451v1 [cs.AI])
19. GINK: Graph-based Interaction-aware Kinodynamic Planning via Reinforcement Learning for Autonomous Driving. (arXiv:2206.01488v1 [cs.RO])
20. Transferring Studies Across Embodiments: A Case Study in Confusion Detection. (arXiv:2206.01493v1 [cs.HC])
21. Causality Learning With Wasserstein Generative Adversarial Networks. (arXiv:2206.01496v1 [cs.LG])
22. Can Requirements Engineering Support Explainable Artificial Intelligence? Towards a User-Centric Approach for Explainability Requirements. (arXiv:2206.01507v1 [cs.SE])
23. Latent Topology Induction for Understanding Contextualized Representations. (arXiv:2206.01512v1 [cs.CL])
24. Understanding deep learning via decision boundary. (arXiv:2206.01515v1 [cs.LG])
25. Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization. (arXiv:2206.01532v1 [cs.CL])
26. Rethinking and Scaling Up Graph Contrastive Learning: An Extremely Efficient Approach with Group Discrimination. (arXiv:2206.01535v1 [cs.LG])
27. Beyond Opinion Mining: Summarizing Opinions of Customer Reviews. (arXiv:2206.01543v1 [cs.CL])
28. Extracting Similar Questions From Naturally-occurring Business Conversations. (arXiv:2206.01585v1 [cs.CL])
29. Employing Socially Interactive Agents for Robotic Neurorehabilitation Training. (arXiv:2206.01587v1 [cs.HC])
30. A Hierarchical Pedestrian Behavior Model to Generate Realistic Human Behavior in Traffic Simulation. (arXiv:2206.01601v1 [cs.RO])
31. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v1 [cs.LG])
32. Learning programs by combining programs. (arXiv:2206.01614v1 [cs.LG])
33. Beyond Tabula Rasa: Reincarnating Reinforcement Learning. (arXiv:2206.01626v1 [cs.LG])
34. PROMISSING: Pruning Missing Values in Neural Networks. (arXiv:2206.01640v1 [cs.LG])
35. Mirror modular cloning and fast quantum associative retrieval. (arXiv:2206.01644v1 [quant-ph])
36. Joint Energy Dispatch and Unit Commitment in Microgrids Based on Deep Reinforcement Learning. (arXiv:2206.01663v1 [cs.LG])
37. Egocentric Video-Language Pretraining. (arXiv:2206.01670v1 [cs.CV])
38. ArgRewrite V.2: an Annotated Argumentative Revisions Corpus. (arXiv:2206.01677v1 [cs.CL])
39. Toward a realistic model of speech processing in the brain with self-supervised learning. (arXiv:2206.01685v1 [q-bio.NC])
40. Measuring Gender Bias in Word Embeddings of Gendered Languages Requires Disentangling Grammatical Gender Signals. (arXiv:2206.01691v1 [cs.CY])
41. Scalar is Not Enough: Vectorization-based Unbiased Learning to Rank. (arXiv:2206.01702v1 [cs.IR])
42. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v1 [cs.CV])
43. Revisiting the "Video" in Video-Language Understanding. (arXiv:2206.01720v1 [cs.CV])
44. A Learning-Based Method for Automatic Operator Selection in the Fanoos XAI System. (arXiv:2206.01722v1 [cs.LG])
45. SNAKE: Shape-aware Neural 3D Keypoint Field. (arXiv:2206.01724v1 [cs.CV])
46. ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero. (arXiv:1902.04522v5 [cs.AI] UPDATED)
47. Explainable Goal-Driven Agents and Robots -- A Comprehensive Review. (arXiv:2004.09705v8 [cs.RO] UPDATED)
48. A Combination of Multi-Objective Genetic Algorithm and Deep Learning for Music Harmony Generation. (arXiv:2102.07960v3 [cs.AI] UPDATED)
49. BlonDe: An Automatic Evaluation Metric for Document-level Machine Translation. (arXiv:2103.11878v3 [cs.CL] UPDATED)
50. Pay attention to your loss: understanding misconceptions about 1-Lipschitz neural networks. (arXiv:2104.05097v5 [cs.LG] UPDATED)
51. Quantum Uncertainty in Decision Theory. (arXiv:2105.07877v2 [cs.AI] UPDATED)
52. Distributional Reinforcement Learning with Unconstrained Monotonic Neural Networks. (arXiv:2106.03228v2 [cs.LG] UPDATED)
53. An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Location Deep Features. (arXiv:2106.15113v3 [cs.CV] UPDATED)
54. LAGr: Labeling Aligned Graphs for Improving Systematic Generalization in Semantic Parsing. (arXiv:2110.07572v2 [cs.CL] UPDATED)
55. Continuous Control with Action Quantization from Demonstrations. (arXiv:2110.10149v2 [cs.LG] UPDATED)
56. Obvious Manipulability of Voting Rules. (arXiv:2111.01983v2 [cs.GT] UPDATED)
57. Meta-Auto-Decoder for Solving Parametric Partial Differential Equations. (arXiv:2111.08823v2 [cs.LG] UPDATED)
58. MVSS-Net: Multi-View Multi-Scale Supervised Networks for Image Manipulation Detection. (arXiv:2112.08935v2 [cs.CV] UPDATED)
59. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v8 [cs.LG] UPDATED)
60. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v4 [cs.CL] UPDATED)
61. Robust Multi-Objective Bayesian Optimization Under Input Noise. (arXiv:2202.07549v4 [cs.LG] UPDATED)
62. BioADAPT-MRC: Adversarial Learning-based Domain Adaptation Improves Biomedical Machine Reading Comprehension Task. (arXiv:2202.13174v2 [cs.CL] UPDATED)
63. MAS2HP: A Multi Agent System to Predict Protein Structure in 2D HP model. (arXiv:2205.08451v4 [q-bio.BM] UPDATED)
64. Hybrid Manufacturing Process Planning for Arbitrary Part and Tool Shapes. (arXiv:2205.11805v2 [cs.CG] UPDATED)
65. Comparing the Digital Annealer with Classical Evolutionary Algorithm. (arXiv:2205.13586v2 [cs.NE] UPDATED)
66. Spatio-Temporal Graph Few-Shot Learning with Cross-City Knowledge Transfer. (arXiv:2205.13947v2 [cs.LG] UPDATED)
67. Geometer: Graph Few-Shot Class-Incremental Learning via Prototype Representation. (arXiv:2205.13954v2 [cs.AI] UPDATED)
68. Efficient Scheduling of Data Augmentation for Deep Reinforcement Learning. (arXiv:2206.00518v2 [cs.LG] UPDATED)
69. Measuring Unintended Memorisation of Unique Private Features in Neural Networks. (arXiv:2202.08099v1 [cs.LG] CROSS LISTED)
70. Transformer-Based Self-Supervised Learning for Emotion Recognition. (arXiv:2204.05103v2 [q-bio.NC] CROSS LISTED)

