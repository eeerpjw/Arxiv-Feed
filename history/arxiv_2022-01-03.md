# Your interest papers
---
## cs.CV
---
### Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
- Authors : Dvir Yerushalmi, Dov Danon
- Link : [http://arxiv.org/abs/2112.15091](http://arxiv.org/abs/2112.15091)
> ABSTRACT  :  Supervision for image-to-image translation (I2I) tasks is hard to come by, but bears significant effect on the resulting quality. In this paper, we observe that for many Unsupervised I2I (UI2I) scenarios, one domain is more familiar than the other, and offers in-domain prior knowledge, such as semantic segmentation. We argue that for complex scenes, figuring out the semantic structure of the domain is hard, especially with no supervision, but is an important part of a successful I2I operation. We hence introduce two techniques to incorporate this invaluable in-domain prior knowledge for the benefit of translation quality: through a novel Multi-Stream generator architecture, and through a semantic segmentation-based regularization loss term. In essence, we propose splitting the input data according to semantic masks, explicitly guiding the network to different behavior for the different regions of the image. In addition, we propose training a semantic segmentation network along with the translation task, and to leverage this output as a loss term that improves robustness. We validate our approach on urban data, demonstrating superior quality in the challenging UI2I tasks of converting day images to **night** ones. In addition, we also demonstrate how reinforcing the target dataset with our augmented images improves the training of downstream tasks such as the classical detection one.  
### Colour alignment for relative colour constancy via non-standard references. (arXiv:2112.15106v1 [eess.IV])
- Authors : Yunfeng Zhao, Stuart Ferguson, Huiyu Zhou, Chris Elliott, Karen Rafferty
- Link : [http://arxiv.org/abs/2112.15106](http://arxiv.org/abs/2112.15106)
> ABSTRACT  :  Relative colour constancy is an essential requirement for many scientific imaging applications. However, most digital cameras differ in their image formations and native sensor output is usually inaccessible, e.g., in smartphone camera applications. This makes it hard to achieve consistent colour assessment across a range of devices, and that undermines the performance of computer vision algorithms. To resolve this issue, we propose a colour alignment model that considers the camera image formation as a black-box and formulates colour alignment as a three-step process: camera response calibration, response linearisation, and colour matching. The proposed model works with non-standard colour references, i.e., colour patches without knowing the true colour values, by utilising a novel balance-of-linear-distances feature. It is equivalent to determining the camera parameters through an unsupervised process. It also works with a minimum number of corresponding colour patches across the images to be colour aligned to deliver the applicable processing. Two challenging image datasets collected by multiple cameras under various illumination and **exposure** conditions were used to evaluate the model. Performance benchmarks demonstrated that our model achieved superior performance compared to other popular and state-of-the-art methods.  
### A Resolution **Enhancement** Plug-in for Deformable Registration of Medical Images. (arXiv:2112.15180v1 [eess.IV])
- Authors : Kaicong Sun, Sven Simon
- Link : [http://arxiv.org/abs/2112.15180](http://arxiv.org/abs/2112.15180)
> ABSTRACT  :  Image registration is a fundamental task for medical imaging. Resampling of the intensity values is required during registration and better spatial resolution with finer and sharper structures can improve the resampling performance and hence the registration accuracy. Super-resolution (SR) is an algorithmic technique targeting at spatial resolution **enhancement** which can achieve an image resolution beyond the hardware limitation. In this work, we consider SR as a preprocessing technique and present a CNN-based resolution **enhancement** module (REM) which can be easily plugged into the registration network in a cascaded manner. Different residual schemes and network configurations of REM are investigated to obtain an effective architecture design of REM. In fact, REM is not confined to image registration, it can also be straightforwardly integrated into other vision tasks for enhanced resolution. The proposed REM is thoroughly evaluated for deformable registration on medical images quantitatively and qualitatively at different upscaling factors. Experiments on LPBA40 brain MRI dataset demonstrate that REM not only improves the registration accuracy, especially when the input images suffer from degraded spatial resolution, but also generates resolution enhanced images which can be exploited for successive diagnosis.  
### PiFeNet: Pillar-Feature Network for **Real-Time** 3D Pedestrian Detection from Point Cloud. (arXiv:2112.15458v1 [cs.CV])
- Authors : Tho Le, Hengcan Shi, Hamid Rezatofighi, Jianfei Cai
- Link : [http://arxiv.org/abs/2112.15458](http://arxiv.org/abs/2112.15458)
> ABSTRACT  :  We present PiFeNet, an efficient and accurate real-time 3D detector for pedestrian detection from point clouds. We address two challenges that 3D object detection frameworks encounter when detecting pedestrians: low expressiveness of pillar features and small occupation areas of pedestrians in point clouds. Firstly, we introduce a stackable Pillar Aware Attention (PAA) module for enhanced pillar features extraction while suppressing noises in the point clouds. By integrating multi-point-aware-pooling, point-wise, channel-wise, and task-aware attention into a simple module, the representation capabilities are boosted while requiring little additional computing resources. We also present Mini-BiFPN, a small yet effective feature network that creates bidirectional information flow and multi-level cross-scale feature fusion to better integrate multi-resolution features. Our approach is ranked 1st in KITTI pedestrian BEV and 3D leaderboards while running at 26 frames per second (FPS), and achieves state-of-the-art performance on Nuscenes detection benchmark.  
### Scene-Adaptive Attention Network for Crowd Counting. (arXiv:2112.15509v1 [cs.CV])
- Authors : Xing Wei, Yuanrui Kang, Jihao Yang, Yunfeng Qiu, Dahu Shi, Wenming Tan, Yihong Gong
- Link : [http://arxiv.org/abs/2112.15509](http://arxiv.org/abs/2112.15509)
> ABSTRACT  :  In recent years, significant progress has been made on the research of crowd counting. However, as the challenging scale variations and complex scenes existed in crowds, neither traditional convolution networks nor recent Transformer architectures with fixed-size attention could handle the task well. To address this problem, this paper proposes a scene-adaptive attention network, termed SAANet. First of all, we design a deformable attention in-built Transformer backbone, which learns adaptive feature representations with deformable sampling locations and dynamic attention weights. Then we propose the multi-level feature fusion and count-attentive feature **enhancement** modules further, to strengthen feature representation under the global image context. The learned representations could attend to the foreground and are adaptive to different scales of crowds. We conduct extensive experiments on four challenging crowd counting benchmarks, demonstrating that our method achieves state-of-the-art performance. Especially, our method currently ranks No.1 on the public leaderboard of the NWPU-Crowd benchmark. We hope our method could be a strong baseline to support future research in crowd counting. The source code will be released to the community.  
### PCNet: A Structure Similarity **Enhancement** Method for Multispectral and Multimodal Image Registration. (arXiv:2106.05124v2 [cs.CV] UPDATED)
- Authors : Yuan Cao, Liang Shen, Lun Luo, Jie Chen, Chunguang Li
- Link : [http://arxiv.org/abs/2106.05124](http://arxiv.org/abs/2106.05124)
> ABSTRACT  :  Multispectral and multimodal image processing is important in the community of computer vision and computational photography. As the acquired multispectral and multimodal data are generally misaligned due to the alternation or movement of the image device, the image registration procedure is necessary. The registration of multispectral or multimodal image is challenging due to the non-linear intensity and gradient variation. To cope with this challenge, we propose the phase congruency network (PCNet), which is able to enhance the structure similarity and alleviate the non-linear intensity and gradient variation. The images can then be aligned using the similarity enhanced features produced by the network. PCNet is constructed under the guidance of the phase congruency prior. The network contains three trainable layers accompany with the modified learnable Gabor kernels according to the phase congruency theory. Thanks to the prior knowledge, PCNet is extremely light-weight. PCNet can be viewed to be fully convolutional and hence can take input of arbitrary sizes. Once trained, PCNet is applicable on a variety of multispectral and multimodal data such as RGB/NIR and flash/no-flash images without additional further tuning. Experimental results validate that PCNet outperforms current state-of-the-art registration algorithms.  
### On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v3 [eess.IV] UPDATED)
- Authors : Zenglin Shi, Pascal Mettes, Subhransu Maji
- Link : [http://arxiv.org/abs/2107.01125](http://arxiv.org/abs/2107.01125)
> ABSTRACT  :  The deep image prior showed that a randomly initialized network with a suitable architecture can be trained to solve inverse imaging problems by simply optimizing it's parameters to reconstruct a single degraded image. However, it suffers from two practical limitations. First, it remains unclear how to control the prior beyond the choice of the network architecture. Second, training requires an oracle stopping criterion as during the optimization the performance degrades after reaching an optimum value. To address these challenges we introduce a frequency-band correspondence measure to characterize the spectral bias of the deep image prior, where low-frequency image signals are learned faster and better than high-frequency counterparts. Based on our observations, we propose techniques to prevent the eventual performance degradation and accelerate convergence. We introduce a Lipschitz-controlled convolution layer and a Gaussian-controlled upsampling layer as plug-in replacements for layers used in the deep architectures. The experiments show that with these changes the performance does not degrade during optimization, relieving us from the need for an oracle stopping criterion. We further outline a stopping criterion to avoid superfluous computation. Finally, we show that our approach obtains favorable results compared to current approaches across various denoising, deblocking, inpainting, super-resolution and detail **enhancement** tasks. Code is available at \url{https://github.com/shizenglin/Measure-and-Control-Spectral-Bias}.  
### A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v3 [cs.CV] UPDATED)
- Authors : Zahra Anvari, Vassilis Athitsos
- Link : [http://arxiv.org/abs/2112.02719](http://arxiv.org/abs/2112.02719)
> ABSTRACT  :  Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image **enhancement** plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks such as character recognition. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image **enhancement** tasks, including binarization, debluring, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image **enhancement** tasks that have received little to no attention, including over and under **exposure** correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research.  
## eess.IV
---
### Colour alignment for relative colour constancy via non-standard references. (arXiv:2112.15106v1 [eess.IV])
- Authors : Yunfeng Zhao, Stuart Ferguson, Huiyu Zhou, Chris Elliott, Karen Rafferty
- Link : [http://arxiv.org/abs/2112.15106](http://arxiv.org/abs/2112.15106)
> ABSTRACT  :  Relative colour constancy is an essential requirement for many scientific imaging applications. However, most digital cameras differ in their image formations and native sensor output is usually inaccessible, e.g., in smartphone camera applications. This makes it hard to achieve consistent colour assessment across a range of devices, and that undermines the performance of computer vision algorithms. To resolve this issue, we propose a colour alignment model that considers the camera image formation as a black-box and formulates colour alignment as a three-step process: camera response calibration, response linearisation, and colour matching. The proposed model works with non-standard colour references, i.e., colour patches without knowing the true colour values, by utilising a novel balance-of-linear-distances feature. It is equivalent to determining the camera parameters through an unsupervised process. It also works with a minimum number of corresponding colour patches across the images to be colour aligned to deliver the applicable processing. Two challenging image datasets collected by multiple cameras under various illumination and **exposure** conditions were used to evaluate the model. Performance benchmarks demonstrated that our model achieved superior performance compared to other popular and state-of-the-art methods.  
### A Resolution **Enhancement** Plug-in for Deformable Registration of Medical Images. (arXiv:2112.15180v1 [eess.IV])
- Authors : Kaicong Sun, Sven Simon
- Link : [http://arxiv.org/abs/2112.15180](http://arxiv.org/abs/2112.15180)
> ABSTRACT  :  Image registration is a fundamental task for medical imaging. Resampling of the intensity values is required during registration and better spatial resolution with finer and sharper structures can improve the resampling performance and hence the registration accuracy. Super-resolution (SR) is an algorithmic technique targeting at spatial resolution **enhancement** which can achieve an image resolution beyond the hardware limitation. In this work, we consider SR as a preprocessing technique and present a CNN-based resolution **enhancement** module (REM) which can be easily plugged into the registration network in a cascaded manner. Different residual schemes and network configurations of REM are investigated to obtain an effective architecture design of REM. In fact, REM is not confined to image registration, it can also be straightforwardly integrated into other vision tasks for enhanced resolution. The proposed REM is thoroughly evaluated for deformable registration on medical images quantitatively and qualitatively at different upscaling factors. Experiments on LPBA40 brain MRI dataset demonstrate that REM not only improves the registration accuracy, especially when the input images suffer from degraded spatial resolution, but also generates resolution enhanced images which can be exploited for successive diagnosis.  
### On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v3 [eess.IV] UPDATED)
- Authors : Zenglin Shi, Pascal Mettes, Subhransu Maji
- Link : [http://arxiv.org/abs/2107.01125](http://arxiv.org/abs/2107.01125)
> ABSTRACT  :  The deep image prior showed that a randomly initialized network with a suitable architecture can be trained to solve inverse imaging problems by simply optimizing it's parameters to reconstruct a single degraded image. However, it suffers from two practical limitations. First, it remains unclear how to control the prior beyond the choice of the network architecture. Second, training requires an oracle stopping criterion as during the optimization the performance degrades after reaching an optimum value. To address these challenges we introduce a frequency-band correspondence measure to characterize the spectral bias of the deep image prior, where low-frequency image signals are learned faster and better than high-frequency counterparts. Based on our observations, we propose techniques to prevent the eventual performance degradation and accelerate convergence. We introduce a Lipschitz-controlled convolution layer and a Gaussian-controlled upsampling layer as plug-in replacements for layers used in the deep architectures. The experiments show that with these changes the performance does not degrade during optimization, relieving us from the need for an oracle stopping criterion. We further outline a stopping criterion to avoid superfluous computation. Finally, we show that our approach obtains favorable results compared to current approaches across various denoising, deblocking, inpainting, super-resolution and detail **enhancement** tasks. Code is available at \url{https://github.com/shizenglin/Measure-and-Control-Spectral-Bias}.  
## cs.LG
---
### DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v1 [physics.comp-ph])
- Authors : Lidong Fang, Pei Ge, **Lei Zhang**, Huan Lei
- Link : [http://arxiv.org/abs/2112.14798](http://arxiv.org/abs/2112.14798)
> ABSTRACT  :  A long standing problem in the modeling of non-Newtonian hydrodynamics is the availability of reliable and interpretable hydrodynamic models that faithfully encode the underlying micro-scale polymer dynamics. The main complication arises from the long polymer relaxation time, the complex molecular structure, and heterogeneous interaction. DeePN$^2$, a deep learning-based non-Newtonian hydrodynamic model, has been proposed and has shown some success in systematically passing the micro-scale structural mechanics information to the macro-scale hydrodynamics for suspensions with simple polymer conformation and bond potential. The model retains a multi-scaled nature by mapping the polymer configurations into a set of symmetry-preserving macro-scale features. The extended constitutive laws for these macro-scale features can be directly learned from the kinetics of their micro-scale counterparts. In this paper, we carry out further study of DeePN$^2$ using more complex micro-structural models. We show that DeePN$^2$ can faithfully capture the broadly overlooked viscoelastic differences arising from the specific molecular structural mechanics without human intervention.  
### A General Traffic Shaping Protocol in E-Commerce. (arXiv:2112.14941v1 [cs.LG])
- Authors : Chenlin Shen, Guangda Huzhang, Yuhang Zhou, Chen Liang, Qing Da
- Link : [http://arxiv.org/abs/2112.14941](http://arxiv.org/abs/2112.14941)
> ABSTRACT  :  To approach different business objectives, online traffic shaping algorithms aim at improving **exposure**s of a target set of items, such as boosting the growth of new commodities. Generally, these algorithms assume that the utility of each user-item pair can be accessed via a well-trained conversion rate prediction model. However, for real E-Commerce platforms, there are unavoidable factors preventing us from learning such an accurate model. In order to break the heavy dependence on accurate inputs of the utility, we propose a general online traffic shaping protocol for online E-Commerce applications. In our framework, we approximate the function mapping the bonus scores, which generally are the only method to influence the ranking result in the traffic shaping problem, to the numbers of **exposure**s and purchases. Concretely, we approximate the above function by a class of the piece-wise linear function constructed on the convex hull of the explored data points. Moreover, we reformulate the online traffic shaping problem as linear programming where these piece-wise linear functions are embedded into both the objective and constraints. Our algorithm can straightforwardly optimize the linear programming in the prime space, and its solution can be simply applied by a stochastic strategy to fulfill the optimized objective and the constraints in expectation. Finally, the online A/B test shows our proposed algorithm steadily outperforms the previous industrial level traffic shaping algorithm.  
### Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
- Authors : Dvir Yerushalmi, Dov Danon
- Link : [http://arxiv.org/abs/2112.15091](http://arxiv.org/abs/2112.15091)
> ABSTRACT  :  Supervision for image-to-image translation (I2I) tasks is hard to come by, but bears significant effect on the resulting quality. In this paper, we observe that for many Unsupervised I2I (UI2I) scenarios, one domain is more familiar than the other, and offers in-domain prior knowledge, such as semantic segmentation. We argue that for complex scenes, figuring out the semantic structure of the domain is hard, especially with no supervision, but is an important part of a successful I2I operation. We hence introduce two techniques to incorporate this invaluable in-domain prior knowledge for the benefit of translation quality: through a novel Multi-Stream generator architecture, and through a semantic segmentation-based regularization loss term. In essence, we propose splitting the input data according to semantic masks, explicitly guiding the network to different behavior for the different regions of the image. In addition, we propose training a semantic segmentation network along with the translation task, and to leverage this output as a loss term that improves robustness. We validate our approach on urban data, demonstrating superior quality in the challenging UI2I tasks of converting day images to **night** ones. In addition, we also demonstrate how reinforcing the target dataset with our augmented images improves the training of downstream tasks such as the classical detection one.  
### From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction Using Social Media Data. (arXiv:2009.13794v3 [cs.SI] UPDATED)
- Authors : Weiran Yao, Sean Qian
- Link : [http://arxiv.org/abs/2009.13794](http://arxiv.org/abs/2009.13794)
> ABSTRACT  :  The effectiveness of traditional traffic prediction methods is often extremely limited when forecasting traffic dynamics in early morning. The reason is that traffic can break down drastically during the early morning commute, and the time and duration of this break-down vary substantially from day to day. Early morning traffic forecast is crucial to inform morning-commute traffic management, but they are generally challenging to predict in advance, particularly by mid**night**. In this paper, we propose to mine Twitter messages as a probing method to understand the impacts of people's work and rest patterns in the evening/mid**night** of the previous day to the next-day morning traffic. The model is tested on freeway networks in Pittsburgh as experiments. The resulting relationship is surprisingly simple and powerful. We find that, in general, the earlier people rest as indicated from Tweets, the more congested roads will be in the next morning. The occurrence of big events in the evening before, represented by higher or lower tweet sentiment than normal, often implies lower travel demand in the next morning than normal days. Besides, people's tweeting activities in the **night** before and early morning are statistically associated with congestion in morning peak hours. We make use of such relationships to build a predictive framework which forecasts morning commute congestion using people's tweeting profiles extracted by 5 am or as late as the mid**night** prior to the morning. The Pittsburgh study supports that our framework can precisely predict morning congestion, particularly for some road segments upstream of roadway bottlenecks with large day-to-day congestion variation. Our approach considerably outperforms those existing methods without Twitter message features, and it can learn meaningful representation of demand from tweeting profiles that offer managerial insights.  
### A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v3 [cs.CV] UPDATED)
- Authors : Zahra Anvari, Vassilis Athitsos
- Link : [http://arxiv.org/abs/2112.02719](http://arxiv.org/abs/2112.02719)
> ABSTRACT  :  Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image **enhancement** plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks such as character recognition. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image **enhancement** tasks, including binarization, debluring, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image **enhancement** tasks that have received little to no attention, including over and under **exposure** correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research.  
## cs.AI
---
### Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
- Authors : Dvir Yerushalmi, Dov Danon
- Link : [http://arxiv.org/abs/2112.15091](http://arxiv.org/abs/2112.15091)
> ABSTRACT  :  Supervision for image-to-image translation (I2I) tasks is hard to come by, but bears significant effect on the resulting quality. In this paper, we observe that for many Unsupervised I2I (UI2I) scenarios, one domain is more familiar than the other, and offers in-domain prior knowledge, such as semantic segmentation. We argue that for complex scenes, figuring out the semantic structure of the domain is hard, especially with no supervision, but is an important part of a successful I2I operation. We hence introduce two techniques to incorporate this invaluable in-domain prior knowledge for the benefit of translation quality: through a novel Multi-Stream generator architecture, and through a semantic segmentation-based regularization loss term. In essence, we propose splitting the input data according to semantic masks, explicitly guiding the network to different behavior for the different regions of the image. In addition, we propose training a semantic segmentation network along with the translation task, and to leverage this output as a loss term that improves robustness. We validate our approach on urban data, demonstrating superior quality in the challenging UI2I tasks of converting day images to **night** ones. In addition, we also demonstrate how reinforcing the target dataset with our augmented images improves the training of downstream tasks such as the classical detection one.  
### Full-Sentence Models Perform Better in Simultaneous Translation Using the Information Enhanced Decoding Strategy. (arXiv:2105.01893v2 [cs.CL] UPDATED)
- Authors : Zhengxin Yang
- Link : [http://arxiv.org/abs/2105.01893](http://arxiv.org/abs/2105.01893)
> ABSTRACT  :  Simultaneous translation, which starts translating each sentence after receiving only a few words in source sentence, has a vital role in many scenarios. Although the previous prefix-to-prefix framework is considered suitable for simultaneous translation and achieves good performance, it still has two inevitable drawbacks: the high computational resource costs caused by the need to train a separate model for each latency $k$ and the insufficient ability to encode information because each target token can only attend to a specific source prefix. We propose a novel framework that adopts a simple but effective decoding strategy which is designed for full-sentence models. Within this framework, training a single full-sentence model can achieve arbitrary given latency and save computational resources. Besides, with the competence of the full-sentence model to encode the whole sentence, our decoding strategy can enhance the information maintained in the decoded states in **real time**. Experimental results show that our method achieves better translation quality than baselines on 4 directions: Zh$\rightarrow$En, En$\rightarrow$Ro and En$\leftrightarrow$De.  
# Paper List
---
## cs.CV
---
**89** new papers in cs.CV:-) 
1. Video Reconstruction from a Single Motion Blurred Image using Learned Dynamic Phase Coding. (arXiv:2112.14768v1 [eess.IV])
2. Deep Graph Clustering via Dual Correlation Reduction. (arXiv:2112.14772v1 [cs.LG])
3. Deep Learning meets Liveness Detection: Recent Advancements and Challenges. (arXiv:2112.14796v1 [cs.CV])
4. Learning Inception Attention for Image Synthesis and Image Recognition. (arXiv:2112.14804v1 [cs.CV])
5. Few-shot Backdoor Defense Using Shapley Estimation. (arXiv:2112.14889v1 [cs.CR])
6. Feature Generation and Hypothesis Verification for Reliable Face Anti-Spoofing. (arXiv:2112.14894v1 [cs.CV])
7. Retrieving Black-box Optimal Images from External Databases. (arXiv:2112.14921v1 [cs.IR])
8. Dense Depth Estimation from Multiple 360-degree Images Using Virtual Depth. (arXiv:2112.14931v1 [cs.CV])
9. SFU-HW-Tracks-v1: Object Tracking Dataset on Raw Video Sequences. (arXiv:2112.14934v1 [cs.CV])
10. A Novel Generator with Auxiliary Branch for Improving GAN Performance. (arXiv:2112.14968v1 [cs.CV])
11. Contrastive Fine-grained Class Clustering via Generative Adversarial Networks. (arXiv:2112.14971v1 [cs.CV])
12. Contrastive Learning of Semantic and Visual Representations for Text Tracking. (arXiv:2112.14976v1 [cs.CV])
13. Exploring the pattern of Emotion in children with ASD as an early biomarker through Recurring-Convolution Neural Network (R-CNN). (arXiv:2112.14983v1 [cs.CV])
14. THE Benchmark: Transferable Representation Learning for Monocular Height Estimation. (arXiv:2112.14985v1 [cs.CV])
15. Knowledge Matters: Radiology Report Generation with General and Specific Knowledge. (arXiv:2112.15009v1 [eess.IV])
16. Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment. (arXiv:2112.15011v1 [eess.IV])
17. Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction. (arXiv:2112.15012v1 [cs.CV])
18. Continually Learning Self-Supervised Representations with Projected Functional Regularization. (arXiv:2112.15022v1 [cs.CV])
19. Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach. (arXiv:2112.15031v1 [cs.CV])
20. Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised Semantic Segmentation. (arXiv:2112.15068v1 [cs.LG])
21. Pose Estimation of Specific Rigid Objects. (arXiv:2112.15075v1 [cs.CV])
22. Feature Extraction and Prediction for Hand Hygiene Gestures with KNN Algorithm. (arXiv:2112.15085v1 [cs.CV])
23. Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
24. Benchmarking Chinese Text Recognition: Datasets, Baselines, and an Empirical Study. (arXiv:2112.15093v1 [cs.CV])
25. A general technique for the estimation of farm animal body part weights from CT scans and its applications in a rabbit breeding program. (arXiv:2112.15095v1 [cs.CV])
26. Colour alignment for relative colour constancy via non-standard references. (arXiv:2112.15106v1 [eess.IV])
27. Stochastic Layers in Vision Transformers. (arXiv:2112.15111v1 [cs.CV])
28. Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural Networks. (arXiv:2112.15139v1 [cs.CV])
29. A Resolution Enhancement Plug-in for Deformable Registration of Medical Images. (arXiv:2112.15180v1 [eess.IV])
30. Towards Robustness of Neural Networks. (arXiv:2112.15188v1 [cs.CV])
31. Visual and Object Geo-localization: A Comprehensive Survey. (arXiv:2112.15202v1 [cs.CV])
32. Data-Free Knowledge Transfer: A Survey. (arXiv:2112.15278v1 [cs.LG])
33. ERNIE-ViLG: Unified Generative Pre-training for Bidirectional Vision-Language Generation. (arXiv:2112.15283v1 [cs.CV])
34. CSformer: Bridging Convolution and Transformer for Compressive Sensing. (arXiv:2112.15299v1 [eess.IV])
35. SplitBrain: Hybrid Data and Model Parallel Deep Learning. (arXiv:2112.15317v1 [cs.LG])
36. InverseMV: Composing Piano Scores with a Convolutional Video-Music Transformer. (arXiv:2112.15320v1 [cs.LG])
37. Deconfounded Visual Grounding. (arXiv:2112.15324v1 [cs.CV])
38. On Distinctive Properties of Universal Perturbations. (arXiv:2112.15329v1 [cs.LG])
39. P2P-Loc: Point to Point Tiny Person Localization. (arXiv:2112.15344v1 [cs.CV])
40. Learning to Predict 3D Lane Shape and Camera Pose from a Single Image via Geometry Constraints. (arXiv:2112.15351v1 [cs.CV])
41. Sparse LiDAR Assisted Self-supervised Stereo Disparity Estimation. (arXiv:2112.15355v1 [cs.CV])
42. Conditional Generative Data-Free Knowledge Distillation based on Attention Transfer. (arXiv:2112.15358v1 [cs.CV])
43. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v1 [eess.IV])
44. Weakly Supervised Change Detection Using Guided Anisotropic Difusion. (arXiv:2112.15367v1 [eess.IV])
45. Efficient Single Image Super-Resolution Using Dual Path Connections with Multiple Scale Learning. (arXiv:2112.15386v1 [eess.IV])
46. InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v1 [cs.CV])
47. Revisiting Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v1 [cs.LG])
48. Disjoint Contrastive Regression Learning for Multi-Sourced Annotations. (arXiv:2112.15411v1 [cs.LG])
49. Deep Facial Synthesis: A New Challenge. (arXiv:2112.15439v1 [cs.CV])
50. PiFeNet: Pillar-Feature Network for Real-Time 3D Pedestrian Detection from Point Cloud. (arXiv:2112.15458v1 [cs.CV])
51. Cloud Removal from Satellite Images. (arXiv:2112.15483v1 [cs.CV])
52. Scene-Adaptive Attention Network for Crowd Counting. (arXiv:2112.15509v1 [cs.CV])
53. Transfer learning for cancer diagnosis in histopathological images. (arXiv:2112.15523v1 [eess.IV])
54. on the effectiveness of generative adversarial network on anomaly detection. (arXiv:2112.15541v1 [cs.LG])
55. Improving Baselines in the Wild. (arXiv:2112.15550v1 [cs.LG])
56. An Unsupervised Domain Adaptation Model based on Dual-module Adversarial Training. (arXiv:2112.15555v1 [cs.LG])
57. PCACE: A Statistical Approach to Ranking Neurons for CNN Interpretability. (arXiv:2112.15571v1 [cs.CV])
58. 3-D Material Style Transfer for Reconstructing Unknown Appearance in Complex Natural Materials. (arXiv:2112.15589v1 [cs.CV])
59. A theory of independent mechanisms for extrapolation in generative models. (arXiv:2004.00184v2 [cs.LG] UPDATED)
60. Learning Expectation of Label Distribution for Facial Age and Attractiveness Estimation. (arXiv:2007.01771v2 [cs.CV] UPDATED)
61. Taking Modality-free Human Identification as Zero-shot Learning. (arXiv:2010.00975v2 [cs.CV] UPDATED)
62. Reconstructing Hand-Object Interactions in the Wild. (arXiv:2012.09856v2 [cs.CV] UPDATED)
63. Transitional Learning: Exploring the Transition States of Degradation for Blind Super-resolution. (arXiv:2103.15290v2 [cs.CV] UPDATED)
64. MutualNet: Adaptive ConvNet via Mutual Learning from Different Model Configurations. (arXiv:2105.07085v2 [cs.CV] UPDATED)
65. Nested Hierarchical Transformer: Towards Accurate, Data-Efficient and Interpretable Visual Understanding. (arXiv:2105.12723v4 [cs.CV] UPDATED)
66. Rethinking Pseudo Labels for Semi-Supervised Object Detection. (arXiv:2106.00168v2 [cs.CV] UPDATED)
67. PCNet: A Structure Similarity Enhancement Method for Multispectral and Multimodal Image Registration. (arXiv:2106.05124v2 [cs.CV] UPDATED)
68. NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial Perturbations. (arXiv:2106.11644v2 [cs.CV] UPDATED)
69. On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v3 [eess.IV] UPDATED)
70. A Survey on Deep Learning Technique for Video Segmentation. (arXiv:2107.01153v3 [cs.CV] UPDATED)
71. Temporal Alignment Prediction for Few-Shot Video Classification. (arXiv:2107.11960v3 [cs.CV] UPDATED)
72. VisBuddy -- A Smart Wearable Assistant for the Visually Challenged. (arXiv:2108.07761v2 [cs.CV] UPDATED)
73. roadscene2vec: A Tool for Extracting and Embedding Road Scene-Graphs. (arXiv:2109.01183v2 [cs.CV] UPDATED)
74. Learning the Regularization in DCE-MR Image Reconstruction for Functional Imaging of Kidneys. (arXiv:2109.07548v2 [cs.LG] UPDATED)
75. Improving 360 Monocular Depth Estimation via Non-local Dense Prediction Transformer and Joint Supervised and Self-supervised Learning. (arXiv:2109.10563v3 [cs.CV] UPDATED)
76. BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation. (arXiv:2109.12271v2 [eess.IV] UPDATED)
77. ARKitScenes -- A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data. (arXiv:2111.08897v2 [cs.CV] UPDATED)
78. ML-Decoder: Scalable and Versatile Classification Head. (arXiv:2111.12933v2 [cs.CV] UPDATED)
79. MutualFormer: Multi-Modality Representation Learning via Mutual Transformer. (arXiv:2112.01177v2 [cs.CV] UPDATED)
80. A Survey on Deep learning based Document Image Enhancement. (arXiv:2112.02719v3 [cs.CV] UPDATED)
81. SAC-GAN: Structure-Aware Image-to-Image Composition for Self-Driving. (arXiv:2112.06596v2 [cs.CV] UPDATED)
82. M-FasterSeg: An Efficient Semantic Segmentation Network Based on Neural Architecture Search. (arXiv:2112.07918v2 [cs.CV] UPDATED)
83. CLEVR3D: Compositional Language and Elementary Visual Reasoning for Question Answering in 3D Real-World Scenes. (arXiv:2112.11691v2 [cs.CV] UPDATED)
84. Dense anomaly detection by robust learning on synthetic negative data. (arXiv:2112.12833v2 [cs.CV] UPDATED)
85. SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v2 [cs.CV] UPDATED)
86. Human View Synthesis using a Single Sparse RGB-D Input. (arXiv:2112.13889v2 [cs.CV] UPDATED)
87. MetaGraspNet: A Large-Scale Benchmark Dataset for Vision-driven Robotic Grasping via Physics-based Metaverse Synthesis. (arXiv:2112.14663v2 [cs.CV] UPDATED)
88. Music-to-Dance Generation with Optimal Transport. (arXiv:2112.01806v1 [cs.SD] CROSS LISTED)
89. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**16** new papers in eess.IV:-) 
1. Video Reconstruction from a Single Motion Blurred Image using Learned Dynamic Phase Coding. (arXiv:2112.14768v1 [eess.IV])
2. Dense Depth Estimation from Multiple 360-degree Images Using Virtual Depth. (arXiv:2112.14931v1 [cs.CV])
3. SFU-HW-Tracks-v1: Object Tracking Dataset on Raw Video Sequences. (arXiv:2112.14934v1 [cs.CV])
4. Knowledge Matters: Radiology Report Generation with General and Specific Knowledge. (arXiv:2112.15009v1 [eess.IV])
5. Radiology Report Generation with a Learned Knowledge Base and Multi-modal Alignment. (arXiv:2112.15011v1 [eess.IV])
6. Colour alignment for relative colour constancy via non-standard references. (arXiv:2112.15106v1 [eess.IV])
7. A Resolution Enhancement Plug-in for Deformable Registration of Medical Images. (arXiv:2112.15180v1 [eess.IV])
8. CSformer: Bridging Convolution and Transformer for Compressive Sensing. (arXiv:2112.15299v1 [eess.IV])
9. Systematic dispersion compensation for spectral domain optical coherence tomography using time-frequency analysis and iterative optimization for iridocorneal angle imaging. (arXiv:2112.15302v1 [eess.IV])
10. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v1 [eess.IV])
11. Weakly Supervised Change Detection Using Guided Anisotropic Difusion. (arXiv:2112.15367v1 [eess.IV])
12. Efficient Single Image Super-Resolution Using Dual Path Connections with Multiple Scale Learning. (arXiv:2112.15386v1 [eess.IV])
13. InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering. (arXiv:2112.15399v1 [cs.CV])
14. Transfer learning for cancer diagnosis in histopathological images. (arXiv:2112.15523v1 [eess.IV])
15. On Measuring and Controlling the Spectral Bias of the Deep Image Prior. (arXiv:2107.01125v3 [eess.IV] UPDATED)
16. BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation. (arXiv:2109.12271v2 [eess.IV] UPDATED)
## cs.LG
---
**171** new papers in cs.LG:-) 
1. Frame invariance and scalability of neural operators for partial differential equations. (arXiv:2112.14769v1 [cs.LG])
2. Deep Graph Clustering via Dual Correlation Reduction. (arXiv:2112.14772v1 [cs.LG])
3. Graph Neural Networks for Communication Networks: Context, Use Cases and Opportunities. (arXiv:2112.14792v1 [cs.NI])
4. A sampling-based approach for efficient clustering in large datasets. (arXiv:2112.14793v1 [cs.LG])
5. DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v1 [physics.comp-ph])
6. Learning Inception Attention for Image Synthesis and Image Recognition. (arXiv:2112.14804v1 [cs.CV])
7. AutoFITS: Automatic Feature Engineering for Irregular Time Series. (arXiv:2112.14806v1 [cs.LG])
8. Active Learning-Based Optimization of Scientific Experimental Design. (arXiv:2112.14811v1 [cs.LG])
9. Application of Hierarchical Temporal Memory Theory for Document Categorization. (arXiv:2112.14820v1 [cs.CL])
10. PINNs for the Solution of the Hyperbolic Buckley-Leverett Problem with a Non-convex Flux Function. (arXiv:2112.14826v1 [physics.flu-dyn])
11. Training Quantized Deep Neural Networks via Cooperative Coevolution. (arXiv:2112.14834v1 [cs.NE])
12. Recent Trends in Artificial Intelligence-inspired Electronic Thermal Management. (arXiv:2112.14837v1 [cs.LG])
13. K-Core Decomposition on Super Large Graphs with Limited Resources. (arXiv:2112.14840v1 [cs.DC])
14. Explainable Signature-based Machine Learning Approach for Identification of Faults in Grid-Connected Photovoltaic Systems. (arXiv:2112.14842v1 [cs.LG])
15. A Graph Attention Learning Approach to Antenna Tilt Optimization. (arXiv:2112.14843v1 [cs.LG])
16. The SAMME.C2 algorithm for severely imbalanced multi-class classification. (arXiv:2112.14868v1 [stat.ML])
17. A Unified DRO View of Multi-class Loss Functions with top-N Consistency. (arXiv:2112.14869v1 [cs.LG])
18. Local Quadratic Convergence of Stochastic Gradient Descent with Adaptive Step Size. (arXiv:2112.14872v1 [math.OC])
19. A Unified and Constructive Framework for the Universality of Neural Networks. (arXiv:2112.14877v1 [cs.LG])
20. Reversible Upper Confidence Bound Algorithm to Generate Diverse Optimized Candidates. (arXiv:2112.14893v1 [cs.LG])
21. Motif Graph Neural Network. (arXiv:2112.14900v1 [cs.LG])
22. A Survey of Deep Learning Techniques for Dynamic Branch Prediction. (arXiv:2112.14911v1 [cs.AR])
23. Retrieving Black-box Optimal Images from External Databases. (arXiv:2112.14921v1 [cs.IR])
24. RheFrameDetect: A Text Classification System for Automatic Detection of Rhetorical Frames in AI from Open Sources. (arXiv:2112.14933v1 [cs.CL])
25. Are we really making much progress? Revisiting, benchmarking, and refining heterogeneous graph neural networks. (arXiv:2112.14936v1 [cs.LG])
26. A General Traffic Shaping Protocol in E-Commerce. (arXiv:2112.14941v1 [cs.LG])
27. Decentralized Optimization Over the Stiefel Manifold by an Approximate Augmented Lagrangian Function. (arXiv:2112.14949v1 [math.OC])
28. Exploring the pattern of Emotion in children with ASD as an early biomarker through Recurring-Convolution Neural Network (R-CNN). (arXiv:2112.14983v1 [cs.CV])
29. Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction. (arXiv:2112.15012v1 [cs.CV])
30. Measuring and Sampling: A Metric-guided Subgraph Learning Framework for Graph Neural Network. (arXiv:2112.15015v1 [cs.LG])
31. Deep Transfer-Learning for patient specific model re-calibration: Application to sEMG-Classification. (arXiv:2112.15019v1 [cs.LG])
32. Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates. (arXiv:2112.15025v1 [cs.LG])
33. Two Instances of Interpretable Neural Network for Universal Approximations. (arXiv:2112.15026v1 [cs.LG])
34. Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach. (arXiv:2112.15031v1 [cs.CV])
35. Self Reward Design with Fine-grained Interpretability. (arXiv:2112.15034v1 [cs.LG])
36. Dimensionality reduction for prediction: Application to Bitcoin and Ethereum. (arXiv:2112.15036v1 [q-fin.ST])
37. Digital Rock Typing DRT Algorithm Formulation with Optimal Supervised Semantic Segmentation. (arXiv:2112.15068v1 [cs.LG])
38. Deep Learning Models for Knowledge Tracing: Review and Empirical Evaluation. (arXiv:2112.15072v1 [cs.LG])
39. Pose Estimation of Specific Rigid Objects. (arXiv:2112.15075v1 [cs.CV])
40. ChunkFormer: Learning Long Time Series with Multi-stage Chunked Transformer. (arXiv:2112.15087v1 [cs.LG])
41. Deconfounded Training for Graph Neural Networks. (arXiv:2112.15089v1 [cs.LG])
42. Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
43. Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems. (arXiv:2112.15094v1 [eess.SY])
44. A general technique for the estimation of farm animal body part weights from CT scans and its applications in a rabbit breeding program. (arXiv:2112.15095v1 [cs.CV])
45. Audio-to-symbolic Arrangement via Cross-modal Music Representation Learning. (arXiv:2112.15110v1 [cs.SD])
46. Aim in Climate Change and City Pollution. (arXiv:2112.15115v1 [cs.LG])
47. On the Role of Neural Collapse in Transfer Learning. (arXiv:2112.15121v1 [cs.LG])
48. Resource-Efficient Deep Learning: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques. (arXiv:2112.15131v1 [cs.LG])
49. Multi-Agent Reinforcement Learning via Adaptive Kalman Temporal Difference and Successor Representation. (arXiv:2112.15156v1 [cs.LG])
50. Towards Robustness of Neural Networks. (arXiv:2112.15188v1 [cs.CV])
51. Accelerated Primal-Dual Gradient Method for Smooth and Convex-Concave Saddle-Point Problems with Bilinear Coupling. (arXiv:2112.15199v1 [math.OC])
52. Persformer: A Transformer Architecture for Topological Machine Learning. (arXiv:2112.15210v1 [cs.LG])
53. Learning Agent State Online with Recurrent Generate-and-Test. (arXiv:2112.15236v1 [cs.LG])
54. Studying the Interplay between Information Loss and Operation Loss in Representations for Classification. (arXiv:2112.15238v1 [cs.LG])
55. When are Iterative Gaussian Processes Reliably Accurate?. (arXiv:2112.15246v1 [cs.LG])
56. Benign Overfitting in Adversarially Robust Linear Classification. (arXiv:2112.15250v1 [cs.LG])
57. Entropy Regularized Optimal Transport Independence Criterion. (arXiv:2112.15265v1 [stat.ML])
58. BP-Net: Cuff-less, Calibration-free, and Non-invasive Blood Pressure Estimation via a Generic Deep Convolutional Architecture. (arXiv:2112.15271v1 [cs.LG])
59. ViNMT: Neural Machine Translation Tookit. (arXiv:2112.15272v1 [cs.CL])
60. Learned Coarse Models for Efficient Turbulence Simulation. (arXiv:2112.15275v1 [physics.flu-dyn])
61. Machine Learning Application Development: Practitioners' Insights. (arXiv:2112.15277v1 [cs.SE])
62. Data-Free Knowledge Transfer: A Survey. (arXiv:2112.15278v1 [cs.LG])
63. What is Event Knowledge Graph: A Survey. (arXiv:2112.15280v1 [cs.LG])
64. Modelling of Bi-directional Spatio-Temporal Dependence and Users' Dynamic Preferences for Missing POI Check-in Identification. (arXiv:2112.15285v1 [cs.LG])
65. Distributed Random Reshuffling over Networks. (arXiv:2112.15287v1 [math.OC])
66. Domain Adaptation with Category Attention Network for Deep Sentiment Analysis. (arXiv:2112.15290v1 [cs.CL])
67. Neural Hierarchical Factorization Machines for User's Event Sequence Analysis. (arXiv:2112.15292v1 [cs.LG])
68. SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning. (arXiv:2112.15303v1 [cs.LG])
69. Bayesian Optimization of Function Networks. (arXiv:2112.15311v1 [cs.LG])
70. SplitBrain: Hybrid Data and Model Parallel Deep Learning. (arXiv:2112.15317v1 [cs.LG])
71. A Critical Review of Inductive Logic Programming Techniques for Explainable AI. (arXiv:2112.15319v1 [cs.LG])
72. InverseMV: Composing Piano Scores with a Convolutional Video-Music Transformer. (arXiv:2112.15320v1 [cs.LG])
73. Sufficient Statistic Memory AMP. (arXiv:2112.15327v1 [cs.IT])
74. On Distinctive Properties of Universal Perturbations. (arXiv:2112.15329v1 [cs.LG])
75. Improved Algorithm for the Network Alignment Problem with Application to Binary Diffing. (arXiv:2112.15336v1 [cs.LG])
76. Binary Diffing as a Network Alignment Problem via Belief Propagation. (arXiv:2112.15337v1 [cs.LG])
77. Training Recurrent Neural Networks by Sequential Least Squares and the Alternating Direction Method of Multipliers. (arXiv:2112.15348v1 [cs.LG])
78. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v1 [eess.IV])
79. Robust Entropy-regularized Markov Decision Processes. (arXiv:2112.15364v1 [cs.LG])
80. Weakly Supervised Change Detection Using Guided Anisotropic Difusion. (arXiv:2112.15367v1 [eess.IV])
81. Processing Images from Multiple IACTs in the TAIGA Experiment with Convolutional Neural Networks. (arXiv:2112.15382v1 [astro-ph.IM])
82. Separation of scales and a thermodynamic description of feature learning in some CNNs. (arXiv:2112.15383v1 [stat.ML])
83. Settling the Bias and Variance of Meta-Gradient Estimation for Meta-Reinforcement Learning. (arXiv:2112.15400v1 [cs.LG])
84. Revisiting Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship. (arXiv:2112.15402v1 [cs.LG])
85. Disjoint Contrastive Regression Learning for Multi-Sourced Annotations. (arXiv:2112.15411v1 [cs.LG])
86. Representation Learning via Consistent Assignment of Views to Clusters. (arXiv:2112.15421v1 [cs.LG])
87. Robustness and risk management via distributional dynamic programming. (arXiv:2112.15430v1 [cs.LG])
88. Adversarial Learning for Incentive Optimization in Mobile Payment Marketing. (arXiv:2112.15434v1 [cs.LG])
89. Mythological Medical Machine Learning: Boosting the Performance of a Deep Learning Medical Data Classifier Using Realistic Physiological Models. (arXiv:2112.15442v1 [cs.LG])
90. GANISP: a GAN-assisted Importance SPlitting Probability Estimator. (arXiv:2112.15444v1 [cs.LG])
91. Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction. (arXiv:2112.15445v1 [cs.LG])
92. Uniform-in-Phase-Space Data Selection with Iterative Normalizing Flows. (arXiv:2112.15446v1 [cs.LG])
93. Shift-Equivariant Similarity-Preserving Hypervector Representations of Sequences. (arXiv:2112.15475v1 [cs.AI])
94. Efficient and Reliable Overlay Networks for Decentralized Federated Learning. (arXiv:2112.15486v1 [cs.NI])
95. State Selection Algorithms and Their Impact on The Performance of Stateful Network Protocol Fuzzing. (arXiv:2112.15498v1 [cs.SE])
96. Transfer learning of phase transitions in percolation and directed percolation. (arXiv:2112.15516v1 [cond-mat.stat-mech])
97. Inferring perceptual decision making parameters from behavior in production and reproduction tasks. (arXiv:2112.15521v1 [cs.LG])
98. Transfer learning for cancer diagnosis in histopathological images. (arXiv:2112.15523v1 [eess.IV])
99. Scalable Deep Graph Clustering with Random-walk based Self-supervised Learning. (arXiv:2112.15530v1 [cs.LG])
100. Machine Learning Trivializing Maps: A First Step Towards Understanding How Flow-Based Samplers Scale Up. (arXiv:2112.15532v1 [hep-lat])
101. Machine learning based disease diagnosis: A comprehensive review. (arXiv:2112.15538v1 [cs.LG])
102. on the effectiveness of generative adversarial network on anomaly detection. (arXiv:2112.15541v1 [cs.LG])
103. Training and Generating Neural Networks in Compressed Weight Space. (arXiv:2112.15545v1 [cs.LG])
104. Improving Baselines in the Wild. (arXiv:2112.15550v1 [cs.LG])
105. An Unsupervised Domain Adaptation Model based on Dual-module Adversarial Training. (arXiv:2112.15555v1 [cs.LG])
106. Actor Loss of Soft Actor Critic Explained. (arXiv:2112.15568v1 [cs.LG])
107. PCACE: A Statistical Approach to Ranking Neurons for CNN Interpretability. (arXiv:2112.15571v1 [cs.CV])
108. Fast Learning of MNL Model from General Partial Rankings with Application to Network Formation Modeling. (arXiv:2112.15575v1 [cs.LG])
109. Infinite wide (finite depth) Neural Networks benefit from multi-task learning unlike shallow Gaussian Processes -- an exact quantitative macroscopic characterization. (arXiv:2112.15577v1 [cs.LG])
110. Importance of Empirical Sample Complexity Analysis for Offline Reinforcement Learning. (arXiv:2112.15578v1 [cs.LG])
111. Single-Shot Pruning for Offline Reinforcement Learning. (arXiv:2112.15579v1 [cs.LG])
112. A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More. (arXiv:2112.15594v1 [cs.LG])
113. Triangular Flows for Generative Modeling: Statistical Consistency, Smoothness Classes, and Fast Rates. (arXiv:2112.15595v1 [stat.ML])
114. G-PATE: Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators. (arXiv:1906.09338v2 [cs.LG] UPDATED)
115. BERTphone: Phonetically-Aware Encoder Representations for Utterance-Level Speaker and Language Recognition. (arXiv:1907.00457v2 [cs.CL] UPDATED)
116. How Much Over-parameterization Is Sufficient to Learn Deep ReLU Networks?. (arXiv:1911.12360v4 [cs.LG] UPDATED)
117. Dynamic Causal Effects Evaluation in A/B Testing with a Reinforcement Learning Framework. (arXiv:2002.01711v5 [cs.LG] UPDATED)
118. A theory of independent mechanisms for extrapolation in generative models. (arXiv:2004.00184v2 [cs.LG] UPDATED)
119. A Two-Timescale Framework for Bilevel Optimization: Complexity Analysis and Application to Actor-Critic. (arXiv:2007.05170v3 [math.OC] UPDATED)
120. From Twitter to Traffic Predictor: Next-Day Morning Traffic Prediction Using Social Media Data. (arXiv:2009.13794v3 [cs.SI] UPDATED)
121. Neural Thompson Sampling. (arXiv:2010.00827v2 [cs.LG] UPDATED)
122. Efficient Robust Training via Backward Smoothing. (arXiv:2010.01278v2 [cs.LG] UPDATED)
123. Memory AMP. (arXiv:2012.10861v5 [cs.IT] UPDATED)
124. Fairness-Oriented User Scheduling for Bursty Downlink Transmission Using Multi-Agent Reinforcement Learning. (arXiv:2012.15081v13 [cs.OS] UPDATED)
125. Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity. (arXiv:2101.01041v3 [math.OC] UPDATED)
126. Hybrid Adversarial Imitation Learning. (arXiv:2102.02454v10 [cs.LG] UPDATED)
127. A Survey of Embodied AI: From Simulators to Research Tasks. (arXiv:2103.04918v6 [cs.AI] UPDATED)
128. Hierarchical forecasting with a top-down alignment of independent level forecasts. (arXiv:2103.08250v4 [stat.ML] UPDATED)
129. Refining Language Models with Compositional Explanations. (arXiv:2103.10415v3 [cs.CL] UPDATED)
130. Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification. (arXiv:2103.12656v2 [cs.LG] UPDATED)
131. Semi-Decentralized Federated Edge Learning for Fast Convergence on Non-IID Data. (arXiv:2104.12678v5 [cs.NI] UPDATED)
132. A GAN-Like Approach for Physics-Based Imitation Learning and Interactive Character Control. (arXiv:2105.10066v4 [cs.GR] UPDATED)
133. Embedding Information onto a Dynamical System. (arXiv:2105.10766v3 [math.DS] UPDATED)
134. Simplifying Software Defect Prediction (via the "early bird" Heuristic). (arXiv:2105.11082v2 [cs.SE] UPDATED)
135. QueryNet: Attack by Multi-Identity Surrogates. (arXiv:2105.15010v3 [cs.LG] UPDATED)
136. Uniform-PAC Bounds for Reinforcement Learning with Linear Function Approximation. (arXiv:2106.11612v2 [cs.LG] UPDATED)
137. NCIS: Neural Contextual Iterative Smoothing for Purifying Adversarial Perturbations. (arXiv:2106.11644v2 [cs.CV] UPDATED)
138. Notes on the H-measure of classifier performance. (arXiv:2106.11888v2 [cs.LG] UPDATED)
139. Geometric Deep Learning on Molecular Representations. (arXiv:2107.12375v4 [physics.chem-ph] UPDATED)
140. Data-driven advice for interpreting local and global model predictions in bioinformatics problems. (arXiv:2108.06201v2 [stat.ML] UPDATED)
141. Analysis of Regularized Learning in Banach Spaces. (arXiv:2109.03159v4 [cs.LG] UPDATED)
142. An objective function for order preserving hierarchical clustering. (arXiv:2109.04266v2 [cs.LG] UPDATED)
143. Learning the Regularization in DCE-MR Image Reconstruction for Functional Imaging of Kidneys. (arXiv:2109.07548v2 [cs.LG] UPDATED)
144. Investigating and Modeling the Dynamics of Long Ties. (arXiv:2109.10523v2 [cs.SI] UPDATED)
145. BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation. (arXiv:2109.12271v2 [eess.IV] UPDATED)
146. An Efficient Epileptic Seizure Detection Technique using Discrete Wavelet Transform and Machine Learning Classifiers. (arXiv:2109.13811v2 [eess.SP] UPDATED)
147. Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation. (arXiv:2110.06394v2 [cs.LG] UPDATED)
148. ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification. (arXiv:2110.09344v2 [cs.LG] UPDATED)
149. Crowd-sensing Enhanced Parking Patrol using Trajectories of Sharing Bikes. (arXiv:2110.15557v2 [cs.LG] UPDATED)
150. Unintended Selection: Persistent Qualification Rate Disparities and Interventions. (arXiv:2111.01201v2 [cs.LG] UPDATED)
151. Hamiltonian Dynamics with Non-Newtonian Momentum for Rapid Sampling. (arXiv:2111.02434v3 [cs.LG] UPDATED)
152. A toolkit for data-driven discovery of governing equations in high-noise regimes. (arXiv:2111.04870v2 [cs.LG] UPDATED)
153. CONFAIR: Configurable and Interpretable Algorithmic Fairness. (arXiv:2111.08878v3 [cs.LG] UPDATED)
154. Random Graph-Based Neuromorphic Learning with a Layer-Weaken Structure. (arXiv:2111.08888v2 [cs.LG] UPDATED)
155. ML-Decoder: Scalable and Versatile Classification Head. (arXiv:2111.12933v2 [cs.CV] UPDATED)
156. Evaluation of Interpretability for Deep Learning algorithms in EEG Emotion Recognition: A case study in Autism. (arXiv:2111.13208v2 [eess.SP] UPDATED)
157. Survey Descent: A Multipoint Generalization of Gradient Descent for Nonsmooth Optimization. (arXiv:2111.15645v2 [math.OC] UPDATED)
158. A Survey on Deep learning based Document Image Enhancement. (arXiv:2112.02719v3 [cs.CV] UPDATED)
159. Score-Based Generative Modeling with Critically-Damped Langevin Diffusion. (arXiv:2112.07068v2 [stat.ML] UPDATED)
160. Non Asymptotic Bounds for Optimization via Online Multiplicative Stochastic Gradient Descent. (arXiv:2112.07110v4 [stat.ML] UPDATED)
161. Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v3 [cs.LG] UPDATED)
162. A Unified Analysis Method for Online Optimization in Normed Vector Space. (arXiv:2112.12134v2 [cs.LG] UPDATED)
163. A Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drone. (arXiv:2112.12545v2 [math.OC] UPDATED)
164. Optimal Model Averaging of Support Vector Machines in Diverging Model Spaces. (arXiv:2112.12961v2 [stat.ML] UPDATED)
165. SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v2 [cs.CV] UPDATED)
166. Expected hypervolume improvement for simultaneous multi-objective and multi-fidelity optimization. (arXiv:2112.13901v2 [cs.LG] UPDATED)
167. Financial Vision Based Differential Privacy Applications. (arXiv:2112.14075v2 [cs.LG] UPDATED)
168. Beta-VAE Reproducibility: Challenges and Extensions. (arXiv:2112.14278v2 [cs.LG] UPDATED)
169. Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v2 [cs.AI] UPDATED)
170. Music-to-Dance Generation with Optimal Transport. (arXiv:2112.01806v1 [cs.SD] CROSS LISTED)
171. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**79** new papers in cs.AI:-) 
1. Proceedings of the 13th International Conference on Automated Deduction in Geometry. (arXiv:2112.14770v1 [cs.AI])
2. Deep Graph Clustering via Dual Correlation Reduction. (arXiv:2112.14772v1 [cs.LG])
3. Active Learning-Based Optimization of Scientific Experimental Design. (arXiv:2112.14811v1 [cs.LG])
4. Training Quantized Deep Neural Networks via Cooperative Coevolution. (arXiv:2112.14834v1 [cs.NE])
5. Recent Trends in Artificial Intelligence-inspired Electronic Thermal Management. (arXiv:2112.14837v1 [cs.LG])
6. An overview of the quantitative causality analysis and causal graph reconstruction based on a rigorous formalism of information flow. (arXiv:2112.14839v1 [eess.SY])
7. Explainable Signature-based Machine Learning Approach for Identification of Faults in Grid-Connected Photovoltaic Systems. (arXiv:2112.14842v1 [cs.LG])
8. A Graph Attention Learning Approach to Antenna Tilt Optimization. (arXiv:2112.14843v1 [cs.LG])
9. A Survey of Deep Learning Techniques for Dynamic Branch Prediction. (arXiv:2112.14911v1 [cs.AR])
10. Retrieving Black-box Optimal Images from External Databases. (arXiv:2112.14921v1 [cs.IR])
11. Dense Depth Estimation from Multiple 360-degree Images Using Virtual Depth. (arXiv:2112.14931v1 [cs.CV])
12. RheFrameDetect: A Text Classification System for Automatic Detection of Rhetorical Frames in AI from Open Sources. (arXiv:2112.14933v1 [cs.CL])
13. Automatic Mixed-Precision Quantization Search of BERT. (arXiv:2112.14938v1 [cs.CL])
14. Contrastive Learning of Semantic and Visual Representations for Text Tracking. (arXiv:2112.14976v1 [cs.CV])
15. Exploring the pattern of Emotion in children with ASD as an early biomarker through Recurring-Convolution Neural Network (R-CNN). (arXiv:2112.14983v1 [cs.CV])
16. Soundness in Object-centric Workflow Petri Nets. (arXiv:2112.14994v1 [cs.LO])
17. Investigating Pose Representations and Motion Contexts Modeling for 3D Motion Prediction. (arXiv:2112.15012v1 [cs.CV])
18. Measuring and Sampling: A Metric-guided Subgraph Learning Framework for Graph Neural Network. (arXiv:2112.15015v1 [cs.LG])
19. Two Instances of Interpretable Neural Network for Universal Approximations. (arXiv:2112.15026v1 [cs.LG])
20. Self Reward Design with Fine-grained Interpretability. (arXiv:2112.15034v1 [cs.LG])
21. Does QA-based intermediate training help fine-tuning language models for text classification?. (arXiv:2112.15051v1 [cs.CL])
22. TextRGNN: Residual Graph Neural Networks for Text Classification. (arXiv:2112.15060v1 [cs.CL])
23. Pose Estimation of Specific Rigid Objects. (arXiv:2112.15075v1 [cs.CV])
24. ChunkFormer: Learning Long Time Series with Multi-stage Chunked Transformer. (arXiv:2112.15087v1 [cs.LG])
25. Deconfounded Training for Graph Neural Networks. (arXiv:2112.15089v1 [cs.LG])
26. Leveraging in-domain supervision for unsupervised image-to-image translation tasks via multi-stream generators. (arXiv:2112.15091v1 [cs.CV])
27. Bayesian Algorithms Learn to Stabilize Unknown Continuous-Time Systems. (arXiv:2112.15094v1 [eess.SY])
28. Aim in Climate Change and City Pollution. (arXiv:2112.15115v1 [cs.LG])
29. From Behavioral Theories to Econometrics: Inferring Preferences of Human Agents from Data on Repeated Interactions. (arXiv:2112.15151v1 [cs.GT])
30. Chatbot for fitness management using IBM Watson. (arXiv:2112.15167v1 [cs.SE])
31. Constraint Sampling Reinforcement Learning: Incorporating Expertise For Faster Learning. (arXiv:2112.15221v1 [cs.AI])
32. Learning Agent State Online with Recurrent Generate-and-Test. (arXiv:2112.15236v1 [cs.LG])
33. What is Event Knowledge Graph: A Survey. (arXiv:2112.15280v1 [cs.LG])
34. SimSR: Simple Distance-based State Representation for Deep Reinforcement Learning. (arXiv:2112.15303v1 [cs.LG])
35. An Intelligent Self-driving Truck System For Highway Transportation. (arXiv:2112.15304v1 [cs.RO])
36. Binary Diffing as a Network Alignment Problem via Belief Propagation. (arXiv:2112.15337v1 [cs.LG])
37. Making AI 'Smart': Bridging AI and Cognitive Science. (arXiv:2112.15360v1 [cs.AI])
38. Robust Entropy-regularized Markov Decision Processes. (arXiv:2112.15364v1 [cs.LG])
39. Settling the Bias and Variance of Meta-Gradient Estimation for Meta-Reinforcement Learning. (arXiv:2112.15400v1 [cs.LG])
40. Scalar reward is not enough: A response to Silver, Singh, Precup and Sutton (2021). (arXiv:2112.15422v1 [cs.AI])
41. A Survey on Hyperdimensional Computing aka Vector Symbolic Architectures, Part II: Applications, Cognitive Models, and Challenges. (arXiv:2112.15424v1 [cs.AI])
42. Robustness and risk management via distributional dynamic programming. (arXiv:2112.15430v1 [cs.LG])
43. GANISP: a GAN-assisted Importance SPlitting Probability Estimator. (arXiv:2112.15444v1 [cs.LG])
44. Speedup deep learning models on GPU by taking advantage of efficient unstructured pruning and bit-width reduction. (arXiv:2112.15445v1 [cs.LG])
45. Uniform-in-Phase-Space Data Selection with Iterative Normalizing Flows. (arXiv:2112.15446v1 [cs.LG])
46. Social Neuro AI: Social Interaction as the "dark matter" of AI. (arXiv:2112.15459v1 [cs.MA])
47. Shift-Equivariant Similarity-Preserving Hypervector Representations of Sequences. (arXiv:2112.15475v1 [cs.AI])
48. A Research Agenda for Artificial Intelligence in the Field of Flexible Production Systems. (arXiv:2112.15484v1 [cs.AI])
49. OWLOOP: A Modular API to Describe OWL Axioms in OOP Objects Hierarchies. (arXiv:2112.15544v1 [cs.AI])
50. Fast Learning of MNL Model from General Partial Rankings with Application to Network Formation Modeling. (arXiv:2112.15575v1 [cs.LG])
51. Importance of Empirical Sample Complexity Analysis for Offline Reinforcement Learning. (arXiv:2112.15578v1 [cs.LG])
52. A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More. (arXiv:2112.15594v1 [cs.LG])
53. Flow: A Modular Learning Framework for Mixed Autonomy Traffic. (arXiv:1710.05465v4 [cs.AI] UPDATED)
54. Towards a Neural Model for Serial Order in Frontal Cortex: a Brain Theory from Memory Development to Higher-Level Cognition. (arXiv:2005.11203v2 [cs.NE] UPDATED)
55. Efficient Robust Training via Backward Smoothing. (arXiv:2010.01278v2 [cs.LG] UPDATED)
56. Memory AMP. (arXiv:2012.10861v5 [cs.IT] UPDATED)
57. Fairness-Oriented User Scheduling for Bursty Downlink Transmission Using Multi-Agent Reinforcement Learning. (arXiv:2012.15081v13 [cs.OS] UPDATED)
58. Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design: Implicit Regularization and Sample Complexity. (arXiv:2101.01041v3 [math.OC] UPDATED)
59. Hybrid Adversarial Imitation Learning. (arXiv:2102.02454v10 [cs.LG] UPDATED)
60. A Survey of Embodied AI: From Simulators to Research Tasks. (arXiv:2103.04918v6 [cs.AI] UPDATED)
61. Full-Sentence Models Perform Better in Simultaneous Translation Using the Information Enhanced Decoding Strategy. (arXiv:2105.01893v2 [cs.CL] UPDATED)
62. Simplifying Software Defect Prediction (via the "early bird" Heuristic). (arXiv:2105.11082v2 [cs.SE] UPDATED)
63. Blockchain Technology: Bitcoins, Cryptocurrency and Applications. (arXiv:2107.07964v2 [cs.CR] UPDATED)
64. Geometric Deep Learning on Molecular Representations. (arXiv:2107.12375v4 [physics.chem-ph] UPDATED)
65. BiTr-Unet: a CNN-Transformer Combined Network for MRI Brain Tumor Segmentation. (arXiv:2109.12271v2 [eess.IV] UPDATED)
66. Motivating Learners in Multi-Orchestrator Mobile Edge Learning: A Stackelberg Game Approach. (arXiv:2109.12409v3 [cs.NI] UPDATED)
67. Reward-Free Model-Based Reinforcement Learning with Linear Function Approximation. (arXiv:2110.06394v2 [cs.LG] UPDATED)
68. A Survey on State-of-the-art Techniques for Knowledge Graphs Construction and Challenges ahead. (arXiv:2110.08012v2 [cs.AI] UPDATED)
69. ifMixup: Towards Intrusion-Free Graph Mixup for Graph Classification. (arXiv:2110.09344v2 [cs.LG] UPDATED)
70. Human-Centered Explainable AI (XAI): From Algorithms to User Experiences. (arXiv:2110.10790v3 [cs.AI] UPDATED)
71. Unintended Selection: Persistent Qualification Rate Disparities and Interventions. (arXiv:2111.01201v2 [cs.LG] UPDATED)
72. Imagine Networks. (arXiv:2111.03048v5 [cs.AI] UPDATED)
73. ARKitScenes -- A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data. (arXiv:2111.08897v2 [cs.CV] UPDATED)
74. Consistent Training and Decoding For End-to-end Speech Recognition Using Lattice-free MMI. (arXiv:2112.02498v2 [cs.AI] UPDATED)
75. Diformer: Directional Transformer for Neural Machine Translation. (arXiv:2112.11632v2 [cs.CL] UPDATED)
76. A Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drone. (arXiv:2112.12545v2 [math.OC] UPDATED)
77. Beta-VAE Reproducibility: Challenges and Extensions. (arXiv:2112.14278v2 [cs.LG] UPDATED)
78. Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v2 [cs.AI] UPDATED)
79. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v1 [cs.CV] CROSS LISTED)
