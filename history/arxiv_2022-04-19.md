# Your interest papers
---
## cs.CV
---
### Efficient Linear Attention for Fast and Accurate Keypoint Matching. (arXiv:2204.07731v1 [cs.CV])
- Authors : Suwichaya Suwanwimolkul, Satoshi Komorita
- Link : [http://arxiv.org/abs/2204.07731](http://arxiv.org/abs/2204.07731)
> ABSTRACT  :  Recently Transformers have provided state-of-the-art performance in sparse matching, crucial to realize high-performance 3D vision applications. Yet, these Transformers lack efficiency due to the quadratic computational complexity of their attention mechanism. To solve this problem, we employ an efficient linear attention for the linear computational complexity. Then, we propose a new attentional aggregation that achieves high accuracy by aggregating both the global and local information from sparse keypoints. To further improve the efficiency, we propose the joint learning of feature matching and description. Our learning enables simpler and faster matching than Sinkhorn, often used in matching the learned descriptors from Transformers. Our method achieves competitive performance with only 0.84M learnable parameters against the bigger SOTAs, SuperGlue (12M parameters) and SGMNet (30M parameters), on three benchmarks, HPatch, ETH, and Aachen Day-**Night**.  
### Towards Lightweight Transformer via Group-wise Transformation for Vision-and-Language Tasks. (arXiv:2204.07780v1 [cs.CV])
- Authors : Gen Luo, Yiyi Zhou, Xiaoshuai Sun, Yan Wang, Liujuan Cao, Yongjian Wu, Feiyue Huang, Rongrong Ji
- Link : [http://arxiv.org/abs/2204.07780](http://arxiv.org/abs/2204.07780)
> ABSTRACT  :  Despite the exciting performance, Transformer is criticized for its excessive parameters and computation cost. However, compressing Transformer remains as an open problem due to its internal complexity of the layer designs, i.e., Multi-Head Attention (MHA) and Feed-Forward Network (FFN). To address this issue, we introduce Group-wise Transformation towards a universal yet lightweight Transformer for vision-and-language tasks, termed as LW-Transformer. LW-Transformer applies Group-wise Transformation to reduce both the parameters and computations of Transformer, while also preserving its two main properties, i.e., the efficient attention modeling on diverse subspaces of MHA, and the expanding-scaling feature transformation of FFN. We apply LW-Transformer to a set of Transformer-based networks, and quantitatively measure them on three vision-and-language tasks and six benchmark datasets. Experimental results show that while saving a large number of parameters and computations, LW-Transformer achieves very competitive performance against the original Transformer networks for vision-and-language tasks. To examine the generalization ability, we also apply our optimization strategy to a recently proposed image Transformer called **Swin**-Transformer for image classification, where the effectiveness can be also confirmed  
### MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral Reconstruction. (arXiv:2204.07908v1 [cs.CV])
- Authors : Yuanhao Cai, Jing Lin, Zudi Lin, Haoqian Wang, Yulun Zhang, Hanspeter Pfister, Radu Timofte, Luc Van
- Link : [http://arxiv.org/abs/2204.07908](http://arxiv.org/abs/2204.07908)
> ABSTRACT  :  Existing leading methods for spectral reconstruction (SR) focus on designing deeper or wider convolutional neural networks (CNNs) to learn the end-to-end mapping from the RGB image to its hyperspectral image (HSI). These CNN-based methods achieve impressive **restoration** performance while showing limitations in capturing the long-range dependencies and self-similarity prior. To cope with this problem, we propose a novel Transformer-based method, Multi-stage Spectral-wise Transformer (MST++), for efficient spectral reconstruction. In particular, we employ Spectral-wise Multi-head Self-attention (S-MSA) that is based on the HSI spatially sparse while spectrally self-similar nature to compose the basic unit, Spectral-wise Attention Block (SAB). Then SABs build up Single-stage Spectral-wise Transformer (SST) that exploits a U-shaped structure to extract multi-resolution contextual information. Finally, our MST++, cascaded by several SSTs, progressively improves the reconstruction quality from coarse to fine. Comprehensive experiments show that our MST++ significantly outperforms other state-of-the-art methods. In the NTIRE 2022 Spectral Reconstruction Challenge, our approach won the First place. Code and pre-trained models are publicly available at https://github.com/caiyuanhao1998/MST-plus-plus.  
### Fast Multi-grid Methods for Minimizing Curvature Energy. (arXiv:2204.07921v1 [cs.CV])
- Authors : Zhenwei Zhang, Ke Chen, Yuping Duan
- Link : [http://arxiv.org/abs/2204.07921](http://arxiv.org/abs/2204.07921)
> ABSTRACT  :  The geometric high-order regularization methods such as mean curvature and Gaussian curvature, have been intensively studied during the last decades due to their abilities in preserving geometric properties including image edges, corners, and image contrast. However, the dilemma between **restoration** quality and computational efficiency is an essential roadblock for high-order methods. In this paper, we propose fast multi-grid algorithms for minimizing both mean curvature and Gaussian curvature energy functionals without sacrificing the accuracy for efficiency. Unlike the existing approaches based on operator splitting and the Augmented Lagrangian method (ALM), no artificial parameters are introduced in our formulation, which guarantees the robustness of the proposed algorithm. Meanwhile, we adopt the domain decomposition method to promote parallel computing and use the fine-to-coarse structure to accelerate the convergence. Numerical experiments are presented on both image denoising and CT reconstruction problem to demonstrate the ability to recover image texture and the efficiency of the proposed method.  
### An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
- Authors : Hwanjun Song, Deqing Sun, Sanghyuk Chun, Varun Jampani, Dongyoon Han, Byeongho Heo, Wonjae Kim, Hsuan Yang
- Link : [http://arxiv.org/abs/2204.07962](http://arxiv.org/abs/2204.07962)
> ABSTRACT  :  Transformers have been widely used in numerous vision problems especially for visual recognition and detection. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to construct an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent **Swin** Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. In addition, we extend it to ViDT+ to support joint-task learning for object detection and instance segmentation. Specifically, we attach an efficient multi-scale feature fusion layer and utilize two more auxiliary training losses, IoU-aware loss and token labeling loss. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and its extended ViDT+ achieves 53.2AP owing to its high scalability for large models. The source code and trained models are available at https://github.com/naver-ai/vidt.  
### VDTR: Video Deblurring with Transformer. (arXiv:2204.08023v1 [cs.CV])
- Authors : Mingdeng Cao, Yanbo Fan, Yong Zhang, Jue Wang, Yujiu Yang
- Link : [http://arxiv.org/abs/2204.08023](http://arxiv.org/abs/2204.08023)
> ABSTRACT  :  Video deblurring is still an unsolved problem due to the challenging spatio-temporal modeling process. While existing convolutional neural network-based methods show a limited capacity for effective spatial and temporal modeling for video deblurring. This paper presents VDTR, an effective Transformer-based model that makes the first attempt to adapt Transformer for video deblurring. VDTR exploits the superior long-range and relation modeling capabilities of Transformer for both spatial and temporal modeling. However, it is challenging to design an appropriate Transformer-based model for video deblurring due to the complicated non-uniform blurs, misalignment across multiple frames and the high computational costs for high-resolution spatial modeling. To address these problems, VDTR advocates performing attention within non-overlapping windows and exploiting the hierarchical structure for long-range dependencies modeling. For frame-level spatial modeling, we propose an encoder-decoder Transformer that utilizes multi-scale features for deblurring. For multi-frame temporal modeling, we adapt Transformer to fuse multiple spatial features efficiently. Compared with CNN-based methods, the proposed method achieves highly competitive results on both synthetic and real-world video deblurring benchmarks, including DVD, GOPRO, REDS and BSD. We hope such a Transformer-based architecture can serve as a powerful alternative baseline for video deblurring and other video **restoration** tasks. The source code will be available at \url{https://github.com/ljzycmd/VDTR}.  
### Deep Learning based Automatic Detection of Dicentric Chromosome. (arXiv:2204.08029v1 [cs.CV])
- Authors : Angad Singh, Nikhil Tyagi, Pinaki Roy
- Link : [http://arxiv.org/abs/2204.08029](http://arxiv.org/abs/2204.08029)
> ABSTRACT  :  Automatic detection of dicentric chromosomes is an essential step to estimate radiation **exposure** and development of end to end emergency bio dosimetry systems. During accidents, a large amount of data is required to be processed for extensive testing to formulate a medical treatment plan for the masses, which requires this process to be automated. Current approaches require human adjustments according to the data and therefore need a human expert to calibrate the system. This paper proposes a completely data driven framework which requires minimum intervention of field experts and can be deployed in emergency cases with relative ease. Our approach involves YOLOv4 to detect the chromosomes and remove the debris in each image, followed by a classifier that differentiates between an analysable chromosome and a non-analysable one. Images are extracted from YOLOv4 based on the protocols described by WHO-BIODOSNET. The analysable chromosome is classified as Monocentric or Dicentric and an image is accepted for consideration of dose estimation based on the analysable chromosome count. We report an accuracy in dicentric identification of 94.33% on a 1:1 split of Dicentric and Monocentric Chromosomes.  
### Heavy Rain Face Image **Restoration**: Integrating Physical Degradation Model and Facial Component Guided Adversarial Learning. (arXiv:2204.08307v1 [cs.CV])
- Authors : Hwan Son, Hee Jeong
- Link : [http://arxiv.org/abs/2204.08307](http://arxiv.org/abs/2204.08307)
> ABSTRACT  :  With the recent increase in intelligent CCTVs for visual surveillance, a new image degradation that integrates resolution conversion and synthetic rain models is required. For example, in heavy rain, face images captured by CCTV from a distance have significant deterioration in both visibility and resolution. Unlike traditional image degradation models (IDM), such as rain removal and superresolution, this study addresses a new IDM referred to as a scale-aware heavy rain model and proposes a method for restoring high-resolution face images (HR-FIs) from low-resolution heavy rain face images (LRHR-FI). To this end, a 2-stage network is presented. The first stage generates low-resolution face images (LR-FIs), from which heavy rain has been removed from the LRHR-FIs to improve visibility. To realize this, an interpretable IDM-based network is constructed to predict physical parameters, such as rain streaks, transmission maps, and atmospheric light. In addition, the image reconstruction loss is evaluated to enhance the estimates of the physical parameters. For the second stage, which aims to reconstruct the HR-FIs from the LR-FIs outputted in the first stage, facial component guided adversarial learning (FCGAL) is applied to boost facial structure expressions. To focus on informative facial features and reinforce the authenticity of facial components, such as the eyes and nose, a face-parsing-guided generator and facial local discriminators are designed for FCGAL. The experimental results verify that the proposed approach based on physical-based network design and FCGAL can remove heavy rain and increase the resolution and visibility simultaneously. Moreover, the proposed heavy-rain face image **restoration** outperforms state-of-the-art models of heavy rain removal, image-to-image translation, and superresolution.  
### BSRT: Improving Burst Super-Resolution with **Swin** Transformer and Flow-Guided Deformable Alignment. (arXiv:2204.08332v1 [cs.CV])
- Authors : Ziwei Luo, Youwei Li, Shen Cheng, Lei Yu, Qi Wu, Zhihong Wen, Haoqiang Fan, Jian Sun, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2204.08332](http://arxiv.org/abs/2204.08332)
> ABSTRACT  :  This work addresses the Burst Super-Resolution (BurstSR) task using a new architecture, which requires restoring a high-quality image from a sequence of noisy, misaligned, and low-resolution RAW bursts. To overcome the challenges in BurstSR, we propose a Burst Super-Resolution Transformer (BSRT), which can significantly improve the capability of extracting inter-frame information and reconstruction. To achieve this goal, we propose a Pyramid Flow-Guided Deformable Convolution Network (Pyramid FG-DCN) and incorporate **Swin** Transformer Blocks and Groups as our main backbone. More specifically, we combine optical flows and deformable convolutions, hence our BSRT can handle misalignment and aggregate the potential texture information in multi-frames more efficiently. In addition, our Transformer-based structure can capture long-range dependency to further improve the performance. The evaluation on both synthetic and real-world tracks demonstrates that our approach achieves a new state-of-the-art in BurstSR task. Further, our BSRT wins the championship in the NTIRE2022 Burst Super-Resolution Challenge.  
### Can You Spot the Chameleon? Adversarially Camouflaging Images from Co-Salient Object Detection. (arXiv:2009.09258v5 [cs.CV] UPDATED)
- Authors : Ruijun Gao, Qing Guo, Felix Juefei, Hongkai Yu, Huazhu Fu, Wei Feng, Yang Liu, Song Wang
- Link : [http://arxiv.org/abs/2009.09258](http://arxiv.org/abs/2009.09258)
> ABSTRACT  :  Co-salient object detection (CoSOD) has recently achieved significant progress and played a key role in retrieval-related tasks. However, it inevitably poses an entirely new safety and security issue, i.e., highly personal and sensitive content can potentially be extracting by powerful CoSOD methods. In this paper, we address this problem from the perspective of adversarial attacks and identify a novel task: adversarial co-saliency attack. Specially, given an image selected from a group of images containing some common and salient objects, we aim to generate an adversarial version that can mislead CoSOD methods to predict incorrect co-salient regions. Note that, compared with general white-box adversarial attacks for classification, this new task faces two additional challenges: (1) low success rate due to the diverse appearance of images in the group; (2) low transferability across CoSOD methods due to the considerable difference between CoSOD pipelines. To address these challenges, we propose the very first black-box joint adversarial **exposure** and noise attack (Jadena), where we jointly and locally tune the **exposure** and additive perturbations of the image according to a newly designed high-feature-level contrast-sensitive loss function. Our method, without any information on the state-of-the-art CoSOD methods, leads to significant performance degradation on various co-saliency detection datasets and makes the co-salient objects undetectable. This can have strong practical benefits in properly securing the large number of personal photos currently shared on the Internet. Moreover, our method is potential to be utilized as a metric for evaluating the robustness of CoSOD methods.  
### A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for **Real-time** Surgical Video Analysis. (arXiv:2103.16847v3 [eess.IV] UPDATED)
- Authors : Ella Selina
- Link : [http://arxiv.org/abs/2103.16847](http://arxiv.org/abs/2103.16847)
> ABSTRACT  :  Seven million people suffer surgical complications each year, but with sufficient surgical training and review, 50\% of these complications could be prevented. To improve surgical performance, existing research uses various deep learning (DL) technologies including convolutional neural networks (CNN) and recurrent neural networks (RNN) to automate surgical tool and workflow detection. However, there is room to improve accuracy; real-time analysis is also minimal due to the complexity of CNN. In this research, a novel DL architecture is proposed to integrate visual simultaneous localization and mapping (vSLAM) into Mask R-CNN. This architecture, vSLAM-CNN (vCNN), for the first time, integrates the best of both worlds, inclusive of (1) vSLAM for object detection, by focusing on geometric information for region proposals, and (2) CNN for object recognition, by focusing on semantic information for image classification, combining them into one joint end-to-end training process. This method, using spatio-temporal information in addition to visual features, is evaluated on M2CAI 2016 challenge datasets, achieving the state-of-the-art results with 96.8 mAP for tool detection and 97.5 mean Jaccard score for workflow detection, surpassing all previous works, and reaching a 50 FPS performance, 10x faster than the region-based CNN. A region proposal module (RPM) replaces the region proposal network (RPN) in Mask R-CNN, accurately placing bounding boxes and lessening the annotation requirement. Furthermore, a Microsoft HoloLens 2 application is developed to provide an augmented reality (AR)-based solution for surgical training and assistance.  
### Salient Objects in Clutter. (arXiv:2105.03053v2 [cs.CV] UPDATED)
- Authors : Ping Fan, Jing Zhang, Gang Xu, Ming Cheng, Ling Shao
- Link : [http://arxiv.org/abs/2105.03053](http://arxiv.org/abs/2105.03053)
> ABSTRACT  :  This paper identifies and addresses a serious design bias of existing salient object detection (SOD) datasets, which unrealistically assume that each image should contain at least one clear and uncluttered salient object. This design bias has led to a saturation in performance for state-of-the-art SOD models when evaluated on existing datasets. However, these models are still far from satisfactory when applied to real-world scenes. Based on our analyses, we propose a new high-quality dataset and update the previous saliency benchmark. Specifically, our dataset, called Salient Objects in Clutter~\textbf{(SOC)}, includes images with both salient and non-salient objects from several common object categories. In addition to object category annotations, each salient image is accompanied by attributes that reflect common challenges in common scenes, which can help provide deeper insight into the SOD problem. Further, with a given saliency encoder, e.g., the backbone network, existing saliency models are designed to achieve mapping from the training image set to the training ground-truth set. We, therefore, argue that improving the dataset can yield higher performance gains than focusing only on the decoder design. With this in mind, we investigate several dataset-**enhancement** strategies, including label smoothing to implicitly emphasize salient boundaries, random image augmentation to adapt saliency models to various scenarios, and self-supervised learning as a regularization strategy to learn from small datasets. Our extensive results demonstrate the effectiveness of these tricks. We also provide a comprehensive benchmark for SOD, which can be found in our repository: https://github.com/DengPingFan/SODBenchmark.  
### GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for Low-dose CT Denoising. (arXiv:2105.07146v2 [eess.IV] UPDATED)
- Authors : Kecheng Chen, Jiayu Sun, Jiang Shen, Jixiang Luo, Xinyu Zhang, Xuelin Pan, Dongsheng Wu, Yue Zhao, Miguel Bento, Yazhou Ren, Xiaorong Pu
- Link : [http://arxiv.org/abs/2105.07146](http://arxiv.org/abs/2105.07146)
> ABSTRACT  :  Being low-level radiation **exposure** and less harmful to health, low-dose computed tomography (LDCT) has been widely adopted in the early screening of lung cancer and COVID-19. LDCT images inevitably suffer from the degradation problem caused by complex noises. It was reported that deep learning (DL)-based LDCT denoising methods using convolutional neural network (CNN) achieved impressive denoising performance. Although most existing DL-based methods (e.g., encoder-decoder framework) can implicitly utilize non-local and contextual information via downsampling operator and 3D CNN, the explicit multi-information (i.e., local, non-local, and contextual) integration may not be explored enough. To address this issue, we propose a novel graph convolutional network-based LDCT denoising model, namely GCN-MIF, to explicitly perform multi-information fusion for denoising purpose. Concretely, by constructing intra- and inter-slice graph, the graph convolutional network is introduced to leverage the non-local and contextual relationships among pixels. The traditional CNN is adopted for the extraction of local information. Finally, the proposed GCN-MIF model fuses all the extracted local, non-local, and contextual information. Extensive experiments show the effectiveness of our proposed GCN-MIF model by quantitative and visualized results. Furthermore, a double-blind reader study on a public clinical dataset is also performed to validate the usability of denoising results in terms of the structural fidelity, the noise suppression, and the overall score. Models and code are available at https://github.com/tonyckc/GCN-MIF_demo.  
### SimMIM: A Simple Framework for Masked Image Modeling. (arXiv:2111.09886v2 [cs.CV] UPDATED)
- Authors : Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, Jianmin Bao, Zhuliang Yao, Qi Dai, Han Hu
- Link : [http://arxiv.org/abs/2111.09886](http://arxiv.org/abs/2111.09886)
> ABSTRACT  :  This paper presents SimMIM, a simple framework for masked image modeling. We simplify recently proposed related approaches without special designs such as block-wise masking and tokenization via discrete VAE or clustering. To study what let the masked image modeling task learn good representations, we systematically study the major components in our framework, and find that simple designs of each component have revealed very strong representation learning performance: 1) random masking of the input image with a moderately large masked patch size (e.g., 32) makes a strong pre-text task; 2) predicting raw pixels of RGB values by direct regression performs no worse than the patch classification approaches with complex designs; 3) the prediction head can be as light as a linear layer, with no worse performance than heavier ones. Using ViT-B, our approach achieves 83.8% top-1 fine-tuning accuracy on ImageNet-1K by pre-training also on this dataset, surpassing previous best approach by +0.6%. When applied on a larger model of about 650 million parameters, **Swin**V2-H, it achieves 87.1% top-1 accuracy on ImageNet-1K using only ImageNet-1K data. We also leverage this approach to facilitate the training of a 3B model (**Swin**V2-G), that by $40\times$ less data than that in previous practice, we achieve the state-of-the-art on four representative vision benchmarks. The code and models will be publicly available at https://github.com/microsoft/SimMIM.  
### Distill and De-bias: Mitigating Bias in Face Verification using Knowledge Distillation. (arXiv:2112.09786v3 [cs.CV] UPDATED)
- Authors : Prithviraj Dhar, Joshua Gleason, Aniket Roy, Jonathon Phillips, Rama Chellappa
- Link : [http://arxiv.org/abs/2112.09786](http://arxiv.org/abs/2112.09786)
> ABSTRACT  :  Face recognition networks generally demonstrate bias with respect to sensitive attributes like gender, skintone etc. For gender and skintone, we observe that the regions of the face that a network attends to vary by the category of an attribute. This might contribute to bias. Building on this intuition, we propose a novel distillation-based approach called Distill and De-bias (D&amp;D) to enforce a network to attend to similar face regions, irrespective of the attribute category. In D&amp;D, we train a teacher network on images from one category of an attribute; e.g. light skintone. Then distilling information from the teacher, we train a student network on images of the remaining category; e.g., **dark** skintone. A feature-level distillation loss constrains the student network to generate teacher-like representations. This allows the student network to attend to similar face regions for all attribute categories and enables it to reduce bias. We also propose a second distillation step on top of D&amp;D, called D&amp;D++. Here, we distill the `un-biasedness' of the D&amp;D network into a new student network, the D&amp;D++ network, while training this new network on all attribute categories; e.g., both light and **dark** skintones. This helps us train a network that is less biased for an attribute, while obtaining higher face verification performance than D&amp;D. We show that D&amp;D++ outperforms existing baselines in reducing gender and skintone bias on the IJB-C dataset, while obtaining higher face verification performance than existing adversarial de-biasing methods. We evaluate the effectiveness of our proposed methods on two state-of-the-art face recognition networks: ArcFace and Crystalface.  
### 3D-aware Image Synthesis via Learning Structural and Textural Representations. (arXiv:2112.10759v2 [cs.CV] UPDATED)
- Authors : Yinghao Xu, Sida Peng, Ceyuan Yang, Yujun Shen, Bolei Zhou
- Link : [http://arxiv.org/abs/2112.10759](http://arxiv.org/abs/2112.10759)
> ABSTRACT  :  Making generative models 3D-aware bridges the 2D image space and the 3D physical world yet remains challenging. Recent attempts equip a Generative Adversarial Network (GAN) with a Neural Radiance Field (**NeRF**), which maps 3D coordinates to pixel values, as a 3D prior. However, the implicit function in **NeRF** has a very local receptive field, making the generator hard to become aware of the global structure. Meanwhile, **NeRF** is built on volume rendering which can be too costly to produce high-resolution results, increasing the optimization difficulty. To alleviate these two problems, we propose a novel framework, termed as VolumeGAN, for high-fidelity 3D-aware image synthesis, through explicitly learning a structural representation and a textural representation. We first learn a feature volume to represent the underlying structure, which is then converted to a feature field using a **NeRF**-like model. The feature field is further accumulated into a 2D feature map as the textural representation, followed by a neural renderer for appearance synthesis. Such a design enables independent control of the shape and the appearance. Extensive experiments on a wide range of datasets show that our approach achieves sufficiently higher image quality and better 3D control than the previous methods.  
### Event Transformer. A sparse-aware solution for efficient event data processing. (arXiv:2204.03355v2 [cs.CV] UPDATED)
- Authors : Alberto Sabater, Luis Montesano
- Link : [http://arxiv.org/abs/2204.03355](http://arxiv.org/abs/2204.03355)
> ABSTRACT  :  Event cameras are sensors of great interest for many applications that run in low-resource and challenging environments. They log sparse illumination changes with high temporal resolution and **high dynamic range**, while they present minimal power consumption. However, top-performing methods often ignore specific event-data properties, leading to the development of generic but computationally expensive algorithms. Efforts toward efficient solutions usually do not achieve top-accuracy results for complex tasks. This work proposes a novel framework, Event Transformer (EvT), that effectively takes advantage of event-data properties to be highly efficient and accurate. We introduce a new patch-based event representation and a compact transformer-like architecture to process it. EvT is evaluated on different event-based benchmarks for action and gesture recognition. Evaluation results show better or comparable accuracy to the state-of-the-art while requiring significantly less computation resources, which makes EvT able to work with minimal latency both on GPU and CPU.  
## eess.IV
---
### Fast Multi-grid Methods for Minimizing Curvature Energy. (arXiv:2204.07921v1 [cs.CV])
- Authors : Zhenwei Zhang, Ke Chen, Yuping Duan
- Link : [http://arxiv.org/abs/2204.07921](http://arxiv.org/abs/2204.07921)
> ABSTRACT  :  The geometric high-order regularization methods such as mean curvature and Gaussian curvature, have been intensively studied during the last decades due to their abilities in preserving geometric properties including image edges, corners, and image contrast. However, the dilemma between **restoration** quality and computational efficiency is an essential roadblock for high-order methods. In this paper, we propose fast multi-grid algorithms for minimizing both mean curvature and Gaussian curvature energy functionals without sacrificing the accuracy for efficiency. Unlike the existing approaches based on operator splitting and the Augmented Lagrangian method (ALM), no artificial parameters are introduced in our formulation, which guarantees the robustness of the proposed algorithm. Meanwhile, we adopt the domain decomposition method to promote parallel computing and use the fine-to-coarse structure to accelerate the convergence. Numerical experiments are presented on both image denoising and CT reconstruction problem to demonstrate the ability to recover image texture and the efficiency of the proposed method.  
### A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for **Real-time** Surgical Video Analysis. (arXiv:2103.16847v3 [eess.IV] UPDATED)
- Authors : Ella Selina
- Link : [http://arxiv.org/abs/2103.16847](http://arxiv.org/abs/2103.16847)
> ABSTRACT  :  Seven million people suffer surgical complications each year, but with sufficient surgical training and review, 50\% of these complications could be prevented. To improve surgical performance, existing research uses various deep learning (DL) technologies including convolutional neural networks (CNN) and recurrent neural networks (RNN) to automate surgical tool and workflow detection. However, there is room to improve accuracy; real-time analysis is also minimal due to the complexity of CNN. In this research, a novel DL architecture is proposed to integrate visual simultaneous localization and mapping (vSLAM) into Mask R-CNN. This architecture, vSLAM-CNN (vCNN), for the first time, integrates the best of both worlds, inclusive of (1) vSLAM for object detection, by focusing on geometric information for region proposals, and (2) CNN for object recognition, by focusing on semantic information for image classification, combining them into one joint end-to-end training process. This method, using spatio-temporal information in addition to visual features, is evaluated on M2CAI 2016 challenge datasets, achieving the state-of-the-art results with 96.8 mAP for tool detection and 97.5 mean Jaccard score for workflow detection, surpassing all previous works, and reaching a 50 FPS performance, 10x faster than the region-based CNN. A region proposal module (RPM) replaces the region proposal network (RPN) in Mask R-CNN, accurately placing bounding boxes and lessening the annotation requirement. Furthermore, a Microsoft HoloLens 2 application is developed to provide an augmented reality (AR)-based solution for surgical training and assistance.  
### GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for Low-dose CT Denoising. (arXiv:2105.07146v2 [eess.IV] UPDATED)
- Authors : Kecheng Chen, Jiayu Sun, Jiang Shen, Jixiang Luo, Xinyu Zhang, Xuelin Pan, Dongsheng Wu, Yue Zhao, Miguel Bento, Yazhou Ren, Xiaorong Pu
- Link : [http://arxiv.org/abs/2105.07146](http://arxiv.org/abs/2105.07146)
> ABSTRACT  :  Being low-level radiation **exposure** and less harmful to health, low-dose computed tomography (LDCT) has been widely adopted in the early screening of lung cancer and COVID-19. LDCT images inevitably suffer from the degradation problem caused by complex noises. It was reported that deep learning (DL)-based LDCT denoising methods using convolutional neural network (CNN) achieved impressive denoising performance. Although most existing DL-based methods (e.g., encoder-decoder framework) can implicitly utilize non-local and contextual information via downsampling operator and 3D CNN, the explicit multi-information (i.e., local, non-local, and contextual) integration may not be explored enough. To address this issue, we propose a novel graph convolutional network-based LDCT denoising model, namely GCN-MIF, to explicitly perform multi-information fusion for denoising purpose. Concretely, by constructing intra- and inter-slice graph, the graph convolutional network is introduced to leverage the non-local and contextual relationships among pixels. The traditional CNN is adopted for the extraction of local information. Finally, the proposed GCN-MIF model fuses all the extracted local, non-local, and contextual information. Extensive experiments show the effectiveness of our proposed GCN-MIF model by quantitative and visualized results. Furthermore, a double-blind reader study on a public clinical dataset is also performed to validate the usability of denoising results in terms of the structural fidelity, the noise suppression, and the overall score. Models and code are available at https://github.com/tonyckc/GCN-MIF_demo.  
## cs.LG
---
### Conditional Injective Flows for Bayesian Imaging. (arXiv:2204.07664v1 [cs.LG])
- Authors : AmirEhsan Khorashadizadeh, Konik Kothari, Leonardo Salsi, Ali Aghababaei, Maarten de, Ivan Dokmani
- Link : [http://arxiv.org/abs/2204.07664](http://arxiv.org/abs/2204.07664)
> ABSTRACT  :  Most deep learning models for computational imaging regress a single reconstructed image. In practice, however, ill-posedness, nonlinearity, model mismatch, and noise often conspire to make such point estimates misleading or insufficient. The Bayesian approach models images and (noisy) measurements as jointly distributed random vectors and aims to approximate the posterior distribution of unknowns. Recent variational inference methods based on conditional normalizing flows are a promising alternative to traditional MCMC methods, but they come with drawbacks: excessive memory and compute demands for moderate to high resolution images and underwhelming performance on hard nonlinear problems. In this work, we propose C-Trumpets -- conditional injective flows specifically designed for imaging problems, which greatly diminish these challenges. Injectivity reduces memory footprint and training time while low-dimensional latent space together with architectural innovations like fixed-volume-change layers and skip-connection revnet layers, C-Trumpets outperform regular conditional flow models on a variety of imaging and image **restoration** tasks, including limited-view CT and nonlinear inverse scattering, with a lower compute and memory budget. C-Trumpets enable fast approximation of point estimates like MMSE or MAP as well as physically-meaningful uncertainty quantification.  
### An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
- Authors : Hwanjun Song, Deqing Sun, Sanghyuk Chun, Varun Jampani, Dongyoon Han, Byeongho Heo, Wonjae Kim, Hsuan Yang
- Link : [http://arxiv.org/abs/2204.07962](http://arxiv.org/abs/2204.07962)
> ABSTRACT  :  Transformers have been widely used in numerous vision problems especially for visual recognition and detection. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to construct an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent **Swin** Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. In addition, we extend it to ViDT+ to support joint-task learning for object detection and instance segmentation. Specifically, we attach an efficient multi-scale feature fusion layer and utilize two more auxiliary training losses, IoU-aware loss and token labeling loss. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and its extended ViDT+ achieves 53.2AP owing to its high scalability for large models. The source code and trained models are available at https://github.com/naver-ai/vidt.  
## cs.AI
---
### An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
- Authors : Hwanjun Song, Deqing Sun, Sanghyuk Chun, Varun Jampani, Dongyoon Han, Byeongho Heo, Wonjae Kim, Hsuan Yang
- Link : [http://arxiv.org/abs/2204.07962](http://arxiv.org/abs/2204.07962)
> ABSTRACT  :  Transformers have been widely used in numerous vision problems especially for visual recognition and detection. Detection transformers are the first fully end-to-end learning systems for object detection, while vision transformers are the first fully transformer-based architecture for image classification. In this paper, we integrate Vision and Detection Transformers (ViDT) to construct an effective and efficient object detector. ViDT introduces a reconfigured attention module to extend the recent **Swin** Transformer to be a standalone object detector, followed by a computationally efficient transformer decoder that exploits multi-scale features and auxiliary techniques essential to boost the detection performance without much increase in computational load. In addition, we extend it to ViDT+ to support joint-task learning for object detection and instance segmentation. Specifically, we attach an efficient multi-scale feature fusion layer and utilize two more auxiliary training losses, IoU-aware loss and token labeling loss. Extensive evaluation results on the Microsoft COCO benchmark dataset demonstrate that ViDT obtains the best AP and latency trade-off among existing fully transformer-based object detectors, and its extended ViDT+ achieves 53.2AP owing to its high scalability for large models. The source code and trained models are available at https://github.com/naver-ai/vidt.  
# Paper List
---
## cs.CV
---
**171** new papers in cs.CV:-) 
1. $\Upsilon$-Net: A Spatiospectral Network for Retinal OCT Segmentation. (arXiv:2204.07613v1 [eess.IV])
2. Multi-Frame Self-Supervised Depth with Transformers. (arXiv:2204.07616v1 [cs.CV])
3. Lagrangian Motion Magnification with Double Sparse Optical Flow Decomposition. (arXiv:2204.07636v1 [cs.CV])
4. Event-aided Direct Sparse Odometry. (arXiv:2204.07640v1 [cs.CV])
5. MultiEarth 2022 -- Multimodal Learning for Earth and Environment Workshop and Challenge. (arXiv:2204.07649v1 [cs.CV])
6. Deep Unlearning via Randomized Conditionally Independent Hessians. (arXiv:2204.07655v1 [cs.CV])
7. It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection. (arXiv:2204.07660v1 [cs.CV])
8. Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations. (arXiv:2204.07673v1 [cs.LG])
9. Safe Self-Refinement for Transformer-based Domain Adaptation. (arXiv:2204.07683v1 [cs.CV])
10. Privacy-Preserving Image Classification Using Isotropic Network. (arXiv:2204.07707v1 [cs.CV])
11. GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing with Spatial Smoothness. (arXiv:2204.07713v1 [cs.CV])
12. Pushing the Performance Limit of Scene Text Recognizer without Human Annotation. (arXiv:2204.07714v1 [cs.CV])
13. Interactiveness Field in Human-Object Interactions. (arXiv:2204.07718v1 [cs.CV])
14. Stress-Testing LiDAR Registration. (arXiv:2204.07719v1 [cs.CV])
15. Searching Intrinsic Dimensions of Vision Transformers. (arXiv:2204.07722v1 [cs.CV])
16. Semantic interpretation for convolutional neural networks: What makes a cat a cat?. (arXiv:2204.07724v1 [cs.LG])
17. Bidirectional Self-Training with Multiple Anisotropic Prototypes for Domain Adaptive Semantic Segmentation. (arXiv:2204.07730v1 [cs.CV])
18. Efficient Linear Attention for Fast and Accurate Keypoint Matching. (arXiv:2204.07731v1 [cs.CV])
19. GitNet: Geometric Prior-based Transformation for Birds-Eye-View Segmentation. (arXiv:2204.07733v1 [cs.CV])
20. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v1 [cs.CV])
21. Language-Grounded Indoor 3D Semantic Segmentation in the Wild. (arXiv:2204.07761v1 [cs.CV])
22. Biometric verification of humans by means of hand geometry. (arXiv:2204.07764v1 [cs.CV])
23. Towards Lightweight Transformer via Group-wise Transformation for Vision-and-Language Tasks. (arXiv:2204.07780v1 [cs.CV])
24. UAMD-Net: A Unified Adaptive Multimodal Neural Network for Dense Depth Completion. (arXiv:2204.07791v1 [cs.CV])
25. FCL-GAN: A Lightweight and Real-Time Baseline for Unsupervised Blind Image Deblurring. (arXiv:2204.07820v1 [cs.CV])
26. Few-Shot Transfer Learning to improve Chest X-Ray pathology detection using limited triplets. (arXiv:2204.07824v1 [eess.IV])
27. A Robust and Scalable Attention Guided Deep Learning Framework for Movement Quality Assessment. (arXiv:2204.07840v1 [cs.CV])
28. Multimodal Few-Shot Object Detection with Meta-Learning Based Cross-Modal Prompting. (arXiv:2204.07841v1 [cs.CV])
29. Shape-guided Object Inpainting. (arXiv:2204.07845v1 [cs.CV])
30. Multi-organ Segmentation Network with Adversarial Performance Validator. (arXiv:2204.07850v1 [eess.IV])
31. Towards a Deeper Understanding of Skeleton-based Gait Recognition. (arXiv:2204.07855v1 [cs.CV])
32. GHM Wavelet Transform for Deep Image Super Resolution. (arXiv:2204.07862v1 [eess.IV])
33. 3D Human Pose Estimation for Free-from and Moving Activities Using WiFi. (arXiv:2204.07878v1 [cs.CV])
34. Mapping LiDAR and Camera Measurements in a Dual Top-View Grid Representation Tailored for Automated Vehicles. (arXiv:2204.07887v1 [cs.CV])
35. SymForce: Symbolic Computation and Code Generation for Robotics. (arXiv:2204.07889v1 [cs.RO])
36. Video Action Detection: Analysing Limitations and Challenges. (arXiv:2204.07892v1 [cs.CV])
37. MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral Reconstruction. (arXiv:2204.07908v1 [cs.CV])
38. What Goes beyond Multi-modal Fusion in One-stage Referring Expression Comprehension: An Empirical Study. (arXiv:2204.07913v1 [cs.CV])
39. Fast Multi-grid Methods for Minimizing Curvature Energy. (arXiv:2204.07921v1 [cs.CV])
40. Accelerated MRI With Deep Linear Convolutional Transform Learning. (arXiv:2204.07923v1 [eess.IV])
41. StyleT2F: Generating Human Faces from Textual Description Using StyleGAN2. (arXiv:2204.07924v1 [cs.CV])
42. In Defense of Subspace Tracker: Orthogonal Embedding for Visual Tracking. (arXiv:2204.07927v1 [cs.CV])
43. Causal Intervention for Subject-Deconfounded Facial Action Unit Recognition. (arXiv:2204.07935v1 [cs.CV])
44. Wound Severity Classification using Deep Neural Network. (arXiv:2204.07942v1 [eess.IV])
45. Global-Supervised Contrastive Loss and View-Aware-Based Post-Processing for Vehicle Re-Identification. (arXiv:2204.07943v1 [cs.CV])
46. DR-GAN: Distribution Regularization for Text-to-Image Generation. (arXiv:2204.07945v1 [cs.CV])
47. Integrated In-vehicle Monitoring System Using 3D Human Pose Estimation and Seat Belt Segmentation. (arXiv:2204.07946v1 [cs.CV])
48. Learning with Signatures. (arXiv:2204.07953v1 [cs.CV])
49. Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis. (arXiv:2204.07955v1 [cs.CV])
50. An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
51. AFSC: Adaptive Fourier Space Compression for Anomaly Detection. (arXiv:2204.07963v1 [eess.IV])
52. Target-Relevant Knowledge Preservation for Multi-Source Domain Adaptive Object Detection. (arXiv:2204.07964v1 [cs.CV])
53. Entropy-based Active Learning for Object Detection with Progressive Diversity Constraint. (arXiv:2204.07965v1 [cs.CV])
54. Augmentation Invariance and Adaptive Sampling in Semantic Segmentation of Agricultural Aerial Images. (arXiv:2204.07969v1 [cs.CV])
55. Automatic spinal curvature measurement on ultrasound spine images using Faster R-CNN. (arXiv:2204.07988v1 [eess.IV])
56. PiouCrypt: Decentralized Lattice-based Method for Visual Symmetric Cryptography. (arXiv:2204.08017v1 [cs.CR])
57. VDTR: Video Deblurring with Transformer. (arXiv:2204.08023v1 [cs.CV])
58. The Z-axis, X-axis, Weight and Disambiguation Methods for Constructing Local Reference Frame in 3D Registration: An Evaluation. (arXiv:2204.08024v1 [cs.CV])
59. Attention Mechanism based Cognition-level Scene Understanding. (arXiv:2204.08027v1 [cs.CV])
60. Deep Learning based Automatic Detection of Dicentric Chromosome. (arXiv:2204.08029v1 [cs.CV])
61. An Adaptive Task-Related Component Analysis Method for SSVEP recognition. (arXiv:2204.08030v1 [cs.CV])
62. NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v1 [cs.CV])
63. Continual Hippocampus Segmentation with Transformers. (arXiv:2204.08043v1 [eess.IV])
64. MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration. (arXiv:2204.08058v1 [cs.CV])
65. Learning 3D Semantics from Pose-Noisy 2D Images with Hierarchical Full Attention Network. (arXiv:2204.08084v1 [cs.CV])
66. Learning Compositional Representations for Effective Low-Shot Generalization. (arXiv:2204.08090v1 [cs.CV])
67. Dataset for Analyzing Various Gaze Zones and Distracted Behaviors of a Driver. (arXiv:2204.08096v1 [cs.CV])
68. Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction. (arXiv:2204.08107v1 [cs.AI])
69. End-to-end Dense Video Captioning as Sequence Generation. (arXiv:2204.08121v1 [cs.CV])
70. Parallel Network with Channel Attention and Post-Processing for Carotid Arteries Vulnerable Plaque Segmentation in Ultrasound Images. (arXiv:2204.08127v1 [eess.IV])
71. Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding. (arXiv:2204.08129v1 [cs.CV])
72. End-to-end Weakly-supervised Multiple 3D Hand Mesh Reconstruction from Single Image. (arXiv:2204.08154v1 [cs.CV])
73. TOD-CNN: An Effective Convolutional Neural Network for Tiny Object Detection in Sperm Videos. (arXiv:2204.08166v1 [cs.CV])
74. Real-world Deep Local Motion Deblurring. (arXiv:2204.08179v1 [cs.CV])
75. Modality-Balanced Embedding for Video Retrieval. (arXiv:2204.08182v1 [cs.CV])
76. Sardino: Ultra-Fast Dynamic Ensemble for Secure Visual Sensing at Mobile Edge. (arXiv:2204.08189v1 [cs.CV])
77. Semi-Supervised Super-Resolution. (arXiv:2204.08192v1 [eess.IV])
78. Self-Supervised Arbitrary-Scale Point Clouds Upsampling via Implicit Neural Representation. (arXiv:2204.08196v1 [cs.CV])
79. OMG: Observe Multiple Granularities for Natural Language-Based Vehicle Retrieval. (arXiv:2204.08209v1 [cs.CV])
80. Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey. (arXiv:2204.08226v1 [cs.LG])
81. The Devil is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-Training. (arXiv:2204.08227v1 [cs.CV])
82. Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v1 [cs.CV])
83. Visio-Linguistic Brain Encoding. (arXiv:2204.08261v1 [cs.CV])
84. Unsupervised domain adaptation and super resolution on drone images for autonomous dry herbage biomass estimation. (arXiv:2204.08271v1 [cs.CV])
85. Heavy Rain Face Image **Restoration**: Integrating Physical Degradation Model and Facial Component Guided Adversarial Learning. (arXiv:2204.08307v1 [cs.CV])
86. Saliency in Augmented Reality. (arXiv:2204.08308v1 [cs.CV])
87. Tracking monocular camera pose and deformation for SLAM inside the human body. (arXiv:2204.08309v1 [cs.CV])
88. Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology. (arXiv:2204.08311v1 [cs.CV])
89. A high-resolution canopy height model of the Earth. (arXiv:2204.08322v1 [cs.CV])
90. Hierarchical Optimal Transport for Comparing Histopathology Datasets. (arXiv:2204.08324v1 [cs.CV])
91. A Comprehensive Survey on Data-Efficient GANs in Image Generation. (arXiv:2204.08329v1 [cs.CV])
92. BSRT: Improving Burst Super-Resolution with **Swin** Transformer and Flow-Guided Deformable Alignment. (arXiv:2204.08332v1 [cs.CV])
93. Migrating Face Swap to Mobile Devices: A lightweight Framework and A Supervised Training Solution. (arXiv:2204.08339v1 [cs.CV])
94. MHSCNet: A Multimodal Hierarchical Shot-aware Convolutional Network for Video Summarization. (arXiv:2204.08352v1 [cs.CV])
95. Detecting, Tracking and Counting Motorcycle Rider Traffic Violations on Unconstrained Roads. (arXiv:2204.08364v1 [cs.CV])
96. Detecting Deepfakes with Self-Blended Images. (arXiv:2204.08376v1 [cs.CV])
97. Multiple-environment Self-adaptive Network for Aerial-view Geo-localization. (arXiv:2204.08381v1 [cs.CV])
98. Subspace Nonnegative Matrix Factorization for Feature Representation. (arXiv:2204.08382v1 [cs.CV])
99. MHSA-Net: Multi-Head Self-Attention Network for Occluded Person Re-Identification. (arXiv:2008.04015v4 [cs.CV] UPDATED)
100. Can You Spot the Chameleon? Adversarially Camouflaging Images from Co-Salient Object Detection. (arXiv:2009.09258v5 [cs.CV] UPDATED)
101. Towards Robust Neural Networks via Orthogonal Diversity. (arXiv:2010.12190v3 [cs.CV] UPDATED)
102. Stretchable Cells Help DARTS Search Better. (arXiv:2011.09300v2 [cs.CV] UPDATED)
103. Semantic Layout Manipulation with High-Resolution Sparse Attention. (arXiv:2012.07288v4 [cs.CV] UPDATED)
104. Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss. (arXiv:2101.11952v4 [cs.CV] UPDATED)
105. A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for **Real-time** Surgical Video Analysis. (arXiv:2103.16847v3 [eess.IV] UPDATED)
106. HIH: Towards More Accurate Face Alignment via Heatmap in Heatmap. (arXiv:2104.03100v2 [cs.CV] UPDATED)
107. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v3 [cs.RO] UPDATED)
108. Salient Objects in Clutter. (arXiv:2105.03053v2 [cs.CV] UPDATED)
109. GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for Low-dose CT Denoising. (arXiv:2105.07146v2 [eess.IV] UPDATED)
110. Semantic segmentation of multispectral photoacoustic images using deep learning. (arXiv:2105.09624v3 [eess.IV] UPDATED)
111. 3D U-NetR: Low Dose Computed Tomography Reconstruction via Deep Learning and 3 Dimensional Convolutions. (arXiv:2105.14130v2 [cs.CV] UPDATED)
112. Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v5 [cs.CV] UPDATED)
113. Two-Stream Consensus Network: Submission to HACS Challenge 2021 Weakly-Supervised Learning Track. (arXiv:2106.10829v3 [cs.CV] UPDATED)
114. "Zero-Shot" Point Cloud Upsampling. (arXiv:2106.13765v2 [cs.CV] UPDATED)
115. One-Cycle Pruning: Pruning ConvNets Under a Tight Training Budget. (arXiv:2107.02086v2 [cs.CV] UPDATED)
116. Integrating Large Circular Kernels into CNNs through Neural Architecture Search. (arXiv:2107.02451v4 [cs.CV] UPDATED)
117. Multiple Classifiers Based Maximum Classifier Discrepancy for Unsupervised Domain Adaptation. (arXiv:2108.00610v2 [cs.CV] UPDATED)
118. Research on Gender-related Fingerprint Features. (arXiv:2108.08233v2 [cs.CV] UPDATED)
119. Learning Disentangled Representations in the Imaging Domain. (arXiv:2108.12043v5 [cs.CV] UPDATED)
120. RVMDE: Radar Validated Monocular Depth Estimation for Robotics. (arXiv:2109.05265v3 [cs.RO] UPDATED)
121. Towards Non-Line-of-Sight Photography. (arXiv:2109.07783v2 [eess.IV] UPDATED)
122. Deep Instance Segmentation with Automotive Radar Detection Points. (arXiv:2110.01775v6 [cs.CV] UPDATED)
123. SimMIM: A Simple Framework for Masked Image Modeling. (arXiv:2111.09886v2 [cs.CV] UPDATED)
124. DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion. (arXiv:2111.10332v3 [cs.CV] UPDATED)
125. GreedyNASv2: Greedier Search with a Greedy Path Filter. (arXiv:2111.12609v2 [cs.CV] UPDATED)
126. VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling. (arXiv:2111.12681v2 [cs.CV] UPDATED)
127. Towards Low-Cost and Efficient Malaria Detection. (arXiv:2111.13656v3 [cs.CV] UPDATED)
128. ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification. (arXiv:2111.14271v6 [cs.CV] UPDATED)
129. AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions. (arXiv:2112.00246v3 [cs.CV] UPDATED)
130. Improving GAN Equilibrium by Raising Spatial Awareness. (arXiv:2112.00718v2 [cs.CV] UPDATED)
131. BA-Net: Bridge Attention for Deep Convolutional Neural Networks. (arXiv:2112.04150v2 [cs.CV] UPDATED)
132. A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms. (arXiv:2112.04490v2 [eess.IV] UPDATED)
133. Improving Vision Transformers for Incremental Learning. (arXiv:2112.06103v3 [cs.CV] UPDATED)
134. Magnifying Networks for Images with Billions of Pixels. (arXiv:2112.06121v2 [cs.CV] UPDATED)
135. SVIP: Sequence VerIfication for Procedures in Videos. (arXiv:2112.06447v3 [cs.CV] UPDATED)
136. Value Retrieval with Arbitrary Queries for Form-like Documents. (arXiv:2112.07820v2 [cs.CV] UPDATED)
137. SPTS: Single-Point Text Spotting. (arXiv:2112.07917v2 [cs.CV] UPDATED)
138. Cross-Model Pseudo-Labeling for Semi-Supervised Action Recognition. (arXiv:2112.09690v2 [cs.CV] UPDATED)
139. Distill and De-bias: Mitigating Bias in Face Verification using Knowledge Distillation. (arXiv:2112.09786v3 [cs.CV] UPDATED)
140. 3D-aware Image Synthesis via Learning Structural and Textural Representations. (arXiv:2112.10759v2 [cs.CV] UPDATED)
141. Shape from Polarization for Complex Scenes in the Wild. (arXiv:2112.11377v2 [cs.CV] UPDATED)
142. BDG-Net: Boundary Distribution Guided Network for Accurate Polyp Segmentation. (arXiv:2201.00767v2 [eess.IV] UPDATED)
143. A Comprehensive Empirical Study of Vision-Language Pre-trained Model for Supervised Cross-Modal Retrieval. (arXiv:2201.02772v2 [cs.CV] UPDATED)
144. Explore and Match: A New Paradigm for Temporal Video Grounding with Natural Language. (arXiv:2201.10168v2 [cs.CV] UPDATED)
145. CrossRectify: Leveraging Disagreement for Semi-supervised Object Detection. (arXiv:2201.10734v2 [cs.CV] UPDATED)
146. An Overview of Compressible and Learnable Image Transformation with Secret Key and Its Applications. (arXiv:2201.11006v2 [cs.CV] UPDATED)
147. Natural Language Descriptions of Deep Visual Features. (arXiv:2201.11114v2 [cs.CV] UPDATED)
148. Deep Feature based Cross-slide Registration. (arXiv:2202.09971v4 [cs.CV] UPDATED)
149. Active Learning for Point Cloud Semantic Segmentation via Spatial-Structural Diversity Reasoning. (arXiv:2202.12588v2 [cs.CV] UPDATED)
150. AGMR-Net: Attention Guided Multiscale Recovery framework for stroke segmentation. (arXiv:2202.13687v2 [cs.CV] UPDATED)
151. Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers. (arXiv:2203.00156v2 [cs.RO] UPDATED)
152. Simultaneous Semantic and Instance Segmentation for Colon Nuclei Identification and Counting. (arXiv:2203.00157v2 [cs.CV] UPDATED)
153. Deep Learning based Prediction of MSI using MMR Markers in Colorectal Cancer. (arXiv:2203.00449v2 [q-bio.QM] UPDATED)
154. Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification. (arXiv:2203.04961v2 [eess.IV] UPDATED)
155. PseudoProp: Robust Pseudo-Label Generation for Semi-Supervised Object Detection in Autonomous Driving Systems. (arXiv:2203.05983v2 [cs.CV] UPDATED)
156. Computer Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey. (arXiv:2203.06951v3 [cs.CV] UPDATED)
157. Deep Unsupervised Hashing with Latent Semantic Components. (arXiv:2203.09420v2 [cs.CV] UPDATED)
158. CM-GAN: Image Inpainting with Cascaded Modulation GAN and Object-Aware Training. (arXiv:2203.11947v2 [cs.CV] UPDATED)
159. Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer Tissue Biopsy Samples. (arXiv:2203.12112v2 [eess.IV] UPDATED)
160. Transformer-based Multimodal Information Fusion for Facial Expression Analysis. (arXiv:2203.12367v2 [cs.CV] UPDATED)
161. EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation. (arXiv:2203.13254v3 [cs.CV] UPDATED)
162. FocalClick: Towards Practical Interactive Image Segmentation. (arXiv:2204.02574v2 [cs.CV] UPDATED)
163. ShowFace: Coordinated Face Inpainting with Memory-Disentangled Refinement Networks. (arXiv:2204.02824v2 [cs.CV] UPDATED)
164. Low-Dose CT Denoising via Sinogram Inner-Structure Transformer. (arXiv:2204.03163v2 [eess.IV] UPDATED)
165. Event Transformer. A sparse-aware solution for efficient event data processing. (arXiv:2204.03355v2 [cs.CV] UPDATED)
166. Learning Trajectory-Aware Transformer for Video Super-Resolution. (arXiv:2204.04216v2 [eess.IV] UPDATED)
167. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v2 [cs.CV] UPDATED)
168. Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v3 [eess.IV] UPDATED)
169. medXGAN: Visual Explanations for Medical Classifiers through a Generative Latent Space. (arXiv:2204.05376v2 [cs.CV] UPDATED)
170. SpoofGAN: Synthetic Fingerprint Spoof Images. (arXiv:2204.06498v2 [cs.CV] UPDATED)
171. INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v2 [cs.CV] UPDATED)
## eess.IV
---
**37** new papers in eess.IV:-) 
1. $\Upsilon$-Net: A Spatiospectral Network for Retinal OCT Segmentation. (arXiv:2204.07613v1 [eess.IV])
2. Privacy-Preserving Image Classification Using Isotropic Network. (arXiv:2204.07707v1 [cs.CV])
3. Disturbance-free single-pixel imaging camera based on P=0.5 Bernoulli modulation and complementary detection. (arXiv:2204.07711v1 [physics.optics])
4. GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing with Spatial Smoothness. (arXiv:2204.07713v1 [cs.CV])
5. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v1 [cs.CV])
6. Wireless Semantic Communications for Video Conferencing. (arXiv:2204.07790v1 [eess.IV])
7. Few-Shot Transfer Learning to improve Chest X-Ray pathology detection using limited triplets. (arXiv:2204.07824v1 [eess.IV])
8. Multi-organ Segmentation Network with Adversarial Performance Validator. (arXiv:2204.07850v1 [eess.IV])
9. GHM Wavelet Transform for Deep Image Super Resolution. (arXiv:2204.07862v1 [eess.IV])
10. Fast Multi-grid Methods for Minimizing Curvature Energy. (arXiv:2204.07921v1 [cs.CV])
11. Accelerated MRI With Deep Linear Convolutional Transform Learning. (arXiv:2204.07923v1 [eess.IV])
12. Wound Severity Classification using Deep Neural Network. (arXiv:2204.07942v1 [eess.IV])
13. AFSC: Adaptive Fourier Space Compression for Anomaly Detection. (arXiv:2204.07963v1 [eess.IV])
14. Automatic spinal curvature measurement on ultrasound spine images using Faster R-CNN. (arXiv:2204.07988v1 [eess.IV])
15. One-step Method for Material Quantitation using In-line Tomography with Single Scanning. (arXiv:2204.08013v1 [physics.med-ph])
16. Continual Hippocampus Segmentation with Transformers. (arXiv:2204.08043v1 [eess.IV])
17. Parallel Network with Channel Attention and Post-Processing for Carotid Arteries Vulnerable Plaque Segmentation in Ultrasound Images. (arXiv:2204.08127v1 [eess.IV])
18. Semi-Supervised Super-Resolution. (arXiv:2204.08192v1 [eess.IV])
19. A high-resolution canopy height model of the Earth. (arXiv:2204.08322v1 [cs.CV])
20. Fast and Memory-Efficient Network Towards Efficient Image Super-Resolution. (arXiv:2204.08397v1 [eess.IV])
21. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v1 [cs.CV])
22. A Novel Deep ML Architecture by Integrating Visual Simultaneous Localization and Mapping (vSLAM) into Mask R-CNN for **Real-time** Surgical Video Analysis. (arXiv:2103.16847v3 [eess.IV] UPDATED)
23. GCN-MIF: Graph Convolutional Network with Multi-Information Fusion for Low-dose CT Denoising. (arXiv:2105.07146v2 [eess.IV] UPDATED)
24. Semantic segmentation of multispectral photoacoustic images using deep learning. (arXiv:2105.09624v3 [eess.IV] UPDATED)
25. 3D U-NetR: Low Dose Computed Tomography Reconstruction via Deep Learning and 3 Dimensional Convolutions. (arXiv:2105.14130v2 [cs.CV] UPDATED)
26. Iterative Self-consistent Parallel Magnetic Resonance Imaging Reconstruction based on Nonlocal Low-Rank Regularization. (arXiv:2108.04517v2 [eess.IV] UPDATED)
27. Towards Non-Line-of-Sight Photography. (arXiv:2109.07783v2 [eess.IV] UPDATED)
28. A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms. (arXiv:2112.04490v2 [eess.IV] UPDATED)
29. BDG-Net: Boundary Distribution Guided Network for Accurate Polyp Segmentation. (arXiv:2201.00767v2 [eess.IV] UPDATED)
30. Deep Feature based Cross-slide Registration. (arXiv:2202.09971v4 [cs.CV] UPDATED)
31. Deep Learning based Prediction of MSI using MMR Markers in Colorectal Cancer. (arXiv:2203.00449v2 [q-bio.QM] UPDATED)
32. Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification. (arXiv:2203.04961v2 [eess.IV] UPDATED)
33. Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer Tissue Biopsy Samples. (arXiv:2203.12112v2 [eess.IV] UPDATED)
34. Imaging Conductivity from Current Density Magnitude using Neural Networks. (arXiv:2204.02441v2 [math.NA] UPDATED)
35. Low-Dose CT Denoising via Sinogram Inner-Structure Transformer. (arXiv:2204.03163v2 [eess.IV] UPDATED)
36. Learning Trajectory-Aware Transformer for Video Super-Resolution. (arXiv:2204.04216v2 [eess.IV] UPDATED)
37. Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v3 [eess.IV] UPDATED)
## cs.LG
---
**181** new papers in cs.LG:-) 
1. Interpretable Fault Diagnosis of Rolling Element Bearings with Temporal Logic Neural Network. (arXiv:2204.07579v1 [cs.LG])
2. Perfectly Balanced: Improving Transfer and Robustness of Supervised Contrastive Learning. (arXiv:2204.07596v1 [stat.ML])
3. Sources of Irreproducibility in Machine Learning: A Review. (arXiv:2204.07610v1 [cs.LG])
4. $\Upsilon$-Net: A Spatiospectral Network for Retinal OCT Segmentation. (arXiv:2204.07613v1 [eess.IV])
5. DeepCSI: Rethinking Wi-Fi Radio Fingerprinting Through MU-MIMO CSI Feedback Deep Learning. (arXiv:2204.07614v1 [cs.NI])
6. Resource-Constrained Neural Architecture Search on Tabular Datasets. (arXiv:2204.07615v1 [cs.LG])
7. Evaluating the Effectiveness of Corrective Demonstrations and a Low-Cost Sensor for Dexterous Manipulation. (arXiv:2204.07631v1 [cs.RO])
8. A generative neural network model for random dot product graphs. (arXiv:2204.07634v1 [stat.ML])
9. Learning time-dependent PDE solver using Message Passing Graph Neural Networks. (arXiv:2204.07651v1 [cs.LG])
10. Deep Unlearning via Randomized Conditionally Independent Hessians. (arXiv:2204.07655v1 [cs.CV])
11. Accurate detection of sepsis at ED triage using machine learning with clinical natural language processing. (arXiv:2204.07657v1 [cs.LG])
12. It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection. (arXiv:2204.07660v1 [cs.CV])
13. Conditional Injective Flows for Bayesian Imaging. (arXiv:2204.07664v1 [cs.LG])
14. Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations. (arXiv:2204.07673v1 [cs.LG])
15. Safe Self-Refinement for Transformer-based Domain Adaptation. (arXiv:2204.07683v1 [cs.CV])
16. Sparsely Activated Mixture-of-Experts are Robust Multi-Task Learners. (arXiv:2204.07689v1 [cs.LG])
17. Theory of Graph Neural Networks: Representation and Learning. (arXiv:2204.07697v1 [cs.LG])
18. On Acceleration of Gradient-Based Empirical Risk Minimization using Local Polynomial Regression. (arXiv:2204.07702v1 [math.OC])
19. FKreg: A MATLAB toolbox for fast Multivariate Kernel Regression. (arXiv:2204.07716v1 [stat.ME])
20. Stress-Testing LiDAR Registration. (arXiv:2204.07719v1 [cs.CV])
21. Searching Intrinsic Dimensions of Vision Transformers. (arXiv:2204.07722v1 [cs.CV])
22. Semantic interpretation for convolutional neural networks: What makes a cat a cat?. (arXiv:2204.07724v1 [cs.LG])
23. A Hierarchical Terminal Recognition Approach based on Network Traffic Analysis. (arXiv:2204.07726v1 [cs.NI])
24. The Tree Loss: Improving Generalization with Many Classes. (arXiv:2204.07727v1 [cs.LG])
25. Efficient Bayesian Policy Reuse with a Scalable Observation Model in Deep Reinforcement Learning. (arXiv:2204.07729v1 [cs.LG])
26. Persua: A Visual Interactive System to Enhance the Persuasiveness of Arguments in Online Discussion. (arXiv:2204.07741v1 [cs.HC])
27. DRFLM: Distributionally Robust Federated Learning with Inter-client Noise via Local Mixup. (arXiv:2204.07742v1 [cs.LG])
28. Tensor-networks for High-order Polynomial Approximation: A Many-body Physics Perspective. (arXiv:2204.07743v1 [quant-ph])
29. A Variational Approach to Bayesian Phylogenetic Inference. (arXiv:2204.07747v1 [stat.ML])
30. Homomorphic Encryption and Federated Learning based Privacy-Preserving CNN Training: COVID-19 Detection Use-Case. (arXiv:2204.07752v1 [cs.CR])
31. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v1 [cs.CV])
32. Cannikin's Law in Tensor Modeling: A Rank Study for Entanglement and Separability in Tensor Complexity and Model Capacity. (arXiv:2204.07760v1 [quant-ph])
33. UFRC: A Unified Framework for Reliable COVID-19 Detection on Crowdsourced Cough Audio. (arXiv:2204.07763v1 [cs.SD])
34. A Distributed and Elastic Aggregation Service for Scalable Federated Learning Systems. (arXiv:2204.07767v1 [cs.LG])
35. SETTI: A Self-supervised Adversarial Malware Detection Architecture in an IoT Environment. (arXiv:2204.07772v1 [cs.CR])
36. FedCau: A Proactive Stop Policy for Communication and Computation Efficient Federated Learning. (arXiv:2204.07773v1 [cs.LG])
37. TASTEset -- Recipe Dataset and Food Entities Recognition Benchmark. (arXiv:2204.07775v1 [cs.CL])
38. Exploiting Multiple EEG Data Domains with Adversarial Learning. (arXiv:2204.07777v1 [eess.SP])
39. Approaching sales forecasting using recurrent neural networks and transformers. (arXiv:2204.07786v1 [cs.LG])
40. Graph-incorporated Latent Factor Analysis for High-dimensional and Sparse Matrices. (arXiv:2204.07818v1 [cs.LG])
41. A Multi-Metric Latent Factor Model for Analyzing High-Dimensional and Sparse data. (arXiv:2204.07819v1 [cs.LG])
42. Beyond L1: Faster and Better Sparse Models with skglm. (arXiv:2204.07826v1 [stat.ML])
43. Optimizing differential equations to fit data and predict outcomes. (arXiv:2204.07833v1 [q-bio.QM])
44. What If: Generating Code to Answer Simulation Questions. (arXiv:2204.07835v1 [cs.CL])
45. nigam@COLIEE-22: Legal Case Retrieval and Entailment using Cascading of Lexical and Semantic-based models. (arXiv:2204.07853v1 [cs.CL])
46. IIFNet: A Fusion based Intelligent Service for Noisy Preamble Detection in 6G. (arXiv:2204.07854v1 [cs.NI])
47. Alternating Channel Estimation and Prediction for Cell-Free mMIMO with Channel Aging: A Deep Learning Based Scheme. (arXiv:2204.07868v1 [cs.IT])
48. Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a Pedestrian Automatic Emergency Brake System. (arXiv:2204.07874v1 [cs.SE])
49. Assessing Differentially Private Variational Autoencoders under Membership Inference. (arXiv:2204.07877v1 [cs.CR])
50. Polynomial-time sparse measure recovery. (arXiv:2204.07879v1 [cs.LG])
51. Accelerated MRI With Deep Linear Convolutional Transform Learning. (arXiv:2204.07923v1 [eess.IV])
52. StyleT2F: Generating Human Faces from Textual Description Using StyleGAN2. (arXiv:2204.07924v1 [cs.CV])
53. Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning. (arXiv:2204.07932v1 [cs.MA])
54. Unsupervised Cross-Task Generalization via Retrieval Augmentation. (arXiv:2204.07937v1 [cs.CL])
55. Wound Severity Classification using Deep Neural Network. (arXiv:2204.07942v1 [eess.IV])
56. An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
57. Fair Classification under Covariate Shift and Missing Protected Attribute -- an Investigation using Related Features. (arXiv:2204.07987v1 [cs.LG])
58. LRH-Net: A Multi-Level Knowledge Distillation Approach for Low-Resource Heart Network. (arXiv:2204.08000v1 [physics.med-ph])
59. Limit theorems of Chatterjee's rank correlation. (arXiv:2204.08031v1 [math.ST])
60. Federated Learning Cost Disparity for IoT Devices. (arXiv:2204.08036v1 [cs.LG])
61. NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v1 [cs.CV])
62. Self-Aware Personalized Federated Learning. (arXiv:2204.08069v1 [cs.LG])
63. A Novel ASIC Design Flow using Weight-Tunable Binary Neurons as Standard Cells. (arXiv:2204.08070v1 [cs.ET])
64. Learning Compositional Representations for Effective Low-Shot Generalization. (arXiv:2204.08090v1 [cs.CV])
65. A Data-Driven Methodology for Considering Feasibility and Pairwise Likelihood in Deep Learning Based Guitar Tablature Transcription Systems. (arXiv:2204.08094v1 [eess.AS])
66. Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction. (arXiv:2204.08107v1 [cs.AI])
67. Non-Parallel Text Style Transfer with Self-Parallel Supervision. (arXiv:2204.08123v1 [cs.CL])
68. FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning by Penalizing KL Divergence. (arXiv:2204.08125v1 [cs.LG])
69. A Practical Cross-Device Federated Learning Framework over 5G Networks. (arXiv:2204.08134v1 [cs.LG])
70. Trinary Tools for Continuously Valued Binary Classifiers. (arXiv:2204.08136v1 [cs.LG])
71. Characterizing and Understanding Distributed GNN Training on GPUs. (arXiv:2204.08150v1 [cs.DC])
72. A dynamical systems based framework for dimension reduction. (arXiv:2204.08155v1 [stat.ML])
73. Multi-scale Anomaly Detection for Big Time Series of Industrial Sensors. (arXiv:2204.08159v1 [cs.LG])
74. On Arbitrary Compression for Decentralized Consensus and Stochastic Optimization over Directed Networks. (arXiv:2204.08160v1 [math.OC])
75. TOD-CNN: An Effective Convolutional Neural Network for Tiny Object Detection in Sperm Videos. (arXiv:2204.08166v1 [cs.CV])
76. TABi: Type-Aware Bi-Encoders for Open-Domain Entity Retrieval. (arXiv:2204.08173v1 [cs.CL])
77. Usage of specific attention improves change point detection. (arXiv:2204.08175v1 [cs.LG])
78. Understanding Gradual Domain Adaptation: Improved Analysis, Optimal Path and Beyond. (arXiv:2204.08200v1 [cs.LG])
79. A Greedy and Optimistic Approach to Clustering with a Specified Uncertainty of Covariates. (arXiv:2204.08205v1 [stat.ME])
80. TigerLily: Finding drug interactions in silico with the Graph. (arXiv:2204.08206v1 [cs.LG])
81. How to Attain Communication-Efficient DNN Training? Convert, Compress, Correct. (arXiv:2204.08211v1 [cs.LG])
82. Empirical Evaluation and Theoretical Analysis for Representation Learning: A Survey. (arXiv:2204.08226v1 [cs.LG])
83. Fast optimization of common basis for matrix set through Common Singular Value Decomposition. (arXiv:2204.08242v1 [cs.LG])
84. Joint Multi-view Unsupervised Feature Selection and Graph Learning. (arXiv:2204.08247v1 [cs.CV])
85. Visio-Linguistic Brain Encoding. (arXiv:2204.08261v1 [cs.CV])
86. Differentiable Time-Frequency Scattering in Kymatio. (arXiv:2204.08269v1 [cs.SD])
87. Iterative Hard Thresholding with Adaptive Regularization: Sparser Solutions Without Sacrificing Runtime. (arXiv:2204.08274v1 [math.OC])
88. Decision-Dependent Risk Minimization in Geometrically Decaying Dynamic Environments. (arXiv:2204.08281v1 [math.OC])
89. A Convergence Analysis of Nesterov's Accelerated Gradient Method in Training Deep Linear Neural Networks. (arXiv:2204.08306v1 [cs.LG])
90. Application of Transfer Learning and Ensemble Learning in Image-level Classification for Breast Histopathology. (arXiv:2204.08311v1 [cs.CV])
91. An alternative approach for distributed parameter estimation under Gaussian settings. (arXiv:2204.08317v1 [eess.SY])
92. Backward Reachability Analysis for Neural Feedback Loops. (arXiv:2204.08319v1 [eess.SY])
93. A high-resolution canopy height model of the Earth. (arXiv:2204.08322v1 [cs.CV])
94. Time Series Clustering for Grouping Products Based on Price and Sales Patterns. (arXiv:2204.08334v1 [cs.LG])
95. Active Learning with Weak Labels for Gaussian Processes. (arXiv:2204.08335v1 [stat.ML])
96. Extracting Targeted Training Data from ASR Models, and How to Mitigate It. (arXiv:2204.08345v1 [cs.SD])
97. AutoMLBench: A Comprehensive Experimental Evaluation of Automated Machine Learning Frameworks. (arXiv:2204.08358v1 [cs.LG])
98. Strengthening Subcommunities: Towards Sustainable Growth in AI Research. (arXiv:2204.08377v1 [cs.AI])
99. Subspace Nonnegative Matrix Factorization for Feature Representation. (arXiv:2204.08382v1 [cs.CV])
100. Stochastic Gradient Descent on Separable Data: Exact Convergence with a Fixed Learning Rate. (arXiv:1806.01796v3 [stat.ML] UPDATED)
101. BPMR: Bayesian Probabilistic Multivariate Ranking. (arXiv:1909.08737v2 [cs.IR] UPDATED)
102. Spatial-Temporal Dynamic Graph Attention Networks for Ride-hailing Demand Prediction. (arXiv:2006.05905v4 [cs.LG] UPDATED)
103. Transfer Learning for Electricity Price Forecasting. (arXiv:2007.03762v3 [eess.SP] UPDATED)
104. Anomaly Awareness. (arXiv:2007.14462v2 [cs.LG] UPDATED)
105. Towards Robust Neural Networks via Orthogonal Diversity. (arXiv:2010.12190v3 [cs.CV] UPDATED)
106. Multi-Agent Online Optimization with Delays: Asynchronicity, Adaptivity, and Optimism. (arXiv:2012.11579v2 [cs.LG] UPDATED)
107. Deep Interactive Bayesian Reinforcement Learning via Meta-Learning. (arXiv:2101.03864v2 [cs.LG] UPDATED)
108. Exponential Savings in Agnostic Active Learning through Abstention. (arXiv:2102.00451v3 [cs.LG] UPDATED)
109. Pre-Training on Dynamic Graph Neural Networks. (arXiv:2102.12380v2 [cs.LG] UPDATED)
110. Occupation Kernel Hilbert Spaces for Fractional Order Liouville Operators and Dynamic Mode Decomposition. (arXiv:2102.13266v2 [math.FA] UPDATED)
111. TSception: Capturing Temporal Dynamics and Spatial Asymmetry from EEG for Emotion Recognition. (arXiv:2104.02935v3 [cs.LG] UPDATED)
112. From Fully Trained to Fully Random Embeddings: Improving Neural Machine Translation with Compact Word Embedding Tables. (arXiv:2104.08677v2 [cs.CL] UPDATED)
113. Transductive Learning for Abstractive News Summarization. (arXiv:2104.09500v2 [cs.CL] UPDATED)
114. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v3 [cs.RO] UPDATED)
115. Heterogeneous Graph Representation Learning with Relation Awareness. (arXiv:2105.11122v2 [cs.LG] UPDATED)
116. An error analysis of generative adversarial networks for learning distributions. (arXiv:2105.13010v5 [cs.LG] UPDATED)
117. Transfer Learning under High-dimensional Generalized Linear Models. (arXiv:2105.14328v4 [stat.ML] UPDATED)
118. Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v5 [cs.CV] UPDATED)
119. Learning Adversarially Robust Policies in Multi-Agent Games. (arXiv:2106.05492v2 [cs.LG] UPDATED)
120. On the Convergence of Differentially Private Federated Learning on Non-Lipschitz Objectives, and with Normalized Client Updates. (arXiv:2106.07094v3 [cs.LG] UPDATED)
121. Quantized Federated Learning under Transmission Delay and Outage Constraints. (arXiv:2106.09397v3 [cs.IT] UPDATED)
122. Leveraging Language to Learn Program Abstractions and Search Heuristics. (arXiv:2106.11053v2 [cs.LG] UPDATED)
123. Provable Convergence of Nesterov's Accelerated Gradient Method for Over-Parameterized Neural Networks. (arXiv:2107.01832v3 [cs.LG] UPDATED)
124. The Role of Pretrained Representations for the OOD Generalization of Reinforcement Learning Agents. (arXiv:2107.05686v4 [cs.LG] UPDATED)
125. FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks. (arXiv:2107.06419v5 [cs.LG] UPDATED)
126. Self-learning Emulators and Eigenvector Continuation. (arXiv:2107.13449v2 [nucl-th] UPDATED)
127. A diffusion-map-based algorithm for gradient computation on manifolds and applications. (arXiv:2108.06988v2 [cs.LG] UPDATED)
128. IsoScore: Measuring the Uniformity of Embedding Space Utilization. (arXiv:2108.07344v2 [cs.CL] UPDATED)
129. A Unifying Theory of Thompson Sampling for Continuous Risk-Averse Bandits. (arXiv:2108.11345v4 [cs.LG] UPDATED)
130. Learning Disentangled Representations in the Imaging Domain. (arXiv:2108.12043v5 [cs.CV] UPDATED)
131. RVMDE: Radar Validated Monocular Depth Estimation for Robotics. (arXiv:2109.05265v3 [cs.RO] UPDATED)
132. Robust Stability of Neural-Network Controlled Nonlinear Systems with Parametric Variability. (arXiv:2109.05710v3 [cs.LG] UPDATED)
133. Multilingual Molecular Representation Learning via Contrastive Pre-training. (arXiv:2109.08830v3 [cs.LG] UPDATED)
134. MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning. (arXiv:2109.12674v2 [cs.LG] UPDATED)
135. FairFed: Enabling Group Fairness in Federated Learning. (arXiv:2110.00857v2 [cs.LG] UPDATED)
136. Finding Materialized Models for Model Reuse. (arXiv:2110.06532v4 [cs.LG] UPDATED)
137. Graph Condensation for Graph Neural Networks. (arXiv:2110.07580v3 [cs.LG] UPDATED)
138. An Artificial Neural Network-Based Model Predictive Control for Three-phase Flying Capacitor Multi-Level Inverter. (arXiv:2110.08101v2 [eess.SY] UPDATED)
139. Safe rules for the identification of zeros in the solutions of the SLOPE problem. (arXiv:2110.11784v2 [cs.LG] UPDATED)
140. Improving Spectral Clustering Using Spectrum-Preserving Node Reduction. (arXiv:2110.12328v3 [cs.LG] UPDATED)
141. Learning to run a power network with trust. (arXiv:2110.12908v2 [cs.AI] UPDATED)
142. Hierarchical Transformers Are More Efficient Language Models. (arXiv:2110.13711v2 [cs.LG] UPDATED)
143. Scalable Unidirectional Pareto Optimality for Multi-Task Learning with Constraints. (arXiv:2110.15442v2 [cs.LG] UPDATED)
144. Does Momentum Help? A Sample Complexity Analysis. (arXiv:2110.15547v2 [cs.LG] UPDATED)
145. On the Complexity of Dynamic Submodular Maximization. (arXiv:2111.03198v2 [cs.DS] UPDATED)
146. DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion. (arXiv:2111.10332v3 [cs.CV] UPDATED)
147. ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification. (arXiv:2111.14271v6 [cs.CV] UPDATED)
148. Structure-Preserving Learning Using Gaussian Processes and Variational Integrators. (arXiv:2112.05451v2 [cs.LG] UPDATED)
149. Magnifying Networks for Images with Billions of Pixels. (arXiv:2112.06121v2 [cs.CV] UPDATED)
150. Risk and optimal policies in bandit experiments. (arXiv:2112.06363v3 [econ.EM] UPDATED)
151. Guaranteed Nonlinear Tracking in the Presence of DNN-Learned Dynamics With Contraction Metrics and Disturbance Estimation. (arXiv:2112.08222v2 [eess.SY] UPDATED)
152. Relationship extraction for knowledge graph creation from biomedical literature. (arXiv:2201.01647v3 [cs.AI] UPDATED)
153. Non-Stationary Representation Learning in Sequential Linear Bandits. (arXiv:2201.04805v2 [cs.LG] UPDATED)
154. Graph Neural Network-based Android Malware Classification with Jumping Knowledge. (arXiv:2201.07537v7 [cs.CR] UPDATED)
155. Natural Language Descriptions of Deep Visual Features. (arXiv:2201.11114v2 [cs.CV] UPDATED)
156. Optimal Estimation of Off-Policy Policy Gradient via Double Fitted Iteration. (arXiv:2202.00076v2 [stat.ML] UPDATED)
157. Faster One-Sample Stochastic Conditional Gradient Method for Composite Convex Minimization. (arXiv:2202.13212v2 [cs.LG] UPDATED)
158. Automated Data Augmentations for Graph Classification. (arXiv:2202.13248v3 [cs.LG] UPDATED)
159. Efficient Attribute Unlearning: Towards Selective Removal of Input Attributes from Feature Representations. (arXiv:2202.13295v2 [cs.LG] UPDATED)
160. Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers. (arXiv:2203.00156v2 [cs.RO] UPDATED)
161. SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v3 [cs.CL] UPDATED)
162. Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification. (arXiv:2203.04961v2 [eess.IV] UPDATED)
163. Active Evaluation: Efficient NLG Evaluation with Few Pairwise Comparisons. (arXiv:2203.06063v2 [cs.CL] UPDATED)
164. The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. (arXiv:2203.06498v5 [cs.LG] UPDATED)
165. Computer Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey. (arXiv:2203.06951v3 [cs.CV] UPDATED)
166. MixNN: A design for protecting deep learning models. (arXiv:2203.14803v2 [cs.DC] UPDATED)
167. A Multi-size Kernel based Adaptive Convolutional Neural Network for Bearing Fault Diagnosis. (arXiv:2203.15275v2 [eess.SP] UPDATED)
168. Improved Convergence Rate of Stochastic Gradient Langevin Dynamics with Variance Reduction and its Application to Optimization. (arXiv:2203.16217v2 [cs.LG] UPDATED)
169. A Differential Evolution-Enhanced Latent Factor Analysis Model for High-dimensional and Sparse Data. (arXiv:2204.00861v2 [cs.LG] UPDATED)
170. Learning-Based Approaches for Graph Problems: A Survey. (arXiv:2204.01057v2 [math.CO] UPDATED)
171. Imaging Conductivity from Current Density Magnitude using Neural Networks. (arXiv:2204.02441v2 [math.NA] UPDATED)
172. Deep Graphic FBSDEs for Opinion Dynamics Stochastic Control. (arXiv:2204.02506v3 [cs.MA] UPDATED)
173. Machine Learning-Enabled IoT Security: Open Issues and Challenges Under Advanced Persistent Threats. (arXiv:2204.03433v2 [cs.CR] UPDATED)
174. Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning. (arXiv:2204.03597v2 [cs.LG] UPDATED)
175. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v2 [cs.CV] UPDATED)
176. Rethinking Machine Learning Model Evaluation in Pathology. (arXiv:2204.05205v3 [eess.IV] UPDATED)
177. InCoder: A Generative Model for Code Infilling and Synthesis. (arXiv:2204.05999v2 [cs.SE] UPDATED)
178. AHP: Learning to Negative Sample for Hyperedge Prediction. (arXiv:2204.06353v2 [cs.LG] UPDATED)
179. CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing. (arXiv:2204.06625v2 [cs.CL] UPDATED)
180. METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v2 [cs.LG] UPDATED)
181. INSTA-BNN: Binary Neural Network with INSTAnce-aware Threshold. (arXiv:2204.07439v2 [cs.CV] UPDATED)
## cs.AI
---
**100** new papers in cs.AI:-) 
1. Interpretable Fault Diagnosis of Rolling Element Bearings with Temporal Logic Neural Network. (arXiv:2204.07579v1 [cs.LG])
2. mGPT: Few-Shot Learners Go Multilingual. (arXiv:2204.07580v1 [cs.CL])
3. Sources of Irreproducibility in Machine Learning: A Review. (arXiv:2204.07610v1 [cs.LG])
4. Contextualizing Artificially Intelligent Morality: A Meta-Ethnography of Top-Down, Bottom-Up, and Hybrid Models for Theoretical and Applied Ethics in Artificial Intelligence. (arXiv:2204.07612v1 [cs.AI])
5. Evaluating the Effectiveness of Corrective Demonstrations and a Low-Cost Sensor for Dexterous Manipulation. (arXiv:2204.07631v1 [cs.RO])
6. Towards a Stronger Theory for Permutation-based Evolutionary Algorithms. (arXiv:2204.07637v1 [cs.NE])
7. Investigating Positive and Negative Qualities of Human-in-the-Loop Optimization for Designing Interaction Techniques. (arXiv:2204.07641v1 [cs.HC])
8. Identifying Ethical Issues in AI Partners in Human-AI Co-Creation. (arXiv:2204.07644v1 [cs.HC])
9. Learning time-dependent PDE solver using Message Passing Graph Neural Networks. (arXiv:2204.07651v1 [cs.LG])
10. It is Okay to Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning by Contrastive Data Collection. (arXiv:2204.07660v1 [cs.CV])
11. Designing Creative AI Partners with COFI: A Framework for Modeling Interaction in Human-AI Co-Creative Systems. (arXiv:2204.07666v1 [cs.HC])
12. Just Fine-tune Twice: Selective Differential Privacy for Large Language Models. (arXiv:2204.07667v1 [cs.CL])
13. Self-Similarity Priors: Neural Collages as Differentiable Fractal Representations. (arXiv:2204.07673v1 [cs.LG])
14. Efficient Reinforcement Learning for Unsupervised Controlled Text Generation. (arXiv:2204.07696v1 [cs.CL])
15. TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction. (arXiv:2204.07703v1 [cs.SI])
16. Benchmarking Generalization via In-Context Instructions on 1,600+ Language Tasks. (arXiv:2204.07705v1 [cs.CL])
17. TVShowGuess: Character Comprehension in Stories as Speaker Guessing. (arXiv:2204.07721v1 [cs.CL])
18. Semantic interpretation for convolutional neural networks: What makes a cat a cat?. (arXiv:2204.07724v1 [cs.LG])
19. The Tree Loss: Improving Generalization with Many Classes. (arXiv:2204.07727v1 [cs.LG])
20. GitNet: Geometric Prior-based Transformation for Birds-Eye-View Segmentation. (arXiv:2204.07733v1 [cs.CV])
21. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v1 [cs.CV])
22. UniGDD: A Unified Generative Framework for Goal-Oriented Document-Grounded Dialogue. (arXiv:2204.07770v1 [cs.CL])
23. TASTEset -- Recipe Dataset and Food Entities Recognition Benchmark. (arXiv:2204.07775v1 [cs.CL])
24. Approaching sales forecasting using recurrent neural networks and transformers. (arXiv:2204.07786v1 [cs.LG])
25. UAMD-Net: A Unified Adaptive Multimodal Neural Network for Dense Depth Completion. (arXiv:2204.07791v1 [cs.CV])
26. Graph-incorporated Latent Factor Analysis for High-dimensional and Sparse Matrices. (arXiv:2204.07818v1 [cs.LG])
27. A Robust and Scalable Attention Guided Deep Learning Framework for Movement Quality Assessment. (arXiv:2204.07840v1 [cs.CV])
28. Multimodal Few-Shot Object Detection with Meta-Learning Based Cross-Modal Prompting. (arXiv:2204.07841v1 [cs.CV])
29. COVIBOT: A Smart Chatbot for Assistance and E-Awareness during COVID-19 Pandemic. (arXiv:2204.07851v1 [cs.CL])
30. Turing's cascade instability supports the coordination of the mind, brain, and behavior. (arXiv:2204.07904v1 [q-bio.NC])
31. Cognitive Architecture for Decision-Making Based on Brain Principles Programming. (arXiv:2204.07919v1 [cs.AI])
32. Towards Comprehensive Testing on the Robustness of Cooperative Multi-agent Reinforcement Learning. (arXiv:2204.07932v1 [cs.MA])
33. Unsupervised Cross-Task Generalization via Retrieval Augmentation. (arXiv:2204.07937v1 [cs.CL])
34. An Extendable, Efficient and Effective Transformer-based Object Detector. (arXiv:2204.07962v1 [cs.CV])
35. On Effectively Learning of Knowledge in Continual Pre-training. (arXiv:2204.07994v1 [cs.CL])
36. WikiOmnia: generative QA corpus on the whole Russian Wikipedia. (arXiv:2204.08009v1 [cs.CL])
37. Attention Mechanism based Cognition-level Scene Understanding. (arXiv:2204.08027v1 [cs.CV])
38. MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration. (arXiv:2204.08058v1 [cs.CV])
39. Self-Aware Personalized Federated Learning. (arXiv:2204.08069v1 [cs.LG])
40. Intelligent Explorations of the String Theory Landscape. (arXiv:2204.08073v1 [hep-th])
41. CPFair: Personalized Consumer and Producer Fairness Re-ranking for Recommender Systems. (arXiv:2204.08085v1 [cs.IR])
42. Learning Compositional Representations for Effective Low-Shot Generalization. (arXiv:2204.08090v1 [cs.CV])
43. Dataset for Analyzing Various Gaze Zones and Distracted Behaviors of a Driver. (arXiv:2204.08096v1 [cs.CV])
44. Exploiting Embodied Simulation to Detect Novel Object Classes Through Interaction. (arXiv:2204.08107v1 [cs.AI])
45. HFT-ONLSTM: Hierarchical and Fine-Tuning Multi-label Text Classification. (arXiv:2204.08115v1 [cs.CL])
46. Non-Parallel Text Style Transfer with Self-Parallel Supervision. (arXiv:2204.08123v1 [cs.CL])
47. Trinary Tools for Continuously Valued Binary Classifiers. (arXiv:2204.08136v1 [cs.LG])
48. Detect Rumors in Microblog Posts for Low-Resource Domains via Adversarial Contrastive Learning. (arXiv:2204.08143v1 [cs.CL])
49. Multi-scale Anomaly Detection for Big Time Series of Industrial Sensors. (arXiv:2204.08159v1 [cs.LG])
50. A Study on Prompt-based Few-Shot Learning Methods for Belief State Tracking in Task-oriented Dialog Systems. (arXiv:2204.08167v1 [cs.CL])
51. HRCF: Enhancing Collaborative Filtering via Hyperbolic Geometric Regularization. (arXiv:2204.08176v1 [cs.IR])
52. Modality-Balanced Embedding for Video Retrieval. (arXiv:2204.08182v1 [cs.CV])
53. TigerLily: Finding drug interactions in silico with the Graph. (arXiv:2204.08206v1 [cs.LG])
54. Preference Enhanced Social Influence Modeling for Network-Aware Cascade Prediction. (arXiv:2204.08229v1 [cs.SI])
55. Visio-Linguistic Brain Encoding. (arXiv:2204.08261v1 [cs.CV])
56. StepGame: A New Benchmark for Robust Multi-Hop Spatial Reasoning in Texts. (arXiv:2204.08292v1 [cs.CL])
57. Hierarchical Optimal Transport for Comparing Histopathology Datasets. (arXiv:2204.08324v1 [cs.CV])
58. A Comprehensive Survey on Data-Efficient GANs in Image Generation. (arXiv:2204.08329v1 [cs.CV])
59. AutoMLBench: A Comprehensive Experimental Evaluation of Automated Machine Learning Frameworks. (arXiv:2204.08358v1 [cs.LG])
60. Strengthening Subcommunities: Towards Sustainable Growth in AI Research. (arXiv:2204.08377v1 [cs.AI])
61. Spatial-Temporal Dynamic Graph Attention Networks for Ride-hailing Demand Prediction. (arXiv:2006.05905v4 [cs.LG] UPDATED)
62. End-to-End Differentiable Molecular Mechanics Force Field Construction. (arXiv:2010.01196v3 [physics.comp-ph] UPDATED)
63. Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss. (arXiv:2101.11952v4 [cs.CV] UPDATED)
64. Transductive Learning for Abstractive News Summarization. (arXiv:2104.09500v2 [cs.CL] UPDATED)
65. Investigating the Impact of Multi-LiDAR Placement on Object Detection for Autonomous Driving. (arXiv:2105.00373v3 [cs.RO] UPDATED)
66. Retrieval-Free Knowledge-Grounded Dialogue Response Generation with Adapters. (arXiv:2105.06232v4 [cs.CL] UPDATED)
67. Panoramic-Encoder: A Fast and Accurate Response Selection Paradigm for Generation-Based Dialogue Systems. (arXiv:2106.01263v3 [cs.CL] UPDATED)
68. Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v5 [cs.CV] UPDATED)
69. Leveraging Language to Learn Program Abstractions and Search Heuristics. (arXiv:2106.11053v2 [cs.LG] UPDATED)
70. Provable Convergence of Nesterov's Accelerated Gradient Method for Over-Parameterized Neural Networks. (arXiv:2107.01832v3 [cs.LG] UPDATED)
71. One-Cycle Pruning: Pruning ConvNets Under a Tight Training Budget. (arXiv:2107.02086v2 [cs.CV] UPDATED)
72. Integrating Large Circular Kernels into CNNs through Neural Architecture Search. (arXiv:2107.02451v4 [cs.CV] UPDATED)
73. A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine. (arXiv:2107.13704v9 [cs.AI] UPDATED)
74. A Concise Function Representation for Faster Exact MPE and Constrained Optimisation in Graphical Models. (arXiv:2108.03899v2 [cs.AI] UPDATED)
75. Graph Condensation for Graph Neural Networks. (arXiv:2110.07580v3 [cs.LG] UPDATED)
76. Learning to run a power network with trust. (arXiv:2110.12908v2 [cs.AI] UPDATED)
77. DeF-DReL: Systematic Deployment of Serverless Functions in Fog and Cloud environments using Deep Reinforcement Learning. (arXiv:2110.15702v3 [cs.DC] UPDATED)
78. DSPoint: Dual-scale Point Cloud Recognition with High-frequency Fusion. (arXiv:2111.10332v3 [cs.CV] UPDATED)
79. Natural Language Processing in-and-for Design Research. (arXiv:2111.13827v2 [cs.CL] UPDATED)
80. ExCon: Explanation-driven Supervised Contrastive Learning for Image Classification. (arXiv:2111.14271v6 [cs.CV] UPDATED)
81. BA-Net: Bridge Attention for Deep Convolutional Neural Networks. (arXiv:2112.04150v2 [cs.CV] UPDATED)
82. Value Retrieval with Arbitrary Queries for Form-like Documents. (arXiv:2112.07820v2 [cs.CV] UPDATED)
83. Few-shot Instruction Prompts for Pretrained Language Models to Detect Social Biases. (arXiv:2112.07868v2 [cs.CL] UPDATED)
84. Relationship extraction for knowledge graph creation from biomedical literature. (arXiv:2201.01647v3 [cs.AI] UPDATED)
85. Natural Language Descriptions of Deep Visual Features. (arXiv:2201.11114v2 [cs.CV] UPDATED)
86. MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation. (arXiv:2202.03851v2 [cs.IR] UPDATED)
87. Efficient Spatial Representation and Routing of Deformable One-Dimensional Objects for Manipulation. (arXiv:2202.06172v2 [cs.RO] UPDATED)
88. Automated Data Augmentations for Graph Classification. (arXiv:2202.13248v3 [cs.LG] UPDATED)
89. CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion. (arXiv:2202.13785v3 [cs.AI] UPDATED)
90. Preemptive Motion Planning for Human-to-Robot Indirect Placement Handovers. (arXiv:2203.00156v2 [cs.RO] UPDATED)
91. SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v3 [cs.CL] UPDATED)
92. Modeling and Validating Temporal Rules with Semantic Petri-Net for Digital Twins. (arXiv:2203.04741v2 [cs.AI] UPDATED)
93. Sharing Generative Models Instead of Private Data: A Simulation Study on Mammography Patch Classification. (arXiv:2203.04961v2 [eess.IV] UPDATED)
94. Active Evaluation: Efficient NLG Evaluation with Few Pairwise Comparisons. (arXiv:2203.06063v2 [cs.CL] UPDATED)
95. A Multi-size Kernel based Adaptive Convolutional Neural Network for Bearing Fault Diagnosis. (arXiv:2203.15275v2 [eess.SP] UPDATED)
96. ELECRec: Training Sequential Recommenders as Discriminators. (arXiv:2204.02011v3 [cs.AI] UPDATED)
97. Imitating, Fast and Slow: Robust learning from demonstrations via decision-time planning. (arXiv:2204.03597v2 [cs.LG] UPDATED)
98. OutfitTransformer: Learning Outfit Representations for Fashion Recommendation. (arXiv:2204.04812v2 [cs.CV] UPDATED)
99. METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v2 [cs.LG] UPDATED)
100. Recent Advances and New Frontiers in Spiking Neural Networks. (arXiv:2204.07050v2 [cs.NE] UPDATED)

