# Your interest papers
---
## cs.CV
---
### Subjective Assessment of **High Dynamic Range** Videos Under Different Ambient Conditions. (arXiv:2209.10005v1 [eess.IV])
- Authors : Zaixi Shang, Yongjun Wu, Hai Wei, Sriram Sethuraman
- Link : [http://arxiv.org/abs/2209.10005](http://arxiv.org/abs/2209.10005)
> ABSTRACT  :  **High Dynamic Range** (**HDR**) videos can represent a much greater range of brightness and color than Standard Dynamic Range (SDR) videos and are rapidly becoming an industry standard. **HDR** videos have more challenging capture, transmission, and display requirements than legacy SDR videos. With their greater bit depth, advanced electro-optical transfer functions, and wider color gamuts, comes the need for video quality algorithms that are specifically designed to predict the quality of **HDR** videos. Towards this end, we present the first publicly released large-scale subjective study of **HDR** videos. We study the effect of distortions such as compression and aliasing on the quality of **HDR** videos. We also study the effect of ambient illumination on perceptual quality of **HDR** videos by conducting the study in both a **dark** lab environment and a brighter living-room environment. A total of 66 subjects participated in the study and more than 20,000 opinion scores were collected, which makes this the largest in-lab study of **HDR** video quality ever. We anticipate that the dataset will be a valuable resource for researchers to develop better models of perceptual quality for **HDR** videos.  
### Fast-Image2Point: Towards Real-Time Point Cloud Reconstruction of a Single Image using 3D Supervision. (arXiv:2209.10029v1 [cs.CV])
- Authors : AmirHossein Zamani, Kamran Ghaffari
- Link : [http://arxiv.org/abs/2209.10029](http://arxiv.org/abs/2209.10029)
> ABSTRACT  :  A key question in the problem of 3D reconstruction is how to train a machine or a robot to model 3D objects. Many tasks like navigation in real-time systems such as autonomous vehicles directly depend on this problem. These systems usually have limited computational power. Despite considerable progress in 3D reconstruction systems in recent years, applying them to real-time systems such as navigation systems in autonomous vehicles is still challenging due to the high complexity and computational demand of the existing methods. This study addresses current problems in reconstructing objects displayed in a single-view image in a faster (real-time) fashion. To this end, a simple yet powerful deep neural framework is developed. The proposed framework consists of two components: the feature extractor module and the 3D generator module. We use point cloud representation for the output of our reconstruction module. The ShapeNet dataset is utilized to compare the method with the existing results in terms of computation time and accuracy. Simulations demonstrate the superior performance of the proposed method.    Index Terms-**Real-time** 3D reconstruction, single-view reconstruction, supervised learning, deep neural network  
### PicT: A Slim Weakly Supervised Vision Transformer for Pavement Distress Classification. (arXiv:2209.10074v1 [cs.CV])
- Authors : Wenhao Tang, Sheng Huang, Xiaoxian Zhang, Luwen Huangfu
- Link : [http://arxiv.org/abs/2209.10074](http://arxiv.org/abs/2209.10074)
> ABSTRACT  :  Automatic pavement distress classification facilitates improving the efficiency of pavement maintenance and reducing the cost of labor and resources. A recently influential branch of this task divides the pavement image into patches and addresses these issues from the perspective of multi-instance learning. However, these methods neglect the correlation between patches and suffer from a low efficiency in the model optimization and inference. Meanwhile, **Swin** Transformer is able to address both of these issues with its unique strengths. Built upon **Swin** Transformer, we present a vision Transformer named \textbf{P}avement \textbf{I}mage \textbf{C}lassification \textbf{T}ransformer (\textbf{PicT}) for pavement distress classification. In order to better exploit the discriminative information of pavement images at the patch level, the \textit{Patch Labeling Teacher} is proposed to leverage a teacher model to dynamically generate pseudo labels of patches from image labels during each iteration, and guides the model to learn the discriminative features of patches. The broad classification head of **Swin** Transformer may dilute the discriminative features of distressed patches in the feature aggregation step due to the small distressed area ratio of the pavement image. To overcome this drawback, we present a \textit{Patch Refiner} to cluster patches into different groups and only select the highest distress-risk group to yield a slim head for the final image classification. We evaluate our method on CQU-BPDD. Extensive results show that \textbf{PicT} outperforms the second-best performed model by a large margin of $+2.4\%$ in P@R on detection task, $+3.9\%$ in $F1$ on recognition task, and 1.8x throughput, while enjoying 7x faster training speed using the same computing resources. Our codes and models have been released on \href{https://github.com/DearCaat/PicT}{https://github.com/DearCaat/PicT}.  
### RNGDet++: Road Network Graph Detection by Transformer with Instance Segmentation and Multi-scale Features **Enhancement**. (arXiv:2209.10150v1 [cs.CV])
- Authors : Zhenhua Xu, Yuxuan Liu, Yuxiang Sun, Ming Liu, Lujia Wang
- Link : [http://arxiv.org/abs/2209.10150](http://arxiv.org/abs/2209.10150)
> ABSTRACT  :  The graph structure of road networks is critical for downstream tasks of autonomous driving systems, such as global planning, motion prediction and control. In the past, the road network graph is usually manually annotated by human experts, which is time-consuming and labor-intensive. To obtain the road network graph with better effectiveness and efficiency, automatic approaches for road network graph detection are required. Previous works either post-process semantic segmentation maps or propose graph-based algorithms to directly predict the road network graph. However, previous works suffer from hard-coded heuristic processing algorithms and inferior final performance. To enhance the previous SOTA (State-of-the-Art) approach RNGDet, we add an instance segmentation head to better supervise the model training, and enable the model to leverage multi-scale features of the backbone network. Since the new proposed approach is improved from RNGDet, it is named RNGDet++. All approaches are evaluated on a large publicly available dataset. RNGDet++ outperforms baseline models on almost all metrics scores. It improves the topology correctness APLS (Average Path Length Similarity) by around 3\%. The demo video and supplementary materials are available on our project page \url{https://tonyxuqaq.github.io/projects/RNGDetPlusPlus/}.  
### Multi-Field De-interlacing using Deformable Convolution Residual Blocks and Self-Attention. (arXiv:2209.10192v1 [eess.IV])
- Authors : Ronglei Ji, Murat Tekalp
- Link : [http://arxiv.org/abs/2209.10192](http://arxiv.org/abs/2209.10192)
> ABSTRACT  :  Although deep learning has made significant impact on image/video **restoration** and super-resolution, learned deinterlacing has so far received less attention in academia or industry. This is despite deinterlacing is well-suited for supervised learning from synthetic data since the degradation model is known and fixed. In this paper, we propose a novel multi-field full frame-rate deinterlacing network, which adapts the state-of-the-art superresolution approaches to the deinterlacing task. Our model aligns features from adjacent fields to a reference field (to be deinterlaced) using both deformable convolution residual blocks and self attention. Our extensive experimental results demonstrate that the proposed method provides state-of-the-art deinterlacing results in terms of both numerical and perceptual performance. At the time of writing, our model ranks first in the Full FrameRate LeaderBoard at https://videoprocessing.ai/benchmarks/deinterlacer.html  
### DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions. (arXiv:2209.10381v1 [cs.CV])
- Authors : Xuhong Ren, Jianlang Chen, Felix Juefei, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shengyong Chen
- Link : [http://arxiv.org/abs/2209.10381](http://arxiv.org/abs/2209.10381)
> ABSTRACT  :  Network architecture search (NAS), in particular the differentiable architecture search (DARTS) method, has shown a great power to learn excellent model architectures on the specific dataset of interest. In contrast to using a fixed dataset, in this work, we focus on a different but important scenario for NAS: how to refine a deployed network's model architecture to enhance its robustness with the guidance of a few collected and misclassified examples that are degraded by some real-world unknown corruptions having a specific pattern (e.g., noise, blur, etc.). To this end, we first conduct an empirical study to validate that the model architectures can be definitely related to the corruption patterns. Surprisingly, by just adding a few corrupted and misclassified examples (e.g., $10^3$ examples) to the clean training dataset (e.g., $5.0 \times 10^4$ examples), we can refine the model architecture and enhance the robustness significantly. To make it more practical, the key problem, i.e., how to select the proper failure examples for the effective NAS guidance, should be carefully investigated. Then, we propose a novel core-failure-set guided DARTS that embeds a K-center-greedy algorithm for DARTS to select suitable corrupted failure examples to refine the model architecture. We use our method for DARTS-refined DNNs on the clean as well as 15 corruptions with the guidance of four specific real-world corruptions. Compared with the state-of-the-art NAS as well as data-augmentation-based **enhancement** methods, our final method can achieve higher accuracy on both corrupted datasets and the original clean dataset. On some of the corruption patterns, we can achieve as high as over 45% absolute accuracy improvements.  
### Sar Ship Detection based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network. (arXiv:2209.10421v1 [cs.CV])
- Authors : Xiao Ke, Xiaoling Zhang, Tianwen Zhang, Jun Shi, Shunjun Wei
- Link : [http://arxiv.org/abs/2209.10421](http://arxiv.org/abs/2209.10421)
> ABSTRACT  :  With the booming of Convolutional Neural Networks (CNNs), CNNs such as VGG-16 and ResNet-50 widely serve as backbone in SAR ship detection. However, CNN based backbone is hard to model long-range dependencies, and causes the lack of enough high-quality semantic information in feature maps of shallow layers, which leads to poor detection performance in complicated background and small-sized ships cases. To address these problems, we propose a SAR ship detection method based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network (FEFPN). **Swin** Transformer serves as backbone to model long-range dependencies and generates hierarchical features maps. FEFPN is proposed to further improve the quality of feature maps by gradually enhancing the semantic information of feature maps at all levels, especially feature maps in shallow layers. Experiments conducted on SAR ship detection dataset (SSDD) reveal the advantage of our proposed methods.  
### L2E: Lasers to Events for 6-DoF Extrinsic Calibration of Lidars and Event Cameras. (arXiv:2207.01009v3 [cs.CV] UPDATED)
- Authors : Kevin Ta, David Bruggemann, Tim Br, Christos Sakaridis, Luc Van
- Link : [http://arxiv.org/abs/2207.01009](http://arxiv.org/abs/2207.01009)
> ABSTRACT  :  As neuromorphic technology is maturing, its application to robotics and autonomous vehicle systems has become an area of active research. In particular, event cameras have emerged as a compelling alternative to frame-based cameras in low-power and latency-demanding applications. To enable event cameras to operate alongside staple sensors like lidar in perception tasks, we propose a direct, temporally-decoupled extrinsic calibration method between event cameras and lidars. The **high dynamic range**, high temporal resolution, and low-latency operation of event cameras are exploited to directly register lidar laser returns, allowing information-based correlation methods to optimize for the 6-DoF extrinsic calibration between the two sensors. This paper presents the first direct calibration method between event cameras and lidars, removing dependencies on frame-based camera intermediaries and/or highly-accurate hand measurements.  
### ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)
- Authors : Zimian Wei, Hengyue Pan, Xin Niu, Dongsheng Li
- Link : [http://arxiv.org/abs/2209.07738](http://arxiv.org/abs/2209.07738)
> ABSTRACT  :  Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more efficient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer outperforms similar size vision transformers(ViTs) and convolutional neural networks (CNNs) in various tasks. For example, ConvFormer-S, ConvFormer-L achieve state-of-the-art performance of 82.8%, 83.6% top-1 accuracy on ImageNet dataset. Moreover, ConvFormer-S outperforms **Swin**-T by 1.5 mIoU on ADE20K, and 0.9 bounding box AP on COCO with a smaller model size. Code and models will be available.  
## eess.IV
---
### Subjective Assessment of **High Dynamic Range** Videos Under Different Ambient Conditions. (arXiv:2209.10005v1 [eess.IV])
- Authors : Zaixi Shang, Yongjun Wu, Hai Wei, Sriram Sethuraman
- Link : [http://arxiv.org/abs/2209.10005](http://arxiv.org/abs/2209.10005)
> ABSTRACT  :  **High Dynamic Range** (**HDR**) videos can represent a much greater range of brightness and color than Standard Dynamic Range (SDR) videos and are rapidly becoming an industry standard. **HDR** videos have more challenging capture, transmission, and display requirements than legacy SDR videos. With their greater bit depth, advanced electro-optical transfer functions, and wider color gamuts, comes the need for video quality algorithms that are specifically designed to predict the quality of **HDR** videos. Towards this end, we present the first publicly released large-scale subjective study of **HDR** videos. We study the effect of distortions such as compression and aliasing on the quality of **HDR** videos. We also study the effect of ambient illumination on perceptual quality of **HDR** videos by conducting the study in both a **dark** lab environment and a brighter living-room environment. A total of 66 subjects participated in the study and more than 20,000 opinion scores were collected, which makes this the largest in-lab study of **HDR** video quality ever. We anticipate that the dataset will be a valuable resource for researchers to develop better models of perceptual quality for **HDR** videos.  
### Multi-Field De-interlacing using Deformable Convolution Residual Blocks and Self-Attention. (arXiv:2209.10192v1 [eess.IV])
- Authors : Ronglei Ji, Murat Tekalp
- Link : [http://arxiv.org/abs/2209.10192](http://arxiv.org/abs/2209.10192)
> ABSTRACT  :  Although deep learning has made significant impact on image/video **restoration** and super-resolution, learned deinterlacing has so far received less attention in academia or industry. This is despite deinterlacing is well-suited for supervised learning from synthetic data since the degradation model is known and fixed. In this paper, we propose a novel multi-field full frame-rate deinterlacing network, which adapts the state-of-the-art superresolution approaches to the deinterlacing task. Our model aligns features from adjacent fields to a reference field (to be deinterlaced) using both deformable convolution residual blocks and self attention. Our extensive experimental results demonstrate that the proposed method provides state-of-the-art deinterlacing results in terms of both numerical and perceptual performance. At the time of writing, our model ranks first in the Full FrameRate LeaderBoard at https://videoprocessing.ai/benchmarks/deinterlacer.html  
### Extending Video Decoding Energy Models for 360{\deg} and **HDR** Video Formats in HEVC. (arXiv:2209.10268v1 [eess.IV])
- Authors : Matthias Kr, Christian Herglotz
- Link : [http://arxiv.org/abs/2209.10268](http://arxiv.org/abs/2209.10268)
> ABSTRACT  :  Research has shown that decoder energy models are helpful tools for improving the energy efficiency in video playback applications. For example, an accurate feature-based bit stream model can reduce the energy consumption of the decoding process. However, until now only sequences of the SDR video format were investigated. Therefore, this paper shows that the decoding energy of HEVC-coded bit streams can be estimated precisely for different video formats and coding bit depths. Therefore, we compare a state-of-the-art model from the literature with a proposed model. We show that bit streams of the 360{\deg}, **HDR**, and fisheye video format can be estimated with a mean estimation error lower than 3.88% if the setups have the same coding bit depth. Furthermore, it is shown that on average, the energy demand for the decoding of bit streams with a bit depth of 10-bit is 55% higher than with 8-bit.  
## cs.LG
---
### Leak Detection in Natural Gas Pipeline Using Machine Learning Models. (arXiv:2209.10121v1 [cs.LG])
- Authors : Adebayo Oshingbesan
- Link : [http://arxiv.org/abs/2209.10121](http://arxiv.org/abs/2209.10121)
> ABSTRACT  :  Leak detection in gas pipelines is an important and persistent problem in the Oil and Gas industry. This is particularly important as pipelines are the most common way of transporting natural gas. This research aims to study the ability of data-driven intelligent models to detect small leaks for a natural gas pipeline using basic operational parameters and then compare the intelligent models among themselves using existing performance metrics. This project applies the observer design technique to detect leaks in natural gas pipelines using a regressoclassification hierarchical model where an intelligent model acts as a regressor and a modified logistic regression model acts as a classifier. Five intelligent models (gradient boosting, decision trees, random forest, support vector machine and artificial neural network) are studied in this project using a pipeline data stream of four weeks. The results shows that while support vector machine and artificial neural networks are better regressors than the others, they do not provide the best results in leak detection due to their internal complexities and the volume of data used. The random forest and decision tree models are the most sensitive as they can detect a leak of 0.1% of nominal flow in about 2 hours. All the intelligent models had high reliability with zero false alarm rate in testing phase. The average time to leak detection for all the intelligent models was compared to a **real time** transient model in literature. The results show that intelligent models perform relatively well in the problem of leak detection. This result suggests that intelligent models could be used alongside a **real time** transient model to significantly improve leak detection results.  
### A data-centric approach to anomaly detection in layer-based additive manufacturing. (arXiv:2209.10178v1 [cs.LG])
- Authors : Alexander Zeiser, Bas van
- Link : [http://arxiv.org/abs/2209.10178](http://arxiv.org/abs/2209.10178)
> ABSTRACT  :  Anomaly detection describes methods of finding abnormal states, instances or data points that differ from a normal value space. Industrial processes are a domain where predicitve models are needed for finding anomalous data instances for quality **enhancement**. A main challenge, however, is absence of labels in this environment. This paper contributes to a data-centric way of approaching artificial intelligence in industrial production. With a use case from additive manufacturing for automotive components we present a deep-learning-based image processing pipeline. We integrate the concept of domain randomisation and synthetic data in the loop that shows promising results for bridging advances in deep learning and its application to real-world, industrial production processes.  
### DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions. (arXiv:2209.10381v1 [cs.CV])
- Authors : Xuhong Ren, Jianlang Chen, Felix Juefei, Wanli Xue, Qing Guo, Lei Ma, Jianjun Zhao, Shengyong Chen
- Link : [http://arxiv.org/abs/2209.10381](http://arxiv.org/abs/2209.10381)
> ABSTRACT  :  Network architecture search (NAS), in particular the differentiable architecture search (DARTS) method, has shown a great power to learn excellent model architectures on the specific dataset of interest. In contrast to using a fixed dataset, in this work, we focus on a different but important scenario for NAS: how to refine a deployed network's model architecture to enhance its robustness with the guidance of a few collected and misclassified examples that are degraded by some real-world unknown corruptions having a specific pattern (e.g., noise, blur, etc.). To this end, we first conduct an empirical study to validate that the model architectures can be definitely related to the corruption patterns. Surprisingly, by just adding a few corrupted and misclassified examples (e.g., $10^3$ examples) to the clean training dataset (e.g., $5.0 \times 10^4$ examples), we can refine the model architecture and enhance the robustness significantly. To make it more practical, the key problem, i.e., how to select the proper failure examples for the effective NAS guidance, should be carefully investigated. Then, we propose a novel core-failure-set guided DARTS that embeds a K-center-greedy algorithm for DARTS to select suitable corrupted failure examples to refine the model architecture. We use our method for DARTS-refined DNNs on the clean as well as 15 corruptions with the guidance of four specific real-world corruptions. Compared with the state-of-the-art NAS as well as data-augmentation-based **enhancement** methods, our final method can achieve higher accuracy on both corrupted datasets and the original clean dataset. On some of the corruption patterns, we can achieve as high as over 45% absolute accuracy improvements.  
### ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)
- Authors : Zimian Wei, Hengyue Pan, Xin Niu, Dongsheng Li
- Link : [http://arxiv.org/abs/2209.07738](http://arxiv.org/abs/2209.07738)
> ABSTRACT  :  Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more efficient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer outperforms similar size vision transformers(ViTs) and convolutional neural networks (CNNs) in various tasks. For example, ConvFormer-S, ConvFormer-L achieve state-of-the-art performance of 82.8%, 83.6% top-1 accuracy on ImageNet dataset. Moreover, ConvFormer-S outperforms **Swin**-T by 1.5 mIoU on ADE20K, and 0.9 bounding box AP on COCO with a smaller model size. Code and models will be available.  
## cs.AI
---
### Sar Ship Detection based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network. (arXiv:2209.10421v1 [cs.CV])
- Authors : Xiao Ke, Xiaoling Zhang, Tianwen Zhang, Jun Shi, Shunjun Wei
- Link : [http://arxiv.org/abs/2209.10421](http://arxiv.org/abs/2209.10421)
> ABSTRACT  :  With the booming of Convolutional Neural Networks (CNNs), CNNs such as VGG-16 and ResNet-50 widely serve as backbone in SAR ship detection. However, CNN based backbone is hard to model long-range dependencies, and causes the lack of enough high-quality semantic information in feature maps of shallow layers, which leads to poor detection performance in complicated background and small-sized ships cases. To address these problems, we propose a SAR ship detection method based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network (FEFPN). **Swin** Transformer serves as backbone to model long-range dependencies and generates hierarchical features maps. FEFPN is proposed to further improve the quality of feature maps by gradually enhancing the semantic information of feature maps at all levels, especially feature maps in shallow layers. Experiments conducted on SAR ship detection dataset (SSDD) reveal the advantage of our proposed methods.  
### ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)
- Authors : Zimian Wei, Hengyue Pan, Xin Niu, Dongsheng Li
- Link : [http://arxiv.org/abs/2209.07738](http://arxiv.org/abs/2209.07738)
> ABSTRACT  :  Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more efficient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer outperforms similar size vision transformers(ViTs) and convolutional neural networks (CNNs) in various tasks. For example, ConvFormer-S, ConvFormer-L achieve state-of-the-art performance of 82.8%, 83.6% top-1 accuracy on ImageNet dataset. Moreover, ConvFormer-S outperforms **Swin**-T by 1.5 mIoU on ADE20K, and 0.9 bounding box AP on COCO with a smaller model size. Code and models will be available.  
# Paper List
---
## cs.CV
---
**92** new papers in cs.CV:-) 
1. Superpixel Generation and Clustering for Weakly Supervised Brain Tumor Segmentation in MR Images. (arXiv:2209.09930v1 [cs.CV])
2. Adversarial Bi-Regressor Network for Domain Adaptive Regression. (arXiv:2209.09943v1 [cs.HC])
3. Learning Sparse Latent Representations for Generator Model. (arXiv:2209.09949v1 [cs.CV])
4. MARIO: Modular and Extensible Architecture for Computing Visual Statistics in RoboCup SPL. (arXiv:2209.09987v1 [cs.CV])
5. Subjective Assessment of **High Dynamic Range** Videos Under Different Ambient Conditions. (arXiv:2209.10005v1 [eess.IV])
6. Fine-Grained VR Sketching: Dataset and Insights. (arXiv:2209.10008v1 [cs.CV])
7. Towards 3D VR-Sketch to 3D Shape Retrieval. (arXiv:2209.10020v1 [cs.CV])
8. Fast-Image2Point: Towards Real-Time Point Cloud Reconstruction of a Single Image using 3D Supervision. (arXiv:2209.10029v1 [cs.CV])
9. MTR-A: 1st Place Solution for 2022 Waymo Open Dataset Challenge -- Motion Prediction. (arXiv:2209.10033v1 [cs.CV])
10. Mutual Information Learned Classifiers: an Information-theoretic Viewpoint of Training Deep Learning Classification Systems. (arXiv:2209.10058v1 [cs.LG])
11. Progressive with Purpose: Guiding Progressive Inpainting DNNs through Context and Structure. (arXiv:2209.10071v1 [cs.CV])
12. Adaptive Local-Component-aware Graph Convolutional Network for One-shot Skeleton-based Action Recognition. (arXiv:2209.10073v1 [cs.CV])
13. PicT: A Slim Weakly Supervised Vision Transformer for Pavement Distress Classification. (arXiv:2209.10074v1 [cs.CV])
14. Can Shadows Reveal Biometric Information?. (arXiv:2209.10077v1 [cs.CV])
15. Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos. (arXiv:2209.10126v1 [cs.CV])
16. Recipe Generation from Unsegmented Cooking Videos. (arXiv:2209.10134v1 [cs.MM])
17. Detecting Crop Burning in India using Satellite Data. (arXiv:2209.10148v1 [cs.CV])
18. RNGDet++: Road Network Graph Detection by Transformer with Instance Segmentation and Multi-scale Features **Enhancement**. (arXiv:2209.10150v1 [cs.CV])
19. Review On Deep Learning Technique For Underwater Object Detection. (arXiv:2209.10151v1 [cs.CV])
20. FT-HID: A Large Scale RGB-D Dataset for First and Third Person Human Interaction Analysis. (arXiv:2209.10155v1 [cs.CV])
21. Position-Aware Relation Learning for RGB-Thermal Salient Object Detection. (arXiv:2209.10158v1 [cs.CV])
22. HAZE-Net: High-Frequency Attentive Super-Resolved Gaze Estimation in Low-Resolution Face Images. (arXiv:2209.10167v1 [cs.CV])
23. FV2ES: A Fully End2End Multimodal System for Fast Yet Effective Video Emotion Recognition Inference. (arXiv:2209.10170v1 [cs.CV])
24. LatentGaze: Cross-Domain Gaze Estimation through Gaze-Aware Analytic Latent Code Manipulation. (arXiv:2209.10171v1 [cs.CV])
25. Learning Reconstructability for Drone Aerial Path Planning. (arXiv:2209.10174v1 [cs.GR])
26. D-InLoc++: Indoor Localization in Dynamic Environments. (arXiv:2209.10185v1 [cs.CV])
27. Implicit Conversion of Manifold B-Rep Solids by Neural Halfspace Representation. (arXiv:2209.10191v1 [cs.GR])
28. Multi-Field De-interlacing using Deformable Convolution Residual Blocks and Self-Attention. (arXiv:2209.10192v1 [eess.IV])
29. Kernel-Based Generalized Median Computation for Consensus Learning. (arXiv:2209.10208v1 [cs.CV])
30. HiFuse: Hierarchical Multi-Scale Feature Fusion Network for Medical Image Classification. (arXiv:2209.10218v1 [eess.IV])
31. Intelligent wayfinding vehicle design based on visual recognition. (arXiv:2209.10229v1 [cs.CV])
32. BEVStereo: Enhancing Depth Estimation in Multi-view 3D Object Detection with Dynamic Temporal Stereo. (arXiv:2209.10248v1 [cs.CV])
33. Query-Guided Networks for Few-shot Fine-grained Classification and Person Search. (arXiv:2209.10250v1 [cs.CV])
34. AirFi: Empowering WiFi-based Passive Human Gesture Recognition to Unseen Environment via Domain Generalization. (arXiv:2209.10285v1 [cs.CV])
35. Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic Resonance. (arXiv:2209.10298v1 [eess.IV])
36. I2DFormer: Learning Image to Document Attention for Zero-Shot Image Classification. (arXiv:2209.10304v1 [cs.CV])
37. KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution. (arXiv:2209.10305v1 [cs.CV])
38. Deep Learning for Medical Image Segmentation: Tricks, Challenges and Future Directions. (arXiv:2209.10307v1 [cs.CV])
39. Rethinking the compositionality of point clouds through regularization in the hyperbolic space. (arXiv:2209.10318v1 [cs.CV])
40. Continual VQA for Disaster Response Systems. (arXiv:2209.10320v1 [cs.CV])
41. Toward 3D Spatial Reasoning for Human-like Text-based Visual Question Answering. (arXiv:2209.10326v1 [cs.CV])
42. SDA-$x$Net: Selective Depth Attention Networks for Adaptive Multi-scale Feature Representation. (arXiv:2209.10327v1 [cs.CV])
43. FNeVR: Neural Volume Rendering for Face Animation. (arXiv:2209.10340v1 [cs.CV])
44. Momentum Adversarial Distillation: Handling Large Distribution Shifts in Data-Free Knowledge Distillation. (arXiv:2209.10359v1 [cs.CV])
45. SoLar: Sinkhorn Label Refinery for Imbalanced Partial-Label Learning. (arXiv:2209.10365v1 [cs.LG])
46. Safety Metrics and Losses for Object Detection in Autonomous Driving. (arXiv:2209.10368v1 [cs.CV])
47. DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions. (arXiv:2209.10381v1 [cs.CV])
48. Long-Lived Accurate Keypoints in Event Streams. (arXiv:2209.10385v1 [cs.CV])
49. IoU-Enhanced Attention for End-to-End Task Specific Object Detection. (arXiv:2209.10391v1 [cs.CV])
50. wildNeRF: Complete view synthesis of in-the-wild dynamic scenes captured using sparse monocular data. (arXiv:2209.10399v1 [cs.CV])
51. Sar Ship Detection based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network. (arXiv:2209.10421v1 [cs.CV])
52. Consecutive Knowledge Meta-Adaptation Learning for Unsupervised Medical Diagnosis. (arXiv:2209.10425v1 [eess.IV])
53. A Few Shot Multi-Representation Approach for N-gram Spotting in Historical Manuscripts. (arXiv:2209.10441v1 [cs.CV])
54. Uncertainty-aware Label Distribution Learning for Facial Expression Recognition. (arXiv:2209.10448v1 [cs.CV])
55. Learning from Mixed Datasets: A Monotonic Image Quality Assessment Model. (arXiv:2209.10451v1 [cs.CV])
56. Sample, Crop, Track: Self-Supervised Mobile 3D Object Detection for Urban Driving LiDAR. (arXiv:2209.10471v1 [cs.CV])
57. Show, Interpret and Tell: Entity-aware Contextualised Image Captioning in Wikipedia. (arXiv:2209.10474v1 [cs.CV])
58. Multi-view Local Co-occurrence and Global Consistency Learning Improve Mammogram Classification Generalisation. (arXiv:2209.10478v1 [cs.CV])
59. Recurrent Super-Resolution Method for Enhancing Low Quality Thermal Facial Data. (arXiv:2209.10489v1 [cs.CV])
60. Animating Still Images. (arXiv:2209.10497v1 [cs.CV])
61. Gemino: Practical and Robust Neural Compression for Video Conferencing. (arXiv:2209.10507v1 [cs.NI])
62. Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation. (arXiv:2209.10510v1 [cs.CV])
63. Benchmarking and Analyzing 3D Human Pose and Shape Estimation Beyond Algorithms. (arXiv:2209.10529v1 [cs.CV])
64. FedFOR: Stateless Heterogeneous Federated Learning with First-Order Regularization. (arXiv:2209.10537v1 [cs.LG])
65. Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training. (arXiv:2105.11333v3 [cs.CV] UPDATED)
66. Universum GANs: Improving GANs through contradictions. (arXiv:2106.09946v2 [cs.LG] UPDATED)
67. Make an Omelette with Breaking Eggs: Zero-Shot Learning for Novel Attribute Synthesis. (arXiv:2111.14182v4 [cs.CV] UPDATED)
68. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v2 [cs.CV] UPDATED)
69. DocSegTr: An Instance-Level End-to-End Document Image Segmentation Transformer. (arXiv:2201.11438v2 [cs.CV] UPDATED)
70. Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance. (arXiv:2202.12387v4 [cs.LG] UPDATED)
71. Multi-trial Neural Architecture Search with Lottery Tickets. (arXiv:2203.04300v2 [cs.LG] UPDATED)
72. FlowFormer: A Transformer Architecture for Optical Flow. (arXiv:2203.16194v4 [cs.CV] UPDATED)
73. Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution. (arXiv:2204.01188v2 [cs.CV] UPDATED)
74. Learning Online Multi-Sensor Depth Fusion. (arXiv:2204.03353v2 [cs.CV] UPDATED)
75. FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects. (arXiv:2205.04382v3 [cs.RO] UPDATED)
76. Transformers in 3D Point Clouds: A Survey. (arXiv:2205.07417v2 [cs.CV] UPDATED)
77. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v3 [cs.LG] UPDATED)
78. Variational Transformer: A Framework Beyond the Trade-off between Accuracy and Diversity for Image Captioning. (arXiv:2205.14458v2 [cs.CV] UPDATED)
79. A Unified Model for Multi-class Anomaly Detection. (arXiv:2206.03687v2 [cs.CV] UPDATED)
80. Understanding Aesthetics with Language: A Photo Critique Dataset for Aesthetic Assessment. (arXiv:2206.08614v3 [cs.CV] UPDATED)
81. Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v3 [cs.CV] UPDATED)
82. Rethinking Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2207.00067v2 [cs.CV] UPDATED)
83. L2E: Lasers to Events for 6-DoF Extrinsic Calibration of Lidars and Event Cameras. (arXiv:2207.01009v3 [cs.CV] UPDATED)
84. CLIFF: Carrying Location Information in Full Frames into Human Pose and Shape Estimation. (arXiv:2208.00571v2 [cs.CV] UPDATED)
85. Pyramidal Predictive Network: A Model for Visual-frame Prediction Based on Predictive Coding Theory. (arXiv:2208.07021v2 [cs.CV] UPDATED)
86. ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation. (arXiv:2209.04145v3 [cs.CV] UPDATED)
87. SVNet: Where SO(3) Equivariance Meets Binarization on Point Cloud Representation. (arXiv:2209.05924v2 [cs.CV] UPDATED)
88. Shape Completion with Points in the Shadow. (arXiv:2209.08345v2 [cs.CV] UPDATED)
89. NeRF-SOS: Any-View Self-supervised Object Segmentation from Complex Real-World Scenes. (arXiv:2209.08776v2 [cs.CV] UPDATED)
90. A Closer Look at Novel Class Discovery from the Labeled Set. (arXiv:2209.09120v2 [cs.CV] UPDATED)
91. Automated ischemic stroke lesion segmentation from 3D MRI. (arXiv:2209.09546v2 [eess.IV] UPDATED)
92. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**18** new papers in eess.IV:-) 
1. Subjective Assessment of **High Dynamic Range** Videos Under Different Ambient Conditions. (arXiv:2209.10005v1 [eess.IV])
2. Learning-Based Radiomic Prediction of Type 2 Diabetes Mellitus Using Image-Derived Phenotypes. (arXiv:2209.10043v1 [cs.LG])
3. Analytic Optimization-Based Microbubble Tracking in Ultrasound Super-Resolution Microscopy. (arXiv:2209.10057v1 [eess.IV])
4. Multi-Field De-interlacing using Deformable Convolution Residual Blocks and Self-Attention. (arXiv:2209.10192v1 [eess.IV])
5. Advanced Design Space Exploration for Joint Energy and Quality Optimization for VVC. (arXiv:2209.10211v1 [eess.IV])
6. HiFuse: Hierarchical Multi-Scale Feature Fusion Network for Medical Image Classification. (arXiv:2209.10218v1 [eess.IV])
7. Decoding Energy Modeling For Versatile Video Coding. (arXiv:2209.10266v1 [eess.IV])
8. Extending Video Decoding Energy Models for 360{\deg} and **HDR** Video Formats in HEVC. (arXiv:2209.10268v1 [eess.IV])
9. A Comparative Analysis of the Time and Energy Demand of Versatile Video Coding and High Efficiency Video Coding Reference Decoders. (arXiv:2209.10283v1 [eess.IV])
10. Artificial Intelligence-Based Image Reconstruction in Cardiac Magnetic Resonance. (arXiv:2209.10298v1 [eess.IV])
11. KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution. (arXiv:2209.10305v1 [cs.CV])
12. Rethinking the compositionality of point clouds through regularization in the hyperbolic space. (arXiv:2209.10318v1 [cs.CV])
13. Matched Quality Evaluation of Temporally Downsampled Videos with Non-Integer Factors. (arXiv:2209.10353v1 [eess.IV])
14. Consecutive Knowledge Meta-Adaptation Learning for Unsupervised Medical Diagnosis. (arXiv:2209.10425v1 [eess.IV])
15. Learning from Mixed Datasets: A Monotonic Image Quality Assessment Model. (arXiv:2209.10451v1 [cs.CV])
16. Recurrent Super-Resolution Method for Enhancing Low Quality Thermal Facial Data. (arXiv:2209.10489v1 [cs.CV])
17. Structural Gaussian Priors for Bayesian CT reconstruction of Subsea Pipes. (arXiv:2203.01030v2 [math.NA] UPDATED)
18. Automated ischemic stroke lesion segmentation from 3D MRI. (arXiv:2209.09546v2 [eess.IV] UPDATED)
## cs.LG
---
**147** new papers in cs.LG:-) 
1. Collaborative Anomaly Detection. (arXiv:2209.09923v1 [cs.LG])
2. Predicting Drug-Drug Interactions using Deep Generative Models on Graphs. (arXiv:2209.09941v1 [q-bio.BM])
3. Learning Acceptance Regions for Many Classes with Anomaly Detection. (arXiv:2209.09963v1 [stat.ML])
4. FoVolNet: Fast Volume Rendering using Foveated Deep Neural Networks. (arXiv:2209.09965v1 [cs.GR])
5. Power of Explanations: Towards automatic debiasing in hate speech detection. (arXiv:2209.09975v1 [cs.CL])
6. Learning Bilinear Models of Actuated Koopman Generators from Partially-Observed Trajectories. (arXiv:2209.09977v1 [math.DS])
7. Deep-Steiner: Learning to Solve the Euclidean Steiner Tree Problem. (arXiv:2209.09983v1 [cs.LG])
8. Learning the Propagation of Worms in Wireless Sensor Networks. (arXiv:2209.09984v1 [cs.LG])
9. Investigating and Mitigating Failure Modes in Physics-informed Neural Networks (PINNs). (arXiv:2209.09988v1 [cs.LG])
10. Optimizing Crop Management with Reinforcement Learning and Imitation Learning. (arXiv:2209.09991v1 [cs.AI])
11. Audit and Improve Robustness of Private Neural Networks on Encrypted Data. (arXiv:2209.09996v1 [cs.LG])
12. Robust, High-Rate Trajectory Tracking on Insect-Scale Soft-Actuated Aerial Robots with Deep-Learned Tube MPC. (arXiv:2209.10007v1 [cs.RO])
13. Intentional Choreography with Semi-Supervised Recurrent VAEs. (arXiv:2209.10010v1 [cs.LG])
14. Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics. (arXiv:2209.10015v1 [cs.LG])
15. Dataset: Impact Events for Structural Health Monitoring of a Plastic Thin Plate. (arXiv:2209.10018v1 [cs.LG])
16. Differentiable Safe Controller Design through Control Barrier Functions. (arXiv:2209.10034v1 [eess.SY])
17. Sanity Check for External Clustering Validation Benchmarks using Internal Validation Measures. (arXiv:2209.10042v1 [cs.LG])
18. Learning-Based Radiomic Prediction of Type 2 Diabetes Mellitus Using Image-Derived Phenotypes. (arXiv:2209.10043v1 [cs.LG])
19. Lamarckian Platform: Pushing the Boundaries of Evolutionary Reinforcement Learning towards Asynchronous Commercial Games. (arXiv:2209.10055v1 [cs.LG])
20. Mutual Information Learned Classifiers: an Information-theoretic Viewpoint of Training Deep Learning Classification Systems. (arXiv:2209.10058v1 [cs.LG])
21. Off-Policy Evaluation for Episodic Partially Observable Markov Decision Processes under Non-Parametric Models. (arXiv:2209.10064v1 [stat.ML])
22. Monotonic Neural Additive Models: Pursuing Regulated Machine Learning Models for Credit Scoring. (arXiv:2209.10070v1 [cs.LG])
23. On the Convergence Theory of Meta Reinforcement Learning with Personalized Policies. (arXiv:2209.10072v1 [cs.AI])
24. Can Shadows Reveal Biometric Information?. (arXiv:2209.10077v1 [cs.CV])
25. A Reinforcement Learning Framework with Description Language for Critical Driving Scenario Generation. (arXiv:2209.10078v1 [cs.AI])
26. Deep Double Descent via Smooth Interpolation. (arXiv:2209.10080v1 [cs.LG])
27. Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v1 [cs.LG])
28. Generalized Gloves of Neural Additive Models: Pursuing transparent and accurate machine learning models in finance. (arXiv:2209.10082v1 [cs.LG])
29. Federated Learning from Pre-Trained Models: A Contrastive Learning Approach. (arXiv:2209.10083v1 [cs.CR])
30. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v1 [eess.AS])
31. Variational Inference for Infinitely Deep Neural Networks. (arXiv:2209.10091v1 [cs.LG])
32. Projected Gradient Descent Algorithms for Solving Nonlinear Inverse Problems with Generative Priors. (arXiv:2209.10093v1 [stat.ML])
33. A Max-relevance-min-divergence Criterion for Data Discretization with Applications on Naive Bayes. (arXiv:2209.10095v1 [cs.LG])
34. NeurOLight: A Physics-Agnostic Neural Operator Enabling Parametric Photonic Device Simulation. (arXiv:2209.10098v1 [cs.ET])
35. Flashlight: Scalable Link Prediction with Effective Decoders. (arXiv:2209.10100v1 [cs.SI])
36. Multi-time Predictions of Wildfire Grid Map using Remote Sensing Local Data. (arXiv:2209.10102v1 [cs.LG])
37. Distributed Online Non-convex Optimization with Composite Regret. (arXiv:2209.10105v1 [cs.LG])
38. Extreme Multi-Domain, Multi-Task Learning With Unified Text-to-Text Transfer Transformers. (arXiv:2209.10106v1 [cs.CL])
39. Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning. (arXiv:2209.10113v1 [cs.LG])
40. A Comprehensive Survey on Trustworthy Recommender Systems. (arXiv:2209.10117v1 [cs.IR])
41. Measuring and Controlling Split Layer Privacy Leakage Using Fisher Information. (arXiv:2209.10119v1 [cs.CR])
42. Leak Detection in Natural Gas Pipeline Using Machine Learning Models. (arXiv:2209.10121v1 [cs.LG])
43. Exploring Modulated Detection Transformer as a Tool for Action Recognition in Videos. (arXiv:2209.10126v1 [cs.CV])
44. The ReturnZero System for VoxCeleb Speaker Recognition Challenge 2022. (arXiv:2209.10147v1 [eess.AS])
45. Detecting Crop Burning in India using Satellite Data. (arXiv:2209.10148v1 [cs.CV])
46. Machine Learning on generalized Complete Intersection Calabi-Yau Manifolds. (arXiv:2209.10157v1 [hep-th])
47. Chaotic Hedging with Iterated Integrals and Neural Networks. (arXiv:2209.10166v1 [q-fin.MF])
48. Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation. (arXiv:2209.10168v1 [cs.LG])
49. A data-centric approach to anomaly detection in layer-based additive manufacturing. (arXiv:2209.10178v1 [cs.LG])
50. Reconstructing Robot Operations via Radio-Frequency Side-Channel. (arXiv:2209.10179v1 [cs.CR])
51. On the convex formulations of robust Markov decision processes. (arXiv:2209.10187v1 [math.OC])
52. Performance Optimization for Variable Bitwidth Federated Learning in Wireless Networks. (arXiv:2209.10200v1 [cs.LG])
53. Fairness Reprogramming. (arXiv:2209.10222v1 [cs.LG])
54. Fingerprinting Robot Movements via Acoustic Side Channel. (arXiv:2209.10240v1 [cs.CR])
55. T5QL: Taming language models for SQL generation. (arXiv:2209.10254v1 [cs.LG])
56. Learning Hierarchical Metrical Structure Beyond Measures. (arXiv:2209.10259v1 [cs.SD])
57. Periodic Extrapolative Generalisation in Neural Networks. (arXiv:2209.10280v1 [cs.LG])
58. Tree Methods for Hierarchical Classification in Parallel. (arXiv:2209.10288v1 [cs.LG])
59. Fast Few shot Self-attentive Semi-supervised Political Inclination Prediction. (arXiv:2209.10292v1 [cs.CY])
60. Deep Learning for Multi-User MIMO Systems: Joint Design of Pilot, Limited Feedback, and Precoding. (arXiv:2209.10332v1 [cs.IT])
61. LCRL: Certified Policy Synthesis via Logically-Constrained Reinforcement Learning. (arXiv:2209.10341v1 [cs.LG])
62. On the Complexity of Finding Small Subgradients in Nonsmooth Optimization. (arXiv:2209.10346v1 [math.OC])
63. MulBot: Unsupervised Bot Detection Based on Multivariate Time Series. (arXiv:2209.10361v1 [cs.SI])
64. SoLar: Sinkhorn Label Refinery for Imbalanced Partial-Label Learning. (arXiv:2209.10365v1 [cs.LG])
65. Safety Metrics and Losses for Object Detection in Autonomous Driving. (arXiv:2209.10368v1 [cs.CV])
66. Approximating the full-field temperature evolution in 3D electronic systems from randomized "Minecraft" systems. (arXiv:2209.10369v1 [physics.comp-ph])
67. DARTSRepair: Core-failure-set Guided DARTS for Network Robustness to Common Corruptions. (arXiv:2209.10381v1 [cs.CV])
68. Robust Information Bottleneck for Task-Oriented Communication with Digital Modulation. (arXiv:2209.10382v1 [cs.IT])
69. GP-net: Grasp Proposal for Mobile Manipulators. (arXiv:2209.10404v1 [cs.RO])
70. Cross Project Software Vulnerability Detection via Domain Adaptation and Max-Margin Principle. (arXiv:2209.10406v1 [cs.CR])
71. An Information-Theoretic and Contrastive Learning-based Approach for Identifying Code Statements Causing Software Vulnerability. (arXiv:2209.10414v1 [cs.CR])
72. Approximate sampling and estimation of partition functions using neural networks. (arXiv:2209.10423v1 [cs.LG])
73. An NWDAF Approach to 5G Core Network Signaling Traffic: Analysis and Characterization. (arXiv:2209.10428v1 [cs.NI])
74. Partial Information Decomposition Reveals the Structure of Neural Representations. (arXiv:2209.10438v1 [cs.IT])
75. Off-Policy Risk Assessment in Markov Decision Processes. (arXiv:2209.10444v1 [cs.LG])
76. Hierarchical Decision Transformer. (arXiv:2209.10447v1 [cs.LG])
77. Learning from Mixed Datasets: A Monotonic Image Quality Assessment Model. (arXiv:2209.10451v1 [cs.CV])
78. Model-Free Reinforcement Learning for Asset Allocation. (arXiv:2209.10458v1 [q-fin.PM])
79. Sample, Crop, Track: Self-Supervised Mobile 3D Object Detection for Urban Driving LiDAR. (arXiv:2209.10471v1 [cs.CV])
80. Benchmarking energy consumption and latency for neuromorphic computing in condensed matter and particle physics. (arXiv:2209.10481v1 [cs.ET])
81. Towards a Standardised Performance Evaluation Protocol for Cooperative MARL. (arXiv:2209.10485v1 [cs.LG])
82. Recurrent Super-Resolution Method for Enhancing Low Quality Thermal Facial Data. (arXiv:2209.10489v1 [cs.CV])
83. Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees. (arXiv:2209.10492v1 [cs.CL])
84. Social-Inverse: Inverse Decision-making of Social Contagion Management with Task Migrations. (arXiv:2209.10493v1 [cs.LG])
85. Learning to Relight Portrait Images via a Virtual Light Stage and Synthetic-to-Real Adaptation. (arXiv:2209.10510v1 [cs.CV])
86. Improved Marginal Unbiased Score Expansion (MUSE) via Implicit Differentiation. (arXiv:2209.10512v1 [stat.ML])
87. Tab2vox: CNN-Based Multivariate Multilevel Demand Forecasting Framework by Tabular-To-Voxel Image Conversion. (arXiv:2209.10516v1 [stat.ML])
88. Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles Between Client Data Subspaces. (arXiv:2209.10526v1 [cs.LG])
89. Identification of Adaptive Driving Style Preference through Implicit Inputs in SAE L2 Vehicles. (arXiv:2209.10536v1 [cs.HC])
90. FedFOR: Stateless Heterogeneous Federated Learning with First-Order Regularization. (arXiv:2209.10537v1 [cs.LG])
91. DTR Bandit: Learning to Make Response-Adaptive Decisions With Low Regret. (arXiv:2005.02791v3 [stat.ML] UPDATED)
92. Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles. (arXiv:2103.03786v2 [cs.LG] UPDATED)
93. Probabilistic Robust Linear Quadratic Regulators with Gaussian Processes. (arXiv:2105.07668v2 [eess.SY] UPDATED)
94. Minimax Optimal Fixed-Budget Best Arm Identification in Linear Bandits. (arXiv:2105.13017v2 [cs.LG] UPDATED)
95. Scheduling Jobs with Stochastic Holding Costs. (arXiv:2105.13655v3 [cs.LG] UPDATED)
96. Universum GANs: Improving GANs through contradictions. (arXiv:2106.09946v2 [cs.LG] UPDATED)
97. Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness. (arXiv:2107.04642v7 [cs.CY] UPDATED)
98. Heterogeneous Treatment Effect Estimation using machine learning for Healthcare application: tutorial and benchmark. (arXiv:2109.12769v3 [cs.LG] UPDATED)
99. Estimating Potential Outcome Distributions with Collaborating Causal Networks. (arXiv:2110.01664v3 [stat.ML] UPDATED)
100. Causal Effect Variational Autoencoder with Uniform Treatment. (arXiv:2111.08656v2 [cs.LG] UPDATED)
101. Make an Omelette with Breaking Eggs: Zero-Shot Learning for Novel Attribute Synthesis. (arXiv:2111.14182v4 [cs.CV] UPDATED)
102. Transfer Learning with Jukebox for Music Source Separation. (arXiv:2111.14200v3 [eess.AS] UPDATED)
103. Reconstructing spectral functions via automatic differentiation. (arXiv:2111.14760v3 [hep-ph] UPDATED)
104. Efficient Calibration of Multi-Agent Simulation Models from Output Series with Bayesian Optimization. (arXiv:2112.03874v2 [q-fin.ST] UPDATED)
105. TECM: Transfer Learning-based Evidential C-Means Clustering. (arXiv:2112.10152v2 [cs.LG] UPDATED)
106. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v2 [cs.CV] UPDATED)
107. Reconfigurable Intelligent Surface Enabled Spatial Multiplexing with Fully Convolutional Network. (arXiv:2201.02834v2 [eess.SP] UPDATED)
108. Are Attention Networks More Robust? Towards Exact Robustness Verification for Attention Networks. (arXiv:2202.03932v2 [cs.LG] UPDATED)
109. Bias-Scalable Near-Memory CMOS Analog Processor for Machine Learning. (arXiv:2202.05022v2 [cs.ET] UPDATED)
110. Benchmarking Online Sequence-to-Sequence and Character-based Handwriting Recognition from IMU-Enhanced Pens. (arXiv:2202.07036v3 [cs.LG] UPDATED)
111. Data Augmentation for Deep Graph Learning: A Survey. (arXiv:2202.08235v2 [cs.LG] UPDATED)
112. FLAME: Federated Learning Across Multi-device Environments. (arXiv:2202.08922v2 [cs.LG] UPDATED)
113. Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance. (arXiv:2202.12387v4 [cs.LG] UPDATED)
114. Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications. (arXiv:2202.12396v6 [math.OC] UPDATED)
115. A Simple Self-Supervised ECG Representation Learning Method via Manipulated Temporal-Spatial Reverse Detection. (arXiv:2202.12458v2 [cs.LG] UPDATED)
116. Data Augmentation as Feature Manipulation. (arXiv:2203.01572v2 [cs.LG] UPDATED)
117. Multi-trial Neural Architecture Search with Lottery Tickets. (arXiv:2203.04300v2 [cs.LG] UPDATED)
118. Amortized Projection Optimization for Sliced Wasserstein Generative Models. (arXiv:2203.13417v2 [stat.ML] UPDATED)
119. Protein language models trained on multiple sequence alignments learn phylogenetic relationships. (arXiv:2203.15465v2 [q-bio.BM] UPDATED)
120. Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution. (arXiv:2204.01188v2 [cs.CV] UPDATED)
121. EXIT: Extrapolation and Interpolation-based Neural Controlled Differential Equations for Time-series Classification and Forecasting. (arXiv:2204.08771v2 [cs.LG] UPDATED)
122. Cliff Diving: Exploring Reward Surfaces in Reinforcement Learning Environments. (arXiv:2205.07015v3 [cs.LG] UPDATED)
123. Can You Still See Me?: Reconstructing Robot Operations Over End-to-End Encrypted Channels. (arXiv:2205.08426v2 [cs.CR] UPDATED)
124. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v3 [cs.LG] UPDATED)
125. Variational Transformer: A Framework Beyond the Trade-off between Accuracy and Diversity for Image Captioning. (arXiv:2205.14458v2 [cs.CV] UPDATED)
126. A Human-Centric Take on Model Monitoring. (arXiv:2206.02868v2 [cs.LG] UPDATED)
127. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v3 [cs.AI] UPDATED)
128. tntorch: Tensor Network Learning with PyTorch. (arXiv:2206.11128v2 [cs.LG] UPDATED)
129. Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v3 [cs.CV] UPDATED)
130. SC2EGSet: StarCraft II Esport Replay and Game-state Dataset. (arXiv:2207.03428v2 [cs.LG] UPDATED)
131. Multi-Model Federated Learning with Provable Guarantees. (arXiv:2207.04330v6 [cs.LG] UPDATED)
132. Improving the Performance of Robust Control through Event-Triggered Learning. (arXiv:2207.14252v2 [eess.SY] UPDATED)
133. Bayesian regularization of empirical MDPs. (arXiv:2208.02362v3 [cs.LG] UPDATED)
134. Predicting the protein-ligand affinity from molecular dynamics trajectories. (arXiv:2208.10230v2 [q-bio.BM] UPDATED)
135. A simple learning agent interacting with an agent-based market model. (arXiv:2208.10434v3 [q-fin.TR] UPDATED)
136. Convex integer optimization with Frank-Wolfe methods. (arXiv:2208.11010v4 [math.OC] UPDATED)
137. Transformer-Boosted Anomaly Detection with Fuzzy Hashes. (arXiv:2208.11367v2 [cs.CR] UPDATED)
138. Information FOMO: The unhealthy fear of missing out on information. A method for removing misleading data for healthier models. (arXiv:2208.13080v2 [cs.LG] UPDATED)
139. Deep Labeling of fMRI Brain Networks Using Cloud Based Processing. (arXiv:2209.08200v2 [cs.LG] UPDATED)
140. In progress. (arXiv:2209.08860v2 [stat.ML] UPDATED)
141. Revisiting Embeddings for Graph Neural Networks. (arXiv:2209.09338v2 [cs.LG] UPDATED)
142. Attributed Network Embedding Model for Exposing COVID-19 Spread Trajectory Archetypes. (arXiv:2209.09448v2 [cs.LG] UPDATED)
143. Streaming Encoding Algorithms for Scalable Hyperdimensional Computing. (arXiv:2209.09868v2 [cs.LG] UPDATED)
144. A Systematic Literature Review on Process-Aware Recommender Systems. (arXiv:2103.16654v2 [cs.IR] CROSS LISTED)
145. Calibrated Forecasts: The Minimax Proof. (arXiv:2209.05863v1 [econ.TH] CROSS LISTED)
146. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)
147. Closing the Gender Wage Gap: Adversarial Fairness in Job Recommendation. (arXiv:2209.09592v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**74** new papers in cs.AI:-) 
1. Comparative analysis of real bugs in open-source Machine Learning projects -- A Registered Report. (arXiv:2209.09932v1 [cs.SE])
2. A Demonstration of Over-the-Air Computation for Federated Edge Learning. (arXiv:2209.09954v1 [eess.SP])
3. jsdp: a Java Stochastic Dynamic Programming Library. (arXiv:2209.09979v1 [cs.AI])
4. Optimizing Crop Management with Reinforcement Learning and Imitation Learning. (arXiv:2209.09991v1 [cs.AI])
5. Macro-Action-Based Multi-Agent/Robot Deep Reinforcement Learning under Partial Observability. (arXiv:2209.10003v1 [cs.AI])
6. Metadata Archaeology: Unearthing Data Subsets by Leveraging Training Dynamics. (arXiv:2209.10015v1 [cs.LG])
7. Setting the rhythm scene: deep learning-based drum loop generation from arbitrary language cues. (arXiv:2209.10016v1 [cs.SD])
8. Learning-Based Radiomic Prediction of Type 2 Diabetes Mellitus Using Image-Derived Phenotypes. (arXiv:2209.10043v1 [cs.LG])
9. Lamarckian Platform: Pushing the Boundaries of Evolutionary Reinforcement Learning towards Asynchronous Commercial Games. (arXiv:2209.10055v1 [cs.LG])
10. Generate rather than Retrieve: Large Language Models are Strong Context Generators. (arXiv:2209.10063v1 [cs.CL])
11. On the Convergence Theory of Meta Reinforcement Learning with Personalized Policies. (arXiv:2209.10072v1 [cs.AI])
12. A Reinforcement Learning Framework with Description Language for Critical Driving Scenario Generation. (arXiv:2209.10078v1 [cs.AI])
13. Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v1 [cs.LG])
14. Generalized Gloves of Neural Additive Models: Pursuing transparent and accurate machine learning models in finance. (arXiv:2209.10082v1 [cs.LG])
15. Federated Learning from Pre-Trained Models: A Contrastive Learning Approach. (arXiv:2209.10083v1 [cs.CR])
16. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v1 [eess.AS])
17. On the benefits of self-taught learning for brain decoding. (arXiv:2209.10099v1 [cs.NE])
18. Flashlight: Scalable Link Prediction with Effective Decoders. (arXiv:2209.10100v1 [cs.SI])
19. Asynchronous Actor-Critic for Multi-Agent Reinforcement Learning. (arXiv:2209.10113v1 [cs.LG])
20. A Comprehensive Survey on Trustworthy Recommender Systems. (arXiv:2209.10117v1 [cs.IR])
21. Interpretable Selective Learning in Credit Risk. (arXiv:2209.10127v1 [q-fin.CP])
22. A Systematic Literature Review of Soft Computing Techniques for Software Maintainability Prediction: State-of-the-Art, Challenges and Future Directions. (arXiv:2209.10131v1 [cs.SE])
23. PePe: Personalized Post-editing Model utilizing User-generated Post-edits. (arXiv:2209.10139v1 [cs.CL])
24. The ReturnZero System for VoxCeleb Speaker Recognition Challenge 2022. (arXiv:2209.10147v1 [eess.AS])
25. DDGHM: Dual Dynamic Graph with Hybrid Metric Training for Cross-Domain Sequential Recommendation. (arXiv:2209.10163v1 [cs.IR])
26. Improving Generalizability of Graph Anomaly Detection Models via Data Augmentation. (arXiv:2209.10168v1 [cs.LG])
27. Evaluation of Look-ahead Economic Dispatch Using Reinforcement Learning. (arXiv:2209.10207v1 [eess.SY])
28. Fairness Reprogramming. (arXiv:2209.10222v1 [cs.LG])
29. Dynamic Time-Alignment of Dimensional Annotations of Emotion using Recurrent Neural Networks. (arXiv:2209.10223v1 [cs.SD])
30. Periodic Extrapolative Generalisation in Neural Networks. (arXiv:2209.10280v1 [cs.LG])
31. Tree Methods for Hierarchical Classification in Parallel. (arXiv:2209.10288v1 [cs.LG])
32. Fast Few shot Self-attentive Semi-supervised Political Inclination Prediction. (arXiv:2209.10292v1 [cs.CY])
33. Analyzing Robustness of Angluin's L* Algorithm in Presence of Noise. (arXiv:2209.10315v1 [cs.FL])
34. Controller Synthesis for Timeline-based Games. (arXiv:2209.10319v1 [cs.AI])
35. LCRL: Certified Policy Synthesis via Logically-Constrained Reinforcement Learning. (arXiv:2209.10341v1 [cs.LG])
36. Partially Observable Markov Decision Processes in Robotics: A Survey. (arXiv:2209.10342v1 [cs.RO])
37. Momentum Adversarial Distillation: Handling Large Distribution Shifts in Data-Free Knowledge Distillation. (arXiv:2209.10359v1 [cs.CV])
38. MulBot: Unsupervised Bot Detection Based on Multivariate Time Series. (arXiv:2209.10361v1 [cs.SI])
39. Safety Metrics and Losses for Object Detection in Autonomous Driving. (arXiv:2209.10368v1 [cs.CV])
40. Approximating the full-field temperature evolution in 3D electronic systems from randomized "Minecraft" systems. (arXiv:2209.10369v1 [physics.comp-ph])
41. WeLM: A Well-Read Pre-trained Language Model for Chinese. (arXiv:2209.10372v1 [cs.CL])
42. Incremental Updates of Generalized Hypertree Decompositions. (arXiv:2209.10375v1 [cs.AI])
43. Cross Project Software Vulnerability Detection via Domain Adaptation and Max-Margin Principle. (arXiv:2209.10406v1 [cs.CR])
44. An Information-Theoretic and Contrastive Learning-based Approach for Identifying Code Statements Causing Software Vulnerability. (arXiv:2209.10414v1 [cs.CR])
45. Sar Ship Detection based on **Swin** Transformer and Feature **Enhancement** Feature Pyramid Network. (arXiv:2209.10421v1 [cs.CV])
46. Partial Information Decomposition Reveals the Structure of Neural Representations. (arXiv:2209.10438v1 [cs.IT])
47. Off-Policy Risk Assessment in Markov Decision Processes. (arXiv:2209.10444v1 [cs.LG])
48. Hierarchical Decision Transformer. (arXiv:2209.10447v1 [cs.LG])
49. Towards a Standardised Performance Evaluation Protocol for Cooperative MARL. (arXiv:2209.10485v1 [cs.LG])
50. Summarization Programs: Interpretable Abstractive Summarization with Neural Modular Trees. (arXiv:2209.10492v1 [cs.CL])
51. Improved Marginal Unbiased Score Expansion (MUSE) via Implicit Differentiation. (arXiv:2209.10512v1 [stat.ML])
52. Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles Between Client Data Subspaces. (arXiv:2209.10526v1 [cs.LG])
53. FedFOR: Stateless Heterogeneous Federated Learning with First-Order Regularization. (arXiv:2209.10537v1 [cs.LG])
54. Recursive Rules with Aggregation: A Simple Unified Semantics. (arXiv:2007.13053v3 [cs.DB] UPDATED)
55. Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles. (arXiv:2103.03786v2 [cs.LG] UPDATED)
56. Universum GANs: Improving GANs through contradictions. (arXiv:2106.09946v2 [cs.LG] UPDATED)
57. Efficient Calibration of Multi-Agent Simulation Models from Output Series with Bayesian Optimization. (arXiv:2112.03874v2 [q-fin.ST] UPDATED)
58. SPViT: Enabling Faster Vision Transformers via Soft Token Pruning. (arXiv:2112.13890v2 [cs.CV] UPDATED)
59. Are Attention Networks More Robust? Towards Exact Robustness Verification for Attention Networks. (arXiv:2202.03932v2 [cs.LG] UPDATED)
60. Bias-Scalable Near-Memory CMOS Analog Processor for Machine Learning. (arXiv:2202.05022v2 [cs.ET] UPDATED)
61. FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects. (arXiv:2205.04382v3 [cs.RO] UPDATED)
62. Cliff Diving: Exploring Reward Surfaces in Reinforcement Learning Environments. (arXiv:2205.07015v3 [cs.LG] UPDATED)
63. Multi-Object Grasping in the Plane. (arXiv:2206.00229v2 [cs.RO] UPDATED)
64. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v3 [cs.AI] UPDATED)
65. Connecting Algorithmic Research and Usage Contexts: A Perspective of Contextualized Evaluation for Explainable AI. (arXiv:2206.10847v3 [cs.AI] UPDATED)
66. Rethinking Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2207.00067v2 [cs.CV] UPDATED)
67. SC2EGSet: StarCraft II Esport Replay and Game-state Dataset. (arXiv:2207.03428v2 [cs.LG] UPDATED)
68. Exploring Wasserstein Distance across Concept Embeddings for Ontology Matching. (arXiv:2207.11324v2 [cs.AI] UPDATED)
69. Pyramidal Predictive Network: A Model for Visual-frame Prediction Based on Predictive Coding Theory. (arXiv:2208.07021v2 [cs.CV] UPDATED)
70. Improving Assistive Robotics with Deep Reinforcement Learning. (arXiv:2209.02160v2 [cs.RO] UPDATED)
71. A Survey on Generative Diffusion Model. (arXiv:2209.02646v5 [cs.AI] UPDATED)
72. A Closer Look at Novel Class Discovery from the Labeled Set. (arXiv:2209.09120v2 [cs.CV] UPDATED)
73. Deep Q-Network for AI Soccer. (arXiv:2209.09491v2 [cs.AI] UPDATED)
74. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV] CROSS LISTED)

