# Your interest papers
---
## cs.CV
---
### Modeling Indirect Illumination for Inverse Rendering. (arXiv:2204.06837v1 [cs.CV])
- Authors : Yuanqing Zhang, Jiaming Sun, Xingyi He, Huan Fu, Rongfei Jia, Xiaowei Zhou
- Link : [http://arxiv.org/abs/2204.06837](http://arxiv.org/abs/2204.06837)
> ABSTRACT  :  Recent advances in **implicit neural representation**s and differentiable rendering make it possible to simultaneously recover the geometry and materials of an object from multi-view RGB images captured under unknown static illumination. Despite the promising results achieved, indirect illumination is rarely modeled in previous methods, as it requires expensive recursive path tracing which makes the inverse rendering computationally intractable. In this paper, we propose a novel approach to efficiently recovering spatially-varying indirect illumination. The key insight is that indirect illumination can be conveniently derived from the neural radiance field learned from input images instead of being estimated jointly with direct illumination and materials. By properly modeling the indirect illumination and visibility of direct illumination, interreflection- and shadow-free albedo can be recovered. The experiments on both synthetic and real data demonstrate the superior performance of our approach compared to previous work and its capability to synthesize realistic renderings under novel viewpoints and illumination. Our code and data are available at https://zju3dv.github.io/invrender/.  
### Residual **Swin** Transformer Channel Attention Network for Image Demosaicing. (arXiv:2204.07098v1 [cs.CV])
- Authors : Wenzhu Xing, Karen Egiazarian
- Link : [http://arxiv.org/abs/2204.07098](http://arxiv.org/abs/2204.07098)
> ABSTRACT  :  Image demosaicing is problem of interpolating full- resolution color images from raw sensor (color filter array) data. During last decade, deep neural networks have been widely used in image **restoration**, and in particular, in demosaicing, attaining significant performance improvement. In recent years, vision transformers have been designed and successfully used in various computer vision applications. One of the recent methods of image **restoration** based on a **Swin** Transformer (ST), **Swin**IR, demonstrates state-of-the-art performance with a smaller number of parameters than neural network-based methods. Inspired by the success of **Swin**IR, we propose in this paper a novel **Swin** Transformer-based network for image demosaicing, called RSTCANet. To extract image features, RSTCANet stacks several residual **Swin** Transformer Channel Attention blocks (RSTCAB), introducing the channel attention for each two successive ST blocks. Extensive experiments demonstrate that RSTCANet out- performs state-of-the-art image demosaicing methods, and has a smaller number of parameters.  
### Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We will open-source our checkpoints, training script, configurations, and our CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer .  
### MiniViT: Compressing Vision Transformers with Weight Multiplexing. (arXiv:2204.07154v1 [cs.CV])
- Authors : Jinnian Zhang, Houwen Peng, Kan Wu, Mengchen Liu, Bin Xiao, Jianlong Fu, Lu Yuan
- Link : [http://arxiv.org/abs/2204.07154](http://arxiv.org/abs/2204.07154)
> ABSTRACT  :  Vision Transformer (ViT) models have recently drawn much attention in computer vision due to their high model capability. However, ViT models suffer from huge number of parameters, restricting their applicability on devices with limited memory. To alleviate this problem, we propose MiniViT, a new compression framework, which achieves parameter reduction in vision transformers while retaining the same performance. The central idea of MiniViT is to multiplex the weights of consecutive transformer blocks. More specifically, we make the weights shared across layers, while imposing a transformation on the weights to increase diversity. Weight distillation over self-attention is also applied to transfer knowledge from large-scale ViT models to weight-multiplexed compact models. Comprehensive experiments demonstrate the efficacy of MiniViT, showing that it can reduce the size of the pre-trained **Swin**-B transformer by 48\%, while achieving an increase of 1.0\% in Top-1 accuracy on ImageNet. Moreover, using a single-layer of parameters, MiniViT is able to compress DeiT-B by 9.7 times from 86M to 9M parameters, without seriously compromising the performance. Finally, we verify the transferability of MiniViT by reporting its performance on downstream benchmarks. Code and models are available at here.  
### Burst Image **Restoration** and **Enhancement**. (arXiv:2110.03680v2 [cs.CV] UPDATED)
- Authors : Akshay Dudhane, Syed Waqas, Salman Khan, Fahad Shahbaz, Hsuan Yang
- Link : [http://arxiv.org/abs/2110.03680](http://arxiv.org/abs/2110.03680)
> ABSTRACT  :  Modern handheld devices can acquire burst image sequence in a quick succession. However, the individual acquired frames suffer from multiple degradations and are misaligned due to camera shake and object motions. The goal of Burst Image **Restoration** is to effectively combine complimentary cues across multiple burst frames to generate high-quality outputs. Towards this goal, we develop a novel approach by solely focusing on the effective information exchange between burst frames, such that the degradations get filtered out while the actual scene details are preserved and enhanced. Our central idea is to create a set of pseudo-burst features that combine complementary information from all the input burst frames to seamlessly exchange information. However, the pseudo-burst cannot be successfully created unless the individual burst frames are properly aligned to discount inter-frame movements. Therefore, our approach initially extracts pre-processed features from each burst frame and matches them using an edge-boosting burst alignment module. The pseudo-burst features are then created and enriched using multi-scale contextual information. Our final step is to adaptively aggregate information from the pseudo-burst features to progressively increase resolution in multiple stages while merging the pseudo-burst features. In comparison to existing works that usually follow a late fusion scheme with single-stage upsampling, our approach performs favorably, delivering state-of-the-art performance on burst superresolution, burst **low-light** image **enhancement**, and burst denoising tasks. The source code and pre-trained models are available at \url{https://github.com/akshaydudhane16/BIPNet}.  
### Distill and De-bias: Mitigating Bias in Face Recognition using Knowledge Distillation. (arXiv:2112.09786v2 [cs.CV] UPDATED)
- Authors : Prithviraj Dhar, Joshua Gleason, Aniket Roy, Jonathon Phillips, Rama Chellappa
- Link : [http://arxiv.org/abs/2112.09786](http://arxiv.org/abs/2112.09786)
> ABSTRACT  :  Face recognition networks generally demonstrate bias with respect to sensitive attributes like gender, skintone etc. For gender and skintone, we observe that the regions of the face that a network attends to vary by the category of an attribute. This might contribute to bias. Building on this intuition, we propose a novel distillation-based approach called Distill and De-bias (D&amp;D) to enforce a network to attend to similar face regions, irrespective of the attribute category. In D&amp;D, we train a teacher network on images from one category of an attribute; e.g. light skintone. Then distilling information from the teacher, we train a student network on images of the remaining category; e.g., **dark** skintone. A feature-level distillation loss constrains the student network to generate teacher-like representations. This allows the student network to attend to similar face regions for all attribute categories and enables it to reduce bias. We also propose a second distillation step on top of D&amp;D, called D&amp;D++. For the D&amp;D++ network, we distill the `un-biasedness' of the D&amp;D network into a new student network, the D&amp;D++ network. We train the new network on all attribute categories; e.g., both light and **dark** skintones. This helps us train a network that is less biased for an attribute, while obtaining higher face verification performance than D&amp;D. We show that D&amp;D++ outperforms existing baselines in reducing gender and skintone bias on the IJB-C dataset, while obtaining higher face verification performance than existing adversarial de-biasing methods. We evaluate the effectiveness of our proposed methods on two state-of-the-art face recognition networks: Crystalface and ArcFace.  
### Unifying Motion Deblurring and Frame Interpolation with Events. (arXiv:2203.12178v2 [cs.CV] UPDATED)
- Authors : Xiang Zhang, Lei Yu
- Link : [http://arxiv.org/abs/2203.12178](http://arxiv.org/abs/2203.12178)
> ABSTRACT  :  Slow shutter speed and long **exposure** time of frame-based cameras often cause visual blur and loss of inter-frame information, degenerating the overall quality of captured videos. To this end, we present a unified framework of event-based motion deblurring and frame interpolation for blurry video **enhancement**, where the extremely low latency of events is leveraged to alleviate motion blur and facilitate intermediate frame prediction. Specifically, the mapping relation between blurry frames and sharp latent images is first predicted by a learnable double integral network, and a fusion network is then proposed to refine the coarse results via utilizing the information from consecutive blurry inputs and the concurrent events. By exploring the mutual constraints among blurry frames, latent images, and event streams, we further propose a self-supervised learning framework to enable network training with real-world blurry videos and events. Extensive experiments demonstrate that our method compares favorably against the state-of-the-art approaches and achieves remarkable performance on both synthetic and real-world datasets.  
### HunYuan_tvr for Text-Video Retrivial. (arXiv:2204.03382v3 [cs.CV] UPDATED)
- Authors : Shaobo Min, Weijie Kong, Cheng Tu, Dihong Gong, Chengfei Cai, Wenzhe Zhao, Chenyang Liu, Sixiao Zheng, Hongfa Wang, Zhifeng Li, Wei Liu
- Link : [http://arxiv.org/abs/2204.03382](http://arxiv.org/abs/2204.03382)
> ABSTRACT  :  Text-Video Retrieval plays an important role in multi-modal understanding and has attracted increasing attention in recent years. Most existing methods focus on constructing contrastive pairs between whole videos and complete caption sentences, while ignoring fine-grained cross-modal relationships, e.g., short clips and phrases or single frame and word. In this paper, we propose a novel method, named HunYuan\_tvr, to explore hierarchical cross-modal interactions by simultaneously exploring video-sentence, clip-phrase, and frame-word relationships. Considering intrinsic semantic relations between frames, HunYuan\_tvr first performs self-attention to explore frame-wise correlations and adaptively clusters correlated frames into clip-level representations. Then, the clip-wise correlation is explored to aggregate clip representations into a compact one to describe the video globally. In this way, we can construct hierarchical video representations for frame-clip-video granularities, and also explore word-wise correlations to form word-phrase-sentence embeddings for the text modality. Finally, hierarchical contrastive learning is designed to explore cross-modal relationships,~\emph{i.e.,} frame-word, clip-phrase, and video-sentence, which enables HunYuan\_tvr to achieve a comprehensive multi-modal understanding. Further boosted by adaptive label denosing and marginal sample **enhancement**, HunYuan\_tvr obtains new state-of-the-art results on various benchmarks, e.g., Rank@1 of 55.0%, 57.8%, 29.7%, 52.1%, and 57.3% on MSR-VTT, MSVD, LSMDC, DiDemo, and ActivityNet respectively.  
## eess.IV
---
### Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])
- Authors : Harikrishna Warrier, Yogesh Gupta
- Link : [http://arxiv.org/abs/2204.07062](http://arxiv.org/abs/2204.07062)
> ABSTRACT  :  Content based providers transmits **real time** complex signal such as video data from one region to another. During this transmission process, the signals usually end up distorted or degraded where the actual information present in the video is lost. This normally happens in the streaming video services applications. Hence there is a need to know the level of degradation that happened in the receiver side. This video degradation can be estimated by network state parameters like data rate and packet loss values. Our proposed solution vQoS GAN (video Quality of Service Generative Adversarial Network) can estimate the network state parameters from the degraded received video data using a deep learning approach of semi supervised generative adversarial network algorithm. A robust and unique design of deep learning network model has been trained with the video data along with data rate and packet loss class labels and achieves over 95 percent of training accuracy. The proposed semi supervised generative adversarial network can additionally reconstruct the degraded video data to its original form for a better end user experience.  
### Residual **Swin** Transformer Channel Attention Network for Image Demosaicing. (arXiv:2204.07098v1 [cs.CV])
- Authors : Wenzhu Xing, Karen Egiazarian
- Link : [http://arxiv.org/abs/2204.07098](http://arxiv.org/abs/2204.07098)
> ABSTRACT  :  Image demosaicing is problem of interpolating full- resolution color images from raw sensor (color filter array) data. During last decade, deep neural networks have been widely used in image **restoration**, and in particular, in demosaicing, attaining significant performance improvement. In recent years, vision transformers have been designed and successfully used in various computer vision applications. One of the recent methods of image **restoration** based on a **Swin** Transformer (ST), **Swin**IR, demonstrates state-of-the-art performance with a smaller number of parameters than neural network-based methods. Inspired by the success of **Swin**IR, we propose in this paper a novel **Swin** Transformer-based network for image demosaicing, called RSTCANet. To extract image features, RSTCANet stacks several residual **Swin** Transformer Channel Attention blocks (RSTCAB), introducing the channel attention for each two successive ST blocks. Extensive experiments demonstrate that RSTCANet out- performs state-of-the-art image demosaicing methods, and has a smaller number of parameters.  
## cs.LG
---
### Control-oriented meta-learning. (arXiv:2204.06716v1 [cs.RO])
- Authors : Navid Azizan, Jacques Slotine, Marco Pavone
- Link : [http://arxiv.org/abs/2204.06716](http://arxiv.org/abs/2204.06716)
> ABSTRACT  :  **Real-time** adaptation is imperative to the control of robots operating in complex, dynamic environments. Adaptive control laws can endow even nonlinear systems with good trajectory tracking performance, provided that any uncertain dynamics terms are linearly parameterizable with known nonlinear features. However, it is often difficult to specify such features a priori, such as for aerodynamic disturbances on rotorcraft or interaction forces between a manipulator arm and various objects. In this paper, we turn to data-driven modeling with neural networks to learn, offline from past data, an adaptive controller with an internal parametric model of these nonlinear features. Our key insight is that we can better prepare the controller for deployment with control-oriented meta-learning of features in closed-loop simulation, rather than regression-oriented meta-learning of features to fit input-output data. Specifically, we meta-learn the adaptive controller with closed-loop tracking simulation as the base-learner and the average tracking error as the meta-objective. With both fully-actuated and underactuated nonlinear planar rotorcraft subject to wind, we demonstrate that our adaptive controller outperforms other controllers trained with regression-oriented meta-learning when deployed in closed-loop for trajectory tracking control.  
### Shedding New Light on the Language of the **Dark** Web. (arXiv:2204.06885v1 [cs.CL])
- Authors : Youngjin Jin, Eugene Jang, Yongjae Lee, Seungwon Shin, Woo Chung
- Link : [http://arxiv.org/abs/2204.06885](http://arxiv.org/abs/2204.06885)
> ABSTRACT  :  The hidden nature and the limited accessibility of the **Dark** Web, combined with the lack of public datasets in this domain, make it difficult to study its inherent characteristics such as linguistic properties. Previous works on text classification of **Dark** Web domain have suggested that the use of deep neural models may be ineffective, potentially due to the linguistic differences between the **Dark** and Surface Webs. However, not much work has been done to uncover the linguistic characteristics of the **Dark** Web. This paper introduces CoDA, a publicly available **Dark** Web dataset consisting of 10000 web documents tailored towards text-based **Dark** Web analysis. By leveraging CoDA, we conduct a thorough linguistic analysis of the **Dark** Web and examine the textual differences between the **Dark** Web and the Surface Web. We also assess the performance of various methods of **Dark** Web page classification. Finally, we compare CoDA with an existing public **Dark** Web dataset and evaluate their suitability for various use cases.  
### Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])
- Authors : Harikrishna Warrier, Yogesh Gupta
- Link : [http://arxiv.org/abs/2204.07062](http://arxiv.org/abs/2204.07062)
> ABSTRACT  :  Content based providers transmits **real time** complex signal such as video data from one region to another. During this transmission process, the signals usually end up distorted or degraded where the actual information present in the video is lost. This normally happens in the streaming video services applications. Hence there is a need to know the level of degradation that happened in the receiver side. This video degradation can be estimated by network state parameters like data rate and packet loss values. Our proposed solution vQoS GAN (video Quality of Service Generative Adversarial Network) can estimate the network state parameters from the degraded received video data using a deep learning approach of semi supervised generative adversarial network algorithm. A robust and unique design of deep learning network model has been trained with the video data along with data rate and packet loss class labels and achieves over 95 percent of training accuracy. The proposed semi supervised generative adversarial network can additionally reconstruct the degraded video data to its original form for a better end user experience.  
### Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We will open-source our checkpoints, training script, configurations, and our CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer .  
### Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v3 [cs.LG] UPDATED)
- Authors : Jiying Zhang, Yuzhao Chen, Xi Xiao, Runiu Lu, Tao Xia
- Link : [http://arxiv.org/abs/2106.06666](http://arxiv.org/abs/2106.06666)
> ABSTRACT  :  Hypergraph Convolutional Neural Networks (HGCNNs) have demonstrated their potential in modeling high-order relations preserved in graph-structured data. However, most existing convolution filters are localized and determined by the pre-defined initial hypergraph topology, neglecting to explore implicit and long-range relations in real-world data. In this paper, we propose the first learning-based method tailored for constructing adaptive hypergraph structure, termed HypERgrAph Laplacian aDaptor (HERALD), which serves as a generic plug-and-play module for improving the representational power of HGCNNs.Specifically, HERALD adaptively optimizes the adjacency relationship between vertices and hyperedges in an end-to-end manner and thus the task-aware hypergraph is learned. Furthermore, HERALD employs the self-attention mechanism to capture the non-local paired-nodes relation. Extensive experiments on various popular hypergraph datasets for node classification and graph classification tasks demonstrate that our approach obtains consistent and considerable performance **enhancement**, proving its effectiveness and generalization ability.  
### **Real-time** Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)
- Authors : Shelly Wang, Samuel Marchal
- Link : [http://arxiv.org/abs/2106.08746](http://arxiv.org/abs/2106.08746)
> ABSTRACT  :  Recent work has shown that deep reinforcement learning (DRL) policies are vulnerable to adversarial perturbations. Adversaries can mislead policies of DRL agents by perturbing the state of the environment observed by the agents. Existing attacks are feasible in principle but face challenges in practice, either by being too slow to fool DRL policies in **real time** or by modifying past observations stored in the agent's memory. We show that using the Universal Adversarial Perturbation (UAP) method to compute perturbations, independent of the individual inputs to which they are applied to, can fool DRL policies effectively and in **real time**. We describe three such attack variants. Via an extensive evaluation using three Atari 2600 games, we show that our attacks are effective, as they fully degrade the performance of three different DRL agents (up to 100%, even when the $l_\infty$ bound on the perturbation is as small as 0.01). It is faster compared to the response time (0.6ms on average) of different DRL policies, and considerably faster than prior attacks using adversarial perturbations (1.8ms on average). We also show that our attack technique is efficient, incurring an online computational cost of 0.027ms on average. Using two further tasks involving robotic movement, we confirm that our results generalize to more complex DRL tasks. Furthermore, we demonstrate that the effectiveness of known defenses diminishes against universal perturbations. We propose an effective technique that detects all known adversarial perturbations against DRL policies, including all the universal perturbations presented in this paper.  
### DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v3 [physics.comp-ph] UPDATED)
- Authors : Lidong Fang, Pei Ge, **Lei Zhang**, Huan Lei
- Link : [http://arxiv.org/abs/2112.14798](http://arxiv.org/abs/2112.14798)
> ABSTRACT  :  A long standing problem in the modeling of non-Newtonian hydrodynamics of polymeric flows is the availability of reliable and interpretable hydrodynamic models that faithfully encode the underlying micro-scale polymer dynamics. The main complication arises from the long polymer relaxation time, the complex molecular structure and heterogeneous interaction. DeePN$^2$, a deep learning-based non-Newtonian hydrodynamic model, has been proposed and has shown some success in systematically passing the micro-scale structural mechanics information to the macro-scale hydrodynamics for suspensions with simple polymer conformation and bond potential. The model retains a multi-scaled nature by mapping the polymer configurations into a set of symmetry-preserving macro-scale features. The extended constitutive laws for these macro-scale features can be directly learned from the kinetics of their micro-scale counterparts. In this paper, we develop DeePN$^2$ using more complex micro-structural models. We show that DeePN$^2$ can faithfully capture the broadly overlooked viscoelastic differences arising from the specific molecular structural mechanics without human intervention.  
### Receptive Field Analysis of Temporal Convolutional Networks for Monaural Speech Dereverberation. (arXiv:2204.06439v2 [cs.SD] UPDATED)
- Authors : William Ravenscroft, Stefan Goetze, Thomas Hain
- Link : [http://arxiv.org/abs/2204.06439](http://arxiv.org/abs/2204.06439)
> ABSTRACT  :  Speech dereverberation is often an important requirement in robust speech processing tasks. Supervised deep learning (DL) models give state-of-the-art performance for single-channel speech dereverberation. Temporal convolutional networks (TCNs) are commonly used for sequence modelling in speech **enhancement** tasks. A feature of TCNs is that they have a receptive field (RF) dependant on the specific model configuration which determines the number of input frames that can be observed to produce an individual output frame. It has been shown that TCNs are capable of performing dereverberation of simulated speech data, however a thorough analysis, especially with focus on the RF is yet lacking in the literature. This paper analyses dereverberation performance depending on the model size and the RF of TCNs. Experiments using the WHAMR corpus which is extended to include room impulse responses (RIRs) with larger T60 values demonstrate that a larger RF can have significant improvement in performance when training smaller TCN models. It is also demonstrated that TCNs benefit from a wider RF when dereverberating RIRs with larger RT60 values.  
## cs.AI
---
### Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We will open-source our checkpoints, training script, configurations, and our CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer .  
### **Real-time** Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)
- Authors : Shelly Wang, Samuel Marchal
- Link : [http://arxiv.org/abs/2106.08746](http://arxiv.org/abs/2106.08746)
> ABSTRACT  :  Recent work has shown that deep reinforcement learning (DRL) policies are vulnerable to adversarial perturbations. Adversaries can mislead policies of DRL agents by perturbing the state of the environment observed by the agents. Existing attacks are feasible in principle but face challenges in practice, either by being too slow to fool DRL policies in **real time** or by modifying past observations stored in the agent's memory. We show that using the Universal Adversarial Perturbation (UAP) method to compute perturbations, independent of the individual inputs to which they are applied to, can fool DRL policies effectively and in **real time**. We describe three such attack variants. Via an extensive evaluation using three Atari 2600 games, we show that our attacks are effective, as they fully degrade the performance of three different DRL agents (up to 100%, even when the $l_\infty$ bound on the perturbation is as small as 0.01). It is faster compared to the response time (0.6ms on average) of different DRL policies, and considerably faster than prior attacks using adversarial perturbations (1.8ms on average). We also show that our attack technique is efficient, incurring an online computational cost of 0.027ms on average. Using two further tasks involving robotic movement, we confirm that our results generalize to more complex DRL tasks. Furthermore, we demonstrate that the effectiveness of known defenses diminishes against universal perturbations. We propose an effective technique that detects all known adversarial perturbations against DRL policies, including all the universal perturbations presented in this paper.  
### Optimizing generalized Gini indices for fairness in rankings. (arXiv:2204.06521v2 [cs.IR] UPDATED)
- Authors : Virginie Do, Nicolas Usunier
- Link : [http://arxiv.org/abs/2204.06521](http://arxiv.org/abs/2204.06521)
> ABSTRACT  :  There is growing interest in designing recommender systems that aim at being fair towards item producers or their least satisfied users. Inspired by the domain of inequality measurement in economics, this paper explores the use of generalized Gini welfare functions (GGFs) as a means to specify the normative criterion that recommender systems should optimize for. GGFs weight individuals depending on their ranks in the population, giving more weight to worse-off individuals to promote equality. Depending on these weights, GGFs minimize the Gini index of item **exposure** to promote equality between items, or focus on the performance on specific quantiles of least satisfied users. GGFs for ranking are challenging to optimize because they are non-differentiable. We resolve this challenge by leveraging tools from non-smooth optimization and projection operators used in differentiable sorting. We present experiments using real datasets with up to 15k users and items, which show that our approach obtains better trade-offs than the baselines on a variety of recommendation tasks and fairness criteria.  
# Paper List
---
## cs.CV
---
**114** new papers in cs.CV:-) 
1. Estimating Structural Disparities for Face Models. (arXiv:2204.06562v1 [cs.CV])
2. Character-focused Video Thumbnail Retrieval. (arXiv:2204.06563v1 [cs.CV])
3. OccAM's Laser: Occlusion-based Attribution Maps for 3D Object Detectors on LiDAR Data. (arXiv:2204.06577v1 [cs.CV])
4. Illumination-Invariant Active Camera Relocalization for Fine-Grained Change Detection in the Wild. (arXiv:2204.06580v1 [cs.CV])
5. Deep Relation Learning for Regression and Its Application to Brain Age Estimation. (arXiv:2204.06598v1 [cs.CV])
6. Towards Metrical Reconstruction of Human Faces. (arXiv:2204.06607v1 [cs.CV])
7. Adaptive Memory Management for Video Object Segmentation. (arXiv:2204.06626v1 [cs.CV])
8. A Novel Approach for Optimum-Path Forest Classification Using Fuzzy Logic. (arXiv:2204.06635v1 [cs.CV])
9. Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])
10. A deep learning algorithm for reducing false positives in screening mammography. (arXiv:2204.06671v1 [cs.CV])
11. Geometric Understanding of Sketches. (arXiv:2204.06675v1 [cs.CV])
12. MINSU (Mobile Inventory And Scanning Unit):Computer Vision and AI. (arXiv:2204.06681v1 [cs.CV])
13. HASA: Hybrid Architecture Search with Aggregation Strategy for Echinococcosis Classification and Ovary Segmentation in Ultrasound Images. (arXiv:2204.06697v1 [cs.CV])
14. Learning Convolutional Neural Networks in Frequency Domain. (arXiv:2204.06718v1 [cs.CV])
15. Information fusion approach for biomass estimation in a plateau mountainous forest using a synergistic system comprising UAS-based digital camera and LiDAR. (arXiv:2204.06746v1 [eess.IV])
16. Unsupervised Domain Adaptation with Implicit Pseudo Supervision for Semantic Segmentation. (arXiv:2204.06747v1 [cs.CV])
17. RecurSeed and CertainMix for Weakly Supervised Semantic Segmentation. (arXiv:2204.06754v1 [cs.CV])
18. High-performance Evolutionary Algorithms for Online Neuron Control. (arXiv:2204.06765v1 [cs.NE])
19. ViTOL: Vision Transformer for Weakly Supervised Object Localization. (arXiv:2204.06772v1 [cs.CV])
20. Visual-Inertial Odometry with Online Calibration of Velocity-Control Based Kinematic Motion Models. (arXiv:2204.06776v1 [cs.CV])
21. 3D Shuffle-Mixer: An Efficient Context-Aware Vision Learner of Transformer-MLP Paradigm for Dense Prediction in Medical Volume. (arXiv:2204.06779v1 [cs.CV])
22. Explainable Analysis of Deep Learning Methods for SAR Image Classification. (arXiv:2204.06783v1 [cs.CV])
23. Pyramidal Attention for Saliency Detection. (arXiv:2204.06788v1 [cs.CV])
24. YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss. (arXiv:2204.06806v1 [cs.CV])
25. Interpretable Vertebral Fracture Quantification via Anchor-Free Landmarks Localization. (arXiv:2204.06818v1 [eess.IV])
26. Deep Vehicle Detection in Satellite Video. (arXiv:2204.06828v1 [cs.CV])
27. Modeling Indirect Illumination for Inverse Rendering. (arXiv:2204.06837v1 [cs.CV])
28. OmniPD: One-Step Person Detection in Top-View Omnidirectional Indoor Scenes. (arXiv:2204.06846v1 [cs.CV])
29. Ensuring accurate stain reproduction in deep generative networks for virtual immunohistochemistry. (arXiv:2204.06849v1 [eess.IV])
30. Semi-Supervised Training to Improve Player and Ball Detection in Soccer. (arXiv:2204.06859v1 [cs.CV])
31. Human Identity-Preserved Motion Retargeting in Video Synthesis by Feature Disentanglement. (arXiv:2204.06862v1 [cs.CV])
32. Clothes-Changing Person Re-identification with RGB Modality Only. (arXiv:2204.06890v1 [cs.CV])
33. Implicit Sample Extension for Unsupervised Person Re-Identification. (arXiv:2204.06892v1 [cs.CV])
34. Spatial Likelihood Voting with Self-Knowledge Distillation for Weakly Supervised Object Detection. (arXiv:2204.06899v1 [cs.CV])
35. SoccerNet-Tracking: Multiple Object Tracking Dataset and Benchmark in Soccer Videos. (arXiv:2204.06918v1 [cs.CV])
36. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v1 [eess.IV])
37. Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])
38. BEHAVE: Dataset and Method for Tracking Human Object Interactions. (arXiv:2204.06950v1 [cs.CV])
39. Unsupervised Deep Learning Meets Chan-Vese Model. (arXiv:2204.06951v1 [cs.CV])
40. LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections. (arXiv:2204.06955v1 [eess.IV])
41. The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark. (arXiv:2204.06972v1 [cs.CV])
42. HyDe: The First Open-Source, Python-Based, GPU-Accelerated Hyperspectral Denoising Package. (arXiv:2204.06979v1 [cs.CV])
43. Cross-Image Relational Knowledge Distillation for Semantic Segmentation. (arXiv:2204.06986v1 [cs.CV])
44. Atmospheric Turbulence Removal with Complex-Valued Convolutional Neural Network. (arXiv:2204.06989v1 [cs.CV])
45. Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma. (arXiv:2204.07004v1 [eess.IV])
46. Interpretability of Machine Learning Methods Applied to Neuroimaging. (arXiv:2204.07005v1 [cs.CV])
47. From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks. (arXiv:2204.07018v1 [cs.SD])
48. Q-TART: Quickly Training for Adversarial Robustness and in-Transferability. (arXiv:2204.07024v1 [cs.CV])
49. Autonomous Satellite Detection and Tracking using Optical Flow. (arXiv:2204.07025v1 [astro-ph.IM])
50. Activation Regression for Continuous Domain Generalization with Applications to Crop Classification. (arXiv:2204.07030v1 [cs.CV])
51. Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking. (arXiv:2204.07049v1 [cs.RO])
52. CroCo: Cross-Modal Contrastive learning for localization of Earth Observation data. (arXiv:2204.07052v1 [cs.CV])
53. Egocentric Human-Object Interaction Detection Exploiting Synthetic Data. (arXiv:2204.07061v1 [cs.CV])
54. Panoptic Segmentation using Synthetic and Real Data. (arXiv:2204.07069v1 [cs.CV])
55. SemiMultiPose: A Semi-supervised Multi-animal Pose Estimation Framework. (arXiv:2204.07072v1 [cs.CV])
56. End-to-end Learning for Joint Depth and Image Reconstruction from Diffracted Rotation. (arXiv:2204.07076v1 [eess.IV])
57. Weakly Supervised Attended Object Detection Using Gaze Data as Annotations. (arXiv:2204.07090v1 [cs.CV])
58. Detection of Degraded Acacia tree species using deep neural networks on uav drone imagery. (arXiv:2204.07096v1 [cs.CV])
59. Residual **Swin** Transformer Channel Attention Network for Image Demosaicing. (arXiv:2204.07098v1 [cs.CV])
60. Look Back and Forth: Video Super-Resolution with Explicit Temporal Difference Modeling. (arXiv:2204.07114v1 [cs.CV])
61. DeiT III: Revenge of the ViT. (arXiv:2204.07118v1 [cs.CV])
62. GIFS: Neural Implicit Function for General Shape Representation. (arXiv:2204.07126v1 [cs.CV])
63. Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])
64. Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
65. Deformable Sprites for Unsupervised Video Decomposition. (arXiv:2204.07151v1 [cs.CV])
66. What's in your hands? 3D Reconstruction of Generic Objects in Hands. (arXiv:2204.07153v1 [cs.CV])
67. MiniViT: Compressing Vision Transformers with Weight Multiplexing. (arXiv:2204.07154v1 [cs.CV])
68. Any-resolution Training for High-resolution Image Synthesis. (arXiv:2204.07156v1 [cs.CV])
69. Joint Forecasting of Panoptic Segmentations with Difference Attention. (arXiv:2204.07157v1 [cs.CV])
70. A Level Set Theory for Neural Implicit Evolution under Explicit Flows. (arXiv:2204.07159v1 [cs.CV])
71. Accurate Lung Nodules Segmentation with Detailed Representation Transfer and Soft Mask Supervision. (arXiv:2007.14556v3 [eess.IV] UPDATED)
72. Activation Map Adaptation for Effective Knowledge Distillation. (arXiv:2010.13500v2 [cs.CV] UPDATED)
73. SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots. (arXiv:2011.06252v2 [cs.CV] UPDATED)
74. Introducing a new high-resolution handwritten digits data set with writer characteristics. (arXiv:2011.07946v3 [cs.CV] UPDATED)
75. Unsupervised Temporal Learning on Monocular Videos for 3D Human Pose Estimation. (arXiv:2012.01511v3 [cs.CV] UPDATED)
76. Cross-Modal Contrastive Learning for Text-to-Image Generation. (arXiv:2101.04702v5 [cs.CV] UPDATED)
77. Analyzing Green View Index and Green View Index best path using Google Street View and deep learning. (arXiv:2104.12627v2 [cs.CV] UPDATED)
78. Improving Adversarial Transferability with Gradient Refining. (arXiv:2105.04834v3 [cs.CV] UPDATED)
79. Understanding Mobile GUI: from Pixel-Words to Screen-Sentences. (arXiv:2105.11941v2 [cs.CV] UPDATED)
80. An Online Learning System for Wireless Charging Alignment using Surround-view Fisheye Cameras. (arXiv:2105.12763v3 [cs.CV] UPDATED)
81. Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v2 [cs.LG] UPDATED)
82. Handling Data Heterogeneity with Generative Replay in Collaborative Learning for Medical Imaging. (arXiv:2106.13208v2 [cs.CV] UPDATED)
83. HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v2 [cs.CV] UPDATED)
84. Burst Image **Restoration** and **Enhancement**. (arXiv:2110.03680v2 [cs.CV] UPDATED)
85. Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images. (arXiv:2111.10610v2 [eess.IV] UPDATED)
86. Medical Knowledge-Guided Deep Learning for Imbalanced Medical Image Classification. (arXiv:2111.10620v2 [eess.IV] UPDATED)
87. Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning. (arXiv:2111.14213v3 [cs.LG] UPDATED)
88. FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis. (arXiv:2112.01148v2 [cs.CV] UPDATED)
89. Distill and De-bias: Mitigating Bias in Face Recognition using Knowledge Distillation. (arXiv:2112.09786v2 [cs.CV] UPDATED)
90. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v2 [cs.CV] UPDATED)
91. BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v2 [cs.LG] UPDATED)
92. ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes. (arXiv:2201.07788v2 [cs.CV] UPDATED)
93. Hybrid Contrastive Learning with Cluster Ensemble for Unsupervised Person Re-identification. (arXiv:2201.11995v2 [cs.CV] UPDATED)
94. A Frustratingly Simple Approach for End-to-End Image Captioning. (arXiv:2201.12723v3 [cs.CV] UPDATED)
95. A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment. (arXiv:2202.04517v2 [eess.IV] UPDATED)
96. Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations. (arXiv:2202.07800v2 [cs.CV] UPDATED)
97. Towards Self-Supervised Learning of Global and Object-Centric Representations. (arXiv:2203.05997v2 [cs.CV] UPDATED)
98. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation. (arXiv:2203.09516v2 [cs.CV] UPDATED)
99. Unifying Motion Deblurring and Frame Interpolation with Events. (arXiv:2203.12178v2 [cs.CV] UPDATED)
100. GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection. (arXiv:2203.13954v2 [cs.CV] UPDATED)
101. Classification of Hyperspectral Images Using SVM with Shape-adaptive Reconstruction and Smoothed Total Variation. (arXiv:2203.15619v3 [cs.CV] UPDATED)
102. Perceptual Quality Assessment of UGC Gaming Videos. (arXiv:2204.00128v2 [eess.IV] UPDATED)
103. Word separation in continuous sign language using isolated signs and post-processing. (arXiv:2204.00923v3 [cs.CV] UPDATED)
104. Learning Dynamic Correlations in Spatiotemporal Graphs for Motion Prediction. (arXiv:2204.01297v3 [cs.CV] UPDATED)
105. End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks. (arXiv:2204.01681v2 [physics.ins-det] UPDATED)
106. ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO. (arXiv:2204.03359v2 [cs.CV] UPDATED)
107. HunYuan_tvr for Text-Video Retrivial. (arXiv:2204.03382v3 [cs.CV] UPDATED)
108. Segmenting across places: The need for fair transfer learning with satellite imagery. (arXiv:2204.04358v2 [cs.CV] UPDATED)
109. Structured Graph Variational Autoencoders for Indoor Furniture layout Generation. (arXiv:2204.04867v2 [cs.CV] UPDATED)
110. Machine Learning State-of-the-Art with Uncertainties. (arXiv:2204.05173v2 [cs.LG] UPDATED)
111. ViViD++: Vision for Visibility Dataset. (arXiv:2204.06183v2 [cs.RO] UPDATED)
112. WSSS4LUAD: Grand Challenge on Weakly-supervised Tissue Semantic Segmentation for Lung Adenocarcinoma. (arXiv:2204.06455v2 [eess.IV] UPDATED)
113. Open-Set Recognition: a Good Closed-Set Classifier is All You Need?. (arXiv:2110.06207v2 [cs.CV] CROSS LISTED)
114. DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization. (arXiv:2204.06504v1 [cs.GR] CROSS LISTED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. Information fusion approach for biomass estimation in a plateau mountainous forest using a synergistic system comprising UAS-based digital camera and LiDAR. (arXiv:2204.06746v1 [eess.IV])
2. A crowdsourced implementation of ITU-T P.910. (arXiv:2204.06784v1 [eess.IV])
3. Interpretable Vertebral Fracture Quantification via Anchor-Free Landmarks Localization. (arXiv:2204.06818v1 [eess.IV])
4. Ensuring accurate stain reproduction in deep generative networks for virtual immunohistochemistry. (arXiv:2204.06849v1 [eess.IV])
5. Gamma Correction in Holographic Projection. (arXiv:2204.06913v1 [eess.IV])
6. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v1 [eess.IV])
7. Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])
8. LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections. (arXiv:2204.06955v1 [eess.IV])
9. HyDe: The First Open-Source, Python-Based, GPU-Accelerated Hyperspectral Denoising Package. (arXiv:2204.06979v1 [cs.CV])
10. Atmospheric Turbulence Removal with Complex-Valued Convolutional Neural Network. (arXiv:2204.06989v1 [cs.CV])
11. Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma. (arXiv:2204.07004v1 [eess.IV])
12. Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])
13. End-to-end Learning for Joint Depth and Image Reconstruction from Diffracted Rotation. (arXiv:2204.07076v1 [eess.IV])
14. Residual **Swin** Transformer Channel Attention Network for Image Demosaicing. (arXiv:2204.07098v1 [cs.CV])
15. Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])
16. Accurate Lung Nodules Segmentation with Detailed Representation Transfer and Soft Mask Supervision. (arXiv:2007.14556v3 [eess.IV] UPDATED)
17. B-spline Parameterized Joint Optimization of Reconstruction and K-space Trajectories (BJORK) for Accelerated 2D MRI. (arXiv:2101.11369v3 [eess.SP] UPDATED)
18. Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v2 [physics.med-ph] UPDATED)
19. Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images. (arXiv:2111.10610v2 [eess.IV] UPDATED)
20. Medical Knowledge-Guided Deep Learning for Imbalanced Medical Image Classification. (arXiv:2111.10620v2 [eess.IV] UPDATED)
21. BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v2 [cs.LG] UPDATED)
22. A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment. (arXiv:2202.04517v2 [eess.IV] UPDATED)
23. Perceptual Quality Assessment of UGC Gaming Videos. (arXiv:2204.00128v2 [eess.IV] UPDATED)
24. WSSS4LUAD: Grand Challenge on Weakly-supervised Tissue Semantic Segmentation for Lung Adenocarcinoma. (arXiv:2204.06455v2 [eess.IV] UPDATED)
## cs.LG
---
**165** new papers in cs.LG:-) 
1. Estimating Structural Disparities for Face Models. (arXiv:2204.06562v1 [cs.CV])
2. Character-focused Video Thumbnail Retrieval. (arXiv:2204.06563v1 [cs.CV])
3. A Study of Causal Confusion in Preference-Based Reward Learning. (arXiv:2204.06601v1 [cs.LG])
4. Modularity benefits reinforcement learning agents with competing homeostatic drives. (arXiv:2204.06608v1 [cs.LG])
5. Formal Language Recognition by Hard Attention Transformers: Perspectives from Circuit Complexity. (arXiv:2204.06618v1 [cs.CC])
6. A Natural Language Processing Approach for Instruction Set Architecture Identification. (arXiv:2204.06624v1 [cs.CR])
7. CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing. (arXiv:2204.06625v1 [cs.CL])
8. Performance Assessment of different Machine Learning Algorithm for Life-Time Prediction of Solder Joints based on Synthetic Data. (arXiv:2204.06627v1 [cs.LG])
9. Clifford Circuits can be Properly PAC Learned if and only if $\textsf{RP}=\textsf{NP}$. (arXiv:2204.06638v1 [quant-ph])
10. Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar. (arXiv:2204.06643v1 [cs.LG])
11. METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v1 [cs.LG])
12. Wassmap: Wasserstein Isometric Mapping for Image Manifold Learning. (arXiv:2204.06645v1 [cs.LG])
13. Joint Coreset Construction and Quantization for Distributed Machine Learning. (arXiv:2204.06652v1 [cs.LG])
14. Sketching Algorithms and Lower Bounds for Ridge Regression. (arXiv:2204.06653v1 [cs.DS])
15. Second Order Regret Bounds Against Generalized Expert Sequences under Partial Bandit Feedback. (arXiv:2204.06660v1 [cs.LG])
16. Achieving Representative Data via Convex Hull Feasibility Sampling Algorithms. (arXiv:2204.06664v1 [stat.ML])
17. A deep learning algorithm for reducing false positives in screening mammography. (arXiv:2204.06671v1 [cs.CV])
18. GM-TOuNN: Graded Multiscale Topology Optimization using Neural Networks. (arXiv:2204.06682v1 [cs.CE])
19. Multifidelity deep neural operators for efficient learning of partial differential equations with application to fast inverse design of nanoscale heat transport. (arXiv:2204.06684v1 [physics.comp-ph])
20. Time Series of Non-Additive Metrics: Identification and Interpretation of Contributing Factors of Variance by Linear Decomposition. (arXiv:2204.06688v1 [cs.LG])
21. HASA: Hybrid Architecture Search with Aggregation Strategy for Echinococcosis Classification and Ovary Segmentation in Ultrasound Images. (arXiv:2204.06697v1 [cs.CV])
22. Leveraging convergence behavior to balance conflicting tasks in multi-task learning. (arXiv:2204.06698v1 [cs.LG])
23. SNP2Vec: Scalable Self-Supervised Pre-Training for Genome-Wide Association Study. (arXiv:2204.06699v1 [cs.LG])
24. LSTM-Autoencoder based Anomaly Detection for Indoor Air Quality Time Series Data. (arXiv:2204.06701v1 [cs.LG])
25. Control-oriented meta-learning. (arXiv:2204.06716v1 [cs.RO])
26. Learning Convolutional Neural Networks in Frequency Domain. (arXiv:2204.06718v1 [cs.CV])
27. Improving Top-K Decoding for Non-Autoregressive Semantic Parsing via Intent Conditioning. (arXiv:2204.06748v1 [cs.CL])
28. HCFL: A High Compression Approach for Communication-Efficient Federated Learning in Very Large Scale IoT Networks. (arXiv:2204.06760v1 [cs.LG])
29. Supplementation of deep neural networks with simplified physics-based features to increase model prediction accuracy. (arXiv:2204.06764v1 [cs.ET])
30. Multimodal spatiotemporal graph neural networks for improved prediction of 30-day all-cause hospital readmission. (arXiv:2204.06766v1 [cs.LG])
31. Learning Task-Aware Energy Disaggregation: a Federated Approach. (arXiv:2204.06767v1 [cs.LG])
32. Sign Bit is Enough: A Learning Synchronization Framework for Multi-hop All-reduce with Ultimate Compression. (arXiv:2204.06787v1 [cs.LG])
33. YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss. (arXiv:2204.06806v1 [cs.CV])
34. deep-significance - Easy and Meaningful Statistical Significance Testing in the Age of Neural Networks. (arXiv:2204.06815v1 [cs.LG])
35. Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v1 [cs.LG])
36. The Vision of Self-Evolving Computing Systems. (arXiv:2204.06825v1 [cs.SE])
37. MARF: Multiscale Adaptive-switch Random Forest for Leg Detection with 2D Laser Scanners. (arXiv:2204.06833v1 [cs.RO])
38. Surface Similarity Parameter: A New Machine Learning Loss Metric for Oscillatory Spatio-Temporal Data. (arXiv:2204.06843v1 [cs.LG])
39. ULF: Unsupervised Labeling Function Correction using Cross-Validation for Weak Supervision. (arXiv:2204.06863v1 [cs.LG])
40. Program Analysis of Probabilistic Programs. (arXiv:2204.06868v1 [cs.PL])
41. Shedding New Light on the Language of the **Dark** Web. (arXiv:2204.06885v1 [cs.CL])
42. Gradient boosting for convex cone predict and optimize problems. (arXiv:2204.06895v1 [cs.LG])
43. Efficient and practical quantum compiler towards multi-qubit systems with deep reinforcement learning. (arXiv:2204.06904v1 [quant-ph])
44. Measurement-based Admission Control in Sliced Networks: A Best Arm Identification Approach. (arXiv:2204.06910v1 [cs.NI])
45. Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])
46. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v1 [eess.IV])
47. Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])
48. Concentration of Random Feature Matrices in High-Dimensions. (arXiv:2204.06935v1 [stat.ML])
49. EEG-ITNet: An Explainable Inception Temporal Convolutional Network for Motor Imagery Classification. (arXiv:2204.06947v1 [cs.LG])
50. LEFM-Nets: Learnable Explicit Feature Map Deep Networks for Segmentation of Histopathological Images of Frozen Sections. (arXiv:2204.06955v1 [eess.IV])
51. Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v1 [cs.LG])
52. Latent Aspect Detection from Online Unsolicited Customer Reviews. (arXiv:2204.06964v1 [cs.CL])
53. The multi-modal universe of fast-fashion: the Visuelle 2.0 benchmark. (arXiv:2204.06972v1 [cs.CV])
54. Planting Undetectable Backdoors in Machine Learning Models. (arXiv:2204.06974v1 [cs.LG])
55. Solving AC Power Flow with Graph Neural Networks under Realistic Constraints. (arXiv:2204.07000v1 [cs.LG])
56. Medical Application of Geometric Deep Learning for the Diagnosis of Glaucoma. (arXiv:2204.07004v1 [eess.IV])
57. Interpretability of Machine Learning Methods Applied to Neuroimaging. (arXiv:2204.07005v1 [cs.CV])
58. Learning Invariances with Generalised Input-Convex Neural Networks. (arXiv:2204.07009v1 [cs.LG])
59. From Environmental Sound Representation to Robustness of 2D CNN Models Against Adversarial Attacks. (arXiv:2204.07018v1 [cs.SD])
60. Q-TART: Quickly Training for Adversarial Robustness and in-Transferability. (arXiv:2204.07024v1 [cs.CV])
61. Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v1 [cs.LG])
62. Activation Regression for Continuous Domain Generalization with Applications to Crop Classification. (arXiv:2204.07030v1 [cs.CV])
63. Epileptic Seizure Risk Assessment by Multi-Channel Imaging of the EEG. (arXiv:2204.07034v1 [eess.SP])
64. LDPC codes: tracking non-stationary channel noise using sequential variational Bayesian estimates. (arXiv:2204.07037v1 [eess.SP])
65. Ensemble learning using individual neonatal data for seizure detection. (arXiv:2204.07043v1 [eess.SP])
66. Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking. (arXiv:2204.07049v1 [cs.RO])
67. BrainGB: A Benchmark for Brain Network Analysis with Graph Neural Networks. (arXiv:2204.07054v1 [q-bio.NC])
68. Reflective Fiber Faults Detection and Characterization Using Long-Short-Term Memory. (arXiv:2204.07058v1 [cs.NI])
69. Machine Learning-based Anomaly Detection in Optical Fiber Monitoring. (arXiv:2204.07059v1 [cs.NI])
70. Network state Estimation using Raw Video Analysis: vQoS-GAN based non-intrusive Deep Learning Approach. (arXiv:2204.07062v1 [cs.MM])
71. Streamable Neural Audio Synthesis With Non-Causal Convolutions. (arXiv:2204.07064v1 [cs.SD])
72. EvoSTS Forecasting: Evolutionary Sparse Time-Series Forecasting. (arXiv:2204.07066v1 [cs.NE])
73. A Unified Analysis of Dynamic Interactive Learning. (arXiv:2204.07071v1 [cs.LG])
74. SemiMultiPose: A Semi-supervised Multi-animal Pose Estimation Framework. (arXiv:2204.07072v1 [cs.CV])
75. Leveraging Natural Learning Processing to Uncover Themes in Clinical Notes of Patients Admitted for Heart Failure. (arXiv:2204.07074v1 [cs.LG])
76. Learning and controlling the source-filter representation of speech with a variational autoencoder. (arXiv:2204.07075v1 [cs.SD])
77. Generative power of a protein language model trained on multiple sequence alignments. (arXiv:2204.07110v1 [q-bio.BM])
78. Exploring Dual Encoder Architectures for Question Answering. (arXiv:2204.07120v1 [cs.CL])
79. MIMO Channel Estimation using Score-Based Generative Models. (arXiv:2204.07122v1 [eess.SP])
80. Learning Optimal Dynamic Treatment Regimes Using Causal Tree Methods in Medicine. (arXiv:2204.07124v1 [stat.ML])
81. Reinforcement Learning Policy Recommendation for Interbank Network Stability. (arXiv:2204.07134v1 [econ.GN])
82. Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems. (arXiv:2204.07135v1 [cs.LG])
83. Accelerated Policy Learning with Parallel Differentiable Simulation. (arXiv:2204.07137v1 [cs.LG])
84. Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])
85. CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations. (arXiv:2204.07142v1 [cs.CL])
86. Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
87. Tight Bounds for Quantum State Certification with Incoherent Measurements. (arXiv:2204.07155v1 [quant-ph])
88. Any-resolution Training for High-resolution Image Synthesis. (arXiv:2204.07156v1 [cs.CV])
89. A Level Set Theory for Neural Implicit Evolution under Explicit Flows. (arXiv:2204.07159v1 [cs.CV])
90. The Power of Linear Recurrent Neural Networks. (arXiv:1802.03308v6 [cs.LG] UPDATED)
91. Data Augmentation for Bayesian Deep Learning. (arXiv:1903.09668v3 [stat.ML] UPDATED)
92. Optimal Training of Fair Predictive Models. (arXiv:1910.04109v3 [stat.ML] UPDATED)
93. To Split or Not to Split: The Impact of Disparate Treatment in Classification. (arXiv:2002.04788v4 [cs.LG] UPDATED)
94. Semi-Discriminative Representation Loss for Online Continual Learning. (arXiv:2006.11234v4 [stat.ML] UPDATED)
95. Surrogate NAS Benchmarks: Going Beyond the Limited Search Spaces of Tabular NAS Benchmarks. (arXiv:2008.09777v4 [cs.LG] UPDATED)
96. Activation Map Adaptation for Effective Knowledge Distillation. (arXiv:2010.13500v2 [cs.CV] UPDATED)
97. SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots. (arXiv:2011.06252v2 [cs.CV] UPDATED)
98. Unsupervised Temporal Learning on Monocular Videos for 3D Human Pose Estimation. (arXiv:2012.01511v3 [cs.CV] UPDATED)
99. Magnetic Resonance Spectroscopy Deep Learning Denoising Using Few In Vivo Data. (arXiv:2101.11442v2 [physics.med-ph] UPDATED)
100. Regret, stability & fairness in matching markets with bandit learners. (arXiv:2102.06246v2 [cs.LG] UPDATED)
101. Learning Spectral Unions of Partial Deformable 3D Shapes. (arXiv:2104.00514v2 [cs.GR] UPDATED)
102. OpenCSI: An Open-Source Dataset for Indoor Localization Using CSI-Based Fingerprinting. (arXiv:2104.07963v3 [eess.SP] UPDATED)
103. Group-Sparse Matrix Factorization for Transfer Learning of Word Embeddings. (arXiv:2104.08928v2 [stat.ML] UPDATED)
104. Optimal Stopping via Randomized Neural Networks. (arXiv:2104.13669v2 [stat.ML] UPDATED)
105. ADASYN-Random Forest Based Intrusion Detection Model. (arXiv:2105.04301v6 [cs.CR] UPDATED)
106. Kernel Thinning. (arXiv:2105.05842v7 [stat.ML] UPDATED)
107. Rethinking Architecture Design for Tackling Data Heterogeneity in Federated Learning. (arXiv:2106.06047v2 [cs.LG] UPDATED)
108. Learnable Hypergraph Laplacian for Hypergraph Learning. (arXiv:2106.06666v3 [cs.LG] UPDATED)
109. **Real-time** Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)
110. Your fairness may vary: Pretrained language model fairness in toxic text classification. (arXiv:2108.01250v3 [cs.CL] UPDATED)
111. HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v2 [cs.CV] UPDATED)
112. Neonatal Bowel Sound Detection Using Convolutional Neural Network and Laplace Hidden Semi-Markov Model. (arXiv:2108.07467v2 [cs.SD] UPDATED)
113. Twitter User Representation Using Weakly Supervised Graph Embedding. (arXiv:2108.08988v3 [cs.CL] UPDATED)
114. Adversarial Parameter Defense by Multi-Step Risk Minimization. (arXiv:2109.02889v2 [cs.LG] UPDATED)
115. Characterizing the Fundamental Trade-offs in Learning Invariant Representations. (arXiv:2109.03386v2 [cs.LG] UPDATED)
116. Modeling the effects of environmental and perceptual uncertainty using deterministic reinforcement learning dynamics with partial observability. (arXiv:2109.07259v2 [nlin.AO] UPDATED)
117. Ranking Feature-Block Importance in Artificial Multiblock Neural Networks. (arXiv:2109.10279v2 [cs.LG] UPDATED)
118. Fairness without Imputation: A Decision Tree Approach for Fair Prediction with Missing Values. (arXiv:2109.10431v2 [cs.LG] UPDATED)
119. A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming. (arXiv:2110.03894v2 [eess.AS] UPDATED)
120. A Melody-Unsupervision Model for Singing Voice Synthesis. (arXiv:2110.06546v2 [eess.AS] UPDATED)
121. Procrastinated Tree Search: Black-box Optimization with Delayed, Noisy, and Multi-Fidelity Feedback. (arXiv:2110.07232v2 [cs.LG] UPDATED)
122. The Pseudo Projection Operator: Applications of Deep Learning to Projection Based Filtering in Non-Trivial Frequency Regimes. (arXiv:2111.07140v3 [eess.SP] UPDATED)
123. Constrained Deep One-Class Feature Learning For Classifying Imbalanced Medical Images. (arXiv:2111.10610v2 [eess.IV] UPDATED)
124. Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning. (arXiv:2111.14213v3 [cs.LG] UPDATED)
125. ExPLoit: Extracting Private Labels in Split Learning. (arXiv:2112.01299v2 [cs.CR] UPDATED)
126. A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v3 [eess.SY] UPDATED)
127. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v2 [cs.CV] UPDATED)
128. DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v3 [physics.comp-ph] UPDATED)
129. BottleFit: Learning Compressed Representations in Deep Neural Networks for Effective and Efficient Split Computing. (arXiv:2201.02693v2 [cs.LG] UPDATED)
130. Incompleteness of graph convolutional neural networks for points clouds in three dimensions. (arXiv:2201.07136v2 [stat.ML] UPDATED)
131. ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes. (arXiv:2201.07788v2 [cs.CV] UPDATED)
132. Question rewriting? Assessing its importance for conversational question answering. (arXiv:2201.09146v2 [cs.CL] UPDATED)
133. Extracting Finite Automata from RNNs Using State Merging. (arXiv:2201.12451v3 [cs.LG] UPDATED)
134. Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v2 [cs.CL] UPDATED)
135. data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language. (arXiv:2202.03555v2 [cs.LG] UPDATED)
136. Improving Computational Complexity in Statistical Models with Second-Order Information. (arXiv:2202.04219v3 [stat.ML] UPDATED)
137. A Neural Network based Framework for Effective Laparoscopic Video Quality Assessment. (arXiv:2202.04517v2 [eess.IV] UPDATED)
138. Semi-Supervised Convolutive NMF for Automatic Piano Transcription. (arXiv:2202.04989v2 [cs.SD] UPDATED)
139. PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v2 [cs.LG] UPDATED)
140. Fine-Grained Population Mobility Data-Based Community-Level COVID-19 Prediction Model. (arXiv:2202.06257v2 [cs.LG] UPDATED)
141. Not All Patches are What You Need: Expediting Vision Transformers via Token Reorganizations. (arXiv:2202.07800v2 [cs.CV] UPDATED)
142. ICSML: Industrial Control Systems Machine Learning Inference Framework natively executing on IEC 61131-3 compliant devices. (arXiv:2202.10075v2 [cs.LG] UPDATED)
143. Integration of neural network and fuzzy logic decision making compared with bilayered neural network in the simulation of daily dew point temperature. (arXiv:2202.12256v2 [cs.LG] UPDATED)
144. Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v3 [cs.LG] UPDATED)
145. SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v2 [cs.CL] UPDATED)
146. Modelling Non-Smooth Signals with Complex Spectral Structure. (arXiv:2203.06997v2 [stat.ML] UPDATED)
147. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation. (arXiv:2203.09516v2 [cs.CV] UPDATED)
148. Matrix Completion with Heterogonous Cost. (arXiv:2203.12120v2 [cs.LG] UPDATED)
149. Robust No-Regret Learning in Min-Max Stackelberg Games. (arXiv:2203.14126v2 [cs.GT] UPDATED)
150. Proceedings of TDA: Applications of Topological Data Analysis to Data Science, Artificial Intelligence, and Machine Learning Workshop at SDM 2022. (arXiv:2204.01142v2 [math.AT] UPDATED)
151. End-to-end multi-particle reconstruction in high occupancy imaging calorimeters with graph neural networks. (arXiv:2204.01681v2 [physics.ins-det] UPDATED)
152. A Low-Cost Robot Science Kit for Education with Symbolic Regression for Hypothesis Discovery and Validation. (arXiv:2204.04187v2 [cond-mat.mtrl-sci] UPDATED)
153. Word Embeddings Are Capable of Capturing Rhythmic Similarity of Words. (arXiv:2204.04833v2 [cs.CL] UPDATED)
154. Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making. (arXiv:2204.05030v2 [cs.AI] UPDATED)
155. Machine Learning State-of-the-Art with Uncertainties. (arXiv:2204.05173v2 [cs.LG] UPDATED)
156. Modelling Evolutionary and Stationary User Preferences for Temporal Sets Prediction. (arXiv:2204.05490v3 [cs.LG] UPDATED)
157. FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning. (arXiv:2204.05562v3 [cs.LG] UPDATED)
158. A Collection of Deep Learning-based Feature-Free Approaches for Characterizing Single-Objective Continuous Fitness Landscapes. (arXiv:2204.05752v2 [cs.LG] UPDATED)
159. The MIT Supercloud Workload Classification Challenge. (arXiv:2204.05839v2 [cs.DC] UPDATED)
160. Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v2 [cs.SI] UPDATED)
161. Neural Operator with Regularity Structure for Modeling Dynamics Driven by SPDEs. (arXiv:2204.06255v2 [cs.LG] UPDATED)
162. Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification. (arXiv:2204.06305v2 [cs.CL] UPDATED)
163. Receptive Field Analysis of Temporal Convolutional Networks for Monaural Speech Dereverberation. (arXiv:2204.06439v2 [cs.SD] UPDATED)
164. Open-Set Recognition: a Good Closed-Set Classifier is All You Need?. (arXiv:2110.06207v2 [cs.CV] CROSS LISTED)
165. DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization. (arXiv:2204.06504v1 [cs.GR] CROSS LISTED)
## cs.AI
---
**71** new papers in cs.AI:-) 
1. Estimating Structural Disparities for Face Models. (arXiv:2204.06562v1 [cs.CV])
2. A Distant Supervision Corpus for Extracting Biomedical Relationships Between Chemicals, Diseases and Genes. (arXiv:2204.06584v1 [cs.CL])
3. Formal Language Recognition by Hard Attention Transformers: Perspectives from Circuit Complexity. (arXiv:2204.06618v1 [cs.CC])
4. Fix Bugs with Transformer through a Neural-Symbolic Edit Grammar. (arXiv:2204.06643v1 [cs.LG])
5. METRO: Efficient Denoising Pretraining of Large Scale Autoencoding Language Models with Model Generated Signals. (arXiv:2204.06644v1 [cs.LG])
6. Copiloting Autonomous Multi-Robot Missions: A Game-inspired Supervisory Control Interface. (arXiv:2204.06647v1 [cs.RO])
7. DRAGON : A suite of Hardware Simulation and Optimization tools for Modern Workloads. (arXiv:2204.06676v1 [cs.AR])
8. MINSU (Mobile Inventory And Scanning Unit):Computer Vision and AI. (arXiv:2204.06681v1 [cs.CV])
9. HASA: Hybrid Architecture Search with Aggregation Strategy for Echinococcosis Classification and Ovary Segmentation in Ultrasound Images. (arXiv:2204.06697v1 [cs.CV])
10. Leveraging convergence behavior to balance conflicting tasks in multi-task learning. (arXiv:2204.06698v1 [cs.LG])
11. SNP2Vec: Scalable Self-Supervised Pre-Training for Genome-Wide Association Study. (arXiv:2204.06699v1 [cs.LG])
12. Learning Convolutional Neural Networks in Frequency Domain. (arXiv:2204.06718v1 [cs.CV])
13. Improving Top-K Decoding for Non-Autoregressive Semantic Parsing via Intent Conditioning. (arXiv:2204.06748v1 [cs.CL])
14. RecurSeed and CertainMix for Weakly Supervised Semantic Segmentation. (arXiv:2204.06754v1 [cs.CV])
15. HCFL: A High Compression Approach for Communication-Efficient Federated Learning in Very Large Scale IoT Networks. (arXiv:2204.06760v1 [cs.LG])
16. Multimodal spatiotemporal graph neural networks for improved prediction of 30-day all-cause hospital readmission. (arXiv:2204.06766v1 [cs.LG])
17. 3D Shuffle-Mixer: An Efficient Context-Aware Vision Learner of Transformer-MLP Paradigm for Dense Prediction in Medical Volume. (arXiv:2204.06779v1 [cs.CV])
18. Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained Motion Planning. (arXiv:2204.06791v1 [cs.RO])
19. YOLO-Pose: Enhancing YOLO for Multi Person Pose Estimation Using Object Keypoint Similarity Loss. (arXiv:2204.06806v1 [cs.CV])
20. Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v1 [cs.LG])
21. GloCAL: Glocalized Curriculum-Aided Learning of Multiple Tasks with Application to Robotic Grasping. (arXiv:2204.06835v1 [cs.RO])
22. OmniPD: One-Step Person Detection in Top-View Omnidirectional Indoor Scenes. (arXiv:2204.06846v1 [cs.CV])
23. RankNEAT: Outperforming Stochastic Gradient Search in Preference Learning Tasks. (arXiv:2204.06901v1 [cs.NE])
24. Exact and approximate determination of the Pareto set using minimal correction subsets. (arXiv:2204.06908v1 [cs.AI])
25. Should I Follow AI-based Advice? Measuring Appropriate Reliance in Human-AI Decision-Making. (arXiv:2204.06916v1 [cs.HC])
26. Global Counterfactual Explanations: Investigations, Implementations and Improvements. (arXiv:2204.06917v1 [cs.LG])
27. Open Source HamNoSys Parser for Multilingual Sign Language Encoding. (arXiv:2204.06924v1 [cs.CL])
28. Geometric Deep Learning to Identify the Critical 3D Structural Features of the Optic Nerve Head for Glaucoma Diagnosis. (arXiv:2204.06931v1 [eess.IV])
29. EEG-ITNet: An Explainable Inception Temporal Convolutional Network for Motor Imagery Classification. (arXiv:2204.06947v1 [cs.LG])
30. Interpretability of Machine Learning Methods Applied to Neuroimaging. (arXiv:2204.07005v1 [cs.CV])
31. Rows from Many Sources: Enriching row completions from Wikidata with a pre-trained Language Model. (arXiv:2204.07014v1 [cs.CL])
32. Composite Code Sparse Autoencoders for first stage retrieval. (arXiv:2204.07023v1 [cs.IR])
33. Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v1 [cs.LG])
34. Farmer-Bot: An Interactive Bot for Farmers. (arXiv:2204.07032v1 [cs.IR])
35. Sequential Multi-task Learning with Task Dependency for Appeal Judgment Prediction. (arXiv:2204.07046v1 [cs.CL])
36. State of the Art in Artificial Intelligence applied to the Legal Domain. (arXiv:2204.07047v1 [cs.CL])
37. Sim-to-Real 6D Object Pose Estimation via Iterative Self-training for Robotic Bin-picking. (arXiv:2204.07049v1 [cs.RO])
38. Recent Advances and New Frontiers in Spiking Neural Networks. (arXiv:2204.07050v1 [cs.NE])
39. Dialogue Strategy Adaptation to New Action Sets Using Multi-dimensional Modelling. (arXiv:2204.07082v1 [cs.CL])
40. Retrospective on the 2021 BASALT Competition on Learning from Human Feedback. (arXiv:2204.07123v1 [cs.AI])
41. Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational AI Systems. (arXiv:2204.07135v1 [cs.LG])
42. Accelerated Policy Learning with Parallel Differentiable Simulation. (arXiv:2204.07137v1 [cs.LG])
43. Masked Siamese Networks for Label-Efficient Learning. (arXiv:2204.07141v1 [cs.LG])
44. CLUES: A Benchmark for Learning Classifiers using Natural Language Explanations. (arXiv:2204.07142v1 [cs.CL])
45. Neighborhood Attention Transformer. (arXiv:2204.07143v1 [cs.CV])
46. Solving the Clustered Traveling Salesman Problem via TSP methods. (arXiv:2007.05254v3 [cs.AI] UPDATED)
47. Intrusion Detection Systems for IoT: opportunities and challenges offered by Edge Computing and Machine Learning. (arXiv:2012.01174v2 [cs.CR] UPDATED)
48. **Real-time** Adversarial Perturbations against Deep Reinforcement Learning Policies: Attacks and Defenses. (arXiv:2106.08746v3 [cs.LG] UPDATED)
49. HCR-Net: A deep learning based script independent handwritten character recognition network. (arXiv:2108.06663v2 [cs.CV] UPDATED)
50. Twitter User Representation Using Weakly Supervised Graph Embedding. (arXiv:2108.08988v3 [cs.CL] UPDATED)
51. Modeling the effects of environmental and perceptual uncertainty using deterministic reinforcement learning dynamics with partial observability. (arXiv:2109.07259v2 [nlin.AO] UPDATED)
52. A Study of Low-Resource Speech Commands Recognition based on Adversarial Reprogramming. (arXiv:2110.03894v2 [eess.AS] UPDATED)
53. Feasibility Study of Neural ODE and DAE Modules for Power System Dynamic Component Modeling. (arXiv:2110.12981v4 [eess.SY] UPDATED)
54. FIBA: Frequency-Injection based Backdoor Attack in Medical Image Analysis. (arXiv:2112.01148v2 [cs.CV] UPDATED)
55. ExPLoit: Extracting Private Labels in Split Learning. (arXiv:2112.01299v2 [cs.CR] UPDATED)
56. A Simple and Efficient Sampling-based Algorithm for General Reachability Analysis. (arXiv:2112.05745v3 [eess.SY] UPDATED)
57. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v2 [cs.CV] UPDATED)
58. ConDor: Self-Supervised Canonicalization of 3D Pose for Partial Shapes. (arXiv:2201.07788v2 [cs.CV] UPDATED)
59. Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v2 [cs.CL] UPDATED)
60. PEg TRAnsfer Workflow recognition challenge report: Does multi-modal data improve recognition?. (arXiv:2202.05821v2 [cs.LG] UPDATED)
61. Toward Interpretable Semantic Textual Similarity via Optimal Transport-based Contrastive Sentence Learning. (arXiv:2202.13196v2 [cs.AI] UPDATED)
62. SkillNet: A Sparsely Activated Model for General-Purpose Natural Language Understanding. (arXiv:2203.03312v2 [cs.CL] UPDATED)
63. Voltage-Dependent Synaptic Plasticity (VDSP): Unsupervised probabilistic Hebbian plasticity rule based on neurons membrane potential. (arXiv:2203.11022v3 [cs.NE] UPDATED)
64. GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection. (arXiv:2203.13954v2 [cs.CV] UPDATED)
65. Spatiotemporal Patterns in Neurobiology: An Overview for Future Artificial Intelligence. (arXiv:2203.15415v2 [q-bio.NC] UPDATED)
66. WAVPROMPT: Towards Few-Shot Spoken Language Understanding with Frozen Language Models. (arXiv:2203.15863v2 [eess.AS] UPDATED)
67. Assessing the communication gap between AI models and healthcare professionals: explainability, utility and trust in AI-driven clinical decision-making. (arXiv:2204.05030v2 [cs.AI] UPDATED)
68. Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v2 [cs.SI] UPDATED)
69. Automatic Multi-Label Prompting: Simple and Interpretable Few-Shot Classification. (arXiv:2204.06305v2 [cs.CL] UPDATED)
70. Optimizing generalized Gini indices for fairness in rankings. (arXiv:2204.06521v2 [cs.IR] UPDATED)
71. DL4SciVis: A State-of-the-Art Survey on Deep Learning for Scientific Visualization. (arXiv:2204.06504v1 [cs.GR] CROSS LISTED)

