# Your interest papers
---
## cs.CV
---
### Adaptive Cross-Layer Attention for Image **Restoration**. (arXiv:2203.03619v1 [eess.IV])
- Authors : Yancheng Wang, Ning Xu, Chong Chen, Yingzhen Yang
- Link : [http://arxiv.org/abs/2203.03619](http://arxiv.org/abs/2203.03619)
> ABSTRACT  :  Non-local attention module has been proven to be crucial for image **restoration**. Conventional non-local attention processes features of each layer separately, so it risks missing correlation between features among different layers. To address this problem, we propose Cross-Layer Attention (CLA) module in this paper. Instead of finding correlated key pixels within the same layer, each query pixel can attend to key pixels at previous layers of the network. In order to further enhance the learning capability and reduce the inference cost of CLA, we further propose Adaptive CLA, or ACLA, as an improved CLA. Two adaptive designs are proposed for ACLA: 1) adaptively selecting the keys for non-local attention at each layer; 2) automatically searching for the insertion locations for ACLA modules. By these two adaptive designs, ACLA dynamically selects the number of keys to be aggregated for non-local attention at layer. In addition, ACLA searches for the optimal insert positions of ACLA modules by a neural architecture search method to render a compact neural network with compelling performance. Extensive experiments on image **restoration** tasks, including single image super-resolution, image denoising, image demosaicing, and image compression artifacts reduction, validate the effectiveness and efficiency of ACLA.  
### Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
- Authors : Hanieh Naderi, Mohammad Rahmati
- Link : [http://arxiv.org/abs/2203.03621](http://arxiv.org/abs/2203.03621)
> ABSTRACT  :  In this paper, we propose a novel motion-compensated frame rate up-conversion (MC-FRUC) algorithm. The proposed algorithm creates interpolated frames by first estimating motion vectors using unilateral (jointing forward and backward) and **bilateral** motion estimation. Then motion vectors are combined based on adaptive threshold, in order to creates high-quality interpolated frames and reduce block artifacts. Since motion-compensated frame interpolation along unilateral motion trajectories yields holes, a new algorithm is introduced to resolve this problem. The experimental results show that the quality of the interpolated frames using the proposed algorithm is much higher than the existing algorithms.  
### Fusion-Correction Network for Single-**Exposure** Correction and Multi-**Exposure** Fusion. (arXiv:2203.03624v1 [eess.IV])
- Authors : Jin Liang, Anran Zhang, Jun Xu, Hui Li, Xiantong Zhen
- Link : [http://arxiv.org/abs/2203.03624](http://arxiv.org/abs/2203.03624)
> ABSTRACT  :  The photographs captured by digital cameras usually suffer from over-**exposure** or under-**exposure** problems. The Single-**Exposure** Correction (SEC) and Multi-**Exposure** Fusion (MEF) are two widely studied image processing tasks for image **exposure** **enhancement**. However, current SEC and MEF methods ignore the internal correlation between SEC and MEF, and are proposed under distinct frameworks. What's more, most MEF methods usually fail at processing a sequence containing only under-exposed or over-exposed images. To alleviate these problems, in this paper, we develop an integrated framework to simultaneously tackle the SEC and MEF tasks. Built upon the Laplacian Pyramid (LP) decomposition, we propose a novel Fusion-Correction Network (FCNet) to fuse and correct an image sequence sequentially in a multi-level scheme. In each LP level, the image sequence is feed into a Fusion block and a Correction block for consecutive image fusion and **exposure** correction. The corrected image is upsampled and re-composed with the high-frequency detail components in next-level, producing the base sequence for the next-level blocks. Experiments on the benchmark dataset demonstrate that our FCNet is effective on both the SEC and MEF tasks.  
### End-to-end system for object detection from sub-sampled radar data. (arXiv:2203.03905v1 [cs.CV])
- Authors : Madhumitha Sakthi, Ahmed Tewfik, Marius Arvinte, Haris Vikalo
- Link : [http://arxiv.org/abs/2203.03905](http://arxiv.org/abs/2203.03905)
> ABSTRACT  :  Robust and accurate sensing is of critical importance for advancing autonomous automotive systems. The need to acquire situational awareness in complex urban conditions using sensors such as radar has motivated research on power and latency-efficient signal acquisition methods. In this paper, we present an end-to-end signal processing pipeline, capable of operating in extreme weather conditions, that relies on sub-sampled radar data to perform object detection in vehicular settings. The results of the object detection are further utilized to sub-sample forthcoming radar data, which stands in contrast to prior work where the sub-sampling relies on image information. We show robust detection based on radar data reconstructed using 20% of samples under extreme weather conditions such as snow or fog, and on low-illuminated **night**s. Additionally, we generate 20% sampled radar data in a fine-tuning set and show 1.1% gain in AP50 across scenes and 3% AP50 gain in motorway condition.  
### Globally-Optimal Event Camera Motion Estimation. (arXiv:2203.03914v1 [cs.CV])
- Authors : Xin Peng, Yifu Wang, Ling Gao, Laurent Kneip
- Link : [http://arxiv.org/abs/2203.03914](http://arxiv.org/abs/2203.03914)
> ABSTRACT  :  Event cameras are bio-inspired sensors that perform well in **HDR** conditions and have high temporal resolution. However, different from traditional frame-based cameras, event cameras measure asynchronous pixel-level brightness changes and return them in a highly discretised format, hence new algorithms are needed. The present paper looks at fronto-parallel motion estimation of an event camera. The flow of the events is modeled by a general homographic warping in a space-time volume, and the objective is formulated as a maximisation of contrast within the image of unwarped events. However, in stark contrast to prior art, we derive a globally optimal solution to this generally non-convex problem, and thus remove the dependency on a good initial guess. Our algorithm relies on branch-and-bound optimisation for which we derive novel, recursive upper and lower bounds for six different contrast estimation functions. The practical validity of our approach is supported by a highly successful application to AGV motion estimation with a downward facing event camera, a challenging scenario in which the sensor experiences fronto-parallel motion in front of noisy, fast moving textures.  
### Stage-Aware Feature Alignment Network for Real-Time Semantic Segmentation of Street Scenes. (arXiv:2203.04031v1 [cs.CV])
- Authors : Xi Weng, Yan Yan, Si Chen, Hao Xue, Hanzi Wang
- Link : [http://arxiv.org/abs/2203.04031](http://arxiv.org/abs/2203.04031)
> ABSTRACT  :  Over the past few years, deep convolutional neural network-based methods have made great progress in semantic segmentation of street scenes. Some recent methods align feature maps to alleviate the semantic gap between them and achieve high segmentation accuracy. However, they usually adopt the feature alignment modules with the same network configuration in the decoder and thus ignore the different roles of stages of the decoder during feature aggregation, leading to a complex decoder structure. Such a manner greatly affects the inference speed. In this paper, we present a novel Stage-aware Feature Alignment Network (SFANet) based on the encoder-decoder structure for real-time semantic segmentation of street scenes. Specifically, a Stage-aware Feature Alignment module (SFA) is proposed to align and aggregate two adjacent levels of feature maps effectively. In the SFA, by taking into account the unique role of each stage in the decoder, a novel stage-aware Feature **Enhancement** Block (FEB) is designed to enhance spatial details and contextual information of feature maps from the encoder. In this way, we are able to address the misalignment problem with a very simple and efficient multi-branch decoder structure. Moreover, an auxiliary training strategy is developed to explicitly alleviate the multi-scale object problem without bringing additional computational costs during the inference phase. Experimental results show that the proposed SFANet exhibits a good balance between accuracy and speed for real-time semantic segmentation of street scenes. In particular, based on ResNet-18, SFANet respectively obtains 78.1% and 74.7% mean of class-wise Intersection-over-Union (mIoU) at inference speeds of 37 FPS and 96 FPS on the challenging Cityscapes and CamVid test datasets by using only a single GTX 1080Ti GPU.  
### Deep Multi-Branch Aggregation Network for Real-Time Semantic Segmentation in Street Scenes. (arXiv:2203.04037v1 [cs.CV])
- Authors : Xi Weng, Yan Yan, Genshun Dong, Chang Shu, Biao Wang, Hanzi Wang, Ji Zhang
- Link : [http://arxiv.org/abs/2203.04037](http://arxiv.org/abs/2203.04037)
> ABSTRACT  :  **Real-time** semantic segmentation, which aims to achieve high segmentation accuracy at real-time inference speed, has received substantial attention over the past few years. However, many state-of-the-art real-time semantic segmentation methods tend to sacrifice some spatial details or contextual information for fast inference, thus leading to degradation in segmentation quality. In this paper, we propose a novel Deep Multi-branch Aggregation Network (called DMA-Net) based on the encoder-decoder structure to perform real-time semantic segmentation in street scenes. Specifically, we first adopt ResNet-18 as the encoder to efficiently generate various levels of feature maps from different stages of convolutions. Then, we develop a Multi-branch Aggregation Network (MAN) as the decoder to effectively aggregate different levels of feature maps and capture the multi-scale information. In MAN, a lattice enhanced residual block is designed to enhance feature representations of the network by taking advantage of the lattice structure. Meanwhile, a feature transformation block is introduced to explicitly transform the feature map from the neighboring branch before feature aggregation. Moreover, a global context block is used to exploit the global contextual information. These key components are tightly combined and jointly optimized in a unified network. Extensive experimental results on the challenging Cityscapes and CamVid datasets demonstrate that our proposed DMA-Net respectively obtains 77.0% and 73.6% mean Intersection over Union (mIoU) at the inference speed of 46.7 FPS and 119.8 FPS by only using a single NVIDIA GTX 1080Ti GPU. This shows that DMA-Net provides a good tradeoff between segmentation quality and speed for semantic segmentation in street scenes.  
### Learning to Erase the Bayer-Filter to See in the **Dark**. (arXiv:2203.04042v1 [eess.IV])
- Authors : Xingbo Dong, Wanyan Xu, Zhihui Miao, Lan Ma, Chao Zhang, Jiewen Yang, Zhe Jin, Andrew Beng, Jin Teoh, Jiajun Shen
- Link : [http://arxiv.org/abs/2203.04042](http://arxiv.org/abs/2203.04042)
> ABSTRACT  :  **Low-light** image **enhancement** - a pervasive but challenging problem, plays a central role in enhancing the visibility of an image captured in a poor illumination environment. Due to the fact that not all photons can pass the Bayer-Filter on the sensor of the color camera, in this work, we first present a De-Bayer-Filter simulator based on deep neural networks to generate a monochrome raw image from the colored raw image. Next, a fully convolutional network is proposed to achieve the **low-light** image **enhancement** by fusing colored raw data with synthesized monochrome raw data. Channel-wise attention is also introduced to the fusion process to establish a complementary interaction between features from colored and monochrome raw images. To train the convolutional networks, we propose a dataset with monochrome and color raw pairs named Mono-Colored Raw paired dataset (MCR) collected by using a monochrome camera without Bayer-Filter and a color camera with Bayer-Filter. The proposed pipeline take advantages of the fusion of the virtual monochrome and the color raw images and our extensive experiments indicate that significant improvement can be achieved by leveraging raw sensor data and data-driven learning.  
### Contrastive **Enhancement** Using Latent Prototype for Few-Shot Segmentation. (arXiv:2203.04095v1 [cs.CV])
- Authors : Xiaoyu Zhao, Xiaoqian Chen, Zhiqiang Gong, Wen Yao, Yunyang Zhang, Xiaohu Zheng
- Link : [http://arxiv.org/abs/2203.04095](http://arxiv.org/abs/2203.04095)
> ABSTRACT  :  Few-shot segmentation enables the model to recognize unseen classes with few annotated examples. Most existing methods adopt prototype learning architecture, where support prototype vectors are expanded and concatenated with query features to perform conditional segmentation. However, such framework potentially focuses more on query features while may neglect the similarity between support and query features. This paper proposes a contrastive **enhancement** approach using latent prototypes to leverage latent classes and raise the utilization of similarity information between prototype and query features. Specifically, a latent prototype sampling module is proposed to generate pseudo-mask and novel prototypes based on features similarity. The module conveniently conducts end-to-end learning and has no strong dependence on clustering numbers like cluster-based method. Besides, a contrastive **enhancement** module is developed to drive models to provide different predictions with the same query features. Our method can be used as an auxiliary module to flexibly integrate into other baselines for a better segmentation performance. Extensive experiments show our approach remarkably improves the performance of state-of-the-art methods for 1-shot and 5-shot segmentation, especially outperforming baseline by 5.9% and 7.3% for 5-shot task on Pascal-5^i and COCO-20^i. Source code is available at https://github.com/zhaoxiaoyu1995/CELP-Pytorch  
### Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
- Authors : Ujjal Kr
- Link : [http://arxiv.org/abs/2112.02891](http://arxiv.org/abs/2112.02891)
> ABSTRACT  :  In this paper, we study the lesser explored avenue of object detection at **night**-time. An object detector trained on abundant labeled daytime images often fails to perform well on **night** images, due to domain gap. As collecting more labeled data from **night**-time is expensive, unpaired generative image translation techniques seek to synthesize **night**-time images. However, unrealistic artifacts often arise on the synthetic images. Illuminating **night**-time inference images also does not work well in practice, as shown in our paper. To address these issues, we suggest a novel technique for enhancing the object detector via Contrastive Learning, which tries to group together embeddings of similar images. To provide anchor-positive image pairs for Contrastive Learning, we leverage Fourier Transformation, which is naturally good at preserving the semantics of an image. For practical benefits in real-time applications, we choose the recently proposed YOLOF single-stage detector, which provides a simple and clean encoder-decoder segregation of the detector network. However, merely trying to teach the encoder to perform well on the auxiliary Contrastive Learning task may lead to catastrophic forgetting of the knowledge essential for object detection. Hence, we train the encoder in a Continual Learning fashion. Our novel method by an elegant training framework achieves state-of-the-art performance on the large scale BDD100K dataset, in an uniform setting, chosen, to the best of our knowledge, for the first time.  
### Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v2 [cs.CV] UPDATED)
- Authors : Zhiyuan You, Yujun Shen, Kai Yang, Wenhan Luo, Xin Lu, Lei Cui, Xinyi Le
- Link : [http://arxiv.org/abs/2201.08959](http://arxiv.org/abs/2201.08959)
> ABSTRACT  :  This work studies the problem of few-shot object counting, which counts the number of exemplar objects (i.e., described by one or several support images) occurring in the query image. The major challenge lies in that the target objects can be densely packed in the query image, making it hard to recognize every single one. To tackle the obstacle, we propose a novel learning block, equipped with a similarity comparison module (SCM) and a feature **enhancement** module (FEM). Concretely, given a support image and a query image, we first derive a score map by comparing their projected features at every spatial position. The score maps regarding all support images are collected together and normalized across both the exemplar dimension and the spatial dimensions, producing a reliable similarity map. We then enhance the query feature with the support features by employing the developed point-wise similarities as the weighting coefficients. Such a design encourages the model to inspect the query image by focusing more on the regions akin to the support images, leading to much clearer boundaries between different objects. Extensive experiments on various benchmarks and training setups suggest that our method surpasses the state-of-the-art approaches by a sufficiently large margin. For instance, on the very recent large-scale FSC-147 dataset, we beat the second competitor by improving the mean absolute counting error from 22.08 to 14.32 (35% $\uparrow$). Code will be made publicly available.  
## eess.IV
---
### Adaptive Cross-Layer Attention for Image **Restoration**. (arXiv:2203.03619v1 [eess.IV])
- Authors : Yancheng Wang, Ning Xu, Chong Chen, Yingzhen Yang
- Link : [http://arxiv.org/abs/2203.03619](http://arxiv.org/abs/2203.03619)
> ABSTRACT  :  Non-local attention module has been proven to be crucial for image **restoration**. Conventional non-local attention processes features of each layer separately, so it risks missing correlation between features among different layers. To address this problem, we propose Cross-Layer Attention (CLA) module in this paper. Instead of finding correlated key pixels within the same layer, each query pixel can attend to key pixels at previous layers of the network. In order to further enhance the learning capability and reduce the inference cost of CLA, we further propose Adaptive CLA, or ACLA, as an improved CLA. Two adaptive designs are proposed for ACLA: 1) adaptively selecting the keys for non-local attention at each layer; 2) automatically searching for the insertion locations for ACLA modules. By these two adaptive designs, ACLA dynamically selects the number of keys to be aggregated for non-local attention at layer. In addition, ACLA searches for the optimal insert positions of ACLA modules by a neural architecture search method to render a compact neural network with compelling performance. Extensive experiments on image **restoration** tasks, including single image super-resolution, image denoising, image demosaicing, and image compression artifacts reduction, validate the effectiveness and efficiency of ACLA.  
### Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
- Authors : Hanieh Naderi, Mohammad Rahmati
- Link : [http://arxiv.org/abs/2203.03621](http://arxiv.org/abs/2203.03621)
> ABSTRACT  :  In this paper, we propose a novel motion-compensated frame rate up-conversion (MC-FRUC) algorithm. The proposed algorithm creates interpolated frames by first estimating motion vectors using unilateral (jointing forward and backward) and **bilateral** motion estimation. Then motion vectors are combined based on adaptive threshold, in order to creates high-quality interpolated frames and reduce block artifacts. Since motion-compensated frame interpolation along unilateral motion trajectories yields holes, a new algorithm is introduced to resolve this problem. The experimental results show that the quality of the interpolated frames using the proposed algorithm is much higher than the existing algorithms.  
### Fusion-Correction Network for Single-**Exposure** Correction and Multi-**Exposure** Fusion. (arXiv:2203.03624v1 [eess.IV])
- Authors : Jin Liang, Anran Zhang, Jun Xu, Hui Li, Xiantong Zhen
- Link : [http://arxiv.org/abs/2203.03624](http://arxiv.org/abs/2203.03624)
> ABSTRACT  :  The photographs captured by digital cameras usually suffer from over-**exposure** or under-**exposure** problems. The Single-**Exposure** Correction (SEC) and Multi-**Exposure** Fusion (MEF) are two widely studied image processing tasks for image **exposure** **enhancement**. However, current SEC and MEF methods ignore the internal correlation between SEC and MEF, and are proposed under distinct frameworks. What's more, most MEF methods usually fail at processing a sequence containing only under-exposed or over-exposed images. To alleviate these problems, in this paper, we develop an integrated framework to simultaneously tackle the SEC and MEF tasks. Built upon the Laplacian Pyramid (LP) decomposition, we propose a novel Fusion-Correction Network (FCNet) to fuse and correct an image sequence sequentially in a multi-level scheme. In each LP level, the image sequence is feed into a Fusion block and a Correction block for consecutive image fusion and **exposure** correction. The corrected image is upsampled and re-composed with the high-frequency detail components in next-level, producing the base sequence for the next-level blocks. Experiments on the benchmark dataset demonstrate that our FCNet is effective on both the SEC and MEF tasks.  
### Learning to Erase the Bayer-Filter to See in the **Dark**. (arXiv:2203.04042v1 [eess.IV])
- Authors : Xingbo Dong, Wanyan Xu, Zhihui Miao, Lan Ma, Chao Zhang, Jiewen Yang, Zhe Jin, Andrew Beng, Jin Teoh, Jiajun Shen
- Link : [http://arxiv.org/abs/2203.04042](http://arxiv.org/abs/2203.04042)
> ABSTRACT  :  **Low-light** image **enhancement** - a pervasive but challenging problem, plays a central role in enhancing the visibility of an image captured in a poor illumination environment. Due to the fact that not all photons can pass the Bayer-Filter on the sensor of the color camera, in this work, we first present a De-Bayer-Filter simulator based on deep neural networks to generate a monochrome raw image from the colored raw image. Next, a fully convolutional network is proposed to achieve the **low-light** image **enhancement** by fusing colored raw data with synthesized monochrome raw data. Channel-wise attention is also introduced to the fusion process to establish a complementary interaction between features from colored and monochrome raw images. To train the convolutional networks, we propose a dataset with monochrome and color raw pairs named Mono-Colored Raw paired dataset (MCR) collected by using a monochrome camera without Bayer-Filter and a color camera with Bayer-Filter. The proposed pipeline take advantages of the fusion of the virtual monochrome and the color raw images and our extensive experiments indicate that significant improvement can be achieved by leveraging raw sensor data and data-driven learning.  
## cs.LG
---
### Towards Efficient Data-Centric Robust Machine Learning with Noise-based Augmentation. (arXiv:2203.03810v1 [cs.LG])
- Authors : Xiaogeng Liu, Haoyu Wang, Yechao Zhang, Fangzhou Wu, Shengshan Hu
- Link : [http://arxiv.org/abs/2203.03810](http://arxiv.org/abs/2203.03810)
> ABSTRACT  :  The data-centric machine learning aims to find effective ways to build appropriate datasets which can improve the performance of AI models. In this paper, we mainly focus on designing an efficient data-centric scheme to improve robustness for models towards unforeseen malicious inputs in the black-box test settings. Specifically, we introduce a noised-based data augmentation method which is composed of Gaussian Noise, Salt-and-Pepper noise, and the PGD adversarial perturbations. The proposed method is built on lightweight algorithms and proved highly effective based on comprehensive evaluations, showing good efficiency on computation cost and robustness **enhancement**. In addition, we share our insights about the data-centric robust machine learning gained from our experiments.  
### Unsupervised Speech **Enhancement** using Dynamical Variational Auto-Encoders. (arXiv:2106.12271v2 [cs.SD] UPDATED)
- Authors : Xiaoyu Bie, Simon Leglaive, Xavier Alameda, Laurent Girin
- Link : [http://arxiv.org/abs/2106.12271](http://arxiv.org/abs/2106.12271)
> ABSTRACT  :  Dynamical variational autoencoders (DVAEs) are a class of deep generative models with latent variables, dedicated to model time series of high-dimensional data. DVAEs can be considered as extensions of the variational autoencoder (VAE) that include temporal dependencies between successive observed and/or latent vectors. Previous work has shown the interest of using DVAEs over the VAE for speech spectrograms modeling. Independently, the VAE has been successfully applied to speech **enhancement** in noise, in an unsupervised noise-agnostic set-up that requires neither noise samples nor noisy speech samples at training time, but only requires clean speech signals. In this paper, we extend these works to DVAE-based single-channel unsupervised speech **enhancement**, hence exploiting both speech signals unsupervised representation learning and dynamics modeling. We propose an unsupervised speech **enhancement** algorithm that combines a DVAE speech prior pre-trained on clean speech signals with a noise model based on nonnegative matrix factorization, and we derive a variational expectation-maximization (VEM) algorithm to perform speech **enhancement**. The algorithm is presented with the most general DVAE formulation and is then applied with three specific DVAE models to illustrate the versatility of the framework. Experimental results show that the proposed DVAE-based approach outperforms its VAE-based counterpart, as well as several supervised and unsupervised noise-dependent baselines, especially when the noise type is unseen during training.  
### Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting. (arXiv:2110.10380v2 [cs.LG] UPDATED)
- Authors : Hyunwook Lee, Seungmin Jin, Hyeshin Chu, Hongkyu Lim, Sungahn Ko
- Link : [http://arxiv.org/abs/2110.10380](http://arxiv.org/abs/2110.10380)
> ABSTRACT  :  Traffic forecasting is a challenging problem due to complex road networks and sudden speed changes caused by various events on roads. A number of models have been proposed to solve this challenging problem with a focus on learning spatio-temporal dependencies of roads. In this work, we propose a new perspective of converting the forecasting problem into a pattern matching task, assuming that large data can be represented by a set of patterns. To evaluate the validness of the new perspective, we design a novel traffic forecasting model, called Pattern-Matching Memory Networks (PM-MemNet), which learns to match input data to the representative patterns with a key-value memory structure. We first extract and cluster representative traffic patterns, which serve as keys in the memory. Then via matching the extracted keys and inputs, PM-MemNet acquires necessary information of existing traffic patterns from the memory and uses it for forecasting. To model spatio-temporal correlation of traffic, we proposed novel memory architecture GCMem, which integrates attention and graph convolution for memory **enhancement**. The experiment results indicate that PM-MemNet is more accurate than state-of-the-art models, such as Graph WaveNet with higher responsiveness. We also present a qualitative analysis result, describing how PM-MemNet works and achieves its higher accuracy when road speed rapidly changes.  
### Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
- Authors : Ujjal Kr
- Link : [http://arxiv.org/abs/2112.02891](http://arxiv.org/abs/2112.02891)
> ABSTRACT  :  In this paper, we study the lesser explored avenue of object detection at **night**-time. An object detector trained on abundant labeled daytime images often fails to perform well on **night** images, due to domain gap. As collecting more labeled data from **night**-time is expensive, unpaired generative image translation techniques seek to synthesize **night**-time images. However, unrealistic artifacts often arise on the synthetic images. Illuminating **night**-time inference images also does not work well in practice, as shown in our paper. To address these issues, we suggest a novel technique for enhancing the object detector via Contrastive Learning, which tries to group together embeddings of similar images. To provide anchor-positive image pairs for Contrastive Learning, we leverage Fourier Transformation, which is naturally good at preserving the semantics of an image. For practical benefits in real-time applications, we choose the recently proposed YOLOF single-stage detector, which provides a simple and clean encoder-decoder segregation of the detector network. However, merely trying to teach the encoder to perform well on the auxiliary Contrastive Learning task may lead to catastrophic forgetting of the knowledge essential for object detection. Hence, we train the encoder in a Continual Learning fashion. Our novel method by an elegant training framework achieves state-of-the-art performance on the large scale BDD100K dataset, in an uniform setting, chosen, to the best of our knowledge, for the first time.  
## cs.AI
---
### Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
- Authors : Hanieh Naderi, Mohammad Rahmati
- Link : [http://arxiv.org/abs/2203.03621](http://arxiv.org/abs/2203.03621)
> ABSTRACT  :  In this paper, we propose a novel motion-compensated frame rate up-conversion (MC-FRUC) algorithm. The proposed algorithm creates interpolated frames by first estimating motion vectors using unilateral (jointing forward and backward) and **bilateral** motion estimation. Then motion vectors are combined based on adaptive threshold, in order to creates high-quality interpolated frames and reduce block artifacts. Since motion-compensated frame interpolation along unilateral motion trajectories yields holes, a new algorithm is introduced to resolve this problem. The experimental results show that the quality of the interpolated frames using the proposed algorithm is much higher than the existing algorithms.  
### Towards Efficient Data-Centric Robust Machine Learning with Noise-based Augmentation. (arXiv:2203.03810v1 [cs.LG])
- Authors : Xiaogeng Liu, Haoyu Wang, Yechao Zhang, Fangzhou Wu, Shengshan Hu
- Link : [http://arxiv.org/abs/2203.03810](http://arxiv.org/abs/2203.03810)
> ABSTRACT  :  The data-centric machine learning aims to find effective ways to build appropriate datasets which can improve the performance of AI models. In this paper, we mainly focus on designing an efficient data-centric scheme to improve robustness for models towards unforeseen malicious inputs in the black-box test settings. Specifically, we introduce a noised-based data augmentation method which is composed of Gaussian Noise, Salt-and-Pepper noise, and the PGD adversarial perturbations. The proposed method is built on lightweight algorithms and proved highly effective based on comprehensive evaluations, showing good efficiency on computation cost and robustness **enhancement**. In addition, we share our insights about the data-centric robust machine learning gained from our experiments.  
### Contrastive **Enhancement** Using Latent Prototype for Few-Shot Segmentation. (arXiv:2203.04095v1 [cs.CV])
- Authors : Xiaoyu Zhao, Xiaoqian Chen, Zhiqiang Gong, Wen Yao, Yunyang Zhang, Xiaohu Zheng
- Link : [http://arxiv.org/abs/2203.04095](http://arxiv.org/abs/2203.04095)
> ABSTRACT  :  Few-shot segmentation enables the model to recognize unseen classes with few annotated examples. Most existing methods adopt prototype learning architecture, where support prototype vectors are expanded and concatenated with query features to perform conditional segmentation. However, such framework potentially focuses more on query features while may neglect the similarity between support and query features. This paper proposes a contrastive **enhancement** approach using latent prototypes to leverage latent classes and raise the utilization of similarity information between prototype and query features. Specifically, a latent prototype sampling module is proposed to generate pseudo-mask and novel prototypes based on features similarity. The module conveniently conducts end-to-end learning and has no strong dependence on clustering numbers like cluster-based method. Besides, a contrastive **enhancement** module is developed to drive models to provide different predictions with the same query features. Our method can be used as an auxiliary module to flexibly integrate into other baselines for a better segmentation performance. Extensive experiments show our approach remarkably improves the performance of state-of-the-art methods for 1-shot and 5-shot segmentation, especially outperforming baseline by 5.9% and 7.3% for 5-shot task on Pascal-5^i and COCO-20^i. Source code is available at https://github.com/zhaoxiaoyu1995/CELP-Pytorch  
### Unsupervised Speech **Enhancement** using Dynamical Variational Auto-Encoders. (arXiv:2106.12271v2 [cs.SD] UPDATED)
- Authors : Xiaoyu Bie, Simon Leglaive, Xavier Alameda, Laurent Girin
- Link : [http://arxiv.org/abs/2106.12271](http://arxiv.org/abs/2106.12271)
> ABSTRACT  :  Dynamical variational autoencoders (DVAEs) are a class of deep generative models with latent variables, dedicated to model time series of high-dimensional data. DVAEs can be considered as extensions of the variational autoencoder (VAE) that include temporal dependencies between successive observed and/or latent vectors. Previous work has shown the interest of using DVAEs over the VAE for speech spectrograms modeling. Independently, the VAE has been successfully applied to speech **enhancement** in noise, in an unsupervised noise-agnostic set-up that requires neither noise samples nor noisy speech samples at training time, but only requires clean speech signals. In this paper, we extend these works to DVAE-based single-channel unsupervised speech **enhancement**, hence exploiting both speech signals unsupervised representation learning and dynamics modeling. We propose an unsupervised speech **enhancement** algorithm that combines a DVAE speech prior pre-trained on clean speech signals with a noise model based on nonnegative matrix factorization, and we derive a variational expectation-maximization (VEM) algorithm to perform speech **enhancement**. The algorithm is presented with the most general DVAE formulation and is then applied with three specific DVAE models to illustrate the versatility of the framework. Experimental results show that the proposed DVAE-based approach outperforms its VAE-based counterpart, as well as several supervised and unsupervised noise-dependent baselines, especially when the noise type is unseen during training.  
### Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
- Authors : Ujjal Kr
- Link : [http://arxiv.org/abs/2112.02891](http://arxiv.org/abs/2112.02891)
> ABSTRACT  :  In this paper, we study the lesser explored avenue of object detection at **night**-time. An object detector trained on abundant labeled daytime images often fails to perform well on **night** images, due to domain gap. As collecting more labeled data from **night**-time is expensive, unpaired generative image translation techniques seek to synthesize **night**-time images. However, unrealistic artifacts often arise on the synthetic images. Illuminating **night**-time inference images also does not work well in practice, as shown in our paper. To address these issues, we suggest a novel technique for enhancing the object detector via Contrastive Learning, which tries to group together embeddings of similar images. To provide anchor-positive image pairs for Contrastive Learning, we leverage Fourier Transformation, which is naturally good at preserving the semantics of an image. For practical benefits in real-time applications, we choose the recently proposed YOLOF single-stage detector, which provides a simple and clean encoder-decoder segregation of the detector network. However, merely trying to teach the encoder to perform well on the auxiliary Contrastive Learning task may lead to catastrophic forgetting of the knowledge essential for object detection. Hence, we train the encoder in a Continual Learning fashion. Our novel method by an elegant training framework achieves state-of-the-art performance on the large scale BDD100K dataset, in an uniform setting, chosen, to the best of our knowledge, for the first time.  
# Paper List
---
## cs.CV
---
**155** new papers in cs.CV:-) 
1. Mammograms Classification: A Review. (arXiv:2203.03618v1 [eess.IV])
2. Adaptive Cross-Layer Attention for Image **Restoration**. (arXiv:2203.03619v1 [eess.IV])
3. Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
4. Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement. (arXiv:2203.03622v1 [eess.IV])
5. Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction. (arXiv:2203.03623v1 [eess.IV])
6. Fusion-Correction Network for Single-**Exposure** Correction and Multi-**Exposure** Fusion. (arXiv:2203.03624v1 [eess.IV])
7. Coordinate Translator for Learning Deformable Medical Image Registration. (arXiv:2203.03626v1 [eess.IV])
8. Multi-channel deep convolutional neural networks for multi-classifying thyroid disease. (arXiv:2203.03627v1 [eess.IV])
9. Student Become Decathlon Master in Retinal Vessel Segmentation via Dual-teacher Multi-target Domain Adaptation. (arXiv:2203.03631v1 [eess.IV])
10. InsightNet: non-contact blood pressure measuring network based on face video. (arXiv:2203.03634v1 [eess.IV])
11. Stepwise Feature Fusion: Local Guides Global. (arXiv:2203.03635v1 [eess.IV])
12. Clustering and classification of low-dimensional data in explicit feature map domain: intraoperative pixel-wise diagnosis of adenocarcinoma of a colon in a liver. (arXiv:2203.03636v1 [eess.IV])
13. Unsupervised Image Registration Towards Enhancing Performance and Explainability in Cardiac And Brain Image Analysis. (arXiv:2203.03638v1 [eess.IV])
14. Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch Decoder Network. (arXiv:2203.03640v1 [eess.IV])
15. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v1 [cs.CV])
16. Object-centric and memory-guided normality reconstruction for video anomaly detection. (arXiv:2203.03677v1 [cs.CV])
17. Monocular Robot Navigation with Self-Supervised Pretrained Vision Transformers. (arXiv:2203.03682v1 [cs.RO])
18. WaveMix: Resource-efficient Token Mixing for Images. (arXiv:2203.03689v1 [cs.CV])
19. Biometric recognition: why not massively adopted yet?. (arXiv:2203.03719v1 [cs.CY])
20. Barlow constrained optimization for Visual Question Answering. (arXiv:2203.03727v1 [cs.CV])
21. CrowdFormer: Weakly-supervised Crowd counting with Improved Generalizability. (arXiv:2203.03768v1 [cs.CV])
22. PAMI-AD: An Activity Detector Exploiting Part-attention and Motion Information in Surveillance Videos. (arXiv:2203.03796v1 [cs.CV])
23. Unknown-Aware Object Detection: Learning What You Don't Know from Videos in the Wild. (arXiv:2203.03800v1 [cs.CV])
24. Panoramic Human Activity Recognition. (arXiv:2203.03806v1 [cs.CV])
25. Image Search with Text Feedback by Additive Attention Compositional Learning. (arXiv:2203.03809v1 [cs.CV])
26. Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction to Treat Diabetic Foot Ulcers. (arXiv:2203.03814v1 [eess.IV])
27. Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon. (arXiv:2203.03818v1 [cs.CV])
28. Table Structure Recognition with Conditional Attention. (arXiv:2203.03819v1 [cs.CV])
29. Coarse-to-Fine Vision Transformer. (arXiv:2203.03821v1 [cs.CV])
30. Deep Rectangling for Image Stitching: A Learning Baseline. (arXiv:2203.03831v1 [cs.CV])
31. Quasi-Balanced Self-Training on Noise-Aware Synthesis of Object Point Clouds for Closing Domain Gap. (arXiv:2203.03833v1 [cs.CV])
32. Multi-Scale Self-Contrastive Learning with Hard Negative Mining for Weakly-Supervised Query-based Video Grounding. (arXiv:2203.03838v1 [cs.CV])
33. Self-supervised Social Relation Representation for Human Group Detection. (arXiv:2203.03843v1 [cs.CV])
34. Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution Networks. (arXiv:2203.03844v1 [eess.IV])
35. Where Does the Performance Improvement Come From? - A Reproducibility Concern about Image-Text Retrieval. (arXiv:2203.03853v1 [cs.IR])
36. A New 27 Class Sign Language Dataset Collected from 173 Individuals. (arXiv:2203.03859v1 [cs.CV])
37. Weakly Supervised Semantic Segmentation using Out-of-Distribution Data. (arXiv:2203.03860v1 [cs.CV])
38. Discriminability-Transferability Trade-Off: An Information-Theoretic Perspective. (arXiv:2203.03871v1 [cs.CV])
39. Visual anomaly detection in video by variational autoencoder. (arXiv:2203.03872v1 [cs.CV])
40. Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels. (arXiv:2203.03884v1 [cs.CV])
41. Boosting Mask R-CNN Performance for Long, Thin Forensic Traces with Pre-Segmentation and IoU Region Merging. (arXiv:2203.03886v1 [cs.CV])
42. ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation. (arXiv:2203.03888v1 [cs.CV])
43. ClearPose: Large-scale Transparent Object Dataset and Benchmark. (arXiv:2203.03890v1 [cs.CV])
44. Multi-Modal Mixup for Robust Fine-tuning. (arXiv:2203.03897v1 [cs.CV])
45. End-to-end system for object detection from sub-sampled radar data. (arXiv:2203.03905v1 [cs.CV])
46. Language Matters: A Weakly Supervised Pre-training Approach for Scene Text Detection and Spotting. (arXiv:2203.03911v1 [cs.CV])
47. Globally-Optimal Event Camera Motion Estimation. (arXiv:2203.03914v1 [cs.CV])
48. Part-Aware Self-Supervised Pre-Training for Person Re-Identification. (arXiv:2203.03931v1 [cs.CV])
49. Dynamic Group Transformer: A General Vision Transformer Backbone with Dynamic Group Attention. (arXiv:2203.03937v1 [cs.CV])
50. An Online Semantic Mapping System for Extending and Enhancing Visual SLAM. (arXiv:2203.03944v1 [cs.RO])
51. RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering. (arXiv:2203.03949v1 [cs.CV])
52. Efficient and Accurate Hyperspectral Pansharpening Using 3D VolumeNet and 2.5D Texture Transfer. (arXiv:2203.03951v1 [cs.CV])
53. EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers. (arXiv:2203.03952v1 [cs.CV])
54. Generative Cooperative Learning for Unsupervised Video Anomaly Detection. (arXiv:2203.03962v1 [cs.CV])
55. GaitStrip: Gait Recognition via Effective Strip-based Feature Representations and Multi-Level Framework. (arXiv:2203.03966v1 [cs.CV])
56. On Generalizing Beyond Domains in Cross-Domain Continual Learning. (arXiv:2203.03970v1 [cs.LG])
57. Universal Prototype Transport for Zero-Shot Action Recognition and Localization. (arXiv:2203.03971v1 [cs.CV])
58. GaitEdge: Beyond Plain End-to-end Gait Recognition for Better Practicality. (arXiv:2203.03972v1 [cs.CV])
59. End-to-end Multiple Instance Learning with Gradient Accumulation. (arXiv:2203.03981v1 [cs.CV])
60. Attention-Based Lip Audio-Visual Synthesis for Talking Face Generation in the Wild. (arXiv:2203.03984v1 [cs.CV])
61. SimpleTrack: Rethinking and Improving the JDE Approach for Multi-Object Tracking. (arXiv:2203.03985v1 [cs.CV])
62. Skating-Mixer: Multimodal MLP for Scoring Figure Skating. (arXiv:2203.03990v1 [cs.CV])
63. DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos. (arXiv:2203.03996v1 [cs.CV])
64. Visual-Language Navigation Pretraining via Prompt-based Environmental Self-exploration. (arXiv:2203.04006v1 [cs.CV])
65. DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set Feature Extraction. (arXiv:2203.04007v1 [cs.CV])
66. Evolutionary Neural Cascade Search across Supernetworks. (arXiv:2203.04011v1 [cs.CV])
67. Mutual Contrastive Learning to Disentangle Whole Slide Image Representations for Glioma Grading. (arXiv:2203.04013v1 [eess.IV])
68. Data augmentation with mixtures of max-entropy transformations for filling-level classification. (arXiv:2203.04027v1 [cs.LG])
69. Stage-Aware Feature Alignment Network for Real-Time Semantic Segmentation of Street Scenes. (arXiv:2203.04031v1 [cs.CV])
70. StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pretrained StyleGAN. (arXiv:2203.04036v1 [cs.CV])
71. Deep Multi-Branch Aggregation Network for Real-Time Semantic Segmentation in Street Scenes. (arXiv:2203.04037v1 [cs.CV])
72. Gait Recognition with Mask-based Regularization. (arXiv:2203.04038v1 [cs.CV])
73. Shape-invariant 3D Adversarial Point Clouds. (arXiv:2203.04041v1 [cs.CV])
74. Learning to Erase the Bayer-Filter to See in the **Dark**. (arXiv:2203.04042v1 [eess.IV])
75. Graph Attention Transformer Network for Multi-Label Image Classification. (arXiv:2203.04049v1 [cs.CV])
76. BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary Camera Rigs. (arXiv:2203.04050v1 [cs.CV])
77. Counting with Adaptive Auxiliary Learning. (arXiv:2203.04061v1 [cs.CV])
78. Analyzing General-Purpose Deep-Learning Detection and Segmentation Models with Images from a Lidar as a Camera Sensor. (arXiv:2203.04064v1 [cs.RO])
79. Lane Detection with Versatile AtrousFormer and Local Semantic Guidance. (arXiv:2203.04067v1 [cs.CV])
80. E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation. (arXiv:2203.04074v1 [cs.CV])
81. Semantic Distillation Guided Salient Object Detection. (arXiv:2203.04076v1 [cs.CV])
82. Exploration of Various Deep Learning Models for Increased Accuracy in Automatic Polyp Detection. (arXiv:2203.04093v1 [eess.IV])
83. Contrastive **Enhancement** Using Latent Prototype for Few-Shot Segmentation. (arXiv:2203.04095v1 [cs.CV])
84. VoViT: Low Latency Graph-based Audio-Visual Voice Separation Transformer. (arXiv:2203.04099v1 [cs.SD])
85. Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies. (arXiv:2203.04107v1 [eess.IV])
86. Explaining Classifiers by Constructing Familiar Concepts. (arXiv:2203.04109v1 [cs.CV])
87. Quantification of Occlusion Handling Capability of a 3D Human Pose Estimation Framework. (arXiv:2203.04113v1 [cs.CV])
88. A study on joint modeling and data augmentation of multi-modalities for audio-visual scene classification. (arXiv:2203.04114v1 [cs.MM])
89. An Efficient Polyp Segmentation Network. (arXiv:2203.04118v1 [eess.IV])
90. Few Shot Generative Model Adaption via Relaxed Spatial Structural Alignment. (arXiv:2203.04121v1 [cs.CV])
91. YouTube-GDD: A challenging gun detection dataset with rich contextual information. (arXiv:2203.04129v1 [cs.CV])
92. NeReF: Neural Refractive Field for Fluid Surface Reconstruction and Implicit Representation. (arXiv:2203.04130v1 [cs.CV])
93. Motron: Multimodal Probabilistic Human Motion Forecasting. (arXiv:2203.04132v1 [cs.CV])
94. Easy Ensemble: Simple Deep Ensemble Learning for Sensor-Based Human Activity Recognition. (arXiv:2203.04153v1 [cs.CV])
95. Robust Local Preserving and Global Aligning Network for Adversarial Domain Adaptation. (arXiv:2203.04156v1 [cs.CV])
96. Understanding person identification via gait. (arXiv:2203.04179v1 [cs.CR])
97. Tuning-free multi-coil compressed sensing MRI with Parallel Variable Density Approximate Message Passing (P-VDAMP). (arXiv:2203.04180v1 [math.NA])
98. Selective-Supervised Contrastive Learning with Noisy Labels. (arXiv:2203.04181v1 [cs.CV])
99. MLSeg: Image and Video Segmentation as Multi-Label Classification and Selected-Label Pixel Classification. (arXiv:2203.04187v1 [cs.CV])
100. A Gating Model for Bias Calibration in Generalized Zero-shot Learning. (arXiv:2203.04195v1 [cs.LG])
101. Trustable Co-label Learning from Multiple Noisy Annotators. (arXiv:2203.04199v1 [cs.LG])
102. AssistQ: Affordance-centric Question-driven Task Completion for Egocentric Assistant. (arXiv:2203.04203v1 [cs.CV])
103. Lightweight Monocular Depth Estimation through Guided Decoding. (arXiv:2203.04206v1 [cs.CV])
104. Towards Universal Texture Synthesis by Combining Texton Broadcasting with Noise Injection in StyleGAN-2. (arXiv:2203.04221v1 [cs.CV])
105. Neural Face Identification in a 2D Wireframe Projection of a Manifold Object. (arXiv:2203.04229v1 [cs.CV])
106. A Lightweight and Detector-free 3D Single Object Tracker on Point Clouds. (arXiv:2203.04232v1 [cs.CV])
107. End-to-End Semi-Supervised Learning for Video Action Detection. (arXiv:2203.04251v1 [cs.CV])
108. Robust Multi-Task Learning and Online Refinement for Spacecraft Pose Estimation across Domain Gap. (arXiv:2203.04275v1 [cs.CV])
109. Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences. (arXiv:2203.04279v1 [cs.CV])
110. Proximal PanNet: A Model-Based Deep Network for Pansharpening. (arXiv:2203.04286v1 [cs.CV])
111. A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation. (arXiv:2203.04287v1 [cs.CV])
112. A Semi-Supervised Framework for Automatic Pixel-Wise Breast Cancer Grading of Histological Images. (arXiv:1907.01696v2 [cs.CV] UPDATED)
113. Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v13 [cs.LG] UPDATED)
114. Geography-Aware Self-Supervised Learning. (arXiv:2011.09980v7 [cs.CV] UPDATED)
115. Forecasting Characteristic 3D Poses of Human Actions. (arXiv:2011.15079v3 [cs.CV] UPDATED)
116. Ensemble deep learning: A review. (arXiv:2104.02395v2 [cs.LG] UPDATED)
117. Few-Shot Segmentation via Cycle-Consistent Transformer. (arXiv:2106.02320v4 [cs.CV] UPDATED)
118. Delving Deep into the Generalization of Vision Transformers under Distribution Shifts. (arXiv:2106.07617v4 [cs.CV] UPDATED)
119. RPR-Net: A Point Cloud-based Rotation-aware Large Scale Place Recognition Network. (arXiv:2108.12790v2 [cs.CV] UPDATED)
120. CAM-loss: Towards Learning Spatially Discriminative Feature Representations. (arXiv:2109.01359v2 [cs.CV] UPDATED)
121. A Deep Learning-Based Unified Framework for Red Lesions Detection on Retinal Fundus Images. (arXiv:2109.05021v3 [eess.IV] UPDATED)
122. Contrastive Quantization with Code Memory for Unsupervised Image Retrieval. (arXiv:2109.05205v2 [cs.CV] UPDATED)
123. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v2 [cs.CV] UPDATED)
124. Deep Instance Segmentation with High-Resolution Automotive Radar. (arXiv:2110.01775v3 [cs.CV] UPDATED)
125. Sim2Air - Synthetic aerial dataset for UAV monitoring. (arXiv:2110.05145v2 [cs.CV] UPDATED)
126. Probabilistic Contrastive Learning for Domain Adaptation. (arXiv:2111.06021v3 [cs.CV] UPDATED)
127. IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for Zero-Shot Network Quantization. (arXiv:2111.09136v4 [cs.CV] UPDATED)
128. Open Vocabulary Object Detection with Pseudo Bounding-Box Labels. (arXiv:2111.09452v2 [cs.CV] UPDATED)
129. Positional Encoder Graph Neural Networks for Geographic Data. (arXiv:2111.10144v2 [cs.LG] UPDATED)
130. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v4 [cs.CV] UPDATED)
131. AirDet: Few-Shot Detection without Fine-tuning for Autonomous Exploration. (arXiv:2112.01740v2 [cs.CV] UPDATED)
132. Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
133. MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for Few-shot Video Classification. (arXiv:2112.04585v2 [cs.CV] UPDATED)
134. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. (arXiv:2112.10741v3 [cs.CV] UPDATED)
135. Roadside Lidar Vehicle Detection and Tracking Using Range And Intensity Background Subtraction. (arXiv:2201.04756v4 [cs.CV] UPDATED)
136. AI Singapore Trusted Media Challenge Dataset. (arXiv:2201.04788v2 [cs.CV] UPDATED)
137. Flexible Style Image Super-Resolution using Conditional Objective. (arXiv:2201.04898v3 [cs.CV] UPDATED)
138. Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. (arXiv:2201.07207v2 [cs.LG] UPDATED)
139. Point-NeRF: Point-based Neural Radiance Fields. (arXiv:2201.08845v3 [cs.CV] UPDATED)
140. Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v2 [cs.CV] UPDATED)
141. Writer Recognition Using Off-line Handwritten Single Block Characters. (arXiv:2201.10665v2 [cs.CV] UPDATED)
142. On the Issues of TrueDepth Sensor Data for Computer Vision Tasks Across Different iPad Generations. (arXiv:2201.10865v2 [cs.CV] UPDATED)
143. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v2 [cs.CV] UPDATED)
144. Edge-Selective Feature Weaving for Point Cloud Matching. (arXiv:2202.02149v3 [cs.CV] UPDATED)
145. Visual Attention Network. (arXiv:2202.09741v3 [cs.CV] UPDATED)
146. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v3 [cs.CR] UPDATED)
147. Learning Transferable Reward for Query Object Localization with Policy Adaptation. (arXiv:2202.12403v2 [cs.CV] UPDATED)
148. Diffeomorphic Image Registration with Neural Velocity Field. (arXiv:2202.12498v2 [cs.CV] UPDATED)
149. Extracting Effective Subnetworks with Gumebel-Softmax. (arXiv:2202.12986v2 [cs.CV] UPDATED)
150. Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and Cycle Idempotence. (arXiv:2203.00911v2 [eess.IV] UPDATED)
151. Recovering 3D Human Mesh from Monocular Images: A Survey. (arXiv:2203.01923v2 [cs.CV] UPDATED)
152. Federated and Generalized Person Re-identification through Domain and Feature Hallucinating. (arXiv:2203.02689v2 [cs.CV] UPDATED)
153. Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation. (arXiv:2203.02925v2 [cs.CV] UPDATED)
154. Adversarial Texture for Fooling Person Detectors in the Physical World. (arXiv:2203.03373v2 [cs.CV] UPDATED)
155. Graph Neural Networks for Image Classification and Reinforcement Learning using Graph representations. (arXiv:2203.03457v2 [cs.LG] UPDATED)
## eess.IV
---
**26** new papers in eess.IV:-) 
1. Mammograms Classification: A Review. (arXiv:2203.03618v1 [eess.IV])
2. Adaptive Cross-Layer Attention for Image **Restoration**. (arXiv:2203.03619v1 [eess.IV])
3. Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
4. Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement. (arXiv:2203.03622v1 [eess.IV])
5. Measurement-conditioned Denoising Diffusion Probabilistic Model for Under-sampled Medical Image Reconstruction. (arXiv:2203.03623v1 [eess.IV])
6. Fusion-Correction Network for Single-**Exposure** Correction and Multi-**Exposure** Fusion. (arXiv:2203.03624v1 [eess.IV])
7. Coordinate Translator for Learning Deformable Medical Image Registration. (arXiv:2203.03626v1 [eess.IV])
8. Multi-channel deep convolutional neural networks for multi-classifying thyroid disease. (arXiv:2203.03627v1 [eess.IV])
9. Student Become Decathlon Master in Retinal Vessel Segmentation via Dual-teacher Multi-target Domain Adaptation. (arXiv:2203.03631v1 [eess.IV])
10. InsightNet: non-contact blood pressure measuring network based on face video. (arXiv:2203.03634v1 [eess.IV])
11. Stepwise Feature Fusion: Local Guides Global. (arXiv:2203.03635v1 [eess.IV])
12. Clustering and classification of low-dimensional data in explicit feature map domain: intraoperative pixel-wise diagnosis of adenocarcinoma of a colon in a liver. (arXiv:2203.03636v1 [eess.IV])
13. Unsupervised Image Registration Towards Enhancing Performance and Explainability in Cardiac And Brain Image Analysis. (arXiv:2203.03638v1 [eess.IV])
14. Conquering Data Variations in Resolution: A Slice-Aware Multi-Branch Decoder Network. (arXiv:2203.03640v1 [eess.IV])
15. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v1 [cs.CV])
16. Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction to Treat Diabetic Foot Ulcers. (arXiv:2203.03814v1 [eess.IV])
17. Dynamic Dual Trainable Bounds for Ultra-low Precision Super-Resolution Networks. (arXiv:2203.03844v1 [eess.IV])
18. Mutual Contrastive Learning to Disentangle Whole Slide Image Representations for Glioma Grading. (arXiv:2203.04013v1 [eess.IV])
19. Learning to Erase the Bayer-Filter to See in the **Dark**. (arXiv:2203.04042v1 [eess.IV])
20. Exploration of Various Deep Learning Models for Increased Accuracy in Automatic Polyp Detection. (arXiv:2203.04093v1 [eess.IV])
21. Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies. (arXiv:2203.04107v1 [eess.IV])
22. An Efficient Polyp Segmentation Network. (arXiv:2203.04118v1 [eess.IV])
23. Tuning-free multi-coil compressed sensing MRI with Parallel Variable Density Approximate Message Passing (P-VDAMP). (arXiv:2203.04180v1 [math.NA])
24. A Deep Learning-Based Unified Framework for Red Lesions Detection on Retinal Fundus Images. (arXiv:2109.05021v3 [eess.IV] UPDATED)
25. Flexible Style Image Super-Resolution using Conditional Objective. (arXiv:2201.04898v3 [cs.CV] UPDATED)
26. Towards Bidirectional Arbitrary Image Rescaling: Joint Optimization and Cycle Idempotence. (arXiv:2203.00911v2 [eess.IV] UPDATED)
## cs.LG
---
**163** new papers in cs.LG:-) 
1. Responsible AI in Healthcare. (arXiv:2203.03616v1 [cs.CY])
2. Mammograms Classification: A Review. (arXiv:2203.03618v1 [eess.IV])
3. Clustering and classification of low-dimensional data in explicit feature map domain: intraoperative pixel-wise diagnosis of adenocarcinoma of a colon in a liver. (arXiv:2203.03636v1 [eess.IV])
4. Unsupervised Image Registration Towards Enhancing Performance and Explainability in Cardiac And Brain Image Analysis. (arXiv:2203.03638v1 [eess.IV])
5. Unsupervised Domain Adaptation with Contrastive Learning for OCT Segmentation. (arXiv:2203.03664v1 [cs.CV])
6. A Typology to Explore and Guide Explanatory Interactive Machine Learning. (arXiv:2203.03668v1 [cs.LG])
7. AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators. (arXiv:2203.03673v1 [stat.ML])
8. Learn to Match with No Regret: Reinforcement Learning in Markov Matching Markets. (arXiv:2203.03684v1 [cs.LG])
9. WaveMix: Resource-efficient Token Mixing for Images. (arXiv:2203.03689v1 [cs.CV])
10. HyperMixer: An MLP-based Green AI Alternative to Transformers. (arXiv:2203.03691v1 [cs.CL])
11. Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks. (arXiv:2203.03692v1 [cs.LG])
12. Learning to Bound: A Generative Cram\'er-Rao Bound. (arXiv:2203.03695v1 [cs.LG])
13. Detection of AI Synthesized Hindi Speech. (arXiv:2203.03706v1 [cs.SD])
14. A Predictive Model for Student Performance in Classrooms Using Student Interactions With an eTextbook. (arXiv:2203.03713v1 [cs.CY])
15. Open-Ended Knowledge Tracing. (arXiv:2203.03716v1 [cs.CY])
16. Biometric recognition: why not massively adopted yet?. (arXiv:2203.03719v1 [cs.CY])
17. Cognitive Diagnosis with Explicit Student Vector Estimation and Unsupervised Question Matrix Learning. (arXiv:2203.03722v1 [cs.CY])
18. A New Era: Intelligent Tutoring Systems Will Transform Online Learning for Millions. (arXiv:2203.03724v1 [cs.CY])
19. Robustness and Usefulness in AI Explanation Methods. (arXiv:2203.03729v1 [cs.LG])
20. Provably Accurate and Scalable Linear Classifiers in Hyperbolic Spaces. (arXiv:2203.03730v1 [cs.LG])
21. A Push-Relabel Based Additive Approximation for Optimal Transport. (arXiv:2203.03732v1 [cs.LG])
22. Flat minima generalize for low-rank matrix recovery. (arXiv:2203.03756v1 [cs.LG])
23. The Fundamental Price of Secure Aggregation in Differentially Private Federated Learning. (arXiv:2203.03761v1 [cs.LG])
24. Defending Graph Convolutional Networks against Dynamic Graph Perturbations via Bayesian Self-supervision. (arXiv:2203.03762v1 [cs.LG])
25. Static Prediction of Runtime Errors by Learning to Execute Programs with External Resource Descriptions. (arXiv:2203.03771v1 [cs.LG])
26. Zero-delay Consistent and Smooth Trainable Interpolation. (arXiv:2203.03776v1 [cs.LG])
27. Data adaptive RKHS Tikhonov regularization for learning kernels in operators. (arXiv:2203.03791v1 [stat.ML])
28. YONO: Modeling Multiple Heterogeneous Neural Networks on Microcontrollers. (arXiv:2203.03794v1 [cs.LG])
29. Learning Sensorimotor Primitives of Sequential Manipulation Tasks from Visual Demonstrations. (arXiv:2203.03797v1 [cs.RO])
30. New Insights on Reducing Abrupt Representation Change in Online Continual Learning. (arXiv:2203.03798v1 [cs.LG])
31. A Fast Scale-Invariant Algorithm for Non-negative Least Squares with Non-negative Data. (arXiv:2203.03808v1 [math.OC])
32. Towards Efficient Data-Centric Robust Machine Learning with Noise-based Augmentation. (arXiv:2203.03810v1 [cs.LG])
33. Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction to Treat Diabetic Foot Ulcers. (arXiv:2203.03814v1 [eess.IV])
34. Informative Planning for Worst-Case Error Minimisation in Sparse Gaussian Process Regression. (arXiv:2203.03828v1 [cs.RO])
35. Multi-Scale Self-Contrastive Learning with Hard Negative Mining for Weakly-Supervised Query-based Video Grounding. (arXiv:2203.03838v1 [cs.CV])
36. Occupancy Flow Fields for Motion Forecasting in Autonomous Driving. (arXiv:2203.03875v1 [cs.RO])
37. High-order Order Proximity-Incorporated, Symmetry and Graph-Regularized Nonnegative Matrix Factorization for Community Detection. (arXiv:2203.03876v1 [cs.SI])
38. Multi-Modal Mixup for Robust Fine-tuning. (arXiv:2203.03897v1 [cs.CV])
39. Noisy Low-rank Matrix Optimization: Geometry of Local Minima and Convergence Rate. (arXiv:2203.03899v1 [math.OC])
40. Graph Reinforcement Learning for Predictive Power Allocation to Mobile Users. (arXiv:2203.03906v1 [cs.LG])
41. Estimating the average causal effect of intervention in continuous variables using machine learning. (arXiv:2203.03916v1 [stat.ML])
42. An Analysis of Measure-Valued Derivatives for Policy Gradients. (arXiv:2203.03917v1 [cs.LG])
43. Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks. (arXiv:2203.03929v1 [cs.LG])
44. Digital Speech Algorithms for Speaker De-Identification. (arXiv:2203.03932v1 [cs.SD])
45. A Preliminary Study on Aging Examining Online Handwriting. (arXiv:2203.03933v1 [cs.HC])
46. Nonlinear Isometric Manifold Learning for Injective Normalizing Flows. (arXiv:2203.03934v1 [cs.LG])
47. Few-Shot Traffic Prediction with Graph Networks using Locale as Relational Inductive Biases. (arXiv:2203.03965v1 [cs.LG])
48. On Generalizing Beyond Domains in Cross-Domain Continual Learning. (arXiv:2203.03970v1 [cs.LG])
49. Contrastive Conditional Neural Processes. (arXiv:2203.03978v1 [cs.LG])
50. Online Weak-form Sparse Identification of Partial Differential Equations. (arXiv:2203.03979v1 [math.OC])
51. End-to-end Multiple Instance Learning with Gradient Accumulation. (arXiv:2203.03981v1 [cs.CV])
52. Adapt$\mathcal{O}$r: Objective-Centric Adaptation Framework for Language Models. (arXiv:2203.03989v1 [cs.CL])
53. Sparsification and Filtering for Spatial-temporal GNN in Multivariate Time-series. (arXiv:2203.03991v1 [cs.LG])
54. DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos. (arXiv:2203.03996v1 [cs.CV])
55. Semi-Random Sparse Recovery in Nearly-Linear Time. (arXiv:2203.04002v1 [cs.DS])
56. A Compilation Flow for the Generation of CNN Inference Accelerators on FPGAs. (arXiv:2203.04015v1 [cs.DC])
57. Data augmentation with mixtures of max-entropy transformations for filling-level classification. (arXiv:2203.04027v1 [cs.LG])
58. Bayesian Optimisation-Assisted Neural Network Training Technique for Radio Localisation. (arXiv:2203.04032v1 [cs.LG])
59. Robot Learning of Mobile Manipulation with Reachability Behavior Priors. (arXiv:2203.04051v1 [cs.RO])
60. AdaPT: Fast Emulation of Approximate DNN Accelerators in PyTorch. (arXiv:2203.04071v1 [cs.LG])
61. Obstacle Aware Sampling for Path Planning. (arXiv:2203.04075v1 [cs.RO])
62. The role of alcohol outlet visits derived from mobile phone location data in enhancing domestic violence prediction at the neighborhood level. (arXiv:2203.04088v1 [cs.CY])
63. COLA: Consistent Learning with Opponent-Learning Awareness. (arXiv:2203.04098v1 [cs.LG])
64. VoViT: Low Latency Graph-based Audio-Visual Voice Separation Transformer. (arXiv:2203.04099v1 [cs.SD])
65. Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies. (arXiv:2203.04107v1 [eess.IV])
66. Explaining Classifiers by Constructing Familiar Concepts. (arXiv:2203.04109v1 [cs.CV])
67. Plumeria at SemEval-2022 Task 6: Robust Approaches for Sarcasm Detection for English and Arabic Using Transformers and Data Augmentation. (arXiv:2203.04111v1 [cs.CL])
68. Biological Sequence Design with GFlowNets. (arXiv:2203.04115v1 [q-bio.BM])
69. Graph-based Reinforcement Learning meets Mixed Integer Programs: An application to 3D robot assembly discovery. (arXiv:2203.04120v1 [cs.RO])
70. Motron: Multimodal Probabilistic Human Motion Forecasting. (arXiv:2203.04132v1 [cs.CV])
71. Robustly-reliable learners under poisoning attacks. (arXiv:2203.04160v1 [cs.LG])
72. Variational methods for simulation-based inference. (arXiv:2203.04176v1 [stat.ML])
73. Selective-Supervised Contrastive Learning with Noisy Labels. (arXiv:2203.04181v1 [cs.CV])
74. Enhancing Mechanical Metamodels with a Generative Model-Based Augmented Training Dataset. (arXiv:2203.04183v1 [cs.LG])
75. Neural Contextual Bandits via Reward-Biased Maximum Likelihood Estimation. (arXiv:2203.04192v1 [cs.LG])
76. A Gating Model for Bias Calibration in Generalized Zero-shot Learning. (arXiv:2203.04195v1 [cs.LG])
77. Locate This, Not That: Class-Conditioned Sound Event DOA Estimation. (arXiv:2203.04197v1 [eess.AS])
78. Trustable Co-label Learning from Multiple Noisy Annotators. (arXiv:2203.04199v1 [cs.LG])
79. Follow the Water: Finding Water, Snow and Clouds on Terrestrial Exoplanets with Photometry and Machine Learning. (arXiv:2203.04201v1 [astro-ph.EP])
80. Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data. (arXiv:2203.04218v1 [cs.RO])
81. Learning based Age of Information Minimization in UAV-relayed IoT Networks. (arXiv:2203.04227v1 [cs.IT])
82. A Sharp Characterization of Linear Estimators for Offline Policy Evaluation. (arXiv:2203.04236v1 [cs.LG])
83. Dual Lottery Ticket Hypothesis. (arXiv:2203.04248v1 [cs.LG])
84. Second-life Lithium-ion batteries: A chemistry-agnostic and scalable health estimation algorithm. (arXiv:2203.04249v1 [eess.SY])
85. Policy-Based Bayesian Experimental Design for Non-Differentiable Implicit Models. (arXiv:2203.04272v1 [cs.LG])
86. Leveraging Initial Hints for Free in Stochastic Linear Bandits. (arXiv:2203.04274v1 [cs.LG])
87. Robust Multi-Task Learning and Online Refinement for Spacecraft Pose Estimation across Domain Gap. (arXiv:2203.04275v1 [cs.CV])
88. Convergence Rates for Gaussian Mixtures of Experts. (arXiv:1907.04377v2 [math.ST] UPDATED)
89. Universal Graph Transformer Self-Attention Networks. (arXiv:1909.11855v13 [cs.LG] UPDATED)
90. Distributed Learning of Deep Neural Networks using Independent Subnet Training. (arXiv:1910.02120v6 [cs.LG] UPDATED)
91. Nonconvex Matrix Completion with Linearly Parameterized Factors. (arXiv:2003.13153v2 [math.ST] UPDATED)
92. QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings. (arXiv:2009.12517v2 [cs.CL] UPDATED)
93. Improving Sequential Latent Variable Models with Autoregressive Flows. (arXiv:2010.03172v2 [cs.LG] UPDATED)
94. FAR: A General Framework for Attributional Robustness. (arXiv:2010.07393v2 [cs.LG] UPDATED)
95. Forecasting Characteristic 3D Poses of Human Actions. (arXiv:2011.15079v3 [cs.CV] UPDATED)
96. Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v5 [cs.AI] UPDATED)
97. Strength of Minibatch Noise in SGD. (arXiv:2102.05375v3 [cs.LG] UPDATED)
98. On the Initialization for Convex-Concave Min-max Problems. (arXiv:2103.00284v2 [math.OC] UPDATED)
99. Constrained Learning with Non-Convex Losses. (arXiv:2103.05134v3 [cs.LG] UPDATED)
100. Encoding Event-Based Data With a Hybrid SNN Guided Variational Auto-encoder in Neuromorphic Hardware. (arXiv:2104.00165v2 [cs.NE] UPDATED)
101. Accounting for uncertainty of non-linear regression models by divisive data resorting. (arXiv:2104.01714v4 [cs.LG] UPDATED)
102. Ensemble deep learning: A review. (arXiv:2104.02395v2 [cs.LG] UPDATED)
103. Hypernetwork Dismantling via Deep Reinforcement Learning. (arXiv:2104.14332v2 [cs.LG] UPDATED)
104. Evidential Turing Processes. (arXiv:2106.01216v3 [cs.LG] UPDATED)
105. Forward Looking Best-Response Multiplicative Weights Update Methods for Bilinear Zero-sum Games. (arXiv:2106.03579v3 [cs.GT] UPDATED)
106. PEARL: Data Synthesis via Private Embeddings and Adversarial Reconstruction Learning. (arXiv:2106.04590v2 [cs.LG] UPDATED)
107. Taxonomy of Machine Learning Safety: A Survey and Primer. (arXiv:2106.04823v2 [cs.LG] UPDATED)
108. RFpredInterval: An R Package for Prediction Intervals with Random Forests and Boosted Forests. (arXiv:2106.08217v2 [stat.ML] UPDATED)
109. Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization. (arXiv:2106.09215v3 [stat.ML] UPDATED)
110. ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models. (arXiv:2106.12248v3 [cs.LG] UPDATED)
111. Unsupervised Speech **Enhancement** using Dynamical Variational Auto-Encoders. (arXiv:2106.12271v2 [cs.SD] UPDATED)
112. You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks. (arXiv:2106.13264v3 [cs.LG] UPDATED)
113. Valid prediction intervals for regression problems. (arXiv:2107.00363v3 [stat.ML] UPDATED)
114. GIFAIR-FL: A Framework for Group and Individual Fairness in Federated Learning. (arXiv:2108.02741v2 [cs.LG] UPDATED)
115. A general class of surrogate functions for stable and efficient reinforcement learning. (arXiv:2108.05828v4 [cs.LG] UPDATED)
116. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v2 [cs.CV] UPDATED)
117. Measuring Fairness under Unawareness of Sensitive Attributes: A Quantification-Based Approach. (arXiv:2109.08549v2 [cs.CY] UPDATED)
118. Secure PAC Bayesian Regression via Real Shamir Secret Sharing. (arXiv:2109.11200v2 [cs.LG] UPDATED)
119. Prune Your Model Before Distill It. (arXiv:2109.14960v2 [cs.LG] UPDATED)
120. A Review of the Gumbel-max Trick and its Extensions for Discrete Stochasticity in Machine Learning. (arXiv:2110.01515v2 [cs.LG] UPDATED)
121. EntQA: Entity Linking as Question Answering. (arXiv:2110.02369v2 [cs.CL] UPDATED)
122. Hierarchical Potential-based Reward Shaping from Task Specifications. (arXiv:2110.02792v2 [cs.LG] UPDATED)
123. A Deep Generative Model for Reordering Adjacency Matrices. (arXiv:2110.04971v3 [cs.HC] UPDATED)
124. Information Theoretic Structured Generative Modeling. (arXiv:2110.05794v2 [cs.LG] UPDATED)
125. Learning to Remember Patterns: Pattern Matching Memory Networks for Traffic Forecasting. (arXiv:2110.10380v2 [cs.LG] UPDATED)
126. Does the Data Induce Capacity Control in Deep Learning?. (arXiv:2110.14163v2 [cs.LG] UPDATED)
127. Nonnegative Tucker Decomposition with Beta-divergence for Music Structure Analysis of audio signals. (arXiv:2110.14434v3 [cs.SD] UPDATED)
128. Exploring single-song autoencoding schemes for audio-based music structure analysis. (arXiv:2110.14437v2 [cs.SD] UPDATED)
129. Manipulation of granular materials by learning particle interactions. (arXiv:2111.02274v2 [cs.RO] UPDATED)
130. Tight bounds for minimum l1-norm interpolation of noisy data. (arXiv:2111.05987v2 [math.ST] UPDATED)
131. Positional Encoder Graph Neural Networks for Geographic Data. (arXiv:2111.10144v2 [cs.LG] UPDATED)
132. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v4 [cs.CV] UPDATED)
133. Adversarial Attacks in Cooperative AI. (arXiv:2111.14833v3 [cs.LG] UPDATED)
134. Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
135. MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for Few-shot Video Classification. (arXiv:2112.04585v2 [cs.CV] UPDATED)
136. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. (arXiv:2112.04906v3 [math.OC] UPDATED)
137. Confidence intervals for the random forest generalization error. (arXiv:2112.06101v2 [stat.ML] UPDATED)
138. GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models. (arXiv:2112.10741v3 [cs.CV] UPDATED)
139. ViNMT: Neural Machine Translation Toolkit. (arXiv:2112.15272v5 [cs.CL] UPDATED)
140. Solving Inventory Management Problems with Inventory-dynamics-informed Neural Networks. (arXiv:2201.06126v3 [cs.LG] UPDATED)
141. A New Look at Dynamic Regret for Non-Stationary Stochastic Bandits. (arXiv:2201.06532v3 [cs.LG] UPDATED)
142. Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. (arXiv:2201.07207v2 [cs.LG] UPDATED)
143. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v2 [cs.LG] UPDATED)
144. Any Variational Autoencoder Can Do Arbitrary Conditioning. (arXiv:2201.12414v2 [cs.LG] UPDATED)
145. Training a Bidirectional GAN-based One-Class Classifier for Network Intrusion Detection. (arXiv:2202.01332v2 [cs.LG] UPDATED)
146. Variational Nearest Neighbor Gaussian Processes. (arXiv:2202.01694v2 [cs.LG] UPDATED)
147. Practical Imitation Learning in the Real World via Task Consistency Loss. (arXiv:2202.01862v2 [cs.RO] UPDATED)
148. Independent Policy Gradient for Large-Scale Markov Potential Games: Sharper Rates, Function Approximation, and Game-Agnostic Convergence. (arXiv:2202.04129v2 [cs.LG] UPDATED)
149. Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries. (arXiv:2202.08549v2 [cs.LG] UPDATED)
150. MuMiN: A Large-Scale Multilingual Multimodal Fact-Checked Misinformation Social Network Dataset. (arXiv:2202.11684v2 [cs.LG] UPDATED)
151. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v3 [cs.CR] UPDATED)
152. Learning Transferable Reward for Query Object Localization with Policy Adaptation. (arXiv:2202.12403v2 [cs.CV] UPDATED)
153. Personalized Federated Learning With Structure. (arXiv:2203.00829v4 [cs.LG] UPDATED)
154. Discontinuous Constituency and BERT: A Case Study of Dutch. (arXiv:2203.01063v2 [cs.CL] UPDATED)
155. Evolving Curricula with Regret-Based Environment Design. (arXiv:2203.01302v2 [cs.LG] UPDATED)
156. Generative Modeling for Low Dimensional Speech Attributes with Neural Spline Flows. (arXiv:2203.01786v2 [cs.SD] UPDATED)
157. KamNet: An Integrated Spatiotemporal Deep Neural Network for Rare Event Search in KamLAND-Zen. (arXiv:2203.01870v4 [physics.ins-det] UPDATED)
158. Graph clustering with Boltzmann machines. (arXiv:2203.02471v2 [cs.LG] UPDATED)
159. A Small Gain Analysis of Single Timescale Actor Critic. (arXiv:2203.02591v2 [math.OC] UPDATED)
160. Covariate-Balancing-Aware Interpretable Deep Learning models for Treatment Effect Estimation. (arXiv:2203.03185v2 [stat.ML] UPDATED)
161. Graph Neural Networks for Image Classification and Reinforcement Learning using Graph representations. (arXiv:2203.03457v2 [cs.LG] UPDATED)
162. TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs. (arXiv:2203.03564v2 [cs.LG] UPDATED)
163. Learning Parameters for a Generalized Vidale-Wolfe Response Model with Flexible Ad Elasticity and Word-of-Mouth. (arXiv:2202.13566v1 [cs.AI] CROSS LISTED)
## cs.AI
---
**75** new papers in cs.AI:-) 
1. Responsible AI in Healthcare. (arXiv:2203.03616v1 [cs.CY])
2. Triple Motion Estimation and Frame Interpolation based on Adaptive Threshold for Frame Rate Up-Conversion. (arXiv:2203.03621v1 [eess.IV])
3. Unsupervised Image Registration Towards Enhancing Performance and Explainability in Cardiac And Brain Image Analysis. (arXiv:2203.03638v1 [eess.IV])
4. A Typology to Explore and Guide Explanatory Interactive Machine Learning. (arXiv:2203.03668v1 [cs.LG])
5. Monocular Robot Navigation with Self-Supervised Pretrained Vision Transformers. (arXiv:2203.03682v1 [cs.RO])
6. Learn to Match with No Regret: Reinforcement Learning in Markov Matching Markets. (arXiv:2203.03684v1 [cs.LG])
7. WaveMix: Resource-efficient Token Mixing for Images. (arXiv:2203.03689v1 [cs.CV])
8. HyperMixer: An MLP-based Green AI Alternative to Transformers. (arXiv:2203.03691v1 [cs.CL])
9. Algorithmic audits of algorithms, and the law. (arXiv:2203.03711v1 [cs.CY])
10. Trusted Data Forever: Is AI the Answer?. (arXiv:2203.03712v1 [cs.CY])
11. Needs and Artificial Intelligence. (arXiv:2203.03715v1 [cs.CY])
12. Towards User-Centered Metrics for Trustworthy AI in Immersive Cyberspace. (arXiv:2203.03718v1 [cs.CY])
13. A New Era: Intelligent Tutoring Systems Will Transform Online Learning for Millions. (arXiv:2203.03724v1 [cs.CY])
14. Battery Cloud with Advanced Algorithms. (arXiv:2203.03737v1 [eess.SY])
15. New Insights on Reducing Abrupt Representation Change in Online Continual Learning. (arXiv:2203.03798v1 [cs.LG])
16. Panoramic Human Activity Recognition. (arXiv:2203.03806v1 [cs.CV])
17. Towards Efficient Data-Centric Robust Machine Learning with Noise-based Augmentation. (arXiv:2203.03810v1 [cs.LG])
18. Quasi-Balanced Self-Training on Noise-Aware Synthesis of Object Point Clouds for Closing Domain Gap. (arXiv:2203.03833v1 [cs.CV])
19. Multi-Scale Self-Contrastive Learning with Hard Negative Mining for Weakly-Supervised Query-based Video Grounding. (arXiv:2203.03838v1 [cs.CV])
20. Trust in AI and Implications for the AEC Research: A Literature Analysis. (arXiv:2203.03847v1 [cs.HC])
21. Discriminability-Transferability Trade-Off: An Information-Theoretic Perspective. (arXiv:2203.03871v1 [cs.CV])
22. Visual anomaly detection in video by variational autoencoder. (arXiv:2203.03872v1 [cs.CV])
23. High-order Order Proximity-Incorporated, Symmetry and Graph-Regularized Nonnegative Matrix Factorization for Community Detection. (arXiv:2203.03876v1 [cs.SI])
24. Boosting Mask R-CNN Performance for Long, Thin Forensic Traces with Pre-Segmentation and IoU Region Merging. (arXiv:2203.03886v1 [cs.CV])
25. Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation. (arXiv:2203.03910v1 [cs.CL])
26. Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks. (arXiv:2203.03929v1 [cs.LG])
27. An Online Semantic Mapping System for Extending and Enhancing Visual SLAM. (arXiv:2203.03944v1 [cs.RO])
28. Adapt$\mathcal{O}$r: Objective-Centric Adaptation Framework for Language Models. (arXiv:2203.03989v1 [cs.CL])
29. DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set Feature Extraction. (arXiv:2203.04007v1 [cs.CV])
30. Robot Learning of Mobile Manipulation with Reachability Behavior Priors. (arXiv:2203.04051v1 [cs.RO])
31. Lane Detection with Versatile AtrousFormer and Local Semantic Guidance. (arXiv:2203.04067v1 [cs.CV])
32. E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation. (arXiv:2203.04074v1 [cs.CV])
33. Foundations for Grassroots Democratic Metaverse. (arXiv:2203.04090v1 [cs.CY])
34. Contrastive **Enhancement** Using Latent Prototype for Few-Shot Segmentation. (arXiv:2203.04095v1 [cs.CV])
35. COLA: Consistent Learning with Opponent-Learning Awareness. (arXiv:2203.04098v1 [cs.LG])
36. Comparing representations of biological data learned with different AI paradigms, augmenting and cropping strategies. (arXiv:2203.04107v1 [eess.IV])
37. Plumeria at SemEval-2022 Task 6: Robust Approaches for Sarcasm Detection for English and Arabic Using Transformers and Data Augmentation. (arXiv:2203.04111v1 [cs.CL])
38. Graph-based Reinforcement Learning meets Mixed Integer Programs: An application to 3D robot assembly discovery. (arXiv:2203.04120v1 [cs.RO])
39. YouTube-GDD: A challenging gun detection dataset with rich contextual information. (arXiv:2203.04129v1 [cs.CV])
40. Robustly-reliable learners under poisoning attacks. (arXiv:2203.04160v1 [cs.LG])
41. Distributed Control using Reinforcement Learning with Temporal-Logic-Based Reward Shaping. (arXiv:2203.04172v1 [cs.AI])
42. Selective-Supervised Contrastive Learning with Noisy Labels. (arXiv:2203.04181v1 [cs.CV])
43. Locate This, Not That: Class-Conditioned Sound Event DOA Estimation. (arXiv:2203.04197v1 [eess.AS])
44. Trustable Co-label Learning from Multiple Noisy Annotators. (arXiv:2203.04199v1 [cs.LG])
45. Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data. (arXiv:2203.04218v1 [cs.RO])
46. Adaptative Perturbation Patterns: Realistic Adversarial Learning for Robust NIDS. (arXiv:2203.04234v1 [cs.CR])
47. Policy-Based Bayesian Experimental Design for Non-Differentiable Implicit Models. (arXiv:2203.04272v1 [cs.LG])
48. QuatRE: Relation-Aware Quaternions for Knowledge Graph Embeddings. (arXiv:2009.12517v2 [cs.CL] UPDATED)
49. Multi-Label Annotation of Chest Abdomen Pelvis Computed Tomography Text Reports Using Deep Learning. (arXiv:2102.02959v5 [cs.AI] UPDATED)
50. Ensemble deep learning: A review. (arXiv:2104.02395v2 [cs.LG] UPDATED)
51. Taxonomy of Machine Learning Safety: A Survey and Primer. (arXiv:2106.04823v2 [cs.LG] UPDATED)
52. ADAVI: Automatic Dual Amortized Variational Inference Applied To Pyramidal Bayesian Models. (arXiv:2106.12248v3 [cs.LG] UPDATED)
53. Unsupervised Speech **Enhancement** using Dynamical Variational Auto-Encoders. (arXiv:2106.12271v2 [cs.SD] UPDATED)
54. You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks. (arXiv:2106.13264v3 [cs.LG] UPDATED)
55. DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection. (arXiv:2107.10648v2 [cs.CL] UPDATED)
56. A general class of surrogate functions for stable and efficient reinforcement learning. (arXiv:2108.05828v4 [cs.LG] UPDATED)
57. Contrastive Quantization with Code Memory for Unsupervised Image Retrieval. (arXiv:2109.05205v2 [cs.CV] UPDATED)
58. SphereFace Revived: Unifying Hyperspherical Face Recognition. (arXiv:2109.05565v2 [cs.CV] UPDATED)
59. Hierarchical Potential-based Reward Shaping from Task Specifications. (arXiv:2110.02792v2 [cs.LG] UPDATED)
60. When Combating Hype, Proceed with Caution. (arXiv:2110.08300v2 [cs.CL] UPDATED)
61. Estimation & Recognition under Perspective of Random-Fuzzy Dual Interpretation of Unknown Quantity: with Demonstration of IMM Filter. (arXiv:2110.10572v3 [eess.SY] UPDATED)
62. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v4 [cs.CV] UPDATED)
63. Adversarial Attacks in Cooperative AI. (arXiv:2111.14833v3 [cs.LG] UPDATED)
64. Seeing BDD100K in **dark**: Single-Stage **Night**-time Object Detection via Continual Fourier Contrastive Learning. (arXiv:2112.02891v2 [cs.CV] UPDATED)
65. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. (arXiv:2112.04906v3 [math.OC] UPDATED)
66. Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents. (arXiv:2201.07207v2 [cs.LG] UPDATED)
67. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v2 [cs.LG] UPDATED)
68. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v2 [cs.CV] UPDATED)
69. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v3 [cs.CR] UPDATED)
70. CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion. (arXiv:2202.13785v2 [cs.AI] UPDATED)
71. EPPAC: Entity Pre-typing Relation Classification with Prompt AnswerCentralizing. (arXiv:2203.00193v2 [cs.CL] UPDATED)
72. Efficient Dynamic Clustering: Capturing Patterns from Historical Cluster Evolution. (arXiv:2203.00812v2 [cs.DB] UPDATED)
73. SPICEprop: Backpropagating Errors Through Memristive Spiking Neural Networks. (arXiv:2203.01426v2 [cs.NE] UPDATED)
74. TIGGER: Scalable Generative Modelling for Temporal Interaction Graphs. (arXiv:2203.03564v2 [cs.LG] UPDATED)
75. Learning Parameters for a Generalized Vidale-Wolfe Response Model with Flexible Ad Elasticity and Word-of-Mouth. (arXiv:2202.13566v1 [cs.AI] CROSS LISTED)

