# Your interest papers
---
## cs.CV
---
### **Swin**-transformer-yolov5 For **Real-time** Wine Grape Bunch Detection. (arXiv:2208.14508v1 [cs.CV])
- Authors : Shenglian Lu, Xiaoyu Liu, Zixaun He, Manoj Karkee, Xin Zhang, Guangxi normal, Washington State, Mississippi State
- Link : [http://arxiv.org/abs/2208.14508](http://arxiv.org/abs/2208.14508)
> ABSTRACT  :  In this research, an integrated detection model, **Swin**-transformer-YOLOv5 or **Swin**-T-YOLOv5, was proposed for real-time wine grape bunch detection to inherit the advantages from both YOLOv5 and **Swin**-transformer. The research was conducted on two different grape varieties of Chardonnay (always white berry skin) and Merlot (white or white-red mix berry skin when immature; red when matured) from July to September in 2019. To verify the superiority of **Swin**-T-YOLOv5, its performance was compared against several commonly used/competitive object detectors, including Faster R-CNN, YOLOv3, YOLOv4, and YOLOv5. All models were assessed under different test conditions, including two different weather conditions (sunny and cloudy), two different berry maturity stages (immature and mature), and three different sunlight directions/intensities (morning, noon, and afternoon) for a comprehensive comparison. Additionally, the predicted number of grape bunches by **Swin**-T-YOLOv5 was further compared with ground truth values, including both in-field manual counting and manual labeling during the annotation process. Results showed that the proposed **Swin**-T-YOLOv5 outperformed all other studied models for grape bunch detection, with up to 97% of mean Average Precision (mAP) and 0.89 of F1-score when the weather was cloudy. This mAP was approximately 44%, 18%, 14%, and 4% greater than Faster R-CNN, YOLOv3, YOLOv4, and YOLOv5, respectively. **Swin**-T-YOLOv5 achieved its lowest mAP (90%) and F1-score (0.82) when detecting immature berries, where the mAP was approximately 40%, 5%, 3%, and 1% greater than the same. Furthermore, **Swin**-T-YOLOv5 performed better on Chardonnay variety with achieved up to 0.91 of R2 and 2.36 root mean square error (RMSE) when comparing the predictions with ground truth. However, it underperformed on Merlot variety with achieved only up to 0.70 of R2 and 3.30 of RMSE.  
### ELSR: Extreme Low-Power Super Resolution Network For Mobile Devices. (arXiv:2208.14600v1 [cs.CV])
- Authors : Tianyu Xu, Zhuang Jia, Yijian Zhang, Long Bao, Heng Sun
- Link : [http://arxiv.org/abs/2208.14600](http://arxiv.org/abs/2208.14600)
> ABSTRACT  :  With the popularity of mobile devices, e.g., smartphone and wearable devices, lighter and faster model is crucial for the application of video super resolution. However, most previous lightweight models tend to concentrate on reducing lantency of model inference on desktop GPU, which may be not energy efficient in current mobile devices. In this paper, we proposed Extreme Low-Power Super Resolution (ELSR) network which only consumes a small amount of energy in mobile devices. Pretraining and finetuning methods are applied to boost the performance of the extremely tiny model. Extensive experiments show that our method achieves a excellent balance between **restoration** quality and power consumption. Finally, we achieve a competitive score of 90.9 with PSNR 27.34 dB and power 0.09 W/30FPS on the target MediaTek Dimensity 9000 plantform, ranking 1st place in the Mobile AI &amp; AIM 2022 Real-Time Video Super-Resolution Challenge.  
### Audiogram Digitization Tool for Audiological Reports. (arXiv:2208.14621v1 [cs.CV])
- Authors : ois Charih
- Link : [http://arxiv.org/abs/2208.14621](http://arxiv.org/abs/2208.14621)
> ABSTRACT  :  A number of private and public insurers compensate workers whose hearing loss can be directly attributed to excessive **exposure** to noise in the workplace. The claim assessment process is typically lengthy and requires significant effort from human adjudicators who must interpret hand-recorded audiograms, often sent via fax or equivalent. In this work, we present a solution developed in partnership with the Workplace Safety Insurance Board of Ontario to streamline the adjudication process. In particular, we present the first audiogram digitization algorithm capable of automatically extracting the hearing thresholds from a scanned or faxed audiology report as a proof-of-concept. The algorithm extracts most thresholds within 5 dB accuracy, allowing to substantially lessen the time required to convert an audiogram into digital format in a semi-supervised fashion, and is a first step towards the automation of the adjudication process. The source code for the digitization algorithm and a desktop-based implementation of our NIHL annotation portal is publicly available on GitHub (https://github.com/GreenCUBIC/AudiogramDigitization).  
### XCAT -- Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation. (arXiv:2208.14655v1 [eess.IV])
- Authors : Mustafa Ayazoglu, Bahri Batuhan
- Link : [http://arxiv.org/abs/2208.14655](http://arxiv.org/abs/2208.14655)
> ABSTRACT  :  We propose a lightweight, single image super-resolution network for mobile devices, named XCAT. XCAT introduces Heterogeneous Group Convolution Blocks with Cross Concatenations (HXBlock). The heterogeneous split of the input channels to the group convolution blocks reduces the number of operations, and cross concatenation allows for information flow between the intermediate input tensors of cascaded HXBlocks. Cross concatenations inside HXBlocks can also avoid using more expensive operations like 1x1 convolutions. To further prev ent expensive tensor copy operations, XCAT utilizes non-trainable convolution kernels to apply up sampling operations. Designed with integer quantization in mind, XCAT also utilizes several techniques on training, like intensity-based data augmentation. Integer quantized XCAT operates in **real time** on Mali-G71 MP2 GPU with 320ms, and on Synaptics Dolphin NPU with 30ms (NCHW) and 8.8ms (NHWC), suitable for real-time applications.  
### ELMformer: Efficient Raw Image **Restoration** with a Locally Multiplicative Transformer. (arXiv:2208.14704v1 [cs.CV])
- Authors : Jiaqi Ma, Shengyuan Yan, Lefei Zhang, Guoli Wang, Qian Zhang
- Link : [http://arxiv.org/abs/2208.14704](http://arxiv.org/abs/2208.14704)
> ABSTRACT  :  In order to get raw images of high quality for downstream Image Signal Process (ISP), in this paper we present an Efficient Locally Multiplicative Transformer called ELMformer for raw image **restoration**. ELMformer contains two core designs especially for raw images whose primitive attribute is single-channel. The first design is a Bi-directional Fusion Projection (BFP) module, where we consider both the color characteristics of raw images and spatial structure of single-channel. The second one is that we propose a Locally Multiplicative Self-Attention (L-MSA) scheme to effectively deliver information from the local space to relevant parts. ELMformer can efficiently reduce the computational consumption and perform well on raw image **restoration** tasks. Enhanced by these two core designs, ELMformer achieves the highest performance and keeps the lowest FLOPs on raw denoising and raw deblurring benchmarks compared with state-of-the-arts. Extensive experiments demonstrate the superiority and generalization ability of ELMformer. On SIDD benchmark, our method has even better denoising performance than ISP-based methods which need huge amount of additional sRGB training images. The codes are release at https://github.com/leonmakise/ELMformer.  
### Dual-Space **NeRF**: Learning Animatable Avatars and Scene Lighting in Separate Spaces. (arXiv:2208.14851v1 [cs.CV])
- Authors : Yihao Zhi, Shenhan Qian, Xinhao Yan, Shenghua Gao
- Link : [http://arxiv.org/abs/2208.14851](http://arxiv.org/abs/2208.14851)
> ABSTRACT  :  Modeling the human body in a canonical space is a common practice for capturing and animation. But when involving the neural radiance field (**NeRF**), learning a static **NeRF** in the canonical space is not enough because the lighting of the body changes when the person moves even though the scene lighting is constant. Previous methods alleviate the inconsistency of lighting by learning a per-frame embedding, but this operation does not generalize to unseen poses. Given that the lighting condition is static in the world space while the human body is consistent in the canonical space, we propose a dual-space **NeRF** that models the scene lighting and the human body with two MLPs in two separate spaces. To bridge these two spaces, previous methods mostly rely on the linear blend skinning (LBS) algorithm. However, the blending weights for LBS of a dynamic neural field are intractable and thus are usually memorized with another MLP, which does not generalize to novel poses. Although it is possible to borrow the blending weights of a parametric mesh such as SMPL, the interpolation operation introduces more artifacts. In this paper, we propose to use the barycentric mapping, which can directly generalize to unseen poses and surprisingly achieves superior results than LBS with neural blending weights. Quantitative and qualitative results on the Human3.6M and the ZJU-MoCap datasets show the effectiveness of our method.  
### NTIRE 2021 Challenge on Quality **Enhancement** of Compressed Video: Methods and Results. (arXiv:2104.10781v6 [eess.IV] UPDATED)
- Authors : Ren Yang, Radu Timofte, Jing Liu, Yi Xu, Xinjian Zhang, Minyi Zhao, Shuigeng Zhou, Shangchen Zhou, Xiangyu Xu, Chen Change, Xin Li, Fanglong Liu, He Zheng, Lielin Jiang, Qi Zhang, Dongliang He, Fu Li, Qingqing Dang, Yibin Huang, Matteo Maggioni, Zhongqian Fu, Shuai Xiao, Cheng li, Thomas Tanay, Fenglong Song, Wentao Chao, Qiang Guo, Yan Liu, Jiang Li, Xiaochao Qu, Dewang Hou, Jiayu Yang, Lyn Jiang, Di You, Zhenyu Zhang, Chong Mou, Iaroslav Koshelev, Pavel Ostyakov, Andrey Somov, Jia Hao, Xueyi Zou, Shijie Zhao, Xiaopeng Sun, Yiting Liao, Yuanzhi Zhang, Qing Wang, Gen Zhan, Mengxi Guo, Junlin Li, Ming Lu, Zhan Ma, Pablo Navarrete, Hai Wang, Yiyun Chen, Jingyu Guo, Liliang Zhang, Wenming Yang, Sijung Kim, Syehoon Oh, Yucong Wang, Minjie Cai, Wei Hao, Kangdi Shi, et al, additional authors, not shown
- Link : [http://arxiv.org/abs/2104.10781](http://arxiv.org/abs/2104.10781)
> ABSTRACT  :  This paper reviews the first NTIRE challenge on quality **enhancement** of compressed video, with a focus on the proposed methods and results. In this challenge, the new Large-scale Diverse Video (LDV) dataset is employed. The challenge has three tracks. Tracks 1 and 2 aim at enhancing the videos compressed by HEVC at a fixed QP, while Track 3 is designed for enhancing the videos compressed by x265 at a fixed bit-rate. Besides, the quality **enhancement** of Tracks 1 and 3 targets at improving the fidelity (PSNR), and Track 2 targets at enhancing the perceptual quality. The three tracks totally attract 482 registrations. In the test phase, 12 teams, 8 teams and 11 teams submitted the final results of Tracks 1, 2 and 3, respectively. The proposed methods and solutions gauge the state-of-the-art of video quality **enhancement**. The homepage of the challenge: https://github.com/RenYang-home/NTIRE21_VEnh  
## eess.IV
---
### ELSR: Extreme Low-Power Super Resolution Network For Mobile Devices. (arXiv:2208.14600v1 [cs.CV])
- Authors : Tianyu Xu, Zhuang Jia, Yijian Zhang, Long Bao, Heng Sun
- Link : [http://arxiv.org/abs/2208.14600](http://arxiv.org/abs/2208.14600)
> ABSTRACT  :  With the popularity of mobile devices, e.g., smartphone and wearable devices, lighter and faster model is crucial for the application of video super resolution. However, most previous lightweight models tend to concentrate on reducing lantency of model inference on desktop GPU, which may be not energy efficient in current mobile devices. In this paper, we proposed Extreme Low-Power Super Resolution (ELSR) network which only consumes a small amount of energy in mobile devices. Pretraining and finetuning methods are applied to boost the performance of the extremely tiny model. Extensive experiments show that our method achieves a excellent balance between **restoration** quality and power consumption. Finally, we achieve a competitive score of 90.9 with PSNR 27.34 dB and power 0.09 W/30FPS on the target MediaTek Dimensity 9000 plantform, ranking 1st place in the Mobile AI &amp; AIM 2022 Real-Time Video Super-Resolution Challenge.  
### XCAT -- Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation. (arXiv:2208.14655v1 [eess.IV])
- Authors : Mustafa Ayazoglu, Bahri Batuhan
- Link : [http://arxiv.org/abs/2208.14655](http://arxiv.org/abs/2208.14655)
> ABSTRACT  :  We propose a lightweight, single image super-resolution network for mobile devices, named XCAT. XCAT introduces Heterogeneous Group Convolution Blocks with Cross Concatenations (HXBlock). The heterogeneous split of the input channels to the group convolution blocks reduces the number of operations, and cross concatenation allows for information flow between the intermediate input tensors of cascaded HXBlocks. Cross concatenations inside HXBlocks can also avoid using more expensive operations like 1x1 convolutions. To further prev ent expensive tensor copy operations, XCAT utilizes non-trainable convolution kernels to apply up sampling operations. Designed with integer quantization in mind, XCAT also utilizes several techniques on training, like intensity-based data augmentation. Integer quantized XCAT operates in **real time** on Mali-G71 MP2 GPU with 320ms, and on Synaptics Dolphin NPU with 30ms (NCHW) and 8.8ms (NHWC), suitable for real-time applications.  
### Denoising method for dynamic contrast-enhanced CT perfusion studies using three-dimensional deep image prior as a simultaneous spatial and temporal regularizer. (arXiv:2208.14897v1 [physics.med-ph])
- Authors : Kenya Murase
- Link : [http://arxiv.org/abs/2208.14897](http://arxiv.org/abs/2208.14897)
> ABSTRACT  :  This study aimed to propose a denoising method for dynamic contrast-enhanced computed tomography (DCE-CT) perfusion studies using a three-dimensional deep image prior (DIP), and to investigate its usefulness in comparison with total variation (TV)-based methods with different regularization parameter (alpha) values through simulation studies. In the proposed DIP method, the DIP was incorporated into the constrained optimization problem for image denoising as a simultaneous spatial and temporal regularizer, which was solved using the alternating direction method of multipliers. In the simulation studies, DCE-CT images were generated using a digital brain phantom and their noise level was varied using the X-ray **exposure** noise model with different **exposure**s (15, 30, 50, 75, and 100 mAs). Cerebral blood flow (CBF) images were generated from the original contrast **enhancement** (CE) images and those obtained by the DIP and TV methods using block-circulant singular value decomposition. The quality of the CE images was evaluated using the peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM). To compare the CBF images obtained by the different methods and those generated from the ground truth images, linear regression analysis was performed. When using the DIP method, the PSNR and SSIM were not significantly dependent on the **exposure**, and the SSIM was the highest for all **exposure**s. When using the TV methods, they were significantly dependent on the **exposure** and alpha values. The results of the linear regression analysis suggested that the linearity of the CBF images obtained by the DIP method was superior to those obtained from the original CE images and by the TV methods. Our preliminary results suggest that the DIP method is useful for denoising DCE-CT images at ultra-low to low **exposure**s and for improving the accuracy of the CBF images generated from them.  
### NTIRE 2021 Challenge on Quality **Enhancement** of Compressed Video: Methods and Results. (arXiv:2104.10781v6 [eess.IV] UPDATED)
- Authors : Ren Yang, Radu Timofte, Jing Liu, Yi Xu, Xinjian Zhang, Minyi Zhao, Shuigeng Zhou, Shangchen Zhou, Xiangyu Xu, Chen Change, Xin Li, Fanglong Liu, He Zheng, Lielin Jiang, Qi Zhang, Dongliang He, Fu Li, Qingqing Dang, Yibin Huang, Matteo Maggioni, Zhongqian Fu, Shuai Xiao, Cheng li, Thomas Tanay, Fenglong Song, Wentao Chao, Qiang Guo, Yan Liu, Jiang Li, Xiaochao Qu, Dewang Hou, Jiayu Yang, Lyn Jiang, Di You, Zhenyu Zhang, Chong Mou, Iaroslav Koshelev, Pavel Ostyakov, Andrey Somov, Jia Hao, Xueyi Zou, Shijie Zhao, Xiaopeng Sun, Yiting Liao, Yuanzhi Zhang, Qing Wang, Gen Zhan, Mengxi Guo, Junlin Li, Ming Lu, Zhan Ma, Pablo Navarrete, Hai Wang, Yiyun Chen, Jingyu Guo, Liliang Zhang, Wenming Yang, Sijung Kim, Syehoon Oh, Yucong Wang, Minjie Cai, Wei Hao, Kangdi Shi, et al, additional authors, not shown
- Link : [http://arxiv.org/abs/2104.10781](http://arxiv.org/abs/2104.10781)
> ABSTRACT  :  This paper reviews the first NTIRE challenge on quality **enhancement** of compressed video, with a focus on the proposed methods and results. In this challenge, the new Large-scale Diverse Video (LDV) dataset is employed. The challenge has three tracks. Tracks 1 and 2 aim at enhancing the videos compressed by HEVC at a fixed QP, while Track 3 is designed for enhancing the videos compressed by x265 at a fixed bit-rate. Besides, the quality **enhancement** of Tracks 1 and 3 targets at improving the fidelity (PSNR), and Track 2 targets at enhancing the perceptual quality. The three tracks totally attract 482 registrations. In the test phase, 12 teams, 8 teams and 11 teams submitted the final results of Tracks 1, 2 and 3, respectively. The proposed methods and solutions gauge the state-of-the-art of video quality **enhancement**. The homepage of the challenge: https://github.com/RenYang-home/NTIRE21_VEnh  
## cs.LG
---
### Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?. (arXiv:2208.14554v1 [cs.CL])
- Authors : 
- Link : [http://arxiv.org/abs/2208.14554](http://arxiv.org/abs/2208.14554)
> ABSTRACT  :  Some languages allow arguments to be omitted in certain contexts. Yet human language comprehenders reliably infer the intended referents of these zero pronouns, in part because they construct expectations about which referents are more likely. We ask whether Neural Language Models also extract the same expectations. We test whether 12 contemporary language models display expectations that reflect human behavior when exposed to sentences with zero pronouns from five behavioral experiments conducted in Italian by Carminati (2005). We find that three models - XGLM 2.9B, 4.5B, and 7.5B - capture the human behavior from all the experiments, with others successfully modeling some of the results. This result suggests that human expectations about coreference can be derived from **exposure** to language, and also indicates features of language models that allow them to better reflect human behavior.  
## cs.AI
---
### Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?. (arXiv:2208.14554v1 [cs.CL])
- Authors : 
- Link : [http://arxiv.org/abs/2208.14554](http://arxiv.org/abs/2208.14554)
> ABSTRACT  :  Some languages allow arguments to be omitted in certain contexts. Yet human language comprehenders reliably infer the intended referents of these zero pronouns, in part because they construct expectations about which referents are more likely. We ask whether Neural Language Models also extract the same expectations. We test whether 12 contemporary language models display expectations that reflect human behavior when exposed to sentences with zero pronouns from five behavioral experiments conducted in Italian by Carminati (2005). We find that three models - XGLM 2.9B, 4.5B, and 7.5B - capture the human behavior from all the experiments, with others successfully modeling some of the results. This result suggests that human expectations about coreference can be derived from **exposure** to language, and also indicates features of language models that allow them to better reflect human behavior.  
# Paper List
---
## cs.CV
---
**78** new papers in cs.CV:-) 
1. Artificial intelligence-based locoregional markers of brain peritumoral microenvironment. (arXiv:2208.14445v1 [q-bio.QM])
2. A Learning-Based 3D EIT Image Reconstruction Method. (arXiv:2208.14449v1 [eess.IV])
3. Constraining Representations Yields Models That Know What They Don't Know. (arXiv:2208.14488v1 [cs.LG])
4. **Swin**-transformer-yolov5 For **Real-time** Wine Grape Bunch Detection. (arXiv:2208.14508v1 [cs.CV])
5. Lesion-Specific Prediction with Discriminator-Based Supervised Guided Attention Module Enabled GANs in Multiple Sclerosis. (arXiv:2208.14533v1 [eess.IV])
6. TCAM: Temporal Class Activation Maps for Object Localization in Weakly-Labeled Unconstrained Videos. (arXiv:2208.14542v1 [cs.CV])
7. BioSLAM: A Bio-inspired Lifelong Memory System for General Place Recognition. (arXiv:2208.14543v1 [cs.RO])
8. Augraphy: A Data Augmentation Library for Document Images. (arXiv:2208.14558v1 [cs.CV])
9. Few-shot Adaptive Object Detection with Cross-Domain CutMix. (arXiv:2208.14586v1 [cs.CV])
10. ELSR: Extreme Low-Power Super Resolution Network For Mobile Devices. (arXiv:2208.14600v1 [cs.CV])
11. Blind Quality Assessment of 3D Dense Point Clouds with Structure Guided Resampling. (arXiv:2208.14603v1 [cs.MM])
12. SIM-Trans: Structure Information Modeling Transformer for Fine-grained Visual Categorization. (arXiv:2208.14607v1 [cs.CV])
13. Audiogram Digitization Tool for Audiological Reports. (arXiv:2208.14621v1 [cs.CV])
14. Temporal Flow Mask Attention for Open-Set Long-Tailed Recognition of Wild Animals in Camera-Trap Images. (arXiv:2208.14625v1 [cs.CV])
15. Segmentation-guided Domain Adaptation and Data Harmonization of Multi-device Retinal Optical Coherence Tomography using Cycle-Consistent Generative Adversarial Networks. (arXiv:2208.14635v1 [eess.IV])
16. An Empirical Study and Analysis of Learning Generalizable Manipulation Skill in the SAPIEN Simulator. (arXiv:2208.14646v1 [cs.RO])
17. Injecting Image Details into CLIP's Feature Space. (arXiv:2208.14649v1 [cs.CV])
18. XCAT -- Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation. (arXiv:2208.14655v1 [eess.IV])
19. EViT: Privacy-Preserving Image Retrieval via Encrypted Vision Transformer in Cloud Computing. (arXiv:2208.14657v1 [cs.CV])
20. Unifying Evaluation of Machine Learning Safety Monitors. (arXiv:2208.14660v1 [cs.LG])
21. AWADA: Attention-Weighted Adversarial Domain Adaptation for Object Detection. (arXiv:2208.14662v1 [cs.CV])
22. Iterative Optimization of Pseudo Ground-Truth Face Image Quality Labels. (arXiv:2208.14683v1 [cs.CV])
23. NeurIPS'22 Cross-Domain MetaDL competition: Design and baseline results. (arXiv:2208.14686v1 [cs.LG])
24. TRUST: An Accurate and End-to-End Table structure Recognizer Using Splitting-based Transformers. (arXiv:2208.14687v1 [cs.CV])
25. Let us Build Bridges: Understanding and Extending Diffusion Generative Models. (arXiv:2208.14699v1 [cs.LG])
26. ELMformer: Efficient Raw Image **Restoration** with a Locally Multiplicative Transformer. (arXiv:2208.14704v1 [cs.CV])
27. Transfering Low-Frequency Features for Domain Adaptation. (arXiv:2208.14706v1 [cs.CV])
28. Scatter Points in Space: 3D Detection from Multi-view Monocular Images. (arXiv:2208.14738v1 [cs.CV])
29. SimpleRecon: 3D Reconstruction Without 3D Convolutions. (arXiv:2208.14743v1 [cs.CV])
30. Accelerating Deep Unrolling Networks via Dimensionality Reduction. (arXiv:2208.14784v1 [eess.IV])
31. 3DLG-Detector: 3D Object Detection via Simultaneous Local-Global Feature Learning. (arXiv:2208.14796v1 [cs.CV])
32. PyTorch Image Quality: Metrics for Image Quality Assessment. (arXiv:2208.14818v1 [eess.IV])
33. QuantNAS for super resolution: searching for efficient quantization-friendly architectures against quantization noise. (arXiv:2208.14839v1 [cs.CV])
34. Attentive pooling for Group Activity Recognition. (arXiv:2208.14847v1 [cs.CV])
35. Dual-Space **NeRF**: Learning Animatable Avatars and Scene Lighting in Separate Spaces. (arXiv:2208.14851v1 [cs.CV])
36. Active Learning with Effective Scoring Functions for Semi-Supervised Temporal Action Localization. (arXiv:2208.14856v1 [cs.CV])
37. Style-Agnostic Reinforcement Learning. (arXiv:2208.14863v1 [cs.CV])
38. Automatic Identification of Coal and Rock/Gangue Based on DenseNet and Gaussian Process. (arXiv:2208.14871v1 [cs.CV])
39. NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation. (arXiv:2208.14876v1 [eess.IV])
40. Hierarchical Local-Global Transformer for Temporal Sentence Grounding. (arXiv:2208.14882v1 [cs.MM])
41. Binary Representation via Jointly Personalized Sparse Hashing. (arXiv:2208.14883v1 [cs.CV])
42. Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation. (arXiv:2208.14888v1 [cs.CV])
43. LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data. (arXiv:2208.14889v1 [cs.CV])
44. Improving RGB-D Point Cloud Registration by Learning Multi-scale Local Linear Transformation. (arXiv:2208.14893v1 [cs.CV])
45. Segmentation of Weakly Visible Environmental Microorganism Images Using Pair-wise Deep Learning Features. (arXiv:2208.14957v1 [cs.CV])
46. A Realism Metric for Generated LiDAR Point Clouds. (arXiv:2208.14958v1 [cs.CV])
47. MotionDiffuse: Text-Driven Human Motion Generation with Diffusion Model. (arXiv:2208.15001v1 [cs.CV])
48. Modified Weibull distribution for Biomedical signals denoising. (arXiv:1605.03624v2 [cs.CV] UPDATED)
49. Robust Kernel-based Feature Representation for 3D Point Cloud Analysis via Circular Convolutional Network. (arXiv:2012.12215v5 [cs.CV] UPDATED)
50. NTIRE 2021 Challenge on Quality **Enhancement** of Compressed Video: Methods and Results. (arXiv:2104.10781v6 [eess.IV] UPDATED)
51. P2T: Pyramid Pooling Transformer for Scene Understanding. (arXiv:2106.12011v6 [cs.CV] UPDATED)
52. Magnification-independent Histopathological Image Classification with Similarity-based Multi-scale Embeddings. (arXiv:2107.01063v2 [cs.CV] UPDATED)
53. ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v4 [cs.LG] UPDATED)
54. Dense Gaussian Processes for Few-Shot Segmentation. (arXiv:2110.03674v2 [cs.CV] UPDATED)
55. Many Heads but One Brain: Fusion Brain -- a Competition and a Single Multimodal Multitask Architecture. (arXiv:2111.10974v2 [cs.CV] UPDATED)
56. Auto-Encoding Score Distribution Regression for Action Quality Assessment. (arXiv:2111.11029v2 [cs.CV] UPDATED)
57. Joint Learning of Localized Representations from Medical Images and Reports. (arXiv:2112.02889v2 [cs.CV] UPDATED)
58. Continuous Spectral Reconstruction from RGB Images via Implicit Neural Representation. (arXiv:2112.13003v2 [cs.CV] UPDATED)
59. Cyber Mobility Mirror for Enabling Cooperative Driving Automation in Mixed Traffic: A Co-Simulation Platform. (arXiv:2201.09463v2 [cs.SE] UPDATED)
60. RePaint: Inpainting using Denoising Diffusion Probabilistic Models. (arXiv:2201.09865v4 [cs.CV] UPDATED)
61. DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set Feature Extraction. (arXiv:2203.04007v2 [cs.CV] UPDATED)
62. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v4 [cs.CV] UPDATED)
63. Video Polyp Segmentation: A Deep Learning Perspective. (arXiv:2203.14291v3 [eess.IV] UPDATED)
64. Deep Quality Estimation: Creating Surrogate Models for Human Quality Ratings. (arXiv:2205.10355v2 [cs.CV] UPDATED)
65. Unsupervised Multi-object Segmentation Using Attention and Soft-argmax. (arXiv:2205.13271v2 [cs.CV] UPDATED)
66. U(1) Symmetry-breaking Observed in Generic CNN Bottleneck Layers. (arXiv:2206.02220v2 [cs.CV] UPDATED)
67. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v2 [eess.IV] UPDATED)
68. Dynamic boxes fusion strategy in object detection. (arXiv:2207.00997v2 [cs.CV] UPDATED)
69. $L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of Features. (arXiv:2207.02625v2 [cs.CV] UPDATED)
70. Towards Smart City Security: Violence and Weaponized Violence Detection using DCNN. (arXiv:2207.12850v2 [cs.CV] UPDATED)
71. Runner-Up Solution to ECCV 2022 Challenge on Out of Vocabulary Scene Text Understanding: Cropped Word Recognition. (arXiv:2208.02747v3 [cs.CV] UPDATED)
72. Multiplex-detection Based Multiple Instance Learning Network for Whole Slide Image Classification. (arXiv:2208.03526v2 [cs.CV] UPDATED)
73. Contrastive Domain Adaptation for Early Misinformation Detection: A Case Study on COVID-19. (arXiv:2208.09578v2 [cs.CV] UPDATED)
74. Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks. (arXiv:2208.10442v2 [cs.CV] UPDATED)
75. TMIC: App Inventor Extension for the Deployment of Image Classification Models Exported from Teachable Machine. (arXiv:2208.12637v2 [cs.CY] UPDATED)
76. Robust Sound-Guided Image Manipulation. (arXiv:2208.14114v2 [cs.CV] UPDATED)
77. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v2 [cs.CV] UPDATED)
78. PanorAMS: Automatic Annotation for Detecting Objects in Urban Context. (arXiv:2208.14295v2 [cs.CV] UPDATED)
## eess.IV
---
**20** new papers in eess.IV:-) 
1. Artificial intelligence-based locoregional markers of brain peritumoral microenvironment. (arXiv:2208.14445v1 [q-bio.QM])
2. A Learning-Based 3D EIT Image Reconstruction Method. (arXiv:2208.14449v1 [eess.IV])
3. Towards reliable head and neck cancers locoregional recurrence prediction using delta-radiomics and learning with rejection option. (arXiv:2208.14452v1 [physics.med-ph])
4. Lesion-Specific Prediction with Discriminator-Based Supervised Guided Attention Module Enabled GANs in Multiple Sclerosis. (arXiv:2208.14533v1 [eess.IV])
5. ELSR: Extreme Low-Power Super Resolution Network For Mobile Devices. (arXiv:2208.14600v1 [cs.CV])
6. Segmentation-guided Domain Adaptation and Data Harmonization of Multi-device Retinal Optical Coherence Tomography using Cycle-Consistent Generative Adversarial Networks. (arXiv:2208.14635v1 [eess.IV])
7. XCAT -- Lightweight Quantized Single Image Super-Resolution using Heterogeneous Group Convolutions and Cross Concatenation. (arXiv:2208.14655v1 [eess.IV])
8. Enhancing Early Lung Cancer Detection on Chest Radiographs with AI-assistance: A Multi-Reader Study. (arXiv:2208.14742v1 [eess.IV])
9. 2BiVQA: Double Bi-LSTM based Video Quality Assessment of UGC Videos. (arXiv:2208.14774v1 [eess.IV])
10. Accelerating Deep Unrolling Networks via Dimensionality Reduction. (arXiv:2208.14784v1 [eess.IV])
11. PyTorch Image Quality: Metrics for Image Quality Assessment. (arXiv:2208.14818v1 [eess.IV])
12. NestedFormer: Nested Modality-Aware Transformer for Brain Tumor Segmentation. (arXiv:2208.14876v1 [eess.IV])
13. Denoising method for dynamic contrast-enhanced CT perfusion studies using three-dimensional deep image prior as a simultaneous spatial and temporal regularizer. (arXiv:2208.14897v1 [physics.med-ph])
14. NTIRE 2021 Challenge on Quality **Enhancement** of Compressed Video: Methods and Results. (arXiv:2104.10781v6 [eess.IV] UPDATED)
15. Joint Learning of Localized Representations from Medical Images and Reports. (arXiv:2112.02889v2 [cs.CV] UPDATED)
16. A Unifying Approach to Inverse Problems of Ultrasound Beamforming and Deconvolution. (arXiv:2112.14294v2 [eess.IV] UPDATED)
17. Phase Object Reconstruction for 4D-STEM using Deep Learning. (arXiv:2202.12611v2 [cond-mat.mtrl-sci] UPDATED)
18. Video Polyp Segmentation: A Deep Learning Perspective. (arXiv:2203.14291v3 [eess.IV] UPDATED)
19. Deep Quality Estimation: Creating Surrogate Models for Human Quality Ratings. (arXiv:2205.10355v2 [cs.CV] UPDATED)
20. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v2 [eess.IV] UPDATED)
## cs.LG
---
**104** new papers in cs.LG:-) 
1. You Only Search Once: On Lightweight Differentiable Architecture Search for Resource-Constrained Embedded Platforms. (arXiv:2208.14446v1 [cs.LG])
2. A further exploration of deep Multi-Agent Reinforcement Learning with Hybrid Action Space. (arXiv:2208.14447v1 [cs.LG])
3. A Learning-Based 3D EIT Image Reconstruction Method. (arXiv:2208.14449v1 [eess.IV])
4. Dual Representation Learning for One-Step Clustering of Multi-View Data. (arXiv:2208.14450v1 [cs.LG])
5. Constraining Representations Yields Models That Know What They Don't Know. (arXiv:2208.14488v1 [cs.LG])
6. Annotated Dataset Creation through General Purpose Language Models for non-English Medical NLP. (arXiv:2208.14493v1 [cs.CL])
7. Model-Based Reinforcement Learning with SINDy. (arXiv:2208.14501v1 [cs.LG])
8. Modeling Soft-Failure Evolution for Triggering Timely Repair with Low QoT Margins. (arXiv:2208.14535v1 [cs.LG])
9. Embedding Functional Data: Multidimensional Scaling and Manifold Learning. (arXiv:2208.14540v1 [math.ST])
10. BioSLAM: A Bio-inspired Lifelong Memory System for General Place Recognition. (arXiv:2208.14543v1 [cs.RO])
11. Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?. (arXiv:2208.14554v1 [cs.CL])
12. Dynamic Global Sensitivity for Differentially Private Contextual Bandits. (arXiv:2208.14555v1 [cs.LG])
13. LINKS: A dataset of a hundred million planar linkage mechanisms for data-driven kinematic design. (arXiv:2208.14567v1 [cs.LG])
14. Truncated Matrix Power Iteration for Differentiable DAG Learning. (arXiv:2208.14571v1 [cs.LG])
15. Efficient Sparsely Activated Transformers. (arXiv:2208.14580v1 [cs.LG])
16. A Prescriptive Learning Analytics Framework: Beyond Predictive Modelling and onto Explainable AI with Prescriptive Analytics. (arXiv:2208.14582v1 [cs.LG])
17. Lifelong Learning for Question Answering with Hierarchical Prompts. (arXiv:2208.14602v1 [cs.CL])
18. Non-readily identifiable data collaboration analysis for multiple datasets including personal information. (arXiv:2208.14611v1 [cs.LG])
19. Fine-Grained Distribution-Dependent Learning Curves. (arXiv:2208.14615v1 [cs.LG])
20. Segmentation-guided Domain Adaptation and Data Harmonization of Multi-device Retinal Optical Coherence Tomography using Cycle-Consistent Generative Adversarial Networks. (arXiv:2208.14635v1 [eess.IV])
21. Unifying Evaluation of Machine Learning Safety Monitors. (arXiv:2208.14660v1 [cs.LG])
22. Incremental Learning in Diagonal Linear Networks. (arXiv:2208.14673v1 [cs.LG])
23. NeurIPS'22 Cross-Domain MetaDL competition: Design and baseline results. (arXiv:2208.14686v1 [cs.LG])
24. Deep Reinforcement Learning for Uplink Multi-Carrier Non-Orthogonal Multiple Access Resource Allocation Using Buffer State Information. (arXiv:2208.14689v1 [cs.NI])
25. Bayesian Optimization-based Combinatorial Assignment. (arXiv:2208.14698v1 [cs.LG])
26. Let us Build Bridges: Understanding and Extending Diffusion Generative Models. (arXiv:2208.14699v1 [cs.LG])
27. Classical-to-quantum convolutional neural network transfer learning. (arXiv:2208.14708v1 [quant-ph])
28. A stabilizing reinforcement learning approach for sampled systems with partially unknown models. (arXiv:2208.14714v1 [eess.SY])
29. Accelerating Deep Unrolling Networks via Dimensionality Reduction. (arXiv:2208.14784v1 [eess.IV])
30. Sparsification of the regularized magnetic Laplacian with multi-type spanning forests. (arXiv:2208.14797v1 [cs.SI])
31. Nonparametric and Online Change Detection in Multivariate Datastreams using QuantTree. (arXiv:2208.14801v1 [cs.LG])
32. Reducing Impacts of System Heterogeneity in Federated Learning using Weight Update Magnitudes. (arXiv:2208.14808v1 [cs.LG])
33. Graph Distance Neural Networks for Predicting Multiple Drug Interactions. (arXiv:2208.14810v1 [cs.LG])
34. Data-Driven Chance Constrained AC-OPF using Hybrid Sparse Gaussian Processes. (arXiv:2208.14814v1 [eess.SY])
35. Cadence Detection in Symbolic Classical Music using Graph Neural Networks. (arXiv:2208.14819v1 [cs.SD])
36. A Fair Experimental Comparison of Neural Network Architectures for Latent Representations of Multi-Omics for Drug Response Prediction. (arXiv:2208.14822v1 [cs.LG])
37. Predicting spatial distribution of Palmer Drought Severity Index. (arXiv:2208.14833v1 [cs.LG])
38. Deep Anomaly Detection and Search via Reinforcement Learning. (arXiv:2208.14834v1 [cs.LG])
39. Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms. (arXiv:2208.14837v1 [cs.LG])
40. Listen to your heart: A self-supervised approach for detecting murmur in heart-beat sounds for the Physionet 2022 challenge. (arXiv:2208.14845v1 [cs.LG])
41. Improving Operational Efficiency In EV Ridepooling Fleets By Predictive Exploitation of Idle Times. (arXiv:2208.14852v1 [cs.LG])
42. Style-Agnostic Reinforcement Learning. (arXiv:2208.14863v1 [cs.CV])
43. Federated Online Clustering of Bandits. (arXiv:2208.14865v1 [cs.LG])
44. Intelligent Closed-loop RAN Control with xApps in OpenRAN Gym. (arXiv:2208.14877v1 [cs.NI])
45. Formalising the Robustness of Counterfactual Explanations for Neural Networks. (arXiv:2208.14878v1 [cs.LG])
46. Feature Alignment by Uncertainty and Self-Training for Source-Free Unsupervised Domain Adaptation. (arXiv:2208.14888v1 [cs.CV])
47. ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling. (arXiv:2208.14919v1 [cs.LG])
48. Learning Tree Structures from Leaves For Particle Decay Reconstruction. (arXiv:2208.14924v1 [physics.comp-ph])
49. Cell-Free Latent Go-Explore. (arXiv:2208.14928v1 [cs.LG])
50. Membership Inference Attacks by Exploiting Loss Trajectory. (arXiv:2208.14933v1 [cs.CR])
51. A Realism Metric for Generated LiDAR Point Clouds. (arXiv:2208.14958v1 [cs.CV])
52. Stationary Kernels and Gaussian Processes on Lie Groups and their Homogeneous Spaces I: the Compact Case. (arXiv:2208.14960v1 [stat.ME])
53. Deep-Learning-Based Device Fingerprinting for Increased LoRa-IoT Security: Sensitivity to Network Deployment Changes. (arXiv:2208.14964v1 [cs.LG])
54. Concept Gradient: Concept-based Interpretation Without Linear Assumption. (arXiv:2208.14966v1 [cs.LG])
55. Zero-day DDoS Attack Detection. (arXiv:2208.14971v1 [cs.CR])
56. Inverse Propensity Score based offline estimator for deterministic ranking lists using position bias. (arXiv:2208.14980v1 [cs.IR])
57. Multiscale Non-stationary Causal Structure Learning from Time Series Data. (arXiv:2208.14989v1 [cs.LG])
58. Discovering Conservation Laws using Optimal Transport and Manifold Learning. (arXiv:2208.14995v1 [physics.comp-ph])
59. Projection Pursuit Gaussian Process Regression. (arXiv:2004.00667v2 [stat.ML] UPDATED)
60. Lazy Online Gradient Descent is Universal on Polytopes. (arXiv:2004.01739v2 [cs.LG] UPDATED)
61. Multidimensional Persistence Module Classification via Lattice-Theoretic Convolutions. (arXiv:2011.14057v2 [math.AT] UPDATED)
62. Statistical embedding: Beyond principal components. (arXiv:2106.01858v2 [stat.ML] UPDATED)
63. Input Invex Neural Network. (arXiv:2106.08748v2 [cs.LG] UPDATED)
64. ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v4 [cs.LG] UPDATED)
65. Uncertainty Quantification and Experimental Design for Large-Scale Linear Inverse Problems under Gaussian Process Priors. (arXiv:2109.03457v4 [stat.ML] UPDATED)
66. Robust Stability of Neural Network-controlled Nonlinear Systems with Parametric Variability. (arXiv:2109.05710v4 [cs.LG] UPDATED)
67. The Complexity of Learning Approval-Based Multiwinner Voting Rules. (arXiv:2110.00254v2 [cs.GT] UPDATED)
68. Joint Learning of Localized Representations from Medical Images and Reports. (arXiv:2112.02889v2 [cs.CV] UPDATED)
69. Online POI Recommendation: Learning Dynamic Geo-Human Interactions in Streams. (arXiv:2201.10983v2 [cs.IR] UPDATED)
70. Learning Stochastic Graph Neural Networks with Constrained Variance. (arXiv:2201.12611v2 [eess.SP] UPDATED)
71. Cooperative Online Learning in Stochastic and Adversarial MDPs. (arXiv:2201.13170v2 [cs.LG] UPDATED)
72. Positive-Unlabeled Learning with Uncertainty-aware Pseudo-label Selection. (arXiv:2201.13192v2 [stat.ML] UPDATED)
73. Automatic event detection in football using tracking data. (arXiv:2202.00804v3 [cs.LG] UPDATED)
74. Fast Convex Optimization for Two-Layer ReLU Networks: Equivalent Model Classes and Cone Decompositions. (arXiv:2202.01331v3 [cs.LG] UPDATED)
75. Multivariate Analysis for Multiple Network Data via Semi-Symmetric Tensor PCA. (arXiv:2202.04719v2 [stat.ML] UPDATED)
76. Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality. (arXiv:2202.06450v3 [cs.LG] UPDATED)
77. Minimax Optimal Quantization of Linear Models: Information-Theoretic Limits and Efficient Algorithms. (arXiv:2202.11277v2 [cs.IT] UPDATED)
78. Efficient CDF Approximations for Normalizing Flows. (arXiv:2202.11322v2 [cs.LG] UPDATED)
79. Hybrid Artifact Detection System for Minute Resolution Blood Pressure Signals from ICU. (arXiv:2203.05947v2 [eess.SP] UPDATED)
80. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v4 [cs.CV] UPDATED)
81. Multimodal Learning on Graphs for Disease Relation Extraction. (arXiv:2203.08893v2 [cs.LG] UPDATED)
82. GCNET: graph-based prediction of stock price movement using graph convolutional network. (arXiv:2203.11091v2 [q-fin.TR] UPDATED)
83. MBI-Net: A Non-Intrusive Multi-Branched Speech Intelligibility Prediction Model for Hearing Aids. (arXiv:2204.03305v2 [eess.AS] UPDATED)
84. MTI-Net: A Multi-Target Speech Intelligibility Prediction Model. (arXiv:2204.03310v2 [eess.AS] UPDATED)
85. Karaoker: Alignment-free singing voice synthesis with speech training data. (arXiv:2204.04127v2 [eess.AS] UPDATED)
86. Efficient Learning of Interpretable Classification Rules. (arXiv:2205.06936v2 [cs.LG] UPDATED)
87. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v4 [cs.LG] UPDATED)
88. Foundation Posteriors for Approximate Probabilistic Inference. (arXiv:2205.09735v2 [cs.LG] UPDATED)
89. Deep Quality Estimation: Creating Surrogate Models for Human Quality Ratings. (arXiv:2205.10355v2 [cs.CV] UPDATED)
90. Mathematical Models of Human Drivers Using Artificial Risk Fields. (arXiv:2205.12722v2 [cs.LG] UPDATED)
91. SFP: State-free Priors for Exploration in Off-Policy Reinforcement Learning. (arXiv:2205.13528v3 [cs.LG] UPDATED)
92. U(1) Symmetry-breaking Observed in Generic CNN Bottleneck Layers. (arXiv:2206.02220v2 [cs.CV] UPDATED)
93. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v2 [eess.IV] UPDATED)
94. Orthonormal Expansions for Translation-Invariant Kernels. (arXiv:2206.08648v2 [math.CA] UPDATED)
95. Model-Based Imitation Learning Using Entropy Regularization of Model and Policy. (arXiv:2206.10101v2 [cs.LG] UPDATED)
96. Protea: Client Profiling within Federated Systems using Flower. (arXiv:2207.01053v2 [cs.LG] UPDATED)
97. A coherence parameter characterizing generative compressed sensing with Fourier measurements. (arXiv:2207.09340v3 [cs.IT] UPDATED)
98. Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference. (arXiv:2207.11597v2 [cs.LG] UPDATED)
99. Bayesian Variable Selection in a Million Dimensions. (arXiv:2208.01180v2 [stat.ME] UPDATED)
100. Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments. (arXiv:2208.11311v2 [cs.LG] UPDATED)
101. TMIC: App Inventor Extension for the Deployment of Image Classification Models Exported from Teachable Machine. (arXiv:2208.12637v2 [cs.CY] UPDATED)
102. Prerequisite-driven Q-matrix Refinement for Learner Knowledge Assessment: A Case Study in Online Learning Context. (arXiv:2208.12642v2 [cs.CY] UPDATED)
103. Empirical Gateaux Derivatives for Causal Inference. (arXiv:2208.13701v2 [stat.ME] UPDATED)
104. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v2 [cs.CV] UPDATED)
## cs.AI
---
**60** new papers in cs.AI:-) 
1. A further exploration of deep Multi-Agent Reinforcement Learning with Hybrid Action Space. (arXiv:2208.14447v1 [cs.LG])
2. Constraining Representations Yields Models That Know What They Don't Know. (arXiv:2208.14488v1 [cs.LG])
3. Annotated Dataset Creation through General Purpose Language Models for non-English Medical NLP. (arXiv:2208.14493v1 [cs.CL])
4. Model-Based Reinforcement Learning with SINDy. (arXiv:2208.14501v1 [cs.LG])
5. System Resilience through Health Monitoring and Reconfiguration. (arXiv:2208.14525v1 [cs.AI])
6. Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?. (arXiv:2208.14554v1 [cs.CL])
7. Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning. (arXiv:2208.14565v1 [cs.CL])
8. Truncated Matrix Power Iteration for Differentiable DAG Learning. (arXiv:2208.14571v1 [cs.LG])
9. Efficient Sparsely Activated Transformers. (arXiv:2208.14580v1 [cs.LG])
10. A Prescriptive Learning Analytics Framework: Beyond Predictive Modelling and onto Explainable AI with Prescriptive Analytics. (arXiv:2208.14582v1 [cs.LG])
11. One-class Recommendation Systems with the Hinge Pairwise Distance Loss and Orthogonal Representations. (arXiv:2208.14594v1 [cs.IR])
12. A topic-aware graph neural network model for knowledge base updating. (arXiv:2208.14601v1 [cs.IR])
13. Lifelong Learning for Question Answering with Hierarchical Prompts. (arXiv:2208.14602v1 [cs.CL])
14. Temporal Flow Mask Attention for Open-Set Long-Tailed Recognition of Wild Animals in Camera-Trap Images. (arXiv:2208.14625v1 [cs.CV])
15. Generating Intermediate Steps for NLI with Next-Step Supervision. (arXiv:2208.14641v1 [cs.CL])
16. An Empirical Study and Analysis of Learning Generalizable Manipulation Skill in the SAPIEN Simulator. (arXiv:2208.14646v1 [cs.RO])
17. Unifying Evaluation of Machine Learning Safety Monitors. (arXiv:2208.14660v1 [cs.LG])
18. NeurIPS'22 Cross-Domain MetaDL competition: Design and baseline results. (arXiv:2208.14686v1 [cs.LG])
19. Modelling and Detection of Driver's Fatigue using Ontology. (arXiv:2208.14694v1 [cs.AI])
20. Open Challenges in Musical Metacreation. (arXiv:2208.14734v1 [cs.SD])
21. Cluster-based Sampling in Hindsight Experience Replay for Robot Control. (arXiv:2208.14741v1 [cs.RO])
22. Enhancing Early Lung Cancer Detection on Chest Radiographs with AI-assistance: A Multi-Reader Study. (arXiv:2208.14742v1 [eess.IV])
23. Negative Human Rights as a Basis for Long-term AI Safety and Regulation. (arXiv:2208.14788v1 [cs.CY])
24. Graph Distance Neural Networks for Predicting Multiple Drug Interactions. (arXiv:2208.14810v1 [cs.LG])
25. Learning Automata-Based Complex Event Patterns in Answer Set Programming. (arXiv:2208.14820v1 [cs.AI])
26. Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms. (arXiv:2208.14837v1 [cs.LG])
27. Improving Operational Efficiency In EV Ridepooling Fleets By Predictive Exploitation of Idle Times. (arXiv:2208.14852v1 [cs.LG])
28. Formalising the Robustness of Counterfactual Explanations for Neural Networks. (arXiv:2208.14878v1 [cs.LG])
29. GRILLBot: An Assistant for Real-World Tasks with Neural Semantic Parsing and Graph-Based Representations. (arXiv:2208.14884v1 [cs.CL])
30. LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data. (arXiv:2208.14889v1 [cs.CV])
31. Cell-Free Latent Go-Explore. (arXiv:2208.14928v1 [cs.LG])
32. A Realism Metric for Generated LiDAR Point Clouds. (arXiv:2208.14958v1 [cs.CV])
33. Foundations of Reasoning with Uncertainty via Real-valued Logics. (arXiv:2008.02429v3 [cs.LO] UPDATED)
34. Structure-Grounded Pretraining for Text-to-SQL. (arXiv:2010.12773v3 [cs.CL] UPDATED)
35. A logic for binary classifiers and their explanations. (arXiv:2105.14452v3 [cs.LO] UPDATED)
36. Time-Frequency Localization Using Deep Convolutional Maxout Neural Network in Persian Speech Recognition. (arXiv:2108.03818v4 [cs.SD] UPDATED)
37. An Objective Metric for Explainable AI: How and Why to Estimate the Degree of Explainability. (arXiv:2109.05327v3 [cs.AI] UPDATED)
38. Many Heads but One Brain: Fusion Brain -- a Competition and a Single Multimodal Multitask Architecture. (arXiv:2111.10974v2 [cs.CV] UPDATED)
39. Online POI Recommendation: Learning Dynamic Geo-Human Interactions in Streams. (arXiv:2201.10983v2 [cs.IR] UPDATED)
40. Towards Deployment-Efficient Reinforcement Learning: Lower Bound and Optimality. (arXiv:2202.06450v3 [cs.LG] UPDATED)
41. DuMLP-Pin: A Dual-MLP-dot-product Permutation-invariant Network for Set Feature Extraction. (arXiv:2203.04007v2 [cs.CV] UPDATED)
42. Multimodal Learning on Graphs for Disease Relation Extraction. (arXiv:2203.08893v2 [cs.LG] UPDATED)
43. GCNET: graph-based prediction of stock price movement using graph convolutional network. (arXiv:2203.11091v2 [q-fin.TR] UPDATED)
44. Automated Clinical Coding: What, Why, and Where We Are?. (arXiv:2203.11092v2 [cs.CL] UPDATED)
45. A Language Model for Text Analytics in Cybersecurity. (arXiv:2204.02685v2 [cs.CL] UPDATED)
46. Efficient Learning of Interpretable Classification Rules. (arXiv:2205.06936v2 [cs.LG] UPDATED)
47. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v4 [cs.LG] UPDATED)
48. Deep Quality Estimation: Creating Surrogate Models for Human Quality Ratings. (arXiv:2205.10355v2 [cs.CV] UPDATED)
49. Model-Based Imitation Learning Using Entropy Regularization of Model and Policy. (arXiv:2206.10101v2 [cs.LG] UPDATED)
50. Protea: Client Profiling within Federated Systems using Flower. (arXiv:2207.01053v2 [cs.LG] UPDATED)
51. $L_2$BN: Enhancing Batch Normalization by Equalizing the $L_2$ Norms of Features. (arXiv:2207.02625v2 [cs.CV] UPDATED)
52. Exploration in Linear Bandits with Rich Action Sets and its Implications for Inference. (arXiv:2207.11597v2 [cs.LG] UPDATED)
53. Towards Smart City Security: Violence and Weaponized Violence Detection using DCNN. (arXiv:2207.12850v2 [cs.CV] UPDATED)
54. Chinese grammatical error correction based on knowledge distillation. (arXiv:2208.00351v4 [cs.CL] UPDATED)
55. Contrastive Domain Adaptation for Early Misinformation Detection: A Case Study on COVID-19. (arXiv:2208.09578v2 [cs.CV] UPDATED)
56. Using Multi-Encoder Fusion Strategies to Improve Personalized Response Selection. (arXiv:2208.09601v2 [cs.CL] UPDATED)
57. Federated Learning via Decentralized Dataset Distillation in Resource-Constrained Edge Environments. (arXiv:2208.11311v2 [cs.LG] UPDATED)
58. TMIC: App Inventor Extension for the Deployment of Image Classification Models Exported from Teachable Machine. (arXiv:2208.12637v2 [cs.CY] UPDATED)
59. Prerequisite-driven Q-matrix Refinement for Learner Knowledge Assessment: A Case Study in Online Learning Context. (arXiv:2208.12642v2 [cs.CY] UPDATED)
60. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v2 [cs.CV] UPDATED)

