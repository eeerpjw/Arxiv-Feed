# Your interest papers
---
## cs.CV
---
### DR**HDR**: A Dual branch Residual Network for Multi-Bracket **High Dynamic Range** Imaging. (arXiv:2206.04124v1 [cs.CV])
- Authors : Juan Mar, Michael Sloth, Peter Schneider
- Link : [http://arxiv.org/abs/2206.04124](http://arxiv.org/abs/2206.04124)
> ABSTRACT  :  We introduce DR**HDR**, a Dual branch Residual Convolutional Neural Network for Multi-Bracket **HDR** Imaging. To address the challenges of fusing multiple brackets from dynamic scenes, we propose an efficient dual branch network that operates on two different resolutions. The full resolution branch uses a Deformable Convolutional Block to align features and retain high-frequency details. A low resolution branch with a Spatial Attention Block aims to attend wanted areas from the non-reference brackets, and suppress displaced features that could incur on ghosting artifacts. By using a dual branch approach we are able to achieve high quality results while constraining the computational resources required to estimate the **HDR** results.  
### JNMR: Joint Non-linear Motion Regression for Video Frame Interpolation. (arXiv:2206.04231v1 [cs.CV])
- Authors : Meiqin Liu, Chenming Xu, Chao Yao, Chunyu Lin, Yao Zhao
- Link : [http://arxiv.org/abs/2206.04231](http://arxiv.org/abs/2206.04231)
> ABSTRACT  :  Video frame interpolation (VFI) aims to generate predictive frames by warping learnable motions from the bidirectional historical references. Most existing works utilize spatio-temporal semantic information extractor to realize motion estimation and interpolation modeling, not enough considering with the real mechanistic rationality of generated middle motions. In this paper, we reformulate VFI as a multi-variable non-linear (MNL) regression problem, and a Joint Non-linear Motion Regression (JNMR) strategy is proposed to model complicated motions of inter-frame. To establish the MNL regression, ConvLSTM is adopted to construct the distribution of complete motions in temporal dimension. The motion correlations between the target frame and multiple reference frames can be regressed by the modeled distribution. Moreover, the feature learning network is designed to optimize for the MNL regression modeling. A coarse-to-fine synthesis **enhancement** module is further conducted to learn visual dynamics at different resolutions through repetitive regression and interpolation. Highly competitive experimental results on frame interpolation show that the effectiveness and significant improvement compared with state-of-the-art performance, and the robustness of complicated motion estimation is improved by the MNL motion regression.  
### **Swin**CheX: Multi-label classification on chest X-ray images with transformers. (arXiv:2206.04246v1 [cs.CV])
- Authors : Sina Taslimi, Soroush Taslimi, Nima Fathi, Mohammadreza Salehi, Mohammad Hossein
- Link : [http://arxiv.org/abs/2206.04246](http://arxiv.org/abs/2206.04246)
> ABSTRACT  :  According to the considerable growth in the avail of chest X-ray images in diagnosing various diseases, as well as gathering extensive datasets, having an automated diagnosis procedure using deep neural networks has occupied the minds of experts. Most of the available methods in computer vision use a CNN backbone to acquire high accuracy on the classification problems. Nevertheless, recent researches show that transformers, established as the de facto method in NLP, can also outperform many CNN-based models in vision. This paper proposes a multi-label classification deep model based on the **Swin** Transformer as the backbone to achieve state-of-the-art diagnosis classification. It leverages Multi-Layer Perceptron, also known as MLP, for the head architecture. We evaluate our model on one of the most widely-used and largest x-ray datasets called "Chest X-ray14," which comprises more than 100,000 frontal/back-view images from over 30,000 patients with 14 famous chest diseases. Our model has been tested with several number of MLP layers for the head setting, each achieves a competitive AUC score on all classes. Comprehensive experiments on Chest X-ray14 have shown that a 3-layer head attains state-of-the-art performance with an average AUC score of 0.810, compared to the former SOTA average AUC of 0.799. We propose an experimental setup for the fair benchmarking of existing methods, which could be used as a basis for the future studies. Finally, we followed up our results by confirming that the proposed method attends to the pathologically relevant areas of the chest.  
### Cross-modal Local Shortest Path and Global **Enhancement** for Visible-Thermal Person Re-Identification. (arXiv:2206.04401v1 [cs.CV])
- Authors : Xiaohong Wang, Chaoqi Li, Xiangcai Ma
- Link : [http://arxiv.org/abs/2206.04401](http://arxiv.org/abs/2206.04401)
> ABSTRACT  :  In addition to considering the recognition difficulty caused by human posture and occlusion, it is also necessary to solve the modal differences caused by different imaging systems in the Visible-Thermal cross-modal person re-identification (VT-ReID) task. In this paper,we propose the Cross-modal Local Shortest Path and Global **Enhancement** (CM-LSP-GE) modules,a two-stream network based on joint learning of local and global features. The core idea of our paper is to use local feature alignment to solve occlusion problem, and to solve modal difference by strengthening global feature. Firstly, Attention-based two-stream ResNet network is designed to extract dual-modality features and map to a unified feature space. Then, to solve the cross-modal person pose and occlusion problems, the image are cut horizontally into several equal parts to obtain local features and the shortest path in local features between two graphs is used to achieve the fine-grained local feature alignment. Thirdly, a batch normalization **enhancement** module applies global features to enhance strategy, resulting in difference **enhancement** between different classes. The multi granularity loss fusion strategy further improves the performance of the algorithm. Finally, joint learning mechanism of local and global features is used to improve cross-modal person re-identification accuracy. The experimental results on two typical datasets show that our model is obviously superior to the most state-of-the-art methods. Especially, on SYSU-MM01 datasets, our model can achieve a gain of 2.89%and 7.96% in all search term of Rank-1 and mAP. The source code will be released soon.  
### Cross-boosting of WNNM Image Denoising method by Directional Wavelet Packets. (arXiv:2206.04431v1 [eess.IV])
- Authors : Amir Averbuch, Pekka Neittaanm, Valery Zheludev, Moshe Salhov, Jonathan Hauser
- Link : [http://arxiv.org/abs/2206.04431](http://arxiv.org/abs/2206.04431)
> ABSTRACT  :  The paper presents an image denoising scheme by combining a method that is based on directional quasi-analytic wavelet packets (qWPs) with the state-of-the-art Weighted Nuclear Norm Minimization (WNNM) denoising algorithm. The qWP-based denoising method (qWPdn) consists of multiscale qWP transform of the degraded image, application of adaptive localized soft thresholding to the transform coefficients using the Bivariate Shrinkage methodology, and **restoration** of the image from the thresholded coefficients from several decomposition levels. The combined method consists of several iterations of qWPdn and WNNM algorithms in a way that at each iteration the output from one algorithm boosts the input to the other. The proposed methodology couples the qWPdn capabilities to capture edges and fine texture patterns even in the severely corrupted images with utilizing the non-local self-similarity in real images that is inherent in the WNNM algorithm.    Multiple experiments, which compared the proposed methodology with six advanced denoising algorithms, including WNNM, confirmed that the combined cross-boosting algorithm outperforms most of them in terms of both quantitative measure and visual perception quality.  
### VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
- Authors : Zeyuan Chen, Yinbo Chen, Jingwen Liu, Xingqian Xu, Vidit Goel, Zhangyang Wang, Humphrey Shi, Xiaolong Wang
- Link : [http://arxiv.org/abs/2206.04647](http://arxiv.org/abs/2206.04647)
> ABSTRACT  :  Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high fidelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a unified framework. However, most of them only support a fixed up-sampling scale, which limits their flexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned **implicit neural representation** can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and significantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at <a href="http://zeyuan-chen.com/VideoINR/">this http URL</a> .  
### Beyond RGB: Scene-Property Synthesis with Neural Radiance Fields. (arXiv:2206.04669v1 [cs.CV])
- Authors : Mingtong Zhang, Shuhong Zheng, Zhipeng Bao, Martial Hebert, Xiong Wang
- Link : [http://arxiv.org/abs/2206.04669](http://arxiv.org/abs/2206.04669)
> ABSTRACT  :  Comprehensive 3D scene understanding, both geometrically and semantically, is important for real-world applications such as robot perception. Most of the existing work has focused on developing data-driven discriminative models for scene understanding. This paper provides a new approach to scene understanding, from a synthesis model perspective, by leveraging the recent progress on implicit 3D representation and neural rendering. Building upon the great success of Neural Radiance Fields (**NeRF**s), we introduce Scene-Property Synthesis with **NeRF** (SS-**NeRF**) that is able to not only render photo-realistic RGB images from novel viewpoints, but also render various accurate scene properties (e.g., appearance, geometry, and semantics). By doing so, we facilitate addressing a variety of scene understanding tasks under a unified framework, including semantic segmentation, surface normal estimation, reshading, keypoint detection, and edge detection. Our SS-**NeRF** framework can be a powerful tool for bridging generative learning and discriminative learning, and thus be beneficial to the investigation of a wide range of interesting problems, such as studying task relationships within a synthesis paradigm, transferring knowledge to novel tasks, facilitating downstream discriminative tasks as ways of data augmentation, and serving as auto-labeller for data creation.  
### Indoor Depth Completion with Boundary Consistency and Self-Attention. (arXiv:1908.08344v3 [cs.CV] UPDATED)
- Authors : Kai Huang, Han Wu, Cheng Liu
- Link : [http://arxiv.org/abs/1908.08344](http://arxiv.org/abs/1908.08344)
> ABSTRACT  :  Depth estimation features are helpful for 3D recognition. Commodity-grade depth cameras are able to capture depth and color image in real-time. However, glossy, transparent or distant surface cannot be scanned properly by the sensor. As a result, **enhancement** and **restoration** from sensing depth is an important task. Depth completion aims at filling the holes that sensors fail to detect, which is still a complex task for machine to learn. Traditional hand-tuned methods have reached their limits, while neural network based methods tend to copy and interpolate the output from surrounding depth values. This leads to blurred boundaries, and structures of the depth map are lost. Consequently, our main work is to design an end-to-end network improving completion depth maps while maintaining edge clarity. We utilize self-attention mechanism, previously used in image inpainting fields, to extract more useful information in each layer of convolution so that the complete depth map is enhanced. In addition, we propose boundary consistency concept to enhance the depth map quality and structure. Experimental results validate the effectiveness of our self-attention and boundary consistency schema, which outperforms previous state-of-the-art depth completion work on Matterport3D dataset. Our code is publicly available at https://github.com/tsunghan-wu/Depth-Completion.  
### Unsupervised Monocular Depth Estimation in Highly Complex Environments. (arXiv:2107.13137v2 [cs.CV] UPDATED)
- Authors : Chaoqiang Zhao, Yang Tang, Qiyu Sun
- Link : [http://arxiv.org/abs/2107.13137](http://arxiv.org/abs/2107.13137)
> ABSTRACT  :  With the development of computational intelligence algorithms, unsupervised monocular depth and pose estimation framework, which is driven by warped photometric consistency, has shown great performance in the daytime scenario. While in some challenging environments, like **night** and rainy **night**, the essential photometric consistency hypothesis is untenable because of the complex lighting and reflection, so that the above unsupervised framework cannot be directly applied to these complex scenarios. In this paper, we investigate the problem of unsupervised monocular depth estimation in highly complex scenarios and address this challenging problem by adopting an image transfer-based domain adaptation framework. We adapt the depth model trained on day-time scenarios to be applicable to **night**-time scenarios, and constraints on both feature space and output space promote the framework to learn the key features for depth decoding. Meanwhile, we further tackle the effects of unstable image transfer quality on domain adaptation, and an image adaptation approach is proposed to evaluate the quality of transferred images and re-weight the corresponding losses, so as to improve the performance of the adapted depth model. Extensive experiments show the effectiveness of the proposed unsupervised framework in estimating the dense depth map from highly complex images.  
### An Educated Warm Start For Deep Image Prior-Based Micro CT Reconstruction. (arXiv:2111.11926v2 [eess.IV] UPDATED)
- Authors : Riccardo Barbano, Johannes Leuschner, Maximilian Schmidt, Alexander Denker, Andreas Hauptmann, Peter Maa, Bangti Jin
- Link : [http://arxiv.org/abs/2111.11926](http://arxiv.org/abs/2111.11926)
> ABSTRACT  :  Deep image prior (DIP) was recently introduced as an effective unsupervised approach for image **restoration** tasks. DIP represents the image to be recovered as the output of a deep convolutional neural network, and learns the network's parameters such that the output matches the corrupted observation. Despite its impressive reconstructive properties, the approach is slow when compared to supervisedly learned, or traditional reconstruction techniques. To address the computational challenge, we bestow DIP with a two-stage learning paradigm: (i) perform a supervised pretraining of the network on a simulated dataset; (ii) fine-tune the network's parameters to adapt to the target reconstruction task. We provide a thorough empirical analysis to shed insights into the impacts of pretraining in the context of image reconstruction. We showcase that pretraining considerably speeds up and stabilizes the subsequent reconstruction task from real-measured 2D and 3D micro computed tomography data of biological specimens. The code and additional experimental materials are available at https://educateddip.github.io/docs.educated_deep_image_prior/.  
### Mip-**NeRF** RGB-D: Depth Assisted Fast Neural Radiance Fields. (arXiv:2205.09351v2 [cs.CV] UPDATED)
- Authors : Arnab Dey, Yassine Ahmine
- Link : [http://arxiv.org/abs/2205.09351](http://arxiv.org/abs/2205.09351)
> ABSTRACT  :  Neural scene representations, such as Neural Radiance Fields (**NeRF**), are based on training a multilayer perceptron (MLP) using a set of color images with known poses. An increasing number of devices now produce RGB-D(color + depth) information, which has been shown to be very important for a wide range of tasks. Therefore, the aim of this paper is to investigate what improvements can be made to these promising implicit representations by incorporating depth information with the color images. In particular, the recently proposed Mip-**NeRF** approach, which uses conical frustums instead of rays for volume rendering, allows one to account for the varying area of a pixel with distance from the camera center. The proposed method additionally models depth uncertainty. This allows to address major limitations of **NeRF**-based approaches including improving the accuracy of geometry, reduced artifacts, faster training time, and shortened prediction time. Experiments are performed on well-known benchmark scenes, and comparisons show improved accuracy in scene geometry and photometric reconstruction, while reducing the training time by 3 - 5 times.  
## eess.IV
---
### DR**HDR**: A Dual branch Residual Network for Multi-Bracket **High Dynamic Range** Imaging. (arXiv:2206.04124v1 [cs.CV])
- Authors : Juan Mar, Michael Sloth, Peter Schneider
- Link : [http://arxiv.org/abs/2206.04124](http://arxiv.org/abs/2206.04124)
> ABSTRACT  :  We introduce DR**HDR**, a Dual branch Residual Convolutional Neural Network for Multi-Bracket **HDR** Imaging. To address the challenges of fusing multiple brackets from dynamic scenes, we propose an efficient dual branch network that operates on two different resolutions. The full resolution branch uses a Deformable Convolutional Block to align features and retain high-frequency details. A low resolution branch with a Spatial Attention Block aims to attend wanted areas from the non-reference brackets, and suppress displaced features that could incur on ghosting artifacts. By using a dual branch approach we are able to achieve high quality results while constraining the computational resources required to estimate the **HDR** results.  
### Cross-boosting of WNNM Image Denoising method by Directional Wavelet Packets. (arXiv:2206.04431v1 [eess.IV])
- Authors : Amir Averbuch, Pekka Neittaanm, Valery Zheludev, Moshe Salhov, Jonathan Hauser
- Link : [http://arxiv.org/abs/2206.04431](http://arxiv.org/abs/2206.04431)
> ABSTRACT  :  The paper presents an image denoising scheme by combining a method that is based on directional quasi-analytic wavelet packets (qWPs) with the state-of-the-art Weighted Nuclear Norm Minimization (WNNM) denoising algorithm. The qWP-based denoising method (qWPdn) consists of multiscale qWP transform of the degraded image, application of adaptive localized soft thresholding to the transform coefficients using the Bivariate Shrinkage methodology, and **restoration** of the image from the thresholded coefficients from several decomposition levels. The combined method consists of several iterations of qWPdn and WNNM algorithms in a way that at each iteration the output from one algorithm boosts the input to the other. The proposed methodology couples the qWPdn capabilities to capture edges and fine texture patterns even in the severely corrupted images with utilizing the non-local self-similarity in real images that is inherent in the WNNM algorithm.    Multiple experiments, which compared the proposed methodology with six advanced denoising algorithms, including WNNM, confirmed that the combined cross-boosting algorithm outperforms most of them in terms of both quantitative measure and visual perception quality.  
### VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
- Authors : Zeyuan Chen, Yinbo Chen, Jingwen Liu, Xingqian Xu, Vidit Goel, Zhangyang Wang, Humphrey Shi, Xiaolong Wang
- Link : [http://arxiv.org/abs/2206.04647](http://arxiv.org/abs/2206.04647)
> ABSTRACT  :  Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high fidelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a unified framework. However, most of them only support a fixed up-sampling scale, which limits their flexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned **implicit neural representation** can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and significantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at <a href="http://zeyuan-chen.com/VideoINR/">this http URL</a> .  
### An Educated Warm Start For Deep Image Prior-Based Micro CT Reconstruction. (arXiv:2111.11926v2 [eess.IV] UPDATED)
- Authors : Riccardo Barbano, Johannes Leuschner, Maximilian Schmidt, Alexander Denker, Andreas Hauptmann, Peter Maa, Bangti Jin
- Link : [http://arxiv.org/abs/2111.11926](http://arxiv.org/abs/2111.11926)
> ABSTRACT  :  Deep image prior (DIP) was recently introduced as an effective unsupervised approach for image **restoration** tasks. DIP represents the image to be recovered as the output of a deep convolutional neural network, and learns the network's parameters such that the output matches the corrupted observation. Despite its impressive reconstructive properties, the approach is slow when compared to supervisedly learned, or traditional reconstruction techniques. To address the computational challenge, we bestow DIP with a two-stage learning paradigm: (i) perform a supervised pretraining of the network on a simulated dataset; (ii) fine-tune the network's parameters to adapt to the target reconstruction task. We provide a thorough empirical analysis to shed insights into the impacts of pretraining in the context of image reconstruction. We showcase that pretraining considerably speeds up and stabilizes the subsequent reconstruction task from real-measured 2D and 3D micro computed tomography data of biological specimens. The code and additional experimental materials are available at https://educateddip.github.io/docs.educated_deep_image_prior/.  
## cs.LG
---
### Gradient Obfuscation Gives a False Sense of Security in Federated Learning. (arXiv:2206.04055v1 [cs.CR])
- Authors : Kai Yue, Richeng Jin, Wai Wong, Dror Baron, Huaiyu Dai
- Link : [http://arxiv.org/abs/2206.04055](http://arxiv.org/abs/2206.04055)
> ABSTRACT  :  Federated learning has been proposed as a privacy-preserving machine learning framework that enables multiple clients to collaborate without sharing raw data. However, client privacy protection is not guaranteed by design in this framework. Prior work has shown that the gradient sharing strategies in federated learning can be vulnerable to data reconstruction attacks. In practice, though, clients may not transmit raw gradients considering the high communication cost or due to privacy **enhancement** requirements. Empirical studies have demonstrated that gradient obfuscation, including intentional obfuscation via gradient noise injection and unintentional obfuscation via gradient compression, can provide more privacy protection against reconstruction attacks. In this work, we present a new data reconstruction attack framework targeting the image classification task in federated learning. We show that commonly adopted gradient postprocessing procedures, such as gradient quantization, gradient sparsification, and gradient perturbation, may give a false sense of security in federated learning. Contrary to prior studies, we argue that privacy **enhancement** should not be treated as a byproduct of gradient compression. Additionally, we design a new method under the proposed framework to reconstruct the image at the semantic level. We quantify the semantic privacy leakage and compare with conventional based on image similarity scores. Our comparisons challenge the image data leakage evaluation schemes in the literature. The results emphasize the importance of revisiting and redesigning the privacy protection mechanisms for client data in existing federated learning algorithms.  
### **Enhancement** of Healthcare Data Transmission using the Levenberg-Marquardt Algorithm. (arXiv:2206.04240v1 [cs.LG])
- Authors : Angela An, James Jin
- Link : [http://arxiv.org/abs/2206.04240](http://arxiv.org/abs/2206.04240)
> ABSTRACT  :  In the healthcare system, patients are required to use wearable devices for the remote data collection and real-time monitoring of health data and the status of health conditions. This adoption of wearables results in a significant increase in the volume of data that is collected and transmitted. As the devices are run by small battery power, they can be quickly diminished due to the high processing requirements of the device for data collection and transmission. Given the importance attached to medical data, it is imperative that all transmitted data adhere to strict integrity and availability requirements. Reducing the volume of healthcare data and the frequency of transmission will improve the device battery life via using inference algorithm. There is an issue of improving transmission metrics with accuracy and efficiency, which trade-off each other such as increasing accuracy reduces the efficiency. This paper demonstrates that machine learning can be used to analyze complex health data metrics such as the accuracy and efficiency of data transmission to overcome the trade-off problem using the Levenberg-Marquardt algorithm to enhance both metrics by taking fewer samples to transmit whilst maintaining the accuracy. The algorithm is tested with a standard heart rate dataset to compare the metrics. The result shows that the LMA has best performed with an efficiency of 3.33 times for reduced sample data size and accuracy of 79.17%, which has the similar accuracies in 7 different sampling cases adopted for testing but demonstrates improved efficiency. These proposed methods significantly improved both metrics using machine learning without sacrificing a metric over the other compared to the existing methods with high efficiency.  
### VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
- Authors : Zeyuan Chen, Yinbo Chen, Jingwen Liu, Xingqian Xu, Vidit Goel, Zhangyang Wang, Humphrey Shi, Xiaolong Wang
- Link : [http://arxiv.org/abs/2206.04647](http://arxiv.org/abs/2206.04647)
> ABSTRACT  :  Videos typically record the streaming and continuous visual data as discrete consecutive frames. Since the storage cost is expensive for videos of high fidelity, most of them are stored in a relatively low resolution and frame rate. Recent works of Space-Time Video Super-Resolution (STVSR) are developed to incorporate temporal interpolation and spatial super-resolution in a unified framework. However, most of them only support a fixed up-sampling scale, which limits their flexibility and applications. In this work, instead of following the discrete representations, we propose Video Implicit Neural Representation (VideoINR), and we show its applications for STVSR. The learned **implicit neural representation** can be decoded to videos of arbitrary spatial resolution and frame rate. We show that VideoINR achieves competitive performances with state-of-the-art STVSR methods on common up-sampling scales and significantly outperforms prior works on continuous and out-of-training-distribution scales. Our project page is at <a href="http://zeyuan-chen.com/VideoINR/">this http URL</a> .  
## cs.AI
---
### Gradient Obfuscation Gives a False Sense of Security in Federated Learning. (arXiv:2206.04055v1 [cs.CR])
- Authors : Kai Yue, Richeng Jin, Wai Wong, Dror Baron, Huaiyu Dai
- Link : [http://arxiv.org/abs/2206.04055](http://arxiv.org/abs/2206.04055)
> ABSTRACT  :  Federated learning has been proposed as a privacy-preserving machine learning framework that enables multiple clients to collaborate without sharing raw data. However, client privacy protection is not guaranteed by design in this framework. Prior work has shown that the gradient sharing strategies in federated learning can be vulnerable to data reconstruction attacks. In practice, though, clients may not transmit raw gradients considering the high communication cost or due to privacy **enhancement** requirements. Empirical studies have demonstrated that gradient obfuscation, including intentional obfuscation via gradient noise injection and unintentional obfuscation via gradient compression, can provide more privacy protection against reconstruction attacks. In this work, we present a new data reconstruction attack framework targeting the image classification task in federated learning. We show that commonly adopted gradient postprocessing procedures, such as gradient quantization, gradient sparsification, and gradient perturbation, may give a false sense of security in federated learning. Contrary to prior studies, we argue that privacy **enhancement** should not be treated as a byproduct of gradient compression. Additionally, we design a new method under the proposed framework to reconstruct the image at the semantic level. We quantify the semantic privacy leakage and compare with conventional based on image similarity scores. Our comparisons challenge the image data leakage evaluation schemes in the literature. The results emphasize the importance of revisiting and redesigning the privacy protection mechanisms for client data in existing federated learning algorithms.  
### Improved two-stage hate speech classification for twitter based on Deep Neural Networks. (arXiv:2206.04162v1 [cs.CL])
- Authors : 
- Link : [http://arxiv.org/abs/2206.04162](http://arxiv.org/abs/2206.04162)
> ABSTRACT  :  Hate speech is a form of online harassment that involves the use of abusive language, and it is commonly seen in social media posts. This sort of harassment mainly focuses on specific group characteristics such as religion, gender, ethnicity, etc and it has both societal and economic consequences nowadays. The automatic detection of abusive language in text postings has always been a difficult task, but it is lately receiving much interest from the scientific community. This paper addresses the important problem of discerning hateful content in social media. The model we propose in this work is an extension of an existing approach based on LSTM neural network architectures, which we appropriately enhanced and fine-tuned to detect certain forms of hatred language, such as racism or sexism, in a short text. The most significant **enhancement** is the conversion to a two-stage scheme consisting of Recurrent Neural Network (RNN) classifiers. The output of all One-vs-Rest (OvR) classifiers from the first stage are combined and used to train the second stage classifier, which finally determines the type of harassment. Our study includes a performance comparison of several proposed alternative methods for the second stage evaluated on a public corpus of 16k tweets, followed by a generalization study on another dataset. The reported results show the superior classification quality of the proposed scheme in the task of hate speech detection as compared to the current state-of-the-art.  
# Paper List
---
## cs.CV
---
**117** new papers in cs.CV:-) 
1. An Improved Deep Convolutional Neural Network by Using Hybrid Optimization Algorithms to Detect and Classify Brain Tumor Using Augmented MRI Images. (arXiv:2206.04056v1 [eess.IV])
2. DR**HDR**: A Dual branch Residual Network for Multi-Bracket **High Dynamic Range** Imaging. (arXiv:2206.04124v1 [cs.CV])
3. Towards Self-supervised and Weight-preserving Neural Architecture Search. (arXiv:2206.04125v1 [cs.CV])
4. Receding Moving Object Segmentation in 3D LiDAR Data Using Sparse 4D Convolutions. (arXiv:2206.04129v1 [cs.RO])
5. Deep Estimation of Speckle Statistics Parametric Images. (arXiv:2206.04145v1 [eess.IV])
6. Ensembling Framework for Texture Extraction Techniques for Classification. (arXiv:2206.04158v1 [cs.CV])
7. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v1 [cs.CV])
8. VN-Transformer: Rotation-Equivariant Attention for Vector Neurons. (arXiv:2206.04176v1 [cs.CV])
9. SCAMPS: Synthetics for Camera Measurement of Physiological Signals. (arXiv:2206.04197v1 [cs.CV])
10. JNMR: Joint Non-linear Motion Regression for Video Frame Interpolation. (arXiv:2206.04231v1 [cs.CV])
11. Cardiac Adipose Tissue Segmentation via Image-Level Annotations. (arXiv:2206.04238v1 [eess.IV])
12. OOD Augmentation May Be at Odds with Open-Set Recognition. (arXiv:2206.04242v1 [cs.CV])
13. **Swin**CheX: Multi-label classification on chest X-ray images with transformers. (arXiv:2206.04246v1 [cs.CV])
14. DeepVerge: Classification of Roadside Verge Biodiversity and Conservation Potential. (arXiv:2206.04271v1 [cs.CV])
15. STEM image analysis based on deep learning: identification of vacancy defects and polymorphs of ${MoS_2}$. (arXiv:2206.04272v1 [cond-mat.mes-hall])
16. Local Spatiotemporal Representation Learning for Longitudinally-consistent Neuroimage Analysis. (arXiv:2206.04281v1 [cs.CV])
17. A No-Reference Deep Learning Quality Assessment Method for Super-resolution Images Based on Frequency Maps. (arXiv:2206.04289v1 [eess.IV])
18. Reconstruct Face from Features Using GAN Generator as a Distribution Constraint. (arXiv:2206.04295v1 [cs.CV])
19. GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing. (arXiv:2206.04310v1 [cs.LG])
20. Blind Surveillance Image Quality Assessment via Deep Neural Network Combined with the Visual Saliency. (arXiv:2206.04318v1 [cs.MM])
21. CFA: Coupled-hypersphere-based Feature Adaptation for Target-Oriented Anomaly Localization. (arXiv:2206.04325v1 [cs.CV])
22. Novel projection schemes for graph-based Light Field coding. (arXiv:2206.04328v1 [eess.IV])
23. Joint Modeling of Image and Label Statistics for Enhancing Model Generalizability of Medical Image Segmentation. (arXiv:2206.04336v1 [eess.IV])
24. How Asynchronous Events Encode Video. (arXiv:2206.04341v1 [eess.IV])
25. Deep radiomic signature with immune cell markers predicts the survival of glioma patients. (arXiv:2206.04349v1 [cs.CV])
26. Deep Neural Network for Blind Visual Quality Assessment of 4K Content. (arXiv:2206.04363v1 [cs.MM])
27. CARLA-GeAR: a Dataset Generator for a Systematic Evaluation of Adversarial Robustness of Vision Models. (arXiv:2206.04365v1 [cs.CV])
28. Uncovering bias in the PlantVillage dataset. (arXiv:2206.04374v1 [cs.CV])
29. STIP: A SpatioTemporal Information-Preserving and Perception-Augmented Model for High-Resolution Video Prediction. (arXiv:2206.04381v1 [cs.CV])
30. CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes. (arXiv:2206.04382v1 [cs.CV])
31. Depression Recognition using Remote Photoplethysmography from Facial Videos. (arXiv:2206.04399v1 [cs.CV])
32. Cross-modal Local Shortest Path and Global **Enhancement** for Visible-Thermal Person Re-Identification. (arXiv:2206.04401v1 [cs.CV])
33. VITA: Video Instance Segmentation via Object Token Association. (arXiv:2206.04403v1 [cs.CV])
34. Unsupervised Learning of the Total Variation Flow. (arXiv:2206.04406v1 [cs.CV])
35. Multiple Instance Learning for Digital Pathology: A Review on the State-of-the-Art, Limitations & Future Potential. (arXiv:2206.04425v1 [cs.CV])
36. Cross-boosting of WNNM Image Denoising method by Directional Wavelet Packets. (arXiv:2206.04431v1 [eess.IV])
37. Segmentation Enhanced Lameness Detection in Dairy Cows from RGB and Depth Video. (arXiv:2206.04449v1 [cs.CV])
38. Draft-and-Revise: Effective Image Generation with Contextual RQ-Transformer. (arXiv:2206.04452v1 [cs.CV])
39. The Missing Link: Finding label relations across datasets. (arXiv:2206.04453v1 [cs.CV])
40. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v1 [cs.LG])
41. BSM loss: A superior way in modeling aleatory uncertainty of fine_grained classification. (arXiv:2206.04479v1 [cs.CV])
42. cycle text2face: cycle text-to-face gan via transformers. (arXiv:2206.04503v1 [cs.CV])
43. Efficient Human Pose Estimation via 3D Event Point Cloud. (arXiv:2206.04511v1 [cs.CV])
44. SAR Despeckling using a Denoising Diffusion Probabilistic Model. (arXiv:2206.04514v1 [eess.IV])
45. Face-Dubbing++: Lip-Synchronous, Voice Preserving Translation of Videos. (arXiv:2206.04523v1 [cs.CL])
46. DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v1 [cs.LG])
47. ECLAD: Extracting Concepts with Local Aggregated Descriptors. (arXiv:2206.04531v1 [cs.CV])
48. Classification of COVID-19 in Chest X-ray Images Using Fusion of Deep Features and LightGBM. (arXiv:2206.04548v1 [eess.IV])
49. SparseFormer: Attention-based Depth Completion Network. (arXiv:2206.04557v1 [cs.CV])
50. BFS-Net: Weakly Supervised Cell Instance Segmentation from Bright-Field Microscopy Z-Stacks. (arXiv:2206.04558v1 [cs.CV])
51. Transformer based Urdu Handwritten Text Optical Character Reader. (arXiv:2206.04575v1 [cs.CV])
52. Efficient and Robust 2D-to-BEV Representation Learning via Geometry-guided Kernel Transformer. (arXiv:2206.04584v1 [cs.CV])
53. GASP: Gated Attention For Saliency Prediction. (arXiv:2206.04590v1 [cs.CV])
54. AttX: Attentive Cross-Connections for Fusion of Wearable Signals in Emotion Recognition. (arXiv:2206.04625v1 [cs.LG])
55. Spatial Entropy Regularization for Vision Transformers. (arXiv:2206.04636v1 [cs.CV])
56. VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
57. Towards Layer-wise Image Vectorization. (arXiv:2206.04655v1 [cs.CV])
58. Simple Cues Lead to a Strong Multi-Object Tracker. (arXiv:2206.04656v1 [cs.CV])
59. DiSparse: Disentangled Sparsification for Multitask Model Compression. (arXiv:2206.04662v1 [cs.CV])
60. On Data Scaling in Masked Image Modeling. (arXiv:2206.04664v1 [cs.CV])
61. AGConv: Adaptive Graph Convolution on 3D Point Clouds. (arXiv:2206.04665v1 [cs.CV])
62. Extreme Masking for Learning Instance and Distributed Visual Representations. (arXiv:2206.04667v1 [cs.CV])
63. GateHUB: Gated History Unit with Background Suppression for Online Action Detection. (arXiv:2206.04668v1 [cs.CV])
64. Beyond RGB: Scene-Property Synthesis with Neural Radiance Fields. (arXiv:2206.04669v1 [cs.CV])
65. PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies. (arXiv:2206.04670v1 [cs.CV])
66. Open Challenges in Deep Stereo: the Booster Dataset. (arXiv:2206.04671v1 [cs.CV])
67. Neural Prompt Search. (arXiv:2206.04673v1 [cs.CV])
68. Uni-Perceiver-MoE: Learning Sparse Generalist Models with Conditional MoEs. (arXiv:2206.04674v1 [cs.CV])
69. Indoor Depth Completion with Boundary Consistency and Self-Attention. (arXiv:1908.08344v3 [cs.CV] UPDATED)
70. Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks. (arXiv:2006.14042v3 [cs.CR] UPDATED)
71. Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks in Highly Accelerated MRI. (arXiv:2008.06029v2 [eess.IV] UPDATED)
72. Denoising Diffusion Implicit Models. (arXiv:2010.02502v3 [cs.LG] UPDATED)
73. Explaining Clinical Decision Support Systems in Medical Imaging using Cycle-Consistent Activation Maximization. (arXiv:2010.05759v3 [eess.IV] UPDATED)
74. DUT: Learning Video Stabilization by Simply Watching Unstable Videos. (arXiv:2011.14574v3 [cs.CV] UPDATED)
75. Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks. (arXiv:2011.14663v3 [cs.CV] UPDATED)
76. NVUM: Non-Volatile Unbiased Memory for Robust Medical Image Classification. (arXiv:2103.04053v4 [cs.CV] UPDATED)
77. A Study of Face Obfuscation in ImageNet. (arXiv:2103.06191v3 [cs.CV] UPDATED)
78. Fast Hierarchical Games for Image Explanations. (arXiv:2104.06164v2 [cs.CV] UPDATED)
79. Backdoor Attacks on Self-Supervised Learning. (arXiv:2105.10123v3 [cs.CV] UPDATED)
80. Image Deformation Estimation via Multi-Objective Optimization. (arXiv:2106.04139v2 [cs.CV] UPDATED)
81. Contrastive Counterfactual Visual Explanations With Overdetermination. (arXiv:2106.14556v3 [cs.CV] UPDATED)
82. Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v3 [cs.LG] UPDATED)
83. Zero-Shot Domain Adaptation in CT Segmentation by Filtered Back Projection Augmentation. (arXiv:2107.08543v4 [eess.IV] UPDATED)
84. ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v3 [cs.CV] UPDATED)
85. Unsupervised Monocular Depth Estimation in Highly Complex Environments. (arXiv:2107.13137v2 [cs.CV] UPDATED)
86. NPBDREG: Uncertainty Assessment in Diffeomorphic Brain MRI Registration using a Non-parametric Bayesian Deep-Learning Based Approach. (arXiv:2108.06771v4 [cs.CV] UPDATED)
87. MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification. (arXiv:2108.12828v4 [cs.CV] UPDATED)
88. Domain Generalization for Medical Image Segmentation via Hierarchical Consistency Regularization. (arXiv:2109.05742v2 [cs.CV] UPDATED)
89. Boosting Fast Adversarial Training with Learnable Adversarial Initialization. (arXiv:2110.05007v2 [cs.CV] UPDATED)
90. Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash. (arXiv:2111.06628v4 [cs.LG] UPDATED)
91. An Educated Warm Start For Deep Image Prior-Based Micro CT Reconstruction. (arXiv:2111.11926v2 [eess.IV] UPDATED)
92. FogAdapt: Self-Supervised Domain Adaptation for Semantic Segmentation of Foggy Images. (arXiv:2201.02588v3 [cs.CV] UPDATED)
93. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v3 [cs.CV] UPDATED)
94. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v4 [cs.LG] UPDATED)
95. ADG-Pose: Automated Dataset Generation for Real-World Human Pose Estimation. (arXiv:2202.00753v2 [cs.CV] UPDATED)
96. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v5 [cs.CV] UPDATED)
97. What Makes Transfer Learning Work For Medical Images: Feature Reuse & Other Factors. (arXiv:2203.01825v2 [cs.LG] UPDATED)
98. Self-Promoted Supervision for Few-Shot Transformer. (arXiv:2203.07057v2 [cs.CV] UPDATED)
99. Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of Demonstrations for Social Navigation. (arXiv:2203.15041v2 [cs.RO] UPDATED)
100. TubeDETR: Spatio-Temporal Video Grounding with Transformers. (arXiv:2203.16434v2 [cs.CV] UPDATED)
101. Knowledge-based Entity Prediction for Improved Machine Perception in Autonomous Systems. (arXiv:2203.16616v3 [cs.AI] UPDATED)
102. SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization. (arXiv:2205.07547v2 [cs.LG] UPDATED)
103. Mip-**NeRF** RGB-D: Depth Assisted Fast Neural Radiance Fields. (arXiv:2205.09351v2 [cs.CV] UPDATED)
104. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v2 [cs.LG] UPDATED)
105. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v3 [cs.LG] UPDATED)
106. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v2 [cs.CV] UPDATED)
107. Tagged-MRI Sequence to Audio Synthesis via Self Residual Attention Guided Heterogeneous Translator. (arXiv:2206.02284v2 [cs.SD] UPDATED)
108. ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with Asymmetric Co-training. (arXiv:2206.02288v2 [cs.CV] UPDATED)
109. EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain Extraction. (arXiv:2206.02837v2 [eess.IV] UPDATED)
110. cViL: Cross-Lingual Training of Vision-Language Models using Knowledge Distillation. (arXiv:2206.03354v2 [cs.CL] UPDATED)
111. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v2 [cs.CV] UPDATED)
112. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v2 [cs.CV] UPDATED)
113. Hypernetwork-based Personalized Federated Learning for Multi-Institutional CT Imaging. (arXiv:2206.03709v2 [eess.IV] UPDATED)
114. Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks. (arXiv:2206.03826v2 [cs.LG] UPDATED)
115. Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays. (arXiv:2206.03935v2 [eess.IV] UPDATED)
116. Accelerating Score-based Generative Models for High-Resolution Image Synthesis. (arXiv:2206.04029v2 [cs.CV] UPDATED)
117. Unsupervised Dictionary Learning for Anomaly Detection. (arXiv:2003.00293v2 [cs.LG] CROSS LISTED)
## eess.IV
---
**30** new papers in eess.IV:-) 
1. An Improved Deep Convolutional Neural Network by Using Hybrid Optimization Algorithms to Detect and Classify Brain Tumor Using Augmented MRI Images. (arXiv:2206.04056v1 [eess.IV])
2. DR**HDR**: A Dual branch Residual Network for Multi-Bracket **High Dynamic Range** Imaging. (arXiv:2206.04124v1 [cs.CV])
3. Deep Estimation of Speckle Statistics Parametric Images. (arXiv:2206.04145v1 [eess.IV])
4. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v1 [cs.CV])
5. Cardiac Adipose Tissue Segmentation via Image-Level Annotations. (arXiv:2206.04238v1 [eess.IV])
6. A No-Reference Deep Learning Quality Assessment Method for Super-resolution Images Based on Frequency Maps. (arXiv:2206.04289v1 [eess.IV])
7. Novel projection schemes for graph-based Light Field coding. (arXiv:2206.04328v1 [eess.IV])
8. Joint Modeling of Image and Label Statistics for Enhancing Model Generalizability of Medical Image Segmentation. (arXiv:2206.04336v1 [eess.IV])
9. How Asynchronous Events Encode Video. (arXiv:2206.04341v1 [eess.IV])
10. Only-Train-Once MR Fingerprinting for Magnetization Transfer Contrast Quantification. (arXiv:2206.04383v1 [eess.IV])
11. Unsupervised Learning of the Total Variation Flow. (arXiv:2206.04406v1 [cs.CV])
12. Cross-boosting of WNNM Image Denoising method by Directional Wavelet Packets. (arXiv:2206.04431v1 [eess.IV])
13. Convolutional Dictionary Learning by End-To-End Training of Iterative Neural Networks. (arXiv:2206.04447v1 [eess.IV])
14. SAR Despeckling using a Denoising Diffusion Probabilistic Model. (arXiv:2206.04514v1 [eess.IV])
15. Face-Dubbing++: Lip-Synchronous, Voice Preserving Translation of Videos. (arXiv:2206.04523v1 [cs.CL])
16. Classification of COVID-19 in Chest X-ray Images Using Fusion of Deep Features and LightGBM. (arXiv:2206.04548v1 [eess.IV])
17. VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
18. Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks in Highly Accelerated MRI. (arXiv:2008.06029v2 [eess.IV] UPDATED)
19. Coupling BM3D with directional wavelet packets for image denoising. (arXiv:2008.11595v2 [eess.IV] UPDATED)
20. Explaining Clinical Decision Support Systems in Medical Imaging using Cycle-Consistent Activation Maximization. (arXiv:2010.05759v3 [eess.IV] UPDATED)
21. A Probabilistic Bayesian Approach to Recover $R_2^*$ map and Phase Images for Quantitative Susceptibility Mapping. (arXiv:2103.05535v2 [eess.IV] UPDATED)
22. Zero-Shot Domain Adaptation in CT Segmentation by Filtered Back Projection Augmentation. (arXiv:2107.08543v4 [eess.IV] UPDATED)
23. Venc Design and Velocity Estimation for Phase Contrast MRI. (arXiv:2109.12481v3 [eess.IV] UPDATED)
24. An Educated Warm Start For Deep Image Prior-Based Micro CT Reconstruction. (arXiv:2111.11926v2 [eess.IV] UPDATED)
25. ADG-Pose: Automated Dataset Generation for Real-World Human Pose Estimation. (arXiv:2202.00753v2 [cs.CV] UPDATED)
26. What Makes Transfer Learning Work For Medical Images: Feature Reuse & Other Factors. (arXiv:2203.01825v2 [cs.LG] UPDATED)
27. EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain Extraction. (arXiv:2206.02837v2 [eess.IV] UPDATED)
28. Hypernetwork-based Personalized Federated Learning for Multi-Institutional CT Imaging. (arXiv:2206.03709v2 [eess.IV] UPDATED)
29. Dual-Distribution Discrepancy for Anomaly Detection in Chest X-Rays. (arXiv:2206.03935v2 [eess.IV] UPDATED)
30. Physically Inspired Constraint for Unsupervised Regularized Ultrasound Elastography. (arXiv:2206.02225v1 [eess.IV] CROSS LISTED)
## cs.LG
---
**196** new papers in cs.LG:-) 
1. N-ACT: An Interpretable Deep Learning Model for Automatic Cell Type and Salient Gene Identification. (arXiv:2206.04047v1 [q-bio.GN])
2. Balanced background and explanation data are needed in explaining deep learning models with SHAP: An empirical study on clinical decision making. (arXiv:2206.04050v1 [cs.LG])
3. Unsupervised Knowledge Adaptation for Passenger Demand Forecasting. (arXiv:2206.04053v1 [cs.LG])
4. Gradient Obfuscation Gives a False Sense of Security in Federated Learning. (arXiv:2206.04055v1 [cs.CR])
5. Hidden Markov Models with Momentum. (arXiv:2206.04057v1 [cs.LG])
6. Uplifting Bandits. (arXiv:2206.04091v1 [stat.ML])
7. What-Is and How-To for Fairness in Machine Learning: A Survey, Reflection, and Perspective. (arXiv:2206.04101v1 [cs.LG])
8. Words are all you need? Capturing human sensory similarity with textual descriptors. (arXiv:2206.04105v1 [cs.CL])
9. Likelihood-free Model Choice for Simulator-based Models with the Jensen--Shannon Divergence. (arXiv:2206.04110v1 [stat.ME])
10. Push--Pull with Device Sampling. (arXiv:2206.04113v1 [math.OC])
11. Deep Hierarchical Planning from Pixels. (arXiv:2206.04114v1 [cs.AI])
12. Simplifying Polylogarithms with Machine Learning. (arXiv:2206.04115v1 [cs.LG])
13. Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem. (arXiv:2206.04119v1 [q-bio.BM])
14. ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret. (arXiv:2206.04122v1 [cs.GT])
15. TreeFlow: Going beyond Tree-based Gaussian Probabilistic Regression. (arXiv:2206.04140v1 [cs.LG])
16. A Comprehensive Survey of Graph-based Deep Learning Approaches for Anomaly Detection in Complex Distributed Systems. (arXiv:2206.04149v1 [cs.LG])
17. Ensembling Framework for Texture Extraction Techniques for Classification. (arXiv:2206.04158v1 [cs.CV])
18. Alternating Mirror Descent for Constrained Min-Max Games. (arXiv:2206.04160v1 [cs.GT])
19. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v1 [cs.CV])
20. On Gradient Descent Convergence beyond the Edge of Stability. (arXiv:2206.04172v1 [cs.LG])
21. VN-Transformer: Rotation-Equivariant Attention for Vector Neurons. (arXiv:2206.04176v1 [cs.CV])
22. Learning in Distributed Contextual Linear Bandits Without Sharing the Context. (arXiv:2206.04180v1 [cs.LG])
23. Reinforced Inverse Scattering. (arXiv:2206.04186v1 [cs.LG])
24. CCP: Correlated Clustering and Projection for Dimensionality Reduction. (arXiv:2206.04189v1 [stat.ML])
25. ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion. (arXiv:2206.04192v1 [cs.LG])
26. Exploring Predictive States via Cantor Embeddings and Wasserstein Distance. (arXiv:2206.04198v1 [cond-mat.stat-mech])
27. Deep Surrogate Assisted Generation of Environments. (arXiv:2206.04199v1 [cs.AI])
28. It's a super deal -- train recurrent network on noisy data and get smooth prediction free. (arXiv:2206.04215v1 [cs.LG])
29. Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link Prediction. (arXiv:2206.04216v1 [cs.LG])
30. GCVAE: Generalized-Controllable Variational AutoEncoder. (arXiv:2206.04225v1 [stat.ML])
31. Analytical Composition of Differential Privacy via the Edgeworth Accountant. (arXiv:2206.04236v1 [cs.CR])
32. **Enhancement** of Healthcare Data Transmission using the Levenberg-Marquardt Algorithm. (arXiv:2206.04240v1 [cs.LG])
33. An Optimization Method-Assisted Ensemble Deep Reinforcement Learning Algorithm to Solve Unit Commitment Problems. (arXiv:2206.04249v1 [eess.SY])
34. ScatterSample: Diversified Label Sampling for Data Efficient Graph Neural Network Learning. (arXiv:2206.04255v1 [cs.LG])
35. There is no Accuracy-Interpretability Tradeoff in Reinforcement Learning for Mazes. (arXiv:2206.04266v1 [cs.LG])
36. A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis. (arXiv:2206.04270v1 [cs.LG])
37. Robust Matrix Completion with Heavy-tailed Noise. (arXiv:2206.04276v1 [math.ST])
38. On Transfer Learning in Functional Linear Regression. (arXiv:2206.04277v1 [stat.ML])
39. Local Spatiotemporal Representation Learning for Longitudinally-consistent Neuroimage Analysis. (arXiv:2206.04281v1 [cs.CV])
40. Sample-Efficient Reinforcement Learning in the Presence of Exogenous Information. (arXiv:2206.04282v1 [cs.LG])
41. Pseudo-Poincar\'e: A Unification Framework for Euclidean and Hyperbolic Graph Neural Networks. (arXiv:2206.04285v1 [cs.LG])
42. Evaluating Aleatoric Uncertainty via Conditional Generative Models. (arXiv:2206.04287v1 [cs.LG])
43. OptWedge: Cognitive Optimized Guidance toward Off-screen POIs. (arXiv:2206.04293v1 [cs.HC])
44. Unveiling Transformers with LEGO: a synthetic reasoning task. (arXiv:2206.04301v1 [cs.LG])
45. GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing. (arXiv:2206.04310v1 [cs.LG])
46. Multi-class Classification with Fuzzy-feature Observations: Theory and Algorithms. (arXiv:2206.04311v1 [cs.LG])
47. Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks. (arXiv:2206.04316v1 [cs.LG])
48. CFA: Coupled-hypersphere-based Feature Adaptation for Target-Oriented Anomaly Localization. (arXiv:2206.04325v1 [cs.CV])
49. Learning to generate imaginary tasks for improving generalization in meta-learning. (arXiv:2206.04335v1 [cs.LG])
50. Graph Attention Multi-Layer Perceptron. (arXiv:2206.04355v1 [cs.LG])
51. A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data. (arXiv:2206.04356v1 [stat.ML])
52. Trajectory-dependent Generalization Bounds for Deep Neural Networks via Fractional Brownian Motion. (arXiv:2206.04359v1 [cs.LG])
53. A general approximation lower bound in $L^p$ norm, with applications to feed-forward neural networks. (arXiv:2206.04360v1 [cs.LG])
54. Model Degradation Hinders Deep Graph Neural Networks. (arXiv:2206.04361v1 [cs.LG])
55. Diagnosing Ensemble Few-Shot Classifiers. (arXiv:2206.04372v1 [cs.LG])
56. Uncovering bias in the PlantVillage dataset. (arXiv:2206.04374v1 [cs.CV])
57. Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning. (arXiv:2206.04384v1 [cs.LG])
58. HideNseek: Federated Lottery Ticket via Server-side Pruning and Sign Supermask. (arXiv:2206.04385v1 [cs.LG])
59. Xplique: A Deep Learning Explainability Toolbox. (arXiv:2206.04394v1 [cs.LG])
60. Depression Recognition using Remote Photoplethysmography from Facial Videos. (arXiv:2206.04399v1 [cs.CV])
61. Conformal Off-Policy Prediction in Contextual Bandits. (arXiv:2206.04405v1 [stat.ML])
62. Unsupervised Learning of the Total Variation Flow. (arXiv:2206.04406v1 [cs.CV])
63. Neonatal EEG graded for severity of background abnormalities in hypoxic-ischaemic encephalopathy. (arXiv:2206.04420v1 [physics.med-ph])
64. Learning to generalize Dispatching rules on the Job Shop Scheduling. (arXiv:2206.04423v1 [cs.LG])
65. Discriminative and Generative Learning for Linear Estimation of Random Signals [Lecture Notes]. (arXiv:2206.04432v1 [eess.SP])
66. Regret Analysis of Certainty Equivalence Policies in Continuous-Time Linear-Quadratic Systems. (arXiv:2206.04434v1 [cs.LG])
67. Towards Safe Reinforcement Learning via Constraining Conditional Value-at-Risk. (arXiv:2206.04436v1 [cs.LG])
68. Convolutional Dictionary Learning by End-To-End Training of Iterative Neural Networks. (arXiv:2206.04447v1 [eess.IV])
69. Draft-and-Revise: Effective Image Generation with Contextual RQ-Transformer. (arXiv:2206.04452v1 [cs.CV])
70. Choosing Answers in $\varepsilon$-Best-Answer Identification for Linear Bandits. (arXiv:2206.04456v1 [stat.ML])
71. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v1 [cs.LG])
72. Meet You Halfway: Explaining Deep Learning Mysteries. (arXiv:2206.04463v1 [cs.LG])
73. Towards Understanding Graph Neural Networks: An Algorithm Unrolling Perspective. (arXiv:2206.04471v1 [cs.LG])
74. Early Transferability of Adversarial Examples in Deep Neural Networks. (arXiv:2206.04472v1 [cs.LG])
75. Individually Fair Learning with One-Sided Feedback. (arXiv:2206.04475v1 [cs.LG])
76. Receding Horizon Inverse Reinforcement Learning. (arXiv:2206.04477v1 [cs.LG])
77. Data-Efficient Brain Connectome Analysis via Multi-Task Meta-Learning. (arXiv:2206.04486v1 [cs.LG])
78. Redundancy in Deep Linear Neural Networks. (arXiv:2206.04490v1 [cs.LG])
79. Mitigating Modality Collapse in Multimodal VAEs via Impartial Optimization. (arXiv:2206.04496v1 [cs.LG])
80. Unlearning Protected User Attributes in Recommendations with Adversarial Training. (arXiv:2206.04500v1 [cs.IR])
81. What is a Good Metric to Study Generalization of Minimax Learners?. (arXiv:2206.04502v1 [stat.ML])
82. Accurate Node Feature Estimation with Structured Variational Graph Autoencoder. (arXiv:2206.04516v1 [cs.LG])
83. An FPGA-based Solution for Convolution Operation Acceleration. (arXiv:2206.04520v1 [cs.AR])
84. DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v1 [cs.LG])
85. ECLAD: Extracting Concepts with Local Aggregated Descriptors. (arXiv:2206.04531v1 [cs.CV])
86. Pragmatically Learning from Pedagogical Demonstrations in Multi-Goal Environments. (arXiv:2206.04546v1 [cs.LG])
87. A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning. (arXiv:2206.04551v1 [cs.LG])
88. Benefits of Overparameterized Convolutional Residual Networks: Function Approximation under Smoothness Constraint. (arXiv:2206.04569v1 [stat.ML])
89. Revisiting End-to-End Speech-to-Text Translation From Scratch. (arXiv:2206.04571v1 [cs.CL])
90. Simple lessons from complex learning: what a neural network model learns about cosmic structure formation. (arXiv:2206.04573v1 [astro-ph.CO])
91. Transformer based Urdu Handwritten Text Optical Character Reader. (arXiv:2206.04575v1 [cs.CV])
92. Clustering with Queries under Semi-Random Noise. (arXiv:2206.04583v1 [cs.LG])
93. Optimal SQ Lower Bounds for Robustly Learning Discrete Product Distributions and Ising Models. (arXiv:2206.04589v1 [cs.DS])
94. Privacy Leakage in Text Classification: A Data Extraction Approach. (arXiv:2206.04591v1 [cs.CL])
95. Field Level Neural Network Emulator for Cosmological N-body Simulations. (arXiv:2206.04594v1 [astro-ph.CO])
96. On Margins and Generalisation for Voting Classifiers. (arXiv:2206.04607v1 [cs.LG])
97. Explicit Regularization in Overparametrized Models via Noise Injection. (arXiv:2206.04613v1 [cs.LG])
98. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v1 [cs.CL])
99. On the Generalization and Adaption Performance of Causal Models. (arXiv:2206.04620v1 [cs.LG])
100. A Critical Review on the Use (and Misuse) of Differential Privacy in Machine Learning. (arXiv:2206.04621v1 [cs.CR])
101. Factuality Enhanced Language Models for Open-Ended Text Generation. (arXiv:2206.04624v1 [cs.CL])
102. AttX: Attentive Cross-Connections for Fusion of Wearable Signals in Emotion Recognition. (arXiv:2206.04625v1 [cs.LG])
103. Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations. (arXiv:2206.04632v1 [cs.RO])
104. Spatial Entropy Regularization for Vision Transformers. (arXiv:2206.04636v1 [cs.CV])
105. Regret Bounds for Information-Directed Reinforcement Learning. (arXiv:2206.04640v1 [cs.LG])
106. Probability flow solution of the Fokker-Planck equation. (arXiv:2206.04642v1 [cs.LG])
107. Globally Optimal Algorithms for Fixed-Budged Best Arm Identification. (arXiv:2206.04646v1 [stat.ML])
108. VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution. (arXiv:2206.04647v1 [eess.IV])
109. BigVGAN: A Universal Neural Vocoder with Large-Scale Training. (arXiv:2206.04658v1 [cs.SD])
110. Distillation Decision Tree. (arXiv:2206.04661v1 [stat.ME])
111. DiSparse: Disentangled Sparsification for Multitask Model Compression. (arXiv:2206.04662v1 [cs.CV])
112. Overcoming the Spectral Bias of Neural Value Approximation. (arXiv:2206.04672v1 [cs.LG])
113. Neural Prompt Search. (arXiv:2206.04673v1 [cs.CV])
114. Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent. (arXiv:2002.04861v3 [stat.ML] UPDATED)
115. Blacklight: Scalable Defense for Neural Networks against Query-Based Black-Box Attacks. (arXiv:2006.14042v3 [cs.CR] UPDATED)
116. The Interpolation Phase Transition in Neural Networks: Memorization and Generalization under Lazy Training. (arXiv:2007.12826v3 [stat.ML] UPDATED)
117. Multi-Mask Self-Supervised Learning for Physics-Guided Neural Networks in Highly Accelerated MRI. (arXiv:2008.06029v2 [eess.IV] UPDATED)
118. Wireless for Machine Learning. (arXiv:2008.13492v3 [eess.SP] UPDATED)
119. Denoising Diffusion Implicit Models. (arXiv:2010.02502v3 [cs.LG] UPDATED)
120. Explaining Clinical Decision Support Systems in Medical Imaging using Cycle-Consistent Activation Maximization. (arXiv:2010.05759v3 [eess.IV] UPDATED)
121. Objective-Based Hierarchical Clustering of Deep Embedding Vectors. (arXiv:2012.08466v2 [cs.LG] UPDATED)
122. Fast Hierarchical Games for Image Explanations. (arXiv:2104.06164v2 [cs.CV] UPDATED)
123. Network insensitivity to parameter noise via adversarial regularization. (arXiv:2106.05009v3 [cs.LG] UPDATED)
124. Generalization and Robustness Implications in Object-Centric Learning. (arXiv:2107.00637v3 [cs.LG] UPDATED)
125. Strategic Instrumental Variable Regression: Recovering Causal Relationships From Strategic Responses. (arXiv:2107.05762v3 [cs.LG] UPDATED)
126. Responsible and Regulatory Conform Machine Learning for Medicine: A Survey of Challenges and Solutions. (arXiv:2107.09546v2 [cs.LG] UPDATED)
127. ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v3 [cs.CV] UPDATED)
128. Time Delay Estimation of Traffic Congestion Propagation based on Transfer Entropy. (arXiv:2108.06717v2 [stat.ML] UPDATED)
129. Graph Attention MLP with Reliable Label Utilization. (arXiv:2108.10097v3 [cs.LG] UPDATED)
130. MEDIC: A Multi-Task Learning Dataset for Disaster Image Classification. (arXiv:2108.12828v4 [cs.CV] UPDATED)
131. Variational Physics Informed Neural Networks: the role of quadratures and test functions. (arXiv:2109.02035v2 [math.NA] UPDATED)
132. Robust Inverse Framework using Knowledge-guided Self-Supervised Learning: An application to Hydrology. (arXiv:2109.06429v2 [cs.LG] UPDATED)
133. Boosting Fast Adversarial Training with Learnable Adversarial Initialization. (arXiv:2110.05007v2 [cs.CV] UPDATED)
134. On the Parameter Combinations That Matter and on Those That do Not. (arXiv:2110.06717v2 [cs.LG] UPDATED)
135. TAG: Toward Accurate Social Media Content Tagging with a Concept Graph. (arXiv:2110.06892v3 [cs.LG] UPDATED)
136. RoMA: a Method for Neural Network Robustness Measurement and Assessment. (arXiv:2110.11088v4 [cs.LG] UPDATED)
137. Vector Optimization with Stochastic Bandit Feedback. (arXiv:2110.12311v3 [cs.LG] UPDATED)
138. Multivariate feature ranking of gene expression data. (arXiv:2111.02357v4 [cs.LG] UPDATED)
139. Learning to Break Deep Perceptual Hashing: The Use Case NeuralHash. (arXiv:2111.06628v4 [cs.LG] UPDATED)
140. Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning via Clairvoyant Multiplicative Weights Update. (arXiv:2111.14737v3 [cs.GT] UPDATED)
141. Learning Invariant Representations with Missing Data. (arXiv:2112.00881v2 [cs.LG] UPDATED)
142. Multi-task Self-distillation for Graph-based Semi-Supervised Learning. (arXiv:2112.01174v2 [cs.LG] UPDATED)
143. Estimation in Rotationally Invariant Generalized Linear Models via Approximate Message Passing. (arXiv:2112.04330v2 [stat.ML] UPDATED)
144. Multi-modal Attention Network for Stock Movements Prediction. (arXiv:2112.13593v3 [cs.LG] UPDATED)
145. FogAdapt: Self-Supervised Domain Adaptation for Semantic Segmentation of Foggy Images. (arXiv:2201.02588v3 [cs.CV] UPDATED)
146. RecoMed: A Knowledge-Aware Recommender System for Hypertension Medications. (arXiv:2201.05461v2 [cs.IR] UPDATED)
147. Contrastive Regularization for Semi-Supervised Learning. (arXiv:2201.06247v2 [cs.LG] UPDATED)
148. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v3 [cs.CV] UPDATED)
149. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v4 [cs.LG] UPDATED)
150. Bounding Training Data Reconstruction in Private (Deep) Learning. (arXiv:2201.12383v3 [cs.LG] UPDATED)
151. Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval. (arXiv:2201.12431v2 [cs.CL] UPDATED)
152. ADG-Pose: Automated Dataset Generation for Real-World Human Pose Estimation. (arXiv:2202.00753v2 [cs.CV] UPDATED)
153. Generative Flow Networks for Discrete Probabilistic Modeling. (arXiv:2202.01361v2 [cs.LG] UPDATED)
154. Improved Differential Privacy for SGD via Optimal Private Linear Operators on Adaptive Streams. (arXiv:2202.08312v2 [cs.LG] UPDATED)
155. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v5 [cs.CV] UPDATED)
156. Study of Feature Importance for Quantum Machine Learning Models. (arXiv:2202.11204v4 [quant-ph] UPDATED)
157. What Makes Transfer Learning Work For Medical Images: Feature Reuse & Other Factors. (arXiv:2203.01825v2 [cs.LG] UPDATED)
158. Label-Free Explainability for Unsupervised Models. (arXiv:2203.01928v3 [cs.LG] UPDATED)
159. Evaluating State of the Art, Forecasting Ensembles- and Meta-learning Strategies for Model Fusion. (arXiv:2203.03279v2 [cs.LG] UPDATED)
160. Privacy-Aware Compression for Federated Data Analysis. (arXiv:2203.08134v2 [cs.LG] UPDATED)
161. Unsupervised Pre-Training on Patient Population Graphs for Patient-Level Predictions. (arXiv:2203.12616v2 [cs.LG] UPDATED)
162. Automatic Debiased Machine Learning for Dynamic Treatment Effects and General Nested Functionals. (arXiv:2203.13887v3 [econ.EM] UPDATED)
163. Socially Compliant Navigation Dataset (SCAND): A Large-Scale Dataset of Demonstrations for Social Navigation. (arXiv:2203.15041v2 [cs.RO] UPDATED)
164. TubeDETR: Spatio-Temporal Video Grounding with Transformers. (arXiv:2203.16434v2 [cs.CV] UPDATED)
165. Understanding the unstable convergence of gradient descent. (arXiv:2204.01050v2 [math.OC] UPDATED)
166. PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v2 [stat.ML] UPDATED)
167. Russian Texts Detoxification with Levenshtein Editing. (arXiv:2204.13638v2 [cs.CL] UPDATED)
168. Physics-aware Reduced-order Modeling of Transonic Flow via $\beta$-Variational Autoencoder. (arXiv:2205.00608v2 [physics.flu-dyn] UPDATED)
169. Original or Translated? A Causal Analysis of the Impact of Translationese on Machine Translation Performance. (arXiv:2205.02293v3 [cs.CL] UPDATED)
170. Learning Multitask Gaussian Bayesian Networks. (arXiv:2205.05343v2 [stat.ML] UPDATED)
171. Collaborative Drug Discovery: Inference-level Data Protection Perspective. (arXiv:2205.06506v2 [cs.CR] UPDATED)
172. SQ-VAE: Variational Bayes on Discrete Representation with Self-annealed Stochastic Quantization. (arXiv:2205.07547v2 [cs.LG] UPDATED)
173. A Psychological Theory of Explainability. (arXiv:2205.08452v2 [cs.AI] UPDATED)
174. The Sufficiency of Off-policyness: PPO is insufficient according to an Off-policy Measure. (arXiv:2205.10047v3 [cs.LG] UPDATED)
175. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v2 [cs.LG] UPDATED)
176. Contextual Information-Directed Sampling. (arXiv:2205.10895v2 [cs.LG] UPDATED)
177. Deep Representations for Time-varying Brain Datasets. (arXiv:2205.11648v2 [cs.LG] UPDATED)
178. Large Language Models are Zero-Shot Reasoners. (arXiv:2205.11916v2 [cs.CL] UPDATED)
179. Aggregating Gradients in Encoded Domain for Federated Learning. (arXiv:2205.13216v2 [cs.CR] UPDATED)
180. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v3 [cs.LG] UPDATED)
181. Hilbert Curve Projection Distance for Distribution Comparison. (arXiv:2205.15059v2 [cs.LG] UPDATED)
182. FELARE: Fair Scheduling of Machine Learning Applications on Heterogeneous Edge Systems. (arXiv:2206.00065v2 [cs.DC] UPDATED)
183. The Phenomenon of Policy Churn. (arXiv:2206.00730v2 [cs.LG] UPDATED)
184. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v3 [cs.LG] UPDATED)
185. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v2 [cs.CV] UPDATED)
186. Markovian Interference in Experiments. (arXiv:2206.02371v2 [cs.LG] UPDATED)
187. Recall Distortion in Neural Network Pruning and the Undecayed Pruning Algorithm. (arXiv:2206.02976v2 [cs.LG] UPDATED)
188. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v2 [cs.CV] UPDATED)
189. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v2 [cs.CV] UPDATED)
190. Toward Certified Robustness Against Real-World Distribution Shifts. (arXiv:2206.03669v2 [cs.LG] UPDATED)
191. Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks. (arXiv:2206.03826v2 [cs.LG] UPDATED)
192. Few-shot Prompting Towards Controllable Response Generation. (arXiv:2206.03931v2 [cs.CL] UPDATED)
193. Accelerating Score-based Generative Models for High-Resolution Image Synthesis. (arXiv:2206.04029v2 [cs.CV] UPDATED)
194. Quick survey of graph-based fraud detection methods. (arXiv:1910.11299v3 [cs.LG] CROSS LISTED)
195. Community-Level Anomaly Detection for Anti-Money Laundering. (arXiv:1910.11313v1 [cs.LG] CROSS LISTED)
196. Unsupervised Dictionary Learning for Anomaly Detection. (arXiv:2003.00293v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**84** new papers in cs.AI:-) 
1. N-ACT: An Interpretable Deep Learning Model for Automatic Cell Type and Salient Gene Identification. (arXiv:2206.04047v1 [q-bio.GN])
2. Unsupervised Knowledge Adaptation for Passenger Demand Forecasting. (arXiv:2206.04053v1 [cs.LG])
3. Gradient Obfuscation Gives a False Sense of Security in Federated Learning. (arXiv:2206.04055v1 [cs.CR])
4. Deep Hierarchical Planning from Pixels. (arXiv:2206.04114v1 [cs.AI])
5. ESCHER: Eschewing Importance Sampling in Games by Computing a History Value Function to Estimate Regret. (arXiv:2206.04122v1 [cs.GT])
6. Deep Estimation of Speckle Statistics Parametric Images. (arXiv:2206.04145v1 [eess.IV])
7. Ensembling Framework for Texture Extraction Techniques for Classification. (arXiv:2206.04158v1 [cs.CV])
8. Improved two-stage hate speech classification for twitter based on Deep Neural Networks. (arXiv:2206.04162v1 [cs.CL])
9. Planning with Dynamically Estimated Action Costs. (arXiv:2206.04166v1 [cs.AI])
10. CASS: Cross Architectural Self-Supervision for Medical Image Analysis. (arXiv:2206.04170v1 [cs.CV])
11. ExpressivE: A Spatio-Functional Embedding For Knowledge Graph Completion. (arXiv:2206.04192v1 [cs.LG])
12. SCAMPS: Synthetics for Camera Measurement of Physiological Signals. (arXiv:2206.04197v1 [cs.CV])
13. Deep Surrogate Assisted Generation of Environments. (arXiv:2206.04199v1 [cs.AI])
14. Neo-GNNs: Neighborhood Overlap-aware Graph Neural Networks for Link Prediction. (arXiv:2206.04216v1 [cs.LG])
15. CLTS+: A New Chinese Long Text Summarization Dataset with Abstractive Summaries. (arXiv:2206.04253v1 [cs.CL])
16. Smart System: Joint Utility and Frequency for Pattern Classification. (arXiv:2206.04269v1 [cs.AI])
17. Unveiling Transformers with LEGO: a synthetic reasoning task. (arXiv:2206.04301v1 [cs.LG])
18. GSmooth: Certified Robustness against Semantic Transformations via Generalized Randomized Smoothing. (arXiv:2206.04310v1 [cs.LG])
19. Adversarial Noises Are Linearly Separable for (Nearly) Random Neural Networks. (arXiv:2206.04316v1 [cs.LG])
20. Negative Shannon Information Hides Networks. (arXiv:2206.04320v1 [quant-ph])
21. Deep radiomic signature with immune cell markers predicts the survival of glioma patients. (arXiv:2206.04349v1 [cs.CV])
22. Graph Attention Multi-Layer Perceptron. (arXiv:2206.04355v1 [cs.LG])
23. Trajectory-dependent Generalization Bounds for Deep Neural Networks via Fractional Brownian Motion. (arXiv:2206.04359v1 [cs.LG])
24. STIP: A SpatioTemporal Information-Preserving and Perception-Augmented Model for High-Resolution Video Prediction. (arXiv:2206.04381v1 [cs.CV])
25. CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes. (arXiv:2206.04382v1 [cs.CV])
26. Value Memory Graph: A Graph-Structured World Model for Offline Reinforcement Learning. (arXiv:2206.04384v1 [cs.LG])
27. Xplique: A Deep Learning Explainability Toolbox. (arXiv:2206.04394v1 [cs.LG])
28. Learning to generalize Dispatching rules on the Job Shop Scheduling. (arXiv:2206.04423v1 [cs.LG])
29. Towards Safe Reinforcement Learning via Constraining Conditional Value-at-Risk. (arXiv:2206.04436v1 [cs.LG])
30. A taxonomy of explanations to support Explainability-by-Design. (arXiv:2206.04438v1 [cs.AI])
31. Dict-NMT: Bilingual Dictionary based NMT for Extremely Low Resource Languages. (arXiv:2206.04439v1 [cs.CL])
32. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v1 [cs.LG])
33. Open ERP System Data For Occupational Fraud Detection. (arXiv:2206.04460v1 [cs.AI])
34. Receding Horizon Inverse Reinforcement Learning. (arXiv:2206.04477v1 [cs.LG])
35. Unlearning Protected User Attributes in Recommendations with Adversarial Training. (arXiv:2206.04500v1 [cs.IR])
36. cycle text2face: cycle text-to-face gan via transformers. (arXiv:2206.04503v1 [cs.CV])
37. AAM-Gym: Artificial Intelligence Testbed for Advanced Air Mobility. (arXiv:2206.04513v1 [cs.AI])
38. An FPGA-based Solution for Convolution Operation Acceleration. (arXiv:2206.04520v1 [cs.AR])
39. DORA: Exploring outlier representations in Deep Neural Networks. (arXiv:2206.04530v1 [cs.LG])
40. ECLAD: Extracting Concepts with Local Aggregated Descriptors. (arXiv:2206.04531v1 [cs.CV])
41. A Relational Intervention Approach for Unsupervised Dynamics Generalization in Model-Based Reinforcement Learning. (arXiv:2206.04551v1 [cs.LG])
42. BFS-Net: Weakly Supervised Cell Instance Segmentation from Bright-Field Microscopy Z-Stacks. (arXiv:2206.04558v1 [cs.CV])
43. Functional Code Building Genetic Programming. (arXiv:2206.04561v1 [cs.AI])
44. TwiBot-22: Towards Graph-Based Twitter Bot Detection. (arXiv:2206.04564v1 [cs.SI])
45. Transformer based Urdu Handwritten Text Optical Character Reader. (arXiv:2206.04575v1 [cs.CV])
46. GASP: Gated Attention For Saliency Prediction. (arXiv:2206.04590v1 [cs.CV])
47. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. (arXiv:2206.04615v1 [cs.CL])
48. On the Generalization and Adaption Performance of Causal Models. (arXiv:2206.04620v1 [cs.LG])
49. Factuality Enhanced Language Models for Open-Ended Text Generation. (arXiv:2206.04624v1 [cs.CL])
50. Temporal Logic Imitation: Learning Plan-Satisficing Motion Policies from Demonstrations. (arXiv:2206.04632v1 [cs.RO])
51. Jewelry Shop Conversational Chatbot. (arXiv:2206.04659v1 [cs.CL])
52. DiSparse: Disentangled Sparsification for Multitask Model Compression. (arXiv:2206.04662v1 [cs.CV])
53. PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies. (arXiv:2206.04670v1 [cs.CV])
54. Neural Prompt Search. (arXiv:2206.04673v1 [cs.CV])
55. Explaining Clinical Decision Support Systems in Medical Imaging using Cycle-Consistent Activation Maximization. (arXiv:2010.05759v3 [eess.IV] UPDATED)
56. Objective-Based Hierarchical Clustering of Deep Embedding Vectors. (arXiv:2012.08466v2 [cs.LG] UPDATED)
57. Contrastive Counterfactual Visual Explanations With Overdetermination. (arXiv:2106.14556v3 [cs.CV] UPDATED)
58. AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with Incomplete Annotations. (arXiv:2109.05233v2 [cs.CL] UPDATED)
59. TAG: Toward Accurate Social Media Content Tagging with a Concept Graph. (arXiv:2110.06892v3 [cs.LG] UPDATED)
60. RoMA: a Method for Neural Network Robustness Measurement and Assessment. (arXiv:2110.11088v4 [cs.LG] UPDATED)
61. Multivariate feature ranking of gene expression data. (arXiv:2111.02357v4 [cs.LG] UPDATED)
62. Multi-Objective Optimization for Value-Sensitive and Sustainable Basket Recommendations. (arXiv:2111.05944v2 [cs.NE] UPDATED)
63. Beyond Time-Average Convergence: Near-Optimal Uncoupled Online Learning via Clairvoyant Multiplicative Weights Update. (arXiv:2111.14737v3 [cs.GT] UPDATED)
64. The CLEAR Benchmark: Continual LEArning on Real-World Imagery. (arXiv:2201.06289v3 [cs.CV] UPDATED)
65. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v4 [cs.LG] UPDATED)
66. Multi-view Intent Disentangle Graph Networks for Bundle Recommendation. (arXiv:2202.11425v2 [cs.IR] UPDATED)
67. Recovery of Missing Sensor Data by Reconstructing Time-varying Graph Signals. (arXiv:2203.00418v2 [eess.SP] UPDATED)
68. Label-Free Explainability for Unsupervised Models. (arXiv:2203.01928v3 [cs.LG] UPDATED)
69. Evaluating State of the Art, Forecasting Ensembles- and Meta-learning Strategies for Model Fusion. (arXiv:2203.03279v2 [cs.LG] UPDATED)
70. Knowledge-based Entity Prediction for Improved Machine Perception in Autonomous Systems. (arXiv:2203.16616v3 [cs.AI] UPDATED)
71. Automating Staged Rollout with Reinforcement Learning. (arXiv:2204.02189v2 [cs.SE] UPDATED)
72. Original or Translated? A Causal Analysis of the Impact of Translationese on Machine Translation Performance. (arXiv:2205.02293v3 [cs.CL] UPDATED)
73. A Psychological Theory of Explainability. (arXiv:2205.08452v2 [cs.AI] UPDATED)
74. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v2 [cs.LG] UPDATED)
75. Large Language Models are Zero-Shot Reasoners. (arXiv:2205.11916v2 [cs.CL] UPDATED)
76. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v3 [cs.LG] UPDATED)
77. The Phenomenon of Policy Churn. (arXiv:2206.00730v2 [cs.LG] UPDATED)
78. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v3 [cs.LG] UPDATED)
79. Compositional Visual Generation with Composable Diffusion Models. (arXiv:2206.01714v2 [cs.CV] UPDATED)
80. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v2 [cs.CV] UPDATED)
81. A Penny for Your (visual) Thoughts: Self-Supervised Reconstruction of Natural Movies from Brain Activity. (arXiv:2206.03544v2 [cs.CV] UPDATED)
82. Compromised account detection using authorship verification: a novel approach. (arXiv:2206.03581v2 [cs.CR] UPDATED)
83. Toward Certified Robustness Against Real-World Distribution Shifts. (arXiv:2206.03669v2 [cs.LG] UPDATED)
84. Few-shot Prompting Towards Controllable Response Generation. (arXiv:2206.03931v2 [cs.CL] UPDATED)

