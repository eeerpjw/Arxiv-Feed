# Your interest papers
---
## cs.CV
---
### Casual Indoor **HDR** Radiance Capture from Omnidirectional Images. (arXiv:2208.07903v1 [cs.CV])
- Authors : Pulkit Gera, Mohammad Reza, Karimi Dastjerdi, Charles Renaud, ois Lalonde
- Link : [http://arxiv.org/abs/2208.07903](http://arxiv.org/abs/2208.07903)
> ABSTRACT  :  We present Pano**HDR**-**NeRF**, a novel pipeline to casually capture a plausible full **HDR** radiance field of a large indoor scene without elaborate setups or complex capture protocols. First, a user captures a low dynamic range (LDR) omnidirectional video of the scene by freely waving an off-the-shelf camera around the scene. Then, an LDR2**HDR** network uplifts the captured LDR frames to **HDR**, subsequently used to train a tailored **NeRF**++ model. The resulting Pano**HDR**-**NeRF** pipeline can estimate full **HDR** panoramas from any location of the scene. Through experiments on a novel test dataset of a variety of real scenes with the ground truth **HDR** radiance captured at locations not seen during training, we show that Pano**HDR**-**NeRF** predicts plausible radiance from any scene point. We also show that the **HDR** images produced by Pano**HDR**-**NeRF** can synthesize correct lighting effects, enabling the augmentation of indoor scenes with synthetic objects that are lit correctly.  
### Blind-Spot Collision Detection System for Commercial Vehicles Using Multi Deep CNN Architecture. (arXiv:2208.08224v1 [cs.CV])
- Authors : Muhammad Muzammel, Mohd Zuki, Mohamad Naufal, Mohamad Saad, Faryal Sheikh, Muhammad Ahsan
- Link : [http://arxiv.org/abs/2208.08224](http://arxiv.org/abs/2208.08224)
> ABSTRACT  :  Buses and heavy vehicles have more blind spots compared to cars and other road vehicles due to their large sizes. Therefore, accidents caused by these heavy vehicles are more fatal and result in severe injuries to other road users. These possible blind-spot collisions can be identified early using vision-based object detection approaches. Yet, the existing state-of-the-art vision-based object detection models rely heavily on a single feature descriptor for making decisions. In this research, the design of two convolutional neural networks (CNNs) based on high-level feature descriptors and their integration with faster R-CNN is proposed to detect blind-spot collisions for heavy vehicles. Moreover, a fusion approach is proposed to integrate two pre-trained networks (i.e., Resnet 50 and Resnet 101) for extracting high level features for blind-spot vehicle detection. The fusion of features significantly improves the performance of faster R-CNN and outperformed the existing state-of-the-art methods. Both approaches are validated on a self-recorded blind-spot vehicle detection dataset for buses and an online LISA dataset for vehicle detection. For both proposed approaches, a false detection rate (FDR) of 3.05% and 3.49% are obtained for the self recorded dataset, making these approaches suitable for **real time** applications.  
### On the Privacy Effect of Data **Enhancement** via the Lens of Memorization. (arXiv:2208.08270v1 [cs.LG])
- Authors : Xiao Li, Qiongxiu Li, Zhanhao Hu, Xiaolin Hu
- Link : [http://arxiv.org/abs/2208.08270](http://arxiv.org/abs/2208.08270)
> ABSTRACT  :  Machine learning poses severe privacy concerns as it is shown that the learned models can reveal sensitive information about their training data. Many works have investigated the effect of widely-adopted data augmentation (DA) and adversarial training (AT) techniques, termed data **enhancement** in the paper, on the privacy leakage of machine learning models. Such privacy effects are often measured by membership inference attacks (MIAs), which aim to identify whether a particular example belongs to the training set or not. We propose to investigate privacy from a new perspective called memorization. Through the lens of memorization, we find that previously deployed MIAs produce misleading results as they are less likely to identify samples with higher privacy risks as members compared to samples with low privacy risks. To solve this problem, we deploy a recent attack that can capture the memorization degrees of individual samples for evaluation. Through extensive experiments, we unveil non-trivial findings about the connections between three important properties of machine learning models, including privacy, generalization gap, and adversarial robustness. We demonstrate that, unlike existing results, the generalization gap is shown not highly correlated with privacy leakage. Moreover, stronger adversarial robustness does not necessarily imply that the model is more susceptible to privacy attacks.  
### ParaColorizer: Realistic Image Colorization using Parallel Generative Networks. (arXiv:2208.08295v1 [cs.CV])
- Authors : Himanshu Kumar, Abeer Banerjee, Sumeet Saurav, Sanjay Singh
- Link : [http://arxiv.org/abs/2208.08295](http://arxiv.org/abs/2208.08295)
> ABSTRACT  :  Grayscale image colorization is a fascinating application of AI for information **restoration**. The inherently ill-posed nature of the problem makes it even more challenging since the outputs could be multi-modal. The learning-based methods currently in use produce acceptable results for straightforward cases but usually fail to restore the contextual information in the absence of clear figure-ground separation. Also, the images suffer from color bleeding and desaturated backgrounds since a single model trained on full image features is insufficient for learning the diverse data modes. To address these issues, we present a parallel GAN-based colorization framework. In our approach, each separately tailored GAN pipeline colorizes the foreground (using object-level features) or the background (using full-image features). The foreground pipeline employs a Residual-UNet with self-attention as its generator trained using the full-image features and the corresponding object-level features from the COCO dataset. The background pipeline relies on full-image features and additional training examples from the Places dataset. We design a DenseFuse-based fusion network to obtain the final colorized image by feature-based fusion of the parallelly generated outputs. We show the shortcomings of the non-perceptual evaluation metrics commonly used to assess multi-modal problems like image colorization and perform extensive performance evaluation of our framework using multiple perceptual metrics. Our approach outperforms most of the existing learning-based methods and produces results comparable to the state-of-the-art. Further, we performed a runtime analysis and obtained an average inference time of 24ms per image.  
### Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
- Authors : Sreeraj Ramachandran, Ajita Rattani
- Link : [http://arxiv.org/abs/2208.08382](http://arxiv.org/abs/2208.08382)
> ABSTRACT  :  Published studies have suggested the bias of automated face-based gender classification algorithms across gender-race groups. Specifically, unequal accuracy rates were obtained for women and **dark**-skinned people. To mitigate the bias of gender classifiers, the vision community has developed several strategies. However, the efficacy of these mitigation strategies is demonstrated for a limited number of races mostly, Caucasian and African-American. Further, these strategies often offer a trade-off between bias and classification accuracy. To further advance the state-of-the-art, we leverage the power of generative views, structured learning, and evidential learning towards mitigating gender classification bias. We demonstrate the superiority of our bias mitigation strategy in improving classification accuracy and reducing bias across gender-racial groups through extensive experimental validation, resulting in state-of-the-art performance in intra- and cross dataset evaluations.  
### DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
- Authors : Bo Zhou, Neel Dey, Jo Schlemper, Seyed Sadegh, Mohseni Salehi, Chi Liu, Michal Sofka
- Link : [http://arxiv.org/abs/2201.10776](http://arxiv.org/abs/2201.10776)
> ABSTRACT  :  Multi-contrast MRI (MC-MRI) captures multiple complementary imaging modalities to aid in radiological decision-making. Given the need for lowering the time cost of multiple acquisitions, current deep accelerated MRI reconstruction networks focus on exploiting the redundancy between multiple contrasts. However, existing works are largely supervised with paired data and/or prohibitively expensive fully-sampled MRI sequences. Further, reconstruction networks typically rely on convolutional architectures which are limited in their capacity to model long-range interactions and may lead to suboptimal recovery of fine anatomical detail. To these ends, we present a dual-domain self-supervised transformer (DSFormer) for accelerated MC-MRI reconstruction. DSFormer develops a deep conditional cascade transformer (DCCT) consisting of several cascaded **Swin** transformer reconstruction networks (**Swin**RN) trained under two deep conditioning strategies to enable MC-MRI information sharing. We further present a dual-domain (image and k-space) self-supervised learning strategy for DCCT to alleviate the costs of acquiring fully sampled training data. DSFormer generates high-fidelity reconstructions which experimentally outperform current fully-supervised baselines. Moreover, we find that DSFormer achieves nearly the same performance when trained either with full supervision or with our proposed dual-domain self-supervision.  
### CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution. (arXiv:2207.10345v2 [cs.CV] UPDATED)
- Authors : Cheeun Hong, Sungyong Baik, Heewon Kim, Seungjun Nah, Kyoung Mu
- Link : [http://arxiv.org/abs/2207.10345](http://arxiv.org/abs/2207.10345)
> ABSTRACT  :  Despite breakthrough advances in image super-resolution (SR) with convolutional neural networks (CNNs), SR has yet to enjoy ubiquitous applications due to the high computational complexity of SR networks. Quantization is one of the promising approaches to solve this problem. However, existing methods fail to quantize SR models with a bit-width lower than 8 bits, suffering from severe accuracy loss due to fixed bit-width quantization applied everywhere. In this work, to achieve high average bit-reduction with less accuracy loss, we propose a novel Content-Aware Dynamic Quantization (CADyQ) method for SR networks that allocates optimal bits to local regions and layers adaptively based on the local contents of an input image. To this end, a trainable bit selector module is introduced to determine the proper bit-width and quantization level for each layer and a given local image patch. This module is governed by the quantization sensitivity that is estimated by using both the average magnitude of image gradient of the patch and the standard deviation of the input feature of the layer. The proposed quantization pipeline has been tested on various SR networks and evaluated on several standard benchmarks extensively. Significant reduction in computational complexity and the elevated **restoration** accuracy clearly demonstrate the effectiveness of the proposed CADyQ framework for SR. Codes are available at https://github.com/Cheeun/CADyQ.  
### Towards Local Underexposed Photo **Enhancement**. (arXiv:2208.07711v2 [cs.CV] UPDATED)
- Authors : Yizhan Huang, Xiaogang Xu
- Link : [http://arxiv.org/abs/2208.07711](http://arxiv.org/abs/2208.07711)
> ABSTRACT  :  Inspired by the ability of deep generative models to generate highly realistic images, much recent work has made progress in enhancing underexposed images globally. However, the local image **enhancement** approach has not been explored, although they are requisite in the real-world scenario, e.g., fixing local under**exposure**. In this work, we define a new task setting for underexposed image **enhancement** where users are able to control which region to be enlightened with an input mask. As indicated by the mask, an image can be divided into three areas, including Masked Area A, Transition Area B, and Unmasked Area C. As a result, Area A should be enlightened to the desired lighting, and there shall be a smooth transition (Area B) from the enlightened area (Area A) to the unchanged region (Area C). To finish this task, we propose two methods: Concatenate the mask as additional channels (MConcat), Mask-based Normlization (MNorm). While MConcat simply append the mask channels to the input images, MNorm can dynamically enhance the spatial-varying pixels, guaranteeing the enhanced images are consistent with the requirement indicated by the input mask. Moreover, MConcat serves as a play-and-plug module, and can be incorporated with existing networks, which globally enhance images, to achieve the local **enhancement**. And the overall network can be trained with three kinds of loss functions in Area A, Area B, and Area C, which are unified for various model structures. We perform extensive experiments on public datasets with various parametric approaches for **low-light** **enhancement**, %the Convolutional-Neutral-Network-based model and Transformer-based model, demonstrating the effectiveness of our methods.  
## eess.IV
---
### Blind-Spot Collision Detection System for Commercial Vehicles Using Multi Deep CNN Architecture. (arXiv:2208.08224v1 [cs.CV])
- Authors : Muhammad Muzammel, Mohd Zuki, Mohamad Naufal, Mohamad Saad, Faryal Sheikh, Muhammad Ahsan
- Link : [http://arxiv.org/abs/2208.08224](http://arxiv.org/abs/2208.08224)
> ABSTRACT  :  Buses and heavy vehicles have more blind spots compared to cars and other road vehicles due to their large sizes. Therefore, accidents caused by these heavy vehicles are more fatal and result in severe injuries to other road users. These possible blind-spot collisions can be identified early using vision-based object detection approaches. Yet, the existing state-of-the-art vision-based object detection models rely heavily on a single feature descriptor for making decisions. In this research, the design of two convolutional neural networks (CNNs) based on high-level feature descriptors and their integration with faster R-CNN is proposed to detect blind-spot collisions for heavy vehicles. Moreover, a fusion approach is proposed to integrate two pre-trained networks (i.e., Resnet 50 and Resnet 101) for extracting high level features for blind-spot vehicle detection. The fusion of features significantly improves the performance of faster R-CNN and outperformed the existing state-of-the-art methods. Both approaches are validated on a self-recorded blind-spot vehicle detection dataset for buses and an online LISA dataset for vehicle detection. For both proposed approaches, a false detection rate (FDR) of 3.05% and 3.49% are obtained for the self recorded dataset, making these approaches suitable for **real time** applications.  
### DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
- Authors : Bo Zhou, Neel Dey, Jo Schlemper, Seyed Sadegh, Mohseni Salehi, Chi Liu, Michal Sofka
- Link : [http://arxiv.org/abs/2201.10776](http://arxiv.org/abs/2201.10776)
> ABSTRACT  :  Multi-contrast MRI (MC-MRI) captures multiple complementary imaging modalities to aid in radiological decision-making. Given the need for lowering the time cost of multiple acquisitions, current deep accelerated MRI reconstruction networks focus on exploiting the redundancy between multiple contrasts. However, existing works are largely supervised with paired data and/or prohibitively expensive fully-sampled MRI sequences. Further, reconstruction networks typically rely on convolutional architectures which are limited in their capacity to model long-range interactions and may lead to suboptimal recovery of fine anatomical detail. To these ends, we present a dual-domain self-supervised transformer (DSFormer) for accelerated MC-MRI reconstruction. DSFormer develops a deep conditional cascade transformer (DCCT) consisting of several cascaded **Swin** transformer reconstruction networks (**Swin**RN) trained under two deep conditioning strategies to enable MC-MRI information sharing. We further present a dual-domain (image and k-space) self-supervised learning strategy for DCCT to alleviate the costs of acquiring fully sampled training data. DSFormer generates high-fidelity reconstructions which experimentally outperform current fully-supervised baselines. Moreover, we find that DSFormer achieves nearly the same performance when trained either with full supervision or with our proposed dual-domain self-supervision.  
### CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution. (arXiv:2207.10345v2 [cs.CV] UPDATED)
- Authors : Cheeun Hong, Sungyong Baik, Heewon Kim, Seungjun Nah, Kyoung Mu
- Link : [http://arxiv.org/abs/2207.10345](http://arxiv.org/abs/2207.10345)
> ABSTRACT  :  Despite breakthrough advances in image super-resolution (SR) with convolutional neural networks (CNNs), SR has yet to enjoy ubiquitous applications due to the high computational complexity of SR networks. Quantization is one of the promising approaches to solve this problem. However, existing methods fail to quantize SR models with a bit-width lower than 8 bits, suffering from severe accuracy loss due to fixed bit-width quantization applied everywhere. In this work, to achieve high average bit-reduction with less accuracy loss, we propose a novel Content-Aware Dynamic Quantization (CADyQ) method for SR networks that allocates optimal bits to local regions and layers adaptively based on the local contents of an input image. To this end, a trainable bit selector module is introduced to determine the proper bit-width and quantization level for each layer and a given local image patch. This module is governed by the quantization sensitivity that is estimated by using both the average magnitude of image gradient of the patch and the standard deviation of the input feature of the layer. The proposed quantization pipeline has been tested on various SR networks and evaluated on several standard benchmarks extensively. Significant reduction in computational complexity and the elevated **restoration** accuracy clearly demonstrate the effectiveness of the proposed CADyQ framework for SR. Codes are available at https://github.com/Cheeun/CADyQ.  
## cs.LG
---
### On the Privacy Effect of Data **Enhancement** via the Lens of Memorization. (arXiv:2208.08270v1 [cs.LG])
- Authors : Xiao Li, Qiongxiu Li, Zhanhao Hu, Xiaolin Hu
- Link : [http://arxiv.org/abs/2208.08270](http://arxiv.org/abs/2208.08270)
> ABSTRACT  :  Machine learning poses severe privacy concerns as it is shown that the learned models can reveal sensitive information about their training data. Many works have investigated the effect of widely-adopted data augmentation (DA) and adversarial training (AT) techniques, termed data **enhancement** in the paper, on the privacy leakage of machine learning models. Such privacy effects are often measured by membership inference attacks (MIAs), which aim to identify whether a particular example belongs to the training set or not. We propose to investigate privacy from a new perspective called memorization. Through the lens of memorization, we find that previously deployed MIAs produce misleading results as they are less likely to identify samples with higher privacy risks as members compared to samples with low privacy risks. To solve this problem, we deploy a recent attack that can capture the memorization degrees of individual samples for evaluation. Through extensive experiments, we unveil non-trivial findings about the connections between three important properties of machine learning models, including privacy, generalization gap, and adversarial robustness. We demonstrate that, unlike existing results, the generalization gap is shown not highly correlated with privacy leakage. Moreover, stronger adversarial robustness does not necessarily imply that the model is more susceptible to privacy attacks.  
### Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
- Authors : Sreeraj Ramachandran, Ajita Rattani
- Link : [http://arxiv.org/abs/2208.08382](http://arxiv.org/abs/2208.08382)
> ABSTRACT  :  Published studies have suggested the bias of automated face-based gender classification algorithms across gender-race groups. Specifically, unequal accuracy rates were obtained for women and **dark**-skinned people. To mitigate the bias of gender classifiers, the vision community has developed several strategies. However, the efficacy of these mitigation strategies is demonstrated for a limited number of races mostly, Caucasian and African-American. Further, these strategies often offer a trade-off between bias and classification accuracy. To further advance the state-of-the-art, we leverage the power of generative views, structured learning, and evidential learning towards mitigating gender classification bias. We demonstrate the superiority of our bias mitigation strategy in improving classification accuracy and reducing bias across gender-racial groups through extensive experimental validation, resulting in state-of-the-art performance in intra- and cross dataset evaluations.  
### DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
- Authors : Bo Zhou, Neel Dey, Jo Schlemper, Seyed Sadegh, Mohseni Salehi, Chi Liu, Michal Sofka
- Link : [http://arxiv.org/abs/2201.10776](http://arxiv.org/abs/2201.10776)
> ABSTRACT  :  Multi-contrast MRI (MC-MRI) captures multiple complementary imaging modalities to aid in radiological decision-making. Given the need for lowering the time cost of multiple acquisitions, current deep accelerated MRI reconstruction networks focus on exploiting the redundancy between multiple contrasts. However, existing works are largely supervised with paired data and/or prohibitively expensive fully-sampled MRI sequences. Further, reconstruction networks typically rely on convolutional architectures which are limited in their capacity to model long-range interactions and may lead to suboptimal recovery of fine anatomical detail. To these ends, we present a dual-domain self-supervised transformer (DSFormer) for accelerated MC-MRI reconstruction. DSFormer develops a deep conditional cascade transformer (DCCT) consisting of several cascaded **Swin** transformer reconstruction networks (**Swin**RN) trained under two deep conditioning strategies to enable MC-MRI information sharing. We further present a dual-domain (image and k-space) self-supervised learning strategy for DCCT to alleviate the costs of acquiring fully sampled training data. DSFormer generates high-fidelity reconstructions which experimentally outperform current fully-supervised baselines. Moreover, we find that DSFormer achieves nearly the same performance when trained either with full supervision or with our proposed dual-domain self-supervision.  
### Analysis of Digitalized ECG Signals Based on Artificial Intelligence and Spectral Analysis Methods Specialized in ARVC. (arXiv:2203.00504v2 [eess.SP] UPDATED)
- Authors : Thomas Zegkos, Georgios Efthimiadis, George Tsaklidis
- Link : [http://arxiv.org/abs/2203.00504](http://arxiv.org/abs/2203.00504)
> ABSTRACT  :  Arrhythmogenic right ventricular cardiomyopathy (ARVC) is an inherited heart muscle disease that appears between the second and forth decade of a patient's life, being responsible for 20% of sudden cardiac deaths before the age of 35. The effective and punctual diagnosis of this disease based on Electrocardiograms (ECGs) could have a vital role in reducing premature cardiovascular mortality. In our analysis, we firstly outline the digitalization process of paper - based ECG signals enhanced by a spatial filter aiming to eliminate **dark** regions in the dataset's images that do not correspond to ECG waveform, producing undesirable noise. Next, we propose the utilization of a low - complexity convolutional neural network for the detection of an arrhythmogenic heart disease, that has not been studied through the usage of deep learning methodology to date, achieving high classification accuracy, namely 99.98% training and 98.6% testing accuracy, on a disease the major identification criterion of which are infinitesimal millivolt variations in the ECG's morphology, in contrast with other arrhythmogenic abnormalities. Finally, by performing spectral analysis we investigate significant differentiations in the field of frequencies between normal ECGs and ECGs corresponding to patients suffering from ARVC. In 16 out of the 18 frequencies where we encounter statistically significant differentiations, the normal ECGs are characterized by greater normalized amplitudes compared to the abnormal ones. The overall research carried out in this article highlights the importance of integrating mathematical methods into the examination and effective diagnosis of various diseases, aiming to a substantial contribution to their successful treatment.  
### Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v3 [cs.AI] UPDATED)
- Authors : Ailing Zeng, Muxi Chen, **Lei Zhang**, Qiang Xu
- Link : [http://arxiv.org/abs/2205.13504](http://arxiv.org/abs/2205.13504)
> ABSTRACT  :  Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the \emph{permutation-invariant} self-attention mechanism inevitably results in temporal information loss. To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future. Code is available at: \url{https://github.com/cure-lab/LTSF-Linear}.  
## cs.AI
---
### Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
- Authors : Sreeraj Ramachandran, Ajita Rattani
- Link : [http://arxiv.org/abs/2208.08382](http://arxiv.org/abs/2208.08382)
> ABSTRACT  :  Published studies have suggested the bias of automated face-based gender classification algorithms across gender-race groups. Specifically, unequal accuracy rates were obtained for women and **dark**-skinned people. To mitigate the bias of gender classifiers, the vision community has developed several strategies. However, the efficacy of these mitigation strategies is demonstrated for a limited number of races mostly, Caucasian and African-American. Further, these strategies often offer a trade-off between bias and classification accuracy. To further advance the state-of-the-art, we leverage the power of generative views, structured learning, and evidential learning towards mitigating gender classification bias. We demonstrate the superiority of our bias mitigation strategy in improving classification accuracy and reducing bias across gender-racial groups through extensive experimental validation, resulting in state-of-the-art performance in intra- and cross dataset evaluations.  
### Summarizing Patients Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models. (arXiv:2208.08408v1 [cs.CL])
- Authors : Yanjun Gao, Dmitry Dligach, Timothy Miller, Dongfang Xu, Majid Afshar
- Link : [http://arxiv.org/abs/2208.08408](http://arxiv.org/abs/2208.08408)
> ABSTRACT  :  Automatically summarizing patients' main problems from daily progress notes using natural language processing methods helps to battle against information and cognitive overload in hospital settings and potentially assists providers with computerized diagnostic decision support. Problem list summarization requires a model to understand, abstract, and generate clinical documentation. In this work, we propose a new NLP task that aims to generate a list of problems in a patient's daily care plan using input from the provider's progress notes during hospitalization. We investigate the performance of T5 and BART, two state-of-the-art seq2seq transformer architectures, in solving this problem. We provide a corpus built on top of progress notes from publicly available electronic health record progress notes in the Medical Information Mart for Intensive Care (MIMIC)-III. T5 and BART are trained on general domain text, and we experiment with a data augmentation method and a domain adaptation pre-training method to increase **exposure** to medical vocabulary and knowledge. Evaluation methods include ROUGE, BERTScore, cosine similarity on sentence embedding, and F-score on medical concepts. Results show that T5 with domain adaptive pre-training achieves significant performance gains compared to a rule-based system and general domain pre-trained language models, indicating a promising direction for tackling the problem summarization task.  
### Towards a Better Understanding Human Reading Comprehension with Brain Signals. (arXiv:2108.01360v3 [cs.IR] UPDATED)
- Authors : Ziyi Ye, Xiaohui Xie, Yiqun Liu, Zhihong Wang, Xuesong Chen, Min Zhang, Shaoping Ma
- Link : [http://arxiv.org/abs/2108.01360](http://arxiv.org/abs/2108.01360)
> ABSTRACT  :  Reading comprehension is a complex cognitive process involving many human brain activities. Plenty of works have studied the patterns and attention allocations of reading comprehension in information retrieval related scenarios. However, little is known about what happens in human brain during reading comprehension and how these cognitive activities can affect information retrieval process. Additionally, with the advances in brain imaging techniques such as electroencephalogram (EEG), it is possible to collect brain signals in almost **real time** and explore whether it can be utilized as feedback to facilitate information acquisition performance. In this paper, we carefully design a lab-based user study to investigate brain activities during reading comprehension. Our findings show that neural responses vary with different types of reading contents, i.e., contents that can satisfy users' information needs and contents that cannot. We suggest that various cognitive activities, e.g., cognitive loading, semantic-thematic understanding, and inferential processing, underpin these neural responses at the micro-time scale during reading comprehension. From these findings, we illustrate several insights for information retrieval tasks, such as ranking models construction and interface design. Besides, we suggest the possibility of detecting reading comprehension status for a proactive real-world system. To this end, we propose a Unified framework for EEG-based Reading Comprehension Modeling (UERCM). To verify its effectiveness, we conduct extensive experiments based on EEG features for two reading comprehension tasks: answer sentence classification and answer extraction. Results show that it is feasible to improve the performance of two tasks with brain signals.  
### Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v3 [cs.AI] UPDATED)
- Authors : Ailing Zeng, Muxi Chen, **Lei Zhang**, Qiang Xu
- Link : [http://arxiv.org/abs/2205.13504](http://arxiv.org/abs/2205.13504)
> ABSTRACT  :  Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the \emph{permutation-invariant} self-attention mechanism inevitably results in temporal information loss. To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future. Code is available at: \url{https://github.com/cure-lab/LTSF-Linear}.  
# Paper List
---
## cs.CV
---
**95** new papers in cs.CV:-) 
1. Casual Indoor **HDR** Radiance Capture from Omnidirectional Images. (arXiv:2208.07903v1 [cs.CV])
2. ViT-ReT: Vision and Recurrent Transformer Neural Networks for Human Activity Recognition in Videos. (arXiv:2208.07929v1 [cs.CV])
3. TRoVE: Transforming Road Scene Datasets into Photorealistic Virtual Environments. (arXiv:2208.07943v1 [cs.CV])
4. Blind Users Accessing Their Training Images in Teachable Object Recognizers. (arXiv:2208.07968v1 [cs.HC])
5. Deep Learning Enabled Time-Lapse 3D Cell Analysis. (arXiv:2208.07997v1 [cs.CV])
6. Cross-Domain Few-Shot Classification via Inter-Source Stylization. (arXiv:2208.08015v1 [cs.CV])
7. UniLayout: Taming Unified Sequence-to-Sequence Transformers for Graphic Layout Generation. (arXiv:2208.08037v1 [cs.CV])
8. InterTrack: Interaction Transformer for 3D Multi-Object Tracking. (arXiv:2208.08041v1 [cs.CV])
9. Urban feature analysis from aerial remote sensing imagery using self-supervised and semi-supervised computer vision. (arXiv:2208.08047v1 [cs.CV])
10. REGAS: REspiratory-GAted Synthesis of Views for Multi-Phase CBCT Reconstruction from a single 3D CBCT Acquisition. (arXiv:2208.08048v1 [eess.IV])
11. PDRF: Progressively Deblurring Radiance Field for Fast and Robust Scene Reconstruction from Blurry Images. (arXiv:2208.08049v1 [cs.CV])
12. Imperceptible and Robust Backdoor Attack in 3D Point Cloud. (arXiv:2208.08052v1 [cs.CV])
13. Efficient dynamic point cloud coding using Slice-Wise Segmentation. (arXiv:2208.08061v1 [cs.CV])
14. Significance of Skeleton-based Features in Virtual Try-On. (arXiv:2208.08076v1 [cs.CV])
15. Look in Different Views: Multi-Scheme Regression Guided Cell Instance Segmentation. (arXiv:2208.08078v1 [cs.CV])
16. Multimodal Lecture Presentations Dataset: Understanding Multimodality in Educational Slides. (arXiv:2208.08080v1 [cs.AI])
17. Two Heads are Better than One: Robust Learning Meets Multi-branch Models. (arXiv:2208.08083v1 [cs.CV])
18. AdaBin: Improving Binary Neural Networks with Adaptive Binary Sets. (arXiv:2208.08084v1 [cs.CV])
19. Autonomous Resource Management in Construction Companies Using Deep Reinforcement Learning Based on IoT. (arXiv:2208.08087v1 [cs.LG])
20. Progressive Cross-modal Knowledge Distillation for Human Action Recognition. (arXiv:2208.08090v1 [cs.CV])
21. In-vehicle alertness monitoring for older adults. (arXiv:2208.08091v1 [cs.CV])
22. Paint2Pix: Interactive Painting based Progressive Image Synthesis and Editing. (arXiv:2208.08092v1 [cs.CV])
23. Understanding Attention for Vision-and-Language Tasks. (arXiv:2208.08104v1 [cs.CV])
24. Disentangling Identity and Pose for Facial Expression Recognition. (arXiv:2208.08106v1 [cs.CV])
25. Boosting Modern and Historical Handwritten Text Recognition with Deformable Convolutions. (arXiv:2208.08109v1 [cs.CV])
26. DLCFT: Deep Linear Continual Fine-Tuning for General Incremental Learning. (arXiv:2208.08112v1 [cs.LG])
27. Road detection via a dual-task network based on cross-layer graph fusion modules. (arXiv:2208.08116v1 [cs.CV])
28. Extreme-scale Talking-Face Video Upsampling with Audio-Visual Priors. (arXiv:2208.08118v1 [cs.CV])
29. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v1 [cs.LG])
30. Stereo Superpixel Segmentation Via Decoupled Dynamic Spatial-Embedding Fusion Network. (arXiv:2208.08145v1 [cs.CV])
31. A Monotonicity Constrained Attention Module for Emotion Classification with Limited EEG Data. (arXiv:2208.08155v1 [eess.SP])
32. KAM -- a Kernel Attention Module for Emotion Classification with EEG Data. (arXiv:2208.08161v1 [cs.CV])
33. Towards Open-vocabulary Scene Graph Generation with Prompt-based Finetuning. (arXiv:2208.08165v1 [cs.CV])
34. Data-Efficient Vision Transformers for Multi-Label Disease Classification on Chest Radiographs. (arXiv:2208.08166v1 [cs.CV])
35. DeepSportradar-v1: Computer Vision Dataset for Sports Understanding with High Quality Annotations. (arXiv:2208.08190v1 [cs.CV])
36. Transformer Vs. MLP-Mixer Exponential Expressive Gap For NLP Problems. (arXiv:2208.08191v1 [cs.CL])
37. Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data. (arXiv:2208.08207v1 [cs.CV])
38. How does the degree of novelty impacts semi-supervised representation learning for novel class retrieval?. (arXiv:2208.08217v1 [cs.CV])
39. Towards an Error-free Deep Occupancy Detector for Smart Camera Parking System. (arXiv:2208.08220v1 [cs.CV])
40. Blind-Spot Collision Detection System for Commercial Vehicles Using Multi Deep CNN Architecture. (arXiv:2208.08224v1 [cs.CV])
41. Auto-segmentation of Hip Joints using MultiPlanar UNet with Transfer learning. (arXiv:2208.08226v1 [eess.IV])
42. HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v1 [cs.CL])
43. ILLUME: Rationalizing Vision-Language Models by Interacting with their Jabber. (arXiv:2208.08241v1 [cs.LG])
44. On the Privacy Effect of Data **Enhancement** via the Lens of Memorization. (arXiv:2208.08270v1 [cs.LG])
45. Novel Deep Learning Approach to Derive Cytokeratin Expression and Epithelium Segmentation from DAPI. (arXiv:2208.08284v1 [eess.IV])
46. Metal artifact correction in cone beam computed tomography using synthetic X-ray data. (arXiv:2208.08288v1 [eess.IV])
47. IDAN: Image Difference Attention Network for Change Detection. (arXiv:2208.08292v1 [cs.CV])
48. ParaColorizer: Realistic Image Colorization using Parallel Generative Networks. (arXiv:2208.08295v1 [cs.CV])
49. Attackar: Attack of the Evolutionary Adversary. (arXiv:2208.08297v1 [cs.CV])
50. Incremental 3D Scene Completion for Safe and Efficient Exploration Mapping and Planning. (arXiv:2208.08307v1 [cs.RO])
51. Video-TransUNet: Temporally Blended Vision Transformer for CT VFSS Instance Segmentation. (arXiv:2208.08315v1 [eess.IV])
52. Leukocyte Classification using Multimodal Architecture Enhanced by Knowledge Distillation. (arXiv:2208.08331v1 [eess.IV])
53. SO(3)-Pose: SO(3)-Equivariance Learning for 6D Object Pose Estimation. (arXiv:2208.08338v1 [cs.CV])
54. Class-Aware Visual Prompt Tuning for Vision-Language Pre-Trained Model. (arXiv:2208.08340v1 [cs.CV])
55. Transferability limitations for Covid 3D Localization Using SARS-CoV-2 segmentation models in 4D CT images. (arXiv:2208.08343v1 [eess.IV])
56. Open Long-Tailed Recognition in a Dynamic World. (arXiv:2208.08349v1 [cs.CV])
57. FCN-Transformer Feature Fusion for Polyp Segmentation. (arXiv:2208.08352v1 [eess.IV])
58. Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
59. Self-Supervised Depth Estimation in Laparoscopic Image using 3D Geometric Consistency. (arXiv:2208.08407v1 [cs.CV])
60. Multi-View Correlation Consistency for Semi-Supervised Semantic Segmentation. (arXiv:2208.08437v1 [cs.CV])
61. Learning to Structure an Image with Few Colors and Beyond. (arXiv:2208.08438v1 [cs.CV])
62. MoCapDeform: Monocular 3D Human Motion Capture in Deformable Scenes. (arXiv:2208.08439v1 [cs.CV])
63. Adversarial Image Color Transformations in Explicit Color Filter Space. (arXiv:2011.06690v2 [cs.CV] UPDATED)
64. GhostSR: Learning Ghost Features for Efficient Image Super-Resolution. (arXiv:2101.08525v2 [eess.IV] UPDATED)
65. A deep learning approach to clustering visual arts. (arXiv:2106.06234v2 [cs.CV] UPDATED)
66. AttDLNet: Attention-based DL Network for 3D LiDAR Place Recognition. (arXiv:2106.09637v3 [cs.CV] UPDATED)
67. CUDA-GHR: Controllable Unsupervised Domain Adaptation for Gaze and Head Redirection. (arXiv:2106.10852v3 [cs.CV] UPDATED)
68. Investigate the Essence of Long-Tailed Recognition from a Unified Perspective. (arXiv:2107.03758v2 [cs.CV] UPDATED)
69. Unsupervised Local Discrimination for Medical Images. (arXiv:2108.09440v4 [cs.CV] UPDATED)
70. TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models. (arXiv:2109.10282v4 [cs.CL] UPDATED)
71. Better Pseudo-label: Joint Domain-aware Label and Dual-classifier for Semi-supervised Domain Generalization. (arXiv:2110.04820v2 [cs.CV] UPDATED)
72. Domain Prompt Learning for Efficiently Adapting CLIP to Unseen Domains. (arXiv:2111.12853v4 [cs.CV] UPDATED)
73. Point Cloud Instance Segmentation with Semi-supervised Bounding-Box Mining. (arXiv:2111.15210v2 [cs.CV] UPDATED)
74. SAGA: Stochastic Whole-Body Grasping with Contact. (arXiv:2112.10103v3 [cs.CV] UPDATED)
75. Efficient Single Image Super-Resolution Using Dual Path Connections with Multiple Scale Learning. (arXiv:2112.15386v2 [eess.IV] UPDATED)
76. DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
77. Automated Learning for Deformable Medical Image Registration by Jointly Optimizing Network Architectures and Objective Functions. (arXiv:2203.06810v2 [cs.CV] UPDATED)
78. A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection. (arXiv:2205.12358v2 [cs.CV] UPDATED)
79. Slim-neck by GSConv: A better design paradigm of detector architectures for autonomous vehicles. (arXiv:2206.02424v2 [cs.CV] UPDATED)
80. PolyU-BPCoMa: A Dataset and Benchmark Towards Mobile Colorized Mapping Using a Backpack Multisensorial System. (arXiv:2206.07468v2 [cs.CV] UPDATED)
81. VLMbench: A Compositional Benchmark for Vision-and-Language Manipulation. (arXiv:2206.08522v2 [cs.RO] UPDATED)
82. Design of Supervision-Scalable Learning Systems: Methodology and Performance Benchmarking. (arXiv:2206.09061v2 [cs.CV] UPDATED)
83. COVID Detection and Severity Prediction with 3D-ConvNeXt and Custom Pretrainings. (arXiv:2206.15073v2 [eess.IV] UPDATED)
84. Deep Optical Coding Design in Computational Imaging. (arXiv:2207.00164v2 [cs.CV] UPDATED)
85. Symmetry-Aware Transformer-based Mirror Detection. (arXiv:2207.06332v2 [cs.CV] UPDATED)
86. CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution. (arXiv:2207.10345v2 [cs.CV] UPDATED)
87. Correspondence Matters for Video Referring Expression Comprehension. (arXiv:2207.10400v2 [cs.CV] UPDATED)
88. Sinusoidal Sensitivity Calculation for Line Segment Geometries. (arXiv:2208.03059v2 [physics.med-ph] UPDATED)
89. Inflating 2D Convolution Weights for Efficient Generation of 3D Medical Images. (arXiv:2208.03934v2 [eess.IV] UPDATED)
90. Bidirectional Feature Globalization for Few-shot Semantic Segmentation of 3D Point Cloud Scenes. (arXiv:2208.06671v2 [cs.CV] UPDATED)
91. Learning Semantic Correspondence with Sparse Annotations. (arXiv:2208.06974v2 [cs.CV] UPDATED)
92. Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets. (arXiv:2208.07463v2 [cs.CV] UPDATED)
93. Towards Local Underexposed Photo **Enhancement**. (arXiv:2208.07711v2 [cs.CV] UPDATED)
94. Classifications of Skull Fractures using CT Scan Images via CNN with Lazy Learning Approach. (arXiv:2203.10786v1 [eess.IV] CROSS LISTED)
95. Predicting skull fractures via CNN with classification algorithms. (arXiv:2208.06756v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**22** new papers in eess.IV:-) 
1. Digital autofocusing of a coded-aperture Laue diffraction microscope. (arXiv:2208.07873v1 [eess.IV])
2. REGAS: REspiratory-GAted Synthesis of Views for Multi-Phase CBCT Reconstruction from a single 3D CBCT Acquisition. (arXiv:2208.08048v1 [eess.IV])
3. Efficient dynamic point cloud coding using Slice-Wise Segmentation. (arXiv:2208.08061v1 [cs.CV])
4. Evaluation of 3D GANs for Lung Tissue Modelling in Pulmonary CT. (arXiv:2208.08184v1 [eess.IV])
5. DeepSportradar-v1: Computer Vision Dataset for Sports Understanding with High Quality Annotations. (arXiv:2208.08190v1 [cs.CV])
6. Blind-Spot Collision Detection System for Commercial Vehicles Using Multi Deep CNN Architecture. (arXiv:2208.08224v1 [cs.CV])
7. Auto-segmentation of Hip Joints using MultiPlanar UNet with Transfer learning. (arXiv:2208.08226v1 [eess.IV])
8. Novel Deep Learning Approach to Derive Cytokeratin Expression and Epithelium Segmentation from DAPI. (arXiv:2208.08284v1 [eess.IV])
9. Metal artifact correction in cone beam computed tomography using synthetic X-ray data. (arXiv:2208.08288v1 [eess.IV])
10. Video-TransUNet: Temporally Blended Vision Transformer for CT VFSS Instance Segmentation. (arXiv:2208.08315v1 [eess.IV])
11. Leukocyte Classification using Multimodal Architecture Enhanced by Knowledge Distillation. (arXiv:2208.08331v1 [eess.IV])
12. Semantic Communications with Discrete-time Analog Transmission: A PAPR Perspective. (arXiv:2208.08342v1 [cs.IT])
13. Transferability limitations for Covid 3D Localization Using SARS-CoV-2 segmentation models in 4D CT images. (arXiv:2208.08343v1 [eess.IV])
14. FCN-Transformer Feature Fusion for Polyp Segmentation. (arXiv:2208.08352v1 [eess.IV])
15. Global Speed-of-Sound Prediction Using Transmission Geometry. (arXiv:2208.08377v1 [physics.med-ph])
16. GhostSR: Learning Ghost Features for Efficient Image Super-Resolution. (arXiv:2101.08525v2 [eess.IV] UPDATED)
17. Efficient Single Image Super-Resolution Using Dual Path Connections with Multiple Scale Learning. (arXiv:2112.15386v2 [eess.IV] UPDATED)
18. DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
19. COVID Detection and Severity Prediction with 3D-ConvNeXt and Custom Pretrainings. (arXiv:2206.15073v2 [eess.IV] UPDATED)
20. CADyQ: Content-Aware Dynamic Quantization for Image Super-Resolution. (arXiv:2207.10345v2 [cs.CV] UPDATED)
21. Inflating 2D Convolution Weights for Efficient Generation of 3D Medical Images. (arXiv:2208.03934v2 [eess.IV] UPDATED)
22. A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathological Images. (arXiv:2208.07655v2 [eess.IV] UPDATED)
## cs.LG
---
**129** new papers in cs.LG:-) 
1. Collaborative causal inference on distributed data. (arXiv:2208.07898v1 [stat.ME])
2. FOLD-SE: Scalable Explainable AI. (arXiv:2208.07912v1 [cs.LG])
3. PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm. (arXiv:2208.07914v1 [cs.LG])
4. Ex-Ante Assessment of Discrimination in Dataset. (arXiv:2208.07918v1 [cs.LG])
5. FedPerm: Private and Robust Federated Learning by Parameter Permutation. (arXiv:2208.07922v1 [cs.LG])
6. Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions. (arXiv:2208.07934v1 [cs.LG])
7. Riemannian Diffusion Models. (arXiv:2208.07949v1 [cs.LG])
8. On the generalization of learning algorithms that do not converge. (arXiv:2208.07951v1 [cs.LG])
9. Generative Thermal Design Through Boundary Representation and Multi-Agent Cooperative Environment. (arXiv:2208.07952v1 [cs.LG])
10. Online Learning for Mixture of Multivariate Hawkes Processes. (arXiv:2208.07961v1 [stat.ML])
11. Mixed Quantum-Classical Method For Fraud Detection with Quantum Feature Selection. (arXiv:2208.07963v1 [quant-ph])
12. Resource-aware Federated Learning using Knowledge Extraction and Multi-model Fusion. (arXiv:2208.07978v1 [cs.DC])
13. Tiny-HR: Towards an interpretable machine learning pipeline for heart rate estimation on edge devices. (arXiv:2208.07981v1 [cs.LG])
14. Private Estimation with Public Data. (arXiv:2208.07984v1 [cs.LG])
15. DICE: Data-Efficient Clinical Event Extraction with Generative Models. (arXiv:2208.07989v1 [cs.CL])
16. Enhancing Audio Perception of Music By AI Picked Room Acoustics. (arXiv:2208.07994v1 [cs.SD])
17. Superior generalization of smaller models in the presence of significant label noise. (arXiv:2208.08003v1 [cs.LG])
18. ShortcutLens: A Visual Analytics Approach for Exploring Shortcuts in Natural Language Understanding Dataset. (arXiv:2208.08010v1 [cs.HC])
19. Interference Cancellation GAN Framework for Dynamic Channels. (arXiv:2208.08019v1 [cs.LG])
20. Streaming Adaptive Submodular Maximization. (arXiv:2208.08021v1 [cs.AI])
21. Artificial Intelligence Empowered Multiple Access for Ultra Reliable and Low Latency THz Wireless Networks. (arXiv:2208.08039v1 [eess.SP])
22. A Survey on Incomplete Multi-view Clustering. (arXiv:2208.08040v1 [cs.LG])
23. Sampling Through the Lens of Sequential Decision Making. (arXiv:2208.08056v1 [cs.LG])
24. Quantum Bayes AI. (arXiv:2208.08068v1 [stat.ML])
25. Multimodal Lecture Presentations Dataset: Understanding Multimodality in Educational Slides. (arXiv:2208.08080v1 [cs.AI])
26. A Hybrid SFANC-FxNLMS Algorithm for Active Noise Control based on Deep Learning. (arXiv:2208.08082v1 [eess.SY])
27. Efficient Detection and Filtering Systems for Distributed Training. (arXiv:2208.08085v1 [cs.LG])
28. Autonomous Resource Management in Construction Companies Using Deep Reinforcement Learning Based on IoT. (arXiv:2208.08087v1 [cs.LG])
29. Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning and Non-Episodic Text Classification. (arXiv:2208.08089v1 [cs.LG])
30. Paint2Pix: Interactive Painting based Progressive Image Synthesis and Editing. (arXiv:2208.08092v1 [cs.CV])
31. DLCFT: Deep Linear Continual Fine-Tuning for General Incremental Learning. (arXiv:2208.08112v1 [cs.LG])
32. Maximising the Utility of Validation Sets for Imbalanced Noisy-label Meta-learning. (arXiv:2208.08132v1 [cs.LG])
33. Metric Residual Networks for Sample Efficient Goal-conditioned Reinforcement Learning. (arXiv:2208.08133v1 [cs.LG])
34. Gradient-Based Meta-Learning Using Uncertainty to Weigh Loss for Few-Shot Learning. (arXiv:2208.08135v1 [cs.LG])
35. Shallow neural network representation of polynomials. (arXiv:2208.08138v1 [stat.ML])
36. A Monotonicity Constrained Attention Module for Emotion Classification with Limited EEG Data. (arXiv:2208.08155v1 [eess.SP])
37. Random Search Hyper-Parameter Tuning: Expected Improvement Estimation and the Corresponding Lower Bound. (arXiv:2208.08170v1 [cs.LG])
38. Deep Learning-Based Discrete Calibrated Survival Prediction. (arXiv:2208.08182v1 [cs.LG])
39. DeepSportradar-v1: Computer Vision Dataset for Sports Understanding with High Quality Annotations. (arXiv:2208.08190v1 [cs.CV])
40. Transformer Vs. MLP-Mixer Exponential Expressive Gap For NLP Problems. (arXiv:2208.08191v1 [cs.CL])
41. Assurance Cases as Foundation Stone for Auditing AI-enabled and Autonomous Systems: Workshop Results and Political Recommendations for Action from the ExamAI Project. (arXiv:2208.08198v1 [cs.SE])
42. AHEAD: A Triple Attention Based Heterogeneous Graph Anomaly Detection Approach. (arXiv:2208.08200v1 [cs.SI])
43. Towards an Error-free Deep Occupancy Detector for Smart Camera Parking System. (arXiv:2208.08220v1 [cs.CV])
44. Which Factors Drive Open Access Publishing? A Springer Nature Case Study. (arXiv:2208.08221v1 [cs.DL])
45. A Scalable and Extensible Approach to Benchmarking NL2Code for 18 Programming Languages. (arXiv:2208.08227v1 [cs.LG])
46. Two-Stage Robust and Sparse Distributed Statistical Inference for Large-Scale Data. (arXiv:2208.08230v1 [stat.ML])
47. Deep Autoencoder Model Construction Based on Pytorch. (arXiv:2208.08231v1 [cs.LG])
48. HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v1 [cs.CL])
49. Dynamical softassign and adaptive parameter tuning for graph matching. (arXiv:2208.08233v1 [math.CO])
50. DPA-1: Pretraining of Attention-based Deep Potential Model for Molecular Simulation. (arXiv:2208.08236v1 [physics.chem-ph])
51. ILLUME: Rationalizing Vision-Language Models by Interacting with their Jabber. (arXiv:2208.08241v1 [cs.LG])
52. Domain Knowledge in A*-Based Causal Discovery. (arXiv:2208.08247v1 [stat.ML])
53. Semi-Supervised Anomaly Detection Based on Quadratic Multiform Separation. (arXiv:2208.08265v1 [stat.ML])
54. Prediction of Oral Food Challenges via Machine Learning. (arXiv:2208.08268v1 [cs.LG])
55. On the Privacy Effect of Data **Enhancement** via the Lens of Memorization. (arXiv:2208.08270v1 [cs.LG])
56. Quantum Machine Learning for Material Synthesis and Hardware Security. (arXiv:2208.08273v1 [quant-ph])
57. SMPL-IK: Learned Morphology-Aware Inverse Kinematics for AI Driven Artistic Workflows. (arXiv:2208.08274v1 [cs.GR])
58. Wave simulation in non-smooth media by PINN with quadratic neural network and PML condition. (arXiv:2208.08276v1 [physics.geo-ph])
59. Error Parity Fairness: Testing for Group Fairness in Regression Tasks. (arXiv:2208.08279v1 [cs.LG])
60. Novel Deep Learning Approach to Derive Cytokeratin Expression and Epithelium Segmentation from DAPI. (arXiv:2208.08284v1 [eess.IV])
61. Sparse Nonnegative Tucker Decomposition and Completion under Noisy Observations. (arXiv:2208.08287v1 [cs.LG])
62. Transformer-Based Deep Learning Model for Stock Price Prediction: A Case Study on Bangladesh Stock Market. (arXiv:2208.08300v1 [q-fin.ST])
63. Position-aware Structure Learning for Graph Topology-imbalance by Relieving Under-reaching and Over-squashing. (arXiv:2208.08302v1 [cs.LG])
64. Leukocyte Classification using Multimodal Architecture Enhanced by Knowledge Distillation. (arXiv:2208.08331v1 [eess.IV])
65. Semantic Communications with Discrete-time Analog Transmission: A PAPR Perspective. (arXiv:2208.08342v1 [cs.IT])
66. Discovering Agents. (arXiv:2208.08345v1 [cs.AI])
67. Open Long-Tailed Recognition in a Dynamic World. (arXiv:2208.08349v1 [cs.CV])
68. Minimum Cost Adaptive Submodular Cover. (arXiv:2208.08351v1 [cs.DS])
69. FCN-Transformer Feature Fusion for Polyp Segmentation. (arXiv:2208.08352v1 [eess.IV])
70. Extract fundamental frequency based on CNN combined with PYIN. (arXiv:2208.08354v1 [cs.SD])
71. Ask Question First for Enhancing Lifelong Language Learning. (arXiv:2208.08367v1 [cs.CL])
72. Commander's Intent: A Dataset and Modeling Approach for Human-AI Task Specification in Strategic Play. (arXiv:2208.08374v1 [cs.AI])
73. Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
74. LAMA-Net: Unsupervised Domain Adaptation via Latent Alignment and Manifold Learning for RUL Prediction. (arXiv:2208.08388v1 [cs.LG])
75. The Counterfactual-Shapley Value: Attributing Change in System Metrics. (arXiv:2208.08399v1 [cs.LG])
76. Conformal Inference for Online Prediction with Arbitrary Distribution Shifts. (arXiv:2208.08401v1 [stat.ME])
77. SYNTHESIS: A Semi-Asynchronous Path-Integrated Stochastic Gradient Method for Distributed Learning in Computing Clusters. (arXiv:2208.08425v1 [cs.LG])
78. Label Flipping Data Poisoning Attack Against Wearable Human Activity Recognition System. (arXiv:2208.08433v1 [cs.CR])
79. Arachne: Search Based Repair of Deep Neural Networks. (arXiv:1912.12463v2 [cs.LG] UPDATED)
80. Localized Debiased Machine Learning: Efficient Inference on Quantile Treatment Effects and Beyond. (arXiv:1912.12945v5 [stat.ML] UPDATED)
81. CoSimGNN: Towards Large-scale Graph Similarity Computation. (arXiv:2005.07115v7 [cs.LG] UPDATED)
82. Supervised PCA: A Multiobjective Approach. (arXiv:2011.05309v4 [stat.ML] UPDATED)
83. Adversarial Image Color Transformations in Explicit Color Filter Space. (arXiv:2011.06690v2 [cs.CV] UPDATED)
84. HypoSVI: Hypocenter inversion with Stein variational inference and Physics Informed Neural Networks. (arXiv:2101.03271v3 [physics.geo-ph] UPDATED)
85. Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v3 [cs.SI] UPDATED)
86. Adversarial Inverse Reinforcement Learning for Mean Field Games. (arXiv:2104.14654v3 [cs.LG] UPDATED)
87. Physics-Guided Discovery of Highly Nonlinear Parametric Partial Differential Equations. (arXiv:2106.01078v2 [cs.LG] UPDATED)
88. RegMix: Data Mixing Augmentation for Regression. (arXiv:2106.03374v4 [cs.LG] UPDATED)
89. Deep Gaussian Process Emulation using Stochastic Imputation. (arXiv:2107.01590v2 [stat.ML] UPDATED)
90. A Framework for Machine Learning of Model Error in Dynamical Systems. (arXiv:2107.06658v3 [math.DS] UPDATED)
91. A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge Domain Adaptation on FPGAs. (arXiv:2107.12824v3 [cs.LG] UPDATED)
92. Deep Contrastive Multiview Network Embedding. (arXiv:2108.08296v2 [cs.LG] UPDATED)
93. Frequency-Severity Experience Rating based on Latent Markovian Risk Profiles. (arXiv:2109.01413v2 [stat.AP] UPDATED)
94. FRL: Federated Rank Learning. (arXiv:2110.04350v3 [cs.LG] UPDATED)
95. Quadratic Multiform Separation: A New Classification Model in Machine Learning. (arXiv:2110.04925v2 [stat.ML] UPDATED)
96. GraPE: fast and scalable Graph Processing and Embedding. (arXiv:2110.06196v2 [cs.LG] UPDATED)
97. Learning to Operate an Electric Vehicle Charging Station Considering Vehicle-grid Integration. (arXiv:2111.01294v2 [cs.LG] UPDATED)
98. Modeling Occasion Evolution in Frequency Domain for Promotion-Aware Click-Through Rate Prediction. (arXiv:2112.13747v4 [cs.LG] UPDATED)
99. Motion Inbetweening via Deep $\Delta$-Interpolator. (arXiv:2201.06701v4 [cs.LG] UPDATED)
100. DSFormer: A Dual-domain Self-supervised Transformer for Accelerated Multi-contrast MRI Reconstruction. (arXiv:2201.10776v2 [eess.IV] UPDATED)
101. Analysis of Digitalized ECG Signals Based on Artificial Intelligence and Spectral Analysis Methods Specialized in ARVC. (arXiv:2203.00504v2 [eess.SP] UPDATED)
102. Learning Neural Set Functions Under the Optimal Subset Oracle. (arXiv:2203.01693v2 [cs.LG] UPDATED)
103. Automated Learning for Deformable Medical Image Registration by Jointly Optimizing Network Architectures and Objective Functions. (arXiv:2203.06810v2 [cs.CV] UPDATED)
104. Feature Structure Distillation with Centered Kernel Alignment in BERT Transferring. (arXiv:2204.08922v2 [cs.CL] UPDATED)
105. E2FL: Equal and Equitable Federated Learning. (arXiv:2205.10454v2 [cs.LG] UPDATED)
106. Deep Representations for Time-varying Brain Datasets. (arXiv:2205.11648v3 [cs.LG] UPDATED)
107. Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v3 [cs.AI] UPDATED)
108. Score-Based Generative Models Detect Manifolds. (arXiv:2206.01018v2 [stat.ML] UPDATED)
109. Learning Generative Factors of EEG Data with Variational auto-encoders. (arXiv:2206.01939v3 [cs.LG] UPDATED)
110. Predicting Corporate Risk by Jointly Modeling Company Networks and Dialogues in Earnings Conference Calls. (arXiv:2206.06174v3 [cs.CL] UPDATED)
111. From Shapley back to Pearson: Hypothesis Testing via the Shapley Value. (arXiv:2207.07038v2 [cs.LG] UPDATED)
112. Model-Aware Contrastive Learning: Towards Escaping Uniformity-Tolerance Dilemma in Training. (arXiv:2207.07874v2 [cs.LG] UPDATED)
113. GATE: Gated Additive Tree Ensemble for Tabular Classification and Regression. (arXiv:2207.08548v3 [cs.LG] UPDATED)
114. Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs. (arXiv:2207.08824v3 [q-bio.QM] UPDATED)
115. Do Quantum Circuit Born Machines Generalize?. (arXiv:2207.13645v2 [quant-ph] UPDATED)
116. An Adjoint-Free Algorithm for CNOP via Sampling. (arXiv:2208.00956v2 [math.OC] UPDATED)
117. Noise tolerance of learning to rank under class-conditional label noise. (arXiv:2208.02126v2 [cs.IR] UPDATED)
118. Decision SincNet: Neurocognitive models of decision making that predict cognitive processes from neural signals. (arXiv:2208.02845v2 [q-bio.NC] UPDATED)
119. Adaptive Resources Allocation CUSUM for Binomial Count Data Monitoring with Application to COVID-19 Hotspot Detection. (arXiv:2208.05045v2 [cs.LG] UPDATED)
120. Feature-Based Time-Series Analysis in R using the theft Package. (arXiv:2208.06146v3 [stat.ML] UPDATED)
121. Semi-automatic tuning of coupled climate models with multiple intrinsic timescales: lessons learned from the Lorenz96 model. (arXiv:2208.06243v2 [physics.ao-ph] UPDATED)
122. RLang: A Declarative Language for Expression Prior Knowledge for Reinforcement Learning. (arXiv:2208.06448v2 [cs.AI] UPDATED)
123. Virgo: Scalable Unsupervised Classification of Cosmological Shock Waves. (arXiv:2208.06859v2 [astro-ph.IM] UPDATED)
124. Reliable Decision from Multiple Subtasks through Threshold Optimization: Content Moderation in the Wild. (arXiv:2208.07522v2 [cs.LG] UPDATED)
125. A unifying partially-interpretable framework for neural network-based extreme quantile regression. (arXiv:2208.07581v2 [stat.ML] UPDATED)
126. Score-Based Diffusion meets Annealed Importance Sampling. (arXiv:2208.07698v2 [stat.ML] UPDATED)
127. Classifications of Skull Fractures using CT Scan Images via CNN with Lazy Learning Approach. (arXiv:2203.10786v1 [eess.IV] CROSS LISTED)
128. Disentangled Modeling of Domain and Relevance for Adaptable Dense Retrieval. (arXiv:2208.05753v1 [cs.IR] CROSS LISTED)
129. Predicting skull fractures via CNN with classification algorithms. (arXiv:2208.06756v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**66** new papers in cs.AI:-) 
1. PD-MORL: Preference-Driven Multi-Objective Reinforcement Learning Algorithm. (arXiv:2208.07914v1 [cs.LG])
2. Measuring Statistical Dependencies via Maximum Norm and Characteristic Functions. (arXiv:2208.07934v1 [cs.LG])
3. Advancing Human-AI Complementarity: The Impact of User Expertise and Algorithmic Tuning on Joint Decision Making. (arXiv:2208.07960v1 [cs.HC])
4. DICE: Data-Efficient Clinical Event Extraction with Generative Models. (arXiv:2208.07989v1 [cs.CL])
5. Enhancing Audio Perception of Music By AI Picked Room Acoustics. (arXiv:2208.07994v1 [cs.SD])
6. Transformer Encoder for Social Science. (arXiv:2208.08005v1 [cs.CL])
7. Towards Generating Robust, Fair, and Emotion-Aware Explanations for Recommender Systems. (arXiv:2208.08017v1 [cs.AI])
8. Interference Cancellation GAN Framework for Dynamic Channels. (arXiv:2208.08019v1 [cs.LG])
9. Streaming Adaptive Submodular Maximization. (arXiv:2208.08021v1 [cs.AI])
10. EGCR: Explanation Generation for Conversational Recommendation. (arXiv:2208.08035v1 [cs.AI])
11. Artificial Intelligence Empowered Multiple Access for Ultra Reliable and Low Latency THz Wireless Networks. (arXiv:2208.08039v1 [eess.SP])
12. A Sequence Tagging based Framework for Few-Shot Relation Extraction. (arXiv:2208.08053v1 [cs.CL])
13. Semi-supervised Learning with Deterministic Labeling and Large Margin Projection. (arXiv:2208.08058v1 [cs.AI])
14. NECE: Narrative Event Chain Extraction Toolkit. (arXiv:2208.08063v1 [cs.AI])
15. An Efficient Multi-Step Framework for Malware Packing Identification. (arXiv:2208.08071v1 [cs.CR])
16. Multimodal Lecture Presentations Dataset: Understanding Multimodality in Educational Slides. (arXiv:2208.08080v1 [cs.AI])
17. Paint2Pix: Interactive Painting based Progressive Image Synthesis and Editing. (arXiv:2208.08092v1 [cs.CV])
18. CommitBART: A Large Pre-trained Model for GitHub Commits. (arXiv:2208.08100v1 [cs.SE])
19. DLCFT: Deep Linear Continual Fine-Tuning for General Incremental Learning. (arXiv:2208.08112v1 [cs.LG])
20. An Empirical Study on the Membership Inference Attack against Tabular Data Synthesis Models. (arXiv:2208.08114v1 [cs.CR])
21. Knowledge Graph Curation: A Practical Framework. (arXiv:2208.08130v1 [cs.DB])
22. Metric Residual Networks for Sample Efficient Goal-conditioned Reinforcement Learning. (arXiv:2208.08133v1 [cs.LG])
23. A Concept and Argumentation based Interpretable Model in High Risk Domains. (arXiv:2208.08149v1 [cs.AI])
24. On Establishing Robust Consistency in Answer Set Programs. (arXiv:2208.08157v1 [cs.AI])
25. Information Loss in Euclidean Preference Models. (arXiv:2208.08160v1 [cs.AI])
26. Random Search Hyper-Parameter Tuning: Expected Improvement Estimation and the Corresponding Lower Bound. (arXiv:2208.08170v1 [cs.LG])
27. Visual Comparison of Language Model Adaptation. (arXiv:2208.08176v1 [cs.AI])
28. Deep Learning-Based Discrete Calibrated Survival Prediction. (arXiv:2208.08182v1 [cs.LG])
29. Understanding Long Documents with Different Position-Aware Attentions. (arXiv:2208.08201v1 [cs.CL])
30. Time flies by: Analyzing the Impact of Face Ageing on the Recognition Performance with Synthetic Data. (arXiv:2208.08207v1 [cs.CV])
31. Path Planning of Cleaning Robot with Reinforcement Learning. (arXiv:2208.08211v1 [cs.RO])
32. How does the degree of novelty impacts semi-supervised representation learning for novel class retrieval?. (arXiv:2208.08217v1 [cs.CV])
33. ODformer: Spatial-Temporal Transformers for Long Sequence Origin-Destination Matrix Forecasting Against Cross Application Scenario. (arXiv:2208.08218v1 [cs.AI])
34. HELP ME THINK: A Simple Prompting Strategy for Non-experts to Create Customized Content with Models. (arXiv:2208.08232v1 [cs.CL])
35. Performance Optimization for Semantic Communications: An Attention-based Reinforcement Learning Approach. (arXiv:2208.08239v1 [cs.IT])
36. ILLUME: Rationalizing Vision-Language Models by Interacting with their Jabber. (arXiv:2208.08241v1 [cs.LG])
37. Domain Knowledge in A*-Based Causal Discovery. (arXiv:2208.08247v1 [stat.ML])
38. On the Elements of Datasets for Cyber Physical Systems Security. (arXiv:2208.08255v1 [cs.CR])
39. Multimodal foundation models are better simulators of the human brain. (arXiv:2208.08263v1 [cs.NE])
40. Position-aware Structure Learning for Graph Topology-imbalance by Relieving Under-reaching and Over-squashing. (arXiv:2208.08302v1 [cs.LG])
41. BIC: Twitter Bot Detection with Text-Graph Interaction and Semantic Consistency. (arXiv:2208.08320v1 [cs.AI])
42. Discovering Agents. (arXiv:2208.08345v1 [cs.AI])
43. Ask Question First for Enhancing Lifelong Language Learning. (arXiv:2208.08367v1 [cs.CL])
44. Commander's Intent: A Dataset and Modeling Approach for Human-AI Task Specification in Strategic Play. (arXiv:2208.08374v1 [cs.AI])
45. Deep Generative Views to Mitigate Gender Classification Bias Across Gender-Race Groups. (arXiv:2208.08382v1 [cs.CV])
46. Summarizing Patients Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models. (arXiv:2208.08408v1 [cs.CL])
47. Logical Separability of Labeled Data Examples under Ontologies. (arXiv:2007.01610v2 [cs.LO] UPDATED)
48. Towards a Better Understanding Human Reading Comprehension with Brain Signals. (arXiv:2108.01360v3 [cs.IR] UPDATED)
49. Deep Contrastive Multiview Network Embedding. (arXiv:2108.08296v2 [cs.LG] UPDATED)
50. mMARCO: A Multilingual Version of the MS MARCO Passage Ranking Dataset. (arXiv:2108.13897v5 [cs.CL] UPDATED)
51. Logical Assessment Formula and Its Principles for Evaluations with Inaccurate Ground-Truth Labels. (arXiv:2110.11567v2 [cs.AI] UPDATED)
52. Point Cloud Instance Segmentation with Semi-supervised Bounding-Box Mining. (arXiv:2111.15210v2 [cs.CV] UPDATED)
53. Feature Structure Distillation with Centered Kernel Alignment in BERT Transferring. (arXiv:2204.08922v2 [cs.CL] UPDATED)
54. An Algorithmic Approach to Emergence. (arXiv:2205.12997v2 [cond-mat.stat-mech] UPDATED)
55. Are Transformers Effective for Time Series Forecasting?. (arXiv:2205.13504v3 [cs.AI] UPDATED)
56. Learning to Represent Programs with Code Hierarchies. (arXiv:2205.15479v2 [cs.SE] UPDATED)
57. TwiBot-22: Towards Graph-Based Twitter Bot Detection. (arXiv:2206.04564v3 [cs.SI] UPDATED)
58. A General Framework for the Representation of Function and Affordance: A Cognitive, Causal, and Grounded Approach, and a Step Toward AGI. (arXiv:2206.05273v3 [cs.AI] UPDATED)
59. Predicting Corporate Risk by Jointly Modeling Company Networks and Dialogues in Earnings Conference Calls. (arXiv:2206.06174v3 [cs.CL] UPDATED)
60. Connecting Algorithmic Research and Usage Contexts: A Perspective of Contextualized Evaluation for Explainable AI. (arXiv:2206.10847v2 [cs.AI] UPDATED)
61. RLang: A Declarative Language for Expression Prior Knowledge for Reinforcement Learning. (arXiv:2208.06448v2 [cs.AI] UPDATED)
62. Recognition of All Categories of Entities by AI. (arXiv:2208.06590v2 [cs.AI] UPDATED)
63. Conv-Adapter: Exploring Parameter Efficient Transfer Learning for ConvNets. (arXiv:2208.07463v2 [cs.CV] UPDATED)
64. A Hybrid Deep Feature-Based Deformable Image Registration Method for Pathological Images. (arXiv:2208.07655v2 [eess.IV] UPDATED)
65. Classifications of Skull Fractures using CT Scan Images via CNN with Lazy Learning Approach. (arXiv:2203.10786v1 [eess.IV] CROSS LISTED)
66. Predicting skull fractures via CNN with classification algorithms. (arXiv:2208.06756v1 [cs.CV] CROSS LISTED)

