# Your interest papers
---
## cs.CV
---
### No Attention is Needed: Grouped Spatial-temporal Shift for Simple and Efficient Video Restorers. (arXiv:2206.10810v1 [eess.IV])
- Authors : Dasong Li, Xiaoyu Shi, Yi Zhang, Xiaogang Wang, Hongwei Qin, Hongsheng Li
- Link : [http://arxiv.org/abs/2206.10810](http://arxiv.org/abs/2206.10810)
> ABSTRACT  :  Video **restoration**, aiming at restoring clear frames from degraded videos, has been attracting increasing attention. Video **restoration** is required to establish the temporal correspondences from multiple misaligned frames. To achieve that end, existing deep methods generally adopt complicated network architectures, such as integrating optical flow, deformable convolution, cross-frame or cross-pixel self-attention layers, resulting in expensive computational cost. We argue that with proper design, temporal information utilization in video **restoration** can be much more efficient and effective. In this study, we propose a simple, fast yet effective framework for video **restoration**. The key of our framework is the grouped spatial-temporal shift, which is simple and lightweight, but can implicitly establish inter-frame correspondences and achieve multi-frame aggregation. Coupled with basic 2D U-Nets for frame-wise encoding and decoding, such an efficient spatial-temporal shift module can effectively tackle the challenges in video **restoration**. Extensive experiments show that our framework surpasses previous state-of-the-art method with 43% of its computational cost on both video deblurring and video denoising.  
### A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing. (arXiv:2206.10830v1 [cs.CV])
- Authors : Haiming Yao, Wenyong Yu, Xue Wang
- Link : [http://arxiv.org/abs/2206.10830](http://arxiv.org/abs/2206.10830)
> ABSTRACT  :  Recent advances in the industrial inspection of textured surfaces-in the form of visual inspection-have made such inspections possible for efficient, flexible manufacturing systems. We propose an unsupervised feature memory rearrangement network (FMR-Net) to accurately detect various textural defects simultaneously. Consistent with mainstream methods, we adopt the idea of background reconstruction; however, we innovatively utilize artificial synthetic defects to enable the model to recognize anomalies, while traditional wisdom relies only on defect-free samples. First, we employ an encoding module to obtain multiscale features of the textured surface. Subsequently, a contrastive-learning-based memory feature module (CMFM) is proposed to obtain discriminative representations and construct a normal feature memory bank in the latent space, which can be employed as a substitute for defects and fast anomaly scores at the patch level. Next, a novel global feature rearrangement module (GFRM) is proposed to further suppress the reconstruction of residual defects. Finally, a decoding module utilizes the restored features to reconstruct the normal texture background. In addition, to improve inspection performance, a two-phase training strategy is utilized for accurate defect **restoration** refinement, and we exploit a multimodal inspection method to achieve noise-robust defect localization. We verify our method through extensive experiments and test its practical deployment in collaborative edge--cloud intelligent manufacturing scenarios by means of a multilevel detection method, demonstrating that FMR-Net exhibits state-of-the-art inspection accuracy and shows great potential for use in edge-computing-enabled smart industries.  
### Parallel Pre-trained Transformers (PPT) for Synthetic Data-based Instance Segmentation. (arXiv:2206.10845v1 [cs.CV])
- Authors : Ming Li, Jie Wu, Jinhang Cai, Jie Qin, Yuxi Ren, Xuefeng Xiao, Min Zheng, Rui Wang, Xin Pan
- Link : [http://arxiv.org/abs/2206.10845](http://arxiv.org/abs/2206.10845)
> ABSTRACT  :  Recently, Synthetic data-based Instance Segmentation has become an exceedingly favorable optimization paradigm since it leverages simulation rendering and physics to generate high-quality image-annotation pairs. In this paper, we propose a Parallel Pre-trained Transformers (PPT) framework to accomplish the synthetic data-based Instance Segmentation task. Specifically, we leverage the off-the-shelf pre-trained vision Transformers to alleviate the gap between natural and synthetic data, which helps to provide good generalization in the downstream synthetic data scene with few samples. **Swin**-B-based CBNet V2, **Swin**L-based CBNet V2 and **Swin**-L-based Uniformer are employed for parallel feature learning, and the results of these three models are fused by pixel-level Non-maximum Suppression (NMS) algorithm to obtain more robust results. The experimental results reveal that PPT ranks first in the CVPR2022 AVA Accessibility Vision and Autonomy Challenge, with a 65.155% mAP.  
### KiloNeuS: Implicit Neural Representations with Real-Time Global Illumination. (arXiv:2206.10885v1 [cs.CV])
- Authors : Stefano Esposito, Daniele Baieri, Stefan Zellmann, Emanuele Rodol
- Link : [http://arxiv.org/abs/2206.10885](http://arxiv.org/abs/2206.10885)
> ABSTRACT  :  The latest trends in inverse rendering techniques for reconstruction use neural networks to learn 3D representations as neural fields. **NeRF**-based techniques fit multi-layer perceptrons (MLPs) to a set of training images to estimate a radiance field which can then be rendered from any virtual camera by means of volume rendering algorithms. Major drawbacks of these representations are the lack of well-defined surfaces and non-interactive rendering times, as wide and deep MLPs must be queried millions of times per single frame. These limitations have recently been singularly overcome, but managing to accomplish this simultaneously opens up new use cases. We present KiloNeuS, a new neural object representation that can be rendered in path-traced scenes at interactive frame rates. KiloNeuS enables the simulation of realistic light interactions between neural and classic primitives in shared scenes, and it demonstrably performs in real-time with plenty of room for future optimizations and extensions.  
### A High Resolution Multi-**exposure** Stereoscopic Image & Video Database of Natural Scenes. (arXiv:2206.11095v1 [cs.CV])
- Authors : Rohit Choudhary, Mansi Sharma, Aditya Wadaskar
- Link : [http://arxiv.org/abs/2206.11095](http://arxiv.org/abs/2206.11095)
> ABSTRACT  :  Immersive displays such as VR headsets, AR glasses, Multiview displays, Free point televisions have emerged as a new class of display technologies in recent years, offering a better visual experience and viewer engagement as compared to conventional displays. With the evolution of 3D video and display technologies, the consumer market for **High Dynamic Range** (**HDR**) cameras and displays is quickly growing. The lack of appropriate experimental data is a critical hindrance for the development of primary research efforts in the field of 3D **HDR** video technology. Also, the unavailability of sufficient real world multi-**exposure** experimental dataset is a major bottleneck for **HDR** imaging research, thereby limiting the quality of experience (QoE) for the viewers. In this paper, we introduce a diversified stereoscopic multi-**exposure** dataset captured within the campus of Indian Institute of Technology Madras, which is home to a diverse flora and fauna. The dataset is captured using ZED stereoscopic camera and provides intricate scenes of outdoor locations such as gardens, roadside views, festival venues, buildings and indoor locations such as academic and residential areas. The proposed dataset accommodates wide depth range, complex depth structure, complicate object movement, illumination variations, rich color dynamics, texture discrepancy in addition to significant randomness introduced by moving camera and background motion. The proposed dataset is made publicly available to the research community. Furthermore, the procedure for capturing, aligning and calibrating multi-**exposure** stereo videos and images is described in detail. Finally, we have discussed the progress, challenges, potential use cases and future research opportunities with respect to **HDR** imaging, depth estimation, consistent tone mapping and 3D **HDR** coding.  
### Towards Robust Blind Face **Restoration** with Codebook Lookup Transformer. (arXiv:2206.11253v1 [cs.CV])
- Authors : Shangchen Zhou, **Chongyi Li**, Chen Change
- Link : [http://arxiv.org/abs/2206.11253](http://arxiv.org/abs/2206.11253)
> ABSTRACT  :  Blind face **restoration** is a highly ill-posed problem that often requires auxiliary guidance to 1) improve the mapping from degraded inputs to desired outputs, or 2) complement high-quality details lost in the inputs. In this paper, we demonstrate that a learned discrete codebook prior in a small proxy space largely reduces the uncertainty and ambiguity of **restoration** mapping by casting blind face **restoration** as a code prediction task, while providing rich visual atoms for generating high-quality faces. Under this paradigm, we propose a Transformer-based prediction network, named CodeFormer, to model global composition and context of the low-quality faces for code prediction, enabling the discovery of natural faces that closely approximate the target faces even when the inputs are severely degraded. To enhance the adaptiveness for different degradation, we also propose a controllable feature transformation module that allows a flexible trade-off between fidelity and quality. Thanks to the expressive codebook prior and global modeling, CodeFormer outperforms state of the arts in both quality and fidelity, showing superior robustness to degradation. Extensive experimental results on synthetic and real-world datasets verify the effectiveness of our method.  
### Mining for Strong Gravitational Lenses with Self-supervised Learning. (arXiv:2110.00023v2 [astro-ph.IM] UPDATED)
- Authors : George Stein, Jacqueline Blaum, Peter Harrington, Tomislav Medan, Zarija Lukic
- Link : [http://arxiv.org/abs/2110.00023](http://arxiv.org/abs/2110.00023)
> ABSTRACT  :  We employ self-supervised representation learning to distill information from 76 million galaxy images from the **Dark** Energy Spectroscopic Instrument Legacy Imaging Surveys' Data Release 9. Targeting the identification of new strong gravitational lens candidates, we first create a rapid similarity search tool to discover new strong lenses given only a single labelled example. We then show how training a simple linear classifier on the self-supervised representations, requiring only a few minutes on a CPU, can automatically classify strong lenses with great efficiency. We present 1192 new strong lens candidates that we identified through a brief visual identification campaign, and release an interactive web-based similarity search tool and the top network predictions to facilitate crowd-sourcing rapid discovery of additional strong gravitational lenses and other rare objects: https://github.com/georgestein/ssl-legacysurvey.  
### Domain Adaptation for Underwater Image **Enhancement** via Content and Style Separation. (arXiv:2202.08537v2 [cs.CV] UPDATED)
- Authors : Wei Chen, Chang Pei
- Link : [http://arxiv.org/abs/2202.08537](http://arxiv.org/abs/2202.08537)
> ABSTRACT  :  Underwater image suffer from color cast, low contrast and hazy effect due to light absorption, refraction and scattering, which degraded the high-level application, e.g, object detection and object tracking. Recent learning-based methods demonstrate astonishing performance on underwater image **enhancement**, however, most of these works use synthetic pair data for supervised learning and ignore the domain gap to real-world data. To solve this problem, we propose a domain adaptation framework for underwater image **enhancement** via content and style separation, different from prior works of domain adaptation for underwater image **enhancement**, which target to minimize the latent discrepancy of synthesis and real-world data, we aim to separate encoded feature into content and style latent and distinguish style latent from different domains, i.e. synthesis, real-world underwater and clean domain, and process domain adaptation and image **enhancement** in latent space. By latent manipulation, our model provide a user interact interface to adjust different enhanced level for continuous change. Experiment on various public real-world underwater benchmarks demonstrate that the proposed framework is capable to perform domain adaptation for underwater image **enhancement** and outperform various state-of-the-art underwater image **enhancement** algorithms in quantity and quality. The model and source code will be available at https://github.com/fordevoted/UIESS  
### Edge-enhanced Feature Distillation Network for Efficient Super-Resolution. (arXiv:2204.08759v2 [cs.CV] UPDATED)
- Authors : Yan Wang
- Link : [http://arxiv.org/abs/2204.08759](http://arxiv.org/abs/2204.08759)
> ABSTRACT  :  With the recently massive development in convolution neural networks, numerous lightweight CNN-based image super-resolution methods have been proposed for practical deployments on edge devices. However, most existing methods focus on one specific aspect: network or loss design, which leads to the difficulty of minimizing the model size. To address the issue, we conclude block devising, architecture searching, and loss design to obtain a more efficient SR structure. In this paper, we proposed an edge-enhanced feature distillation network, named EFDN, to preserve the high-frequency information under constrained resources. In detail, we build an edge-enhanced convolution block based on the existing reparameterization methods. Meanwhile, we propose edge-enhanced gradient loss to calibrate the reparameterized path training. Experimental results show that our edge-enhanced strategies preserve the edge and significantly improve the final **restoration** quality. Code is available at https://github.com/icandle/EFDN.  
### Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09193](http://arxiv.org/abs/2206.09193)
> ABSTRACT  :  Over the past few years deep learning-based techniques such as Generative Adversarial Networks (GANs) have significantly improved solutions to image super-resolution and image-to-image translation problems. In this paper, we propose a solution to the joint problem of image super-resolution and multi-modality image-to-image translation. The problem can be stated as the recovery of a high-resolution image in a modality, given a low-resolution observation of the same image in an alternative modality. Our paper offers two models to address this problem and will be evaluated on the recovery of high-resolution day images given low-resolution **night** images of the same scene. Promising qualitative and quantitative results will be presented for each model.  
### Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09210](http://arxiv.org/abs/2206.09210)
> ABSTRACT  :  Deep learning techniques, especially Generative Adversarial Networks (GANs) have significantly improved image inpainting and image-to-image translation tasks over the past few years. To the best of our knowledge, the problem of combining the image inpainting task with the multi-modality image-to-image translation remains intact. In this paper, we propose a model to address this problem. The model will be evaluated on combined **night**-to-day image translation and inpainting, along with promising qualitative and quantitative results.  
## eess.IV
---
### No Attention is Needed: Grouped Spatial-temporal Shift for Simple and Efficient Video Restorers. (arXiv:2206.10810v1 [eess.IV])
- Authors : Dasong Li, Xiaoyu Shi, Yi Zhang, Xiaogang Wang, Hongwei Qin, Hongsheng Li
- Link : [http://arxiv.org/abs/2206.10810](http://arxiv.org/abs/2206.10810)
> ABSTRACT  :  Video **restoration**, aiming at restoring clear frames from degraded videos, has been attracting increasing attention. Video **restoration** is required to establish the temporal correspondences from multiple misaligned frames. To achieve that end, existing deep methods generally adopt complicated network architectures, such as integrating optical flow, deformable convolution, cross-frame or cross-pixel self-attention layers, resulting in expensive computational cost. We argue that with proper design, temporal information utilization in video **restoration** can be much more efficient and effective. In this study, we propose a simple, fast yet effective framework for video **restoration**. The key of our framework is the grouped spatial-temporal shift, which is simple and lightweight, but can implicitly establish inter-frame correspondences and achieve multi-frame aggregation. Coupled with basic 2D U-Nets for frame-wise encoding and decoding, such an efficient spatial-temporal shift module can effectively tackle the challenges in video **restoration**. Extensive experiments show that our framework surpasses previous state-of-the-art method with 43% of its computational cost on both video deblurring and video denoising.  
### A High Resolution Multi-**exposure** Stereoscopic Image & Video Database of Natural Scenes. (arXiv:2206.11095v1 [cs.CV])
- Authors : Rohit Choudhary, Mansi Sharma, Aditya Wadaskar
- Link : [http://arxiv.org/abs/2206.11095](http://arxiv.org/abs/2206.11095)
> ABSTRACT  :  Immersive displays such as VR headsets, AR glasses, Multiview displays, Free point televisions have emerged as a new class of display technologies in recent years, offering a better visual experience and viewer engagement as compared to conventional displays. With the evolution of 3D video and display technologies, the consumer market for **High Dynamic Range** (**HDR**) cameras and displays is quickly growing. The lack of appropriate experimental data is a critical hindrance for the development of primary research efforts in the field of 3D **HDR** video technology. Also, the unavailability of sufficient real world multi-**exposure** experimental dataset is a major bottleneck for **HDR** imaging research, thereby limiting the quality of experience (QoE) for the viewers. In this paper, we introduce a diversified stereoscopic multi-**exposure** dataset captured within the campus of Indian Institute of Technology Madras, which is home to a diverse flora and fauna. The dataset is captured using ZED stereoscopic camera and provides intricate scenes of outdoor locations such as gardens, roadside views, festival venues, buildings and indoor locations such as academic and residential areas. The proposed dataset accommodates wide depth range, complex depth structure, complicate object movement, illumination variations, rich color dynamics, texture discrepancy in addition to significant randomness introduced by moving camera and background motion. The proposed dataset is made publicly available to the research community. Furthermore, the procedure for capturing, aligning and calibrating multi-**exposure** stereo videos and images is described in detail. Finally, we have discussed the progress, challenges, potential use cases and future research opportunities with respect to **HDR** imaging, depth estimation, consistent tone mapping and 3D **HDR** coding.  
### Edge-enhanced Feature Distillation Network for Efficient Super-Resolution. (arXiv:2204.08759v2 [cs.CV] UPDATED)
- Authors : Yan Wang
- Link : [http://arxiv.org/abs/2204.08759](http://arxiv.org/abs/2204.08759)
> ABSTRACT  :  With the recently massive development in convolution neural networks, numerous lightweight CNN-based image super-resolution methods have been proposed for practical deployments on edge devices. However, most existing methods focus on one specific aspect: network or loss design, which leads to the difficulty of minimizing the model size. To address the issue, we conclude block devising, architecture searching, and loss design to obtain a more efficient SR structure. In this paper, we proposed an edge-enhanced feature distillation network, named EFDN, to preserve the high-frequency information under constrained resources. In detail, we build an edge-enhanced convolution block based on the existing reparameterization methods. Meanwhile, we propose edge-enhanced gradient loss to calibrate the reparameterized path training. Experimental results show that our edge-enhanced strategies preserve the edge and significantly improve the final **restoration** quality. Code is available at https://github.com/icandle/EFDN.  
### Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09193](http://arxiv.org/abs/2206.09193)
> ABSTRACT  :  Over the past few years deep learning-based techniques such as Generative Adversarial Networks (GANs) have significantly improved solutions to image super-resolution and image-to-image translation problems. In this paper, we propose a solution to the joint problem of image super-resolution and multi-modality image-to-image translation. The problem can be stated as the recovery of a high-resolution image in a modality, given a low-resolution observation of the same image in an alternative modality. Our paper offers two models to address this problem and will be evaluated on the recovery of high-resolution day images given low-resolution **night** images of the same scene. Promising qualitative and quantitative results will be presented for each model.  
### Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09210](http://arxiv.org/abs/2206.09210)
> ABSTRACT  :  Deep learning techniques, especially Generative Adversarial Networks (GANs) have significantly improved image inpainting and image-to-image translation tasks over the past few years. To the best of our knowledge, the problem of combining the image inpainting task with the multi-modality image-to-image translation remains intact. In this paper, we propose a model to address this problem. The model will be evaluated on combined **night**-to-day image translation and inpainting, along with promising qualitative and quantitative results.  
## cs.LG
---
### KiloNeuS: Implicit Neural Representations with Real-Time Global Illumination. (arXiv:2206.10885v1 [cs.CV])
- Authors : Stefano Esposito, Daniele Baieri, Stefan Zellmann, Emanuele Rodol
- Link : [http://arxiv.org/abs/2206.10885](http://arxiv.org/abs/2206.10885)
> ABSTRACT  :  The latest trends in inverse rendering techniques for reconstruction use neural networks to learn 3D representations as neural fields. **NeRF**-based techniques fit multi-layer perceptrons (MLPs) to a set of training images to estimate a radiance field which can then be rendered from any virtual camera by means of volume rendering algorithms. Major drawbacks of these representations are the lack of well-defined surfaces and non-interactive rendering times, as wide and deep MLPs must be queried millions of times per single frame. These limitations have recently been singularly overcome, but managing to accomplish this simultaneously opens up new use cases. We present KiloNeuS, a new neural object representation that can be rendered in path-traced scenes at interactive frame rates. KiloNeuS enables the simulation of realistic light interactions between neural and classic primitives in shared scenes, and it demonstrably performs in real-time with plenty of room for future optimizations and extensions.  
### A Systematic Comparison of Phonetic Aware Techniques for Speech **Enhancement**. (arXiv:2206.11000v1 [eess.AS])
- Authors : Or Tal, Moshe Mandel, Felix Kreuk, Yossi Adi
- Link : [http://arxiv.org/abs/2206.11000](http://arxiv.org/abs/2206.11000)
> ABSTRACT  :  Speech **enhancement** has seen great improvement in recent years using end-to-end neural networks. However, most models are agnostic to the spoken phonetic content. Recently, several studies suggested phonetic-aware speech **enhancement**, mostly using perceptual supervision. Yet, injecting phonetic features during model optimization can take additional forms (e.g., model conditioning). In this paper, we conduct a systematic comparison between different methods of incorporating phonetic information in a speech **enhancement** model. By conducting a series of controlled experiments, we observe the influence of different phonetic content models as well as various feature-injection techniques on **enhancement** performance, considering both causal and non-causal models. Specifically, we evaluate three settings for injecting phonetic information, namely: i) feature conditioning; ii) perceptual supervision; and iii) regularization. Phonetic features are obtained using an intermediate layer of either a supervised pre-trained Automatic Speech Recognition (ASR) model or by using a pre-trained Self-Supervised Learning (SSL) model. We further observe the effect of choosing different embedding layers on performance, considering both manual and learned configurations. Results suggest that using a SSL model as phonetic features outperforms the ASR one in most cases. Interestingly, the conditioning setting performs best among the evaluated configurations.  
### Answer Fast: Accelerating BERT on the Tensor Streaming Processor. (arXiv:2206.11062v1 [cs.LG])
- Authors : Ibrahim Ahmed, Sahil Parmar, Matthew Boyd, Michael Beidler, Kris Kang, Bill Liu, Kyle Roach, John Kim, Dennis Abts
- Link : [http://arxiv.org/abs/2206.11062](http://arxiv.org/abs/2206.11062)
> ABSTRACT  :  Transformers have become a predominant machine learning workload, they are not only the de-facto standard for natural language processing tasks, but they are also being deployed in other domains such as vision and speech recognition. Many of the transformer-based applications are real-time systems such as machine translation and web search. These **real time** systems often come with strict end-to-end inference latency requirements. Unfortunately, while the majority of the transformer computation comes from matrix multiplications, transformers also include several non-linear components that tend to become the bottleneck during an inference. In this work, we accelerate the inference of BERT models on the tensor streaming processor. By carefully fusing all the nonlinear components with the matrix multiplication components, we are able to efficiently utilize the on-chip matrix multiplication units resulting in a deterministic tail latency of 130 $\mu$s for a batch-1 inference through BERT-base, which is 6X faster than the current state-of-the-art.  
### On the Role of Spatial, Spectral, and Temporal Processing for DNN-based Non-linear Multi-channel Speech **Enhancement**. (arXiv:2206.11181v1 [eess.AS])
- Authors : Kristina Tesch, Hendrik Mohrmann, Timo Gerkmann
- Link : [http://arxiv.org/abs/2206.11181](http://arxiv.org/abs/2206.11181)
> ABSTRACT  :  Employing deep neural networks (DNNs) to directly learn filters for multi-channel speech **enhancement** has potentially two key advantages over a traditional approach combining a linear spatial filter with an independent tempo-spectral post-filter: 1) non-linear spatial filtering allows to overcome potential restrictions originating from a linear processing model and 2) joint processing of spatial and tempo-spectral information allows to exploit interdependencies between different sources of information. A variety of DNN-based non-linear filters have been proposed recently, for which good **enhancement** performance is reported. However, little is known about the internal mechanisms which turns network architecture design into a game of chance. Therefore, in this paper, we perform experiments to better understand the internal processing of spatial, spectral and temporal information by DNN-based non-linear filters. On the one hand, our experiments in a difficult speech extraction scenario confirm the importance of non-linear spatial filtering, which outperforms an oracle linear spatial filter by 0.24 POLQA score. On the other hand, we demonstrate that joint processing results in a large performance gap of 0.4 POLQA score between network architectures exploiting spectral versus temporal information besides spatial information.  
### Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09193](http://arxiv.org/abs/2206.09193)
> ABSTRACT  :  Over the past few years deep learning-based techniques such as Generative Adversarial Networks (GANs) have significantly improved solutions to image super-resolution and image-to-image translation problems. In this paper, we propose a solution to the joint problem of image super-resolution and multi-modality image-to-image translation. The problem can be stated as the recovery of a high-resolution image in a modality, given a low-resolution observation of the same image in an alternative modality. Our paper offers two models to address this problem and will be evaluated on the recovery of high-resolution day images given low-resolution **night** images of the same scene. Promising qualitative and quantitative results will be presented for each model.  
### Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
- Authors : Aref Abedjooy, Mehran Ebrahimi
- Link : [http://arxiv.org/abs/2206.09210](http://arxiv.org/abs/2206.09210)
> ABSTRACT  :  Deep learning techniques, especially Generative Adversarial Networks (GANs) have significantly improved image inpainting and image-to-image translation tasks over the past few years. To the best of our knowledge, the problem of combining the image inpainting task with the multi-modality image-to-image translation remains intact. In this paper, we propose a model to address this problem. The model will be evaluated on combined **night**-to-day image translation and inpainting, along with promising qualitative and quantitative results.  
## cs.AI
---
### A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing. (arXiv:2206.10830v1 [cs.CV])
- Authors : Haiming Yao, Wenyong Yu, Xue Wang
- Link : [http://arxiv.org/abs/2206.10830](http://arxiv.org/abs/2206.10830)
> ABSTRACT  :  Recent advances in the industrial inspection of textured surfaces-in the form of visual inspection-have made such inspections possible for efficient, flexible manufacturing systems. We propose an unsupervised feature memory rearrangement network (FMR-Net) to accurately detect various textural defects simultaneously. Consistent with mainstream methods, we adopt the idea of background reconstruction; however, we innovatively utilize artificial synthetic defects to enable the model to recognize anomalies, while traditional wisdom relies only on defect-free samples. First, we employ an encoding module to obtain multiscale features of the textured surface. Subsequently, a contrastive-learning-based memory feature module (CMFM) is proposed to obtain discriminative representations and construct a normal feature memory bank in the latent space, which can be employed as a substitute for defects and fast anomaly scores at the patch level. Next, a novel global feature rearrangement module (GFRM) is proposed to further suppress the reconstruction of residual defects. Finally, a decoding module utilizes the restored features to reconstruct the normal texture background. In addition, to improve inspection performance, a two-phase training strategy is utilized for accurate defect **restoration** refinement, and we exploit a multimodal inspection method to achieve noise-robust defect localization. We verify our method through extensive experiments and test its practical deployment in collaborative edge--cloud intelligent manufacturing scenarios by means of a multilevel detection method, demonstrating that FMR-Net exhibits state-of-the-art inspection accuracy and shows great potential for use in edge-computing-enabled smart industries.  
### Parallel Pre-trained Transformers (PPT) for Synthetic Data-based Instance Segmentation. (arXiv:2206.10845v1 [cs.CV])
- Authors : Ming Li, Jie Wu, Jinhang Cai, Jie Qin, Yuxi Ren, Xuefeng Xiao, Min Zheng, Rui Wang, Xin Pan
- Link : [http://arxiv.org/abs/2206.10845](http://arxiv.org/abs/2206.10845)
> ABSTRACT  :  Recently, Synthetic data-based Instance Segmentation has become an exceedingly favorable optimization paradigm since it leverages simulation rendering and physics to generate high-quality image-annotation pairs. In this paper, we propose a Parallel Pre-trained Transformers (PPT) framework to accomplish the synthetic data-based Instance Segmentation task. Specifically, we leverage the off-the-shelf pre-trained vision Transformers to alleviate the gap between natural and synthetic data, which helps to provide good generalization in the downstream synthetic data scene with few samples. **Swin**-B-based CBNet V2, **Swin**L-based CBNet V2 and **Swin**-L-based Uniformer are employed for parallel feature learning, and the results of these three models are fused by pixel-level Non-maximum Suppression (NMS) algorithm to obtain more robust results. The experimental results reveal that PPT ranks first in the CVPR2022 AVA Accessibility Vision and Autonomy Challenge, with a 65.155% mAP.  
### Generalizing Multimodal Pre-training into Multilingual via Language Acquisition. (arXiv:2206.11091v1 [cs.CL])
- Authors : Liang Zhang, Anwen Hu, Qin Jin
- Link : [http://arxiv.org/abs/2206.11091](http://arxiv.org/abs/2206.11091)
> ABSTRACT  :  English-based Vision-Language Pre-training (VLP) has achieved great success in various downstream tasks. Some efforts have been taken to generalize this success to non-English languages through Multilingual Vision-Language Pre-training (M-VLP). However, due to the large number of languages, M-VLP models often require huge computing resources and cannot be flexibly extended to new languages. In this work, we propose a \textbf{M}ulti\textbf{L}ingual \textbf{A}cquisition (MLA) framework that can easily generalize a monolingual Vision-Language Pre-training model into multilingual. Specifically, we design a lightweight language acquisition encoder based on state-of-the-art monolingual VLP models. We further propose a two-stage training strategy to optimize the language acquisition encoder, namely the Native Language Transfer stage and the Language **Exposure** stage. With much less multilingual training data and computing resources, our model achieves state-of-the-art performance on multilingual image-text and video-text retrieval benchmarks.  
# Paper List
---
## cs.CV
---
**110** new papers in cs.CV:-) 
1. CoCoPIE XGen: A Full-Stack AI-Oriented Optimizing Framework. (arXiv:2206.10620v1 [cs.LG])
2. BOSS: A Benchmark for Human Belief Prediction in Object-context Scenarios. (arXiv:2206.10665v1 [cs.CV])
3. SCIM: Simultaneous Clustering, Inference, and Mapping for Open-World Semantic Scene Understanding. (arXiv:2206.10670v1 [cs.RO])
4. Natural Backdoor Datasets. (arXiv:2206.10673v1 [cs.CV])
5. Learning Continuous Rotation Canonicalization with Radial Beam Sampling. (arXiv:2206.10690v1 [cs.CV])
6. Multi-level Domain Adaptation for Lane Detection. (arXiv:2206.10692v1 [cs.CV])
7. TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning. (arXiv:2206.10698v1 [cs.CV])
8. Panoramic Panoptic Segmentation: Insights Into Surrounding Parsing for Mobile Agents via Unsupervised Contrastive Learning. (arXiv:2206.10711v1 [cs.CV])
9. Deep Metric Color Embeddings for Splicing Localization in Severely Degraded Images. (arXiv:2206.10737v1 [cs.CV])
10. Floor Map Reconstruction Through Radio Sensing and Learning By a Large Intelligent Surface. (arXiv:2206.10750v1 [eess.SP])
11. Towards Ground Truth for Single Image Deraining. (arXiv:2206.10779v1 [cs.CV])
12. Scaling Autoregressive Models for Content-Rich Text-to-Image Generation. (arXiv:2206.10789v1 [cs.CV])
13. Imitation Learning for Generalizable Self-driving Policy with Sim-to-real Transfer. (arXiv:2206.10797v1 [cs.LG])
14. SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI. (arXiv:2206.10802v1 [eess.IV])
15. SSMI: How to Make Objects of Interest Disappear without Accessing Object Detectors?. (arXiv:2206.10809v1 [cs.CV])
16. No Attention is Needed: Grouped Spatial-temporal Shift for Simple and Efficient Video Restorers. (arXiv:2206.10810v1 [eess.IV])
17. Fighting Fire with Fire: Avoiding DNN Shortcuts through Priming. (arXiv:2206.10816v1 [cs.LG])
18. Coupling Visual Semantics of Artificial Neural Networks and Human Brain Function via Synchronized Activations. (arXiv:2206.10821v1 [cs.CV])
19. A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing. (arXiv:2206.10830v1 [cs.CV])
20. MultiEarth 2022 Deforestation Challenge -- ForestGump. (arXiv:2206.10831v1 [cs.CV])
21. Learning Debiased Classifier with Biased Committee. (arXiv:2206.10843v1 [cs.LG])
22. Parallel Pre-trained Transformers (PPT) for Synthetic Data-based Instance Segmentation. (arXiv:2206.10845v1 [cs.CV])
23. UniCon+: ICTCAS-UCAS Submission to the AVA-ActiveSpeaker Task at ActivityNet Challenge 2022. (arXiv:2206.10861v1 [cs.CV])
24. NVIDIA-UNIBZ Submission for EPIC-KITCHENS-100 Action Anticipation Challenge 2022. (arXiv:2206.10869v1 [cs.CV])
25. Feature Re-calibration based MIL for Whole Slide Image Classification. (arXiv:2206.10878v1 [cs.CV])
26. Symmetric Network with Spatial Relationship Modeling for Natural Language-based Vehicle Retrieval. (arXiv:2206.10879v1 [cs.CV])
27. KiloNeuS: Implicit Neural Representations with Real-Time Global Illumination. (arXiv:2206.10885v1 [cs.CV])
28. Optical Flow Regularization of Implicit Neural Representations for Video Frame Interpolation. (arXiv:2206.10886v1 [cs.CV])
29. I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation. (arXiv:2206.10892v1 [cs.CV])
30. S2TNet: Spatio-Temporal Transformer Networks for Trajectory Prediction in Autonomous Driving. (arXiv:2206.10902v1 [cs.CV])
31. UniUD-FBK-UB-UniBZ Submission to the EPIC-Kitchens-100 Multi-Instance Retrieval Challenge 2022. (arXiv:2206.10903v1 [cs.CV])
32. SpA-Former: Transformer image shadow detection and removal via spatial attention. (arXiv:2206.10910v1 [cs.CV])
33. Influence of uncertainty estimation techniques on false-positive reduction in liver lesion detection. (arXiv:2206.10911v1 [eess.IV])
34. AI-based software for lung nodule detection in chest X-rays -- Time for a second reader approach?. (arXiv:2206.10912v1 [eess.IV])
35. Understanding the effect of sparsity on neural networks robustness. (arXiv:2206.10915v1 [cs.CV])
36. A Study on the Evaluation of Generative Models. (arXiv:2206.10935v1 [cs.LG])
37. Polar Parametrization for Vision-based Surround-View 3D Detection. (arXiv:2206.10965v1 [cs.CV])
38. Single Morphing Attack Detection using Siamese Network and Few-shot Learning. (arXiv:2206.10969v1 [cs.CV])
39. AdvSmo: Black-box Adversarial Attack by Smoothing Linear Structure of Texture. (arXiv:2206.10988v1 [cs.CV])
40. Identity Documents Authentication based on Forgery Detection of Guilloche Pattern. (arXiv:2206.10989v1 [cs.CV])
41. Prototypical Contrastive Language Image Pretraining. (arXiv:2206.10996v1 [cs.CV])
42. Weakly-supervised Action Localization via Hierarchical Mining. (arXiv:2206.11011v1 [cs.CV])
43. Automated GI tract segmentation using deep learning. (arXiv:2206.11048v1 [eess.IV])
44. Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer. (arXiv:2206.11053v1 [cs.CV])
45. A Unified and Biologically-Plausible Relational Graph Representation of Vision Transformers. (arXiv:2206.11073v1 [cs.NE])
46. Motion Gait: Gait Recognition via Motion Excitation. (arXiv:2206.11080v1 [cs.CV])
47. A High Resolution Multi-**exposure** Stereoscopic Image & Video Database of Natural Scenes. (arXiv:2206.11095v1 [cs.CV])
48. ICC++: Explainable Image Retrieval for Art Historical Corpora using Image Composition Canvas. (arXiv:2206.11115v1 [cs.CV])
49. CNN-based fully automatic wrist cartilage volume quantification in MR Image. (arXiv:2206.11127v1 [eess.IV])
50. Open Vocabulary Object Detection with Proposal Mining and Prediction Equalization. (arXiv:2206.11134v1 [cs.CV])
51. Hybrid Physical Metric For 6-DoF Grasp Pose Detection. (arXiv:2206.11141v1 [cs.RO])
52. Optimal transport meets noisy label robust loss and MixUp regularization for domain adaptation. (arXiv:2206.11180v1 [cs.CV])
53. Facke: a Survey on Generative Models for Face Swapping. (arXiv:2206.11203v1 [cs.CV])
54. VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives. (arXiv:2206.11212v1 [cs.CV])
55. Correct and Certify: A New Approach to Self-Supervised 3D-Object Perception. (arXiv:2206.11215v1 [cs.CV])
56. Business Document Information Extraction: Towards Practical Benchmarks. (arXiv:2206.11229v1 [cs.IR])
57. Depth-aware Glass Surface Detection with Cross-modal Context Mining. (arXiv:2206.11250v1 [cs.CV])
58. Behavior Transformers: Cloning $k$ modes with one stone. (arXiv:2206.11251v1 [cs.LG])
59. Towards Robust Blind Face **Restoration** with Codebook Lookup Transformer. (arXiv:2206.11253v1 [cs.CV])
60. SegGroup: Seg-Level Supervision for 3D Instance and Semantic Segmentation. (arXiv:2012.10217v3 [cs.CV] UPDATED)
61. Cross-modal Learning for Domain Adaptation in 3D Semantic Segmentation. (arXiv:2101.07253v2 [cs.CV] UPDATED)
62. Making Generated Images Hard To Spot: A Transferable Attack On Synthetic Image Detectors. (arXiv:2104.12069v2 [cs.CV] UPDATED)
63. Kernel Clustering with Sigmoid-based Regularization for Efficient Segmentation of Sequential Data. (arXiv:2106.11541v2 [cs.LG] UPDATED)
64. Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v3 [cs.CV] UPDATED)
65. Visual SLAM with Graph-Cut Optimized Multi-Plane Reconstruction. (arXiv:2108.04281v2 [cs.CV] UPDATED)
66. Robust fine-tuning of zero-shot models. (arXiv:2109.01903v3 [cs.CV] UPDATED)
67. Mining for Strong Gravitational Lenses with Self-supervised Learning. (arXiv:2110.00023v2 [astro-ph.IM] UPDATED)
68. Detecting Dementia from Speech and Transcripts using Transformers. (arXiv:2110.14769v2 [cs.CL] UPDATED)
69. LiT: Zero-Shot Transfer with Locked-image text Tuning. (arXiv:2111.07991v3 [cs.CV] UPDATED)
70. CDistNet: Perceiving Multi-Domain Character Distance for Robust Text Recognition. (arXiv:2111.11011v3 [cs.CV] UPDATED)
71. Talk-to-Resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot. (arXiv:2111.11099v2 [cs.RO] UPDATED)
72. Intuitive Shape Editing in Latent Space. (arXiv:2111.12488v3 [cs.CV] UPDATED)
73. Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v4 [cs.CV] UPDATED)
74. 3D Instance Segmentation of MVS Buildings. (arXiv:2112.09902v2 [cs.CV] UPDATED)
75. Scene Graph Generation: A Comprehensive Survey. (arXiv:2201.00443v2 [cs.CV] UPDATED)
76. 3D Face Morphing Attacks: Generation, Vulnerability and Detection. (arXiv:2201.03454v2 [cs.CV] UPDATED)
77. Adversarial Masking for Self-Supervised Learning. (arXiv:2201.13100v2 [cs.CV] UPDATED)
78. Metrics for saliency map evaluation of deep learning explanation methods. (arXiv:2201.13291v3 [cs.CV] UPDATED)
79. GiraffeDet: A Heavy-Neck Paradigm for Object Detection. (arXiv:2202.04256v2 [cs.CV] UPDATED)
80. Domain Adaptation for Underwater Image **Enhancement** via Content and Style Separation. (arXiv:2202.08537v2 [cs.CV] UPDATED)
81. Interpolation-based Contrastive Learning for Few-Label Semi-Supervised Learning. (arXiv:2202.11915v2 [cs.CV] UPDATED)
82. Understanding person identification via gait. (arXiv:2203.04179v3 [cs.CR] UPDATED)
83. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. (arXiv:2203.05482v2 [cs.LG] UPDATED)
84. HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR. (arXiv:2203.09215v3 [cs.CV] UPDATED)
85. Multi-similarity based Hyperrelation Network for few-shot segmentation. (arXiv:2203.09550v4 [cs.CV] UPDATED)
86. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v2 [cs.LG] UPDATED)
87. End-to-end Autonomous Driving with Semantic Depth Cloud Mapping and Multi-agent. (arXiv:2204.05513v2 [cs.RO] UPDATED)
88. Edge-enhanced Feature Distillation Network for Efficient Super-Resolution. (arXiv:2204.08759v2 [cs.CV] UPDATED)
89. Learning to Purification for Unsupervised Person Re-identification. (arXiv:2204.09931v2 [cs.CV] UPDATED)
90. Non-Isometric Shape Matching via Functional Maps on Landmark-Adapted Bases. (arXiv:2205.04800v2 [cs.CV] UPDATED)
91. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v2 [cs.LG] UPDATED)
92. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v2 [cs.CV] UPDATED)
93. Efficient visual object representation using a biologically plausible spike-latency code and winner-take-all inhibition. (arXiv:2205.10338v2 [cs.CV] UPDATED)
94. Scalable and Efficient Training of Large Convolutional Neural Networks with Differential Privacy. (arXiv:2205.10683v2 [cs.LG] UPDATED)
95. An Effective Fusion Method to Enhance the Robustness of CNN. (arXiv:2205.15582v2 [cs.CV] UPDATED)
96. Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs for Medical Image Segmentation and Detection. (arXiv:2206.01736v2 [eess.IV] UPDATED)
97. MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive Learning. (arXiv:2206.03010v3 [cs.CV] UPDATED)
98. SeATrans: Learning Segmentation-Assisted diagnosis model via Transformer. (arXiv:2206.05763v2 [cs.CV] UPDATED)
99. Dual-Stream Transformer with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v2 [eess.IV] UPDATED)
100. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v2 [q-bio.NC] UPDATED)
101. Learning Using Privileged Information for Zero-Shot Action Recognition. (arXiv:2206.08632v2 [cs.CV] UPDATED)
102. Local Slot Attention for Vision-and-Language Navigation. (arXiv:2206.08645v2 [cs.CV] UPDATED)
103. Bear the Query in Mind: Visual Grounding with Query-conditioned Convolution. (arXiv:2206.09114v2 [cs.CV] UPDATED)
104. Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
105. Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
106. SAViR-T: Spatially Attentive Visual Reasoning with Transformers. (arXiv:2206.09265v2 [cs.CV] UPDATED)
107. Winning the CVPR'2022 AQTC Challenge: A Two-stage Function-centric Approach. (arXiv:2206.09597v2 [cs.CV] UPDATED)
108. Semantic Labeling of High Resolution Images Using EfficientUNets and Transformers. (arXiv:2206.09731v2 [cs.CV] UPDATED)
109. Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive Representation Learning. (arXiv:2206.10137v2 [cs.CV] UPDATED)
110. Learning to Estimate and Refine Fluid Motion with Physical Dynamics. (arXiv:2206.10480v2 [cs.LG] UPDATED)
## eess.IV
---
**25** new papers in eess.IV:-) 
1. Asymmetric Learned Image Compression with Multi-Scale Residual Block, Importance Map, and Post-Quantization Filtering. (arXiv:2206.10618v1 [eess.IV])
2. Panoramic Panoptic Segmentation: Insights Into Surrounding Parsing for Mobile Agents via Unsupervised Contrastive Learning. (arXiv:2206.10711v1 [cs.CV])
3. SVoRT: Iterative Transformer for Slice-to-Volume Registration in Fetal Brain MRI. (arXiv:2206.10802v1 [eess.IV])
4. No Attention is Needed: Grouped Spatial-temporal Shift for Simple and Efficient Video Restorers. (arXiv:2206.10810v1 [eess.IV])
5. MultiEarth 2022 Deforestation Challenge -- ForestGump. (arXiv:2206.10831v1 [cs.CV])
6. Influence of uncertainty estimation techniques on false-positive reduction in liver lesion detection. (arXiv:2206.10911v1 [eess.IV])
7. AI-based software for lung nodule detection in chest X-rays -- Time for a second reader approach?. (arXiv:2206.10912v1 [eess.IV])
8. Hierarchical Sampling based Particle Filter for Visual-inertial Gimbal in the Wild. (arXiv:2206.10981v1 [cs.RO])
9. Automated GI tract segmentation using deep learning. (arXiv:2206.11048v1 [eess.IV])
10. Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer. (arXiv:2206.11053v1 [cs.CV])
11. A High Resolution Multi-**exposure** Stereoscopic Image & Video Database of Natural Scenes. (arXiv:2206.11095v1 [cs.CV])
12. CNN-based fully automatic wrist cartilage volume quantification in MR Image. (arXiv:2206.11127v1 [eess.IV])
13. Intensity-Sensitive Similarity Indexes for Image Quality Assessment. (arXiv:2206.11207v1 [eess.IV])
14. Deep reinforcement learning for fMRI prediction of Autism Spectrum Disorder. (arXiv:2206.11224v1 [q-bio.NC])
15. Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review. (arXiv:2206.11233v1 [q-bio.NC])
16. Making Generated Images Hard To Spot: A Transferable Attack On Synthetic Image Detectors. (arXiv:2104.12069v2 [cs.CV] UPDATED)
17. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v2 [cs.LG] UPDATED)
18. Learning-based Lossless Point Cloud Geometry Coding using Sparse Tensors. (arXiv:2204.05043v2 [eess.IV] UPDATED)
19. Edge-enhanced Feature Distillation Network for Efficient Super-Resolution. (arXiv:2204.08759v2 [cs.CV] UPDATED)
20. Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs for Medical Image Segmentation and Detection. (arXiv:2206.01736v2 [eess.IV] UPDATED)
21. Dual-Stream Transformer with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v2 [eess.IV] UPDATED)
22. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v2 [q-bio.NC] UPDATED)
23. Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
24. Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
25. Semantic Labeling of High Resolution Images Using EfficientUNets and Transformers. (arXiv:2206.09731v2 [cs.CV] UPDATED)
## cs.LG
---
**226** new papers in cs.LG:-) 
1. Can Foundation Models Talk Causality?. (arXiv:2206.10591v1 [cs.AI])
2. Identifying Electrocardiogram Abnormalities Using a Handcrafted-Rule-Enhanced Neural Network. (arXiv:2206.10592v1 [cs.AI])
3. A Survey on Computational Intelligence-based Transfer Learning. (arXiv:2206.10593v1 [cs.AI])
4. Demystifying the Base and Novel Performances for Few-shot Class-incremental Learning. (arXiv:2206.10596v1 [cs.LG])
5. Deep Inverse Reinforcement Learning for Route Choice Modeling. (arXiv:2206.10598v1 [cs.LG])
6. Artificial intelligence system based on multi-value classification of fully connected neural network for construction management. (arXiv:2206.10604v1 [cs.LG])
7. Good Time to Ask: A Learning Framework for Asking for Help in Embodied Visual Navigation. (arXiv:2206.10606v1 [cs.LG])
8. MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer. (arXiv:2206.10607v1 [cs.LG])
9. Generating Diverse Indoor Furniture Arrangements. (arXiv:2206.10608v1 [cs.LG])
10. Autoencoder-based Attribute Noise Handling Method for Medical Data. (arXiv:2206.10609v1 [cs.LG])
11. Stop ordering machine learning algorithms by their explainability! A user-centered investigation of performance and explainability. (arXiv:2206.10610v1 [cs.LG])
12. Neural Activation Patterns (NAPs): Visual Explainability of Learned Concepts. (arXiv:2206.10611v1 [cs.LG])
13. Metareview-informed Explainable Cytokine Storm Detection during CAR-T cell Therapy. (arXiv:2206.10612v1 [q-bio.QM])
14. The Right Tool for the Job: Open-Source Auditing Tools in Machine Learning. (arXiv:2206.10613v1 [cs.LG])
15. On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games. (arXiv:2206.10614v1 [cs.GT])
16. Asymmetric Learned Image Compression with Multi-Scale Residual Block, Importance Map, and Post-Quantization Filtering. (arXiv:2206.10618v1 [eess.IV])
17. CoCoPIE XGen: A Full-Stack AI-Oriented Optimizing Framework. (arXiv:2206.10620v1 [cs.LG])
18. Sparse Kernel Gaussian Processes through Iterative Charted Refinement (ICR). (arXiv:2206.10634v1 [cs.LG])
19. On the Maximum Hessian Eigenvalue and Generalization. (arXiv:2206.10654v1 [cs.LG])
20. ConTraNet: A single end-to-end hybrid network for EEG-based and EMG-based human machine interfaces. (arXiv:2206.10677v1 [q-bio.NC])
21. Learning Neuro-Symbolic Skills for Bilevel Planning. (arXiv:2206.10680v1 [cs.RO])
22. Differentially Private Maximal Information Coefficients. (arXiv:2206.10685v1 [cs.CR])
23. Learning Continuous Rotation Canonicalization with Radial Beam Sampling. (arXiv:2206.10690v1 [cs.CV])
24. Towards OOD Detection in Graph Classification from Uncertainty Estimation Perspective. (arXiv:2206.10691v1 [cs.LG])
25. Multi-level Domain Adaptation for Lane Detection. (arXiv:2206.10692v1 [cs.CV])
26. A consistent and flexible framework for deep matrix factorizations. (arXiv:2206.10693v1 [cs.LG])
27. Epicasting: An Ensemble Wavelet Neural Network (EWNet) for Forecasting Epidemics. (arXiv:2206.10696v1 [cs.LG])
28. Performance Prediction Under Dataset Shift. (arXiv:2206.10697v1 [cs.LG])
29. TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning. (arXiv:2206.10698v1 [cs.CV])
30. Multi-Omic Data Integration and Feature Selection for Survival-based Patient Stratification via Supervised Concrete Autoencoders. (arXiv:2206.10699v1 [cs.LG])
31. TraSE: Towards Tackling Authorial Style from a Cognitive Science Perspective. (arXiv:2206.10706v1 [cs.CL])
32. Beyond Uniform Lipschitz Condition in Differentially Private Optimization. (arXiv:2206.10713v1 [cs.LG])
33. Meta Reinforcement Learning with Finite Training Tasks -- a Density Estimation Approach. (arXiv:2206.10716v1 [cs.LG])
34. Physics-informed machine learning with differentiable programming for heterogeneous underground reservoir pressure management. (arXiv:2206.10718v1 [physics.comp-ph])
35. Predicting Team Performance with Spatial Temporal Graph Convolutional Networks. (arXiv:2206.10720v1 [cs.LG])
36. Sharp Constants in Uniformity Testing via the Huber Statistic. (arXiv:2206.10722v1 [stat.ML])
37. Imitate then Transcend: Multi-Agent Optimal Execution with Dual-Window Denoise PPO. (arXiv:2206.10736v1 [cs.LG])
38. Quantum-Enhanced Selection Operators for Evolutionary Algorithms. (arXiv:2206.10743v1 [quant-ph])
39. Derivate Informed Neural Operator: An Efficient Framework for High-Dimensional Parametric Derivative Learning. (arXiv:2206.10745v1 [math.NA])
40. BiometricBlender: Ultra-high dimensional, multi-class synthetic data generator to imitate biometric feature space. (arXiv:2206.10747v1 [cs.LG])
41. On the Statistical Efficiency of Reward-Free Exploration in Non-Linear RL. (arXiv:2206.10770v1 [cs.LG])
42. Efficient and effective training of language and graph neural network models. (arXiv:2206.10781v1 [cs.LG])
43. Federated Latent Class Regression for Hierarchical Data. (arXiv:2206.10783v1 [cs.LG])
44. Generative Pretraining for Black-Box Optimization. (arXiv:2206.10786v1 [cs.LG])
45. Scaling Autoregressive Models for Content-Rich Text-to-Image Generation. (arXiv:2206.10789v1 [cs.CV])
46. Multi-Resolution, Multi-Horizon Distributed Solar PV Power Forecasting with Forecast Combinations. (arXiv:2206.10795v1 [cs.LG])
47. Imitation Learning for Generalizable Self-driving Policy with Sim-to-real Transfer. (arXiv:2206.10797v1 [cs.LG])
48. Automated Cancer Subtyping via Vector Quantization Mutual Information Maximization. (arXiv:2206.10801v1 [cs.LG])
49. Jointist: Joint Learning for Multi-instrument Transcription and Its Applications. (arXiv:2206.10805v1 [cs.SD])
50. $\texttt{FedBC}$: Calibrating Global and Local Models via Federated Learning Beyond Consensus. (arXiv:2206.10815v1 [cs.LG])
51. Fighting Fire with Fire: Avoiding DNN Shortcuts through Priming. (arXiv:2206.10816v1 [cs.LG])
52. Efficient Interdependent Systems Recovery Modeling with DeepONets. (arXiv:2206.10829v1 [cs.LG])
53. Robust Bayesian Recourse. (arXiv:2206.10833v1 [cs.LG])
54. Learning Distribution Grid Topologies: A Tutorial. (arXiv:2206.10837v1 [math.OC])
55. Learning Debiased Classifier with Biased Committee. (arXiv:2206.10843v1 [cs.LG])
56. Quantization Robust Federated Learning for Efficient Inference on Heterogeneous Devices. (arXiv:2206.10844v1 [cs.LG])
57. DaisyRec 2.0: Benchmarking Recommendation for Rigorous Evaluation. (arXiv:2206.10848v1 [cs.IR])
58. Play It Cool: Dynamic Shifting Prevents Thermal Throttling. (arXiv:2206.10849v1 [cs.LG])
59. Robust Universal Adversarial Perturbations. (arXiv:2206.10858v1 [cs.LG])
60. Bregman Power k-Means for Clustering Exponential Family Data. (arXiv:2206.10860v1 [stat.ML])
61. Decentralized Gossip-Based Stochastic Bilevel Optimization over Communication Networks. (arXiv:2206.10870v1 [stat.ML])
62. Guided Diffusion Model for Adversarial Purification from Random Noise. (arXiv:2206.10875v1 [cs.LG])
63. KiloNeuS: Implicit Neural Representations with Real-Time Global Illumination. (arXiv:2206.10885v1 [cs.CV])
64. Optical Flow Regularization of Implicit Neural Representations for Video Frame Interpolation. (arXiv:2206.10886v1 [cs.CV])
65. How to Combine Variational Bayesian Networks in Federated Learning. (arXiv:2206.10897v1 [cs.LG])
66. S2TNet: Spatio-Temporal Transformer Networks for Trajectory Prediction in Autonomous Driving. (arXiv:2206.10902v1 [cs.CV])
67. SpA-Former: Transformer image shadow detection and removal via spatial attention. (arXiv:2206.10910v1 [cs.CV])
68. Influence of uncertainty estimation techniques on false-positive reduction in liver lesion detection. (arXiv:2206.10911v1 [eess.IV])
69. AI-based software for lung nodule detection in chest X-rays -- Time for a second reader approach?. (arXiv:2206.10912v1 [eess.IV])
70. FairGrad: Fairness Aware Gradient Descent. (arXiv:2206.10923v1 [cs.LG])
71. A Study on the Evaluation of Generative Models. (arXiv:2206.10935v1 [cs.LG])
72. Information Geometry of Dropout Training. (arXiv:2206.10936v1 [stat.ML])
73. List-Decodable Covariance Estimation. (arXiv:2206.10942v1 [cs.DS])
74. POGEMA: Partially Observable Grid Environment for Multiple Agents. (arXiv:2206.10944v1 [cs.LG])
75. Defect Prediction Using Stylistic Metrics. (arXiv:2206.10959v1 [cs.SE])
76. Multi-task twin support vector machine with Universum data. (arXiv:2206.10978v1 [cs.LG])
77. Diagnostic Tool for Out-of-Sample Model Evaluation. (arXiv:2206.10982v1 [stat.ML])
78. Traffic Congestion Prediction Using Machine Learning Techniques. (arXiv:2206.10983v1 [cs.LG])
79. Graph Neural Networks as Gradient Flows. (arXiv:2206.10991v1 [cs.LG])
80. Neural Networks as Paths through the Space of Representations. (arXiv:2206.10999v1 [cs.LG])
81. A Systematic Comparison of Phonetic Aware Techniques for Speech **Enhancement**. (arXiv:2206.11000v1 [eess.AS])
82. Auto-Encoding Adversarial Imitation Learning. (arXiv:2206.11004v1 [cs.LG])
83. Agent-based Graph Neural Networks. (arXiv:2206.11010v1 [cs.LG])
84. ROSE: A RObust and SEcure DNN Watermarking. (arXiv:2206.11024v1 [cs.CR])
85. KeyCLD: Learning Constrained Lagrangian Dynamics in Keypoint Coordinates from Images. (arXiv:2206.11030v1 [cs.LG])
86. World of Bugs: A Platform for Automated Bug Detection in 3D Video Games. (arXiv:2206.11037v1 [cs.SE])
87. Deep Reinforcement Learning for Turbulence Modeling in Large Eddy Simulations. (arXiv:2206.11038v1 [physics.flu-dyn])
88. Supermodular $\mf$-divergences and bounds on lossy compression and generalization error with mutual $\mf$-information. (arXiv:2206.11042v1 [cs.IT])
89. COVYT: Introducing the Coronavirus YouTube and TikTok speech dataset featuring the same speakers with and without infection. (arXiv:2206.11045v1 [eess.AS])
90. Automated GI tract segmentation using deep learning. (arXiv:2206.11048v1 [eess.IV])
91. Dynamic Restrained Uncertainty Weighting Loss for Multitask Learning of Vocal Expression. (arXiv:2206.11049v1 [cs.SD])
92. Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer. (arXiv:2206.11053v1 [cs.CV])
93. S2RL: Do We Really Need to Perceive All States in Deep Multi-Agent Reinforcement Learning?. (arXiv:2206.11054v1 [cs.LG])
94. Generational Differences in Automobility: Comparing America's Millennials and Gen Xers Using Gradient Boosting Decision Trees. (arXiv:2206.11056v1 [cs.LG])
95. Transformer Neural Networks Attending to Both Sequence and Structure for Protein Prediction Tasks. (arXiv:2206.11057v1 [cs.LG])
96. Answer Fast: Accelerating BERT on the Tensor Streaming Processor. (arXiv:2206.11062v1 [cs.LG])
97. An Embedded Feature Selection Framework for Control. (arXiv:2206.11064v1 [cs.LG])
98. AlphaMLDigger: A Novel Machine Learning Solution to Explore Excess Return on Investment. (arXiv:2206.11072v1 [q-fin.CP])
99. Traffic-Twitter Transformer: A Nature Language Processing-joined Framework For Network-wide Traffic Forecasting. (arXiv:2206.11078v1 [cs.LG])
100. Noisy $\ell^{0}$-Sparse Subspace Clustering on Dimensionality Reduced Data. (arXiv:2206.11079v1 [stat.ML])
101. Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks. (arXiv:2206.11081v1 [cs.LG])
102. Federated Adaptation of Reservoirs via Intrinsic Plasticity. (arXiv:2206.11087v1 [cs.NE])
103. OpenXAI: Towards a Transparent Evaluation of Model Explanations. (arXiv:2206.11104v1 [cs.LG])
104. Beyond RMSE: Do machine-learned models of road user interaction produce human-like behavior?. (arXiv:2206.11110v1 [cs.LG])
105. StaDRe and StaDRo: Reliability and Robustness Estimation of ML-based Forecasting using Statistical Distance Measures. (arXiv:2206.11116v1 [cs.LG])
106. Near-optimal control of dynamical systems with neural ordinary differential equations. (arXiv:2206.11120v1 [cs.LG])
107. A view of mini-batch SGD via generating functions: conditions of convergence, phase transitions, benefit from negative momenta. (arXiv:2206.11124v1 [cs.LG])
108. Explanation-based Counterfactual Retraining(XCR): A Calibration Method for Black-box Models. (arXiv:2206.11126v1 [cs.LG])
109. tntorch: Tensor Network Learning with PyTorch. (arXiv:2206.11128v1 [cs.LG])
110. Variational Causal Dynamics: Discovering Modular World Models from Interventions. (arXiv:2206.11131v1 [cs.LG])
111. A Novel Three-Dimensional Navigation Method for the Visually Impaired. (arXiv:2206.11136v1 [cs.HC])
112. Understanding and Extending Subgraph GNNs by Rethinking Their Symmetries. (arXiv:2206.11140v1 [cs.LG])
113. Discussion of `Multiscale Fisher's Independence Test for Multivariate Dependence'. (arXiv:2206.11142v1 [stat.ME])
114. reStructured Pre-training. (arXiv:2206.11147v1 [cs.CL])
115. Then and Now: Quantifying the Longitudinal Validity of Self-Disclosed Depression Diagnoses. (arXiv:2206.11155v1 [cs.LG])
116. Sharing pattern submodels for prediction with missing values. (arXiv:2206.11161v1 [cs.LG])
117. Ordered Subgraph Aggregation Networks. (arXiv:2206.11168v1 [cs.LG])
118. Neural Inverse Transform Sampler. (arXiv:2206.11172v1 [cs.LG])
119. Cold Posteriors through PAC-Bayes. (arXiv:2206.11173v1 [cs.LG])
120. Optimal transport meets noisy label robust loss and MixUp regularization for domain adaptation. (arXiv:2206.11180v1 [cs.CV])
121. On the Role of Spatial, Spectral, and Temporal Processing for DNN-based Non-linear Multi-channel Speech **Enhancement**. (arXiv:2206.11181v1 [eess.AS])
122. Active Learning with Safety Constraints. (arXiv:2206.11183v1 [cs.LG])
123. Towards Unsupervised Content Disentanglement in Sentence Representations via Syntactic Roles. (arXiv:2206.11184v1 [cs.CL])
124. Learning Optimal Treatment Strategies for Sepsis Using Offline Reinforcement Learning in Continuous Space. (arXiv:2206.11190v1 [cs.LG])
125. General Univariate Estimation-of-Distribution Algorithms. (arXiv:2206.11198v1 [cs.NE])
126. Constant-Factor Approximation Algorithms for Socially Fair $k$-Clustering. (arXiv:2206.11210v1 [cs.DS])
127. VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives. (arXiv:2206.11212v1 [cs.CV])
128. Correct and Certify: A New Approach to Self-Supervised 3D-Object Perception. (arXiv:2206.11215v1 [cs.CV])
129. Deep reinforcement learning for fMRI prediction of Autism Spectrum Disorder. (arXiv:2206.11224v1 [q-bio.NC])
130. RetrievalGuard: Provably Robust 1-Nearest Neighbor Image Retrieval. (arXiv:2206.11225v1 [cs.IR])
131. Adversarially trained neural representations may already be as robust as corresponding biological neural representations. (arXiv:2206.11228v1 [q-bio.NC])
132. Business Document Information Extraction: Towards Practical Benchmarks. (arXiv:2206.11229v1 [cs.IR])
133. Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review. (arXiv:2206.11233v1 [q-bio.NC])
134. FedorAS: Federated Architecture Search under system heterogeneity. (arXiv:2206.11239v1 [cs.LG])
135. Concentration inequalities and optimal number of layers for stochastic deep neural networks. (arXiv:2206.11241v1 [cs.LG])
136. GEMv2: Multilingual NLG Benchmarking in a Single Line of Code. (arXiv:2206.11249v1 [cs.CL])
137. Behavior Transformers: Cloning $k$ modes with one stone. (arXiv:2206.11251v1 [cs.LG])
138. Langevin Monte Carlo for Contextual Bandits. (arXiv:2206.11254v1 [cs.LG])
139. Data-Augmented Contact Model for Rigid Body Simulation. (arXiv:1803.04019v4 [cs.RO] UPDATED)
140. Learning Monotone Dynamics by Neural Networks. (arXiv:2006.06417v2 [cs.LG] UPDATED)
141. Least Squares Estimation Using Sketched Data with Heteroskedastic Errors. (arXiv:2007.07781v3 [stat.ML] UPDATED)
142. MedFilter: Improving Extraction of Task-relevant Utterances from Doctor-Patient Conversations through Integration of Discourse Structure and Ontological Knowledge. (arXiv:2010.02246v3 [cs.CL] UPDATED)
143. exploRNN: Understanding Recurrent Neural Networks through Visual Exploration. (arXiv:2012.06326v3 [cs.LG] UPDATED)
144. Multi-hop RIS-Empowered Terahertz Communications: A DRL-based Hybrid Beamforming Design. (arXiv:2101.09137v2 [eess.SP] UPDATED)
145. $k$-Anonymity in Practice: How Generalisation and Suppression Affect Machine Learning Classifiers. (arXiv:2102.04763v2 [cs.LG] UPDATED)
146. Introduction to Machine Learning for the Sciences. (arXiv:2102.04883v2 [physics.comp-ph] UPDATED)
147. Domain Adaptation for Time Series Forecasting via Attention Sharing. (arXiv:2102.06828v9 [cs.LG] UPDATED)
148. Model-free Representation Learning and Exploration in Low-rank MDPs. (arXiv:2102.07035v2 [cs.LG] UPDATED)
149. Discriminative Bayesian filtering lends momentum to the stochastic Newton method for minimizing log-convex functions. (arXiv:2104.12949v2 [stat.ML] UPDATED)
150. Scaling and Scalability: Provable Nonconvex Low-Rank Tensor Estimation from Incomplete Measurements. (arXiv:2104.14526v3 [cs.LG] UPDATED)
151. Generic E-Variables for Exact Sequential k-Sample Tests that allow for Optional Stopping. (arXiv:2106.02693v3 [stat.ME] UPDATED)
152. Kernel Clustering with Sigmoid-based Regularization for Efficient Segmentation of Sequential Data. (arXiv:2106.11541v2 [cs.LG] UPDATED)
153. Restless and Uncertain: Robust Policies for Restless Bandits via Deep Multi-Agent Reinforcement Learning. (arXiv:2107.01689v2 [cs.LG] UPDATED)
154. Beyond Low-pass Filtering: Graph Convolutional Networks with Automatic Filtering. (arXiv:2107.04755v3 [cs.LG] UPDATED)
155. Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v3 [cs.CV] UPDATED)
156. Beyond No Regret: Instance-Dependent PAC Reinforcement Learning. (arXiv:2108.02717v2 [cs.LG] UPDATED)
157. Convergence Rates for Learning Linear Operators from Noisy Data. (arXiv:2108.12515v2 [math.ST] UPDATED)
158. Robust fine-tuning of zero-shot models. (arXiv:2109.01903v3 [cs.CV] UPDATED)
159. Looper: An end-to-end ML platform for product decisions. (arXiv:2110.07554v8 [cs.LG] UPDATED)
160. Realistic Actor-Critic: A Framework for Balance Between Value Overestimation and Underestimation. (arXiv:2110.09712v5 [cs.LG] UPDATED)
161. Does the Data Induce Capacity Control in Deep Learning?. (arXiv:2110.14163v3 [cs.LG] UPDATED)
162. MMD Aggregated Two-Sample Test. (arXiv:2110.15073v2 [stat.ML] UPDATED)
163. LiT: Zero-Shot Transfer with Locked-image text Tuning. (arXiv:2111.07991v3 [cs.CV] UPDATED)
164. Private and polynomial time algorithms for learning Gaussians and beyond. (arXiv:2111.11320v3 [stat.ML] UPDATED)
165. Intuitive Shape Editing in Latent Space. (arXiv:2111.12488v3 [cs.CV] UPDATED)
166. Surfer100: Generating Surveys From Web Resources, Wikipedia-style. (arXiv:2112.06377v4 [cs.CL] UPDATED)
167. Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v4 [cs.CV] UPDATED)
168. 3D Instance Segmentation of MVS Buildings. (arXiv:2112.09902v2 [cs.CV] UPDATED)
169. Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2112.10006v4 [cs.LG] UPDATED)
170. Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review. (arXiv:2112.12705v3 [cs.AI] UPDATED)
171. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v4 [cs.CR] UPDATED)
172. Exploring Longitudinal Cough, Breath, and Voice Data for COVID-19 Progression Prediction via Sequential Deep Learning: Model Development and Validation. (arXiv:2201.01232v2 [cs.SD] UPDATED)
173. Encoding large information structures in linear algebra and statistical models. (arXiv:2201.08233v3 [cs.LG] UPDATED)
174. On Uniform Boundedness Properties of SGD and its Momentum Variants. (arXiv:2201.10245v2 [cs.LG] UPDATED)
175. A Context-Integrated Transformer-Based Neural Network for Auction Design. (arXiv:2201.12489v2 [cs.GT] UPDATED)
176. Adversarial Masking for Self-Supervised Learning. (arXiv:2201.13100v2 [cs.CV] UPDATED)
177. KSD Aggregated Goodness-of-fit Test. (arXiv:2202.00824v3 [stat.ML] UPDATED)
178. MRI Reconstruction via Data Driven Markov Chain with Joint Uncertainty Estimation. (arXiv:2202.01479v2 [cs.LG] UPDATED)
179. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v5 [cs.CL] UPDATED)
180. Algorithms that get old : the case of generative deep neural networks. (arXiv:2202.03008v2 [stat.ML] UPDATED)
181. Inference of Multiscale Gaussian Graphical Model. (arXiv:2202.05775v2 [stat.ML] UPDATED)
182. Saute RL: Almost Surely Safe Reinforcement Learning Using State Augmentation. (arXiv:2202.06558v3 [cs.LG] UPDATED)
183. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v3 [cs.LG] UPDATED)
184. Efficient Online Linear Control with Stochastic Convex Costs and Unknown Dynamics. (arXiv:2203.01170v2 [math.OC] UPDATED)
185. Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time. (arXiv:2203.05482v2 [cs.LG] UPDATED)
186. Supervised Graph Contrastive Learning for Few-shot Node Classification. (arXiv:2203.15936v3 [cs.LG] UPDATED)
187. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v2 [cs.LG] UPDATED)
188. Graph Ordering Attention Networks. (arXiv:2204.05351v2 [cs.LG] UPDATED)
189. Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v3 [cs.SI] UPDATED)
190. Minimizing Control for Credit Assignment with Strong Feedback. (arXiv:2204.07249v2 [cs.NE] UPDATED)
191. Universum-inspired Supervised Contrastive Learning. (arXiv:2204.10695v2 [cs.LG] UPDATED)
192. Beyond the Quadratic Approximation: the Multiscale Structure of Neural Network Loss Landscapes. (arXiv:2204.11326v3 [cs.LG] UPDATED)
193. Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models. (arXiv:2204.12584v2 [cs.RO] UPDATED)
194. Explain to Not Forget: Defending Against Catastrophic Forgetting with XAI. (arXiv:2205.01929v4 [cs.LG] UPDATED)
195. Model-Based Deep Learning: On the Intersection of Deep Learning and Optimization. (arXiv:2205.02640v2 [eess.SP] UPDATED)
196. From Dirichlet to Rubin: Optimistic Exploration in RL without Bonuses. (arXiv:2205.07704v2 [stat.ML] UPDATED)
197. Supervised Learning for Coverage-Directed Test Selection in Simulation-Based Verification. (arXiv:2205.08524v2 [cs.AR] UPDATED)
198. Hybrid Intelligent Testing in Simulation-Based Verification. (arXiv:2205.09552v2 [cs.AR] UPDATED)
199. EXACT: How to Train Your Accuracy. (arXiv:2205.09615v2 [cs.LG] UPDATED)
200. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v2 [cs.CV] UPDATED)
201. Scalable and Efficient Training of Large Convolutional Neural Networks with Differential Privacy. (arXiv:2205.10683v2 [cs.LG] UPDATED)
202. Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs for Medical Image Segmentation and Detection. (arXiv:2206.01736v2 [eess.IV] UPDATED)
203. Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models. (arXiv:2206.02246v2 [cs.SD] UPDATED)
204. Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning. (arXiv:2206.03715v2 [cs.AI] UPDATED)
205. Conformal Prediction Intervals for Markov Decision Process Trajectories. (arXiv:2206.04860v2 [cs.LG] UPDATED)
206. Dual-Stream Transformer with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v2 [eess.IV] UPDATED)
207. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v2 [q-bio.NC] UPDATED)
208. A Spatio-Temporal Neural Network Forecasting Approach for Emulation of Firefront Models. (arXiv:2206.08523v2 [cs.LG] UPDATED)
209. Understanding Robust Overfitting of Adversarial Training and Beyond. (arXiv:2206.08675v2 [cs.LG] UPDATED)
210. Decoupled Dynamic Spatial-Temporal Graph Neural Network for Traffic Forecasting. (arXiv:2206.09112v2 [cs.LG] UPDATED)
211. Bear the Query in Mind: Visual Grounding with Query-conditioned Convolution. (arXiv:2206.09114v2 [cs.CV] UPDATED)
212. Nonparametric Multi-shape Modeling with Uncertainty Quantification. (arXiv:2206.09127v2 [stat.ML] UPDATED)
213. Coin Flipping Neural Networks. (arXiv:2206.09182v2 [cs.LG] UPDATED)
214. Multi-Modality Image Super-Resolution using Generative Adversarial Networks. (arXiv:2206.09193v2 [eess.IV] UPDATED)
215. Multi-Modality Image Inpainting using Generative Adversarial Networks. (arXiv:2206.09210v2 [eess.IV] UPDATED)
216. $C^*$-algebra Net: A New Approach Generalizing Neural Network Parameters to $C^*$-algebra. (arXiv:2206.09513v2 [stat.ML] UPDATED)
217. Multiple Testing Framework for Out-of-Distribution Detection. (arXiv:2206.09522v2 [stat.ML] UPDATED)
218. SMT-DTA: Improving Drug-Target Affinity Prediction with Semi-supervised Multi-task Training. (arXiv:2206.09818v2 [q-bio.BM] UPDATED)
219. Only Tails Matter: Average-Case Universality and Robustness in the Convex Regime. (arXiv:2206.09901v2 [math.OC] UPDATED)
220. Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive Representation Learning. (arXiv:2206.10137v2 [cs.CV] UPDATED)
221. Neural Moving Horizon Estimation for Robust Flight Control. (arXiv:2206.10397v2 [cs.RO] UPDATED)
222. The Privacy Onion Effect: Memorization is Relative. (arXiv:2206.10469v2 [cs.LG] UPDATED)
223. Learning to Estimate and Refine Fluid Motion with Physical Dynamics. (arXiv:2206.10480v2 [cs.LG] UPDATED)
224. sqSGD: Locally Private and Communication Efficient Federated Learning. (arXiv:2206.10565v2 [cs.LG] UPDATED)
225. X-Risk Analysis for AI Research. (arXiv:2206.05862v3 [cs.CY] CROSS LISTED)
226. Predicting Human Performance in Vertical Hierarchical Menu Selection in Immersive AR Using Hand-gesture and Head-gaze. (arXiv:2206.09480v1 [cs.HC] CROSS LISTED)
## cs.AI
---
**117** new papers in cs.AI:-) 
1. Can Foundation Models Talk Causality?. (arXiv:2206.10591v1 [cs.AI])
2. Identifying Electrocardiogram Abnormalities Using a Handcrafted-Rule-Enhanced Neural Network. (arXiv:2206.10592v1 [cs.AI])
3. A Survey on Computational Intelligence-based Transfer Learning. (arXiv:2206.10593v1 [cs.AI])
4. Demystifying the Base and Novel Performances for Few-shot Class-incremental Learning. (arXiv:2206.10596v1 [cs.LG])
5. Deep Inverse Reinforcement Learning for Route Choice Modeling. (arXiv:2206.10598v1 [cs.LG])
6. Artificial intelligence system based on multi-value classification of fully connected neural network for construction management. (arXiv:2206.10604v1 [cs.LG])
7. Good Time to Ask: A Learning Framework for Asking for Help in Embodied Visual Navigation. (arXiv:2206.10606v1 [cs.LG])
8. MASER: Multi-Agent Reinforcement Learning with Subgoals Generated from Experience Replay Buffer. (arXiv:2206.10607v1 [cs.LG])
9. Generating Diverse Indoor Furniture Arrangements. (arXiv:2206.10608v1 [cs.LG])
10. Autoencoder-based Attribute Noise Handling Method for Medical Data. (arXiv:2206.10609v1 [cs.LG])
11. Stop ordering machine learning algorithms by their explainability! A user-centered investigation of performance and explainability. (arXiv:2206.10610v1 [cs.LG])
12. Neural Activation Patterns (NAPs): Visual Explainability of Learned Concepts. (arXiv:2206.10611v1 [cs.LG])
13. The Right Tool for the Job: Open-Source Auditing Tools in Machine Learning. (arXiv:2206.10613v1 [cs.LG])
14. On the Impossibility of Learning to Cooperate with Adaptive Partner Strategies in Repeated Games. (arXiv:2206.10614v1 [cs.GT])
15. CoCoPIE XGen: A Full-Stack AI-Oriented Optimizing Framework. (arXiv:2206.10620v1 [cs.LG])
16. Learning Neuro-Symbolic Skills for Bilevel Planning. (arXiv:2206.10680v1 [cs.RO])
17. Learning Continuous Rotation Canonicalization with Radial Beam Sampling. (arXiv:2206.10690v1 [cs.CV])
18. Making the case for audience design in conversational AI: Rapport expectations and language ideologies in a task-oriented chatbot. (arXiv:2206.10694v1 [cs.CL])
19. TiCo: Transformation Invariance and Covariance Contrast for Self-Supervised Visual Representation Learning. (arXiv:2206.10698v1 [cs.CV])
20. TraSE: Towards Tackling Authorial Style from a Cognitive Science Perspective. (arXiv:2206.10706v1 [cs.CL])
21. Meta Reinforcement Learning with Finite Training Tasks -- a Density Estimation Approach. (arXiv:2206.10716v1 [cs.LG])
22. Imitate then Transcend: Multi-Agent Optimal Execution with Dual-Window Denoise PPO. (arXiv:2206.10736v1 [cs.LG])
23. Don't Forget About Pronouns: Removing Gender Bias in Language Models Without Losing Factual Gender Information. (arXiv:2206.10744v1 [cs.CL])
24. BiometricBlender: Ultra-high dimensional, multi-class synthetic data generator to imitate biometric feature space. (arXiv:2206.10747v1 [cs.LG])
25. A method for ethical AI in Defence: A case study on developing trustworthy autonomous systems. (arXiv:2206.10769v1 [cs.CY])
26. On the Statistical Efficiency of Reward-Free Exploration in Non-Linear RL. (arXiv:2206.10770v1 [cs.LG])
27. Generative Pretraining for Black-Box Optimization. (arXiv:2206.10786v1 [cs.LG])
28. Automated Cancer Subtyping via Vector Quantization Mutual Information Maximization. (arXiv:2206.10801v1 [cs.LG])
29. Jointist: Joint Learning for Multi-instrument Transcription and Its Applications. (arXiv:2206.10805v1 [cs.SD])
30. SSMI: How to Make Objects of Interest Disappear without Accessing Object Detectors?. (arXiv:2206.10809v1 [cs.CV])
31. A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing. (arXiv:2206.10830v1 [cs.CV])
32. Parallel Pre-trained Transformers (PPT) for Synthetic Data-based Instance Segmentation. (arXiv:2206.10845v1 [cs.CV])
33. Connecting Algorithmic Research and Usage Contexts: A Perspective of Contextualized Evaluation for Explainable AI. (arXiv:2206.10847v1 [cs.AI])
34. Play It Cool: Dynamic Shifting Prevents Thermal Throttling. (arXiv:2206.10849v1 [cs.LG])
35. I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation. (arXiv:2206.10892v1 [cs.CV])
36. How to Combine Variational Bayesian Networks in Federated Learning. (arXiv:2206.10897v1 [cs.LG])
37. Recognising Affordances in Predicted Futures to Plan with Consideration of Non-canonical Affordance Effects. (arXiv:2206.10920v1 [cs.RO])
38. FairGrad: Fairness Aware Gradient Descent. (arXiv:2206.10923v1 [cs.LG])
39. POGEMA: Partially Observable Grid Environment for Multiple Agents. (arXiv:2206.10944v1 [cs.LG])
40. Toward An Optimal Selection of Dialogue Strategies: A Target-Driven Approach for Intelligent Outbound Robots. (arXiv:2206.10953v1 [cs.CL])
41. Human-AI communication for human-human communication: Applying interpretable unsupervised anomaly detection to executive coaching. (arXiv:2206.10987v1 [cs.HC])
42. Agent-based Graph Neural Networks. (arXiv:2206.11010v1 [cs.LG])
43. Object Type Clustering using Markov Directly-Follow Multigraph in Object-Centric Process Mining. (arXiv:2206.11017v1 [cs.AI])
44. Heterogeneous Graph Neural Networks for Software Effort Estimation. (arXiv:2206.11023v1 [cs.SE])
45. ROSE: A RObust and SEcure DNN Watermarking. (arXiv:2206.11024v1 [cs.CR])
46. On three types of $L$-fuzzy $\beta$-covering-based rough sets. (arXiv:2206.11025v1 [cs.AI])
47. World of Bugs: A Platform for Automated Bug Detection in 3D Video Games. (arXiv:2206.11037v1 [cs.SE])
48. Deep Reinforcement Learning for Turbulence Modeling in Large Eddy Simulations. (arXiv:2206.11038v1 [physics.flu-dyn])
49. Penalty Weights in QUBO Formulations: Permutation Problems. (arXiv:2206.11040v1 [math.OC])
50. Surgical-VQA: Visual Question Answering in Surgical Scenes using Transformer. (arXiv:2206.11053v1 [cs.CV])
51. S2RL: Do We Really Need to Perceive All States in Deep Multi-Agent Reinforcement Learning?. (arXiv:2206.11054v1 [cs.LG])
52. Transformer Neural Networks Attending to Both Sequence and Structure for Protein Prediction Tasks. (arXiv:2206.11057v1 [cs.LG])
53. An Ontological Approach to Analysing Social Service Provisioning. (arXiv:2206.11061v1 [cs.DB])
54. An Embedded Feature Selection Framework for Control. (arXiv:2206.11064v1 [cs.LG])
55. Estimation of Electric Vehicle Public Charging Demand using Cellphone Data and Points of Interest-based Segmentation. (arXiv:2206.11065v1 [eess.SY])
56. A Unified and Biologically-Plausible Relational Graph Representation of Vision Transformers. (arXiv:2206.11073v1 [cs.NE])
57. Traffic-Twitter Transformer: A Nature Language Processing-joined Framework For Network-wide Traffic Forecasting. (arXiv:2206.11078v1 [cs.LG])
58. Descent Steps of a Relation-Aware Energy Produce Heterogeneous Graph Neural Networks. (arXiv:2206.11081v1 [cs.LG])
59. Investigating the Benefits of Free-Form Rationales. (arXiv:2206.11083v1 [cs.CL])
60. Generalizing Multimodal Pre-training into Multilingual via Language Acquisition. (arXiv:2206.11091v1 [cs.CL])
61. OpenXAI: Towards a Transparent Evaluation of Model Explanations. (arXiv:2206.11104v1 [cs.LG])
62. Evolutionary Game-Theoretical Analysis for General Multiplayer Asymmetric Games. (arXiv:2206.11114v1 [cs.AI])
63. StaDRe and StaDRo: Reliability and Robustness Estimation of ML-based Forecasting using Statistical Distance Measures. (arXiv:2206.11116v1 [cs.LG])
64. Multi-View Clustering for Open Knowledge Base Canonicalization. (arXiv:2206.11130v1 [cs.CL])
65. Hybrid Physical Metric For 6-DoF Grasp Pose Detection. (arXiv:2206.11141v1 [cs.RO])
66. reStructured Pre-training. (arXiv:2206.11147v1 [cs.CL])
67. Ordered Subgraph Aggregation Networks. (arXiv:2206.11168v1 [cs.LG])
68. Attack Techniques and Threat Identification for Vulnerabilities. (arXiv:2206.11171v1 [cs.CR])
69. Cold Posteriors through PAC-Bayes. (arXiv:2206.11173v1 [cs.LG])
70. Vulnerability Prioritization: An Offensive Security Approach. (arXiv:2206.11182v1 [cs.CR])
71. Towards Unsupervised Content Disentanglement in Sentence Representations via Syntactic Roles. (arXiv:2206.11184v1 [cs.CL])
72. Automated Compliance Blueprint Optimization with Artificial Intelligence. (arXiv:2206.11187v1 [cs.AI])
73. Learning Optimal Treatment Strategies for Sepsis Using Offline Reinforcement Learning in Continuous Space. (arXiv:2206.11190v1 [cs.LG])
74. General Univariate Estimation-of-Distribution Algorithms. (arXiv:2206.11198v1 [cs.NE])
75. Facke: a Survey on Generative Models for Face Swapping. (arXiv:2206.11203v1 [cs.CV])
76. Constant-Factor Approximation Algorithms for Socially Fair $k$-Clustering. (arXiv:2206.11210v1 [cs.DS])
77. VisFIS: Visual Feature Importance Supervision with Right-for-the-Right-Reason Objectives. (arXiv:2206.11212v1 [cs.CV])
78. Deep reinforcement learning for fMRI prediction of Autism Spectrum Disorder. (arXiv:2206.11224v1 [q-bio.NC])
79. Business Document Information Extraction: Towards Practical Benchmarks. (arXiv:2206.11229v1 [cs.IR])
80. GEMv2: Multilingual NLG Benchmarking in a Single Line of Code. (arXiv:2206.11249v1 [cs.CL])
81. Behavior Transformers: Cloning $k$ modes with one stone. (arXiv:2206.11251v1 [cs.LG])
82. exploRNN: Understanding Recurrent Neural Networks through Visual Exploration. (arXiv:2012.06326v3 [cs.LG] UPDATED)
83. FFConv: Fast Factorized Convolutional Neural Network Inference on Encrypted Data. (arXiv:2102.03494v2 [cs.CR] UPDATED)
84. Diff-Explainer: Differentiable Convex Optimization for Explainable Multi-hop Inference. (arXiv:2105.03417v2 [cs.CL] UPDATED)
85. Prevention and Resolution of Conflicts in Social Navigation -- a Survey. (arXiv:2106.12113v2 [cs.RO] UPDATED)
86. Beyond Low-pass Filtering: Graph Convolutional Networks with Automatic Filtering. (arXiv:2107.04755v3 [cs.LG] UPDATED)
87. Looper: An end-to-end ML platform for product decisions. (arXiv:2110.07554v8 [cs.LG] UPDATED)
88. CDistNet: Perceiving Multi-Domain Character Distance for Robust Text Recognition. (arXiv:2111.11011v3 [cs.CV] UPDATED)
89. Talk-to-Resolve: Combining scene understanding and spatial dialogue to resolve granular task ambiguity for a collocated robot. (arXiv:2111.11099v2 [cs.RO] UPDATED)
90. Learning to Search in Task and Motion Planning with Streams. (arXiv:2111.13144v2 [cs.RO] UPDATED)
91. Margin Calibration for Long-Tailed Visual Recognition. (arXiv:2112.07225v4 [cs.CV] UPDATED)
92. 3D Instance Segmentation of MVS Buildings. (arXiv:2112.09902v2 [cs.CV] UPDATED)
93. Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2112.10006v4 [cs.LG] UPDATED)
94. Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review. (arXiv:2112.12705v3 [cs.AI] UPDATED)
95. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v4 [cs.CR] UPDATED)
96. Metrics for saliency map evaluation of deep learning explanation methods. (arXiv:2201.13291v3 [cs.CV] UPDATED)
97. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v5 [cs.CL] UPDATED)
98. Saute RL: Almost Surely Safe Reinforcement Learning Using State Augmentation. (arXiv:2202.06558v3 [cs.LG] UPDATED)
99. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v3 [cs.LG] UPDATED)
100. HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR. (arXiv:2203.09215v3 [cs.CV] UPDATED)
101. Data-Free Quantization with Accurate Activation Clipping and Adaptive Batch Normalization. (arXiv:2204.04215v2 [cs.LG] UPDATED)
102. End-to-end Autonomous Driving with Semantic Depth Cloud Mapping and Multi-agent. (arXiv:2204.05513v2 [cs.RO] UPDATED)
103. Large-scale multi-objective influence maximisation with network downscaling. (arXiv:2204.06250v3 [cs.SI] UPDATED)
104. Learning to Purification for Unsupervised Person Re-identification. (arXiv:2204.09931v2 [cs.CV] UPDATED)
105. Supervised Learning for Coverage-Directed Test Selection in Simulation-Based Verification. (arXiv:2205.08524v2 [cs.AR] UPDATED)
106. Hybrid Intelligent Testing in Simulation-Based Verification. (arXiv:2205.09552v2 [cs.AR] UPDATED)
107. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v2 [cs.CV] UPDATED)
108. Adaptive Adversarial Training to Improve Adversarial Robustness of DNNs for Medical Image Segmentation and Detection. (arXiv:2206.01736v2 [eess.IV] UPDATED)
109. Zero-Shot Voice Conditioning for Denoising Diffusion TTS Models. (arXiv:2206.02246v2 [cs.SD] UPDATED)
110. Modularized Transfer Learning with Multiple Knowledge Graphs for Zero-shot Commonsense Reasoning. (arXiv:2206.03715v2 [cs.AI] UPDATED)
111. Region-enhanced Deep Graph Convolutional Networks for Rumor Detection. (arXiv:2206.07665v2 [cs.SI] UPDATED)
112. Understanding Robust Overfitting of Adversarial Training and Beyond. (arXiv:2206.08675v2 [cs.LG] UPDATED)
113. From Understanding Genetic Drift to a Smart-Restart Mechanism for Estimation-of-Distribution Algorithms. (arXiv:2206.09090v2 [cs.NE] UPDATED)
114. SMT-DTA: Improving Drug-Target Affinity Prediction with Semi-supervised Multi-task Training. (arXiv:2206.09818v2 [q-bio.BM] UPDATED)
115. Few-Max: Few-Shot Domain Adaptation for Unsupervised Contrastive Representation Learning. (arXiv:2206.10137v2 [cs.CV] UPDATED)
116. Graphical Join: A New Physical Join Algorithm for RDBMSs. (arXiv:2206.10435v2 [cs.DB] UPDATED)
117. X-Risk Analysis for AI Research. (arXiv:2206.05862v3 [cs.CY] CROSS LISTED)

