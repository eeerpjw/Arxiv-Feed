# Your interest papers
---
## cs.CV
---
### Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
- Authors : Arash Rabbani, Masoud Babaei
- Link : [http://arxiv.org/abs/2208.00163](http://arxiv.org/abs/2208.00163)
> ABSTRACT  :  In this study, a method has been developed to improve the resolution of histological human placenta images. For this purpose, a paired series of high- and low-resolution images have been collected to train a deep neural network model that can predict image residuals required to improve the resolution of the input images. A modified version of the U-net neural network model has been tailored to find the relationship between the low resolution and residual images. After training for 900 epochs on an augmented dataset of 1000 images, the relative mean squared error of 0.003 is achieved for the prediction of 320 test images. The proposed method has not only improved the contrast of the low-resolution images at the edges of cells but added critical details and textures that mimic high-resolution images of placenta villous space.  
### Distilled Low Rank Neural Radiance Field with Quantization for Light Field Compression. (arXiv:2208.00164v1 [cs.CV])
- Authors : Jinglei Shi, Christine Guillemot
- Link : [http://arxiv.org/abs/2208.00164](http://arxiv.org/abs/2208.00164)
> ABSTRACT  :  In this paper, we propose a novel light field compression method based on a Quantized Distilled Low Rank Neural Radiance Field (QDLR-**NeRF**) representation. While existing compression methods encode the set of light field sub-aperture images, our proposed method instead learns an implicit scene representation in the form of a Neural Radiance Field (**NeRF**), which also enables view synthesis. For reducing its size, the model is first learned under a Low Rank (LR) constraint using a Tensor Train (TT) decomposition in an Alternating Direction Method of Multipliers (ADMM) optimization framework. To further reduce the model size, the components of the tensor train decomposition need to be quantized. However, performing the optimization of the **NeRF** model by simultaneously taking the low rank constraint and the rate-constrained weight quantization into consideration is challenging. To deal with this difficulty, we introduce a network distillation operation that separates the low rank approximation and the weight quantization in the network training. The information from the initial LR constrained **NeRF** (LR-**NeRF**) is distilled to a model of a much smaller dimension (DLR-**NeRF**) based on the TT decomposition of the LR-**NeRF**. An optimized global codebook is then learned to quantize all TT components, producing the final QDLR**NeRF**. Experimental results show that our proposed method yields better compression efficiency compared with state-of-the-art methods, and it additionally has the advantage of allowing the synthesis of any light field view with a high quality.  
### Mobile**NeRF**: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. (arXiv:2208.00277v1 [cs.CV])
- Authors : Zhiqin Chen, Thomas Funkhouser, Peter Hedman, Andrea Tagliasacchi
- Link : [http://arxiv.org/abs/2208.00277](http://arxiv.org/abs/2208.00277)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**s) have demonstrated amazing ability to synthesize images of 3D scenes from novel views. However, they rely upon specialized volumetric rendering algorithms based on ray marching that are mismatched to the capabilities of widely deployed graphics hardware. This paper introduces a new **NeRF** representation based on textured polygons that can synthesize novel images efficiently with standard rendering pipelines. The **NeRF** is represented as a set of polygons with textures representing binary opacities and feature vectors. Traditional rendering of the polygons with a z-buffer yields an image with features at every pixel, which are interpreted by a small, view-dependent MLP running in a fragment shader to produce a final pixel color. This approach enables **NeRF**s to be rendered with the traditional polygon rasterization pipeline, which provides massive pixel-level parallelism, achieving interactive frame rates on a wide range of compute platforms, including mobile phones.  
### STrajNet: Occupancy Flow Prediction via Multi-modal **Swin** Transformer. (arXiv:2208.00394v1 [cs.CV])
- Authors : Haochen Liu, Zhiyu Huang, Chen Lv
- Link : [http://arxiv.org/abs/2208.00394](http://arxiv.org/abs/2208.00394)
> ABSTRACT  :  Making an accurate prediction of occupancy and flow is essential to enable better safety and interaction for autonomous vehicles under complex traffic scenarios. This work proposes STrajNet: a multi-modal **Swin** Transformerbased framework for effective scene occupancy and flow predictions. We employ **Swin** Transformer to encode the image and interaction-aware motion representations and propose a cross-attention module to inject motion awareness into grid cells across different time steps. Flow and occupancy predictions are then decoded through temporalsharing Pyramid decoders. The proposed method shows competitive prediction accuracy and other evaluation metrics in the Waymo Open Dataset benchmark.  
### TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
- Authors : Reza Azad, Moein Heidari, Moein Shariatnia, Ehsan Khodapanah, Sanaz Karimijafarbigloo, Ehsan Adeli, Dorit Merhof
- Link : [http://arxiv.org/abs/2208.00713](http://arxiv.org/abs/2208.00713)
> ABSTRACT  :  Convolutional neural networks (CNNs) have been the de facto standard in a diverse set of computer vision tasks for many years. Especially, deep neural networks based on seminal architectures such as U-shaped models with skip-connections or atrous convolution with pyramid pooling have been tailored to a wide range of medical image analysis tasks. The main advantage of such architectures is that they are prone to detaining versatile local features. However, as a general consensus, CNNs fail to capture long-range dependencies and spatial correlations due to the intrinsic property of confined receptive field size of convolution operations. Alternatively, Transformer, profiting from global information modelling that stems from the self-attention mechanism, has recently attained remarkable performance in natural language processing and computer vision. Nevertheless, previous studies prove that both local and global features are critical for a deep model in dense prediction, such as segmenting complicated structures with disparate shapes and configurations. To this end, this paper proposes TransDeepLab, a novel DeepLab-like pure Transformer for medical image segmentation. Specifically, we exploit hierarchical **Swin**-Transformer with shifted windows to extend the DeepLabv3 and model the Atrous Spatial Pyramid Pooling (ASPP) module. A thorough search of the relevant literature yielded that we are the first to model the seminal DeepLab model with a pure Transformer-based model. Extensive experiments on various medical image segmentation tasks verify that our approach performs superior or on par with most contemporary works on an amalgamation of Vision Transformer and CNN-based methods, along with a significant reduction of model complexity. The codes and trained models are publicly available at https://github.com/rezazad68/transdeeplab  
### Real Time Object Detection System with YOLO and CNN Models: A Review. (arXiv:2208.00773v1 [cs.CV])
- Authors : 
- Link : [http://arxiv.org/abs/2208.00773](http://arxiv.org/abs/2208.00773)
> ABSTRACT  :  The field of artificial intelligence is built on object detection techniques. YOU ONLY LOOK ONCE (YOLO) algorithm and it's more evolved versions are briefly described in this research survey. This survey is all about YOLO and convolution neural networks (CNN)in the direction of **real time** object detection.YOLO does generalized object representation more effectively without precision losses than other object detection models.CNN architecture models have the ability to eliminate highlights and identify objects in any given image. When implemented appropriately, CNN models can address issues like deformity diagnosis, creating educational or instructive application, etc. This article reached atnumber of observations and perspective findings through the analysis.Also it provides support for the focused visual information and feature extraction in the financial and other industries, highlights the method of target detection and feature selection, and briefly describe the development process of YOLO algorithm.  
### Unpaired Depth Super-Resolution in the Wild. (arXiv:2105.12038v3 [cs.CV] UPDATED)
- Authors : Aleksandr Safin, Maxim Kan, Nikita Drobyshev, Oleg Voynov, Alexey Artemov, Alexander Filippov, Denis Zorin, Evgeny Burnaev
- Link : [http://arxiv.org/abs/2105.12038](http://arxiv.org/abs/2105.12038)
> ABSTRACT  :  Depth maps captured with commodity sensors are often of low quality and resolution; these maps need to be enhanced to be used in many applications. State-of-the-art data-driven methods of depth map super-resolution rely on registered pairs of low- and high-resolution depth maps of the same scenes. Acquisition of real-world paired data requires specialized setups. Another alternative, generating low-resolution maps from high-resolution maps by subsampling, adding noise and other artificial degradation methods, does not fully capture the characteristics of real-world low-resolution images. As a consequence, supervised learning methods trained on such artificial paired data may not perform well on real-world low-resolution inputs. We consider an approach to depth super-resolution based on learning from unpaired data. While many techniques for unpaired image-to-image translation have been proposed, most fail to deliver effective hole-filling or reconstruct accurate surfaces using depth maps. We propose an unpaired learning method for depth super-resolution, which is based on a learnable degradation model, **enhancement** component and surface normal estimates as features to produce more accurate depth maps. We propose a benchmark for unpaired depth SR and demonstrate that our method outperforms existing unpaired methods and performs on par with paired.  
### Stacked BNAS: Rethinking Broad Convolutional Neural Network for Neural Architecture Search. (arXiv:2111.07722v4 [cs.CV] UPDATED)
- Authors : Zixiang Ding, Yaran Chen, Nannan Li, Dongbin Zhao, Philip Chen
- Link : [http://arxiv.org/abs/2111.07722](http://arxiv.org/abs/2111.07722)
> ABSTRACT  :  Different from other deep scalable architecture-based NAS approaches, Broad Neural Architecture Search (BNAS) proposes a broad scalable architecture which consists of convolution and **enhancement** blocks, dubbed Broad Convolutional Neural Network (BCNN), as the search space for amazing efficiency improvement. BCNN reuses the topologies of cells in the convolution block so that BNAS can employ few cells for efficient search. Moreover, multi-scale feature fusion and knowledge embedding are proposed to improve the performance of BCNN with shallow topology. However, BNAS suffers some drawbacks: 1) insufficient representation diversity for feature fusion and **enhancement** and 2) time consumption of knowledge embedding design by human experts. This paper proposes Stacked BNAS, whose search space is a developed broad scalable architecture named Stacked BCNN, with better performance than BNAS. On the one hand, Stacked BCNN treats mini BCNN as a basic block to preserve comprehensive representation and deliver powerful feature extraction ability. For multi-scale feature **enhancement**, each mini BCNN feeds the outputs of deep and broad cells to the **enhancement** cell. For multi-scale feature fusion, each mini BCNN feeds the outputs of deep, broad and **enhancement** cells to the output node. On the other hand, Knowledge Embedding Search (KES) is proposed to learn appropriate knowledge embeddings in a differentiable way. Moreover, the basic unit of KES is an over-parameterized knowledge embedding module that consists of all possible candidate knowledge embeddings. Experimental results show that 1) Stacked BNAS obtains better performance than BNAS-v2 on both CIFAR-10 and ImageNet, 2) the proposed KES algorithm contributes to reducing the parameters of the learned architecture with satisfactory performance, and 3) Stacked BNAS delivers a state-of-the-art efficiency of 0.02 GPU days.  
### Unidirectional Video Denoising by Mimicking Backward Recurrent Modules with Look-ahead Forward Ones. (arXiv:2204.05532v3 [cs.CV] UPDATED)
- Authors : Junyi Li, Xiaohe Wu, Zhenxing Niu, Wangmeng Zuo
- Link : [http://arxiv.org/abs/2204.05532](http://arxiv.org/abs/2204.05532)
> ABSTRACT  :  While significant progress has been made in deep video denoising, it remains very challenging for exploiting historical and future frames. Bidirectional recurrent networks (BiRNN) have exhibited appealing performance in several video **restoration** tasks. However, BiRNN is intrinsically offline because it uses backward recurrent modules to propagate from the last to current frames, which causes high latency and large memory consumption. To address the offline issue of BiRNN, we present a novel recurrent network consisting of forward and look-ahead recurrent modules for unidirectional video denoising. Particularly, look-ahead module is an elaborate forward module for leveraging information from near-future frames. When denoising the current frame, the hidden features by forward and look-ahead recurrent modules are combined, thereby making it feasible to exploit both historical and near-future frames. Due to the scene motion between non-neighboring frames, border pixels missing may occur when warping look-ahead feature from near-future frame to current frame, which can be largely alleviated by incorporating forward warping and proposed border enlargement. Experiments show that our method achieves state-of-the-art performance with constant latency and memory consumption. Code is avaliable at https://github.com/nagejacob/FloRNN.  
### Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v2 [cs.CV] UPDATED)
- Authors : Chunwei Tian, Yixuan Yuan, Shichao Zhang, Wen Lin, Wangmeng Zuo, David Zhang
- Link : [http://arxiv.org/abs/2205.14548](http://arxiv.org/abs/2205.14548)
> ABSTRACT  :  CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal **enhancement** operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.  
### GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v3 [cs.CV] UPDATED)
- Authors : Peng Zheng, Huazhu Fu, Ping Fan, Qi Fan, Jie Qin, Wing Tai, Keung Tang, Luc Van
- Link : [http://arxiv.org/abs/2205.15469](http://arxiv.org/abs/2205.15469)
> ABSTRACT  :  In this paper, we present a novel end-to-end group collaborative learning network, termed GCoNet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. The proposed GCoNet+ achieves the new state-of-the-art performance for co-salient object detection (CoSOD) through mining consensus representations based on the following two essential criteria: 1) intra-group compactness to better formulate the consistency among co-salient objects by capturing their inherent shared attributes using our novel group affinity module (GAM); 2) inter-group separability to effectively suppress the influence of noisy objects on the output by introducing our new group collaborating module (GCM) conditioning on the inconsistent consensus. To further improve the accuracy, we design a series of simple yet effective components as follows: i) a recurrent auxiliary classification module (RACM) promoting the model learning at the semantic level; ii) a confidence **enhancement** module (CEM) helping the model to improve the quality of the final predictions; and iii) a group-based symmetric triplet (GST) loss guiding the model to learn more discriminative features. Extensive experiments on three challenging benchmarks, i.e., CoCA, CoSOD3k, and CoSal2015, demonstrate that our GCoNet+ outperforms the existing 12 cutting-edge models. Code has been released at https://github.com/ZhengPeng7/GCoNet_plus.  
### S$^{5}$Mars: Self-Supervised and Semi-Supervised Learning for Mars Segmentation. (arXiv:2207.01200v2 [cs.CV] UPDATED)
- Authors : Jiahang Zhang, Lilang Lin, Zejia Fan, Wenjing Wang, **Jiaying Liu**
- Link : [http://arxiv.org/abs/2207.01200](http://arxiv.org/abs/2207.01200)
> ABSTRACT  :  Deep learning has become a powerful tool for Mars exploration. Mars terrain segmentation is an important Martian vision task, which is the base of rover autonomous planning and safe driving. However, existing deep-learning-based terrain segmentation methods face two problems: one is the lack of sufficient detailed and high-confidence annotations, and the other is the over-reliance of models on annotated training data. In this paper, we address these two problems from the perspective of joint data and method design. We first present a new Mars terrain segmentation dataset which contains 6K high-resolution images and is sparsely annotated based on confidence, ensuring the high quality of labels. Then to learn from this sparse data, we propose a representation-learning-based framework for Mars terrain segmentation, including a self-supervised learning stage (for pre-training) and a semi-supervised learning stage (for fine-tuning). Specifically, for self-supervised learning, we design a multi-task mechanism based on the masked image modeling (MIM) concept to emphasize the texture information of images. For semi-supervised learning, since our dataset is sparsely annotated, we encourage the model to excavate the information of unlabeled area in each image by generating and utilizing pseudo-labels online. We name our dataset and method Self-Supervised and Semi-Supervised Segmentation for Mars (S$^{5}$Mars). Experimental results show that our method can outperform state-of-the-art approaches and improve terrain segmentation performance by a large margin. Our project is available at https://jhang2020.github.io/S5Mars.github.io/ .  
### End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v2 [cs.CV] UPDATED)
- Authors : Zelin Zhao, Jiaya Jia
- Link : [http://arxiv.org/abs/2207.14741](http://arxiv.org/abs/2207.14741)
> ABSTRACT  :  In this paper, we present a simple seq2seq formulation for view synthesis where we take a set of ray points as input and output colors corresponding to the rays. Directly applying a standard transformer on this seq2seq formulation has two limitations. First, the standard attention cannot successfully fit the volumetric rendering procedure, and therefore high-frequency components are missing in the synthesized views. Second, applying global attention to all rays and pixels is extremely inefficient. Inspired by the neural radiance field (**NeRF**), we propose the **NeRF** attention (**NeRF**A) to address the above problems. On the one hand, **NeRF**A considers the volumetric rendering equation as a soft feature modulation procedure. In this way, the feature modulation enhances the transformers with the **NeRF**-like inductive bias. On the other hand, **NeRF**A performs multi-stage attention to reduce the computational overhead. Furthermore, the **NeRF**A model adopts the ray and pixel transformers to learn the interactions between rays and pixels. **NeRF**A demonstrates superior performance over **NeRF** and NerFormer on four datasets: DeepVoxels, Blender, LLFF, and CO3D. Besides, **NeRF**A establishes a new state-of-the-art under two settings: the single-scene view synthesis and the category-centric novel view synthesis. The code will be made publicly available.  
## eess.IV
---
### Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
- Authors : Arash Rabbani, Masoud Babaei
- Link : [http://arxiv.org/abs/2208.00163](http://arxiv.org/abs/2208.00163)
> ABSTRACT  :  In this study, a method has been developed to improve the resolution of histological human placenta images. For this purpose, a paired series of high- and low-resolution images have been collected to train a deep neural network model that can predict image residuals required to improve the resolution of the input images. A modified version of the U-net neural network model has been tailored to find the relationship between the low resolution and residual images. After training for 900 epochs on an augmented dataset of 1000 images, the relative mean squared error of 0.003 is achieved for the prediction of 320 test images. The proposed method has not only improved the contrast of the low-resolution images at the edges of cells but added critical details and textures that mimic high-resolution images of placenta villous space.  
### Photon-Limited Blind Deconvolution using Unsupervised Iterative Kernel Estimation. (arXiv:2208.00451v1 [eess.IV])
- Authors : Yash Sanghvi, Abhiram Gnanasambandam, Zhiyuan Mao
- Link : [http://arxiv.org/abs/2208.00451](http://arxiv.org/abs/2208.00451)
> ABSTRACT  :  Blind deconvolution in **low-light** is one of the more challenging problems in image **restoration** because of the photon shot noise. However, existing algorithms -- both classical and deep-learning based -- are not designed for this condition. When the shot noise is strong, conventional deconvolution methods fail because (1) the presence of noise makes the estimation of the blur kernel difficult; (2) generic deep-**restoration** models rarely model the forward process explicitly; (3) there are currently no iterative strategies to incorporate a non-blind solver in a kernel estimation stage. This paper addresses these challenges by presenting an unsupervised blind deconvolution method. At the core of this method is a reformulation of the general blind deconvolution framework from the conventional image-kernel alternating minimization to a purely kernel-based minimization. This kernel-based minimization leads to a new iterative scheme that backpropagates an unsupervised loss through a pre-trained non-blind solver to update the blur kernel. Experimental results show that the proposed framework achieves superior results than state-of-the-art blind deconvolution algorithms in **low-light** conditions.  
### TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
- Authors : Reza Azad, Moein Heidari, Moein Shariatnia, Ehsan Khodapanah, Sanaz Karimijafarbigloo, Ehsan Adeli, Dorit Merhof
- Link : [http://arxiv.org/abs/2208.00713](http://arxiv.org/abs/2208.00713)
> ABSTRACT  :  Convolutional neural networks (CNNs) have been the de facto standard in a diverse set of computer vision tasks for many years. Especially, deep neural networks based on seminal architectures such as U-shaped models with skip-connections or atrous convolution with pyramid pooling have been tailored to a wide range of medical image analysis tasks. The main advantage of such architectures is that they are prone to detaining versatile local features. However, as a general consensus, CNNs fail to capture long-range dependencies and spatial correlations due to the intrinsic property of confined receptive field size of convolution operations. Alternatively, Transformer, profiting from global information modelling that stems from the self-attention mechanism, has recently attained remarkable performance in natural language processing and computer vision. Nevertheless, previous studies prove that both local and global features are critical for a deep model in dense prediction, such as segmenting complicated structures with disparate shapes and configurations. To this end, this paper proposes TransDeepLab, a novel DeepLab-like pure Transformer for medical image segmentation. Specifically, we exploit hierarchical **Swin**-Transformer with shifted windows to extend the DeepLabv3 and model the Atrous Spatial Pyramid Pooling (ASPP) module. A thorough search of the relevant literature yielded that we are the first to model the seminal DeepLab model with a pure Transformer-based model. Extensive experiments on various medical image segmentation tasks verify that our approach performs superior or on par with most contemporary works on an amalgamation of Vision Transformer and CNN-based methods, along with a significant reduction of model complexity. The codes and trained models are publicly available at https://github.com/rezazad68/transdeeplab  
### Real Time Object Detection System with YOLO and CNN Models: A Review. (arXiv:2208.00773v1 [cs.CV])
- Authors : 
- Link : [http://arxiv.org/abs/2208.00773](http://arxiv.org/abs/2208.00773)
> ABSTRACT  :  The field of artificial intelligence is built on object detection techniques. YOU ONLY LOOK ONCE (YOLO) algorithm and it's more evolved versions are briefly described in this research survey. This survey is all about YOLO and convolution neural networks (CNN)in the direction of **real time** object detection.YOLO does generalized object representation more effectively without precision losses than other object detection models.CNN architecture models have the ability to eliminate highlights and identify objects in any given image. When implemented appropriately, CNN models can address issues like deformity diagnosis, creating educational or instructive application, etc. This article reached atnumber of observations and perspective findings through the analysis.Also it provides support for the focused visual information and feature extraction in the financial and other industries, highlights the method of target detection and feature selection, and briefly describe the development process of YOLO algorithm.  
### Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v2 [cs.CV] UPDATED)
- Authors : Chunwei Tian, Yixuan Yuan, Shichao Zhang, Wen Lin, Wangmeng Zuo, David Zhang
- Link : [http://arxiv.org/abs/2205.14548](http://arxiv.org/abs/2205.14548)
> ABSTRACT  :  CNNs with strong learning abilities are widely chosen to resolve super-resolution problem. However, CNNs depend on deeper network architectures to improve performance of image super-resolution, which may increase computational cost in general. In this paper, we present an enhanced super-resolution group CNN (ESRGCNN) with a shallow architecture by fully fusing deep and wide channel features to extract more accurate low-frequency information in terms of correlations of different channels in single image super-resolution (SISR). Also, a signal **enhancement** operation in the ESRGCNN is useful to inherit more long-distance contextual information for resolving long-term dependency. An adaptive up-sampling operation is gathered into a CNN to obtain an image super-resolution model with low-resolution images of different sizes. Extensive experiments report that our ESRGCNN surpasses the state-of-the-arts in terms of SISR performance, complexity, execution speed, image quality evaluation and visual effect in SISR. Code is found at https://github.com/hellloxiaotian/ESRGCNN.  
## cs.LG
---
### Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
- Authors : Arash Rabbani, Masoud Babaei
- Link : [http://arxiv.org/abs/2208.00163](http://arxiv.org/abs/2208.00163)
> ABSTRACT  :  In this study, a method has been developed to improve the resolution of histological human placenta images. For this purpose, a paired series of high- and low-resolution images have been collected to train a deep neural network model that can predict image residuals required to improve the resolution of the input images. A modified version of the U-net neural network model has been tailored to find the relationship between the low resolution and residual images. After training for 900 epochs on an augmented dataset of 1000 images, the relative mean squared error of 0.003 is achieved for the prediction of 320 test images. The proposed method has not only improved the contrast of the low-resolution images at the edges of cells but added critical details and textures that mimic high-resolution images of placenta villous space.  
### Mobile**NeRF**: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. (arXiv:2208.00277v1 [cs.CV])
- Authors : Zhiqin Chen, Thomas Funkhouser, Peter Hedman, Andrea Tagliasacchi
- Link : [http://arxiv.org/abs/2208.00277](http://arxiv.org/abs/2208.00277)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**s) have demonstrated amazing ability to synthesize images of 3D scenes from novel views. However, they rely upon specialized volumetric rendering algorithms based on ray marching that are mismatched to the capabilities of widely deployed graphics hardware. This paper introduces a new **NeRF** representation based on textured polygons that can synthesize novel images efficiently with standard rendering pipelines. The **NeRF** is represented as a set of polygons with textures representing binary opacities and feature vectors. Traditional rendering of the polygons with a z-buffer yields an image with features at every pixel, which are interpreted by a small, view-dependent MLP running in a fragment shader to produce a final pixel color. This approach enables **NeRF**s to be rendered with the traditional polygon rasterization pipeline, which provides massive pixel-level parallelism, achieving interactive frame rates on a wide range of compute platforms, including mobile phones.  
### A **Real-time** Edge-AI System for Reef Surveys. (arXiv:2208.00598v1 [cs.LG])
- Authors : Yang Li, Jiajun Liu, Brano Kusy, Ross Marchant, Brendan Do, Torsten Merz, Joey Crosswell, Andy Steven, Lachlan Tychsen, David Ahmedt, Jeremy Oorloff, Peyman Moghadam, Russ Babcock, Megha Malpani, Ard Oerlemans
- Link : [http://arxiv.org/abs/2208.00598](http://arxiv.org/abs/2208.00598)
> ABSTRACT  :  Crown-of-Thorn Starfish (COTS) outbreaks are a major cause of coral loss on the Great Barrier Reef (GBR) and substantial surveillance and control programs are ongoing to manage COTS populations to ecologically sustainable levels. In this paper, we present a comprehensive real-time machine learning-based underwater data collection and curation system on edge devices for COTS monitoring. In particular, we leverage the power of deep learning-based object detection techniques, and propose a resource-efficient COTS detector that performs detection inferences on the edge device to assist marine experts with COTS identification during the data collection phase. The preliminary results show that several strategies for improving computational efficiency (e.g., batch-wise processing, frame skipping, model input size) can be combined to run the proposed detection model on edge hardware with low resource consumption and low information loss.  
### TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
- Authors : Reza Azad, Moein Heidari, Moein Shariatnia, Ehsan Khodapanah, Sanaz Karimijafarbigloo, Ehsan Adeli, Dorit Merhof
- Link : [http://arxiv.org/abs/2208.00713](http://arxiv.org/abs/2208.00713)
> ABSTRACT  :  Convolutional neural networks (CNNs) have been the de facto standard in a diverse set of computer vision tasks for many years. Especially, deep neural networks based on seminal architectures such as U-shaped models with skip-connections or atrous convolution with pyramid pooling have been tailored to a wide range of medical image analysis tasks. The main advantage of such architectures is that they are prone to detaining versatile local features. However, as a general consensus, CNNs fail to capture long-range dependencies and spatial correlations due to the intrinsic property of confined receptive field size of convolution operations. Alternatively, Transformer, profiting from global information modelling that stems from the self-attention mechanism, has recently attained remarkable performance in natural language processing and computer vision. Nevertheless, previous studies prove that both local and global features are critical for a deep model in dense prediction, such as segmenting complicated structures with disparate shapes and configurations. To this end, this paper proposes TransDeepLab, a novel DeepLab-like pure Transformer for medical image segmentation. Specifically, we exploit hierarchical **Swin**-Transformer with shifted windows to extend the DeepLabv3 and model the Atrous Spatial Pyramid Pooling (ASPP) module. A thorough search of the relevant literature yielded that we are the first to model the seminal DeepLab model with a pure Transformer-based model. Extensive experiments on various medical image segmentation tasks verify that our approach performs superior or on par with most contemporary works on an amalgamation of Vision Transformer and CNN-based methods, along with a significant reduction of model complexity. The codes and trained models are publicly available at https://github.com/rezazad68/transdeeplab  
### A rigorous introduction to linear models. (arXiv:2105.04240v4 [cs.LG] UPDATED)
- Authors : Jun Lu
- Link : [http://arxiv.org/abs/2105.04240](http://arxiv.org/abs/2105.04240)
> ABSTRACT  :  This survey is meant to provide an introduction to linear models and the theories behind them. Our goal is to give a rigorous introduction to the readers with prior **exposure** to ordinary least squares. In machine learning, the output is usually a nonlinear function of the input. Deep learning even aims to find a nonlinear dependence with many layers which require a large amount of computation. However, most of these algorithms build upon simple linear models. We then describe linear models from different views and find the properties and theories behind the models. The linear model is the main technique in regression problems and the primary tool for it is the least squares approximation which minimizes a sum of squared errors. This is a natural choice when we're interested in finding the regression function which minimizes the corresponding expected squared error. This survey is primarily a summary of purpose, significance of important theories behind linear models, e.g., distribution theory, minimum variance estimator. We first describe ordinary least squares from three different points of view upon which we disturb the model with random noise and Gaussian noise. By Gaussian noise, the model gives rise to the likelihood so that we introduce a maximum likelihood estimator. It also develops some distribution theories via this Gaussian disturbance. The distribution theory of least squares will help us answer various questions and introduce related applications. We then prove least squares is the best unbiased linear model in the sense of mean squared error and most importantly, it actually approaches the theoretical limit. We end up with linear models with the Bayesian approach and beyond.  
## cs.AI
---
### STrajNet: Occupancy Flow Prediction via Multi-modal **Swin** Transformer. (arXiv:2208.00394v1 [cs.CV])
- Authors : Haochen Liu, Zhiyu Huang, Chen Lv
- Link : [http://arxiv.org/abs/2208.00394](http://arxiv.org/abs/2208.00394)
> ABSTRACT  :  Making an accurate prediction of occupancy and flow is essential to enable better safety and interaction for autonomous vehicles under complex traffic scenarios. This work proposes STrajNet: a multi-modal **Swin** Transformerbased framework for effective scene occupancy and flow predictions. We employ **Swin** Transformer to encode the image and interaction-aware motion representations and propose a cross-attention module to inject motion awareness into grid cells across different time steps. Flow and occupancy predictions are then decoded through temporalsharing Pyramid decoders. The proposed method shows competitive prediction accuracy and other evaluation metrics in the Waymo Open Dataset benchmark.  
### Autonomously Untangling Long Cables. (arXiv:2207.07813v2 [cs.RO] UPDATED)
- Authors : Vainavi Viswanath, Kaushik Shivakumar, Justin Kerr, Brijen Thananjeyan, Ellen Novoseller, Jeffrey Ichnowski, Alejandro Escontrela, Michael Laskey, Ken Goldberg
- Link : [http://arxiv.org/abs/2207.07813](http://arxiv.org/abs/2207.07813)
> ABSTRACT  :  Cables are ubiquitous in many settings and it is often useful to untangle them. However, cables are prone to self-occlusions and knots, making them difficult to perceive and manipulate. The challenge increases with cable length: long cables require more complex slack management to facilitate observability and reachability. In this paper, we focus on autonomously untangling cables up to 3 meters in length using a **bilateral** robot. We develop RGBD perception and motion primitives to efficiently untangle long cables and novel gripper jaws specialized for this task. We present Sliding and Grasping for Tangle Manipulation (SGTM), an algorithm that composes these primitives to iteratively untangle cables with success rates of 67% on isolated overhand and figure-eight knots and 50% on more complex configurations. Supplementary material, visualizations, and videos can be found at https://sites.google.com/view/rss-2022-untangling/home.  
### End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v2 [cs.CV] UPDATED)
- Authors : Zelin Zhao, Jiaya Jia
- Link : [http://arxiv.org/abs/2207.14741](http://arxiv.org/abs/2207.14741)
> ABSTRACT  :  In this paper, we present a simple seq2seq formulation for view synthesis where we take a set of ray points as input and output colors corresponding to the rays. Directly applying a standard transformer on this seq2seq formulation has two limitations. First, the standard attention cannot successfully fit the volumetric rendering procedure, and therefore high-frequency components are missing in the synthesized views. Second, applying global attention to all rays and pixels is extremely inefficient. Inspired by the neural radiance field (**NeRF**), we propose the **NeRF** attention (**NeRF**A) to address the above problems. On the one hand, **NeRF**A considers the volumetric rendering equation as a soft feature modulation procedure. In this way, the feature modulation enhances the transformers with the **NeRF**-like inductive bias. On the other hand, **NeRF**A performs multi-stage attention to reduce the computational overhead. Furthermore, the **NeRF**A model adopts the ray and pixel transformers to learn the interactions between rays and pixels. **NeRF**A demonstrates superior performance over **NeRF** and NerFormer on four datasets: DeepVoxels, Blender, LLFF, and CO3D. Besides, **NeRF**A establishes a new state-of-the-art under two settings: the single-scene view synthesis and the category-centric novel view synthesis. The code will be made publicly available.  
# Paper List
---
## cs.CV
---
**172** new papers in cs.CV:-) 
1. FastGeodis: Fast Generalised Geodesic Distance Transform. (arXiv:2208.00001v1 [cs.CV])
2. HOB-CNN: Hallucination of Occluded Branches with a Convolutional Neural Network for 2D Fruit Trees. (arXiv:2208.00002v1 [cs.CV])
3. Testing Relational Understanding in Text-Guided Image Generation. (arXiv:2208.00005v1 [cs.CV])
4. Paddy Leaf diseases identification on Infrared Images based on Convolutional Neural Networks. (arXiv:2208.00031v1 [cs.CV])
5. A review of Deep learning Techniques for COVID-19 identification on Chest CT images. (arXiv:2208.00032v1 [eess.IV])
6. MulViMotion: Shape-aware 3D Myocardial Motion Tracking from Multi-View Cardiac MRI. (arXiv:2208.00034v1 [eess.IV])
7. Generating Complex 4D Expression Transitions by Learning Face Landmark Trajectories. (arXiv:2208.00050v1 [cs.CV])
8. UAVM: A Unified Model for Audio-Visual Learning. (arXiv:2208.00061v1 [cs.CV])
9. Machine Learning and Computer Vision Techniques in Bee Monitoring Applications. (arXiv:2208.00085v1 [cs.CV])
10. Low-complexity Approximate Convolutional Neural Networks. (arXiv:2208.00087v1 [cs.LG])
11. Explicit Occlusion Reasoning for Multi-person 3D Human Pose Estimation. (arXiv:2208.00090v1 [cs.CV])
12. Robust Trajectory Prediction against Adversarial Attacks. (arXiv:2208.00094v1 [cs.LG])
13. Weakly Supervised Deep Instance Nuclei Detection using Points Annotation in 3D Cardiovascular Immunofluorescent Images. (arXiv:2208.00098v1 [cs.CV])
14. Neural Correspondence Field for Object Pose Estimation. (arXiv:2208.00113v1 [cs.CV])
15. Adaptive Feature Fusion for Cooperative Perception using LiDAR Point Clouds. (arXiv:2208.00116v1 [cs.CV])
16. DAS: Densely-Anchored Sampling for Deep Metric Learning. (arXiv:2208.00119v1 [cs.CV])
17. Few-Shot Class-Incremental Learning from an Open-Set Perspective. (arXiv:2208.00147v1 [cs.CV])
18. Learning Shadow Correspondence for Video Shadow Detection. (arXiv:2208.00150v1 [cs.CV])
19. Learning Feature Decomposition for Domain Adaptive Monocular Depth Estimation. (arXiv:2208.00160v1 [cs.CV])
20. Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
21. Distilled Low Rank Neural Radiance Field with Quantization for Light Field Compression. (arXiv:2208.00164v1 [cs.CV])
22. Temporal extrapolation of heart wall segmentation in cardiac magnetic resonance images via pixel tracking. (arXiv:2208.00165v1 [eess.IV])
23. Virtual Reality Simulator for Fetoscopic Spina Bifida Repair Surgery. (arXiv:2208.00169v1 [cs.CV])
24. A Survey on Masked Autoencoder for Self-supervised Learning in Vision and Beyond. (arXiv:2208.00173v1 [cs.CV])
25. Few-shot Single-view 3D Reconstruction with Memory Prior Contrastive Network. (arXiv:2208.00183v1 [cs.CV])
26. LRIP-Net: Low-Resolution Image Prior based Network for Limited-Angle CT Reconstruction. (arXiv:2208.00207v1 [eess.IV])
27. Multiple Categories Of Visual Smoke Detection Database. (arXiv:2208.00210v1 [cs.CV])
28. Towards Privacy-Preserving, Real-Time and Lossless Feature Matching. (arXiv:2208.00214v1 [cs.CV])
29. Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation. (arXiv:2208.00219v1 [cs.CV])
30. PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds. (arXiv:2208.00223v1 [cs.CV])
31. Learning Pseudo Front Depth for 2D Forward-Looking Sonar-based Multi-view Stereo. (arXiv:2208.00233v1 [cs.CV])
32. RBP-Pose: Residual Bounding Box Projection for Category-Level Pose Estimation. (arXiv:2208.00237v1 [cs.CV])
33. Improving Fine-tuning of Self-supervised Models with Contrastive Initialization. (arXiv:2208.00238v1 [cs.CV])
34. Revisiting the Critical Factors of Augmentation-Invariant Representation Learning. (arXiv:2208.00275v1 [cs.CV])
35. Mobile**NeRF**: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. (arXiv:2208.00277v1 [cs.CV])
36. Point Primitive Transformer for Long-Term 4D Point Cloud Video Understanding. (arXiv:2208.00281v1 [cs.CV])
37. Simplex Clustering via sBeta with Applications to Online Adjustments of Black-Box Predictions. (arXiv:2208.00287v1 [cs.CV])
38. Doubly Deformable Aggregation of Covariance Matrices for Few-shot Segmentation. (arXiv:2208.00306v1 [cs.CV])
39. Delving into Effective Gradient Matching for Dataset Condensation. (arXiv:2208.00311v1 [cs.LG])
40. enpheeph: A Fault Injection Framework for Spiking and Compressed Deep Neural Networks. (arXiv:2208.00328v1 [cs.NE])
41. Towards Intercultural Affect Recognition: Audio-Visual Affect Recognition in the Wild Across Six Cultures. (arXiv:2208.00344v1 [cs.CV])
42. One for All: One-stage Referring Expression Comprehension with Dynamic Reasoning. (arXiv:2208.00361v1 [cs.CV])
43. Skeleton-Parted Graph Scattering Networks for 3D Human Motion Prediction. (arXiv:2208.00368v1 [cs.CV])
44. Neuro-Symbolic Learning: Principles and Applications in Ophthalmology. (arXiv:2208.00374v1 [cs.CV])
45. Less is More: Consistent Video Depth Estimation with Masked Frames Modeling. (arXiv:2208.00380v1 [cs.CV])
46. Evaluating Table Structure Recognition: A New Perspective. (arXiv:2208.00385v1 [cs.CV])
47. Robotic Dough Shaping. (arXiv:2208.00386v1 [cs.RO])
48. PVBM: A Python Vasculature Biomarker Toolbox Based On Retinal Blood Vessel Segmentation. (arXiv:2208.00392v1 [cs.CV])
49. STrajNet: Occupancy Flow Prediction via Multi-modal **Swin** Transformer. (arXiv:2208.00394v1 [cs.CV])
50. FixMatchSeg: Fixing FixMatch for Semi-Supervised Semantic Segmentation. (arXiv:2208.00400v1 [cs.CV])
51. Speckle2Speckle: Unsupervised Learning of Ultrasound Speckle Filtering Without Clean Data. (arXiv:2208.00402v1 [eess.IV])
52. DA$^2$ Dataset: Toward Dexterity-Aware Dual-Arm Grasping. (arXiv:2208.00408v1 [cs.RO])
53. Robust Real-World Image Super-Resolution against Adversarial Attacks. (arXiv:2208.00428v1 [cs.CV])
54. Toward Understanding WordArt: Corner-Guided Transformer for Scene Text Recognition. (arXiv:2208.00438v1 [cs.CV])
55. Design What You Desire: Icon Generation from Orthogonal Application and Theme Labels. (arXiv:2208.00439v1 [cs.CV])
56. BYOLMed3D: Self-Supervised Representation Learning of Medical Videos using Gradient Accumulation Assisted 3D BYOL Framework. (arXiv:2208.00444v1 [cs.CV])
57. Out-of-Distribution Detection with Semantic Mismatch under Masking. (arXiv:2208.00446v1 [cs.CV])
58. SdAE: Self-distillated Masked Autoencoder. (arXiv:2208.00449v1 [cs.CV])
59. One-Shot Medical Landmark Localization by Edge-Guided Transform and Noisy Landmark Refinement. (arXiv:2208.00453v1 [cs.CV])
60. INSightR-Net: Interpretable Neural Network for Regression using Similarity-based Comparisons to Prototypical Examples. (arXiv:2208.00457v1 [cs.CV])
61. COCOA: Cross Modality Contrastive Learning for Sensor Data. (arXiv:2208.00467v1 [cs.CV])
62. Feather-Light Fourier Domain Adaptation in Magnetic Resonance Imaging. (arXiv:2208.00474v1 [eess.IV])
63. Augmenting Vision Language Pretraining by Learning Codebook with Visual Semantics. (arXiv:2208.00475v1 [cs.CV])
64. One Object at a Time: Accurate and Robust Structure From Motion for Robots. (arXiv:2208.00487v1 [cs.RO])
65. Deep Active Learning with Budget Annotation. (arXiv:2208.00508v1 [cs.LG])
66. Assessing The Performance of YOLOv5 Algorithm for Detecting Volunteer Cotton Plants in Corn Fields at Three Different Growth Stages. (arXiv:2208.00519v1 [cs.CV])
67. CloudAttention: Efficient Multi-Scale Attention Scheme For 3D Point Cloud Learning. (arXiv:2208.00524v1 [cs.CV])
68. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v1 [cs.CV])
69. Analysis of Semi-Supervised Methods for Facial Expression Recognition. (arXiv:2208.00544v1 [cs.CV])
70. AvatarGen: a 3D Generative Model for Animatable Human Avatars. (arXiv:2208.00561v1 [cs.CV])
71. CLIFF: Carrying Location Information in Full Frames into Human Pose and Shape Estimation. (arXiv:2208.00571v1 [cs.CV])
72. An Enhanced Deep Learning Technique for Prostate Cancer Identification Based on MRI Scans. (arXiv:2208.00583v1 [eess.IV])
73. Breast Cancer Classification Based on Histopathological Images Using a Deep Learning Capsule Network. (arXiv:2208.00594v1 [eess.IV])
74. Accurate Polygonal Mapping of Buildings in Satellite Imagery. (arXiv:2208.00609v1 [cs.CV])
75. Improving Fine-Grained Visual Recognition in Low Data Regimes via Self-Boosting Attention Mechanism. (arXiv:2208.00617v1 [cs.CV])
76. Software Package for Automated Analysis of Lung Ultrasound Videos. (arXiv:2208.00620v1 [eess.IV])
77. Quality Evaluation of Arbitrary Style Transfer: Subjective Study and Objective Metric. (arXiv:2208.00623v1 [cs.CV])
78. A Rotation Meanout Network with Invariance for Dermoscopy Image Classification and Retrieval. (arXiv:2208.00627v1 [cs.CV])
79. XOOD: Extreme Value Based Out-Of-Distribution Detection For Image Classification. (arXiv:2208.00629v1 [cs.LG])
80. Multi-spectral Vehicle Re-identification with Cross-directional Consistency Network and a High-quality Benchmark. (arXiv:2208.00632v1 [cs.CV])
81. Dress Well via Fashion Cognitive Learning. (arXiv:2208.00639v1 [cs.CV])
82. Lung nodules segmentation from CT with DeepHealth toolkit. (arXiv:2208.00641v1 [eess.IV])
83. UniToBrain dataset: a Brain Perfusion Dataset. (arXiv:2208.00650v1 [eess.IV])
84. SiamixFormer: A Siamese Transformer Network For Building Detection And Change Detection From Bi-Temporal Remote Sensing Images. (arXiv:2208.00657v1 [cs.CV])
85. Local Perception-Aware Transformer for Aerial Tracking. (arXiv:2208.00662v1 [cs.CV])
86. Generative Bias for Visual Question Answering. (arXiv:2208.00690v1 [cs.CV])
87. Cross Attention Based Style Distribution for Controllable Person Image Synthesis. (arXiv:2208.00712v1 [cs.CV])
88. TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
89. Fashion Recommendation Based on Style and Social Events. (arXiv:2208.00725v1 [cs.CV])
90. CSDN: Cross-modal Shape-transfer Dual-refinement Network for Point Cloud Completion. (arXiv:2208.00751v1 [cs.CV])
91. Tutorial on the development of AI models for medical image analysis. (arXiv:2208.00766v1 [eess.IV])
92. Multimodal Neural Machine Translation with Search Engine Based Image Retrieval. (arXiv:2208.00767v1 [cs.CV])
93. Brain Tumor Diagnosis and Classification via Pre-Trained Convolutional Neural Networks. (arXiv:2208.00768v1 [eess.IV])
94. Real Time Object Detection System with YOLO and CNN Models: A Review. (arXiv:2208.00773v1 [cs.CV])
95. Interaction Mix and Match: Synthesizing Close Interaction using Conditional Hierarchical GAN with Multi-Hot Class Embedding. (arXiv:2208.00774v1 [cs.GR])
96. Pavementscapes: a large-scale hierarchical image dataset for asphalt pavement damage segmentation. (arXiv:2208.00775v1 [cs.CV])
97. Deep 360$^\circ$ Optical Flow Estimation Based on Multi-Projection Fusion. (arXiv:2208.00776v1 [cs.CV])
98. $\textrm{D}^3\textrm{Former}$: Debiased Dual Distilled Transformer for Incremental Learning. (arXiv:2208.00777v1 [cs.CV])
99. Union-net: A deep neural network model adapted to small data sets. (arXiv:2012.13044v2 [cs.CV] UPDATED)
100. Constructing Robust Emotional State-based Feature with a Novel Voting Scheme for Multi-modal Deception Detection in Videos. (arXiv:2104.08373v2 [cs.CV] UPDATED)
101. Generative Adversarial Networks via a Composite Annealing of Noise and Diffusion. (arXiv:2105.00220v3 [cs.LG] UPDATED)
102. Unpaired Depth Super-Resolution in the Wild. (arXiv:2105.12038v3 [cs.CV] UPDATED)
103. Multi-Exit Semantic Segmentation Networks. (arXiv:2106.03527v3 [cs.CV] UPDATED)
104. On Anytime Learning at Macroscale. (arXiv:2106.09563v4 [cs.LG] UPDATED)
105. Score-Based Point Cloud Denoising (Learning Gradient Fields for Point Cloud Denoising). (arXiv:2107.10981v4 [cs.CV] UPDATED)
106. How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?. (arXiv:2108.04893v6 [cs.CV] UPDATED)
107. Cross-Modal Graph with Meta Concepts for Video Captioning. (arXiv:2108.06458v3 [cs.CV] UPDATED)
108. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v4 [cs.CV] UPDATED)
109. A Joint Graph and Image Convolution Network for Automatic Brain Tumor Segmentation. (arXiv:2109.05580v2 [eess.IV] UPDATED)
110. Spiking neural networks trained via proxy. (arXiv:2109.13208v3 [cs.NE] UPDATED)
111. Learning Structural Representations for Recipe Generation and Food Retrieval. (arXiv:2110.01209v2 [cs.CV] UPDATED)
112. Trajectory Prediction with Graph-based Dual-scale Context Fusion. (arXiv:2111.01592v2 [cs.RO] UPDATED)
113. CodEx: A Modular Framework for Joint Temporal De-blurring and Tomographic Reconstruction. (arXiv:2111.06069v3 [eess.IV] UPDATED)
114. Stacked BNAS: Rethinking Broad Convolutional Neural Network for Neural Architecture Search. (arXiv:2111.07722v4 [cs.CV] UPDATED)
115. FRT-PAD: Effective Presentation Attack Detection Driven by Face Related Task. (arXiv:2111.11046v2 [cs.CV] UPDATED)
116. Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach. (arXiv:2112.15031v3 [cs.CV] UPDATED)
117. Problem-dependent attention and effort in neural networks with an application to image resolution. (arXiv:2201.01415v2 [cs.CV] UPDATED)
118. POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v4 [eess.IV] UPDATED)
119. Misinformation Detection in Social Media Video Posts. (arXiv:2202.07706v2 [cs.CV] UPDATED)
120. VLP: A Survey on Vision-Language Pre-training. (arXiv:2202.09061v4 [cs.CV] UPDATED)
121. Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance. (arXiv:2202.12387v3 [cs.LG] UPDATED)
122. TransKD: Transformer Knowledge Distillation for Efficient Semantic Segmentation. (arXiv:2202.13393v2 [cs.CV] UPDATED)
123. Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images. (arXiv:2203.02846v3 [cs.CV] UPDATED)
124. Coordinate Translator for Learning Deformable Medical Image Registration. (arXiv:2203.03626v2 [eess.IV] UPDATED)
125. Learning-based Localizability Estimation for Robust LiDAR Localization. (arXiv:2203.05698v2 [cs.RO] UPDATED)
126. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v4 [cs.CV] UPDATED)
127. SocialVAE: Human Trajectory Prediction using Timewise Latents. (arXiv:2203.08207v4 [cs.CV] UPDATED)
128. Learning Where To Look -- Generative NAS is Surprisingly Efficient. (arXiv:2203.08734v2 [cs.LG] UPDATED)
129. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v3 [cs.LG] UPDATED)
130. PACS: A Dataset for Physical Audiovisual CommonSense Reasoning. (arXiv:2203.11130v3 [cs.LG] UPDATED)
131. Masked Discrimination for Self-Supervised Learning on Point Clouds. (arXiv:2203.11183v2 [cs.CV] UPDATED)
132. DAN: a Segmentation-free Document Attention Network for Handwritten Document Recognition. (arXiv:2203.12273v3 [cs.CV] UPDATED)
133. Is Geometry Enough for Matching in Visual Localization?. (arXiv:2203.12979v2 [cs.CV] UPDATED)
134. How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?. (arXiv:2203.14221v2 [cs.CV] UPDATED)
135. Leveraging Clinically Relevant Biometric Constraints To Supervise A Deep Learning Model For The Accurate Caliper Placement To Obtain Sonographic Measurements Of The Fetal Brain. (arXiv:2203.14482v2 [eess.IV] UPDATED)
136. Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature Aggregation and Pyramid Decoders. (arXiv:2204.04944v2 [cs.CV] UPDATED)
137. CXR-FL: Deep Learning-Based Chest X-ray Image Analysis Using Federated Learning. (arXiv:2204.05203v2 [eess.IV] UPDATED)
138. Few-shot Learning with Noisy Labels. (arXiv:2204.05494v2 [cs.CV] UPDATED)
139. Unidirectional Video Denoising by Mimicking Backward Recurrent Modules with Look-ahead Forward Ones. (arXiv:2204.05532v3 [cs.CV] UPDATED)
140. Neural Space-filling Curves. (arXiv:2204.08453v2 [cs.CV] UPDATED)
141. Joint-Modal Label Denoising for Weakly-Supervised Audio-Visual Video Parsing. (arXiv:2204.11573v4 [cs.CV] UPDATED)
142. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v2 [cs.CV] UPDATED)
143. BlobGAN: Spatially Disentangled Scene Representations. (arXiv:2205.02837v2 [cs.CV] UPDATED)
144. Shadow-Aware Dynamic Convolution for Shadow Removal. (arXiv:2205.04908v2 [cs.CV] UPDATED)
145. Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating. (arXiv:2205.05874v4 [cs.LG] UPDATED)
146. GARDNet: Robust Multi-View Network for Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v3 [eess.IV] UPDATED)
147. Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v2 [cs.CV] UPDATED)
148. GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v3 [cs.CV] UPDATED)
149. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v2 [cs.CV] UPDATED)
150. Dynamic Structured Illumination Microscopy with a Neural Space-time Model. (arXiv:2206.01397v2 [physics.optics] UPDATED)
151. NCAGC: A Neighborhood Contrast Framework for Attributed Graph Clustering. (arXiv:2206.07897v2 [cs.CV] UPDATED)
152. Hybrid Facial Expression Recognition (FER2013) Model for Real-Time Emotion Classification and Prediction. (arXiv:2206.09509v2 [cs.CV] UPDATED)
153. Feature Representation Learning for Robust Retinal Disease Detection from Optical Coherence Tomography Images. (arXiv:2206.12136v2 [eess.IV] UPDATED)
154. Timestamp-Supervised Action Segmentation with Graph Convolutional Networks. (arXiv:2206.15031v3 [cs.CV] UPDATED)
155. Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis. (arXiv:2207.00762v2 [cs.CV] UPDATED)
156. S$^{5}$Mars: Self-Supervised and Semi-Supervised Learning for Mars Segmentation. (arXiv:2207.01200v2 [cs.CV] UPDATED)
157. FishFormer: Annulus Slicing-based Transformer for Fisheye Rectification with Efficacy Domain Exploration. (arXiv:2207.01925v2 [cs.CV] UPDATED)
158. IDEA: Increasing Text Diversity via Online Multi-Label Recognition for Vision-Language Pre-training. (arXiv:2207.05333v2 [cs.CV] UPDATED)
159. Clover: Towards A Unified Video-Language Alignment and Fusion Model. (arXiv:2207.07885v2 [cs.CV] UPDATED)
160. Object-Compositional Neural Implicit Surfaces. (arXiv:2207.09686v2 [cs.CV] UPDATED)
161. Meta Spatio-Temporal Debiasing for Video Scene Graph Generation. (arXiv:2207.11441v2 [cs.CV] UPDATED)
162. Inter-model Interpretability: Self-supervised Models as a Case Study. (arXiv:2207.11837v2 [cs.CV] UPDATED)
163. Convolutional Embedding Makes Hierarchical Vision Transformer Stronger. (arXiv:2207.13317v2 [cs.CV] UPDATED)
164. Adaptive sampling for scanning pixel cameras. (arXiv:2207.13460v2 [cs.CV] UPDATED)
165. Future Unruptured Intracranial Aneurysm Growth Prediction using Mesh Convolutional Neural Networks. (arXiv:2207.13518v2 [eess.IV] UPDATED)
166. Lighting (In)consistency of Paint by Text. (arXiv:2207.13744v2 [cs.CV] UPDATED)
167. Towards Large-Scale Small Object Detection: Survey and Benchmarks. (arXiv:2207.14096v2 [cs.CV] UPDATED)
168. Content-oriented learned image compression. (arXiv:2207.14168v2 [cs.CV] UPDATED)
169. Graph Inverse Reinforcement Learning from Diverse Videos. (arXiv:2207.14299v2 [cs.LG] UPDATED)
170. Prompting for Multi-Modal Tracking. (arXiv:2207.14571v2 [cs.CV] UPDATED)
171. Replacing the Framingham-based equation for prediction of cardiovascular disease risk and adverse outcome by using artificial intelligence and retinal imaging. (arXiv:2207.14685v2 [eess.IV] UPDATED)
172. End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v2 [cs.CV] UPDATED)
## eess.IV
---
**45** new papers in eess.IV:-) 
1. FastGeodis: Fast Generalised Geodesic Distance Transform. (arXiv:2208.00001v1 [cs.CV])
2. HOB-CNN: Hallucination of Occluded Branches with a Convolutional Neural Network for 2D Fruit Trees. (arXiv:2208.00002v1 [cs.CV])
3. A review of Deep learning Techniques for COVID-19 identification on Chest CT images. (arXiv:2208.00032v1 [eess.IV])
4. MulViMotion: Shape-aware 3D Myocardial Motion Tracking from Multi-View Cardiac MRI. (arXiv:2208.00034v1 [eess.IV])
5. Robust Rayleigh Regression Method for SAR Image Processing in Presence of Outliers. (arXiv:2208.00097v1 [stat.AP])
6. Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
7. Temporal extrapolation of heart wall segmentation in cardiac magnetic resonance images via pixel tracking. (arXiv:2208.00165v1 [eess.IV])
8. LRIP-Net: Low-Resolution Image Prior based Network for Limited-Angle CT Reconstruction. (arXiv:2208.00207v1 [eess.IV])
9. Speckle2Speckle: Unsupervised Learning of Ultrasound Speckle Filtering Without Clean Data. (arXiv:2208.00402v1 [eess.IV])
10. Robust Real-World Image Super-Resolution against Adversarial Attacks. (arXiv:2208.00428v1 [cs.CV])
11. Photon-Limited Blind Deconvolution using Unsupervised Iterative Kernel Estimation. (arXiv:2208.00451v1 [eess.IV])
12. Learning while Acquisition: Towards Active Learning Framework for Beamforming in Ultrasound Imaging. (arXiv:2208.00464v1 [eess.SP])
13. Feather-Light Fourier Domain Adaptation in Magnetic Resonance Imaging. (arXiv:2208.00474v1 [eess.IV])
14. An Enhanced Deep Learning Technique for Prostate Cancer Identification Based on MRI Scans. (arXiv:2208.00583v1 [eess.IV])
15. Breast Cancer Classification Based on Histopathological Images Using a Deep Learning Capsule Network. (arXiv:2208.00594v1 [eess.IV])
16. Software Package for Automated Analysis of Lung Ultrasound Videos. (arXiv:2208.00620v1 [eess.IV])
17. Quality Evaluation of Arbitrary Style Transfer: Subjective Study and Objective Metric. (arXiv:2208.00623v1 [cs.CV])
18. Lung nodules segmentation from CT with DeepHealth toolkit. (arXiv:2208.00641v1 [eess.IV])
19. UniToBrain dataset: a Brain Perfusion Dataset. (arXiv:2208.00650v1 [eess.IV])
20. TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
21. Tutorial on the development of AI models for medical image analysis. (arXiv:2208.00766v1 [eess.IV])
22. Brain Tumor Diagnosis and Classification via Pre-Trained Convolutional Neural Networks. (arXiv:2208.00768v1 [eess.IV])
23. Real Time Object Detection System with YOLO and CNN Models: A Review. (arXiv:2208.00773v1 [cs.CV])
24. Deep COVID-19 Recognition using Chest X-ray Images: A Comparative Analysis. (arXiv:2208.00784v1 [eess.IV])
25. A Transformer-based Neural Language Model that Synthesizes Brain Activation Maps from Free-Form Text Queries. (arXiv:2208.00840v1 [q-bio.NC])
26. AdaWCT: Adaptive Whitening and Coloring Style Injection. (arXiv:2208.00921v1 [cs.CV])
27. Fast Two-step Blind Optical Aberration Correction. (arXiv:2208.00950v1 [eess.IV])
28. A Joint Graph and Image Convolution Network for Automatic Brain Tumor Segmentation. (arXiv:2109.05580v2 [eess.IV] UPDATED)
29. CodEx: A Modular Framework for Joint Temporal De-blurring and Tomographic Reconstruction. (arXiv:2111.06069v3 [eess.IV] UPDATED)
30. Problem-dependent attention and effort in neural networks with an application to image resolution. (arXiv:2201.01415v2 [cs.CV] UPDATED)
31. POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v4 [eess.IV] UPDATED)
32. TransKD: Transformer Knowledge Distillation for Efficient Semantic Segmentation. (arXiv:2202.13393v2 [cs.CV] UPDATED)
33. Coordinate Translator for Learning Deformable Medical Image Registration. (arXiv:2203.03626v2 [eess.IV] UPDATED)
34. Learning Nonlocal Sparse and Low-Rank Models for Image Compressive Sensing. (arXiv:2203.09656v3 [eess.IV] UPDATED)
35. Leveraging Clinically Relevant Biometric Constraints To Supervise A Deep Learning Model For The Accurate Caliper Placement To Obtain Sonographic Measurements Of The Fetal Brain. (arXiv:2203.14482v2 [eess.IV] UPDATED)
36. CXR-FL: Deep Learning-Based Chest X-ray Image Analysis Using Federated Learning. (arXiv:2204.05203v2 [eess.IV] UPDATED)
37. GlacierNet2: A Hybrid Multi-Model Learning Architecture for Alpine Glacier Mapping. (arXiv:2204.05818v2 [eess.IV] UPDATED)
38. GARDNet: Robust Multi-View Network for Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v3 [eess.IV] UPDATED)
39. Image Super-resolution with An Enhanced Group Convolutional Neural Network. (arXiv:2205.14548v2 [cs.CV] UPDATED)
40. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v2 [cs.CV] UPDATED)
41. Dynamic Structured Illumination Microscopy with a Neural Space-time Model. (arXiv:2206.01397v2 [physics.optics] UPDATED)
42. Feature Representation Learning for Robust Retinal Disease Detection from Optical Coherence Tomography Images. (arXiv:2206.12136v2 [eess.IV] UPDATED)
43. Future Unruptured Intracranial Aneurysm Growth Prediction using Mesh Convolutional Neural Networks. (arXiv:2207.13518v2 [eess.IV] UPDATED)
44. Content-oriented learned image compression. (arXiv:2207.14168v2 [cs.CV] UPDATED)
45. Replacing the Framingham-based equation for prediction of cardiovascular disease risk and adverse outcome by using artificial intelligence and retinal imaging. (arXiv:2207.14685v2 [eess.IV] UPDATED)
## cs.LG
---
**187** new papers in cs.LG:-) 
1. RangL: A Reinforcement Learning Competition Platform. (arXiv:2208.00003v1 [cs.LG])
2. Testing Relational Understanding in Text-Guided Image Generation. (arXiv:2208.00005v1 [cs.CV])
3. A review of Deep learning Techniques for COVID-19 identification on Chest CT images. (arXiv:2208.00032v1 [eess.IV])
4. Personalised recommendations of sleep behaviour with neural networks using sleep diaries captured in Sleepio. (arXiv:2208.00033v1 [cs.LG])
5. MulViMotion: Shape-aware 3D Myocardial Motion Tracking from Multi-View Cardiac MRI. (arXiv:2208.00034v1 [eess.IV])
6. Enhanced gradient-based MCMC in discrete spaces. (arXiv:2208.00040v1 [stat.ML])
7. Topology-Driven Generative Completion of Lacunae in Molecular Data. (arXiv:2208.00063v1 [cs.LG])
8. Sampling Attacks on Meta Reinforcement Learning: A Minimax Formulation and Complexity Analysis. (arXiv:2208.00081v1 [cs.LG])
9. Low-complexity Approximate Convolutional Neural Networks. (arXiv:2208.00087v1 [cs.LG])
10. Improved Policy Optimization for Online Imitation Learning. (arXiv:2208.00088v1 [cs.LG])
11. Robust Trajectory Prediction against Adversarial Attacks. (arXiv:2208.00094v1 [cs.LG])
12. Robust Rayleigh Regression Method for SAR Image Processing in Presence of Outliers. (arXiv:2208.00097v1 [stat.AP])
13. Neural Correspondence Field for Object Pose Estimation. (arXiv:2208.00113v1 [cs.CV])
14. Local Graph Embeddings Based on Neighbors Degree Frequency of Nodes. (arXiv:2208.00152v1 [cs.SI])
15. Reinforcement learning with experience replay and adaptation of action dispersion. (arXiv:2208.00156v1 [cs.LG])
16. Resolution **enhancement** of placenta histological images using deep learning. (arXiv:2208.00163v1 [eess.IV])
17. A Survey on Masked Autoencoder for Self-supervised Learning in Vision and Beyond. (arXiv:2208.00173v1 [cs.CV])
18. Streaming Algorithms for Diversity Maximization with Fairness Constraints. (arXiv:2208.00194v1 [cs.DS])
19. Adding Context to Source Code Representations for Deep Learning. (arXiv:2208.00203v1 [cs.SE])
20. Tackling Neural Architecture Search With Quality Diversity Optimization. (arXiv:2208.00204v1 [cs.LG])
21. DRSOM: A Dimension Reduced Second-Order Method and Preliminary Analyses. (arXiv:2208.00208v1 [math.OC])
22. Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation. (arXiv:2208.00219v1 [cs.CV])
23. HPO X ELA: Investigating Hyperparameter Optimization Landscapes by Means of Exploratory Landscape Analysis. (arXiv:2208.00220v1 [cs.LG])
24. PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds. (arXiv:2208.00223v1 [cs.CV])
25. Geometric deep learning for computational mechanics Part II: Graph embedding for interpretable multiscale plasticity. (arXiv:2208.00246v1 [cs.LG])
26. A Bayesian Approach to Learning Bandit Structure in Markov Decision Processes. (arXiv:2208.00250v1 [cs.LG])
27. Automatically Categorising GitHub Repositories by Application Domain. (arXiv:2208.00269v1 [cs.SE])
28. Revisiting the Critical Factors of Augmentation-Invariant Representation Learning. (arXiv:2208.00275v1 [cs.CV])
29. Mobile**NeRF**: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures. (arXiv:2208.00277v1 [cs.CV])
30. Robust Contact State Estimation in Humanoid Walking Gaits. (arXiv:2208.00278v1 [cs.RO])
31. Simplex Clustering via sBeta with Applications to Online Adjustments of Black-Box Predictions. (arXiv:2208.00287v1 [cs.CV])
32. A Gradient Smoothed Functional Algorithm with Truncated Cauchy Random Perturbations for Stochastic Optimization. (arXiv:2208.00290v1 [math.OC])
33. Global Attention-based Encoder-Decoder LSTM Model for Temperature Prediction of Permanent Magnet Synchronous Motors. (arXiv:2208.00293v1 [cs.LG])
34. ANOVA-based Automatic Attribute Selection and a Predictive Model for Heart Disease Prognosis. (arXiv:2208.00296v1 [cs.LG])
35. Efficient Compilation and Mapping of Fixed Function Combinational Logic onto Digital Signal Processors Targeting Neural Network Inference and Utilizing High-level Synthesis. (arXiv:2208.00302v1 [cs.AR])
36. Delving into Effective Gradient Matching for Dataset Condensation. (arXiv:2208.00311v1 [cs.LG])
37. Untargeted Region of Interest Selection for GC-MS Data using a Pseudo F-Ratio Moving Window ($\psi$FRMV). (arXiv:2208.00313v1 [stat.ML])
38. A Multi-View Learning Approach to Enhance Automatic 12-Lead ECG Diagnosis Performance. (arXiv:2208.00323v1 [eess.SP])
39. enpheeph: A Fault Injection Framework for Spiking and Compressed Deep Neural Networks. (arXiv:2208.00328v1 [cs.NE])
40. Convex duality for stochastic shortest path problems in known and unknown environments. (arXiv:2208.00330v1 [cs.LG])
41. CoNLoCNN: Exploiting Correlation and Non-Uniform Quantization for Energy-Efficient Low-precision Deep Convolutional Neural Networks. (arXiv:2208.00331v1 [cs.AR])
42. Functional Rule Extraction Method for Artificial Neural Networks. (arXiv:2208.00335v1 [cs.LG])
43. Symmetry Regularization and Saturating Nonlinearity for Robust Quantization. (arXiv:2208.00338v1 [cs.LG])
44. Towards Intercultural Affect Recognition: Audio-Visual Affect Recognition in the Wild Across Six Cultures. (arXiv:2208.00344v1 [cs.CV])
45. Improving Distantly Supervised Relation Extraction by Natural Language Inference. (arXiv:2208.00346v1 [cs.CL])
46. What Do Deep Neural Networks Find in Disordered Structures of Glasses?. (arXiv:2208.00349v1 [cond-mat.dis-nn])
47. Neural Correlates of Face Familiarity Perception. (arXiv:2208.00352v1 [q-bio.NC])
48. Neuro-Symbolic Learning: Principles and Applications in Ophthalmology. (arXiv:2208.00374v1 [cs.CV])
49. Evaluating Table Structure Recognition: A New Perspective. (arXiv:2208.00385v1 [cs.CV])
50. An Experimental Study on Learning Correlated Equilibrium in Routing Games. (arXiv:2208.00391v1 [cs.GT])
51. Speckle2Speckle: Unsupervised Learning of Ultrasound Speckle Filtering Without Clean Data. (arXiv:2208.00402v1 [eess.IV])
52. Intelligent decision-making method of TBM operating parameters based on multiple constraints and objective optimization. (arXiv:2208.00404v1 [cs.LG])
53. eco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI. (arXiv:2208.00406v1 [cs.LG])
54. Unitary Approximate Message Passing for Matrix Factorization. (arXiv:2208.00422v1 [eess.SP])
55. INSightR-Net: Interpretable Neural Network for Regression using Similarity-based Comparisons to Prototypical Examples. (arXiv:2208.00457v1 [cs.CV])
56. Adaptive Temperature Scaling for Robust Calibration of Deep Neural Networks. (arXiv:2208.00461v1 [cs.LG])
57. Vector-Based Data Improves Left-Right Eye-Tracking Classifier Performance After a Covariate Distributional Shift. (arXiv:2208.00465v1 [cs.LG])
58. COCOA: Cross Modality Contrastive Learning for Sensor Data. (arXiv:2208.00467v1 [cs.CV])
59. Robot Policy Learning from Demonstration Using Advantage Weighting and Early Termination. (arXiv:2208.00478v1 [cs.LG])
60. Building an Efficiency Pipeline: Commutativity and Cumulativeness of Efficiency Operators for Transformers. (arXiv:2208.00483v1 [cs.CL])
61. Adaptive Edge Offloading for Image Classification Under Rate Limit. (arXiv:2208.00485v1 [cs.DC])
62. Scrutinizing Shipment Records To Thwart Illegal Timber Trade. (arXiv:2208.00493v1 [cs.LG])
63. DNNShield: Dynamic Randomized Model Sparsification, A Defense Against Adversarial Machine Learning. (arXiv:2208.00498v1 [cs.CR])
64. Formal guarantees for heuristic optimization algorithms used in machine learning. (arXiv:2208.00502v1 [cs.LG])
65. Deep Active Learning with Budget Annotation. (arXiv:2208.00508v1 [cs.LG])
66. Online Decentralized Frank-Wolfe: From theoretical bound to applications in smart-building. (arXiv:2208.00522v1 [cs.LG])
67. Learning to generate Reliable Broadcast Algorithms. (arXiv:2208.00525v1 [cs.DC])
68. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v1 [cs.CV])
69. Unifying Approaches in Data Subset Selection via Fisher Information and Information-Theoretic Quantities. (arXiv:2208.00549v1 [cs.LG])
70. Evo* 2022 -- Late-Breaking Abstracts Volume. (arXiv:2208.00555v1 [cs.NE])
71. Quantum Adaptive Fourier Features for Neural Density Estimation. (arXiv:2208.00564v1 [cs.LG])
72. Momentum Transformer: Closing the Performance Gap Between Self-attention and Its Linearization. (arXiv:2208.00579v1 [cs.LG])
73. Long Short-Term Preference Modeling for Continuous-Time Sequential Recommendation. (arXiv:2208.00593v1 [cs.IR])
74. A **Real-time** Edge-AI System for Reef Surveys. (arXiv:2208.00598v1 [cs.LG])
75. Weighted Scaling Approach for Metabolomics Data Analysis. (arXiv:2208.00603v1 [stat.ML])
76. Beyond kNN: Adaptive, Sparse Neighborhood Graphs via Optimal Transport. (arXiv:2208.00604v1 [stat.ML])
77. XOOD: Extreme Value Based Out-Of-Distribution Detection For Image Classification. (arXiv:2208.00629v1 [cs.LG])
78. An Evidential Neural Network Model for Regression Based on Random Fuzzy Numbers. (arXiv:2208.00647v1 [cs.LG])
79. UniToBrain dataset: a Brain Perfusion Dataset. (arXiv:2208.00650v1 [eess.IV])
80. De-biased Representation Learning for Fairness with Unreliable Labels. (arXiv:2208.00651v1 [cs.LG])
81. Model-based graph reinforcement learning for inductive traffic signal control. (arXiv:2208.00659v1 [cs.LG])
82. Generative Bias for Visual Question Answering. (arXiv:2208.00690v1 [cs.CV])
83. TransDeepLab: Convolution-Free Transformer-based DeepLab v3+ for Medical Image Segmentation. (arXiv:2208.00713v1 [eess.IV])
84. Graph Neural Network with Local Frame for Molecular Potential Energy Surface. (arXiv:2208.00716v1 [cs.LG])
85. Safe Policy Improvement Approaches and their Limitations. (arXiv:2208.00724v1 [cs.LG])
86. Performance Comparison of Deep RL Algorithms for Energy Systems Optimal Scheduling. (arXiv:2208.00728v1 [eess.SY])
87. Efficient Long-Text Understanding with Short-Text Models. (arXiv:2208.00748v1 [cs.CL])
88. Off-Policy Correction for Actor-Critic Algorithms in Deep Reinforcement Learning. (arXiv:2208.00755v1 [cs.LG])
89. Learning to Navigate using Visual Sensor Networks. (arXiv:2208.00759v1 [cs.RO])
90. $\textrm{D}^3\textrm{Former}$: Debiased Dual Distilled Transformer for Incremental Learning. (arXiv:2208.00777v1 [cs.CV])
91. SFILES 2.0: An extended text-based flowsheet representation. (arXiv:2208.00778v1 [cs.DB])
92. Intrinsic Universal Measurements of Non-linear Embeddings. (arXiv:1811.01464v2 [cs.LG] UPDATED)
93. PennyLane: Automatic differentiation of hybrid quantum-classical computations. (arXiv:1811.04968v4 [quant-ph] UPDATED)
94. Practical Deep Reinforcement Learning Approach for Stock Trading. (arXiv:1811.07522v3 [cs.LG] UPDATED)
95. Graph Transfer Learning via Adversarial Domain Adaptation with Graph Convolution. (arXiv:1909.01541v4 [cs.LG] UPDATED)
96. TCMI: a non-parametric mutual-dependence estimator for multivariate continuous distributions. (arXiv:2001.11212v3 [stat.ML] UPDATED)
97. Learning Object-Based State Estimators for Household Robots. (arXiv:2011.03183v4 [cs.LG] UPDATED)
98. A Small Survey On Event Detection Using Twitter. (arXiv:2011.05801v2 [cs.SI] UPDATED)
99. Inductive Biases for Deep Learning of Higher-Level Cognition. (arXiv:2011.15091v4 [cs.LG] UPDATED)
100. Learning a Group-Aware Policy for Robot Navigation. (arXiv:2012.12291v3 [cs.RO] UPDATED)
101. Disentangled Sequence Clustering for Human Intention Inference. (arXiv:2101.09500v4 [cs.RO] UPDATED)
102. Towards Bridging the gap between Empirical and Certified Robustness against Adversarial Examples. (arXiv:2102.05096v3 [cs.LG] UPDATED)
103. Online $k$-means Clustering on Arbitrary Data Streams. (arXiv:2102.09101v4 [cs.LG] UPDATED)
104. Generative Adversarial Networks via a Composite Annealing of Noise and Diffusion. (arXiv:2105.00220v3 [cs.LG] UPDATED)
105. A rigorous introduction to linear models. (arXiv:2105.04240v4 [cs.LG] UPDATED)
106. Assessing the Early Bird Heuristic (for Predicting Project Quality). (arXiv:2105.11082v3 [cs.SE] UPDATED)
107. Multi-Exit Semantic Segmentation Networks. (arXiv:2106.03527v3 [cs.CV] UPDATED)
108. Error Loss Networks. (arXiv:2106.03722v3 [cs.LG] UPDATED)
109. EMFlow: Data Imputation in Latent Space via EM and Deep Flow Models. (arXiv:2106.04804v2 [cs.LG] UPDATED)
110. Machine learning-based conditional mean filter: a generalization of the ensemble Kalman filter for nonlinear data assimilation. (arXiv:2106.07908v2 [cs.LG] UPDATED)
111. Machine Learning for Postprocessing Medium-range Ensemble Streamflow Forecasts. (arXiv:2106.09547v2 [cs.LG] UPDATED)
112. On Anytime Learning at Macroscale. (arXiv:2106.09563v4 [cs.LG] UPDATED)
113. Learning to Control DC Motor for Micromobility in Real Time with Reinforcement Learning. (arXiv:2108.00138v4 [cs.LG] UPDATED)
114. How Self-Supervised Learning Can be Used for Fine-Grained Head Pose Estimation?. (arXiv:2108.04893v6 [cs.CV] UPDATED)
115. PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management. (arXiv:2108.05818v4 [cs.LG] UPDATED)
116. Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond. (arXiv:2109.00725v2 [cs.CL] UPDATED)
117. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v4 [cs.CV] UPDATED)
118. YAHPO Gym -- An Efficient Multi-Objective Multi-Fidelity Benchmark for Hyperparameter Optimization. (arXiv:2109.03670v4 [cs.LG] UPDATED)
119. A Joint Graph and Image Convolution Network for Automatic Brain Tumor Segmentation. (arXiv:2109.05580v2 [eess.IV] UPDATED)
120. Bayesian Active Learning for Sim-to-Real Robotic Perception. (arXiv:2109.11547v3 [cs.RO] UPDATED)
121. PM-FSM: Policies Modulating Finite State Machine for Robust Quadrupedal Locomotion. (arXiv:2109.12696v2 [cs.RO] UPDATED)
122. CENN: Conservative energy method based on neural networks with subdomains for solving variational problems involving heterogeneous and complex geometries. (arXiv:2110.01359v4 [math.NA] UPDATED)
123. Adversarial Robustness Verification and Attack Synthesis in Stochastic Systems. (arXiv:2110.02125v2 [cs.CR] UPDATED)
124. Decoupled Contrastive Learning. (arXiv:2110.06848v3 [cs.LG] UPDATED)
125. Tight Concentrations and Confidence Sequences from the Regret of Universal Portfolio. (arXiv:2110.14099v3 [stat.ML] UPDATED)
126. DSEE: Dually Sparsity-embedded Efficient Tuning of Pre-trained Language Models. (arXiv:2111.00160v2 [cs.LG] UPDATED)
127. Generating Diverse Realistic Laughter for Interactive Art. (arXiv:2111.03146v2 [cs.LG] UPDATED)
128. Neural networks with linear threshold activations: structure and algorithms. (arXiv:2111.08117v2 [cs.LG] UPDATED)
129. The Geometry of Adversarial Training in Binary Classification. (arXiv:2111.13613v2 [cs.LG] UPDATED)
130. NN2Poly: A polynomial representation for deep feed-forward artificial neural networks. (arXiv:2112.11397v2 [stat.ML] UPDATED)
131. Development of a face mask detection pipeline for mask-wearing monitoring in the era of the COVID-19 pandemic: A modular approach. (arXiv:2112.15031v3 [cs.CV] UPDATED)
132. Problem-dependent attention and effort in neural networks with an application to image resolution. (arXiv:2201.01415v2 [cs.CV] UPDATED)
133. POTHER: Patch-Voted Deep Learning-Based Chest X-ray Bias Analysis for COVID-19 Detection. (arXiv:2201.09360v4 [eess.IV] UPDATED)
134. Learning Stationary Nash Equilibrium Policies in $n$-Player Stochastic Games with Independent Chains via Dual Mirror Descent. (arXiv:2201.12224v3 [cs.LG] UPDATED)
135. On the Power-Law Hessian Spectrums in Deep Learning. (arXiv:2201.13011v2 [cs.LG] UPDATED)
136. Harmony: Overcoming the Hurdles of GPU Memory Capacity to Train Massive DNN Models on Commodity Servers. (arXiv:2202.01306v2 [cs.DC] UPDATED)
137. Certifying Out-of-Domain Generalization for Blackbox Functions. (arXiv:2202.01679v2 [cs.LG] UPDATED)
138. On the Detection of Adaptive Adversarial Attacks in Speaker Verification Systems. (arXiv:2202.05725v2 [cs.CR] UPDATED)
139. Provable Stochastic Optimization for Global Contrastive Learning: Small Batch Does Not Harm Performance. (arXiv:2202.12387v3 [cs.LG] UPDATED)
140. Integrated multimodal artificial intelligence framework for healthcare applications. (arXiv:2202.12998v3 [cs.LG] UPDATED)
141. Query Processing on Tensor Computation Runtimes. (arXiv:2203.01877v3 [cs.DB] UPDATED)
142. Learning-based Localizability Estimation for Robust LiDAR Localization. (arXiv:2203.05698v2 [cs.RO] UPDATED)
143. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v2 [cs.LG] UPDATED)
144. On Connecting Deep Trigonometric Networks with Deep Gaussian Processes: Covariance, Expressivity, and Neural Tangent Kernel. (arXiv:2203.07411v3 [cs.LG] UPDATED)
145. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v4 [cs.CV] UPDATED)
146. SocialVAE: Human Trajectory Prediction using Timewise Latents. (arXiv:2203.08207v4 [cs.CV] UPDATED)
147. Learning Where To Look -- Generative NAS is Surprisingly Efficient. (arXiv:2203.08734v2 [cs.LG] UPDATED)
148. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v3 [cs.LG] UPDATED)
149. PACS: A Dataset for Physical Audiovisual CommonSense Reasoning. (arXiv:2203.11130v3 [cs.LG] UPDATED)
150. Shoring Up the Foundations: Fusing Model Embeddings and Weak Supervision. (arXiv:2203.13270v2 [stat.ML] UPDATED)
151. A Reinforcement Learning Approach to Sensing Design in Resource-Constrained Wireless Networked Control Systems. (arXiv:2204.00703v3 [eess.SY] UPDATED)
152. Generative Adversarial Method Based On Neural Tangent Kernels. (arXiv:2204.04090v4 [cs.LG] UPDATED)
153. Modelling Evolutionary and Stationary User Preferences for Temporal Sets Prediction. (arXiv:2204.05490v6 [cs.LG] UPDATED)
154. FederatedScope-GNN: Towards a Unified, Comprehensive and Efficient Package for Federated Graph Learning. (arXiv:2204.05562v5 [cs.LG] UPDATED)
155. GlacierNet2: A Hybrid Multi-Model Learning Architecture for Alpine Glacier Mapping. (arXiv:2204.05818v2 [eess.IV] UPDATED)
156. Decentralized Collaborative Learning Framework for Next POI Recommendation. (arXiv:2204.06516v4 [cs.IR] UPDATED)
157. Do ReLU Networks Have An Edge When Approximating Compactly-Supported Functions?. (arXiv:2204.11231v2 [cs.LG] UPDATED)
158. IRC-safe Graph Autoencoder for unsupervised anomaly detection. (arXiv:2204.12231v2 [hep-ph] UPDATED)
159. A Collection of Quality Diversity Optimization Problems Derived from Hyperparameter Optimization of Machine Learning Models. (arXiv:2204.14061v2 [cs.LG] UPDATED)
160. Lifelong Ensemble Learning based on Multiple Representations for Few-Shot Object Recognition. (arXiv:2205.01982v3 [cs.RO] UPDATED)
161. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v2 [cs.CV] UPDATED)
162. Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v4 [cs.AI] UPDATED)
163. Calibrating for Class Weights by Modeling Machine Learning. (arXiv:2205.04613v2 [cs.LG] UPDATED)
164. Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating. (arXiv:2205.05874v4 [cs.LG] UPDATED)
165. Closing the gap: Exact maximum likelihood training of generative autoencoders using invertible layers. (arXiv:2205.09546v2 [stat.ML] UPDATED)
166. Realization Theory Of Recurrent Neural ODEs Using Polynomial System Embeddings. (arXiv:2205.11989v2 [math.OC] UPDATED)
167. GARDNet: Robust Multi-View Network for Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v3 [eess.IV] UPDATED)
168. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v2 [cs.CV] UPDATED)
169. Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain. (arXiv:2206.01410v2 [cs.LG] UPDATED)
170. A Survey on Surrogate-assisted Efficient Neural Architecture Search. (arXiv:2206.01520v2 [cs.LG] UPDATED)
171. Markov Chain Score Ascent: A Unifying Framework of Variational Inference with Markovian Gradients. (arXiv:2206.06295v2 [cs.LG] UPDATED)
172. How should we proxy for race/ethnicity? Comparing Bayesian improved surname geocoding to machine learning methods. (arXiv:2206.14583v2 [cs.LG] UPDATED)
173. ICE-NODE: Integration of Clinical Embeddings with Neural Ordinary Differential Equations. (arXiv:2207.01873v3 [cs.LG] UPDATED)
174. Improved conformalized quantile regression. (arXiv:2207.02808v3 [stat.ML] UPDATED)
175. IDEA: Increasing Text Diversity via Online Multi-Label Recognition for Vision-Language Pre-training. (arXiv:2207.05333v2 [cs.CV] UPDATED)
176. Distilled Non-Semantic Speech Embeddings with Binary Neural Networks for Low-Resource Devices. (arXiv:2207.05784v2 [cs.SD] UPDATED)
177. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v3 [eess.SY] UPDATED)
178. Latent Space Unsupervised Semantic Segmentation. (arXiv:2207.11067v2 [cs.LG] UPDATED)
179. Density-Aware Personalized Training for Risk Prediction in Imbalanced Medical Data. (arXiv:2207.11382v2 [cs.LG] UPDATED)
180. Optimization of the Shape of a Hydrokinetic Turbine's Draft Tube and Hub Assembly Using Design-by-Morphing with Bayesian Optimization. (arXiv:2207.11451v2 [cs.CG] UPDATED)
181. Approximate Low-Rank Decomposition for Real Symmetric Tensors. (arXiv:2207.12529v2 [math.NA] UPDATED)
182. Encoding Concepts in Graph Neural Networks. (arXiv:2207.13586v2 [cs.LG] UPDATED)
183. Graph Inverse Reinforcement Learning from Diverse Videos. (arXiv:2207.14299v2 [cs.LG] UPDATED)
184. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v2 [cs.CL] UPDATED)
185. Replacing the Framingham-based equation for prediction of cardiovascular disease risk and adverse outcome by using artificial intelligence and retinal imaging. (arXiv:2207.14685v2 [eess.IV] UPDATED)
186. A Data-driven Latent Semantic Analysis for Automatic Text Summarization using LDA Topic Modelling. (arXiv:2207.14687v2 [cs.IR] UPDATED)
187. Topological structure of complex predictions. (arXiv:2207.14358v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**105** new papers in cs.AI:-) 
1. RangL: A Reinforcement Learning Competition Platform. (arXiv:2208.00003v1 [cs.LG])
2. Testing Relational Understanding in Text-Guided Image Generation. (arXiv:2208.00005v1 [cs.CV])
3. Paddy Leaf diseases identification on Infrared Images based on Convolutional Neural Networks. (arXiv:2208.00031v1 [cs.CV])
4. Personalised recommendations of sleep behaviour with neural networks using sleep diaries captured in Sleepio. (arXiv:2208.00033v1 [cs.LG])
5. Thutmose Tagger: Single-pass neural model for Inverse Text Normalization. (arXiv:2208.00064v1 [cs.CL])
6. Machine Learning and Computer Vision Techniques in Bee Monitoring Applications. (arXiv:2208.00085v1 [cs.CV])
7. Robust Trajectory Prediction against Adversarial Attacks. (arXiv:2208.00094v1 [cs.LG])
8. Weakly Supervised Deep Instance Nuclei Detection using Points Annotation in 3D Cardiovascular Immunofluorescent Images. (arXiv:2208.00098v1 [cs.CV])
9. Some Practice for Improving the Search Results of E-commerce. (arXiv:2208.00108v1 [cs.IR])
10. 20 years of network community detection. (arXiv:2208.00111v1 [physics.soc-ph])
11. Neural Correspondence Field for Object Pose Estimation. (arXiv:2208.00113v1 [cs.CV])
12. A Survey on Masked Autoencoder for Self-supervised Learning in Vision and Beyond. (arXiv:2208.00173v1 [cs.CV])
13. Celeritas: Fast Optimizer for Large Dataflow Graphs. (arXiv:2208.00184v1 [cs.DC])
14. PUSH: a primal heuristic based on Feasibility PUmp and SHifting. (arXiv:2208.00191v1 [math.OC])
15. Solving the vehicle routing problem with deep reinforcement learning. (arXiv:2208.00202v1 [math.OC])
16. Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation. (arXiv:2208.00219v1 [cs.CV])
17. PolarMix: A General Data Augmentation Technique for LiDAR Point Clouds. (arXiv:2208.00223v1 [cs.CV])
18. A Bayesian Approach to Learning Bandit Structure in Markov Decision Processes. (arXiv:2208.00250v1 [cs.LG])
19. Unified Automatic Control of Vehicular Systems with Reinforcement Learning. (arXiv:2208.00268v1 [cs.AI])
20. Robust Contact State Estimation in Humanoid Walking Gaits. (arXiv:2208.00278v1 [cs.RO])
21. Simplex Clustering via sBeta with Applications to Online Adjustments of Black-Box Predictions. (arXiv:2208.00287v1 [cs.CV])
22. Global Attention-based Encoder-Decoder LSTM Model for Temperature Prediction of Permanent Magnet Synchronous Motors. (arXiv:2208.00293v1 [cs.LG])
23. On Interactive Explanations as Non-Monotonic Reasoning. (arXiv:2208.00316v1 [cs.AI])
24. A Multi-View Learning Approach to Enhance Automatic 12-Lead ECG Diagnosis Performance. (arXiv:2208.00323v1 [eess.SP])
25. Symmetry Regularization and Saturating Nonlinearity for Robust Quantization. (arXiv:2208.00338v1 [cs.LG])
26. Chinese grammatical error correction based on knowledge distillation. (arXiv:2208.00351v1 [cs.CL])
27. Exploring Attention-Aware Network Resource Allocation for Customized Metaverse Services. (arXiv:2208.00369v1 [cs.NI])
28. Neuro-Symbolic Learning: Principles and Applications in Ophthalmology. (arXiv:2208.00374v1 [cs.CV])
29. Using Chatbots to Teach Languages. (arXiv:2208.00376v1 [cs.CL])
30. DRL-M4MR: An Intelligent Multicast Routing Approach Based on DQN Deep Reinforcement Learning in SDN. (arXiv:2208.00383v1 [cs.NI])
31. Robotic Dough Shaping. (arXiv:2208.00386v1 [cs.RO])
32. STrajNet: Occupancy Flow Prediction via Multi-modal **Swin** Transformer. (arXiv:2208.00394v1 [cs.CV])
33. Neural Knowledge Bank for Pretrained Transformers. (arXiv:2208.00399v1 [cs.CL])
34. eco2AI: carbon emissions tracking of machine learning models as the first step towards sustainable AI. (arXiv:2208.00406v1 [cs.LG])
35. Out-of-Distribution Detection with Semantic Mismatch under Masking. (arXiv:2208.00446v1 [cs.CV])
36. Parameter-Parallel Distributed Variational Quantum Algorithm. (arXiv:2208.00450v1 [quant-ph])
37. Repairing $\mathcal{EL}$ Ontologies Using Weakening and Completing. (arXiv:2208.00486v1 [cs.AI])
38. Scrutinizing Shipment Records To Thwart Illegal Timber Trade. (arXiv:2208.00493v1 [cs.LG])
39. Assessing The Performance of YOLOv5 Algorithm for Detecting Volunteer Cotton Plants in Corn Fields at Three Different Growth Stages. (arXiv:2208.00519v1 [cs.CV])
40. CloudAttention: Efficient Multi-Scale Attention Scheme For 3D Point Cloud Learning. (arXiv:2208.00524v1 [cs.CV])
41. Is current research on adversarial robustness addressing the right problem?. (arXiv:2208.00539v1 [cs.CV])
42. DeScoD-ECG: Deep Score-Based Diffusion Model for ECG Baseline Wander and Noise Removal. (arXiv:2208.00542v1 [eess.SP])
43. Unifying Approaches in Data Subset Selection via Fisher Information and Information-Theoretic Quantities. (arXiv:2208.00549v1 [cs.LG])
44. Search for or Navigate to? Dual Adaptive Thinking for Object Navigation. (arXiv:2208.00553v1 [cs.AI])
45. Evo* 2022 -- Late-Breaking Abstracts Volume. (arXiv:2208.00555v1 [cs.NE])
46. A Particle-Based Algorithm for Distributional Optimization on \textit{Constrained Domains} via Variational Transport and Mirror Descent. (arXiv:2208.00587v1 [math.OC])
47. XOOD: Extreme Value Based Out-Of-Distribution Detection For Image Classification. (arXiv:2208.00629v1 [cs.LG])
48. Studying writer-suggestion interaction: A qualitative study to understand writer interaction with aligned/misaligned next-phrase suggestion. (arXiv:2208.00636v1 [cs.HC])
49. Composable Text Control Operations in Latent Space with Ordinary Differential Equations. (arXiv:2208.00638v1 [cs.CL])
50. De-biased Representation Learning for Fairness with Unreliable Labels. (arXiv:2208.00651v1 [cs.LG])
51. Generative Bias for Visual Question Answering. (arXiv:2208.00690v1 [cs.CV])
52. Proportional Fair Division of Multi-layered Cakes. (arXiv:2208.00726v1 [cs.AI])
53. e-Genia3 An AgentSpeak extension for empathic agents. (arXiv:2208.00737v1 [cs.MA])
54. Efficient Long-Text Understanding with Short-Text Models. (arXiv:2208.00748v1 [cs.CL])
55. Data Collection and Analysis of French Dialects. (arXiv:2208.00752v1 [cs.CL])
56. Off-Policy Correction for Actor-Critic Algorithms in Deep Reinforcement Learning. (arXiv:2208.00755v1 [cs.LG])
57. HiKonv: Maximizing the Throughput of Quantized Convolution With Novel Bit-wise Management and Computation. (arXiv:2208.00763v1 [cs.AR])
58. Solving the optimal stopping problem with reinforcement learning: an application in financial option exercise. (arXiv:2208.00765v1 [q-fin.CP])
59. Multimodal Neural Machine Translation with Search Engine Based Image Retrieval. (arXiv:2208.00767v1 [cs.CV])
60. DADAO: Decoupled Accelerated Decentralized Asynchronous Optimization for Time-Varying Gossips. (arXiv:2208.00779v1 [math.OC])
61. MedDG: An Entity-Centric Medical Consultation Dataset for Entity-Aware Medical Dialogue Generation. (arXiv:2010.07497v2 [cs.CL] UPDATED)
62. Learning Object-Based State Estimators for Household Robots. (arXiv:2011.03183v4 [cs.LG] UPDATED)
63. Inductive Biases for Deep Learning of Higher-Level Cognition. (arXiv:2011.15091v4 [cs.LG] UPDATED)
64. Towards Bridging the gap between Empirical and Certified Robustness against Adversarial Examples. (arXiv:2102.05096v3 [cs.LG] UPDATED)
65. Assessing the Early Bird Heuristic (for Predicting Project Quality). (arXiv:2105.11082v3 [cs.SE] UPDATED)
66. Human Perception of Audio Deepfakes. (arXiv:2107.09667v4 [cs.HC] UPDATED)
67. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v4 [cs.CV] UPDATED)
68. Bayesian Active Learning for Sim-to-Real Robotic Perception. (arXiv:2109.11547v3 [cs.RO] UPDATED)
69. Learning Cross-Lingual IR from an English Retriever. (arXiv:2112.08185v3 [cs.CL] UPDATED)
70. Integrated multimodal artificial intelligence framework for healthcare applications. (arXiv:2202.12998v3 [cs.LG] UPDATED)
71. Learning-based Localizability Estimation for Robust LiDAR Localization. (arXiv:2203.05698v2 [cs.RO] UPDATED)
72. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v2 [cs.LG] UPDATED)
73. Physical Neural Cellular Automata for 2D Shape Classification. (arXiv:2203.07548v2 [cs.RO] UPDATED)
74. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v4 [cs.CV] UPDATED)
75. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v3 [cs.LG] UPDATED)
76. PACS: A Dataset for Physical Audiovisual CommonSense Reasoning. (arXiv:2203.11130v3 [cs.LG] UPDATED)
77. CXR-FL: Deep Learning-Based Chest X-ray Image Analysis Using Federated Learning. (arXiv:2204.05203v2 [eess.IV] UPDATED)
78. Recent Advances and New Frontiers in Spiking Neural Networks. (arXiv:2204.07050v6 [cs.NE] UPDATED)
79. Interventional Behavior Prediction: Avoiding Overly Confident Anticipation in Interactive Prediction. (arXiv:2204.08665v2 [cs.RO] UPDATED)
80. Do ReLU Networks Have An Edge When Approximating Compactly-Supported Functions?. (arXiv:2204.11231v2 [cs.LG] UPDATED)
81. Intelligent Trajectory Design for RIS-NOMA aided Multi-robot Communications. (arXiv:2205.01647v4 [cs.RO] UPDATED)
82. Improved Orientation Estimation and Detection with Hybrid Object Detection Networks for Automotive Radar. (arXiv:2205.02111v2 [cs.CV] UPDATED)
83. Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v4 [cs.AI] UPDATED)
84. Distinction Maximization Loss: Efficiently Improving Out-of-Distribution Detection and Uncertainty Estimation by Replacing the Loss and Calibrating. (arXiv:2205.05874v4 [cs.LG] UPDATED)
85. GARDNet: Robust Multi-View Network for Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v3 [eess.IV] UPDATED)
86. Incremental Learning Meets Transfer Learning: Application to Multi-site Prostate MRI Segmentation. (arXiv:2206.01369v2 [cs.CV] UPDATED)
87. Fair Classification via Transformer Neural Networks: Case Study of an Educational Domain. (arXiv:2206.01410v2 [cs.LG] UPDATED)
88. A Machine Learning Model for Predicting, Diagnosing, and Mitigating Health Disparities in Hospital Readmission. (arXiv:2206.06279v2 [cs.AI] UPDATED)
89. Markov Chain Score Ascent: A Unifying Framework of Variational Inference with Markovian Gradients. (arXiv:2206.06295v2 [cs.LG] UPDATED)
90. How to Agree to Disagree: Managing Ontological Perspectives using Standpoint Logic. (arXiv:2206.06793v2 [cs.AI] UPDATED)
91. Hybrid Facial Expression Recognition (FER2013) Model for Real-Time Emotion Classification and Prediction. (arXiv:2206.09509v2 [cs.CV] UPDATED)
92. The NPC AI of The Last of Us: A case study. (arXiv:2207.00682v2 [cs.AI] UPDATED)
93. Backdoor Attack is a Devil in Federated GAN-based Medical Image Synthesis. (arXiv:2207.00762v2 [cs.CV] UPDATED)
94. Refutation of Spectral Graph Theory Conjectures with Monte Carlo Search. (arXiv:2207.03343v2 [cs.AI] UPDATED)
95. Autonomously Untangling Long Cables. (arXiv:2207.07813v2 [cs.RO] UPDATED)
96. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v3 [eess.SY] UPDATED)
97. NusaCrowd: A Call for Open and Reproducible NLP Research in Indonesian Languages. (arXiv:2207.10524v2 [cs.CL] UPDATED)
98. Latent Space Unsupervised Semantic Segmentation. (arXiv:2207.11067v2 [cs.LG] UPDATED)
99. Convolutional Embedding Makes Hierarchical Vision Transformer Stronger. (arXiv:2207.13317v2 [cs.CV] UPDATED)
100. Future Unruptured Intracranial Aneurysm Growth Prediction using Mesh Convolutional Neural Networks. (arXiv:2207.13518v2 [eess.IV] UPDATED)
101. Encoding Concepts in Graph Neural Networks. (arXiv:2207.13586v2 [cs.LG] UPDATED)
102. Lighting (In)consistency of Paint by Text. (arXiv:2207.13744v2 [cs.CV] UPDATED)
103. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v2 [cs.CL] UPDATED)
104. Replacing the Framingham-based equation for prediction of cardiovascular disease risk and adverse outcome by using artificial intelligence and retinal imaging. (arXiv:2207.14685v2 [eess.IV] UPDATED)
105. End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v2 [cs.CV] UPDATED)

