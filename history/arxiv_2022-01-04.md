# Your interest papers
---
## cs.CV
---
### Image **Restoration** using Feature-guidance. (arXiv:2201.00187v1 [eess.IV])
- Authors : Maitreya Suin, Kuldeep Purohit
- Link : [http://arxiv.org/abs/2201.00187](http://arxiv.org/abs/2201.00187)
> ABSTRACT  :  Image **restoration** is the task of recovering a clean image from a degraded version. In most cases, the degradation is spatially varying, and it requires the **restoration** network to both localize and restore the affected regions. In this paper, we present a new approach suitable for handling the image-specific and spatially-varying nature of degradation in images affected by practically occurring artifacts such as blur, rain-streaks. We decompose the **restoration** task into two stages of degradation localization and degraded region-guided **restoration**, unlike existing methods which directly learn a mapping between the degraded and clean images. Our premise is to use the auxiliary task of degradation mask prediction to guide the **restoration** process. We demonstrate that the model trained for this auxiliary task contains vital region knowledge, which can be exploited to guide the **restoration** network's training using attentive knowledge distillation technique. Further, we propose mask-guided convolution and global context aggregation module that focuses solely on restoring the degraded regions. The proposed approach's effectiveness is demonstrated by achieving significant improvement over strong baselines.  
### Subspace modeling for fast and high-sensitivity X-ray chemical imaging. (arXiv:2201.00259v1 [eess.IV])
- Authors : Jizhou Li, Bin Chen, Guibin Zan, Guannan Qian, Piero Pianetta, Yijin Liu
- Link : [http://arxiv.org/abs/2201.00259](http://arxiv.org/abs/2201.00259)
> ABSTRACT  :  Resolving morphological chemical phase transformations at the nanoscale is of vital importance to many scientific and industrial applications across various disciplines. The TXM-XANES imaging technique, by combining full field transmission X-ray microscopy (TXM) and X-ray absorption near edge structure (XANES), has been an emerging tool which operates by acquiring a series of microscopy images with multi-energy X-rays and fitting to obtain the chemical map. Its capability, however, is limited by the poor signal-to-noise ratios due to the system errors and low **exposure** illuminations for fast acquisition. In this work, by exploiting the intrinsic properties and subspace modeling of the TXM-XANES imaging data, we introduce a simple and robust denoising approach to improve the image quality, which enables fast and high-sensitivity chemical imaging. Extensive experiments on both synthetic and real datasets demonstrate the superior performance of the proposed method.  
### Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v1 [cs.CV])
- Authors : Yifan Jiang, Bart Wronski, Ben Mildenhall, Jon Barron, Zhangyang Wang, Tianfan Xue
- Link : [http://arxiv.org/abs/2201.00392](http://arxiv.org/abs/2201.00392)
> ABSTRACT  :  Many image processing networks apply a single set of static convolutional kernels across the entire input image, which is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Recent work in classification, segmentation, and image **restoration** has demonstrated that dynamic kernels outperform static kernels at modeling local image statistics. However, these works often adopt per-pixel convolution kernels, which introduce high memory and computation costs. To achieve spatial-varying processing without significant overhead, we present \textbf{Malle}able \textbf{Conv}olution (\textbf{MalleConv}), as an efficient variant of dynamic convolution. The weights of \ours are dynamically produced by an efficient predictor network capable of generating content-dependent outputs at specific spatial locations. Unlike previous works, \ours generates a much smaller set of spatially-varying kernels from input, which enlarges the network's receptive field and significantly reduces computational and memory costs. These kernels are then applied to a full-resolution feature map through an efficient slice-and-conv operator with minimum memory overhead. We further build a efficient denoising network using MalleConv, coined as \textbf{MalleNet}. It achieves high quality results without very deep architecture, \eg, it is 8.91$\times$ faster than the best performed denoising algorithms (SwinIR), while maintaining similar performance. We also show that a single \ours added to a standard convolution-based backbones can contribute significantly reduce the computational cost or boost image quality at similar cost. Project page: https://yifanjiang.net/MalleConv.html  
### RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v1 [eess.IV])
- Authors : Zhuo Deng, Yuanhao Cai, Lu Chen, Zheng Gong, Qiqi Bao, Xue Yao, Dong Fang, Shaochong Zhang, Lan Ma
- Link : [http://arxiv.org/abs/2201.00466](http://arxiv.org/abs/2201.00466)
> ABSTRACT  :  Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image **restoration** is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image **restoration** problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications. The dataset, code, and models will be released.  
### FaceQgen: Semi-Supervised Deep Learning for Face Image Quality Assessment. (arXiv:2201.00770v1 [cs.CV])
- Authors : Javier Hernandez, Julian Fierrez, Ignacio Serna, Aythami Morales
- Link : [http://arxiv.org/abs/2201.00770](http://arxiv.org/abs/2201.00770)
> ABSTRACT  :  In this paper we develop FaceQgen, a No-Reference Quality Assessment approach for face images based on a Generative Adversarial Network that generates a scalar quality measure related with the face recognition accuracy. FaceQgen does not require labelled quality measures for training. It is trained from scratch using the SCface database. FaceQgen applies image **restoration** to a face image of unknown quality, transforming it into a canonical high quality image, i.e., frontal pose, homogeneous background, etc. The quality estimation is built as the similarity between the original and the restored images, since low quality images experience bigger changes due to **restoration**. We compare three different numerical quality measures: a) the MSE between the original and the restored images, b) their SSIM, and c) the output score of the Discriminator of the GAN. The results demonstrate that FaceQgen's quality measures are good estimators of face recognition accuracy. Our experiments include a comparison with other quality assessment methods designed for faces and for general images, in order to position FaceQgen in the state of the art. This comparison shows that, even though FaceQgen does not surpass the best existing face quality assessment methods in terms of face recognition accuracy prediction, it achieves good enough results to demonstrate the potential of semi-supervised learning approaches for quality estimation (in particular, data-driven learning based on a single high quality image per subject), having the capacity to improve its performance in the future with adequate refinement of the model and the significant advantage over competing methods of not needing quality labels for its development. This makes FaceQgen flexible and scalable without expensive data curation.  
### Boosting Salient Object Detection with Transformer-based Asymmetric **Bilateral** U-Net. (arXiv:2108.07851v4 [cs.CV] UPDATED)
- Authors : Yu Qiu, Yun Liu, Le Zhang, Jing Xu
- Link : [http://arxiv.org/abs/2108.07851](http://arxiv.org/abs/2108.07851)
> ABSTRACT  :  Existing salient object detection (SOD) methods mainly rely on CNN-based U-shaped structures with skip connections to combine the global contexts and local spatial details that are crucial for locating salient objects and refining object details, respectively. Despite great successes, the ability of CNN in learning global contexts is limited. Recently, the vision transformer has achieved revolutionary progress in computer vision owing to its powerful modeling of global dependencies. However, directly applying the transformer to SOD is suboptimal because the transformer lacks the ability to learn local spatial representations. To this end, this paper explores the combination of transformer and CNN to learn both global and local representations for SOD. We propose a transformer-based Asymmetric **Bilateral** U-Net (ABiU-Net). The asymmetric **bilateral** encoder has a transformer path and a lightweight CNN path, where the two paths communicate at each encoder stage to learn complementary global contexts and local spatial details, respectively. The asymmetric **bilateral** decoder also consists of two paths to process features from the transformer and CNN encoder paths, with communication at each decoder stage for decoding coarse salient object locations and find-grained object details, respectively. Such communication between the two encoder/decoder paths enables AbiU-Net to learn complementary global and local representations, taking advantage of the natural properties of transformer and CNN, respectively. Hence, ABiU-Net provides a new perspective for transformer-based SOD. Extensive experiments demonstrate that ABiU-Net performs favorably against previous state-of-the-art SOD methods. The code will be released.  
### A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v4 [cs.CV] UPDATED)
- Authors : Zahra Anvari, Vassilis Athitsos
- Link : [http://arxiv.org/abs/2112.02719](http://arxiv.org/abs/2112.02719)
> ABSTRACT  :  Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image **enhancement** plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks such as character recognition. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image **enhancement** tasks, including binarization, debluring, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image **enhancement** tasks that have received little to no attention, including over and under **exposure** correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research.  
## eess.IV
---
### Image **Restoration** using Feature-guidance. (arXiv:2201.00187v1 [eess.IV])
- Authors : Maitreya Suin, Kuldeep Purohit
- Link : [http://arxiv.org/abs/2201.00187](http://arxiv.org/abs/2201.00187)
> ABSTRACT  :  Image **restoration** is the task of recovering a clean image from a degraded version. In most cases, the degradation is spatially varying, and it requires the **restoration** network to both localize and restore the affected regions. In this paper, we present a new approach suitable for handling the image-specific and spatially-varying nature of degradation in images affected by practically occurring artifacts such as blur, rain-streaks. We decompose the **restoration** task into two stages of degradation localization and degraded region-guided **restoration**, unlike existing methods which directly learn a mapping between the degraded and clean images. Our premise is to use the auxiliary task of degradation mask prediction to guide the **restoration** process. We demonstrate that the model trained for this auxiliary task contains vital region knowledge, which can be exploited to guide the **restoration** network's training using attentive knowledge distillation technique. Further, we propose mask-guided convolution and global context aggregation module that focuses solely on restoring the degraded regions. The proposed approach's effectiveness is demonstrated by achieving significant improvement over strong baselines.  
### Subspace modeling for fast and high-sensitivity X-ray chemical imaging. (arXiv:2201.00259v1 [eess.IV])
- Authors : Jizhou Li, Bin Chen, Guibin Zan, Guannan Qian, Piero Pianetta, Yijin Liu
- Link : [http://arxiv.org/abs/2201.00259](http://arxiv.org/abs/2201.00259)
> ABSTRACT  :  Resolving morphological chemical phase transformations at the nanoscale is of vital importance to many scientific and industrial applications across various disciplines. The TXM-XANES imaging technique, by combining full field transmission X-ray microscopy (TXM) and X-ray absorption near edge structure (XANES), has been an emerging tool which operates by acquiring a series of microscopy images with multi-energy X-rays and fitting to obtain the chemical map. Its capability, however, is limited by the poor signal-to-noise ratios due to the system errors and low **exposure** illuminations for fast acquisition. In this work, by exploiting the intrinsic properties and subspace modeling of the TXM-XANES imaging data, we introduce a simple and robust denoising approach to improve the image quality, which enables fast and high-sensitivity chemical imaging. Extensive experiments on both synthetic and real datasets demonstrate the superior performance of the proposed method.  
### Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v1 [cs.CV])
- Authors : Yifan Jiang, Bart Wronski, Ben Mildenhall, Jon Barron, Zhangyang Wang, Tianfan Xue
- Link : [http://arxiv.org/abs/2201.00392](http://arxiv.org/abs/2201.00392)
> ABSTRACT  :  Many image processing networks apply a single set of static convolutional kernels across the entire input image, which is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Recent work in classification, segmentation, and image **restoration** has demonstrated that dynamic kernels outperform static kernels at modeling local image statistics. However, these works often adopt per-pixel convolution kernels, which introduce high memory and computation costs. To achieve spatial-varying processing without significant overhead, we present \textbf{Malle}able \textbf{Conv}olution (\textbf{MalleConv}), as an efficient variant of dynamic convolution. The weights of \ours are dynamically produced by an efficient predictor network capable of generating content-dependent outputs at specific spatial locations. Unlike previous works, \ours generates a much smaller set of spatially-varying kernels from input, which enlarges the network's receptive field and significantly reduces computational and memory costs. These kernels are then applied to a full-resolution feature map through an efficient slice-and-conv operator with minimum memory overhead. We further build a efficient denoising network using MalleConv, coined as \textbf{MalleNet}. It achieves high quality results without very deep architecture, \eg, it is 8.91$\times$ faster than the best performed denoising algorithms (SwinIR), while maintaining similar performance. We also show that a single \ours added to a standard convolution-based backbones can contribute significantly reduce the computational cost or boost image quality at similar cost. Project page: https://yifanjiang.net/MalleConv.html  
### RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v1 [eess.IV])
- Authors : Zhuo Deng, Yuanhao Cai, Lu Chen, Zheng Gong, Qiqi Bao, Xue Yao, Dong Fang, Shaochong Zhang, Lan Ma
- Link : [http://arxiv.org/abs/2201.00466](http://arxiv.org/abs/2201.00466)
> ABSTRACT  :  Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image **restoration** is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image **restoration** problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications. The dataset, code, and models will be released.  
### FaceQgen: Semi-Supervised Deep Learning for Face Image Quality Assessment. (arXiv:2201.00770v1 [cs.CV])
- Authors : Javier Hernandez, Julian Fierrez, Ignacio Serna, Aythami Morales
- Link : [http://arxiv.org/abs/2201.00770](http://arxiv.org/abs/2201.00770)
> ABSTRACT  :  In this paper we develop FaceQgen, a No-Reference Quality Assessment approach for face images based on a Generative Adversarial Network that generates a scalar quality measure related with the face recognition accuracy. FaceQgen does not require labelled quality measures for training. It is trained from scratch using the SCface database. FaceQgen applies image **restoration** to a face image of unknown quality, transforming it into a canonical high quality image, i.e., frontal pose, homogeneous background, etc. The quality estimation is built as the similarity between the original and the restored images, since low quality images experience bigger changes due to **restoration**. We compare three different numerical quality measures: a) the MSE between the original and the restored images, b) their SSIM, and c) the output score of the Discriminator of the GAN. The results demonstrate that FaceQgen's quality measures are good estimators of face recognition accuracy. Our experiments include a comparison with other quality assessment methods designed for faces and for general images, in order to position FaceQgen in the state of the art. This comparison shows that, even though FaceQgen does not surpass the best existing face quality assessment methods in terms of face recognition accuracy prediction, it achieves good enough results to demonstrate the potential of semi-supervised learning approaches for quality estimation (in particular, data-driven learning based on a single high quality image per subject), having the capacity to improve its performance in the future with adequate refinement of the model and the significant advantage over competing methods of not needing quality labels for its development. This makes FaceQgen flexible and scalable without expensive data curation.  
## cs.LG
---
### High-dimensional Bayesian Optimization Algorithm with Recurrent Neural Network for Disease Control Models in Time Series. (arXiv:2201.00147v1 [cs.LG])
- Authors : Yuyang Chen, Kaiming Bi, David Ben, Ashesh Sinha
- Link : [http://arxiv.org/abs/2201.00147](http://arxiv.org/abs/2201.00147)
> ABSTRACT  :  Bayesian Optimization algorithm has become a promising approach for nonlinear global optimization problems and many machine learning applications. Over the past few years, improvements and **enhancement**s have been brought forward and they have shown some promising results in solving the complex dynamic problems, systems of ordinary differential equations where the objective functions are computationally expensive to evaluate. Besides, the straightforward implementation of the Bayesian Optimization algorithm performs well merely for optimization problems with 10-20 dimensions. The study presented in this paper proposes a new high dimensional Bayesian Optimization algorithm combining Recurrent neural networks, which is expected to predict the optimal solution for the global optimization problems with high dimensional or time series decision models. The proposed RNN-BO algorithm can solve the optimal control problems in the lower dimension space and then learn from the historical data using the recurrent neural network to learn the historical optimal solution data and predict the optimal control strategy for any new initial system value setting. In addition, accurately and quickly providing the optimal control strategy is essential to effectively and efficiently control the epidemic spread while minimizing the associated financial costs. Therefore, to verify the effectiveness of the proposed algorithm, computational experiments are carried out on a deterministic SEIR epidemic model and a stochastic SIS optimal control model. Finally, we also discuss the impacts of different numbers of the RNN layers and training epochs on the trade-off between solution quality and related computational efforts.  
### Transfer-learning-based Surrogate Model for Thermal Conductivity of Nanofluids. (arXiv:2201.00435v1 [physics.flu-dyn])
- Authors : Abhijeet Banthiya
- Link : [http://arxiv.org/abs/2201.00435](http://arxiv.org/abs/2201.00435)
> ABSTRACT  :  Heat transfer characteristics of nanofluids have been extensively studied since the 1990s. Research investigations show that the suspended nanoparticles significantly alter the suspension's thermal properties. The thermal conductivity of nanofluids is one of the properties that is generally found to be greater than that of the base fluid. This increase in thermal conductivity is found to depend on several parameters. Several theories have been proposed to model the thermal conductivities of nanofluids, but there is no reliable universal theory yet to model the anomalous thermal conductivity of nanofluids. In recent years, supervised data-driven methods have been successfully employed to create surrogate models across various scientific disciplines, especially for modeling difficult-to-understand phenomena. These supervised learning methods allow the models to capture highly non-linear phenomena. In this work, we have taken advantage of existing correlations and used them concurrently with available experimental results to develop more robust surrogate models for predicting the thermal conductivity of nanofluids. Artificial neural networks are trained using the transfer learning approach to predict the thermal conductivity **enhancement** of nanofluids with spherical particles for 32 different particle-fluid combinations (8 particles materials and 4 fluids). The large amount of lower accuracy data generated from correlations is used to coarse-tune the model parameters, and the limited amount of more trustworthy experimental data is used to fine-tune the model parameters. The transfer learning-based models' results are compared with those from baseline models which are trained only on experimental data using a goodness of fit metric. It is found that the transfer learning models perform better with goodness of fit values of 0.93 as opposed to 0.83 from the baseline models.  
### Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions. (arXiv:2201.00768v1 [cs.CL])
- Authors : Marwan Omar, Soohyeon Choi, DaeHun Nyang, David Mohaisen
- Link : [http://arxiv.org/abs/2201.00768](http://arxiv.org/abs/2201.00768)
> ABSTRACT  :  Recent natural language processing (NLP) techniques have accomplished high performance on benchmark datasets, primarily due to the significant improvement in the performance of deep learning. The advances in the research community have led to great **enhancement**s in state-of-the-art production systems for NLP tasks, such as virtual assistants, speech recognition, and sentiment analysis. However, such NLP systems still often fail when tested with adversarial attacks. The initial lack of robustness exposed troubling gaps in current models' language understanding capabilities, creating problems when NLP systems are deployed in real life. In this paper, we present a structured overview of NLP robustness research by summarizing the literature in a systemic way across various dimensions. We then take a deep-dive into the various dimensions of robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we argue that robustness should be multi-dimensional, provide insights into current research, identify gaps in the literature to suggest directions worth pursuing to address these gaps.  
### Characterizing Speech Adversarial Examples Using Self-Attention U-Net **Enhancement**. (arXiv:2003.13917v2 [eess.AS] UPDATED)
- Authors : Han Huck, Jun Qi, Yu Chen, Xiaoli Ma, Hui Lee
- Link : [http://arxiv.org/abs/2003.13917](http://arxiv.org/abs/2003.13917)
> ABSTRACT  :  Recent studies have highlighted adversarial examples as ubiquitous threats to the deep neural network (DNN) based speech recognition systems. In this work, we present a U-Net based attention model, U-Net $_{At}$, to enhance adversarial speech signals. Specifically, we evaluate the model performance by interpretable speech recognition metrics and discuss the model performance by the augmented adversarial training. Our experiments show that our proposed U-Net$_{At}$ improves the perceptual evaluation of speech quality (PESQ) from 1.13 to 2.78, speech transmission index (STI) from 0.65 to 0.75, short-term objective intelligibility (STOI) from 0.83 to 0.96 on the task of speech **enhancement** with adversarial speech examples. We conduct experiments on the automatic speech recognition (ASR) task with adversarial audio attacks. We find that (i) temporal features learned by the attention network are capable of enhancing the robustness of DNN based ASR models; (ii) the generalization power of DNN based ASR model could be enhanced by applying adversarial training with an additive adversarial data augmentation. The ASR metric on word-error-rates (WERs) shows that there is an absolute 2.22 $\%$ decrease under gradient-based perturbation, and an absolute 2.03 $\%$ decrease, under evolutionary-optimized perturbation, which suggests that our **enhancement** models with adversarial training can further secure a resilient ASR system.  
### A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v4 [cs.CV] UPDATED)
- Authors : Zahra Anvari, Vassilis Athitsos
- Link : [http://arxiv.org/abs/2112.02719](http://arxiv.org/abs/2112.02719)
> ABSTRACT  :  Digitized documents such as scientific articles, tax forms, invoices, contract papers, historic texts are widely used nowadays. These document images could be degraded or damaged due to various reasons including poor lighting conditions, shadow, distortions like noise and blur, aging, ink stain, bleed-through, watermark, stamp, etc. Document image **enhancement** plays a crucial role as a pre-processing step in many automated document analysis and recognition tasks such as character recognition. With recent advances in deep learning, many methods are proposed to enhance the quality of these document images. In this paper, we review deep learning-based methods, datasets, and metrics for six main document image **enhancement** tasks, including binarization, debluring, denoising, defading, watermark removal, and shadow removal. We summarize the recent works for each task and discuss their features, challenges, and limitations. We introduce multiple document image **enhancement** tasks that have received little to no attention, including over and under **exposure** correction, super resolution, and bleed-through removal. We identify several promising research directions and opportunities for future research.  
## cs.AI
---
### CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution. (arXiv:2201.00689v1 [cs.IR])
- Authors : Di Yao, Chang Gong, **Lei Zhang**, Sheng Chen, Jingping Bi
- Link : [http://arxiv.org/abs/2201.00689](http://arxiv.org/abs/2201.00689)
> ABSTRACT  :  Multi-touch attribution (MTA), aiming to estimate the contribution of each advertisement touchpoint in conversion journeys, is essential for budget allocation and automatically advertising. Existing methods first train a model to predict the conversion probability of the advertisement journeys with historical data and calculate the attribution of each touchpoint using counterfactual predictions. An assumption of these works is the conversion prediction model is unbiased, i.e., it can give accurate predictions on any randomly assigned journey, including both the factual and counterfactual ones. Nevertheless, this assumption does not always hold as the exposed advertisements are recommended according to user preferences. This confounding bias of users would lead to an out-of-distribution (OOD) problem in the counterfactual prediction and cause concept drift in attribution. In this paper, we define the causal MTA task and propose CausalMTA to eliminate the influence of user preferences. It systemically eliminates the confounding bias from both static and dynamic preferences to learn the conversion prediction model using historical data. We also provide a theoretical analysis to prove CausalMTA can learn an unbiased prediction model with sufficient data. Extensive experiments on both public datasets and the impression data in an e-commerce company show that CausalMTA not only achieves better prediction performance than the state-of-the-art method but also generates meaningful attribution credits across different advertising channels.  
### Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions. (arXiv:2201.00768v1 [cs.CL])
- Authors : Marwan Omar, Soohyeon Choi, DaeHun Nyang, David Mohaisen
- Link : [http://arxiv.org/abs/2201.00768](http://arxiv.org/abs/2201.00768)
> ABSTRACT  :  Recent natural language processing (NLP) techniques have accomplished high performance on benchmark datasets, primarily due to the significant improvement in the performance of deep learning. The advances in the research community have led to great **enhancement**s in state-of-the-art production systems for NLP tasks, such as virtual assistants, speech recognition, and sentiment analysis. However, such NLP systems still often fail when tested with adversarial attacks. The initial lack of robustness exposed troubling gaps in current models' language understanding capabilities, creating problems when NLP systems are deployed in real life. In this paper, we present a structured overview of NLP robustness research by summarizing the literature in a systemic way across various dimensions. We then take a deep-dive into the various dimensions of robustness, across techniques, metrics, embeddings, and benchmarks. Finally, we argue that robustness should be multi-dimensional, provide insights into current research, identify gaps in the literature to suggest directions worth pursuing to address these gaps.  
# Paper List
---
## cs.CV
---
**115** new papers in cs.CV:-) 
1. Multi-Dimensional Model Compression of Vision Transformer. (arXiv:2201.00043v1 [cs.CV])
2. iCaps: Iterative Category-level Object Pose and Shape Estimation. (arXiv:2201.00059v1 [cs.CV])
3. Croesus: Multi-Stage Processing and Transactions for Video-Analytics in Edge-Cloud Systems. (arXiv:2201.00063v1 [eess.SY])
4. PatchTrack: Multiple Object Tracking Using Frame Patches. (arXiv:2201.00080v1 [cs.CV])
5. Performance Comparison of Deep Learning Architectures for Artifact Removal in Gastrointestinal Endoscopic Imaging. (arXiv:2201.00084v1 [eess.IV])
6. Computer Vision Based Parking Optimization System. (arXiv:2201.00095v1 [cs.CV])
7. SalyPath360: Saliency and Scanpath Prediction Framework for Omnidirectional Images. (arXiv:2201.00096v1 [cs.CV])
8. Adversarial Attack via Dual-Stage Network Erosion. (arXiv:2201.00097v1 [cs.CV])
9. Boosting RGB-D Saliency Detection by Leveraging Unlabeled RGB Images. (arXiv:2201.00100v1 [eess.IV])
10. Robust Region Feature Synthesizer for Zero-Shot Object Detection. (arXiv:2201.00103v1 [cs.CV])
11. Quality-aware Part Models for Occluded Person Re-identification. (arXiv:2201.00107v1 [cs.CV])
12. SurfGen: Adversarial 3D Shape Synthesis with Explicit Surface Discriminators. (arXiv:2201.00112v1 [cs.CV])
13. SAFL: A Self-Attention Scene Text Recognizer with Focal Loss. (arXiv:2201.00132v1 [cs.CV])
14. Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness. (arXiv:2201.00148v1 [cs.LG])
15. Adaptive Single Image Deblurring. (arXiv:2201.00155v1 [eess.IV])
16. Development of Diabetic Foot Ulcer Datasets: An Overview. (arXiv:2201.00163v1 [eess.IV])
17. Self-attention Multi-view Representation Learning with Diversity-promoting Complementarity. (arXiv:2201.00168v1 [cs.LG])
18. Dynamic Scene Video Deblurring using Non-Local Attention. (arXiv:2201.00169v1 [eess.IV])
19. Multi-view Subspace Adaptive Learning via Autoencoder and Attention. (arXiv:2201.00171v1 [cs.LG])
20. Adaptive Image Inpainting. (arXiv:2201.00177v1 [cs.CV])
21. Image **Restoration** using Feature-guidance. (arXiv:2201.00187v1 [eess.IV])
22. Turath-150K: Image Database of Arab Heritage. (arXiv:2201.00220v1 [cs.CV])
23. Deep Learning Applications for Lung Cancer Diagnosis: A systematic review. (arXiv:2201.00227v1 [eess.IV])
24. SporeAgent: Reinforced Scene-level Plausibility for Object Pose Refinement. (arXiv:2201.00239v1 [cs.CV])
25. Subspace modeling for fast and high-sensitivity X-ray chemical imaging. (arXiv:2201.00259v1 [eess.IV])
26. On the Cross-dataset Generalization for License Plate Recognition. (arXiv:2201.00267v1 [cs.CV])
27. DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents. (arXiv:2201.00308v1 [cs.LG])
28. Recurrent Feature Propagation and Edge Skip-Connections for Automatic Abdominal Organ Segmentation. (arXiv:2201.00317v1 [eess.IV])
29. V-LinkNet: Learning Contextual Inpainting Across Latent Space of Generative Adversarial Network. (arXiv:2201.00323v1 [cs.CV])
30. Riemannian Nearest-Regularized Subspace Classification for Polarimetric SAR images. (arXiv:2201.00337v1 [eess.IV])
31. Detail-Preserving Transformer for Light Field Image Super-Resolution. (arXiv:2201.00346v1 [cs.CV])
32. Parkour Spot ID: Feature Matching in Satellite and Street view images using Deep Learning. (arXiv:2201.00377v1 [cs.CV])
33. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v1 [cs.CV])
34. MHATC: Autism Spectrum Disorder identification utilizing multi-head attention encoder along with temporal consolidation modules. (arXiv:2201.00404v1 [q-bio.NC])
35. The Introspective Agent: Interdependence of Strategy, Physiology, and Sensing for Embodied Agents. (arXiv:2201.00411v1 [cs.CV])
36. FUSeg: The Foot Ulcer Segmentation Challenge. (arXiv:2201.00414v1 [eess.IV])
37. Splicing ViT Features for Semantic Appearance Transfer. (arXiv:2201.00424v1 [cs.CV])
38. Image Denoising with Control over Deep Network Hallucination. (arXiv:2201.00429v1 [eess.IV])
39. TVNet: Temporal Voting Network for Action Localization. (arXiv:2201.00434v1 [cs.CV])
40. Salient Object Detection by LTP Texture Characterization on Opposing Color Pairs under SLICO Superpixel Constraint. (arXiv:2201.00439v1 [cs.CV])
41. Scene Graph Generation: A Comprehensive Survey. (arXiv:2201.00443v1 [cs.CV])
42. Memory-Guided Semantic Learning Network for Temporal Sentence Grounding. (arXiv:2201.00454v1 [cs.CV])
43. Exploring Motion and Appearance Information for Temporal Sentence Grounding. (arXiv:2201.00457v1 [cs.CV])
44. Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark. (arXiv:2201.00458v1 [eess.IV])
45. Biometrics in the Time of Pandemic: 40% Masked Face Recognition Degradation can be Reduced to 2%. (arXiv:2201.00461v1 [cs.CV])
46. D-Former: A U-shaped Dilated Transformer for 3D Medical Image Segmentation. (arXiv:2201.00462v1 [cs.CV])
47. RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v1 [eess.IV])
48. maskGRU: Tracking Small Objects in the Presence of Large Background Motions. (arXiv:2201.00467v1 [cs.CV])
49. Revisiting Open World Object Detection. (arXiv:2201.00471v1 [cs.CV])
50. CaFT: Clustering and Filter on Tokens of Transformer for Weakly Supervised Object Localization. (arXiv:2201.00475v1 [cs.CV])
51. Language as Queries for Referring Video Object Segmentation. (arXiv:2201.00487v1 [cs.CV])
52. R-Theta Local Neighborhood Pattern for Unconstrained Facial Image Recognition and Retrieval. (arXiv:2201.00504v1 [cs.CV])
53. Local Gradient Hexa Pattern: A Descriptor for Face Recognition and Retrieval. (arXiv:2201.00509v1 [cs.CV])
54. Centre Symmetric Quadruple Pattern: A Novel Descriptor for Facial Image Recognition and Retrieval. (arXiv:2201.00511v1 [cs.MM])
55. Cascaded Asymmetric Local Pattern: A Novel Descriptor for Unconstrained Facial Image Recognition and Retrieval. (arXiv:2201.00518v1 [cs.CV])
56. Vision Transformer with Deformable Attention. (arXiv:2201.00520v1 [cs.CV])
57. Novelty-based Generalization Evaluation for Traffic Light Detection. (arXiv:2201.00531v1 [cs.CV])
58. Concept Embeddings for Fuzzy Logic Verification of Deep Neural Networks in Perception Tasks. (arXiv:2201.00572v1 [cs.CV])
59. Semantically Grounded Visual Embeddings for Zero-Shot Learning. (arXiv:2201.00577v1 [cs.CV])
60. LiDAR Point--to--point Correspondences for Rigorous Registration of Kinematic Scanning in Dynamic Networks. (arXiv:2201.00596v1 [cs.RO])
61. An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v1 [cs.LG])
62. GAT-CADNet: Graph Attention Network for Panoptic Symbol Spotting in CAD Drawings. (arXiv:2201.00625v1 [cs.CV])
63. Improving Feature Extraction from Histopathological Images Through A Fine-tuning ImageNet Model. (arXiv:2201.00636v1 [eess.IV])
64. Compression-Resistant Backdoor Attack against Deep Neural Networks. (arXiv:2201.00672v1 [cs.CV])
65. Multimodal Entity Tagging with Multimodal Knowledge Base. (arXiv:2201.00693v1 [cs.IR])
66. Multiview point cloud registration with anisotropic and space-varying localization noise. (arXiv:2201.00708v1 [cs.CV])
67. Multi-view Data Classification with a Label-driven Auto-weighted Strategy. (arXiv:2201.00714v1 [cs.CV])
68. BDG-Net: Boundary Distribution Guided Network for Accurate Polyp Segmentation. (arXiv:2201.00767v1 [eess.IV])
69. FaceQgen: Semi-Supervised Deep Learning for Face Image Quality Assessment. (arXiv:2201.00770v1 [cs.CV])
70. Implicit Autoencoder for Point Cloud Self-supervised Representation Learning. (arXiv:2201.00785v1 [cs.CV])
71. DFA-NeRF: Personalized Talking Head Generation via Disentangled Face Attributes Neural Rendering. (arXiv:2201.00791v1 [cs.CV])
72. Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space. (arXiv:2201.00814v1 [cs.CV])
73. Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods. (arXiv:1907.09358v3 [cs.CV] UPDATED)
74. Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v2 [cs.CV] UPDATED)
75. FedBoost: Federated Learning with Gradient Protected Boosting for Text Recognition. (arXiv:2007.07296v2 [cs.CV] UPDATED)
76. A Boundary Based Out-of-Distribution Classifier for Generalized Zero-Shot Learning. (arXiv:2008.04872v2 [cs.CV] UPDATED)
77. Fast and Incremental Loop Closure Detection with Deep Features and Proximity Graphs. (arXiv:2010.11703v2 [cs.CV] UPDATED)
78. Boosting Contrastive Self-Supervised Learning with False Negative Cancellation. (arXiv:2011.11765v2 [cs.CV] UPDATED)
79. A Review of Open-World Learning and Steps Toward Open-World Learning Without Labels. (arXiv:2011.12906v3 [cs.CV] UPDATED)
80. A General Descent Aggregation Framework for Gradient-based Bi-level Optimization. (arXiv:2102.07976v3 [cs.LG] UPDATED)
81. Galaxy Zoo DECaLS: Detailed Visual Morphology Measurements from Volunteers and Deep Learning for 314,000 Galaxies. (arXiv:2102.08414v2 [astro-ph.GA] UPDATED)
82. Elsa: Energy-based learning for semi-supervised anomaly detection. (arXiv:2103.15296v2 [cs.CV] UPDATED)
83. Visual Vibration Tomography: Estimating Interior Material Properties from Monocular Video. (arXiv:2104.02735v3 [cs.CV] UPDATED)
84. BM-NAS: Bilevel Multimodal Neural Architecture Search. (arXiv:2104.09379v2 [cs.CV] UPDATED)
85. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v3 [cs.CV] UPDATED)
86. Multi-modal Visual Place Recognition in Dynamics-Invariant Perception Space. (arXiv:2105.07800v2 [cs.CV] UPDATED)
87. A Novel lightweight Convolutional Neural Network, ExquisiteNetV2. (arXiv:2105.09008v4 [cs.CV] UPDATED)
88. Medical Matting: A New Perspective on Medical Segmentation with Uncertainty. (arXiv:2106.09887v3 [cs.CV] UPDATED)
89. Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation. (arXiv:2107.03358v2 [cs.CV] UPDATED)
90. Modality specific U-Net variants for biomedical image segmentation: A survey. (arXiv:2107.04537v3 [eess.IV] UPDATED)
91. LASOR: Learning Accurate 3D Human Pose and Shape Via Synthetic Occlusion-Aware Data and Neural Mesh Rendering. (arXiv:2108.00351v4 [cs.CV] UPDATED)
92. Data Acquisition and Preparation for Dual-reference Deep Learning of Image Super-Resolution. (arXiv:2108.02348v4 [eess.IV] UPDATED)
93. RCA-IUnet: A residual cross-spatial attention guided inception U-Net model for tumor segmentation in breast ultrasound imaging. (arXiv:2108.02508v4 [eess.IV] UPDATED)
94. Bird's-Eye-View Panoptic Segmentation Using Monocular Frontal View Images. (arXiv:2108.03227v3 [cs.CV] UPDATED)
95. Boosting Salient Object Detection with Transformer-based Asymmetric **Bilateral** U-Net. (arXiv:2108.07851v4 [cs.CV] UPDATED)
96. Towards Transferable Adversarial Attacks on Vision Transformers. (arXiv:2109.04176v3 [cs.CV] UPDATED)
97. Semantics-Guided Contrastive Network for Zero-Shot Object detection. (arXiv:2109.06062v2 [cs.CV] UPDATED)
98. Two-Stage Mesh Deep Learning for Automated Tooth Segmentation and Landmark Localization on 3D Intraoral Scans. (arXiv:2109.11941v2 [cs.CV] UPDATED)
99. A General Gaussian Heatmap Label Assignment for Arbitrary-Oriented Object Detection. (arXiv:2109.12848v4 [cs.CV] UPDATED)
100. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v3 [cs.LG] UPDATED)
101. Robust Pedestrian Attribute Recognition Using Group Sparsity for Occlusion Videos. (arXiv:2110.08708v3 [cs.CV] UPDATED)
102. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v5 [eess.IV] UPDATED)
103. SLURP: Side Learning Uncertainty for Regression Problems. (arXiv:2110.11182v2 [cs.CV] UPDATED)
104. AugMax: Adversarial Composition of Random Augmentations for Robust Training. (arXiv:2110.13771v3 [cs.CV] UPDATED)
105. Robust Contrastive Learning Using Negative Samples with Diminished Semantics. (arXiv:2110.14189v2 [cs.CV] UPDATED)
106. Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models. (arXiv:2111.07355v2 [eess.IV] UPDATED)
107. NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning. (arXiv:2111.13984v2 [cs.LG] UPDATED)
108. A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v4 [cs.CV] UPDATED)
109. BT-Unet: A self-supervised learning framework for biomedical image segmentation using Barlow Twins with U-Net models. (arXiv:2112.03916v2 [eess.IV] UPDATED)
110. Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning. (arXiv:2112.04731v3 [cs.CV] UPDATED)
111. UFPMP-Det: Toward Accurate and Efficient Object Detection on Drone Imagery. (arXiv:2112.10415v2 [cs.CV] UPDATED)
112. HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images. (arXiv:2112.10775v2 [eess.IV] UPDATED)
113. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v2 [eess.IV] UPDATED)
114. Weakly Supervised Visual-Auditory Saliency Detection with Multigranularity Perception. (arXiv:2112.13697v2 [cs.CV] UPDATED)
115. Finding the Task-Optimal Low-Bit Sub-Distribution in Deep Neural Networks. (arXiv:2112.15139v2 [cs.CV] UPDATED)
## eess.IV
---
**35** new papers in eess.IV:-) 
1. Experimental realization of the active convolved illumination imaging technique for enhanced signal-to-noise ratio. (arXiv:2201.00046v1 [physics.optics])
2. Performance Comparison of Deep Learning Architectures for Artifact Removal in Gastrointestinal Endoscopic Imaging. (arXiv:2201.00084v1 [eess.IV])
3. Adversarial Attack via Dual-Stage Network Erosion. (arXiv:2201.00097v1 [cs.CV])
4. Boosting RGB-D Saliency Detection by Leveraging Unlabeled RGB Images. (arXiv:2201.00100v1 [eess.IV])
5. Adaptive Single Image Deblurring. (arXiv:2201.00155v1 [eess.IV])
6. Development of Diabetic Foot Ulcer Datasets: An Overview. (arXiv:2201.00163v1 [eess.IV])
7. Dynamic Scene Video Deblurring using Non-Local Attention. (arXiv:2201.00169v1 [eess.IV])
8. Image **Restoration** using Feature-guidance. (arXiv:2201.00187v1 [eess.IV])
9. Deep Learning Applications for Lung Cancer Diagnosis: A systematic review. (arXiv:2201.00227v1 [eess.IV])
10. Subspace modeling for fast and high-sensitivity X-ray chemical imaging. (arXiv:2201.00259v1 [eess.IV])
11. Recurrent Feature Propagation and Edge Skip-Connections for Automatic Abdominal Organ Segmentation. (arXiv:2201.00317v1 [eess.IV])
12. Riemannian Nearest-Regularized Subspace Classification for Polarimetric SAR images. (arXiv:2201.00337v1 [eess.IV])
13. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v1 [cs.CV])
14. MHATC: Autism Spectrum Disorder identification utilizing multi-head attention encoder along with temporal consolidation modules. (arXiv:2201.00404v1 [q-bio.NC])
15. FUSeg: The Foot Ulcer Segmentation Challenge. (arXiv:2201.00414v1 [eess.IV])
16. Image Denoising with Control over Deep Network Hallucination. (arXiv:2201.00429v1 [eess.IV])
17. Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark. (arXiv:2201.00458v1 [eess.IV])
18. RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v1 [eess.IV])
19. Generative adversarial network for super-resolution imaging through a fiber. (arXiv:2201.00601v1 [eess.IV])
20. Improving Feature Extraction from Histopathological Images Through A Fine-tuning ImageNet Model. (arXiv:2201.00636v1 [eess.IV])
21. Learning a microlocal priorfor limited-angle tomography. (arXiv:2201.00656v1 [eess.IV])
22. BDG-Net: Boundary Distribution Guided Network for Accurate Polyp Segmentation. (arXiv:2201.00767v1 [eess.IV])
23. FaceQgen: Semi-Supervised Deep Learning for Face Image Quality Assessment. (arXiv:2201.00770v1 [cs.CV])
24. A Review of Open-World Learning and Steps Toward Open-World Learning Without Labels. (arXiv:2011.12906v3 [cs.CV] UPDATED)
25. Visual Vibration Tomography: Estimating Interior Material Properties from Monocular Video. (arXiv:2104.02735v3 [cs.CV] UPDATED)
26. Multi-Resolution Data Fusion for Super Resolution Imaging. (arXiv:2105.06533v6 [eess.IV] UPDATED)
27. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v3 [cs.CV] UPDATED)
28. Modality specific U-Net variants for biomedical image segmentation: A survey. (arXiv:2107.04537v3 [eess.IV] UPDATED)
29. Data Acquisition and Preparation for Dual-reference Deep Learning of Image Super-Resolution. (arXiv:2108.02348v4 [eess.IV] UPDATED)
30. RCA-IUnet: A residual cross-spatial attention guided inception U-Net model for tumor segmentation in breast ultrasound imaging. (arXiv:2108.02508v4 [eess.IV] UPDATED)
31. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v5 [eess.IV] UPDATED)
32. Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models. (arXiv:2111.07355v2 [eess.IV] UPDATED)
33. BT-Unet: A self-supervised learning framework for biomedical image segmentation using Barlow Twins with U-Net models. (arXiv:2112.03916v2 [eess.IV] UPDATED)
34. HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images. (arXiv:2112.10775v2 [eess.IV] UPDATED)
35. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v2 [eess.IV] UPDATED)
## cs.LG
---
**192** new papers in cs.LG:-) 
1. A Literature Review on Length of Stay Prediction for Stroke Patients using Machine Learning and Statistical Approaches. (arXiv:2201.00005v1 [cs.LG])
2. Knowledge intensive state design for traffic signal control. (arXiv:2201.00006v1 [cs.LG])
3. Confidence-Aware Multi-Teacher Knowledge Distillation. (arXiv:2201.00007v1 [cs.LG])
4. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v1 [cs.LG])
5. Augmentative eXplanation and the Distributional Gap of Confidence Optimization Score. (arXiv:2201.00009v1 [cs.LG])
6. An Efficient Federated Distillation Learning System for Multi-task Time Series Classification. (arXiv:2201.00011v1 [cs.LG])
7. MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning. (arXiv:2201.00012v1 [cs.LG])
8. Exploiting Bi-directional Global Transition Patterns and Personal Preferences for Missing POI Category Identification. (arXiv:2201.00014v1 [cs.LG])
9. TransLog: A Unified Transformer-based Framework for Log Anomaly Detection. (arXiv:2201.00016v1 [cs.LG])
10. Stochastic convex optimization for provably efficient apprenticeship learning. (arXiv:2201.00039v1 [cs.LG])
11. Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments. (arXiv:2201.00042v1 [cs.NE])
12. Multi-Dimensional Model Compression of Vision Transformer. (arXiv:2201.00043v1 [cs.CV])
13. Transformer Embeddings of Irregularly Spaced Events and Their Participants. (arXiv:2201.00044v1 [cs.LG])
14. Evaluating Deep Music Generation Methods Using Data Augmentation. (arXiv:2201.00052v1 [cs.SD])
15. Optimal Representations for Covariate Shift. (arXiv:2201.00057v1 [cs.LG])
16. Representation Topology Divergence: A Method for Comparing Neural Network Representations. (arXiv:2201.00058v1 [cs.LG])
17. Croesus: Multi-Stage Processing and Transactions for Video-Analytics in Edge-Cloud Systems. (arXiv:2201.00063v1 [eess.SY])
18. BARACK: Partially Supervised Group Robustness With Guarantees. (arXiv:2201.00072v1 [cs.LG])
19. How do lexical semantics affect translation? An empirical study. (arXiv:2201.00075v1 [cs.CL])
20. Performance Comparison of Deep Learning Architectures for Artifact Removal in Gastrointestinal Endoscopic Imaging. (arXiv:2201.00084v1 [eess.IV])
21. Dynamic Persistent Homology for Brain Networks via Wasserstein Graph Clustering. (arXiv:2201.00087v1 [math.AT])
22. Distributed Evolution Strategies Using TPUs for Meta-Learning. (arXiv:2201.00093v1 [cs.NE])
23. Role of Data Augmentation Strategies in Knowledge Distillation for Wearable Sensor Data. (arXiv:2201.00111v1 [cs.LG])
24. Toward the Analysis of Graph Neural Networks. (arXiv:2201.00115v1 [cs.SE])
25. Semantic Search for Large Scale Clinical Ontologies. (arXiv:2201.00118v1 [cs.CL])
26. SAFL: A Self-Attention Scene Text Recognizer with Focal Loss. (arXiv:2201.00132v1 [cs.CV])
27. Matrix Decomposition and Applications. (arXiv:2201.00145v1 [math.NA])
28. High-dimensional Bayesian Optimization Algorithm with Recurrent Neural Network for Disease Control Models in Time Series. (arXiv:2201.00147v1 [cs.LG])
29. Rethinking Feature Uncertainty in Stochastic Neural Networks for Adversarial Robustness. (arXiv:2201.00148v1 [cs.LG])
30. MLOps -- Definitions, Tools and Challenges. (arXiv:2201.00162v1 [cs.LG])
31. Self-attention Multi-view Representation Learning with Diversity-promoting Complementarity. (arXiv:2201.00168v1 [cs.LG])
32. Multi-view Subspace Adaptive Learning via Autoencoder and Attention. (arXiv:2201.00171v1 [cs.LG])
33. FamilySeer: Towards Optimized Tensor Codes by Exploiting Computation Subgraph Similarity. (arXiv:2201.00194v1 [cs.LG])
34. The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling. (arXiv:2201.00199v1 [cs.LG])
35. AutoDES: AutoML Pipeline Generation of Classification with Dynamic Ensemble Strategy Selection. (arXiv:2201.00207v1 [cs.LG])
36. Deep Nonparametric Estimation of Operators between Infinite Dimensional Spaces. (arXiv:2201.00217v1 [stat.ML])
37. Deep Learning Applications for Lung Cancer Diagnosis: A systematic review. (arXiv:2201.00227v1 [eess.IV])
38. Dynamic Least-Squares Regression. (arXiv:2201.00228v1 [cs.DS])
39. Recover the spectrum of covariance matrix: a non-asymptotic iterative method. (arXiv:2201.00230v1 [stat.ML])
40. Towards Robust Graph Neural Networks for Noisy Graphs with Sparse Labels. (arXiv:2201.00232v1 [cs.LG])
41. Operator Deep Q-Learning: Zero-Shot Reward Transferring in Reinforcement Learning. (arXiv:2201.00236v1 [cs.LG])
42. Transfer RL across Observation Feature Spaces via Model-Based Regularization. (arXiv:2201.00248v1 [cs.LG])
43. Thinking inside the box: A tutorial on grey-box Bayesian optimization. (arXiv:2201.00272v1 [cs.LG])
44. Applications of Gaussian Mutation for Self Adaptation in Evolutionary Genetic Algorithms. (arXiv:2201.00285v1 [cs.NE])
45. Reinforcement Learning for Task Specifications with Action-Constraints. (arXiv:2201.00286v1 [cs.LG])
46. Fair Data Representation for Machine Learning at the Pareto Frontier. (arXiv:2201.00292v1 [stat.ML])
47. Improving Out-of-Distribution Robustness via Selective Augmentation. (arXiv:2201.00299v1 [cs.LG])
48. DiffuseVAE: Efficient, Controllable and High-Fidelity Generation from Low-Dimensional Latents. (arXiv:2201.00308v1 [cs.LG])
49. On Sensitivity of Deep Learning Based Text Classification Algorithms to Practical Input Perturbations. (arXiv:2201.00318v1 [cs.CL])
50. Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference. (arXiv:2201.00354v1 [cs.LG])
51. Experiment Based Crafting and Analyzing of Machine Learning Solutions. (arXiv:2201.00355v1 [cs.LG])
52. Semi-Supervised Graph Attention Networks for Event Representation Learning. (arXiv:2201.00363v1 [cs.LG])
53. Parkour Spot ID: Feature Matching in Satellite and Street view images using Deep Learning. (arXiv:2201.00377v1 [cs.CV])
54. Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring Platforms. (arXiv:2201.00378v1 [eess.SP])
55. ECOD: Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions. (arXiv:2201.00382v1 [cs.LG])
56. Randomized Signature Layers for Signal Extraction in Time Series Data. (arXiv:2201.00384v1 [cs.LG])
57. On the convex hull of convex quadratic optimization problems with indicators. (arXiv:2201.00387v1 [math.OC])
58. Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization. (arXiv:2201.00402v1 [math.OC])
59. MHATC: Autism Spectrum Disorder identification utilizing multi-head attention encoder along with temporal consolidation modules. (arXiv:2201.00404v1 [q-bio.NC])
60. FUSeg: The Foot Ulcer Segmentation Challenge. (arXiv:2201.00414v1 [eess.IV])
61. Succinct Differentiation of Disparate Boosting Ensemble Learning Methods for Prognostication of Polycystic Ovary Syndrome Diagnosis. (arXiv:2201.00418v1 [cs.LG])
62. The DONUT Approach to EnsembleCombination Forecasting. (arXiv:2201.00426v1 [cs.LG])
63. Transfer-learning-based Surrogate Model for Thermal Conductivity of Nanofluids. (arXiv:2201.00435v1 [physics.flu-dyn])
64. An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation. (arXiv:2201.00436v1 [cs.LG])
65. Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting: A Review. (arXiv:2201.00437v1 [cs.LG])
66. Actor-Critic Network for Q&A in an Adversarial Environment. (arXiv:2201.00455v1 [cs.CL])
67. Lung-Originated Tumor Segmentation from Computed Tomography Scan (LOTUS) Benchmark. (arXiv:2201.00458v1 [eess.IV])
68. Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection. (arXiv:2201.00464v1 [cs.LG])
69. maskGRU: Tracking Small Objects in the Presence of Large Background Motions. (arXiv:2201.00467v1 [cs.CV])
70. Using Non-Stationary Bandits for Learning in Repeated Cournot Games with Non-Stationary Demand. (arXiv:2201.00486v1 [cs.LG])
71. KerGNNs: Interpretable Graph Neural Networks with Graph Kernels. (arXiv:2201.00491v1 [cs.LG])
72. Stochastic Weight Averaging Revisited. (arXiv:2201.00519v1 [cs.LG])
73. Novelty-based Generalization Evaluation for Traffic Light Detection. (arXiv:2201.00531v1 [cs.CV])
74. Hybrid intelligence for dynamic job-shop scheduling with deep reinforcement learning and attention mechanism. (arXiv:2201.00548v1 [cs.AI])
75. Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional Knowledge Graph Embeddings. (arXiv:2201.00565v1 [cs.LG])
76. Asymptotic Convergence of Deep Multi-Agent Actor-Critic Algorithms. (arXiv:2201.00570v1 [cs.LG])
77. Concept Embeddings for Fuzzy Logic Verification of Deep Neural Networks in Perception Tasks. (arXiv:2201.00572v1 [cs.CV])
78. 'Moving On' -- Investigating Inventors' Ethnic Origins Using Supervised Learning. (arXiv:2201.00578v1 [econ.GN])
79. An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v1 [cs.LG])
80. Semi-supervised Stance Detection of Tweets Via Distant Network Supervision. (arXiv:2201.00614v1 [cs.SI])
81. Overview of the EEG Pilot Subtask at MediaEval 2021: Predicting Media Memorability. (arXiv:2201.00620v1 [q-bio.NC])
82. Learning shared neural manifolds from multi-subject FMRI data. (arXiv:2201.00622v1 [q-bio.NC])
83. Uncertainty Detection in EEG Neural Decoding Models. (arXiv:2201.00627v1 [eess.SP])
84. Neural network training under semidefinite constraints. (arXiv:2201.00632v1 [cs.LG])
85. VDPC: Variational Density Peak Clustering Algorithm. (arXiv:2201.00641v1 [cs.LG])
86. Feature matching as improved transfer learning technique for wearable EEG. (arXiv:2201.00644v1 [eess.SP])
87. SAE: Sequential Anchored Ensembles. (arXiv:2201.00649v1 [cs.LG])
88. Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI. (arXiv:2201.00650v1 [cs.LG])
89. Neural combinatorial optimization beyond the TSP: Existing architectures under-represent graph structure. (arXiv:2201.00668v1 [cs.AI])
90. A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges. (arXiv:2201.00680v1 [cs.LG])
91. Topic Analysis of Superconductivity Literature by Semantic Non-negative Matrix Factorization. (arXiv:2201.00687v1 [cs.DL])
92. Automatic Pharma News Categorization. (arXiv:2201.00688v1 [cs.IR])
93. Improved Topic modeling in Twitter through Community Pooling. (arXiv:2201.00690v1 [cs.IR])
94. FIFA ranking: Evaluation and path forward. (arXiv:2201.00691v1 [cs.IR])
95. Validation and Transparency in AI systems for pharmacovigilance: a case study applied to the medical literature monitoring of adverse events. (arXiv:2201.00692v1 [cs.IR])
96. An Efficient Combinatorial Optimization Model Using Learning-to-Rank Distillation. (arXiv:2201.00695v1 [cs.IR])
97. Deep-learning-based upscaling method for geologic models via theory-guided convolutional neural network. (arXiv:2201.00698v1 [cs.LG])
98. Scalable semi-supervised dimensionality reduction with GPU-accelerated EmbedSOM. (arXiv:2201.00701v1 [cs.LG])
99. Continuous Submodular Maximization: Boosting via Non-oblivious Function. (arXiv:2201.00703v1 [cs.LG])
100. Machine learning approaches for localized lockdown during COVID-19: a case study analysis. (arXiv:2201.00715v1 [cs.LG])
101. PowerGraph: Using neural networks and principal components to multivariate statistical power trade-offs. (arXiv:2201.00719v1 [stat.ME])
102. A Cluster-Based Trip Prediction Graph Neural Network Model for Bike Sharing Systems. (arXiv:2201.00720v1 [cs.LG])
103. A Mixed Integer Programming Approach to Training Dense Neural Networks. (arXiv:2201.00723v1 [cs.LG])
104. Application of Machine Learning Methods in Inferring Surface Water Groundwater Exchanges using High Temporal Resolution Temperature Measurements. (arXiv:2201.00726v1 [cs.LG])
105. Faster Unbalanced Optimal Transport: Translation invariant Sinkhorn and 1-D Frank-Wolfe. (arXiv:2201.00730v1 [math.OC])
106. Rank-1 Similarity Matrix Decomposition For Modeling Changes in Antivirus Consensus Through Time. (arXiv:2201.00757v1 [cs.CR])
107. Execute Order 66: Targeted Data Poisoning for Reinforcement Learning. (arXiv:2201.00762v1 [cs.LG])
108. DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection. (arXiv:2201.00763v1 [cs.CR])
109. Have I done enough planning or should I plan more?. (arXiv:2201.00764v1 [cs.AI])
110. Class-Incremental Continual Learning into the eXtended DER-verse. (arXiv:2201.00766v1 [cs.LG])
111. Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions. (arXiv:2201.00768v1 [cs.CL])
112. Descriptors for Machine Learning Model of Generalized Force Field in Condensed Matter Systems. (arXiv:2201.00798v1 [cond-mat.str-el])
113. Revisiting PGD Attacks for Stability Analysis of Large-Scale Nonlinear Systems and Perception-Based Control. (arXiv:2201.00801v1 [math.OC])
114. Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space. (arXiv:2201.00814v1 [cs.CV])
115. Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods. (arXiv:1907.09358v3 [cs.CV] UPDATED)
116. Audiogmenter: a MATLAB Toolbox for Audio Data Augmentation. (arXiv:1912.05472v4 [eess.AS] UPDATED)
117. A Family of Deep Learning Architectures for Channel Estimation and Hybrid Beamforming in Multi-Carrier mm-Wave Massive MIMO. (arXiv:1912.10036v6 [eess.SP] UPDATED)
118. Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v2 [cs.CV] UPDATED)
119. Provable Meta-Learning of Linear Representations. (arXiv:2002.11684v5 [cs.LG] UPDATED)
120. Statistical and Topological Properties of Sliced Probability Divergences. (arXiv:2003.05783v2 [stat.ML] UPDATED)
121. Characterizing Speech Adversarial Examples Using Self-Attention U-Net **Enhancement**. (arXiv:2003.13917v2 [eess.AS] UPDATED)
122. Self Punishment and Reward Backfill for Deep Q-Learning. (arXiv:2004.05002v2 [cs.AI] UPDATED)
123. Layer-Wise Multi-View Decoding for Improved Natural Language Generation. (arXiv:2005.08081v6 [cs.CL] UPDATED)
124. Online Regularization towards Always-Valid High-Dimensional Dynamic Pricing. (arXiv:2007.02470v2 [stat.ML] UPDATED)
125. Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users. (arXiv:2007.06823v3 [cs.LG] UPDATED)
126. Nearly Minimax Optimal Reinforcement Learning for Discounted MDPs. (arXiv:2010.00587v3 [cs.LG] UPDATED)
127. Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model. (arXiv:2010.02065v4 [cs.LG] UPDATED)
128. Support vector machines and Radon's theorem. (arXiv:2011.00617v2 [cs.LG] UPDATED)
129. The complementarity of a diverse range of deep learning features extracted from video content for video recommendation. (arXiv:2011.10834v2 [cs.IR] UPDATED)
130. Boosting Contrastive Self-Supervised Learning with False Negative Cancellation. (arXiv:2011.11765v2 [cs.CV] UPDATED)
131. A Review of Open-World Learning and Steps Toward Open-World Learning Without Labels. (arXiv:2011.12906v3 [cs.CV] UPDATED)
132. Model-free Neural Counterfactual Regret Minimization with Bootstrap Learning. (arXiv:2012.01870v3 [cs.LG] UPDATED)
133. Minimum Excess Risk in Bayesian Learning. (arXiv:2012.14868v2 [cs.LG] UPDATED)
134. Continuity of Generalized Entropy and Statistical Learning. (arXiv:2012.15829v2 [cs.LG] UPDATED)
135. Provably Efficient Reinforcement Learning with Linear Function Approximation Under Adaptivity Constraints. (arXiv:2101.02195v2 [cs.LG] UPDATED)
136. AHAR: Adaptive CNN for Energy-efficient Human Activity Recognition in Low-power Edge Devices. (arXiv:2102.01875v3 [cs.LG] UPDATED)
137. Generalization Bounds for Noisy Iterative Algorithms Using Properties of Additive Noise Channels. (arXiv:2102.02976v3 [stat.ML] UPDATED)
138. Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v18 [cs.LG] UPDATED)
139. A General Descent Aggregation Framework for Gradient-based Bi-level Optimization. (arXiv:2102.07976v3 [cs.LG] UPDATED)
140. Linear Classifiers in Product Space Forms. (arXiv:2102.10204v3 [cs.LG] UPDATED)
141. Snowflake: Scaling GNNs to High-Dimensional Continuous Control via Parameter Freezing. (arXiv:2103.01009v3 [cs.LG] UPDATED)
142. A Survey of Embodied AI: From Simulators to Research Tasks. (arXiv:2103.04918v7 [cs.AI] UPDATED)
143. Covariate-assisted Sparse Tensor Completion. (arXiv:2103.06428v2 [stat.ML] UPDATED)
144. Improving Actor-Critic Reinforcement Learning via Hamiltonian Monte Carlo Method. (arXiv:2103.12020v3 [cs.LG] UPDATED)
145. Elsa: Energy-based learning for semi-supervised anomaly detection. (arXiv:2103.15296v2 [cs.CV] UPDATED)
146. Optimal Sampling Gaps for Adaptive Submodular Maximization. (arXiv:2104.01750v4 [cs.LG] UPDATED)
147. BM-NAS: Bilevel Multimodal Neural Architecture Search. (arXiv:2104.09379v2 [cs.CV] UPDATED)
148. Conditional Selective Inference for Robust Regression and Outlier Detection using Piecewise-Linear Homotopy Continuation. (arXiv:2104.10840v2 [stat.ML] UPDATED)
149. Risk Bounds for Over-parameterized Maximum Margin Classification on Sub-Gaussian Mixtures. (arXiv:2104.13628v2 [cs.LG] UPDATED)
150. Machine learning moment closure models for the radiative transfer equation I: directly learning a gradient based closure. (arXiv:2105.05690v2 [math.NA] UPDATED)
151. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v3 [cs.CV] UPDATED)
152. Latent Gaussian Model Boosting. (arXiv:2105.08966v3 [cs.LG] UPDATED)
153. User-Level Label Leakage from Gradients in Federated Learning. (arXiv:2105.09369v4 [cs.CR] UPDATED)
154. Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning. (arXiv:2106.01854v2 [cs.LG] UPDATED)
155. DSelect-k: Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning. (arXiv:2106.03760v3 [cs.LG] UPDATED)
156. Game of GANs: Game-Theoretical Models for Generative Adversarial Networks. (arXiv:2106.06976v3 [cs.LG] UPDATED)
157. The Flip Side of the Reweighted Coin: Duality of Adaptive Dropout and Regularization. (arXiv:2106.07769v3 [cs.LG] UPDATED)
158. A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models. (arXiv:2106.12887v2 [cs.LG] UPDATED)
159. Latent structure blockmodels for Bayesian spectral graph clustering. (arXiv:2107.01734v2 [stat.ML] UPDATED)
160. Sample Complexity of Learning Parametric Quantum Circuits. (arXiv:2107.09078v2 [quant-ph] UPDATED)
161. An Embedding of ReLU Networks and an Analysis of their Identifiability. (arXiv:2107.09370v2 [cs.LG] UPDATED)
162. Learning cortical representations through perturbed and adversarial dreaming. (arXiv:2109.04261v2 [q-bio.NC] UPDATED)
163. AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators. (arXiv:2109.10259v2 [cs.LG] UPDATED)
164. On the Provable Generalization of Recurrent Neural Networks. (arXiv:2109.14142v3 [cs.LG] UPDATED)
165. Graph Pointer Neural Networks. (arXiv:2110.00973v2 [cs.LG] UPDATED)
166. Convergence of Random Reshuffling Under The Kurdyka-{\L}ojasiewicz Inequality. (arXiv:2110.04926v2 [math.OC] UPDATED)
167. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v3 [cs.LG] UPDATED)
168. Layer-wise Adaptive Model Aggregation for Scalable Federated Learning. (arXiv:2110.10302v3 [cs.LG] UPDATED)
169. SLURP: Side Learning Uncertainty for Regression Problems. (arXiv:2110.11182v2 [cs.CV] UPDATED)
170. A Comprehensive Survey of Logging in Software: From Logging Statements Automation to Log Mining and Analysis. (arXiv:2110.12489v2 [cs.SE] UPDATED)
171. Identify comorbidities associated with recurrent ED and in-patient visits. (arXiv:2110.13769v2 [stat.ML] UPDATED)
172. AugMax: Adversarial Composition of Random Augmentations for Robust Training. (arXiv:2110.13771v3 [cs.CV] UPDATED)
173. Robust Contrastive Learning Using Negative Samples with Diminished Semantics. (arXiv:2110.14189v2 [cs.CV] UPDATED)
174. Fracture Detection in Wrist X-ray Images Using Deep Learning-Based Object Detection Models. (arXiv:2111.07355v2 [eess.IV] UPDATED)
175. A Survey of Generalisation in Deep Reinforcement Learning. (arXiv:2111.09794v3 [cs.LG] UPDATED)
176. Deep Representation Learning with an Information-theoretic Loss. (arXiv:2111.12950v3 [cs.LG] UPDATED)
177. NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning. (arXiv:2111.13984v2 [cs.LG] UPDATED)
178. Reconstructing spectral functions via automatic differentiation. (arXiv:2111.14760v2 [hep-ph] UPDATED)
179. Logic Shrinkage: Learned FPGA Netlist Sparsity for Efficient Neural Network Inference. (arXiv:2112.02346v2 [cs.LG] UPDATED)
180. A Survey on Deep learning based Document Image **Enhancement**. (arXiv:2112.02719v4 [cs.CV] UPDATED)
181. Mimicking the Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning. (arXiv:2112.04731v3 [cs.CV] UPDATED)
182. On Optimizing Interventions in Shared Autonomy. (arXiv:2112.09169v2 [cs.AI] UPDATED)
183. Estimating Causal Effects of Multi-Aspect Online Reviews with Multi-Modal Proxies. (arXiv:2112.10274v2 [cs.LG] UPDATED)
184. GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation System. (arXiv:2112.10767v4 [cs.LG] UPDATED)
185. HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images. (arXiv:2112.10775v2 [eess.IV] UPDATED)
186. An Attention Score Based Attacker for Black-box NLP Classifier. (arXiv:2112.11660v2 [cs.LG] UPDATED)
187. A Unified Analysis Method for Online Optimization in Normed Vector Space. (arXiv:2112.12134v3 [cs.LG] UPDATED)
188. SoK: Privacy-preserving Deep Learning with Homomorphic Encryption. (arXiv:2112.12855v2 [cs.CR] UPDATED)
189. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v2 [cs.CR] UPDATED)
190. Resource-Efficient and Delay-Aware Federated Learning Design under Edge Heterogeneity. (arXiv:2112.13926v2 [cs.NI] UPDATED)
191. Transfer learning of phase transitions in percolation and directed percolation. (arXiv:2112.15516v2 [cond-mat.stat-mech] UPDATED)
192. DDPG car-following model with real-world human driving experience in CARLA. (arXiv:2112.14602v1 [cs.RO] CROSS LISTED)
## cs.AI
---
**82** new papers in cs.AI:-) 
1. A Literature Review on Length of Stay Prediction for Stroke Patients using Machine Learning and Statistical Approaches. (arXiv:2201.00005v1 [cs.LG])
2. Knowledge intensive state design for traffic signal control. (arXiv:2201.00006v1 [cs.LG])
3. Confidence-Aware Multi-Teacher Knowledge Distillation. (arXiv:2201.00007v1 [cs.LG])
4. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v1 [cs.LG])
5. Augmentative eXplanation and the Distributional Gap of Confidence Optimization Score. (arXiv:2201.00009v1 [cs.LG])
6. An Efficient Federated Distillation Learning System for Multi-task Time Series Classification. (arXiv:2201.00011v1 [cs.LG])
7. MORAL: Aligning AI with Human Norms through Multi-Objective Reinforced Active Learning. (arXiv:2201.00012v1 [cs.LG])
8. TransLog: A Unified Transformer-based Framework for Log Anomaly Detection. (arXiv:2201.00016v1 [cs.LG])
9. Avoiding Catastrophe: Active Dendrites Enable Multi-Task Learning in Dynamic Environments. (arXiv:2201.00042v1 [cs.NE])
10. Transformer Embeddings of Irregularly Spaced Events and Their Participants. (arXiv:2201.00044v1 [cs.LG])
11. Optimal Representations for Covariate Shift. (arXiv:2201.00057v1 [cs.LG])
12. Distributed Evolution Strategies Using TPUs for Meta-Learning. (arXiv:2201.00093v1 [cs.NE])
13. Computer Vision Based Parking Optimization System. (arXiv:2201.00095v1 [cs.CV])
14. IoT-based Route Recommendation for an Intelligent Waste Management System. (arXiv:2201.00180v1 [cs.AI])
15. The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling. (arXiv:2201.00199v1 [cs.LG])
16. Learning Free Gait Transition for Quadruped Robots via Phase-Guided Controller. (arXiv:2201.00206v1 [cs.RO])
17. The Parametric Cost Function Approximation: A new approach for multistage stochastic programming. (arXiv:2201.00258v1 [math.OC])
18. Reinforcement Learning for Task Specifications with Action-Constraints. (arXiv:2201.00286v1 [cs.LG])
19. Informed Multi-context Entity Alignment. (arXiv:2201.00304v1 [cs.AI])
20. LSTM Architecture for Oil Stocks Prices Prediction. (arXiv:2201.00350v1 [q-fin.ST])
21. Toward Causal-Aware RL: State-Wise Action-Refined Temporal Difference. (arXiv:2201.00354v1 [cs.LG])
22. Integrating Artificial Intelligence and Augmented Reality in Robotic Surgery: An Initial dVRK Study Using a Surgical Education Scenario. (arXiv:2201.00383v1 [cs.RO])
23. Mind Your Solver! On Adversarial Attack and Defense for Combinatorial Optimization. (arXiv:2201.00402v1 [math.OC])
24. The Introspective Agent: Interdependence of Strategy, Physiology, and Sensing for Embodied Agents. (arXiv:2201.00411v1 [cs.CV])
25. An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation. (arXiv:2201.00436v1 [cs.LG])
26. Artificial Intelligence and Statistical Techniques in Short-Term Load Forecasting: A Review. (arXiv:2201.00437v1 [cs.LG])
27. Actor-Critic Network for Q&A in an Adversarial Environment. (arXiv:2201.00455v1 [cs.CL])
28. Biometrics in the Time of Pandemic: 40% Masked Face Recognition Degradation can be Reduced to 2%. (arXiv:2201.00461v1 [cs.CV])
29. D-Former: A U-shaped Dilated Transformer for 3D Medical Image Segmentation. (arXiv:2201.00462v1 [cs.CV])
30. Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection. (arXiv:2201.00464v1 [cs.LG])
31. KerGNNs: Interpretable Graph Neural Networks with Graph Kernels. (arXiv:2201.00491v1 [cs.LG])
32. Hybrid intelligence for dynamic job-shop scheduling with deep reinforcement learning and attention mechanism. (arXiv:2201.00548v1 [cs.AI])
33. Zero-Shot Cost Models for Out-of-the-box Learned Cost Prediction. (arXiv:2201.00561v1 [cs.DB])
34. Swift and Sure: Hardness-aware Contrastive Learning for Low-dimensional Knowledge Graph Embeddings. (arXiv:2201.00565v1 [cs.LG])
35. Asymptotic Convergence of Deep Multi-Agent Actor-Critic Algorithms. (arXiv:2201.00570v1 [cs.LG])
36. Feature Selection-based Intrusion Detection System Using Genetic Whale Optimization Algorithm and Sample-based Classification. (arXiv:2201.00584v1 [cs.CR])
37. Relating Blindsight and AI: A Review. (arXiv:2201.00616v1 [q-bio.NC])
38. Wireless-Enabled Asynchronous Federated Fourier Neural Network for Turbulence Prediction in Urban Air Mobility (UAM). (arXiv:2201.00626v1 [eess.SP])
39. Uncertainty Detection in EEG Neural Decoding Models. (arXiv:2201.00627v1 [eess.SP])
40. An EEG-based approach for Parkinson's disease diagnosis using Capsule network. (arXiv:2201.00628v1 [eess.SP])
41. VDPC: Variational Density Peak Clustering Algorithm. (arXiv:2201.00641v1 [cs.LG])
42. Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI. (arXiv:2201.00650v1 [cs.LG])
43. Formal Verification of Unknown Dynamical Systems via Gaussian Process Regression. (arXiv:2201.00655v1 [eess.SY])
44. Neural combinatorial optimization beyond the TSP: Existing architectures under-represent graph structure. (arXiv:2201.00668v1 [cs.AI])
45. A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges. (arXiv:2201.00680v1 [cs.LG])
46. CausalMTA: Eliminating the User Confounding Bias for Causal Multi-touch Attribution. (arXiv:2201.00689v1 [cs.IR])
47. Multimodal Entity Tagging with Multimodal Knowledge Base. (arXiv:2201.00693v1 [cs.IR])
48. Decision support system for distributed manufacturing based on input-output analysis and economic complexity. (arXiv:2201.00694v1 [cs.IR])
49. An Efficient Combinatorial Optimization Model Using Learning-to-Rank Distillation. (arXiv:2201.00695v1 [cs.IR])
50. Deep-learning-based upscaling method for geologic models via theory-guided convolutional neural network. (arXiv:2201.00698v1 [cs.LG])
51. Modeling Associative Reasoning Processes. (arXiv:2201.00716v1 [cs.AI])
52. Execute Order 66: Targeted Data Poisoning for Reinforcement Learning. (arXiv:2201.00762v1 [cs.LG])
53. Have I done enough planning or should I plan more?. (arXiv:2201.00764v1 [cs.AI])
54. Robust Natural Language Processing: Recent Advances, Challenges, and Future Directions. (arXiv:2201.00768v1 [cs.CL])
55. Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space. (arXiv:2201.00814v1 [cs.CV])
56. Development of formal models, algorithms, procedures, engineering and functioning of the software system "Instrumental complex for ontological engineering purpose". (arXiv:1803.10684v2 [cs.SE] UPDATED)
57. Provable Meta-Learning of Linear Representations. (arXiv:2002.11684v5 [cs.LG] UPDATED)
58. Self Punishment and Reward Backfill for Deep Q-Learning. (arXiv:2004.05002v2 [cs.AI] UPDATED)
59. Detecting Misclassification Errors in Neural Networks with a Gaussian Process Model. (arXiv:2010.02065v4 [cs.LG] UPDATED)
60. A Review of Open-World Learning and Steps Toward Open-World Learning Without Labels. (arXiv:2011.12906v3 [cs.CV] UPDATED)
61. Minimum Excess Risk in Bayesian Learning. (arXiv:2012.14868v2 [cs.LG] UPDATED)
62. Rethinking the Implementation Tricks and Monotonicity Constraint in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v18 [cs.LG] UPDATED)
63. A Survey of Embodied AI: From Simulators to Research Tasks. (arXiv:2103.04918v7 [cs.AI] UPDATED)
64. One Model to Rule them All: Towards Zero-Shot Learning for Databases. (arXiv:2105.00642v4 [cs.DB] UPDATED)
65. Latent Gaussian Model Boosting. (arXiv:2105.08966v3 [cs.LG] UPDATED)
66. A Novel lightweight Convolutional Neural Network, ExquisiteNetV2. (arXiv:2105.09008v4 [cs.CV] UPDATED)
67. D2CFR: Minimize Counterfactual Regret with Deep Dueling Neural Network. (arXiv:2105.12328v2 [cs.AI] UPDATED)
68. Game of GANs: Game-Theoretical Models for Generative Adversarial Networks. (arXiv:2106.06976v3 [cs.LG] UPDATED)
69. A Near-Optimal Algorithm for Debiasing Trained Machine Learning Models. (arXiv:2106.12887v2 [cs.LG] UPDATED)
70. Knowledge Graph Augmented Political Perspective Detection in News Media. (arXiv:2108.03861v3 [cs.CL] UPDATED)
71. Legislator Representation Learning with Social Context and Expert Knowledge. (arXiv:2108.03881v3 [cs.CL] UPDATED)
72. Attentive Knowledge-aware Graph Convolutional Networks with Collaborative Guidance for Personalized Recommendation. (arXiv:2109.02046v2 [cs.IR] UPDATED)
73. Towards Transferable Adversarial Attacks on Vision Transformers. (arXiv:2109.04176v3 [cs.CV] UPDATED)
74. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v3 [cs.LG] UPDATED)
75. A Survey of Generalisation in Deep Reinforcement Learning. (arXiv:2111.09794v3 [cs.LG] UPDATED)
76. Learning to acquire novel cognitive tasks with evolution, plasticity and meta-meta-learning. (arXiv:2112.08588v2 [cs.NE] UPDATED)
77. On Optimizing Interventions in Shared Autonomy. (arXiv:2112.09169v2 [cs.AI] UPDATED)
78. Estimating Causal Effects of Multi-Aspect Online Reviews with Multi-Modal Proxies. (arXiv:2112.10274v2 [cs.LG] UPDATED)
79. HarmoFL: Harmonizing Local and Global Drifts in Federated Learning on Heterogeneous Medical Images. (arXiv:2112.10775v2 [eess.IV] UPDATED)
80. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v2 [cs.CR] UPDATED)
81. Social Neuro AI: Social Interaction as the "dark matter" of AI. (arXiv:2112.15459v2 [cs.MA] UPDATED)
82. DDPG car-following model with real-world human driving experience in CARLA. (arXiv:2112.14602v1 [cs.RO] CROSS LISTED)
