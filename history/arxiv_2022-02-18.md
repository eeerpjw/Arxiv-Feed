# Your interest papers
---
## cs.CV
---
### Domain Adaptation for Underwater Image **Enhancement** via Content and Style Separation. (arXiv:2202.08537v1 [cs.CV])
- Authors : Wei Chen, Chang Pei
- Link : [http://arxiv.org/abs/2202.08537](http://arxiv.org/abs/2202.08537)
> ABSTRACT  :  Underwater image suffer from color cast, low contrast and hazy effect due to light absorption, refraction and scattering, which degraded the high-level application, e.g, object detection and object tracking. Recent learning-based methods demonstrate astonishing performance on underwater image **enhancement**, however, most of these works use synthesis pair data for supervised learning and ignore the domain gap to real-world data. In this paper, we propose a domain adaptation framework for underwater image **enhancement** via content and style separation, we assume image could be disentangled to content and style latent, and image could be clustered to the sub-domain of associated style in latent space, the goal is to build up the mapping between underwater style latent and clean one. Different from prior works of domain adaptation for underwater image **enhancement**, which target to minimize the latent discrepancy of synthesis and real-world data, we aim to distinguish style latent from different sub-domains. To solve the problem of lacking pair real-world data, we leverage synthesis to real image-to-image translation to obtain pseudo real underwater image pairs for supervised learning, and **enhancement** can be achieved by input content and clean style latent into generator. Our model provide a user interact interface to adjust different enhanced level by latent manipulation. Experiment on various public real-world underwater benchmarks demonstrate that the proposed framework is capable to perform domain adaptation for underwater image **enhancement** and outperform various state-of-the-art underwater image **enhancement** algorithms in quantity and quality. The model and source code are available at https://github.com/fordevoted/UIESS  
### Fourier PlenOctrees for Dynamic Radiance Field Rendering in **Real-time**. (arXiv:2202.08614v1 [cs.CV])
- Authors : Liao Wang, Jiakai Zhang, Xinhang Liu, Fuqiang Zhao, Yanshun Zhang, Yingliang Zhang, Minye Wu, Lan Xu, Jingyi Yu
- Link : [http://arxiv.org/abs/2202.08614](http://arxiv.org/abs/2202.08614)
> ABSTRACT  :  Implicit neural representations such as Neural Radiance Field (NeRF) have focused mainly on modeling static objects captured under multi-view settings where real-time rendering can be achieved with smart data structures, e.g., PlenOctree. In this paper, we present a novel Fourier PlenOctree (FPO) technique to tackle efficient neural modeling and real-time rendering of dynamic scenes captured under the free-view video (FVV) setting. The key idea in our FPO is a novel combination of generalized NeRF, PlenOctree representation, volumetric fusion and Fourier transform. To accelerate FPO construction, we present a novel coarse-to-fine fusion scheme that leverages the generalizable NeRF technique to generate the tree via spatial blending. To tackle dynamic scenes, we tailor the implicit network to model the Fourier coefficients of timevarying density and color attributes. Finally, we construct the FPO and train the Fourier coefficients directly on the leaves of a union PlenOctree structure of the dynamic sequence. We show that the resulting FPO enables compact memory overload to handle dynamic objects and supports efficient fine-tuning. Extensive experiments show that the proposed method is 3000 times faster than the original NeRF and achieves over an order of magnitude acceleration over SOTA while preserving high visual quality for the free-viewpoint rendering of unseen dynamic scenes.  
### A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v1 [cs.CV])
- Authors : Ziyin Ma, Changjae Oh
- Link : [http://arxiv.org/abs/2202.08758](http://arxiv.org/abs/2202.08758)
> ABSTRACT  :  We present a wavelet-based dual-stream network that addresses color cast and blurry details in underwater images. We handle these artifacts separately by decomposing an input image into multiple frequency bands using discrete wavelet transform, which generates the downsampled structure image and detail images. These sub-band images are used as input to our dual-stream network that incorporates two sub-networks: the multi-color space fusion network and the detail **enhancement** network. The multi-color space fusion network takes the decomposed structure image as input and estimates the color corrected output by employing the feature representations from diverse color spaces of the input. The detail **enhancement** network addresses the blurriness of the original underwater image by improving the image details from high-frequency sub-bands. We validate the proposed method on both real-world and synthetic underwater datasets and show the effectiveness of our model in color correction and blur removal with low computational complexity.  
### Distilling a Powerful Student Model via Online Knowledge Distillation. (arXiv:2103.14473v3 [cs.CV] UPDATED)
- Authors : Shaojie Li, Mingbao Lin, Yan Wang, Yongjian Wu, Yonghong Tian, Ling Shao, Rongrong Ji
- Link : [http://arxiv.org/abs/2103.14473](http://arxiv.org/abs/2103.14473)
> ABSTRACT  :  Existing online knowledge distillation approaches either adopt the student with the best performance or construct an ensemble model for better holistic performance. However, the former strategy ignores other students' information, while the latter increases the computational complexity during deployment. In this paper, we propose a novel method for online knowledge distillation, termed FFSD, which comprises two key components: Feature Fusion and Self-Distillation, towards solving the above problems in a unified framework. Different from previous works, where all students are treated equally, the proposed FFSD splits them into a leader student and a common student set. Then, the feature fusion module converts the concatenation of feature maps from all common students into a fused feature map. The fused representation is used to assist the learning of the leader student. To enable the leader student to absorb more diverse information, we design an **enhancement** strategy to increase the diversity among students. Besides, a self-distillation module is adopted to convert the feature map of deeper layers into a shallower one. Then, the shallower layers are encouraged to mimic the transformed feature maps of the deeper layers, which helps the students to generalize better. After training, we simply adopt the leader student, which achieves superior performance, over the common students, without increasing the storage or inference cost. Extensive experiments on CIFAR-100 and ImageNet demonstrate the superiority of our FFSD over existing works. The code is available at https://github.com/SJLeo/FFSD.  
## eess.IV
---
### A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v1 [cs.CV])
- Authors : Ziyin Ma, Changjae Oh
- Link : [http://arxiv.org/abs/2202.08758](http://arxiv.org/abs/2202.08758)
> ABSTRACT  :  We present a wavelet-based dual-stream network that addresses color cast and blurry details in underwater images. We handle these artifacts separately by decomposing an input image into multiple frequency bands using discrete wavelet transform, which generates the downsampled structure image and detail images. These sub-band images are used as input to our dual-stream network that incorporates two sub-networks: the multi-color space fusion network and the detail **enhancement** network. The multi-color space fusion network takes the decomposed structure image as input and estimates the color corrected output by employing the feature representations from diverse color spaces of the input. The detail **enhancement** network addresses the blurriness of the original underwater image by improving the image details from high-frequency sub-bands. We validate the proposed method on both real-world and synthetic underwater datasets and show the effectiveness of our model in color correction and blur removal with low computational complexity.  
## cs.LG
---
### Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition. (arXiv:2202.08532v1 [eess.AS])
- Authors : Han Huck, Zeeshan Ahmed, Yile Gu, Joseph Szurley, Roger Ren, Linda Liu, Andreas Stolcke, Ivan Bulyko
- Link : [http://arxiv.org/abs/2202.08532](http://arxiv.org/abs/2202.08532)
> ABSTRACT  :  In this work, we aim to enhance the system robustness of end-to-end automatic speech recognition (ASR) against adversarially-noisy speech examples. We focus on a rigorous and empirical "closed-model adversarial robustness" setting (e.g., on-device or cloud applications). The adversarial noise is only generated by closed-model optimization (e.g., evolutionary and zeroth-order estimation) without accessing gradient information of a targeted ASR model directly. We propose an advanced Bayesian neural network (BNN) based adversarial detector, which could model latent distributions against adaptive adversarial perturbation with divergence measurement. We further simulate deployment scenarios of RNN Transducer, Conformer, and wav2vec-2.0 based ASR systems with the proposed adversarial detection system. Leveraging the proposed BNN based detection system, we improve detection rate by +2.77 to +5.42% (relative +3.03 to +6.26%) and reduce the word error rate by 5.02 to 7.47% on LibriSpeech datasets compared to the current model **enhancement** methods against the adversarial speech examples.  
### Winograd Convolution: A Perspective from Fault Tolerance. (arXiv:2202.08675v1 [cs.LG])
- Authors : Xinghua Xue, Haitong Huang, Cheng Liu, Ying Wang, Tao Luo, **Lei Zhang**
- Link : [http://arxiv.org/abs/2202.08675](http://arxiv.org/abs/2202.08675)
> ABSTRACT  :  Winograd convolution is originally proposed to reduce the computing overhead by converting multiplication in neural network (NN) with addition via linear transformation. Other than the computing efficiency, we observe its great potential in improving NN fault tolerance and evaluate its fault tolerance comprehensively for the first time. Then, we explore the use of fault tolerance of winograd convolution for either fault-tolerant or energy-efficient NN processing. According to our experiments, winograd convolution can be utilized to reduce fault-tolerant design overhead by 27.49\% or energy consumption by 7.19\% without any accuracy loss compared to that without being aware of the fault tolerance  
## cs.AI
---
### Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition. (arXiv:2202.08532v1 [eess.AS])
- Authors : Han Huck, Zeeshan Ahmed, Yile Gu, Joseph Szurley, Roger Ren, Linda Liu, Andreas Stolcke, Ivan Bulyko
- Link : [http://arxiv.org/abs/2202.08532](http://arxiv.org/abs/2202.08532)
> ABSTRACT  :  In this work, we aim to enhance the system robustness of end-to-end automatic speech recognition (ASR) against adversarially-noisy speech examples. We focus on a rigorous and empirical "closed-model adversarial robustness" setting (e.g., on-device or cloud applications). The adversarial noise is only generated by closed-model optimization (e.g., evolutionary and zeroth-order estimation) without accessing gradient information of a targeted ASR model directly. We propose an advanced Bayesian neural network (BNN) based adversarial detector, which could model latent distributions against adaptive adversarial perturbation with divergence measurement. We further simulate deployment scenarios of RNN Transducer, Conformer, and wav2vec-2.0 based ASR systems with the proposed adversarial detection system. Leveraging the proposed BNN based detection system, we improve detection rate by +2.77 to +5.42% (relative +3.03 to +6.26%) and reduce the word error rate by 5.02 to 7.47% on LibriSpeech datasets compared to the current model **enhancement** methods against the adversarial speech examples.  
# Paper List
---
## cs.CV
---
**81** new papers in cs.CV:-) 
1. Evaluation and Analysis of Different Aggregation and Hyperparameter Selection Methods for Federated Brain Tumor Segmentation. (arXiv:2202.08261v1 [cs.LG])
2. Phase Aberration Robust Beamformer for Planewave US Using Self-Supervised Learning. (arXiv:2202.08262v1 [eess.IV])
3. OpenKBP-Opt: An international and reproducible evaluation of 76 knowledge-based planning pipelines. (arXiv:2202.08303v1 [physics.med-ph])
4. Contextualize differential privacy in image database: a lightweight image differential privacy approach based on principle component analysis inverse. (arXiv:2202.08309v1 [cs.CR])
5. A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments. (arXiv:2202.08325v1 [cs.LG])
6. CortexODE: Learning Cortical Surface Reconstruction by Neural ODEs. (arXiv:2202.08329v1 [eess.IV])
7. A Developmentally-Inspired Examination of Shape versus Texture Bias in Machines. (arXiv:2202.08340v1 [cs.CV])
8. Anomalib: A Deep Learning Library for Anomaly Detection. (arXiv:2202.08341v1 [cs.CV])
9. Learning Smooth Neural Functions via Lipschitz Regularization. (arXiv:2202.08345v1 [cs.CV])
10. Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision. (arXiv:2202.08360v1 [cs.CV])
11. Fuzzy Pooling. (arXiv:2202.08372v1 [cs.LG])
12. How to Fill the Optimum Set? Population Gradient Descent with Harmless Diversity. (arXiv:2202.08376v1 [cs.LG])
13. Limitations of Neural Collapse for Understanding Generalization in Deep Learning. (arXiv:2202.08384v1 [cs.LG])
14. Shift-Memory Network for Temporal Scene Segmentation. (arXiv:2202.08399v1 [cs.CV])
15. FPIC: A Novel Semantic Dataset for Optical PCB Assurance. (arXiv:2202.08414v1 [cs.CV])
16. Neural Marionette: Unsupervised Learning of Motion Skeleton and Latent Dynamics from Volumetric Video. (arXiv:2202.08418v1 [cs.CV])
17. AKB-48: A Real-World Articulated Object Knowledge Base. (arXiv:2202.08432v1 [cs.CV])
18. PENCIL: Deep Learning with Noisy Labels. (arXiv:2202.08436v1 [cs.CV])
19. Visual attention analysis of pathologists examining whole slide images of Prostate cancer. (arXiv:2202.08437v1 [eess.IV])
20. V2X-Sim: A Virtual Collaborative Perception Dataset for Autonomous Driving. (arXiv:2202.08449v1 [cs.CV])
21. PCB Component Detection using Computer Vision for Hardware Assurance. (arXiv:2202.08452v1 [cs.CV])
22. TraSeTR: Track-to-Segment Transformer with Contrastive Query for Instance-level Instrument Segmentation in Robotic Surgery. (arXiv:2202.08453v1 [cs.CV])
23. TransCG: A Large-Scale Real-World Dataset for Transparent Object Depth Completion and Grasping. (arXiv:2202.08471v1 [cs.RO])
24. Dynamic Object Comprehension: A Framework For Evaluating Artificial Visual Perception. (arXiv:2202.08490v1 [cs.CV])
25. Feels Bad Man: Dissecting Automated Hateful Meme Detection Through the Lens of Facebook's Challenge. (arXiv:2202.08492v1 [cs.CY])
26. Mirror-Yolo: An attention-based instance segmentation and detection model for mirrors. (arXiv:2202.08498v1 [cs.CV])
27. CLS: Cross Labeling Supervision for Semi-Supervised Learning. (arXiv:2202.08502v1 [cs.CV])
28. CSCNet: Contextual Semantic Consistency Network for Trajectory Prediction in Crowded Spaces. (arXiv:2202.08506v1 [cs.CV])
29. A Study of Designing Compact Audio-Visual Wake Word Spotting System Based on Iterative Fine-Tuning in Neural Network Pruning. (arXiv:2202.08509v1 [cs.SD])
30. A hybrid 2-stage vision transformer for AI-assisted 5 class pathologic diagnosis of gastric endoscopic biopsies. (arXiv:2202.08510v1 [eess.IV])
31. Visual Ground Truth Construction as Faceted Classification. (arXiv:2202.08512v1 [cs.CV])
32. Survey on Self-supervised Representation Learning Using Image Transformations. (arXiv:2202.08514v1 [cs.CV])
33. TAFNet: A Three-Stream Adaptive Fusion Network for RGB-T Crowd Counting. (arXiv:2202.08517v1 [cs.CV])
34. Point Cloud Generation with Continuous Conditioning. (arXiv:2202.08526v1 [cs.CV])
35. Domain Adaptation for Underwater Image **Enhancement** via Content and Style Separation. (arXiv:2202.08537v1 [cs.CV])
36. An overview of deep learning in medical imaging. (arXiv:2202.08546v1 [eess.IV])
37. EBHI:A New Enteroscope Biopsy Histopathological H&E Image Dataset for Image Classification Evaluation. (arXiv:2202.08552v1 [eess.IV])
38. 3D-Aware Indoor Scene Synthesis with Depth Priors. (arXiv:2202.08553v1 [cs.CV])
39. CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving. (arXiv:2202.08557v1 [cs.CV])
40. Anatomically Parameterized Statistical Shape Model: Explaining Morphometry through Statistical Learning. (arXiv:2202.08580v1 [eess.IV])
41. Point cloud completion on structured feature map with feedback network. (arXiv:2202.08583v1 [cs.CV])
42. Single UHD Image Dehazing via Interpretable Pyramid Network. (arXiv:2202.08589v1 [cs.CV])
43. Two-Stage Architectural Fine-Tuning with Neural Architecture Search using Early-Stopping in Image Classification. (arXiv:2202.08604v1 [cs.CV])
44. Fourier PlenOctrees for Dynamic Radiance Field Rendering in **Real-time**. (arXiv:2202.08614v1 [cs.CV])
45. Semantically Proportional Patchmix for Few-Shot Learning. (arXiv:2202.08647v1 [cs.CV])
46. Domain Randomization for Object Counting. (arXiv:2202.08670v1 [cs.CV])
47. Synthetic data for unsupervised polyp segmentation. (arXiv:2202.08680v1 [eess.IV])
48. End-to-end Neuron Instance Segmentation based on Weakly Supervised Efficient UNet and Morphological Post-processing. (arXiv:2202.08682v1 [eess.IV])
49. A study of deep perceptual metrics for image quality assessment. (arXiv:2202.08692v1 [cs.CV])
50. Detecting and Learning the Unknown in Semantic Segmentation. (arXiv:2202.08700v1 [cs.CV])
51. Level set based particle filter driven by optical flow: an application to track the salt boundary from X-ray CT time-series. (arXiv:2202.08717v1 [cs.CV])
52. Colonoscopy polyp detection with massive endoscopic images. (arXiv:2202.08730v1 [cs.CV])
53. OmniSyn: Synthesizing 360 Videos with Wide-baseline Panoramas. (arXiv:2202.08752v1 [cs.CV])
54. A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v1 [cs.CV])
55. Realistic Blur Synthesis for Learning Image Deblurring. (arXiv:2202.08771v1 [cs.CV])
56. Grammar-Based Grounded Lexicon Learning. (arXiv:2202.08806v1 [cs.CL])
57. General Cyclical Training of Neural Networks. (arXiv:2202.08835v1 [cs.LG])
58. Adiabatic Quantum Computing for Multi Object Tracking. (arXiv:2202.08837v1 [cs.CV])
59. MRI Reconstruction Using Deep Bayesian Estimation. (arXiv:1909.01127v3 [cs.CV] UPDATED)
60. Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v3 [cs.CV] UPDATED)
61. Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation Learning. (arXiv:2003.05438v5 [cs.CV] UPDATED)
62. Wisdom of Committees: An Overlooked Approach To Faster and More Accurate Models. (arXiv:2012.01988v6 [cs.CV] UPDATED)
63. Single-path Bit Sharing for Automatic Loss-aware Model Compression. (arXiv:2101.04935v3 [cs.CV] UPDATED)
64. Generative Models as Distributions of Functions. (arXiv:2102.04776v4 [cs.LG] UPDATED)
65. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v3 [cs.CV] UPDATED)
66. Learning Versatile Neural Architectures by Propagating Network Codes. (arXiv:2103.13253v2 [cs.CV] UPDATED)
67. Distilling a Powerful Student Model via Online Knowledge Distillation. (arXiv:2103.14473v3 [cs.CV] UPDATED)
68. GasHis-Transformer: A Multi-scale Visual Transformer Approach for Gastric Histopathology Image Classification. (arXiv:2104.14528v6 [cs.CV] UPDATED)
69. Preservation of Global Knowledge by Not-True Distillation in Federated Learning. (arXiv:2106.03097v3 [cs.LG] UPDATED)
70. LoGG3D-Net: Locally Guided Global Descriptor Learning for 3D Place Recognition. (arXiv:2109.08336v3 [cs.CV] UPDATED)
71. Nested Multiple Instance Learning with Attention Mechanisms. (arXiv:2111.00947v3 [cs.LG] UPDATED)
72. Optimizing Latent Space Directions For GAN-based Local Image Editing. (arXiv:2111.12583v2 [cs.CV] UPDATED)
73. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v2 [eess.IV] UPDATED)
74. Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and Neck Tumor Segmentation and Outcome Prediction in PET/CT Images. (arXiv:2201.04138v2 [eess.IV] UPDATED)
75. Low-rank features based double transformation matrices learning for image classification. (arXiv:2201.12351v2 [cs.LG] UPDATED)
76. Signing the Supermask: Keep, Hide, Invert. (arXiv:2201.13361v2 [cs.LG] UPDATED)
77. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v2 [cs.CV] UPDATED)
78. Box Supervised Video Segmentation Proposal Network. (arXiv:2202.07025v2 [cs.CV] UPDATED)
79. Beyond Natural Motion: Exploring Discontinuity for Video Frame Interpolation. (arXiv:2202.07291v2 [cs.CV] UPDATED)
80. A Survey of Semen Quality Evaluation in Microscopic Videos Using Computer Assisted Sperm Analysis. (arXiv:2202.07820v2 [eess.IV] UPDATED)
81. A multi-reconstruction study of breast density estimation using Deep Learning. (arXiv:2202.08238v2 [eess.IV] UPDATED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. Low-Rank Phase Retrieval with Structured Tensor Models. (arXiv:2202.08260v1 [eess.IV])
2. Evaluation and Analysis of Different Aggregation and Hyperparameter Selection Methods for Federated Brain Tumor Segmentation. (arXiv:2202.08261v1 [cs.LG])
3. Phase Aberration Robust Beamformer for Planewave US Using Self-Supervised Learning. (arXiv:2202.08262v1 [eess.IV])
4. Contextualize differential privacy in image database: a lightweight image differential privacy approach based on principle component analysis inverse. (arXiv:2202.08309v1 [cs.CR])
5. CortexODE: Learning Cortical Surface Reconstruction by Neural ODEs. (arXiv:2202.08329v1 [eess.IV])
6. FPIC: A Novel Semantic Dataset for Optical PCB Assurance. (arXiv:2202.08414v1 [cs.CV])
7. Visual attention analysis of pathologists examining whole slide images of Prostate cancer. (arXiv:2202.08437v1 [eess.IV])
8. A hybrid 2-stage vision transformer for AI-assisted 5 class pathologic diagnosis of gastric endoscopic biopsies. (arXiv:2202.08510v1 [eess.IV])
9. An overview of deep learning in medical imaging. (arXiv:2202.08546v1 [eess.IV])
10. EBHI:A New Enteroscope Biopsy Histopathological H&E Image Dataset for Image Classification Evaluation. (arXiv:2202.08552v1 [eess.IV])
11. Anatomically Parameterized Statistical Shape Model: Explaining Morphometry through Statistical Learning. (arXiv:2202.08580v1 [eess.IV])
12. Deep VQA based on a Novel Hybrid Training Methodology. (arXiv:2202.08595v1 [eess.IV])
13. Accelerated iterative tomographic reconstruction with x-ray edge illumination. (arXiv:2202.08627v1 [eess.IV])
14. Synthetic data for unsupervised polyp segmentation. (arXiv:2202.08680v1 [eess.IV])
15. End-to-end Neuron Instance Segmentation based on Weakly Supervised Efficient UNet and Morphological Post-processing. (arXiv:2202.08682v1 [eess.IV])
16. Level set based particle filter driven by optical flow: an application to track the salt boundary from X-ray CT time-series. (arXiv:2202.08717v1 [cs.CV])
17. A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v1 [cs.CV])
18. Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation Learning. (arXiv:2003.05438v5 [cs.CV] UPDATED)
19. Towards Low-Photon Nanoscale Imaging: Holographic Phase Retrieval via Maximum Likelihood Optimization. (arXiv:2105.11512v2 [eess.IV] UPDATED)
20. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v2 [eess.IV] UPDATED)
21. Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and Neck Tumor Segmentation and Outcome Prediction in PET/CT Images. (arXiv:2201.04138v2 [eess.IV] UPDATED)
22. A hypothesis-driven method based on machine learning for neuroimaging data analysis. (arXiv:2202.04397v2 [stat.ML] UPDATED)
23. A Survey of Semen Quality Evaluation in Microscopic Videos Using Computer Assisted Sperm Analysis. (arXiv:2202.07820v2 [eess.IV] UPDATED)
24. A multi-reconstruction study of breast density estimation using Deep Learning. (arXiv:2202.08238v2 [eess.IV] UPDATED)
## cs.LG
---
**186** new papers in cs.LG:-) 
1. Low-Rank Phase Retrieval with Structured Tensor Models. (arXiv:2202.08260v1 [eess.IV])
2. Evaluation and Analysis of Different Aggregation and Hyperparameter Selection Methods for Federated Brain Tumor Segmentation. (arXiv:2202.08261v1 [cs.LG])
3. Phase Aberration Robust Beamformer for Planewave US Using Self-Supervised Learning. (arXiv:2202.08262v1 [eess.IV])
4. XAI in the context of Predictive Process Monitoring: Too much to Reveal. (arXiv:2202.08265v1 [cs.LG])
5. Open-Ended Reinforcement Learning with Neural Reward Functions. (arXiv:2202.08266v1 [cs.LG])
6. More to Less (M2L): Enhanced Health Recognition in the Wild with Reduced Modality of Wearable Sensors. (arXiv:2202.08267v1 [cs.LG])
7. Controlling Epidemic Spread using Probabilistic Diffusion Models on Networks. (arXiv:2202.08296v1 [cs.DS])
8. The learning phases in NN: From Fitting the Majority to Fitting a Few. (arXiv:2202.08299v1 [cs.LG])
9. Efficient Distributed Machine Learning via Combinatorial Multi-Armed Bandits. (arXiv:2202.08302v1 [cs.IT])
10. Towards Verifiable Federated Learning. (arXiv:2202.08310v1 [cs.CR])
11. Single Trajectory Nonparametric Learning of Nonlinear Dynamics. (arXiv:2202.08311v1 [cs.LG])
12. Private Online Prefix Sums via Optimal Matrix Factorizations. (arXiv:2202.08312v1 [cs.LG])
13. TorchDrug: A Powerful and Flexible Machine Learning Platform for Drug Discovery. (arXiv:2202.08320v1 [cs.LG])
14. A Data-Augmentation Is Worth A Thousand Samples: Exact Quantification From Analytical Augmented Sample Moments. (arXiv:2202.08325v1 [cs.LG])
15. Self-Supervised Representation Learning via Latent Graph Prediction. (arXiv:2202.08333v1 [cs.LG])
16. Task-Agnostic Graph Explanations. (arXiv:2202.08335v1 [cs.LG])
17. Single-shot Hyper-parameter Optimization for Federated Learning: A General Algorithm & Analysis. (arXiv:2202.08338v1 [cs.LG])
18. A Developmentally-Inspired Examination of Shape versus Texture Bias in Machines. (arXiv:2202.08340v1 [cs.CV])
19. Anomalib: A Deep Learning Library for Anomaly Detection. (arXiv:2202.08341v1 [cs.CV])
20. Learning Transferrable Representations of Career Trajectories for Economic Prediction. (arXiv:2202.08370v1 [cs.LG])
21. The Quarks of Attention. (arXiv:2202.08371v1 [cs.LG])
22. Fuzzy Pooling. (arXiv:2202.08372v1 [cs.LG])
23. Text-Based Action-Model Acquisition for Planning. (arXiv:2202.08373v1 [cs.LG])
24. How to Fill the Optimum Set? Population Gradient Descent with Harmless Diversity. (arXiv:2202.08376v1 [cs.LG])
25. Limitations of Neural Collapse for Understanding Generalization in Deep Learning. (arXiv:2202.08384v1 [cs.LG])
26. Generalizable Information Theoretic Causal Representation. (arXiv:2202.08388v1 [cs.LG])
27. Graph Masked Autoencoder. (arXiv:2202.08391v1 [cs.LG])
28. Robust Reinforcement Learning via Genetic Curriculum. (arXiv:2202.08393v1 [cs.LG])
29. SWIM: Selective Write-Verify for Computing-in-Memory Neural Accelerators. (arXiv:2202.08395v1 [cs.LG])
30. Augment with Care: Contrastive Learning for the Boolean Satisfiability Problem. (arXiv:2202.08396v1 [cs.LG])
31. Federated Stochastic Gradient Descent Begets Self-Induced Momentum. (arXiv:2202.08402v1 [cs.LG])
32. AutoScore-Ordinal: An interpretable machine learning framework for generating scoring models for ordinal outcomes. (arXiv:2202.08407v1 [cs.LG])
33. Multivariate Time Series Forecasting with Dynamic Graph Neural ODEs. (arXiv:2202.08408v1 [cs.LG])
34. Entropic Associative Memory for Manuscript Symbols. (arXiv:2202.08413v1 [cs.LG])
35. Retrieval-Augmented Reinforcement Learning. (arXiv:2202.08417v1 [cs.LG])
36. Time-Correlated Sparsification for Efficient Over-the-Air Model Aggregation in Wireless Federated Learning. (arXiv:2202.08420v1 [cs.IT])
37. Synthetic Control As Online Linear Regression. (arXiv:2202.08426v1 [econ.EM])
38. ADD 2022: the First Audio Deep Synthesis Detection Challenge. (arXiv:2202.08433v1 [cs.SD])
39. A Survey of Explainable Reinforcement Learning. (arXiv:2202.08434v1 [cs.LG])
40. A Survey on Deep Reinforcement Learning-based Approaches for Adaptation and Generalization. (arXiv:2202.08444v1 [cs.LG])
41. Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization. (arXiv:2202.08450v1 [cs.LG])
42. Transformer for Graphs: An Overview from Architecture Perspective. (arXiv:2202.08455v1 [cs.LG])
43. MLP-ASR: Sequence-length agnostic all-MLP architectures for speech recognition. (arXiv:2202.08456v1 [eess.AS])
44. End-to-End Training of Both Translation Models in the Back-Translation Framework. (arXiv:2202.08465v1 [cs.CL])
45. Full-Span Log-Linear Model and Fast Learning Algorithm. (arXiv:2202.08472v1 [cs.LG])
46. Structural and Semantic Contrastive Learning for Self-supervised Node Representation Learning. (arXiv:2202.08480v1 [cs.LG])
47. Multi-Objective Model Selection for Time Series Forecasting. (arXiv:2202.08485v1 [cs.LG])
48. Dynamic Object Comprehension: A Framework For Evaluating Artificial Visual Perception. (arXiv:2202.08490v1 [cs.CV])
49. Learning continuous models for continuous physics. (arXiv:2202.08494v1 [cs.LG])
50. A Study of Designing Compact Audio-Visual Wake Word Spotting System Based on Iterative Fine-Tuning in Neural Network Pruning. (arXiv:2202.08509v1 [cs.SD])
51. A hybrid 2-stage vision transformer for AI-assisted 5 class pathologic diagnosis of gastric endoscopic biopsies. (arXiv:2202.08510v1 [eess.IV])
52. Survey on Self-supervised Representation Learning Using Image Transformations. (arXiv:2202.08514v1 [cs.CV])
53. SAITS: Self-Attention-based Imputation for Time Series. (arXiv:2202.08516v1 [cs.LG])
54. DeepHybrid: Deep Learning on Automotive Radar Spectra and Reflections for Object Classification. (arXiv:2202.08519v1 [cs.LG])
55. End-to-end Music Remastering System Using Self-supervised and Adversarial Training. (arXiv:2202.08520v1 [eess.AS])
56. Recovering Unbalanced Communities in the Stochastic Block Model With Application to Clustering with a Faulty Oracle. (arXiv:2202.08522v1 [cs.LG])
57. Contrastive Meta Learning with Behavior Multiplicity for Recommendation. (arXiv:2202.08523v1 [cs.IR])
58. A Collection and Categorization of Open-Source Wind and Wind Power Datasets. (arXiv:2202.08524v1 [cs.LG])
59. Point Cloud Generation with Continuous Conditioning. (arXiv:2202.08526v1 [cs.CV])
60. Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition. (arXiv:2202.08532v1 [eess.AS])
61. Does the End Justify the Means? On the Moral Justification of Fairness-Aware Machine Learning. (arXiv:2202.08536v1 [cs.LG])
62. When, where, and how to add new neurons to ANNs. (arXiv:2202.08539v1 [cs.LG])
63. Information Theory with Kernel Methods. (arXiv:2202.08545v1 [cs.IT])
64. Oracle-Efficient Online Learning for Beyond Worst-Case Adversaries. (arXiv:2202.08549v1 [cs.LG])
65. Delay-adaptive step-sizes for asynchronous learning. (arXiv:2202.08550v1 [cs.LG])
66. Efficient and Reliable Probabilistic Interactive Learning with Structured Outputs. (arXiv:2202.08566v1 [cs.LG])
67. Robust SVM Optimization in Banach spaces. (arXiv:2202.08567v1 [stat.ML])
68. An Equivalence Between Data Poisoning and Byzantine Gradient Attacks. (arXiv:2202.08578v1 [cs.LG])
69. Gradients without Backpropagation. (arXiv:2202.08587v1 [cs.LG])
70. CoFED: Cross-silo Heterogeneous Federated Multi-task Learning via Co-training. (arXiv:2202.08603v1 [cs.LG])
71. On the evaluation of (meta-)solver approaches. (arXiv:2202.08613v1 [cs.AI])
72. Revisiting Over-smoothing in BERT from the Perspective of Graph. (arXiv:2202.08625v1 [cs.LG])
73. The merged-staircase property: a necessary and nearly sufficient condition for SGD learning of sparse functions on two-layer neural networks. (arXiv:2202.08658v1 [cs.LG])
74. Measuring Trustworthiness or Automating Physiognomy? A Comment on Safra, Chevallier, Gr\`ezes, and Baumard (2020). (arXiv:2202.08674v1 [cs.LG])
75. Winograd Convolution: A Perspective from Fault Tolerance. (arXiv:2202.08675v1 [cs.LG])
76. Where Is My Training Bottleneck? Hidden Trade-Offs in Deep Learning Preprocessing Pipelines. (arXiv:2202.08679v1 [cs.LG])
77. Detecting and Learning the Unknown in Semantic Segmentation. (arXiv:2202.08700v1 [cs.CV])
78. Learning stochastic dynamics and predicting emergent behavior using transformers. (arXiv:2202.08708v1 [cond-mat.stat-mech])
79. Improving Rating and Relevance with Point-of-Interest Recommender System. (arXiv:2202.08751v1 [cs.IR])
80. Ensemble Conformalized Quantile Regression for Probabilistic Time Series Forecasting. (arXiv:2202.08756v1 [cs.LG])
81. Global Convergence of Sub-gradient Method for Robust Matrix Recovery: Small Initialization, Noisy Measurements, and Over-parameterization. (arXiv:2202.08788v1 [cs.LG])
82. Hamilton-Jacobi equations on graphs with applications to semi-supervised learning and data depth. (arXiv:2202.08789v1 [math.AP])
83. Grammar-Based Grounded Lexicon Learning. (arXiv:2202.08806v1 [cs.CL])
84. Should I send this notification? Optimizing push notifications decision making by modeling the future. (arXiv:2202.08812v1 [cs.IR])
85. GRAPHSHAP: Motif-based Explanations for Black-box Graph Classifiers. (arXiv:2202.08815v1 [cs.LG])
86. Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning. (arXiv:2202.08816v1 [cs.IR])
87. Human-Algorithm Collaboration: Achieving Complementarity and Avoiding Unfairness. (arXiv:2202.08821v1 [cs.CY])
88. Multi-stage Ensemble Model for Cross-market Recommendation. (arXiv:2202.08824v1 [cs.IR])
89. LAMP: Extracting Text from Gradients with Language Model Priors. (arXiv:2202.08827v1 [cs.LG])
90. Universality of empirical risk minimization. (arXiv:2202.08832v1 [math.ST])
91. The Exact Class of Graph Functions Generated by Graph Neural Networks. (arXiv:2202.08833v1 [cs.LG])
92. General Cyclical Training of Neural Networks. (arXiv:2202.08835v1 [cs.LG])
93. Data-SUITE: Data-centric identification of in-distribution incongruous examples. (arXiv:2202.08836v1 [cs.LG])
94. Adiabatic Quantum Computing for Multi Object Tracking. (arXiv:2202.08837v1 [cs.CV])
95. The Supermarket Model with Known and Predicted Service Times. (arXiv:1905.12155v4 [cs.PF] UPDATED)
96. Characterizing Attacks on Deep Reinforcement Learning. (arXiv:1907.09470v3 [cs.LG] UPDATED)
97. Drawing Early-Bird Tickets: Towards More Efficient Training of Deep Networks. (arXiv:1909.11957v5 [cs.LG] UPDATED)
98. FANN-on-MCU: An Open-Source Toolkit for Energy-Efficient Neural Network Inference at the Edge of the Internet of Things. (arXiv:1911.03314v3 [cs.LG] UPDATED)
99. Deep Feature Fusion for Mitosis Counting. (arXiv:2002.03781v3 [cs.CV] UPDATED)
100. Un-Mix: Rethinking Image Mixtures for Unsupervised Visual Representation Learning. (arXiv:2003.05438v5 [cs.CV] UPDATED)
101. SplitFed: When Federated Learning Meets Split Learning. (arXiv:2004.12088v5 [cs.LG] UPDATED)
102. Infant Crying Detection in Real-World Environments. (arXiv:2005.07036v6 [eess.AS] UPDATED)
103. Neural Loop Combiner: Neural Network Models for Assessing the Compatibility of Loops. (arXiv:2008.02011v2 [cs.SD] UPDATED)
104. Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers. (arXiv:2008.07303v6 [cs.GT] UPDATED)
105. Deep Surrogate Q-Learning for Autonomous Driving. (arXiv:2010.11278v2 [cs.LG] UPDATED)
106. Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v3 [cs.LG] UPDATED)
107. From Geometry to Topology: Inverse Theorems for Distributed Persistence. (arXiv:2101.12288v3 [math.AT] UPDATED)
108. Generative Models as Distributions of Functions. (arXiv:2102.04776v4 [cs.LG] UPDATED)
109. Domain Adaptation for Time Series Forecasting via Attention Sharing. (arXiv:2102.06828v5 [cs.LG] UPDATED)
110. Measuring the Transferability of $\ell_\infty$ Attacks by the $\ell_2$ Norm. (arXiv:2102.10343v3 [cs.LG] UPDATED)
111. Hierarchical Reinforcement Learning Framework for Stochastic Spaceflight Campaign Design. (arXiv:2103.08981v2 [cs.LG] UPDATED)
112. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v3 [cs.CV] UPDATED)
113. Data-driven Aerodynamic Analysis of Structures using Gaussian Processes. (arXiv:2103.13877v2 [physics.flu-dyn] UPDATED)
114. Improving Robustness of Deep Reinforcement Learning Agents: Environment Attack based on the Critic Network. (arXiv:2104.03154v2 [cs.LG] UPDATED)
115. Deep Time Series Forecasting with Shape and Temporal Criteria. (arXiv:2104.04610v2 [stat.ML] UPDATED)
116. Integration of Pre-trained Networks with Continuous Token Interface for End-to-End Spoken Language Understanding. (arXiv:2104.07253v2 [cs.CL] UPDATED)
117. Hyperspherically Regularized Networks for BYOL Improves Feature Uniformity and Separability. (arXiv:2105.00925v3 [cs.LG] UPDATED)
118. Robust Learning in Heterogeneous Contexts. (arXiv:2105.08532v3 [stat.ML] UPDATED)
119. An Exact Poly-Time Membership-Queries Algorithm for Extraction a three-Layer ReLU Network. (arXiv:2105.09673v2 [cs.LG] UPDATED)
120. Short-Term Stock Price-Trend Prediction Using Meta-Learning. (arXiv:2105.13599v2 [cs.LG] UPDATED)
121. Solving Schr\"odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v8 [stat.ML] UPDATED)
122. Preservation of Global Knowledge by Not-True Distillation in Federated Learning. (arXiv:2106.03097v3 [cs.LG] UPDATED)
123. Linear Convergence of Entropy-Regularized Natural Policy Gradient with Linear Function Approximation. (arXiv:2106.04096v3 [cs.LG] UPDATED)
124. Offline Preference-Based Apprenticeship Learning. (arXiv:2107.09251v3 [cs.LG] UPDATED)
125. SVSNet: An End-to-end Speaker Voice Similarity Assessment Model. (arXiv:2107.09392v2 [eess.AS] UPDATED)
126. Sequential Multivariate Change Detection with Calibrated and Memoryless False Detection Rates. (arXiv:2108.00883v2 [stat.ME] UPDATED)
127. Deep Reinforcement Learning Based Networked Control with Network Delays for Signal Temporal Logic Specifications. (arXiv:2108.01317v2 [eess.SY] UPDATED)
128. Accelerating Serverless Computing by Harvesting Idle Resources. (arXiv:2108.12717v2 [cs.DC] UPDATED)
129. ECQ$^{\text{x}}$: Explainability-Driven Quantization for Low-Bit and Sparse DNNs. (arXiv:2109.04236v2 [cs.LG] UPDATED)
130. Learning to be Fair: A Consequentialist Approach to Equitable Decision-Making. (arXiv:2109.08792v2 [cs.LG] UPDATED)
131. A Functional Operator for Model Uncertainty Quantification in the RKHS. (arXiv:2109.10888v5 [cs.LG] UPDATED)
132. Robust Generalization of Quadratic Neural Networks via Function Identification. (arXiv:2109.10935v3 [cs.LG] UPDATED)
133. Toward a Unified Framework for Debugging Concept-based Models. (arXiv:2109.11160v2 [cs.LG] UPDATED)
134. Variational Marginal Particle Filters. (arXiv:2109.15134v2 [stat.ML] UPDATED)
135. A manifold learning approach for gesture recognition from micro-Doppler radar measurements. (arXiv:2110.01670v2 [cs.LG] UPDATED)
136. The Mirrornet : Learning Audio Synthesizer Controls Inspired by Sensorimotor Interaction. (arXiv:2110.05695v3 [eess.AS] UPDATED)
137. Automatic DJ Transitions with Differentiable Audio Effects and Generative Adversarial Networks. (arXiv:2110.06525v2 [cs.SD] UPDATED)
138. Provable Regret Bounds for Deep Online Learning and Control. (arXiv:2110.07807v3 [cs.LG] UPDATED)
139. $k\texttt{-experts}$ -- Online Policies and Fundamental Limits. (arXiv:2110.07881v2 [cs.IT] UPDATED)
140. A Framework for Learning to Request Rich and Contextually Useful Information from Humans. (arXiv:2110.08258v3 [cs.LG] UPDATED)
141. Novel Features for Time Series Analysis: A Complex Networks Approach. (arXiv:2110.09888v3 [cs.SI] UPDATED)
142. Identifiable Deep Generative Models via Sparse Decoding. (arXiv:2110.10804v2 [stat.ML] UPDATED)
143. (Optimal) Online Bipartite Matching with Predicted Degrees. (arXiv:2110.11439v2 [cs.DS] UPDATED)
144. Causal Effect Identification with Context-specific Independence Relations of Control Variables. (arXiv:2110.12064v2 [cs.LG] UPDATED)
145. Towards Evaluating the Robustness of Neural Networks Learned by Transduction. (arXiv:2110.14735v2 [cs.LG] UPDATED)
146. Nested Multiple Instance Learning with Attention Mechanisms. (arXiv:2111.00947v3 [cs.LG] UPDATED)
147. DataWords: Getting Contrarian with Text, Structured Data and Explanations. (arXiv:2111.05384v2 [cs.LG] UPDATED)
148. Computing Graph Edit Distance with Algorithms on Quantum Devices. (arXiv:2111.10183v2 [quant-ph] UPDATED)
149. Optimizing Latent Space Directions For GAN-based Local Image Editing. (arXiv:2111.12583v2 [cs.CV] UPDATED)
150. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v2 [eess.IV] UPDATED)
151. Improving Experience Replay with Successor Representation. (arXiv:2111.14331v2 [cs.LG] UPDATED)
152. Environmental Sound Extraction Using Onomatopoeic Words. (arXiv:2112.00209v4 [cs.SD] UPDATED)
153. The Representation Jensen-R\'enyi Divergence. (arXiv:2112.01583v3 [cs.LG] UPDATED)
154. Learning music audio representations via weak language supervision. (arXiv:2112.04214v2 [cs.SD] UPDATED)
155. End-to-end Alexa Device Arbitration. (arXiv:2112.04914v2 [eess.AS] UPDATED)
156. Real-Time Neural Voice Camouflage. (arXiv:2112.07076v2 [cs.SD] UPDATED)
157. Modeling Strong and Human-Like Gameplay with KL-Regularized Search. (arXiv:2112.07544v2 [cs.MA] UPDATED)
158. Isometric MT: Neural Machine Translation for Automatic Dubbing. (arXiv:2112.08682v3 [cs.CL] UPDATED)
159. Sublinear Time Approximation of Text Similarity Matrices. (arXiv:2112.09631v2 [cs.LG] UPDATED)
160. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v2 [cs.LG] UPDATED)
161. Evolutionary Action Selection for Gradient-based Policy Learning. (arXiv:2201.04286v3 [cs.NE] UPDATED)
162. Analytic-DPM: an Analytic Estimate of the Optimal Reverse Variance in Diffusion Probabilistic Models. (arXiv:2201.06503v2 [cs.LG] UPDATED)
163. Distributed Bandits with Heterogeneous Agents. (arXiv:2201.09353v2 [cs.LG] UPDATED)
164. From Motion to Muscle. (arXiv:2201.11501v2 [cs.LG] UPDATED)
165. FedLite: A Scalable Approach for Federated Learning on Resource-constrained Clients. (arXiv:2201.11865v2 [cs.LG] UPDATED)
166. Fast Interpretable Greedy-Tree Sums (FIGS). (arXiv:2201.11931v2 [cs.LG] UPDATED)
167. Approximately Equivariant Networks for Imperfectly Symmetric Dynamics. (arXiv:2201.11969v3 [cs.LG] UPDATED)
168. Rapid protein assignments and structures from raw NMR spectra with the deep learning technique ARTINA. (arXiv:2201.12041v2 [q-bio.BM] UPDATED)
169. Low-rank features based double transformation matrices learning for image classification. (arXiv:2201.12351v2 [cs.LG] UPDATED)
170. Explaining Graph-level Predictions with Communication Structure-Aware Cooperative Games. (arXiv:2201.12380v2 [cs.LG] UPDATED)
171. Signing the Supermask: Keep, Hide, Invert. (arXiv:2201.13361v2 [cs.LG] UPDATED)
172. SnAKe: Bayesian Optimization with Pathwise Exploration. (arXiv:2202.00060v2 [cs.LG] UPDATED)
173. SUGAR: Efficient Subgraph-level Training via Resource-aware Graph Partitioning. (arXiv:2202.00075v3 [cs.LG] UPDATED)
174. Discovering Distribution Shifts using Latent Space Representations. (arXiv:2202.02339v2 [cs.LG] UPDATED)
175. Emblaze: Illuminating Machine Learning Representations through Interactive Comparison of Embedding Spaces. (arXiv:2202.02641v2 [cs.HC] UPDATED)
176. Learning fair representation with a parametric integral probability metric. (arXiv:2202.02943v2 [stat.ML] UPDATED)
177. Graph Self-supervised Learning with Accurate Discrepancy Learning. (arXiv:2202.02989v2 [cs.LG] UPDATED)
178. B2EA: An Evolutionary Algorithm Assisted by Two Bayesian Optimization Modules for Neural Architecture Search. (arXiv:2202.03005v2 [cs.NE] UPDATED)
179. Conditional Gradients for the Approximately Vanishing Ideal. (arXiv:2202.03349v4 [cs.LG] UPDATED)
180. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v2 [cs.CV] UPDATED)
181. A hypothesis-driven method based on machine learning for neuroimaging data analysis. (arXiv:2202.04397v2 [stat.ML] UPDATED)
182. Bayesian Optimisation for Mixed-Variable Inputs using Value Proposals. (arXiv:2202.04832v2 [stat.ML] UPDATED)
183. Optimal sizing of a holdout set for safe predictive model updating. (arXiv:2202.06374v2 [stat.ML] UPDATED)
184. User-Oriented Robust Reinforcement Learning. (arXiv:2202.07301v2 [cs.LG] UPDATED)
185. When Does A Spectral Graph Neural Network Fail in Node Classification?. (arXiv:2202.07902v2 [cs.LG] UPDATED)
186. A multi-reconstruction study of breast density estimation using Deep Learning. (arXiv:2202.08238v2 [eess.IV] UPDATED)
## cs.AI
---
**67** new papers in cs.AI:-) 
1. Evaluation and Analysis of Different Aggregation and Hyperparameter Selection Methods for Federated Brain Tumor Segmentation. (arXiv:2202.08261v1 [cs.LG])
2. Phase Aberration Robust Beamformer for Planewave US Using Self-Supervised Learning. (arXiv:2202.08262v1 [eess.IV])
3. Open-Ended Reinforcement Learning with Neural Reward Functions. (arXiv:2202.08266v1 [cs.LG])
4. More to Less (M2L): Enhanced Health Recognition in the Wild with Reduced Modality of Wearable Sensors. (arXiv:2202.08267v1 [cs.LG])
5. OpenKBP-Opt: An international and reproducible evaluation of 76 knowledge-based planning pipelines. (arXiv:2202.08303v1 [physics.med-ph])
6. Towards Verifiable Federated Learning. (arXiv:2202.08310v1 [cs.CR])
7. Vision Models Are More Robust And Fair When Pretrained On Uncurated Images Without Supervision. (arXiv:2202.08360v1 [cs.CV])
8. The Quarks of Attention. (arXiv:2202.08371v1 [cs.LG])
9. Fuzzy Pooling. (arXiv:2202.08372v1 [cs.LG])
10. Text-Based Action-Model Acquisition for Planning. (arXiv:2202.08373v1 [cs.LG])
11. Augment with Care: Contrastive Learning for the Boolean Satisfiability Problem. (arXiv:2202.08396v1 [cs.LG])
12. Neural Marionette: Unsupervised Learning of Motion Skeleton and Latent Dynamics from Volumetric Video. (arXiv:2202.08418v1 [cs.CV])
13. Chord-Conditioned Melody Choralization with Controllable Harmonicity and Polyphonicity. (arXiv:2202.08423v1 [cs.SD])
14. A Survey on Deep Reinforcement Learning-based Approaches for Adaptation and Generalization. (arXiv:2202.08444v1 [cs.LG])
15. Transformer for Graphs: An Overview from Architecture Perspective. (arXiv:2202.08455v1 [cs.LG])
16. The Gene of Scientific Success. (arXiv:2202.08461v1 [cs.DL])
17. Revisiting the Evaluation Metrics of Paraphrase Generation. (arXiv:2202.08479v1 [cs.CL])
18. Dynamic Object Comprehension: A Framework For Evaluating Artificial Visual Perception. (arXiv:2202.08490v1 [cs.CV])
19. CSCNet: Contextual Semantic Consistency Network for Trajectory Prediction in Crowded Spaces. (arXiv:2202.08506v1 [cs.CV])
20. A Study of Designing Compact Audio-Visual Wake Word Spotting System Based on Iterative Fine-Tuning in Neural Network Pruning. (arXiv:2202.08509v1 [cs.SD])
21. A hybrid 2-stage vision transformer for AI-assisted 5 class pathologic diagnosis of gastric endoscopic biopsies. (arXiv:2202.08510v1 [eess.IV])
22. Visual Ground Truth Construction as Faceted Classification. (arXiv:2202.08512v1 [cs.CV])
23. Contrastive Meta Learning with Behavior Multiplicity for Recommendation. (arXiv:2202.08523v1 [cs.IR])
24. Point Cloud Generation with Continuous Conditioning. (arXiv:2202.08526v1 [cs.CV])
25. Mitigating Closed-model Adversarial Examples with Bayesian Neural Modeling for Enhanced End-to-End Speech Recognition. (arXiv:2202.08532v1 [eess.AS])
26. AISHELL-NER: Named Entity Recognition from Chinese Speech. (arXiv:2202.08533v1 [cs.CL])
27. Does the End Justify the Means? On the Moral Justification of Fairness-Aware Machine Learning. (arXiv:2202.08536v1 [cs.LG])
28. Query Answering with Transitive and Linear-Ordered Data. (arXiv:2202.08555v1 [cs.LO])
29. CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving. (arXiv:2202.08557v1 [cs.CV])
30. Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations. (arXiv:2202.08602v1 [cs.CR])
31. Two-Stage Architectural Fine-Tuning with Neural Architecture Search using Early-Stopping in Image Classification. (arXiv:2202.08604v1 [cs.CV])
32. On the evaluation of (meta-)solver approaches. (arXiv:2202.08613v1 [cs.AI])
33. Domain Randomization for Object Counting. (arXiv:2202.08670v1 [cs.CV])
34. Measuring Trustworthiness or Automating Physiognomy? A Comment on Safra, Chevallier, Gr\`ezes, and Baumard (2020). (arXiv:2202.08674v1 [cs.LG])
35. A study of deep perceptual metrics for image quality assessment. (arXiv:2202.08692v1 [cs.CV])
36. Mining On Alzheimer's Diseases Related Knowledge Graph to Identity Potential AD-related Semantic Triples for Drug Repurposing. (arXiv:2202.08712v1 [cs.AI])
37. Listing Maximal k-Plexes in Large Real-World Graphs. (arXiv:2202.08737v1 [cs.DS])
38. Seeing Like a Toolkit: How Toolkits Envision the Work of AI Ethics. (arXiv:2202.08792v1 [cs.CY])
39. Grammar-Based Grounded Lexicon Learning. (arXiv:2202.08806v1 [cs.CL])
40. GRAPHSHAP: Motif-based Explanations for Black-box Graph Classifiers. (arXiv:2202.08815v1 [cs.LG])
41. General Cyclical Training of Neural Networks. (arXiv:2202.08835v1 [cs.LG])
42. Data-SUITE: Data-centric identification of in-distribution incongruous examples. (arXiv:2202.08836v1 [cs.LG])
43. Adiabatic Quantum Computing for Multi Object Tracking. (arXiv:2202.08837v1 [cs.CV])
44. Characterizing Attacks on Deep Reinforcement Learning. (arXiv:1907.09470v3 [cs.LG] UPDATED)
45. Learning Game-Theoretic Models of Multiagent Trajectories Using Implicit Layers. (arXiv:2008.07303v6 [cs.GT] UPDATED)
46. Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v3 [cs.LG] UPDATED)
47. Scaling Creative Inspiration with Fine-Grained Functional Aspects of Ideas. (arXiv:2102.09761v3 [cs.HC] UPDATED)
48. Improving Robustness of Deep Reinforcement Learning Agents: Environment Attack based on the Critic Network. (arXiv:2104.03154v2 [cs.LG] UPDATED)
49. Deep Time Series Forecasting with Shape and Temporal Criteria. (arXiv:2104.04610v2 [stat.ML] UPDATED)
50. Integration of Pre-trained Networks with Continuous Token Interface for End-to-End Spoken Language Understanding. (arXiv:2104.07253v2 [cs.CL] UPDATED)
51. Did I do that? Blame as a means to identify controlled effects in reinforcement learning. (arXiv:2106.00266v3 [cs.AI] UPDATED)
52. Preservation of Global Knowledge by Not-True Distillation in Federated Learning. (arXiv:2106.03097v3 [cs.LG] UPDATED)
53. Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning. (arXiv:2107.03961v3 [cs.AI] UPDATED)
54. ECQ$^{\text{x}}$: Explainability-Driven Quantization for Low-Bit and Sparse DNNs. (arXiv:2109.04236v2 [cs.LG] UPDATED)
55. A Framework for Learning to Request Rich and Contextually Useful Information from Humans. (arXiv:2110.08258v3 [cs.LG] UPDATED)
56. HARPS: An Online POMDP Framework for Human-Assisted Robotic Planning and Sensing. (arXiv:2110.10324v3 [cs.RO] UPDATED)
57. DataWords: Getting Contrarian with Text, Structured Data and Explanations. (arXiv:2111.05384v2 [cs.LG] UPDATED)
58. Improving Experience Replay with Successor Representation. (arXiv:2111.14331v2 [cs.LG] UPDATED)
59. Modeling Strong and Human-Like Gameplay with KL-Regularized Search. (arXiv:2112.07544v2 [cs.MA] UPDATED)
60. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v2 [cs.LG] UPDATED)
61. Advancing Deep Residual Learning by Solving the Crux of Degradation in Spiking Neural Networks. (arXiv:2201.07209v2 [cs.NE] UPDATED)
62. Fast Interpretable Greedy-Tree Sums (FIGS). (arXiv:2201.11931v2 [cs.LG] UPDATED)
63. Low-rank features based double transformation matrices learning for image classification. (arXiv:2201.12351v2 [cs.LG] UPDATED)
64. SUGAR: Efficient Subgraph-level Training via Resource-aware Graph Partitioning. (arXiv:2202.00075v3 [cs.LG] UPDATED)
65. Efficient Policy Space Response Oracles. (arXiv:2202.00633v3 [cs.GT] UPDATED)
66. Graph Self-supervised Learning with Accurate Discrepancy Learning. (arXiv:2202.02989v2 [cs.LG] UPDATED)
67. Decision boundaries and convex hulls in the feature space that deep learning functions learn from images. (arXiv:2202.04052v2 [cs.CV] UPDATED)

