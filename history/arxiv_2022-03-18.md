# Your interest papers
---
## cs.CV
---
### Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
- Authors : Roxana Daneshjou, Kailas Vodrahalli, Melissa Jenkins, Weixin Liang, Veronica Rotemberg, Justin Ko, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, Utako Okata, James Zou, Albert Chiou
- Link : [http://arxiv.org/abs/2203.08807](http://arxiv.org/abs/2203.08807)
> ABSTRACT  :  Access to dermatological care is a major issue, with an estimated 3 billion people lacking access to care globally. Artificial intelligence (AI) may aid in triaging skin diseases. However, most AI models have not been rigorously assessed on images of diverse skin tones or uncommon diseases. To ascertain potential biases in algorithm performance in this context, we curated the Diverse Dermatology Images (DDI) dataset-the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. Using this dataset of 656 images, we show that state-of-the-art dermatology AI models perform substantially worse on DDI, with receiver operator curve area under the curve (ROC-AUC) dropping by 27-36 percent compared to the models' original test results. All the models performed worse on **dark** skin tones and uncommon diseases, which are represented in the DDI dataset. Additionally, we find that dermatologists, who typically provide visual labels for AI training and test datasets, also perform worse on images of **dark** skin tones and uncommon diseases compared to ground truth biopsy annotations. Finally, fine-tuning AI models on the well-characterized and diverse DDI images closed the performance gap between light and **dark** skin tones. Moreover, algorithms fine-tuned on diverse skin tones outperformed dermatologists on identifying malignancy on images of **dark** skin tones. Our findings identify important weaknesses and biases in dermatology AI that need to be addressed to ensure reliable application to diverse patients and diseases.  
### Towards True Detail **Restoration** for Super-Resolution: A Benchmark and a Quality Metric. (arXiv:2203.08923v1 [cs.CV])
- Authors : Eugene Lyapustin, Anastasia Kirillova, Viacheslav Meshchaninov, Evgeney Zimin, Nikolai Karetin, Dmitriy Vatolin
- Link : [http://arxiv.org/abs/2203.08923](http://arxiv.org/abs/2203.08923)
> ABSTRACT  :  Super-resolution (SR) has become a widely researched topic in recent years. SR methods can improve overall image and video quality and create new possibilities for further content analysis. But the SR mainstream focuses primarily on increasing the naturalness of the resulting image despite potentially losing context accuracy. Such methods may produce an incorrect digit, character, face, or other structural object even though they otherwise yield good visual quality. Incorrect detail **restoration** can cause errors when detecting and identifying objects both manually and automatically. To analyze the detail-**restoration** capabilities of image and video SR models, we developed a benchmark based on our own video dataset, which contains complex patterns that SR models generally fail to correctly restore. We assessed 32 recent SR models using our benchmark and compared their ability to preserve scene context. We also conducted a crowd-sourced comparison of restored details and developed an objective assessment metric that outperforms other quality metrics by correlation with subjective scores for this task. In conclusion, we provide a deep analysis of benchmark results that yields insights for future SR-based work.  
### Semantic-aligned Fusion Transformer for One-shot Object Detection. (arXiv:2203.09093v1 [cs.CV])
- Authors : Yizhou Zhao, Xun Guo, Yan Lu
- Link : [http://arxiv.org/abs/2203.09093](http://arxiv.org/abs/2203.09093)
> ABSTRACT  :  One-shot object detection aims at detecting novel objects according to merely one given instance. With extreme data scarcity, current approaches explore various feature fusions to obtain directly transferable meta-knowledge. Yet, their performances are often unsatisfactory. In this paper, we attribute this to inappropriate correlation methods that misalign query-support semantics by overlooking spatial structures and scale variances. Upon analysis, we leverage the attention mechanism and propose a simple but effective architecture named Semantic-aligned Fusion Transformer (SaFT) to resolve these issues. Specifically, we equip SaFT with a vertical fusion module (VFM) for cross-scale semantic **enhancement** and a horizontal fusion module (HFM) for cross-sample feature fusion. Together, they broaden the vision for each feature point from the support to a whole augmented feature pyramid from the query, facilitating semantic-aligned associations. Extensive experiments on multiple benchmarks demonstrate the superiority of our framework. Without fine-tuning on novel classes, it brings significant performance gains to one-stage baselines, lifting state-of-the-art results to a higher level.  
### Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution. (arXiv:2203.09195v1 [cs.CV])
- Authors : Jie Liang, Hui Zeng, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09195](http://arxiv.org/abs/2203.09195)
> ABSTRACT  :  Single image super-resolution (SISR) with generative adversarial networks (GAN) has recently attracted increasing attention due to its potentials to generate rich details. However, the training of GAN is unstable, and it often introduces many perceptually unpleasant artifacts along with the generated details. In this paper, we demonstrate that it is possible to train a GAN-based SISR model which can stably generate perceptually realistic details while inhibiting visual artifacts. Based on the observation that the local statistics (e.g., residual variance) of artifact areas are often different from the areas of perceptually friendly details, we develop a framework to discriminate between GAN-generated artifacts and realistic details, and consequently generate an artifact map to regularize and stabilize the model training process. Our proposed locally discriminative learning (LDL) method is simple yet effective, which can be easily plugged in off-the-shelf SISR methods and boost their performance. Experiments demonstrate that LDL outperforms the state-of-the-art GAN based SISR methods, achieving not only higher reconstruction accuracy but also superior perceptual quality on both synthetic and real-world datasets. Codes and models are available at https://github.com/csjliang/LDL.  
### Neural Compression-Based Feature Learning for Video **Restoration**. (arXiv:2203.09208v1 [cs.CV])
- Authors : Cong Huang, Jiahao Li, Bin Li, Dong Liu, Yan Lu
- Link : [http://arxiv.org/abs/2203.09208](http://arxiv.org/abs/2203.09208)
> ABSTRACT  :  How to efficiently utilize the temporal features is crucial, yet challenging, for video **restoration**. The temporal features usually contain various noisy and uncorrelated information, and they may interfere with the **restoration** of the current frame. This paper proposes learning noise-robust feature representations to help video **restoration**. We are inspired by that the neural codec is a natural denoiser. In neural codec, the noisy and uncorrelated contents which are hard to predict but cost lots of bits are more inclined to be discarded for bitrate saving. Therefore, we design a neural compression module to filter the noise and keep the most useful information in features for video **restoration**. To achieve robustness to noise, our compression module adopts a spatial-channel-wise quantization mechanism to adaptively determine the quantization step size for each position in the latent. Experiments show that our method can significantly boost the performance on video denoising, where we obtain 0.13 dB improvement over BasicVSR++ with only 0.23x FLOPs. Meanwhile, our method also obtains SOTA results on video deraining and dehazing.  
### Depth-aware Neural Style Transfer using Instance Normalization. (arXiv:2203.09242v1 [cs.CV])
- Authors : Eleftherios Ioannou, Steve Maddock
- Link : [http://arxiv.org/abs/2203.09242](http://arxiv.org/abs/2203.09242)
> ABSTRACT  :  Neural Style Transfer (NST) is concerned with the artistic stylization of visual media. It can be described as the process of transferring the style of an artistic image onto an ordinary photograph. Recently, a number of studies have considered the **enhancement** of the depth-preserving capabilities of the NST algorithms to address the undesired effects that occur when the input content images include numerous objects at various depths. Our approach uses a deep residual convolutional network with instance normalization layers that utilizes an advanced depth prediction network to integrate depth preservation as an additional loss function to content and style. We demonstrate results that are effective in retaining the depth and global structure of content images. Three different evaluation processes show that our system is capable of preserving the structure of the stylized results while exhibiting style-capture capabilities and aesthetic qualities comparable or superior to state-of-the-art methods.  
### ART-SS: An Adaptive Rejection Technique for Semi-Supervised **restoration** for adverse weather-affected images. (arXiv:2203.09275v1 [cs.CV])
- Authors : Rajeev Yasarla, Vishal Patel
- Link : [http://arxiv.org/abs/2203.09275](http://arxiv.org/abs/2203.09275)
> ABSTRACT  :  In recent years, convolutional neural network-based single image adverse weather removal methods have achieved significant performance improvements on many benchmark datasets. However, these methods require large amounts of clean-weather degraded image pairs for training, which is often difficult to obtain in practice. Although various weather degradation synthesis methods exist in the literature, the use of synthetically generated weather degraded images often results in sub-optimal performance on the real weather degraded images due to the domain gap between synthetic and real-world images. To deal with this problem, various semi-supervised **restoration** (SSR) methods have been proposed for deraining or dehazing which learn to restore the clean image using synthetically generated datasets while generalizing better using unlabeled real-world images. The performance of a semi-supervised method is essentially based on the quality of the unlabeled data. In particular, if the unlabeled data characteristics are very different from that of the labeled data, then the performance of a semi-supervised method degrades significantly. We theoretically study the effect of unlabeled data on the performance of an SSR method and develop a technique that rejects the unlabeled images that degrade the performance. Extensive experiments and ablation study show that the proposed sample rejection method increases the performance of existing SSR deraining and dehazing methods significantly. Code is available at :https://github.com/rajeevyasarla/ART-SS  
### PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer. (arXiv:2203.09293v1 [cs.CV])
- Authors : Lina Achaji, Thierno Barry, Thibault Fouqueray, Julien Moreau, Francois Aioun, Francois Charpillet
- Link : [http://arxiv.org/abs/2203.09293](http://arxiv.org/abs/2203.09293)
> ABSTRACT  :  Nowadays, our mobility systems are evolving into the era of intelligent vehicles that aim to improve road safety. Due to their vulnerability, pedestrians are the users who will benefit the most from these developments. However, predicting their trajectory is one of the most challenging concerns. Indeed, accurate prediction requires a good understanding of multi-agent interactions that can be complex. Learning the underlying spatial and temporal patterns caused by these interactions is even more of a competitive and open problem that many researchers are tackling. In this paper, we introduce a model called PRediction Transformer (PReTR) that extracts features from the multi-agent scenes by employing a factorized spatio-temporal attention module. It shows less computational needs than previously studied models with empirically better results. Besides, previous works in motion prediction suffer from the **exposure** bias problem caused by generating future sequences conditioned on model prediction samples rather than ground-truth samples. In order to go beyond the proposed solutions, we leverage encoder-decoder Transformer networks for parallel decoding a set of learned object queries. This non-autoregressive solution avoids the need for iterative conditioning and arguably decreases training and testing computational time. We evaluate our model on the ETH/UCY datasets, a publicly available benchmark for pedestrian trajectory prediction. Finally, we justify our usage of the parallel decoding technique by showing that the trajectory prediction task can be better solved as a non-autoregressive task.  
### A Differentiable Two-stage Alignment Scheme for Burst Image Reconstruction with Large Shift. (arXiv:2203.09294v1 [cs.CV])
- Authors : Shi Guo, Xi Yang, Jianqi Ma, Gaofeng Ren, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09294](http://arxiv.org/abs/2203.09294)
> ABSTRACT  :  Denoising and demosaicking are two essential steps to reconstruct a clean full-color image from the raw data. Recently, joint denoising and demosaicking (JDD) for burst images, namely JDD-B, has attracted much attention by using multiple raw images captured in a short time to reconstruct a single high-quality image. One key challenge of JDD-B lies in the robust alignment of image frames. State-of-the-art alignment methods in feature domain cannot effectively utilize the temporal information of burst images, where large shifts commonly exist due to camera and object motion. In addition, the higher resolution (e.g., 4K) of modern imaging devices results in larger displacement between frames. To address these challenges, we design a differentiable two-stage alignment scheme sequentially in patch and pixel level for effective JDD-B. The input burst images are firstly aligned in the patch level by using a differentiable progressive block matching method, which can estimate the offset between distant frames with small computational cost. Then we perform implicit pixel-wise alignment in full-resolution feature domain to refine the alignment results. The two stages are jointly trained in an end-to-end manner. Extensive experiments demonstrate the significant improvement of our method over existing JDD-B methods. Codes are available at https://github.com/GuoShi28/2StageAlign.  
### A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-resolution. (arXiv:2203.09388v1 [cs.CV])
- Authors : Jianqi Ma, Zhetong Liang, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09388](http://arxiv.org/abs/2203.09388)
> ABSTRACT  :  Scene text image super-resolution aims to increase the resolution and readability of the text in low-resolution images. Though significant improvement has been achieved by deep convolutional neural networks (CNNs), it remains difficult to reconstruct high-resolution images for spatially deformed texts, especially rotated and curve-shaped ones. This is because the current CNN-based methods adopt locality-based operations, which are not effective to deal with the variation caused by deformations. In this paper, we propose a CNN based Text ATTention network (TATT) to address this problem. The semantics of the text are firstly extracted by a text recognition module as text prior information. Then we design a novel transformer-based module, which leverages global attention mechanism, to exert the semantic guidance of text prior to the text reconstruction process. In addition, we propose a text structure consistency loss to refine the visual appearance by imposing structural consistency on the reconstructions of regular and deformed texts. Experiments on the benchmark TextZoom dataset show that the proposed TATT not only achieves state-of-the-art performance in terms of PSNR/SSIM metrics, but also significantly improves the recognition accuracy in the downstream text recognition task, particularly for text instances with multi-orientation and curved shapes. Code is available at https://github.com/mjq11302010044/TATT.  
### Medium Transmission Map Matters for Learning to Restore Real-World Underwater Images. (arXiv:2203.09414v1 [cs.CV])
- Authors : Yan Kai, Liang Lanyue, Zheng Ziqiang, Wang Guoqing, Yang Yang
- Link : [http://arxiv.org/abs/2203.09414](http://arxiv.org/abs/2203.09414)
> ABSTRACT  :  Underwater visual perception is essentially important for underwater exploration, archeology, ecosystem and so on. The low illumination, light reflections, scattering, absorption and suspended particles inevitably lead to the critically degraded underwater image quality, which causes great challenges on recognizing the objects from the underwater images. The existing underwater **enhancement** methods that aim to promote the underwater visibility, heavily suffer from the poor image **restoration** performance and generalization ability. To reduce the difficulty of underwater image **enhancement**, we introduce the media transmission map as guidance to assist in image **enhancement**. We formulate the interaction between the underwater visual images and the transmission map to obtain better **enhancement** results. Even with simple and lightweight network configuration, the proposed method can achieve advanced results of 22.6 dB on the challenging Test-R90 with an impressive 30 times faster than the existing models. Comprehensive experimental results have demonstrated the superiority and potential on underwater perception. Paper's code is privoded on: https://github.com/GroupG-yk/MTUR-Net  
### Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
- Authors : Cian Eastwood, Ian Mason, Bernhard Sch
- Link : [http://arxiv.org/abs/2107.05446](http://arxiv.org/abs/2107.05446)
> ABSTRACT  :  Source-free domain adaptation (SFDA) aims to adapt a model trained on labelled data in a source domain to unlabelled data in a target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation in the target domain. We address these issues for a particularly pervasive type of domain shift called measurement shift which can be resolved by restoring the source features rather than extracting new ones. In particular, we propose Feature **Restoration** (FR) wherein we: (i) store a lightweight and flexible approximation of the feature distribution under the source data; and (ii) adapt the feature-extractor such that the approximate feature distribution under the target data realigns with that saved on the source. We additionally propose a bottom-up training scheme which boosts performance, which we call Bottom-Up Feature **Restoration** (BUFR). On real and synthetic data, we demonstrate that BUFR outperforms existing SFDA methods in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model in the target domain.  
### AS-MLP: An Axial Shifted MLP Architecture for Vision. (arXiv:2107.08391v2 [cs.CV] UPDATED)
- Authors : Dongze Lian, Zehao Yu, Xing Sun, Shenghua Gao
- Link : [http://arxiv.org/abs/2107.08391](http://arxiv.org/abs/2107.08391)
> ABSTRACT  :  An Axial Shifted MLP architecture (AS-MLP) is proposed in this paper. Different from MLP-Mixer, where the global spatial feature is encoded for information flow through matrix transposition and one token-mixing MLP, we pay more attention to the local features interaction. By axially shifting channels of the feature map, AS-MLP is able to obtain the information flow from different axial directions, which captures the local dependencies. Such an operation enables us to utilize a pure MLP architecture to achieve the same local receptive field as CNN-like architecture. We can also design the receptive field size and dilation of blocks of AS-MLP, etc, in the same spirit of convolutional neural networks. With the proposed AS-MLP architecture, our model obtains 83.3% Top-1 accuracy with 88M parameters and 15.2 GFLOPs on the ImageNet-1K dataset. Such a simple yet effective architecture outperforms all MLP-based architectures and achieves competitive performance compared to the transformer-based architectures (e.g., **Swin** Transformer) even with slightly lower FLOPs. In addition, AS-MLP is also the first MLP-based architecture to be applied to the downstream tasks (e.g., object detection and semantic segmentation). The experimental results are also impressive. Our proposed AS-MLP obtains 51.5 mAP on the COCO validation set and 49.5 MS mIoU on the ADE20K dataset, which is competitive compared to the transformer-based architectures. Our AS-MLP establishes a strong baseline of MLP-based architecture. Code is available at https://github.com/svip-lab/AS-MLP.  
### SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v2 [cs.CV] UPDATED)
- Authors : Jitesh Jain, Anukriti Singh, Nikita Orlov, Zilong Huang, Jiachen Li, Steven Walton, Humphrey Shi
- Link : [http://arxiv.org/abs/2112.12782](http://arxiv.org/abs/2112.12782)
> ABSTRACT  :  Finetuning a pretrained backbone in the encoder part of an image transformer network has been the traditional approach for the semantic segmentation task. However, such an approach leaves out the semantic context that an image provides during the encoding stage. This paper argues that incorporating semantic information of the image into pretrained hierarchical transformer-based backbones while finetuning improves the performance considerably. To achieve this, we propose SeMask, a simple and effective framework that incorporates semantic information into the encoder with the help of a semantic attention operation. In addition, we use a lightweight semantic decoder during training to provide supervision to the intermediate semantic prior maps at every stage. Our experiments demonstrate that incorporating semantic priors enhances the performance of the established hierarchical encoders with a slight increase in the number of FLOPs. We provide empirical proof by integrating SeMask into **Swin** Transformer and Mix Transformer backbones as our encoder paired with different decoders. Our framework achieves a new state-of-the-art of 58.22% mIoU on the ADE20K dataset and improvements of over 3% in the mIoU metric on the Cityscapes dataset. The code and checkpoints are publicly available at https://github.com/Picsart-AI-Research/SeMask-Segmentation .  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  We revisit large kernel design in modern convolutional neural networks (CNNs). Inspired by recent advances of vision transformers (ViTs), in this paper, we demonstrate that using a few large convolutional kernels instead of a stack of small kernels could be a more powerful paradigm. We suggested five guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31, in contrast to commonly used 3x3. RepLKNet greatly closes the performance gap between CNNs and ViTs, e.g., achieving comparable or superior results than **Swin** Transformer on ImageNet and a few typical downstream tasks, with lower latency. RepLKNet also shows nice scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0% mIoU on ADE20K, which is very competitive among the state-of-the-arts with similar model sizes. Our study further reveals that, in contrast to small-kernel CNNs, large-kernel CNNs have much larger effective receptive fields, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
### Active Exploration for Neural Global Illumination of Variable Scenes. (arXiv:2203.08272v1 [cs.GR] CROSS LISTED)
- Authors : Stavros Diolatzis, Julien Philip, George Drettakis
- Link : [http://arxiv.org/abs/2203.08272](http://arxiv.org/abs/2203.08272)
> ABSTRACT  :  Neural rendering algorithms introduce a fundamentally new approach for photorealistic rendering, typically by learning a neural representation of illumination on large numbers of ground truth images. When training for a given variable scene, i.e., changing objects, materials, lights and viewpoint, the space D of possible training data instances quickly becomes unmanageable as the dimensions of variable parameters increase. We introduce a novel Active Exploration method using Markov Chain Monte Carlo, which explores D, generating samples (i.e., ground truth renderings) that best help training and interleaves training and on-the-fly sample data generation. We introduce a self-tuning sample reuse strategy to minimize the expensive step of rendering training samples. We apply our approach on a neural generator that learns to render novel scene instances given an explicit parameterization of the scene configuration. Our results show that Active Exploration trains our network much more efficiently than uniformly sampling, and together with our resolution **enhancement** approach, achieves better quality than uniform sampling at convergence. Our method allows interactive rendering of hard light transport paths (e.g., complex caustics) -- that require very high samples counts to be captured -- and provides dynamic scene navigation and manipulation, after training for 5-18 hours depending on required quality and variations.  
## eess.IV
---
### Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
- Authors : Roxana Daneshjou, Kailas Vodrahalli, Melissa Jenkins, Weixin Liang, Veronica Rotemberg, Justin Ko, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, Utako Okata, James Zou, Albert Chiou
- Link : [http://arxiv.org/abs/2203.08807](http://arxiv.org/abs/2203.08807)
> ABSTRACT  :  Access to dermatological care is a major issue, with an estimated 3 billion people lacking access to care globally. Artificial intelligence (AI) may aid in triaging skin diseases. However, most AI models have not been rigorously assessed on images of diverse skin tones or uncommon diseases. To ascertain potential biases in algorithm performance in this context, we curated the Diverse Dermatology Images (DDI) dataset-the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. Using this dataset of 656 images, we show that state-of-the-art dermatology AI models perform substantially worse on DDI, with receiver operator curve area under the curve (ROC-AUC) dropping by 27-36 percent compared to the models' original test results. All the models performed worse on **dark** skin tones and uncommon diseases, which are represented in the DDI dataset. Additionally, we find that dermatologists, who typically provide visual labels for AI training and test datasets, also perform worse on images of **dark** skin tones and uncommon diseases compared to ground truth biopsy annotations. Finally, fine-tuning AI models on the well-characterized and diverse DDI images closed the performance gap between light and **dark** skin tones. Moreover, algorithms fine-tuned on diverse skin tones outperformed dermatologists on identifying malignancy on images of **dark** skin tones. Our findings identify important weaknesses and biases in dermatology AI that need to be addressed to ensure reliable application to diverse patients and diseases.  
## cs.LG
---
### Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
- Authors : Roxana Daneshjou, Kailas Vodrahalli, Melissa Jenkins, Weixin Liang, Veronica Rotemberg, Justin Ko, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, Utako Okata, James Zou, Albert Chiou
- Link : [http://arxiv.org/abs/2203.08807](http://arxiv.org/abs/2203.08807)
> ABSTRACT  :  Access to dermatological care is a major issue, with an estimated 3 billion people lacking access to care globally. Artificial intelligence (AI) may aid in triaging skin diseases. However, most AI models have not been rigorously assessed on images of diverse skin tones or uncommon diseases. To ascertain potential biases in algorithm performance in this context, we curated the Diverse Dermatology Images (DDI) dataset-the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. Using this dataset of 656 images, we show that state-of-the-art dermatology AI models perform substantially worse on DDI, with receiver operator curve area under the curve (ROC-AUC) dropping by 27-36 percent compared to the models' original test results. All the models performed worse on **dark** skin tones and uncommon diseases, which are represented in the DDI dataset. Additionally, we find that dermatologists, who typically provide visual labels for AI training and test datasets, also perform worse on images of **dark** skin tones and uncommon diseases compared to ground truth biopsy annotations. Finally, fine-tuning AI models on the well-characterized and diverse DDI images closed the performance gap between light and **dark** skin tones. Moreover, algorithms fine-tuned on diverse skin tones outperformed dermatologists on identifying malignancy on images of **dark** skin tones. Our findings identify important weaknesses and biases in dermatology AI that need to be addressed to ensure reliable application to diverse patients and diseases.  
### Discovering the building blocks of **dark** matter halo density profiles with neural networks. (arXiv:2203.08827v1 [astro-ph.CO])
- Authors : Luisa Lucie, Andrew Pontzen, Brian Nord, Jeyan Thiyagalingam, Davide Piras
- Link : [http://arxiv.org/abs/2203.08827](http://arxiv.org/abs/2203.08827)
> ABSTRACT  :  The density profiles of **dark** matter halos are typically modeled using empirical formulae fitted to the density profiles of relaxed halo populations. We present a neural network model that is trained to learn the mapping from the raw density field containing each halo to the **dark** matter density profile. We show that the model recovers the widely-used Navarro-Frenk-White (NFW) profile out to the virial radius, and can additionally describe the variability in the outer profile of the halos. The neural network architecture consists of a supervised encoder-decoder framework, which first compresses the density inputs into a low-dimensional latent representation, and then outputs $\rho(r)$ for any desired value of radius $r$. The latent representation contains all the information used by the model to predict the density profiles. This allows us to interpret the latent representation by quantifying the mutual information between the representation and the halos' ground-truth density profiles. A two-dimensional representation is sufficient to accurately model the density profiles up to the virial radius; however, a three-dimensional representation is required to describe the outer profiles beyond the virial radius. The additional dimension in the representation contains information about the infalling material in the outer profiles of **dark** matter halos, thus discovering the splashback boundary of halos without prior knowledge of the halos' dynamical history.  
### PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer. (arXiv:2203.09293v1 [cs.CV])
- Authors : Lina Achaji, Thierno Barry, Thibault Fouqueray, Julien Moreau, Francois Aioun, Francois Charpillet
- Link : [http://arxiv.org/abs/2203.09293](http://arxiv.org/abs/2203.09293)
> ABSTRACT  :  Nowadays, our mobility systems are evolving into the era of intelligent vehicles that aim to improve road safety. Due to their vulnerability, pedestrians are the users who will benefit the most from these developments. However, predicting their trajectory is one of the most challenging concerns. Indeed, accurate prediction requires a good understanding of multi-agent interactions that can be complex. Learning the underlying spatial and temporal patterns caused by these interactions is even more of a competitive and open problem that many researchers are tackling. In this paper, we introduce a model called PRediction Transformer (PReTR) that extracts features from the multi-agent scenes by employing a factorized spatio-temporal attention module. It shows less computational needs than previously studied models with empirically better results. Besides, previous works in motion prediction suffer from the **exposure** bias problem caused by generating future sequences conditioned on model prediction samples rather than ground-truth samples. In order to go beyond the proposed solutions, we leverage encoder-decoder Transformer networks for parallel decoding a set of learned object queries. This non-autoregressive solution avoids the need for iterative conditioning and arguably decreases training and testing computational time. We evaluate our model on the ETH/UCY datasets, a publicly available benchmark for pedestrian trajectory prediction. Finally, we justify our usage of the parallel decoding technique by showing that the trajectory prediction task can be better solved as a non-autoregressive task.  
### Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
- Authors : Cian Eastwood, Ian Mason, Bernhard Sch
- Link : [http://arxiv.org/abs/2107.05446](http://arxiv.org/abs/2107.05446)
> ABSTRACT  :  Source-free domain adaptation (SFDA) aims to adapt a model trained on labelled data in a source domain to unlabelled data in a target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation in the target domain. We address these issues for a particularly pervasive type of domain shift called measurement shift which can be resolved by restoring the source features rather than extracting new ones. In particular, we propose Feature **Restoration** (FR) wherein we: (i) store a lightweight and flexible approximation of the feature distribution under the source data; and (ii) adapt the feature-extractor such that the approximate feature distribution under the target data realigns with that saved on the source. We additionally propose a bottom-up training scheme which boosts performance, which we call Bottom-Up Feature **Restoration** (BUFR). On real and synthetic data, we demonstrate that BUFR outperforms existing SFDA methods in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model in the target domain.  
### SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v2 [cs.CV] UPDATED)
- Authors : Jitesh Jain, Anukriti Singh, Nikita Orlov, Zilong Huang, Jiachen Li, Steven Walton, Humphrey Shi
- Link : [http://arxiv.org/abs/2112.12782](http://arxiv.org/abs/2112.12782)
> ABSTRACT  :  Finetuning a pretrained backbone in the encoder part of an image transformer network has been the traditional approach for the semantic segmentation task. However, such an approach leaves out the semantic context that an image provides during the encoding stage. This paper argues that incorporating semantic information of the image into pretrained hierarchical transformer-based backbones while finetuning improves the performance considerably. To achieve this, we propose SeMask, a simple and effective framework that incorporates semantic information into the encoder with the help of a semantic attention operation. In addition, we use a lightweight semantic decoder during training to provide supervision to the intermediate semantic prior maps at every stage. Our experiments demonstrate that incorporating semantic priors enhances the performance of the established hierarchical encoders with a slight increase in the number of FLOPs. We provide empirical proof by integrating SeMask into **Swin** Transformer and Mix Transformer backbones as our encoder paired with different decoders. Our framework achieves a new state-of-the-art of 58.22% mIoU on the ADE20K dataset and improvements of over 3% in the mIoU metric on the Cityscapes dataset. The code and checkpoints are publicly available at https://github.com/Picsart-AI-Research/SeMask-Segmentation .  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  We revisit large kernel design in modern convolutional neural networks (CNNs). Inspired by recent advances of vision transformers (ViTs), in this paper, we demonstrate that using a few large convolutional kernels instead of a stack of small kernels could be a more powerful paradigm. We suggested five guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31, in contrast to commonly used 3x3. RepLKNet greatly closes the performance gap between CNNs and ViTs, e.g., achieving comparable or superior results than **Swin** Transformer on ImageNet and a few typical downstream tasks, with lower latency. RepLKNet also shows nice scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0% mIoU on ADE20K, which is very competitive among the state-of-the-arts with similar model sizes. Our study further reveals that, in contrast to small-kernel CNNs, large-kernel CNNs have much larger effective receptive fields, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
### Sensitivity Estimation for **Dark** Matter Subhalos in Synthetic Gaia DR2 using Deep Learning. (arXiv:2203.08161v1 [astro-ph.GA] CROSS LISTED)
- Authors : Abdullah Bazarov, Rain Kipper, Joosep Pata
- Link : [http://arxiv.org/abs/2203.08161](http://arxiv.org/abs/2203.08161)
> ABSTRACT  :  The abundance of **dark** matter subhalos orbiting a host galaxy is a generic prediction of the cosmological framework. It is a promising way to constrain the nature of **dark** matter. Here we describe the challenges of detecting stars whose phase-space distribution may be perturbed by the passage of **dark** matter subhalos using a machine learning approach. The training data are three Milky Way-like galaxies and nine synthetic Gaia DR2 surveys derived from these. We first quantify the magnitude of the perturbations in the simulated galaxies using an anomaly detection algorithm. We also estimate the feasibility of this approach in the Gaia DR2-like catalogues by comparing the anomaly detection based approach with a supervised classification. We find that a classification algorithm optimized on about half a billion synthetic star observables exhibits mild but nonzero sensitivity. This classification-based approach is not sufficiently sensitive to pinpoint the exact locations of subhalos in the simulation, as would be expected from the very limited number of subhalos in the detectable region. The enormous size of the Gaia dataset motivates the further development of scalable and accurate computational methods that could be used to select potential regions of interest for **dark** matter searches to ultimately constrain the Milky Way's subhalo mass function.  
## cs.AI
---
### Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
- Authors : Roxana Daneshjou, Kailas Vodrahalli, Melissa Jenkins, Weixin Liang, Veronica Rotemberg, Justin Ko, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, Utako Okata, James Zou, Albert Chiou
- Link : [http://arxiv.org/abs/2203.08807](http://arxiv.org/abs/2203.08807)
> ABSTRACT  :  Access to dermatological care is a major issue, with an estimated 3 billion people lacking access to care globally. Artificial intelligence (AI) may aid in triaging skin diseases. However, most AI models have not been rigorously assessed on images of diverse skin tones or uncommon diseases. To ascertain potential biases in algorithm performance in this context, we curated the Diverse Dermatology Images (DDI) dataset-the first publicly available, expertly curated, and pathologically confirmed image dataset with diverse skin tones. Using this dataset of 656 images, we show that state-of-the-art dermatology AI models perform substantially worse on DDI, with receiver operator curve area under the curve (ROC-AUC) dropping by 27-36 percent compared to the models' original test results. All the models performed worse on **dark** skin tones and uncommon diseases, which are represented in the DDI dataset. Additionally, we find that dermatologists, who typically provide visual labels for AI training and test datasets, also perform worse on images of **dark** skin tones and uncommon diseases compared to ground truth biopsy annotations. Finally, fine-tuning AI models on the well-characterized and diverse DDI images closed the performance gap between light and **dark** skin tones. Moreover, algorithms fine-tuned on diverse skin tones outperformed dermatologists on identifying malignancy on images of **dark** skin tones. Our findings identify important weaknesses and biases in dermatology AI that need to be addressed to ensure reliable application to diverse patients and diseases.  
### Discovering the building blocks of **dark** matter halo density profiles with neural networks. (arXiv:2203.08827v1 [astro-ph.CO])
- Authors : Luisa Lucie, Andrew Pontzen, Brian Nord, Jeyan Thiyagalingam, Davide Piras
- Link : [http://arxiv.org/abs/2203.08827](http://arxiv.org/abs/2203.08827)
> ABSTRACT  :  The density profiles of **dark** matter halos are typically modeled using empirical formulae fitted to the density profiles of relaxed halo populations. We present a neural network model that is trained to learn the mapping from the raw density field containing each halo to the **dark** matter density profile. We show that the model recovers the widely-used Navarro-Frenk-White (NFW) profile out to the virial radius, and can additionally describe the variability in the outer profile of the halos. The neural network architecture consists of a supervised encoder-decoder framework, which first compresses the density inputs into a low-dimensional latent representation, and then outputs $\rho(r)$ for any desired value of radius $r$. The latent representation contains all the information used by the model to predict the density profiles. This allows us to interpret the latent representation by quantifying the mutual information between the representation and the halos' ground-truth density profiles. A two-dimensional representation is sufficient to accurately model the density profiles up to the virial radius; however, a three-dimensional representation is required to describe the outer profiles beyond the virial radius. The additional dimension in the representation contains information about the infalling material in the outer profiles of **dark** matter halos, thus discovering the splashback boundary of halos without prior knowledge of the halos' dynamical history.  
### Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
- Authors : Cian Eastwood, Ian Mason, Bernhard Sch
- Link : [http://arxiv.org/abs/2107.05446](http://arxiv.org/abs/2107.05446)
> ABSTRACT  :  Source-free domain adaptation (SFDA) aims to adapt a model trained on labelled data in a source domain to unlabelled data in a target domain without access to the source-domain data during adaptation. Existing methods for SFDA leverage entropy-minimization techniques which: (i) apply only to classification; (ii) destroy model calibration; and (iii) rely on the source model achieving a good level of feature-space class-separation in the target domain. We address these issues for a particularly pervasive type of domain shift called measurement shift which can be resolved by restoring the source features rather than extracting new ones. In particular, we propose Feature **Restoration** (FR) wherein we: (i) store a lightweight and flexible approximation of the feature distribution under the source data; and (ii) adapt the feature-extractor such that the approximate feature distribution under the target data realigns with that saved on the source. We additionally propose a bottom-up training scheme which boosts performance, which we call Bottom-Up Feature **Restoration** (BUFR). On real and synthetic data, we demonstrate that BUFR outperforms existing SFDA methods in terms of accuracy, calibration, and data efficiency, while being less reliant on the performance of the source model in the target domain.  
### Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
- Authors : Xiaohan Ding, Xiangyu Zhang, Yizhuang Zhou, Jungong Han, Guiguang Ding, Jian Sun
- Link : [http://arxiv.org/abs/2203.06717](http://arxiv.org/abs/2203.06717)
> ABSTRACT  :  We revisit large kernel design in modern convolutional neural networks (CNNs). Inspired by recent advances of vision transformers (ViTs), in this paper, we demonstrate that using a few large convolutional kernels instead of a stack of small kernels could be a more powerful paradigm. We suggested five guidelines, e.g., applying re-parameterized large depth-wise convolutions, to design efficient high-performance large-kernel CNNs. Following the guidelines, we propose RepLKNet, a pure CNN architecture whose kernel size is as large as 31x31, in contrast to commonly used 3x3. RepLKNet greatly closes the performance gap between CNNs and ViTs, e.g., achieving comparable or superior results than **Swin** Transformer on ImageNet and a few typical downstream tasks, with lower latency. RepLKNet also shows nice scalability to big data and large models, obtaining 87.8% top-1 accuracy on ImageNet and 56.0% mIoU on ADE20K, which is very competitive among the state-of-the-arts with similar model sizes. Our study further reveals that, in contrast to small-kernel CNNs, large-kernel CNNs have much larger effective receptive fields, and higher shape bias rather than texture bias. Code &amp; models at https://github.com/megvii-research/RepLKNet.  
# Paper List
---
## cs.CV
---
**165** new papers in cs.CV:-) 
1. Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
2. Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography. (arXiv:2203.08812v1 [eess.IV])
3. Example Perplexity. (arXiv:2203.08813v1 [cs.LG])
4. DePS: An improved deep learning model for de novo peptide sequencing. (arXiv:2203.08820v1 [q-bio.QM])
5. Understanding robustness and generalization of artificial neural networks through Fourier masks. (arXiv:2203.08822v1 [cs.CV])
6. A Real-Time Region Tracking Algorithm Tailored to Endoscopic Video with Open-Source Implementation. (arXiv:2203.08858v1 [eess.IV])
7. SC2: Supervised Compression for Split Computing. (arXiv:2203.08875v1 [cs.LG])
8. Layer Ensembles: A Single-Pass Uncertainty Estimation in Deep Learning for Segmentation. (arXiv:2203.08878v1 [cs.CV])
9. Hyperbolic Uncertainty Aware Semantic Segmentation. (arXiv:2203.08881v1 [cs.CV])
10. Sat-NeRF: Learning Multi-View Satellite Photogrammetry With Transient Objects and Shadow Modeling Using RPC Cameras. (arXiv:2203.08896v1 [cs.CV])
11. Gate-Shift-Fuse for Video Action Recognition. (arXiv:2203.08897v1 [cs.CV])
12. Automated Grading of Radiographic Knee Osteoarthritis Severity Combined with Joint Space Narrowing. (arXiv:2203.08914v1 [cs.CV])
13. Hybrid Pixel-Unshuffled Network for Lightweight Image Super-Resolution. (arXiv:2203.08921v1 [cs.CV])
14. Towards True Detail **Restoration** for Super-Resolution: A Benchmark and a Quality Metric. (arXiv:2203.08923v1 [cs.CV])
15. Creating Multimedia Summaries Using Tweets and Videos. (arXiv:2203.08931v1 [cs.CL])
16. ABN: Agent-Aware Boundary Networks for Temporal Action Proposal Generation. (arXiv:2203.08942v1 [cs.CV])
17. CapsNet for Medical Image Segmentation. (arXiv:2203.08948v1 [eess.IV])
18. Meta-Learning of NAS for Few-shot Learning in Medical Image Applications. (arXiv:2203.08951v1 [cs.LG])
19. Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training. (arXiv:2203.08959v1 [cs.LG])
20. Point-Unet: A Context-aware Point-based Neural Network for Volumetric Segmentation. (arXiv:2203.08964v1 [cs.CV])
21. 3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation. (arXiv:2203.08965v1 [cs.CV])
22. Extensive Threat Analysis of Vein Attack Databases and Attack Detection by Fusion of Comparison Scores. (arXiv:2203.08972v1 [cs.CV])
23. Semantic-diversity transfer network for generalized zero-shot learning via inner disagreement based OOD detector. (arXiv:2203.09017v1 [cs.CV])
24. HybridNets: End-to-End Perception Network. (arXiv:2203.09035v1 [cs.CV])
25. An Active Contour Model with Local Variance Force Term and Its Efficient Minimization Solver for Multi-phase Image Segmentation. (arXiv:2203.09036v1 [cs.CV])
26. DATA: Domain-Aware and Task-Aware Pre-training. (arXiv:2203.09041v1 [cs.CV])
27. Latent Image Animator: Learning to Animate Images via Latent Space Navigation. (arXiv:2203.09043v1 [cs.CV])
28. DU-VLG: Unifying Vision-and-Language Generation via Dual Sequence-to-Sequence Pre-training. (arXiv:2203.09052v1 [cs.CV])
29. Robust Table Detection and Structure Recognition from Heterogeneous Document Images. (arXiv:2203.09056v1 [cs.CV])
30. Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning. (arXiv:2203.09064v1 [cs.CV])
31. STPLS3D: A Large-Scale Synthetic and Real Aerial Photogrammetry 3D Point Cloud Dataset. (arXiv:2203.09065v1 [cs.CV])
32. UNIMO-2: End-to-End Unified Vision-Language Grounded Learning. (arXiv:2203.09067v1 [cs.CV])
33. Do We Really Need a Learnable Classifier at the End of Deep Neural Network?. (arXiv:2203.09081v1 [cs.LG])
34. Deep Point Cloud Simplification for High-quality Surface Reconstruction. (arXiv:2203.09088v1 [cs.CV])
35. deepNIR: Datasets for generating synthetic NIR images and improved fruit detection system using deep learning techniques. (arXiv:2203.09091v1 [cs.CV])
36. Semantic-aligned Fusion Transformer for One-shot Object Detection. (arXiv:2203.09093v1 [cs.CV])
37. Community-Driven Comprehensive Scientific Paper Summarization: Insight from cvpaper.challenge. (arXiv:2203.09109v1 [cs.CV])
38. MotionAug: Augmentation with Physical Correction for Human Motion Prediction. (arXiv:2203.09116v1 [cs.CV])
39. DRAG: Dynamic Region-Aware GCN for Privacy-Leaking Image Detection. (arXiv:2203.09121v1 [cs.CV])
40. Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input. (arXiv:2203.09123v1 [cs.CV])
41. Are Vision Transformers Robust to Spurious Correlations?. (arXiv:2203.09125v1 [cs.CV])
42. Mutual Generative Transformer Learning for Cross-view Geo-localization. (arXiv:2203.09135v1 [cs.CV])
43. Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning. (arXiv:2203.09137v1 [cs.LG])
44. MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-based Visual Question Answering. (arXiv:2203.09138v1 [cs.CV])
45. Active Visuo-Haptic Object Shape Completion. (arXiv:2203.09149v1 [cs.RO])
46. Optimal Rejection Function Meets Character Recognition Tasks. (arXiv:2203.09151v1 [cs.CV])
47. Biasing Like Human: A Cognitive Bias Framework for Scene Graph Generation. (arXiv:2203.09160v1 [cs.CV])
48. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v1 [cs.CL])
49. UWED: Unsigned Distance Field for Accurate 3D Scene Representation and Completion. (arXiv:2203.09167v1 [cs.CV])
50. Generalized Classification of Satellite Image Time Series with Thermal Positional Encoding. (arXiv:2203.09175v1 [cs.CV])
51. A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers. (arXiv:2203.09180v1 [eess.IV])
52. An Interactive Explanatory AI System for Industrial Quality Control. (arXiv:2203.09181v1 [cs.LG])
53. Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution. (arXiv:2203.09195v1 [cs.CV])
54. Novel Consistency Check For Fast Recursive Reconstruction Of Non-Regularly Sampled Video Data. (arXiv:2203.09200v1 [eess.IV])
55. Simulation-Driven Training of Vision Transformers Enabling Metal Segmentation in X-Ray Images. (arXiv:2203.09207v1 [eess.IV])
56. Neural Compression-Based Feature Learning for Video **Restoration**. (arXiv:2203.09208v1 [cs.CV])
57. HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR. (arXiv:2203.09215v1 [cs.CV])
58. Surgical Workflow Recognition: from Analysis of Challenges to Architectural Study. (arXiv:2203.09230v1 [cs.CV])
59. Depth-aware Neural Style Transfer using Instance Normalization. (arXiv:2203.09242v1 [cs.CV])
60. On the Properties of Adversarially-Trained CNNs. (arXiv:2203.09243v1 [cs.CV])
61. Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning. (arXiv:2203.09249v1 [cs.LG])
62. Contrastive Learning for Cross-Domain Open World Recognition. (arXiv:2203.09257v1 [cs.CV])
63. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v1 [eess.IV])
64. ART-SS: An Adaptive Rejection Technique for Semi-Supervised **restoration** for adverse weather-affected images. (arXiv:2203.09275v1 [cs.CV])
65. PanoFormer: Panorama Transformer for Indoor 360{\deg} Depth Estimation. (arXiv:2203.09283v1 [cs.CV])
66. HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions. (arXiv:2203.09287v1 [cs.CV])
67. PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer. (arXiv:2203.09293v1 [cs.CV])
68. A Differentiable Two-stage Alignment Scheme for Burst Image Reconstruction with Large Shift. (arXiv:2203.09294v1 [cs.CV])
69. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v1 [cs.CV])
70. Video Prediction at Multiple Scales with Hierarchical Recurrent Networks. (arXiv:2203.09303v1 [cs.CV])
71. Finding Structural Knowledge in Multimodal-BERT. (arXiv:2203.09306v1 [cs.CL])
72. Localizing Visual Sounds the Easy Way. (arXiv:2203.09324v1 [cs.CV])
73. Modulated Contrast for Versatile Image Synthesis. (arXiv:2203.09333v1 [cs.CV])
74. Object Localization under Single Coarse Point Supervision. (arXiv:2203.09338v1 [cs.CV])
75. CYBORGS: Contrastively Bootstrapping Object Representations by Grounding in Segmentation. (arXiv:2203.09343v1 [cs.CV])
76. POSTER: Diagnosis of COVID-19 through Transfer Learning Techniques on CT Scans: A Comparison of Deep Learning Models. (arXiv:2203.09348v1 [eess.IV])
77. Fine Detailed Texture Learning for 3D Meshes with Generative Models. (arXiv:2203.09362v1 [cs.CV])
78. Interacting Attention Graph for Single Image Two-Hand Reconstruction. (arXiv:2203.09364v1 [cs.CV])
79. Transforming Gait: Video-Based Spatiotemporal Gait Analysis. (arXiv:2203.09371v1 [cs.CV])
80. Using the Order of Tomographic Slices as a Prior for Neural Networks Pre-Training. (arXiv:2203.09372v1 [eess.IV])
81. Neural Part Priors: Learning to Optimize Part-Based Object Completion in RGB-D Scans. (arXiv:2203.09375v1 [cs.CV])
82. One-Stage Deep Edge Detection Based on Dense-Scale Feature Fusion and Pixel-Level Imbalance Learning. (arXiv:2203.09387v1 [cs.CV])
83. A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-resolution. (arXiv:2203.09388v1 [cs.CV])
84. Medium Transmission Map Matters for Learning to Restore Real-World Underwater Images. (arXiv:2203.09414v1 [cs.CV])
85. Bi-directional Object-context Prioritization Learning for Saliency Ranking. (arXiv:2203.09416v1 [cs.CV])
86. ZebraPose: Coarse to Fine Surface Encoding for 6DoF Object Pose Estimation. (arXiv:2203.09418v1 [cs.CV])
87. Deep Unsupervised Hashing with Latent Semantic Components. (arXiv:2203.09420v1 [cs.CV])
88. Mutual Learning for Domain Adaptation: Self-distillation Image Dehazing Network with Sample-cycle. (arXiv:2203.09430v1 [cs.CV])
89. TO-Scene: A Large-scale Dataset for Understanding 3D Tabletop Scenes. (arXiv:2203.09440v1 [cs.CV])
90. Image Super-Resolution With Deep Variational Autoencoders. (arXiv:2203.09445v1 [cs.CV])
91. Vox2Cortex: Fast Explicit Reconstruction of Cortical Surfaces from 3D MRI Scans with Geometric Deep Neural Networks. (arXiv:2203.09446v1 [cs.CV])
92. Continual Learning Based on OOD Detection and Task Masking. (arXiv:2203.09450v1 [cs.CV])
93. Synthetic-to-Real Domain Adaptation using Contrastive Unpaired Translation. (arXiv:2203.09454v1 [cs.CV])
94. Look Outside the Room: Synthesizing A Consistent Long-Term 3D Scene Video from A Single Image. (arXiv:2203.09457v1 [cs.CV])
95. FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos. (arXiv:2203.09463v1 [cs.CV])
96. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v1 [cs.CV])
97. CaRTS: Causality-driven Robot Tool Segmentation from Vision and Kinematics Data. (arXiv:2203.09475v1 [cs.RO])
98. Computer Vision Algorithm for Predicting the Welding Efficiency of Friction Stir Welded Copper Joints from its Microstructures. (arXiv:2203.09479v1 [cs.CV])
99. Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v1 [cs.CV])
100. Transframer: Arbitrary Frame Prediction with Generative Models. (arXiv:2203.09494v1 [cs.CV])
101. Visualizing Global Explanations of Point Cloud DNNs. (arXiv:2203.09505v1 [cs.CV])
102. Towards Data-Efficient Detection Transformers. (arXiv:2203.09507v1 [cs.CV])
103. DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection. (arXiv:2203.09510v1 [cs.CV])
104. On Multi-Domain Long-Tailed Recognition, Generalization and Beyond. (arXiv:2203.09513v1 [cs.LG])
105. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation. (arXiv:2203.09516v1 [cs.CV])
106. TensoRF: Tensorial Radiance Fields. (arXiv:2203.09517v1 [cs.CV])
107. Depth Descent Synchronization in $\mathrm{SO}(D)$. (arXiv:2002.05299v3 [math.OC] UPDATED)
108. Intracranial Hemorrhage Detection Using Neural Network Based Methods With Federated Learning. (arXiv:2005.08644v3 [cs.CV] UPDATED)
109. SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image Classifiers. (arXiv:2012.05858v3 [cs.CV] UPDATED)
110. RoRD: Rotation-Robust Descriptors and Orthographic Views for Local Feature Matching. (arXiv:2103.08573v3 [cs.CV] UPDATED)
111. Revisiting the Loss Weight Adjustment in Object Detection. (arXiv:2103.09488v4 [cs.CV] UPDATED)
112. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v5 [cs.CV] UPDATED)
113. Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v3 [cs.CV] UPDATED)
114. Fine-grained Anomaly Detection via Multi-task Self-Supervision. (arXiv:2104.09993v2 [cs.CV] UPDATED)
115. GLSD: The Global Large-Scale Ship Database and Baseline Evaluations. (arXiv:2106.02773v2 [cs.CV] UPDATED)
116. Category Contrast for Unsupervised Domain Adaptation in Visual Tasks. (arXiv:2106.02885v3 [cs.CV] UPDATED)
117. Wavelet-Packets for Deepfake Image Analysis and Detection. (arXiv:2106.09369v3 [cs.CV] UPDATED)
118. ReGO: Reference-Guided Outpainting for Scenery Image. (arXiv:2106.10601v3 [cs.CV] UPDATED)
119. Bag of Instances Aggregation Boosts Self-supervised Distillation. (arXiv:2107.01691v2 [cs.CV] UPDATED)
120. Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
121. Agent-Environment Network for Temporal Action Proposal Generation. (arXiv:2107.08323v3 [cs.CV] UPDATED)
122. AS-MLP: An Axial Shifted MLP Architecture for Vision. (arXiv:2107.08391v2 [cs.CV] UPDATED)
123. SimVLM: Simple Visual Language Model Pretraining with Weak Supervision. (arXiv:2108.10904v2 [cs.CV] UPDATED)
124. High-Fidelity GAN Inversion for Image Attribute Editing. (arXiv:2109.06590v3 [cs.CV] UPDATED)
125. TAda! Temporally-Adaptive Convolutions for Video Understanding. (arXiv:2110.06178v4 [cs.CV] UPDATED)
126. FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes. (arXiv:2110.08059v3 [cs.CV] UPDATED)
127. Understanding Multimodal Procedural Knowledge by Sequencing Multimodal Instructional Manuals. (arXiv:2110.08486v3 [cs.CL] UPDATED)
128. Temporally stable video segmentation without video annotations. (arXiv:2110.08893v2 [cs.CV] UPDATED)
129. ConAM: Confidence Attention Module for Convolutional Neural Networks. (arXiv:2110.14369v2 [cs.CV] UPDATED)
130. Vision Transformer for Classification of Breast Ultrasound Images. (arXiv:2110.14731v2 [cs.CV] UPDATED)
131. CDGNet: Class Distribution Guided Network for Human Parsing. (arXiv:2111.14173v3 [cs.CV] UPDATED)
132. StyleMesh: Style Transfer for Indoor 3D Scene Reconstructions. (arXiv:2112.01530v2 [cs.CV] UPDATED)
133. FaceFormer: Speech-Driven 3D Facial Animation with Transformers. (arXiv:2112.05329v4 [cs.CV] UPDATED)
134. CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic Data. (arXiv:2112.09081v2 [cs.CV] UPDATED)
135. Efficient Visual Tracking with Exemplar Transformers. (arXiv:2112.09686v2 [cs.CV] UPDATED)
136. Generalizable Cross-modality Medical Image Segmentation via Style Augmentation and Dual Normalization. (arXiv:2112.11177v2 [cs.CV] UPDATED)
137. FourierMask: Instance Segmentation using Fourier Mapping in Implicit Neural Networks. (arXiv:2112.12535v2 [cs.CV] UPDATED)
138. SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v2 [cs.CV] UPDATED)
139. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v3 [eess.IV] UPDATED)
140. Bridging Video-text Retrieval with Multiple Choice Questions. (arXiv:2201.04850v2 [cs.CV] UPDATED)
141. Enhancing Pseudo Label Quality for Semi-Supervised Domain-Generalized Medical Image Segmentation. (arXiv:2201.08657v2 [cs.CV] UPDATED)
142. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v3 [cs.CV] UPDATED)
143. Improving Human Sperm Head Morphology Classification with Unsupervised Anatomical Feature Distillation. (arXiv:2202.07191v3 [cs.CV] UPDATED)
144. HDAM: Heuristic Difference Attention Module for Convolutional Neural Networks. (arXiv:2202.09556v2 [cs.CV] UPDATED)
145. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v2 [cs.CV] UPDATED)
146. Neural Adaptive SCEne Tracing. (arXiv:2202.13664v2 [cs.CV] UPDATED)
147. Enhancing Local Feature Learning for 3D Point Cloud Processing using Unary-Pairwise Attention. (arXiv:2203.00172v2 [cs.CV] UPDATED)
148. Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement. (arXiv:2203.03622v2 [eess.IV] UPDATED)
149. StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pre-trained StyleGAN. (arXiv:2203.04036v2 [cs.CV] UPDATED)
150. P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained TinyML Applications. (arXiv:2203.04737v2 [cs.LG] UPDATED)
151. Multiscale Transformer for Hyperspectral Image Classification. (arXiv:2203.04771v3 [cs.CV] UPDATED)
152. Domain Generalisation for Object Detection. (arXiv:2203.05294v2 [cs.CV] UPDATED)
153. Towards Bi-directional Skip Connections in Encoder-Decoder Architectures and Beyond. (arXiv:2203.05709v2 [cs.CV] UPDATED)
154. Training Protocol Matters: Towards Accurate Scene Text Recognition via Training Protocol Searching. (arXiv:2203.06696v2 [cs.CV] UPDATED)
155. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
156. SimMatch: Semi-supervised Learning with Similarity Matching. (arXiv:2203.06915v2 [cs.CV] UPDATED)
157. Extracting associations and meanings of objects depicted in artworks through bi-modal deep networks. (arXiv:2203.07026v2 [cs.CV] UPDATED)
158. A Survey of Non-Rigid 3D Registration. (arXiv:2203.07858v2 [cs.CV] UPDATED)
159. GPV-Pose: Category-level Object Pose Estimation via Geometry-guided Point-wise Voting. (arXiv:2203.07918v2 [cs.CV] UPDATED)
160. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v2 [cs.CV] UPDATED)
161. Motif Mining: Finding and Summarizing Remixed Image Content. (arXiv:2203.08327v2 [cs.CV] UPDATED)
162. Data Efficient 3D Learner via Knowledge Transferred from 2D Model. (arXiv:2203.08479v2 [cs.CV] UPDATED)
163. Complexity Reduction of Learned In-Loop Filtering in Video Coding. (arXiv:2203.08650v2 [eess.IV] UPDATED)
164. Graph Flow: Cross-layer Graph Flow Distillation for Dual-Efficient Medical Image Segmentation. (arXiv:2203.08667v2 [cs.CV] UPDATED)
165. Active Exploration for Neural Global Illumination of Variable Scenes. (arXiv:2203.08272v1 [cs.GR] CROSS LISTED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
2. Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography. (arXiv:2203.08812v1 [eess.IV])
3. Understanding robustness and generalization of artificial neural networks through Fourier masks. (arXiv:2203.08822v1 [cs.CV])
4. A Real-Time Region Tracking Algorithm Tailored to Endoscopic Video with Open-Source Implementation. (arXiv:2203.08858v1 [eess.IV])
5. SC2: Supervised Compression for Split Computing. (arXiv:2203.08875v1 [cs.LG])
6. Neural network processing of holographic images. (arXiv:2203.08898v1 [eess.IV])
7. CapsNet for Medical Image Segmentation. (arXiv:2203.08948v1 [eess.IV])
8. Meta-Learning of NAS for Few-shot Learning in Medical Image Applications. (arXiv:2203.08951v1 [cs.LG])
9. GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis. (arXiv:2203.09034v1 [cs.LG])
10. DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v1 [cs.LG])
11. A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers. (arXiv:2203.09180v1 [eess.IV])
12. Novel Consistency Check For Fast Recursive Reconstruction Of Non-Regularly Sampled Video Data. (arXiv:2203.09200v1 [eess.IV])
13. Simulation-Driven Training of Vision Transformers Enabling Metal Segmentation in X-Ray Images. (arXiv:2203.09207v1 [eess.IV])
14. Frequency-Selective Mesh-to-Mesh Resampling for Color Upsampling of Point Clouds. (arXiv:2203.09224v1 [eess.IV])
15. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v1 [eess.IV])
16. POSTER: Diagnosis of COVID-19 through Transfer Learning Techniques on CT Scans: A Comparison of Deep Learning Models. (arXiv:2203.09348v1 [eess.IV])
17. Using the Order of Tomographic Slices as a Prior for Neural Networks Pre-Training. (arXiv:2203.09372v1 [eess.IV])
18. Image Super-Resolution With Deep Variational Autoencoders. (arXiv:2203.09445v1 [cs.CV])
19. Intracranial Hemorrhage Detection Using Neural Network Based Methods With Federated Learning. (arXiv:2005.08644v3 [cs.CV] UPDATED)
20. Model-based Synthetic Data-driven Learning (MOST-DL): Application in Single-shot T2 Mapping with Severe Head Motion Using Overlapping-echo Acquisition. (arXiv:2107.14521v2 [eess.IV] UPDATED)
21. Robust Segmentation of Cell Nuclei in 3-D Microscopy Images. (arXiv:2110.03193v2 [eess.IV] UPDATED)
22. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v3 [eess.IV] UPDATED)
23. Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement. (arXiv:2203.03622v2 [eess.IV] UPDATED)
24. Complexity Reduction of Learned In-Loop Filtering in Video Coding. (arXiv:2203.08650v2 [eess.IV] UPDATED)
## cs.LG
---
**183** new papers in cs.LG:-) 
1. Physics-Informed Neural Networks with Adaptive Localized Artificial Viscosity. (arXiv:2203.08802v1 [physics.flu-dyn])
2. New directions for surrogate models and differentiable programming for High Energy Physics detector simulation. (arXiv:2203.08806v1 [hep-ph])
3. Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
4. Neural-Network-Directed Genetic Programmer for Discovery of Governing Equations. (arXiv:2203.08808v1 [cs.NE])
5. Semi-FedSER: Semi-supervised Learning for Speech Emotion Recognition On Federated Learning using Multiview Pseudo-Labeling. (arXiv:2203.08810v1 [eess.AS])
6. Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography. (arXiv:2203.08812v1 [eess.IV])
7. Example Perplexity. (arXiv:2203.08813v1 [cs.LG])
8. QUBOs for Sorting Lists and Building Trees. (arXiv:2203.08815v1 [cs.DS])
9. Hierarchical Clustering and Matrix Completion for the Reconstruction of World Input-Output Tables. (arXiv:2203.08819v1 [stat.ML])
10. DePS: An improved deep learning model for de novo peptide sequencing. (arXiv:2203.08820v1 [q-bio.QM])
11. Understanding robustness and generalization of artificial neural networks through Fourier masks. (arXiv:2203.08822v1 [cs.CV])
12. Discovering the building blocks of **dark** matter halo density profiles with neural networks. (arXiv:2203.08827v1 [astro-ph.CO])
13. Learning the Dynamics of Physical Systems from Sparse Observations with Finite Element Networks. (arXiv:2203.08852v1 [cs.LG])
14. Noisy Tensor Completion via Low-rank Tensor Ring. (arXiv:2203.08857v1 [stat.ML])
15. SC2: Supervised Compression for Split Computing. (arXiv:2203.08875v1 [cs.LG])
16. On Redundancy and Diversity in Cell-based Neural Architecture Search. (arXiv:2203.08887v1 [stat.ML])
17. The Mathematics of Artificial Intelligence. (arXiv:2203.08890v1 [cs.LG])
18. Multimodal Learning on Graphs for Disease Relation Extraction. (arXiv:2203.08893v1 [cs.LG])
19. Neural network processing of holographic images. (arXiv:2203.08898v1 [eess.IV])
20. Adversarial Support Alignment. (arXiv:2203.08908v1 [cs.LG])
21. Memorizing Transformers. (arXiv:2203.08913v1 [cs.LG])
22. $\ell_p$ Slack Norm Support Vector Data Description. (arXiv:2203.08932v1 [cs.LG])
23. Backpropagation through Time and Space: Learning Numerical Methods with Multi-Agent Reinforcement Learning. (arXiv:2203.08937v1 [cs.LG])
24. Provable Adversarial Robustness for Fractional Lp Threat Models. (arXiv:2203.08945v1 [cs.LG])
25. Latent-Variable Advantage-Weighted Policy Optimization for Offline RL. (arXiv:2203.08949v1 [cs.LG])
26. Meta-Learning of NAS for Few-shot Learning in Medical Image Applications. (arXiv:2203.08951v1 [cs.LG])
27. Risk-Averse No-Regret Learning in Online Convex Games. (arXiv:2203.08957v1 [cs.LG])
28. On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers. (arXiv:2203.08958v1 [cs.LG])
29. Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training. (arXiv:2203.08959v1 [cs.LG])
30. On the Convergence of Certified Robust Training with Interval Bound Propagation. (arXiv:2203.08961v1 [cs.LG])
31. 3D-UCaps: 3D Capsules Unet for Volumetric Image Segmentation. (arXiv:2203.08965v1 [cs.CV])
32. A Survey of Multi-Agent Reinforcement Learning with Communication. (arXiv:2203.08975v1 [cs.MA])
33. Adaptive n-ary Activation Functions for Probabilistic Boolean Logic. (arXiv:2203.08977v1 [cs.LG])
34. AI Autonomy: Self-Initiation, Adaptation and Continual Learning. (arXiv:2203.08994v1 [cs.AI])
35. Kan Extensions in Data Science and Machine Learning. (arXiv:2203.09018v1 [cs.LG])
36. Graph Augmentation Learning. (arXiv:2203.09020v1 [cs.LG])
37. Phased Flight Trajectory Prediction with Deep Learning. (arXiv:2203.09033v1 [cs.LG])
38. GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis. (arXiv:2203.09034v1 [cs.LG])
39. HybridNets: End-to-End Perception Network. (arXiv:2203.09035v1 [cs.CV])
40. Convert, compress, correct: Three steps toward communication-efficient DNN training. (arXiv:2203.09044v1 [cs.LG])
41. Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning. (arXiv:2203.09064v1 [cs.CV])
42. Do We Really Need a Learnable Classifier at the End of Deep Neural Network?. (arXiv:2203.09081v1 [cs.LG])
43. Confidence Dimension for Deep Learning based on Hoeffding Inequality and Relative Evaluation. (arXiv:2203.09082v1 [cs.LG])
44. DeepAD: A Robust Deep Learning Model of Alzheimer's Disease Progression for Real-World Clinical Applications. (arXiv:2203.09096v1 [cs.LG])
45. TMS: A Temporal Multi-scale Backbone Design for Speaker Embedding. (arXiv:2203.09098v1 [cs.SD])
46. MotionAug: Augmentation with Physical Correction for Human Motion Prediction. (arXiv:2203.09116v1 [cs.CV])
47. Time and the Value of Data. (arXiv:2203.09118v1 [cs.LG])
48. Improving the Transferability of Targeted Adversarial Examples through Object-Based Diverse Input. (arXiv:2203.09123v1 [cs.CV])
49. Are Vision Transformers Robust to Spurious Correlations?. (arXiv:2203.09125v1 [cs.CV])
50. Time Dependency, Data Flow, and Competitive Advantage. (arXiv:2203.09128v1 [cs.LG])
51. Contrastive Learning with Positive-Negative Frame Mask for Music Representation. (arXiv:2203.09129v1 [cs.SD])
52. Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning. (arXiv:2203.09137v1 [cs.LG])
53. Graph Representation Learning with Individualization and Refinement. (arXiv:2203.09141v1 [cs.LG])
54. Covid19 Reproduction Number: Credibility Intervals by Blockwise Proximal Monte Carlo Samplers. (arXiv:2203.09142v1 [cs.LG])
55. Prediction of speech intelligibility with DNN-based performance measures. (arXiv:2203.09148v1 [cs.SD])
56. Optimal Rejection Function Meets Character Recognition Tasks. (arXiv:2203.09151v1 [cs.CV])
57. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v1 [cs.CL])
58. On the Pitfalls of Heteroscedastic Uncertainty Estimation with Probabilistic Neural Networks. (arXiv:2203.09168v1 [cs.LG])
59. Recurrent Neural Networks for Forecasting Time Series with Multiple Seasonality: A Comparative Study. (arXiv:2203.09170v1 [cs.LG])
60. Nearest Neighbor Classifier with Margin Penalty for Active Learning. (arXiv:2203.09174v1 [cs.IR])
61. Generalized Classification of Satellite Image Time Series with Thermal Positional Encoding. (arXiv:2203.09175v1 [cs.CV])
62. Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed. (arXiv:2203.09179v1 [math.ST])
63. An Interactive Explanatory AI System for Industrial Quality Control. (arXiv:2203.09181v1 [cs.LG])
64. Investigation of Physics-Informed Deep Learning for the Prediction of Parametric, Three-Dimensional Flow Based on Boundary Data. (arXiv:2203.09204v1 [cs.LG])
65. SoK: Differential Privacy on Graph-Structured Data. (arXiv:2203.09205v1 [cs.CR])
66. On the Properties of Adversarially-Trained CNNs. (arXiv:2203.09243v1 [cs.CV])
67. Fine-tuning Global Model via Data-Free Knowledge Distillation for Non-IID Federated Learning. (arXiv:2203.09249v1 [cs.LG])
68. Symmetry-Based Representations for Artificial and Biological General Intelligence. (arXiv:2203.09250v1 [q-bio.NC])
69. Near Instance-Optimal PAC Reinforcement Learning for Deterministic MDPs. (arXiv:2203.09251v1 [cs.LG])
70. Visualizing Riemannian data with Rie-SNE. (arXiv:2203.09253v1 [cs.LG])
71. On the Spectral Bias of Convolutional Neural Tangent and Gaussian Process Kernels. (arXiv:2203.09255v1 [cs.LG])
72. Explainability in Graph Neural Networks: An Experimental Survey. (arXiv:2203.09258v1 [cs.LG])
73. Progressive Subsampling for Oversampled Data -- Application to Quantitative MRI. (arXiv:2203.09268v1 [eess.IV])
74. Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series. (arXiv:2203.09270v1 [stat.ML])
75. Stochastic and Private Nonconvex Outlier-Robust PCA. (arXiv:2203.09276v1 [cs.LG])
76. Transfer learning for cross-modal demand prediction of bike-share and public transit. (arXiv:2203.09279v1 [cs.LG])
77. Ranking of Communities in Multiplex Spatiotemporal Models of Brain Dynamics. (arXiv:2203.09281v1 [q-bio.NC])
78. PiDAn: A Coherence Optimization Approach for Backdoor Attack Detection and Mitigation in Deep Neural Networks. (arXiv:2203.09289v1 [cs.LG])
79. PreTR: Spatio-Temporal Non-Autoregressive Trajectory Prediction Transformer. (arXiv:2203.09293v1 [cs.CV])
80. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v1 [cs.CV])
81. Few-Shot Learning on Graphs: A Survey. (arXiv:2203.09308v1 [cs.LG])
82. Localizing Visual Sounds the Easy Way. (arXiv:2203.09324v1 [cs.CV])
83. CYBORGS: Contrastively Bootstrapping Object Representations by Grounding in Segmentation. (arXiv:2203.09343v1 [cs.CV])
84. Error estimates for physics informed neural networks approximating the Navier-Stokes equations. (arXiv:2203.09346v1 [math.NA])
85. Dimensionality Reduction and Wasserstein Stability for Kernel Regression. (arXiv:2203.09347v1 [stat.ML])
86. Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models. (arXiv:2203.09354v1 [cs.LG])
87. Semi-Markov Offline Reinforcement Learning for Healthcare. (arXiv:2203.09365v1 [cs.LG])
88. Gaussian initializations help deep variational quantum circuits escape from the barren plateau. (arXiv:2203.09376v1 [quant-ph])
89. Euler State Networks. (arXiv:2203.09382v1 [cs.LG])
90. When Chosen Wisely, More Data Is What You Need: A Universal Sample-Efficient Strategy For Data Augmentation. (arXiv:2203.09391v1 [cs.LG])
91. A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v1 [stat.ML])
92. Stability and Risk Bounds of Iterative Hard Thresholding. (arXiv:2203.09413v1 [stat.ML])
93. A Stochastic Halpern Iteration with Variance Reduction for Stochastic Monotone Inclusion Problems. (arXiv:2203.09436v1 [math.OC])
94. An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival. (arXiv:2203.09438v1 [cs.LG])
95. Image Super-Resolution With Deep Variational Autoencoders. (arXiv:2203.09445v1 [cs.CV])
96. Continual Learning Based on OOD Detection and Task Masking. (arXiv:2203.09450v1 [cs.CV])
97. MolNet: A Chemically Intuitive Graph Neural Network for Prediction of Molecular Properties. (arXiv:2203.09456v1 [physics.chem-ph])
98. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v1 [cs.CV])
99. Uncertainty with UAV Search of Multiple Goal-oriented Targets. (arXiv:2203.09476v1 [cs.RO])
100. A Decomposition-Based Hybrid Ensemble CNN Framework for Improving Cross-Subject EEG Decoding Performance. (arXiv:2203.09477v1 [eess.SP])
101. Diffusion Probabilistic Modeling for Video Generation. (arXiv:2203.09481v1 [cs.CV])
102. Defending Against Adversarial Attack in ECG Classification with Adversarial Distillation Training. (arXiv:2203.09487v1 [eess.SP])
103. Transframer: Arbitrary Frame Prediction with Generative Models. (arXiv:2203.09494v1 [cs.CV])
104. The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents. (arXiv:2203.09498v1 [cs.AI])
105. DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection. (arXiv:2203.09510v1 [cs.CV])
106. On Multi-Domain Long-Tailed Recognition, Generalization and Beyond. (arXiv:2203.09513v1 [cs.LG])
107. AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation. (arXiv:2203.09516v1 [cs.CV])
108. Adaptive Graph Auto-Encoder for General Data Clustering. (arXiv:2002.08648v5 [cs.LG] UPDATED)
109. Intracranial Hemorrhage Detection Using Neural Network Based Methods With Federated Learning. (arXiv:2005.08644v3 [cs.CV] UPDATED)
110. Bandit Labor Training. (arXiv:2006.06853v5 [cs.LG] UPDATED)
111. Augmented Sliced Wasserstein Distances. (arXiv:2006.08812v7 [cs.LG] UPDATED)
112. Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions. (arXiv:2008.07343v4 [cs.CY] UPDATED)
113. Towards Understanding Asynchronous Advantage Actor-critic: Convergence and Linear Speedup. (arXiv:2012.15511v2 [cs.LG] UPDATED)
114. Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model. (arXiv:2101.05467v3 [cs.LG] UPDATED)
115. CKConv: Continuous Kernel Convolution For Sequential Data. (arXiv:2102.02611v3 [cs.LG] UPDATED)
116. A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and Remedies. (arXiv:2102.07258v2 [cs.LG] UPDATED)
117. Topological Graph Neural Networks. (arXiv:2102.07835v4 [cs.LG] UPDATED)
118. Towards Personalized Federated Learning. (arXiv:2103.00710v3 [cs.LG] UPDATED)
119. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v5 [cs.CV] UPDATED)
120. GLM: General Language Model Pretraining with Autoregressive Blank Infilling. (arXiv:2103.10360v2 [cs.CL] UPDATED)
121. Generating Novel Scene Compositions from Single Images and Videos. (arXiv:2103.13389v3 [cs.CV] UPDATED)
122. Unsupervised Instance Selection with Low-Label, Supervised Learning for Outlier Detection. (arXiv:2104.12837v2 [cs.LG] UPDATED)
123. Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts. (arXiv:2105.03363v3 [cs.LG] UPDATED)
124. Meta-Learning with Fewer Tasks through Task Interpolation. (arXiv:2106.02695v2 [cs.LG] UPDATED)
125. Self-Supervised Metric Learning in Multi-View Data: A Downstream Task Perspective. (arXiv:2106.07138v4 [stat.ML] UPDATED)
126. Probabilistic Margins for Instance Reweighting in Adversarial Training. (arXiv:2106.07904v2 [cs.LG] UPDATED)
127. How Low Can We Go: Trading Memory for Error in Low-Precision Training. (arXiv:2106.09686v3 [cs.LG] UPDATED)
128. BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models. (arXiv:2106.10199v3 [cs.LG] UPDATED)
129. Pure Exploration in Kernel and Neural Bandits. (arXiv:2106.12034v2 [stat.ML] UPDATED)
130. Markov Decision Process modeled with Bandits for Sequential Decision Making in Linear-flow. (arXiv:2107.00204v2 [cs.LG] UPDATED)
131. Out-of-distribution Generalization in the Presence of Nuisance-Induced Spurious Correlations. (arXiv:2107.00520v4 [cs.LG] UPDATED)
132. Understanding Intrinsic Robustness Using Label Uncertainty. (arXiv:2107.03250v2 [cs.LG] UPDATED)
133. Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
134. On Constraints in First-Order Optimization: A View from Non-Smooth Dynamical Systems. (arXiv:2107.08225v2 [math.OC] UPDATED)
135. Small-Text: Active Learning for Text Classification in Python. (arXiv:2107.10314v3 [cs.LG] UPDATED)
136. Recurrent Neural Network-based Internal Model Control design for stable nonlinear systems. (arXiv:2108.04585v3 [cs.LG] UPDATED)
137. Excited state, non-adiabatic dynamics of large photoswitchable molecules using a chemically transferable machine learning potential. (arXiv:2108.04879v3 [physics.chem-ph] UPDATED)
138. SimVLM: Simple Visual Language Model Pretraining with Weak Supervision. (arXiv:2108.10904v2 [cs.CV] UPDATED)
139. Near Instance Optimal Model Selection for Pure Exploration Linear Bandits. (arXiv:2109.05131v2 [stat.ML] UPDATED)
140. Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking for Smart Cities. (arXiv:2109.11661v2 [cs.LG] UPDATED)
141. Equivariant Subgraph Aggregation Networks. (arXiv:2110.02910v3 [cs.LG] UPDATED)
142. Fine-grained style control in Transformer-based Text-to-speech Synthesis. (arXiv:2110.06306v2 [eess.AS] UPDATED)
143. FILM: Following Instructions in Language with Modular Methods. (arXiv:2110.07342v3 [cs.CL] UPDATED)
144. FlexConv: Continuous Kernel Convolutions with Differentiable Kernel Sizes. (arXiv:2110.08059v3 [cs.CV] UPDATED)
145. Multitask Prompted Training Enables Zero-Shot Task Generalization. (arXiv:2110.08207v3 [cs.LG] UPDATED)
146. Accelerating Training and Inference of Graph Neural Networks with Fast Sampling and Pipelining. (arXiv:2110.08450v2 [cs.LG] UPDATED)
147. A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning. (arXiv:2110.08465v3 [cs.LG] UPDATED)
148. Deep Generative Models in Engineering Design: A Review. (arXiv:2110.10863v4 [cs.LG] UPDATED)
149. A Novel Sleep Stage Classification Using CNN Generated by an Efficient Neural Architecture Search with a New Data Processing Trick. (arXiv:2110.15277v2 [eess.SP] UPDATED)
150. Latent Structure Mining with Contrastive Modality Fusion for Multimedia Recommendation. (arXiv:2111.00678v2 [cs.IR] UPDATED)
151. Bayesian Framework for Gradient Leakage. (arXiv:2111.04706v2 [cs.LG] UPDATED)
152. Reachability analysis of neural networks using mixed monotonicity. (arXiv:2111.07683v2 [eess.SY] UPDATED)
153. Personalized Federated Learning through Local Memorization. (arXiv:2111.09360v2 [cs.LG] UPDATED)
154. Learning Long-Term Reward Redistribution via Randomized Return Decomposition. (arXiv:2111.13485v2 [cs.LG] UPDATED)
155. Local Citation Recommendation with Hierarchical-Attention Text Encoder and SciBERT-based Reranking. (arXiv:2112.01206v3 [cs.IR] UPDATED)
156. Dynamic fracture of a bicontinuously nanostructured copolymer: A deep-learning analysis of big-data-generating experiment. (arXiv:2112.01971v2 [cond-mat.mtrl-sci] UPDATED)
157. Training Structured Neural Networks Through Manifold Identification and Variance Reduction. (arXiv:2112.02612v2 [cs.LG] UPDATED)
158. FourierMask: Instance Segmentation using Fourier Mapping in Implicit Neural Networks. (arXiv:2112.12535v2 [cs.CV] UPDATED)
159. SeMask: Semantically Masked Transformers for Semantic Segmentation. (arXiv:2112.12782v2 [cs.CV] UPDATED)
160. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v3 [eess.IV] UPDATED)
161. Calibration of P-values for calibration and for deviation of a subpopulation from the full population. (arXiv:2202.00100v3 [stat.ME] UPDATED)
162. EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction. (arXiv:2202.05146v2 [q-bio.BM] UPDATED)
163. Improving Human Sperm Head Morphology Classification with Unsupervised Anatomical Feature Distillation. (arXiv:2202.07191v3 [cs.CV] UPDATED)
164. Speaker Adaptation Using Spectro-Temporal Deep Features for Dysarthric and Elderly Speech Recognition. (arXiv:2202.10290v3 [eess.AS] UPDATED)
165. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v2 [cs.CV] UPDATED)
166. The Machine Learning for Combinatorial Optimization Competition (ML4CO): Results and Insights. (arXiv:2203.02433v2 [cs.LG] UPDATED)
167. P2M: A Processing-in-Pixel-in-Memory Paradigm for Resource-Constrained TinyML Applications. (arXiv:2203.04737v2 [cs.LG] UPDATED)
168. Optimal Methods for Risk Averse Distributed Optimization. (arXiv:2203.05117v2 [math.OC] UPDATED)
169. Learning from humans: combining imitation and deep reinforcement learning to accomplish human-level performance on a virtual foraging task. (arXiv:2203.06250v2 [cs.LG] UPDATED)
170. Symbolic Learning to Optimize: Towards Interpretability and Scalability. (arXiv:2203.06578v2 [cs.LG] UPDATED)
171. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
172. Extracting associations and meanings of objects depicted in artworks through bi-modal deep networks. (arXiv:2203.07026v2 [cs.CV] UPDATED)
173. Orchestrated Value Mapping for Reinforcement Learning. (arXiv:2203.07171v2 [cs.LG] UPDATED)
174. Toward the Detection of Polyglot Files. (arXiv:2203.07561v2 [cs.CR] UPDATED)
175. A Survey of Non-Rigid 3D Registration. (arXiv:2203.07858v2 [cs.CV] UPDATED)
176. Threat Detection for General Social Engineering Attack Using Machine Learning Techniques. (arXiv:2203.07933v2 [cs.CR] UPDATED)
177. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v2 [cs.CV] UPDATED)
178. Practical data monitoring in the internet-services domain. (arXiv:2203.08067v2 [cs.LG] UPDATED)
179. Playing with blocks: Toward re-usable deep learning models for side-channel profiled attacks. (arXiv:2203.08448v2 [cs.CR] UPDATED)
180. The Structured Abstain Problem and the Lov\'asz Hinge. (arXiv:2203.08645v2 [cs.LG] UPDATED)
181. Distributed-Memory Sparse Kernels for Machine Learning. (arXiv:2203.07673v1 [cs.DC] CROSS LISTED)
182. Sensitivity Estimation for **Dark** Matter Subhalos in Synthetic Gaia DR2 using Deep Learning. (arXiv:2203.08161v1 [astro-ph.GA] CROSS LISTED)
183. Counterfactual Inference of Second Opinions. (arXiv:2203.08653v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**81** new papers in cs.AI:-) 
1. Disparities in Dermatology AI Performance on a Diverse, Curated Clinical Image Set. (arXiv:2203.08807v1 [eess.IV])
2. Self-Supervised Deep Learning to Enhance Breast Cancer Detection on Screening Mammography. (arXiv:2203.08812v1 [eess.IV])
3. Example Perplexity. (arXiv:2203.08813v1 [cs.LG])
4. Discovering the building blocks of **dark** matter halo density profiles with neural networks. (arXiv:2203.08827v1 [astro-ph.CO])
5. Noisy Tensor Completion via Low-rank Tensor Ring. (arXiv:2203.08857v1 [stat.ML])
6. Layer Ensembles: A Single-Pass Uncertainty Estimation in Deep Learning for Segmentation. (arXiv:2203.08878v1 [cs.CV])
7. On Redundancy and Diversity in Cell-based Neural Architecture Search. (arXiv:2203.08887v1 [stat.ML])
8. Multimodal Learning on Graphs for Disease Relation Extraction. (arXiv:2203.08893v1 [cs.LG])
9. Explaining Preference-driven Schedules: the EXPRES Framework. (arXiv:2203.08895v1 [cs.AI])
10. Memorizing Transformers. (arXiv:2203.08913v1 [cs.LG])
11. Automated Grading of Radiographic Knee Osteoarthritis Severity Combined with Joint Space Narrowing. (arXiv:2203.08914v1 [cs.CV])
12. BPE vs. Morphological Segmentation: A Case Study on Machine Translation of Four Polysynthetic Languages. (arXiv:2203.08954v1 [cs.CL])
13. On the Usefulness of the Fit-on-the-Test View on Evaluating Calibration of Classifiers. (arXiv:2203.08958v1 [cs.LG])
14. Adaptive n-ary Activation Functions for Probabilistic Boolean Logic. (arXiv:2203.08977v1 [cs.LG])
15. AdaLoGN: Adaptive Logic Graph Network for Reasoning-Based Machine Reading Comprehension. (arXiv:2203.08992v1 [cs.CL])
16. AI Autonomy: Self-Initiation, Adaptation and Continual Learning. (arXiv:2203.08994v1 [cs.AI])
17. Graph Augmentation Learning. (arXiv:2203.09020v1 [cs.LG])
18. DU-VLG: Unifying Vision-and-Language Generation via Dual Sequence-to-Sequence Pre-training. (arXiv:2203.09052v1 [cs.CV])
19. Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework. (arXiv:2203.09053v1 [cs.CL])
20. Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-shot Learning. (arXiv:2203.09064v1 [cs.CV])
21. Gaussian Multi-head Attention for Simultaneous Machine Translation. (arXiv:2203.09072v1 [cs.CL])
22. CodeReviewer: Pre-Training for Automating Code Review Activities. (arXiv:2203.09095v1 [cs.SE])
23. Knowledge Graph-Enabled Text-Based Automatic Personality Prediction. (arXiv:2203.09103v1 [cs.CL])
24. Causal Robot Communication Inspired by Observational Learning Insights. (arXiv:2203.09114v1 [cs.RO])
25. Are Vision Transformers Robust to Spurious Correlations?. (arXiv:2203.09125v1 [cs.CV])
26. Conversational Recommendation: A Grand AI Challenge. (arXiv:2203.09126v1 [cs.AI])
27. POLARIS: A Geographic Pre-trained Model and its Applications in Baidu Maps. (arXiv:2203.09127v1 [cs.CL])
28. Prediction of speech intelligibility with DNN-based performance measures. (arXiv:2203.09148v1 [cs.SD])
29. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v1 [cs.CL])
30. Modeling Dual Read/Write Paths for Simultaneous Machine Translation. (arXiv:2203.09163v1 [cs.CL])
31. A Novel End-To-End Network for Reconstruction of Non-Regularly Sampled Image Data Using Locally Fully Connected Layers. (arXiv:2203.09180v1 [eess.IV])
32. RoMe: A Robust Metric for Evaluating Natural Language Generation. (arXiv:2203.09183v1 [cs.CL])
33. SoK: Differential Privacy on Graph-Structured Data. (arXiv:2203.09205v1 [cs.CR])
34. Symmetry-Based Representations for Artificial and Biological General Intelligence. (arXiv:2203.09250v1 [q-bio.NC])
35. On the Spectral Bias of Convolutional Neural Tangent and Gaussian Process Kernels. (arXiv:2203.09255v1 [cs.LG])
36. Explainability in Graph Neural Networks: An Experimental Survey. (arXiv:2203.09258v1 [cs.LG])
37. Mixing Up Contrastive Learning: Self-Supervised Representation Learning for Time Series. (arXiv:2203.09270v1 [stat.ML])
38. Knowledge Graph Embedding Methods for Entity Alignment: An Experimental Review. (arXiv:2203.09280v1 [cs.DB])
39. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v1 [cs.CV])
40. EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training. (arXiv:2203.09313v1 [cs.CL])
41. CYBORGS: Contrastively Bootstrapping Object Representations by Grounding in Segmentation. (arXiv:2203.09343v1 [cs.CV])
42. Context-Dependent Anomaly Detection with Knowledge Graph Embedding Models. (arXiv:2203.09354v1 [cs.LG])
43. Expressivity of Planning with Horn Description Logic Ontologies (Technical Report). (arXiv:2203.09361v1 [cs.AI])
44. Euler State Networks. (arXiv:2203.09382v1 [cs.LG])
45. Learning of Structurally Unambiguous Probabilistic Grammars. (arXiv:2203.09441v1 [cs.LO])
46. MolNet: A Chemically Intuitive Graph Neural Network for Prediction of Molecular Properties. (arXiv:2203.09456v1 [physics.chem-ph])
47. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v1 [cs.CV])
48. Uncertainty with UAV Search of Multiple Goal-oriented Targets. (arXiv:2203.09476v1 [cs.RO])
49. The Frost Hollow Experiments: Pavlovian Signalling as a Path to Coordination and Communication Between Agents. (arXiv:2203.09498v1 [cs.AI])
50. Towards Data-Efficient Detection Transformers. (arXiv:2203.09507v1 [cs.CV])
51. DetMatch: Two Teachers are Better Than One for Joint 2D and 3D Semi-Supervised Object Detection. (arXiv:2203.09510v1 [cs.CV])
52. On Multi-Domain Long-Tailed Recognition, Generalization and Beyond. (arXiv:2203.09513v1 [cs.LG])
53. Wavelet-based Temporal Models of Human Activity for Anomaly Detection in Smart Robot-assisted Environments. (arXiv:2002.11503v2 [cs.AI] UPDATED)
54. Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions. (arXiv:2008.07343v4 [cs.CY] UPDATED)
55. Semantic-preserving Reinforcement Learning Attack Against Graph Neural Networks for Malware Detection. (arXiv:2009.05602v3 [cs.CR] UPDATED)
56. Everyone Knows that Everyone Knows: Gossip Protocols for Super Experts. (arXiv:2011.13203v2 [cs.AI] UPDATED)
57. Nominal Unification and Matching of Higher Order Expressions with Recursive Let. (arXiv:2102.08146v3 [cs.LO] UPDATED)
58. Towards Personalized Federated Learning. (arXiv:2103.00710v3 [cs.LG] UPDATED)
59. Revisiting the Loss Weight Adjustment in Object Detection. (arXiv:2103.09488v4 [cs.CV] UPDATED)
60. GLM: General Language Model Pretraining with Autoregressive Blank Infilling. (arXiv:2103.10360v2 [cs.CL] UPDATED)
61. Unsupervised Instance Selection with Low-Label, Supervised Learning for Outlier Detection. (arXiv:2104.12837v2 [cs.LG] UPDATED)
62. Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts. (arXiv:2105.03363v3 [cs.LG] UPDATED)
63. How Low Can We Go: Trading Memory for Error in Low-Precision Training. (arXiv:2106.09686v3 [cs.LG] UPDATED)
64. A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v4 [cs.CL] UPDATED)
65. Source-Free Adaptation to Measurement Shift via Bottom-Up Feature **Restoration**. (arXiv:2107.05446v3 [cs.LG] UPDATED)
66. Deep Reinforcement Learning-Based Long-Range Autonomous Valet Parking for Smart Cities. (arXiv:2109.11661v2 [cs.LG] UPDATED)
67. Accelerating Training and Inference of Graph Neural Networks with Fast Sampling and Pipelining. (arXiv:2110.08450v2 [cs.LG] UPDATED)
68. Learning Long-Term Reward Redistribution via Randomized Return Decomposition. (arXiv:2111.13485v2 [cs.LG] UPDATED)
69. CrossLoc: Scalable Aerial Localization Assisted by Multimodal Synthetic Data. (arXiv:2112.09081v2 [cs.CV] UPDATED)
70. Safe Equilibrium. (arXiv:2201.04266v4 [cs.GT] UPDATED)
71. Enhancing Pseudo Label Quality for Semi-Supervised Domain-Generalized Medical Image Segmentation. (arXiv:2201.08657v2 [cs.CV] UPDATED)
72. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v3 [cs.CV] UPDATED)
73. Speaker Adaptation Using Spectro-Temporal Deep Features for Dysarthric and Elderly Speech Recognition. (arXiv:2202.10290v3 [eess.AS] UPDATED)
74. Confidence Based Bidirectional Global Context Aware Training Framework for Neural Machine Translation. (arXiv:2202.13663v3 [cs.CL] UPDATED)
75. OneRel:Joint Entity and Relation Extraction with One Module in One Step. (arXiv:2203.05412v2 [cs.CL] UPDATED)
76. Symbolic Learning to Optimize: Towards Interpretability and Scalability. (arXiv:2203.06578v2 [cs.LG] UPDATED)
77. Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs. (arXiv:2203.06717v2 [cs.CV] UPDATED)
78. Efficient Language Modeling with Sparse all-MLP. (arXiv:2203.06850v2 [cs.CL] UPDATED)
79. Orchestrated Value Mapping for Reinforcement Learning. (arXiv:2203.07171v2 [cs.LG] UPDATED)
80. Show Me More Details: Discovering Hierarchies of Procedures from Semi-structured Web Data. (arXiv:2203.07264v2 [cs.CL] UPDATED)
81. RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion. (arXiv:2203.07993v2 [cs.AI] UPDATED)

