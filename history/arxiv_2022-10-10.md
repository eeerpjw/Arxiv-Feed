# Your interest papers
---
## cs.CV
---
### A Keypoint Based **Enhancement** Method for Audio Driven Free View Talking Head Synthesis. (arXiv:2210.03335v1 [cs.CV])
- Authors : Yichen Han, Ya Li, Yingming Gao, Jinlong Xue, Songpo Wang, Lei Yang
- Link : [http://arxiv.org/abs/2210.03335](http://arxiv.org/abs/2210.03335)
> ABSTRACT  :  Audio driven talking head synthesis is a challenging task that attracts increasing attention in recent years. Although existing methods based on 2D landmarks or 3D face models can synthesize accurate lip synchronization and rhythmic head pose for arbitrary identity, they still have limitations, such as the cut feeling in the mouth mapping and the lack of skin highlights. The morphed region is blurry compared to the surrounding face. A Keypoint Based **Enhancement** (KPBE) method is proposed for audio driven free view talking head synthesis to improve the naturalness of the generated video. Firstly, existing methods were used as the backend to synthesize intermediate results. Then we used keypoint decomposition to extract video synthesis controlling parameters from the backend output and the source image. After that, the controlling parameters were composited to the source keypoints and the driving keypoints. A motion field based method was used to generate the final image from the keypoint representation. With keypoint representation, we overcame the cut feeling in the mouth mapping and the lack of skin highlights. Experiments show that our proposed **enhancement** method improved the quality of talking-head videos in terms of mean opinion score.  
### A Simple Plugin for Transforming Images to Arbitrary Scales. (arXiv:2210.03417v1 [cs.CV])
- Authors : Qinye Zhou, Ziyi Li, Weidi Xie, Xiaoyun Zhang, Ya Zhang, Yanfeng Wang
- Link : [http://arxiv.org/abs/2210.03417](http://arxiv.org/abs/2210.03417)
> ABSTRACT  :  Existing models on super-resolution often specialized for one scale, fundamentally limiting their use in practical scenarios. In this paper, we aim to develop a general plugin that can be inserted into existing super-resolution models, conveniently augmenting their ability towards Arbitrary Resolution Image Scaling, thus termed ARIS. We make the following contributions: (i) we propose a transformer-based plugin module, which uses spatial coordinates as query, iteratively attend the low-resolution image feature through cross-attention, and output visual feature for the queried spatial location, resembling an implicit representation for images; (ii) we introduce a novel self-supervised training scheme, that exploits consistency constraints to effectively augment the model's ability for upsampling images towards unseen scales, i.e. ground-truth high-resolution images are not available; (iii) without loss of generality, we inject the proposed ARIS plugin module into several existing models, namely, IPT, **Swin**IR, and HAT, showing that the resulting models can not only maintain their original performance on fixed scale factor but also extrapolate to unseen scales, substantially outperforming existing any-scale super-resolution models on standard benchmarks, e.g. Urban100, DIV2K, etc.  
### Key Information Extraction in Purchase Documents using Deep Learning and Rule-based Corrections. (arXiv:2210.03453v1 [cs.CV])
- Authors : Roberto Arroyo, Javier Yebes, Elena Mart, ctor Corrales, Javier Lorenzo
- Link : [http://arxiv.org/abs/2210.03453](http://arxiv.org/abs/2210.03453)
> ABSTRACT  :  Deep Learning (DL) is dominating the fields of Natural Language Processing (NLP) and Computer Vision (CV) in the recent times. However, DL commonly relies on the availability of large data annotations, so other alternative or complementary pattern-based techniques can help to improve results. In this paper, we build upon Key Information Extraction (KIE) in purchase documents using both DL and rule-based corrections. Our system initially trusts on Optical Character Recognition (OCR) and text understanding based on entity tagging to identify purchase facts of interest (e.g., product codes, descriptions, quantities, or prices). These facts are then linked to a same product group, which is recognized by means of line detection and some grouping heuristics. Once these DL approaches are processed, we contribute several mechanisms consisting of rule-based corrections for improving the baseline DL predictions. We prove the **enhancement**s provided by these rule-based corrections over the baseline DL results in the presented experiments for purchase documents from public and NielsenIQ datasets.  
### Compressing Video Calls using Synthetic Talking Heads. (arXiv:2210.03692v1 [cs.CV])
- Authors : Madhav Agarwal, Anchit Gupta, Rudrabha Mukhopadhyay
- Link : [http://arxiv.org/abs/2210.03692](http://arxiv.org/abs/2210.03692)
> ABSTRACT  :  We leverage the modern advancements in talking head generation to propose an end-to-end system for talking head video compression. Our algorithm transmits pivot frames intermittently while the rest of the talking head video is generated by animating them. We use a state-of-the-art face reenactment network to detect key points in the non-pivot frames and transmit them to the receiver. A dense flow is then calculated to warp a pivot frame to reconstruct the non-pivot ones. Transmitting key points instead of full frames leads to significant compression. We propose a novel algorithm to adaptively select the best-suited pivot frames at regular intervals to provide a smooth experience. We also propose a frame-interpolater at the receiver's end to improve the compression levels further. Finally, a face **enhancement** network improves reconstruction quality, significantly improving several aspects like the sharpness of the generations. We evaluate our method both qualitatively and quantitatively on benchmark datasets and compare it with multiple compression techniques. We release a demo video and additional information at https://cvit.iiit.ac.in/research/projects/cvit-projects/talking-video-compression.  
### MUAD: Multiple Uncertainties for Autonomous Driving, a benchmark for multiple uncertainty types and tasks. (arXiv:2203.01437v2 [cs.CV] UPDATED)
- Authors : Gianni Franchi, Xuanlong Yu, Andrei Bursuc, Angel Tena, mi Kazmierczak, verine Dubuisson, Emanuel Aldea, David Filliat
- Link : [http://arxiv.org/abs/2203.01437](http://arxiv.org/abs/2203.01437)
> ABSTRACT  :  Predictive uncertainty estimation is essential for safe deployment of Deep Neural Networks in real-world autonomous systems. However, disentangling the different types and sources of uncertainty is non trivial for most datasets, especially since there is no ground truth for uncertainty. In addition, while adverse weather conditions of varying intensities can disrupt neural network predictions, they are usually under-represented in both training and test sets in public datasets.We attempt to mitigate these setbacks and introduce the MUAD dataset (Multiple Uncertainties for Autonomous Driving), consisting of 10,413 realistic synthetic images with diverse adverse weather conditions (**night**, fog, rain, snow), out-of-distribution objects, and annotations for semantic segmentation, depth estimation, object, and instance detection. MUAD allows to better assess the impact of different sources of uncertainty on model performance. We conduct a thorough experimental study of this impact on several baseline Deep Neural Networks across multiple tasks, and release our dataset to allow researchers to benchmark their algorithm methodically in adverse conditions. More visualizations and the download link for MUAD are available at https://muad-dataset.github.io/.  
### HunYuan_tvr for Text-Video Retrieval. (arXiv:2204.03382v6 [cs.CV] UPDATED)
- Authors : Shaobo Min, Weijie Kong, Cheng Tu, Dihong Gong, Chengfei Cai, Wenzhe Zhao, Chenyang Liu, Sixiao Zheng, Hongfa Wang, Zhifeng Li, Wei Liu
- Link : [http://arxiv.org/abs/2204.03382](http://arxiv.org/abs/2204.03382)
> ABSTRACT  :  Text-Video Retrieval plays an important role in multi-modal understanding and has attracted increasing attention in recent years. Most existing methods focus on constructing contrastive pairs between whole videos and complete caption sentences, while ignoring fine-grained cross-modal relationships, e.g., short clips and phrases or single frame and word. In this paper, we propose a novel method, named HunYuan\_tvr, to explore hierarchical cross-modal interactions by simultaneously exploring video-sentence, clip-phrase, and frame-word relationships. Considering intrinsic semantic relations between frames, HunYuan\_tvr first performs self-attention to explore frame-wise correlations and adaptively clusters correlated frames into clip-level representations. Then, the clip-wise correlation is explored to aggregate clip representations into a compact one to describe the video globally. In this way, we can construct hierarchical video representations for frame-clip-video granularities, and also explore word-wise correlations to form word-phrase-sentence embeddings for the text modality. Finally, hierarchical contrastive learning is designed to explore cross-modal relationships,~\emph{i.e.,} frame-word, clip-phrase, and video-sentence, which enables HunYuan\_tvr to achieve a comprehensive multi-modal understanding. Further boosted by adaptive label denoising and marginal sample **enhancement**, HunYuan\_tvr obtains new state-of-the-art results on various benchmarks, e.g., Rank@1 of 55.0%, 57.8%, 29.7%, 52.1%, and 57.3% on MSR-VTT, MSVD, LSMDC, DiDemo, and ActivityNet respectively.  
### Seeing Through The Noisy **Dark**: Toward Real-world **Low-Light** Image **Enhancement** and Denoising. (arXiv:2210.00545v2 [cs.CV] UPDATED)
- Authors : Jiahuan Ren, Zhao Zhang, Richang Hong, Mingliang Xu, Yi Yang, Shuicheng Yan
- Link : [http://arxiv.org/abs/2210.00545](http://arxiv.org/abs/2210.00545)
> ABSTRACT  :  Images collected in real-world **low-light** environment usually suffer from lower visibility and heavier noise, due to the insufficient light or hardware limitation. While existing **low-light** image **enhancement** (LLIE) methods basically ignored the noise interference and mainly focus on refining the illumination of the **low-light** images based on benchmarked noise-negligible datasets. Such operations will make them inept for the real-world LLIE (RLLIE) with heavy noise, and result in speckle noise and blur in the enhanced images. Although several LLIE methods considered the noise in **low-light** image, they are trained on the raw data and hence cannot be used for sRGB images, since the domains of data are different and lack of expertise or unknown protocols. In this paper, we clearly consider the task of seeing through the noisy **dark** in sRGB color space, and propose a novel end-to-end method termed Real-world **Low-light** **Enhancement** &amp; Denoising Network (RLED-Net). Since natural images can usually be characterized by low-rank subspaces in which the redundant information and noise can be removed, we design a Latent Subspace Reconstruction Block (LSRB) for feature extraction and denoising. To reduce the loss of global feature (e.g., color/shape information) and extract more accurate local features (e.g., edge/texture information), we also present a basic layer with two branches, called Cross-channel &amp; Shift-window Transformer (CST). Based on the CST, we further present a new backbone to design a U-structure Network (CSTNet) for deep feature recovery, and also design a Feature Refine Block (FRB) to refine the final features. Extensive experiments on real noisy images and public databases verified the effectiveness of our RLED-Net for both RLLIE and denoising.  
## eess.IV
---
## cs.LG
---
### Spiking neural network for nonlinear regression. (arXiv:2210.03515v1 [cs.NE])
- Authors : Alexander Henkes, Henning Wessels
- Link : [http://arxiv.org/abs/2210.03515](http://arxiv.org/abs/2210.03515)
> ABSTRACT  :  Spiking neural networks, also often referred to as the third generation of neural networks, carry the potential for a massive reduction in memory and energy consumption over traditional, second-generation neural networks. Inspired by the undisputed efficiency of the human brain, they introduce temporal and neuronal sparsity, which can be exploited by next-generation neuromorphic hardware. To open the pathway toward engineering applications, we introduce this exciting technology in the context of continuum mechanics. However, the nature of spiking neural networks poses a challenge for regression problems, which frequently arise in the modeling of engineering sciences. To overcome this problem, a framework for regression using spiking neural networks is proposed. In particular, a network topology for decoding binary spike trains to real numbers is introduced, utilizing the membrane potential of spiking neurons. As the aim of this contribution is a concise introduction to this new methodology, several different spiking neural architectures, ranging from simple spiking feed-forward to complex spiking long short-term memory neural networks, are derived. Several numerical experiments directed towards regression of linear and nonlinear, history-dependent material models are carried out. A direct comparison with counterparts of traditional neural networks shows that the proposed framework is much more efficient while retaining precision and generalizability. All code has been made publicly available in the interest of reproducibility and to promote continued **enhancement** in this new domain.  
### Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models. (arXiv:2202.04173v2 [cs.CL] UPDATED)
- Authors : Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro
- Link : [http://arxiv.org/abs/2202.04173](http://arxiv.org/abs/2202.04173)
> ABSTRACT  :  Pre-trained language models (LMs) are shown to easily generate toxic language. In this work, we systematically explore domain-adaptive training to reduce the toxicity of language models. We conduct this study on three dimensions: training corpus, model size, and parameter efficiency. For the training corpus, we propose to leverage the generative power of LMs and generate nontoxic datasets for domain-adaptive training, which mitigates the **exposure** bias and is shown to be more data-efficient than using a curated pre-training corpus. We demonstrate that the self-generation method consistently outperforms the existing baselines across various model sizes on both automatic and human evaluations, even when it uses a 1/3 smaller training corpus. We then comprehensively study detoxifying LMs with parameter sizes ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never been studied before. We find that i) large LMs have similar toxicity levels as smaller ones given the same pre-training corpus, and ii) large LMs require more endeavor to detoxify. We also explore parameter-efficient training methods for detoxification. We demonstrate that adding and training adapter-only layers in LMs not only saves a lot of parameters but also achieves a better trade-off between toxicity and perplexity than whole model adaptation for the large-scale models.  
### Efficient Neural Neighborhood Search for Pickup and Delivery Problems. (arXiv:2204.11399v3 [cs.LG] UPDATED)
- Authors : Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Hongliang Guo, Yuejiao Gong, Yeow Meng
- Link : [http://arxiv.org/abs/2204.11399](http://arxiv.org/abs/2204.11399)
> ABSTRACT  :  We present an efficient Neural Neighborhood Search (N2S) approach for pickup and delivery problems (PDPs). In specific, we design a powerful Synthesis Attention that allows the vanilla self-attention to synthesize various types of features regarding a route solution. We also exploit two customized decoders that automatically learn to perform removal and reinsertion of a pickup-delivery node pair to tackle the precedence constraint. Additionally, a diversity **enhancement** scheme is leveraged to further ameliorate the performance. Our N2S is generic, and extensive experiments on two canonical PDP variants show that it can produce state-of-the-art results among existing neural methods. Moreover, it even outstrips the well-known LKH3 solver on the more constrained PDP variant. Our implementation for N2S is available online.  
## cs.AI
---
### Zero-shot stance detection based on cross-domain feature **enhancement** by contrastive learning. (arXiv:2210.03380v1 [cs.CL])
- Authors : Xuechen Zhao, Jiaying Zou, Zhong Zhang, Feng Xie, Bin Zhou, Lei Tian
- Link : [http://arxiv.org/abs/2210.03380](http://arxiv.org/abs/2210.03380)
> ABSTRACT  :  Zero-shot stance detection is challenging because it requires detecting the stance of previously unseen targets in the inference phase. The ability to learn transferable target-invariant features is critical for zero-shot stance detection. In this work, we propose a stance detection approach that can efficiently adapt to unseen targets, the core of which is to capture target-invariant syntactic expression patterns as transferable knowledge. Specifically, we first augment the data by masking the topic words of sentences, and then feed the augmented data to an unsupervised contrastive learning module to capture transferable features. Then, to fit a specific target, we encode the raw texts as target-specific features. Finally, we adopt an attention mechanism, which combines syntactic expression patterns with target-specific features to obtain enhanced features for predicting previously unseen targets. Experiments demonstrate that our model outperforms competitive baselines on four benchmark datasets.  
### Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models. (arXiv:2202.04173v2 [cs.CL] UPDATED)
- Authors : Boxin Wang, Wei Ping, Chaowei Xiao, Peng Xu, Mostofa Patwary, Mohammad Shoeybi, Bo Li, Anima Anandkumar, Bryan Catanzaro
- Link : [http://arxiv.org/abs/2202.04173](http://arxiv.org/abs/2202.04173)
> ABSTRACT  :  Pre-trained language models (LMs) are shown to easily generate toxic language. In this work, we systematically explore domain-adaptive training to reduce the toxicity of language models. We conduct this study on three dimensions: training corpus, model size, and parameter efficiency. For the training corpus, we propose to leverage the generative power of LMs and generate nontoxic datasets for domain-adaptive training, which mitigates the **exposure** bias and is shown to be more data-efficient than using a curated pre-training corpus. We demonstrate that the self-generation method consistently outperforms the existing baselines across various model sizes on both automatic and human evaluations, even when it uses a 1/3 smaller training corpus. We then comprehensively study detoxifying LMs with parameter sizes ranging from 126M up to 530B (3x larger than GPT-3), a scale that has never been studied before. We find that i) large LMs have similar toxicity levels as smaller ones given the same pre-training corpus, and ii) large LMs require more endeavor to detoxify. We also explore parameter-efficient training methods for detoxification. We demonstrate that adding and training adapter-only layers in LMs not only saves a lot of parameters but also achieves a better trade-off between toxicity and perplexity than whole model adaptation for the large-scale models.  
### Efficient Neural Neighborhood Search for Pickup and Delivery Problems. (arXiv:2204.11399v3 [cs.LG] UPDATED)
- Authors : Yining Ma, Jingwen Li, Zhiguang Cao, Wen Song, Hongliang Guo, Yuejiao Gong, Yeow Meng
- Link : [http://arxiv.org/abs/2204.11399](http://arxiv.org/abs/2204.11399)
> ABSTRACT  :  We present an efficient Neural Neighborhood Search (N2S) approach for pickup and delivery problems (PDPs). In specific, we design a powerful Synthesis Attention that allows the vanilla self-attention to synthesize various types of features regarding a route solution. We also exploit two customized decoders that automatically learn to perform removal and reinsertion of a pickup-delivery node pair to tackle the precedence constraint. Additionally, a diversity **enhancement** scheme is leveraged to further ameliorate the performance. Our N2S is generic, and extensive experiments on two canonical PDP variants show that it can produce state-of-the-art results among existing neural methods. Moreover, it even outstrips the well-known LKH3 solver on the more constrained PDP variant. Our implementation for N2S is available online.  
# Paper List
---
## cs.CV
---
**106** new papers in cs.CV:-) 
1. On Distillation of Guided Diffusion Models. (arXiv:2210.03142v1 [cs.CV])
2. Integrative Imaging Informatics for Cancer Research: Workflow Automation for Neuro-oncology (I3CR-WANO). (arXiv:2210.03151v1 [eess.IV])
3. Neural Volumetric Mesh Generator. (arXiv:2210.03158v1 [cs.CV])
4. Brief Introduction to Contrastive Learning Pretext Tasks for Visual Representation. (arXiv:2210.03163v1 [cs.CV])
5. Gastrointestinal Disorder Detection with a Transformer Based Approach. (arXiv:2210.03168v1 [cs.CV])
6. CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration. (arXiv:2210.03173v1 [cs.RO])
7. A ResNet is All You Need? Modeling A Strong Baseline for Detecting Referable Diabetic Retinopathy in Fundus Images. (arXiv:2210.03180v1 [eess.IV])
8. FocalUNETR: A Focal Transformer for Boundary-aware Segmentation of CT Images. (arXiv:2210.03189v1 [eess.IV])
9. Enabling Deep Learning on Edge Devices. (arXiv:2210.03204v1 [cs.LG])
10. Synthetic Dataset Generation for Privacy-Preserving Machine Learning. (arXiv:2210.03205v1 [cs.CR])
11. Self-Supervised Monocular Depth Underwater. (arXiv:2210.03206v1 [cs.CV])
12. Adversarial Lagrangian Integrated Contrastive Embedding for Limited Size Datasets. (arXiv:2210.03261v1 [cs.CV])
13. Polyhistor: Parameter-Efficient Multi-Task Adaptation for Dense Vision Tasks. (arXiv:2210.03265v1 [cs.CV])
14. TRADE: Object Tracking with 3D Trajectory and Ground Depth Estimates for UAVs. (arXiv:2210.03270v1 [cs.RO])
15. Scalable Self-Supervised Representation Learning from Spatiotemporal Motion Trajectories for Multimodal Computer Vision. (arXiv:2210.03289v1 [cs.CV])
16. GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow. (arXiv:2210.03296v1 [cs.CV])
17. Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems. (arXiv:2210.03297v1 [cs.CR])
18. Topology-Preserving Segmentation Network. (arXiv:2210.03299v1 [cs.CV])
19. GOLLIC: Learning Global Context beyond Patches for Lossless High-Resolution Image Compression. (arXiv:2210.03301v1 [eess.IV])
20. Scaling Forward Gradient With Local Losses. (arXiv:2210.03310v1 [cs.LG])
21. Resolving Class Imbalance for LiDAR-based Object Detector by Dynamic Weight Average and Contextual Ground Truth Sampling. (arXiv:2210.03331v1 [cs.CV])
22. Explainable AI based Glaucoma Detection using Transfer Learning and LIME. (arXiv:2210.03332v1 [cs.CV])
23. A Keypoint Based **Enhancement** Method for Audio Driven Free View Talking Head Synthesis. (arXiv:2210.03335v1 [cs.CV])
24. Dual Clustering Co-teaching with Consistent Sample Mining for Unsupervised Person Re-Identification. (arXiv:2210.03339v1 [cs.CV])
25. Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding. (arXiv:2210.03347v1 [cs.CL])
26. Game-Theoretic Understanding of Misclassification. (arXiv:2210.03349v1 [cs.CV])
27. Multiple Object Tracking from appearance by hierarchically clustering tracklets. (arXiv:2210.03355v1 [cs.CV])
28. Pre-trained Adversarial Perturbations. (arXiv:2210.03372v1 [cs.CV])
29. Temporal Feature Alignment in Contrastive Self-Supervised Learning for Human Activity Recognition. (arXiv:2210.03382v1 [cs.CV])
30. Mars Rover Localization Based on A2G Obstacle Distribution Pattern Matching. (arXiv:2210.03398v1 [cs.CV])
31. Computational imaging with the human brain. (arXiv:2210.03400v1 [cs.CV])
32. Detailed Annotations of Chest X-Rays via CT Projection for Report Understanding. (arXiv:2210.03416v1 [cs.CV])
33. A Simple Plugin for Transforming Images to Arbitrary Scales. (arXiv:2210.03417v1 [cs.CV])
34. Missing Modality meets Meta Sampling (M3S): An Efficient Universal Approach for Multimodal Sentiment Analysis with Missing Modality. (arXiv:2210.03428v1 [cs.CV])
35. Adversarially Robust Prototypical Few-shot Segmentation with Neural-ODEs. (arXiv:2210.03429v1 [cs.CV])
36. PS-ARM: An End-to-End Attention-aware Relation Mixer Network for Person Search. (arXiv:2210.03433v1 [cs.CV])
37. IDPL: Intra-subdomain adaptation adversarial learning segmentation method based on Dynamic Pseudo Labels. (arXiv:2210.03435v1 [cs.CV])
38. Trans2k: Unlocking the Power of Deep Models for Transparent Object Tracking. (arXiv:2210.03436v1 [cs.CV])
39. KRF: Keypoint Refinement with Fusion Network for 6D Pose Estimation. (arXiv:2210.03437v1 [cs.CV])
40. Key Information Extraction in Purchase Documents using Deep Learning and Rule-based Corrections. (arXiv:2210.03453v1 [cs.CV])
41. Flexible Alignment Super-Resolution Network for Multi-Contrast MRI. (arXiv:2210.03460v1 [eess.IV])
42. FastCLIPStyler: Towards fast text-based image style transfer using style representation. (arXiv:2210.03461v1 [cs.CV])
43. IDa-Det: An Information Discrepancy-aware Distillation for 1-bit Detectors. (arXiv:2210.03477v1 [cs.CV])
44. Neighbor Regularized Bayesian Optimization for Hyperparameter Optimization. (arXiv:2210.03481v1 [cs.CV])
45. CLAD: A realistic Continual Learning benchmark for Autonomous Driving. (arXiv:2210.03482v1 [cs.CV])
46. Learning to Learn and Sample BRDFs. (arXiv:2210.03510v1 [cs.GR])
47. Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces. (arXiv:2210.03529v1 [cs.CV])
48. A2: Efficient Automated Attacker for Boosting Adversarial Training. (arXiv:2210.03543v1 [cs.CV])
49. Time-Space Transformers for Video Panoptic Segmentation. (arXiv:2210.03546v1 [cs.CV])
50. Instance Segmentation of Dense and Overlapping Objects via Layering. (arXiv:2210.03551v1 [cs.CV])
51. A deep learning approach for detection and localization of leaf anomalies. (arXiv:2210.03558v1 [cs.CV])
52. Automated segmentation and morphological characterization of placental histology images based on a single labeled image. (arXiv:2210.03566v1 [eess.IV])
53. AI-Driven Road Maintenance Inspection v2: Reducing Data Dependency & Quantifying Road Damage. (arXiv:2210.03570v1 [cs.CV])
54. An Investigation into Whitening Loss for Self-supervised Learning. (arXiv:2210.03586v1 [cs.CV])
55. Modeling Inter-Class and Intra-Class Constraints in Novel Class Discovery. (arXiv:2210.03591v1 [cs.CV])
56. Specialized Re-Ranking: A Novel Retrieval-Verification Framework for Cloth Changing Person Re-Identification. (arXiv:2210.03592v1 [cs.CV])
57. BlanketSet -- A clinical real word action recognition and qualitative semi-synchronised MoCap dataset. (arXiv:2210.03600v1 [cs.CV])
58. 1st ICLR International Workshop on Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data (PAIR^2Struct). (arXiv:2210.03612v1 [stat.ML])
59. C2KD: Cross-Lingual Cross-Modal Knowledge Distillation for Multilingual Text-Video Retrieval. (arXiv:2210.03625v1 [cs.CL])
60. Pose Guided Human Image Synthesis with Partially Decoupled GAN. (arXiv:2210.03627v1 [cs.CV])
61. Leveraging Structure from Motion to Localize Inaccessible Bus Stops. (arXiv:2210.03646v1 [cs.CV])
62. Understanding the Covariance Structure of Convolutional Filters. (arXiv:2210.03651v1 [cs.CV])
63. Spatio-temporal Tendency Reasoning for Human Body Pose and Shape Estimation from Videos. (arXiv:2210.03659v1 [cs.CV])
64. Bi-directional Weakly Supervised Knowledge Distillation for Whole Slide Image Classification. (arXiv:2210.03664v1 [cs.CV])
65. IronDepth: Iterative Refinement of Single-View Depth using Surface Normal and its Uncertainty. (arXiv:2210.03676v1 [cs.CV])
66. Quantitative Metrics for Evaluating Explanations of Video DeepFake Detectors. (arXiv:2210.03683v1 [cs.CV])
67. Humans need not label more humans: Occlusion Copy & Paste for Occluded Human Instance Segmentation. (arXiv:2210.03686v1 [cs.CV])
68. GENHOP: An Image Generation Method Based on Successive Subspace Learning. (arXiv:2210.03689v1 [eess.IV])
69. Compressing Video Calls using Synthetic Talking Heads. (arXiv:2210.03692v1 [cs.CV])
70. Multi-Frequency-Aware Patch Adversarial Learning for Neural Point Cloud Rendering. (arXiv:2210.03693v1 [cs.CV])
71. Spectral Image Segmentation with Global Appearance Modeling. (arXiv:2006.06573v2 [cs.CV] UPDATED)
72. Normalized Weighting Schemes for Image Interpolation Algorithms. (arXiv:2011.08559v5 [cs.GR] UPDATED)
73. Domain Adaptation for the Segmentation of Confidential Medical Images. (arXiv:2101.00522v3 [cs.CV] UPDATED)
74. Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers. (arXiv:2103.14829v4 [cs.CV] UPDATED)
75. Hyper-Convolution Networks for Biomedical Image Segmentation. (arXiv:2105.10559v2 [eess.IV] UPDATED)
76. DROID: Driver-centric Risk Object Identification. (arXiv:2106.13201v2 [cs.CV] UPDATED)
77. Noise2Recon: Enabling Joint MRI Reconstruction and Denoising with Semi-Supervised and Self-Supervised Learning. (arXiv:2110.00075v2 [eess.IV] UPDATED)
78. Biometric Template Protection for Neural-Network-based Face Recognition Systems: A Survey of Methods and Evaluation Techniques. (arXiv:2110.05044v3 [cs.CV] UPDATED)
79. On the Effect of Selfie Beautification Filters on Face Detection and Recognition. (arXiv:2110.08934v4 [cs.CV] UPDATED)
80. The magnitude vector of images. (arXiv:2110.15188v2 [cs.LG] UPDATED)
81. SSR: An Efficient and Robust Framework for Learning with Unknown Label Noise. (arXiv:2111.11288v2 [cs.CV] UPDATED)
82. ViCE: Improving Dense Representation Learning by Superpixelization and Contrasting Cluster Assignment. (arXiv:2111.12460v3 [cs.CV] UPDATED)
83. Information Theoretic Representation Distillation. (arXiv:2112.00459v3 [cs.CV] UPDATED)
84. AdaViT: Adaptive Tokens for Efficient Vision Transformer. (arXiv:2112.07658v3 [cs.CV] UPDATED)
85. NeRD++: Improved 3D-mirror symmetry learning from a single image. (arXiv:2112.12579v2 [cs.CV] UPDATED)
86. COTReg:Coupled Optimal Transport based Point Cloud Registration. (arXiv:2112.14381v2 [cs.CV] UPDATED)
87. Class-Aware Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v4 [cs.CV] UPDATED)
88. Cross-Modality Neuroimage Synthesis: A Survey. (arXiv:2202.06997v3 [eess.IV] UPDATED)
89. MUAD: Multiple Uncertainties for Autonomous Driving, a benchmark for multiple uncertainty types and tasks. (arXiv:2203.01437v2 [cs.CV] UPDATED)
90. Evaluating the Consequences of Object (mis)Detection from a Safety and Reliability Perspective: Discussion and Measures. (arXiv:2203.02205v2 [cs.LG] UPDATED)
91. Mapping global dynamics of benchmark creation and saturation in artificial intelligence. (arXiv:2203.04592v4 [cs.AI] UPDATED)
92. Re-examining Distillation For Continual Object Detection. (arXiv:2204.01407v2 [cs.CV] UPDATED)
93. SqueezeNeRF: Further factorized FastNeRF for memory-efficient inference. (arXiv:2204.02585v3 [cs.CV] UPDATED)
94. HunYuan_tvr for Text-Video Retrieval. (arXiv:2204.03382v6 [cs.CV] UPDATED)
95. What You See is What You Classify: Black Box Attributions. (arXiv:2205.11266v2 [cs.CV] UPDATED)
96. A Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks. (arXiv:2206.06544v2 [cs.CV] UPDATED)
97. Learning Best Combination for Efficient N:M Sparsity. (arXiv:2206.06662v2 [cs.LG] UPDATED)
98. K-Radar: 4D Radar Object Detection for Autonomous Driving in Various Weather Conditions. (arXiv:2206.08171v2 [cs.CV] UPDATED)
99. Forward Error Correction applied to JPEG-XS codestreams. (arXiv:2207.04825v2 [eess.IV] UPDATED)
100. Self-Supervised Face Presentation Attack Detection with Dynamic Grayscale Snippets. (arXiv:2208.13070v3 [cs.CV] UPDATED)
101. Seq-UPS: Sequential Uncertainty-aware Pseudo-label Selection for Semi-Supervised Text Recognition. (arXiv:2209.00641v2 [cs.CV] UPDATED)
102. Long-Lived Accurate Keypoints in Event Streams. (arXiv:2209.10385v2 [cs.CV] UPDATED)
103. Towards Frame Rate Agnostic Multi-Object Tracking. (arXiv:2209.11404v2 [cs.CV] UPDATED)
104. Image-Based Detection of Modifications in Gas Pump PCBs with Deep Convolutional Autoencoders. (arXiv:2210.00100v2 [cs.CV] UPDATED)
105. Seeing Through The Noisy **Dark**: Toward Real-world **Low-Light** Image **Enhancement** and Denoising. (arXiv:2210.00545v2 [cs.CV] UPDATED)
106. Spatio-Temporal Learnable Proposals for End-to-End Video Object Detection. (arXiv:2210.02368v2 [cs.CV] UPDATED)
## eess.IV
---
**18** new papers in eess.IV:-) 
1. Integrative Imaging Informatics for Cancer Research: Workflow Automation for Neuro-oncology (I3CR-WANO). (arXiv:2210.03151v1 [eess.IV])
2. A ResNet is All You Need? Modeling A Strong Baseline for Detecting Referable Diabetic Retinopathy in Fundus Images. (arXiv:2210.03180v1 [eess.IV])
3. FocalUNETR: A Focal Transformer for Boundary-aware Segmentation of CT Images. (arXiv:2210.03189v1 [eess.IV])
4. GOLLIC: Learning Global Context beyond Patches for Lossless High-Resolution Image Compression. (arXiv:2210.03301v1 [eess.IV])
5. The UTE and ZTE Sequences at Ultra-High Magnetic Field Strengths: A Survey. (arXiv:2210.03317v1 [physics.med-ph])
6. Flexible Alignment Super-Resolution Network for Multi-Contrast MRI. (arXiv:2210.03460v1 [eess.IV])
7. Automated segmentation and morphological characterization of placental histology images based on a single labeled image. (arXiv:2210.03566v1 [eess.IV])
8. GENHOP: An Image Generation Method Based on Successive Subspace Learning. (arXiv:2210.03689v1 [eess.IV])
9. Multi-Frequency-Aware Patch Adversarial Learning for Neural Point Cloud Rendering. (arXiv:2210.03693v1 [cs.CV])
10. Spectral Image Segmentation with Global Appearance Modeling. (arXiv:2006.06573v2 [cs.CV] UPDATED)
11. Domain Adaptation for the Segmentation of Confidential Medical Images. (arXiv:2101.00522v3 [cs.CV] UPDATED)
12. Hyper-Convolution Networks for Biomedical Image Segmentation. (arXiv:2105.10559v2 [eess.IV] UPDATED)
13. Noise2Recon: Enabling Joint MRI Reconstruction and Denoising with Semi-Supervised and Self-Supervised Learning. (arXiv:2110.00075v2 [eess.IV] UPDATED)
14. Boosting Neural Image Compression for Machines Using Latent Space Masking. (arXiv:2112.08168v2 [eess.IV] UPDATED)
15. Class-Aware Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v4 [cs.CV] UPDATED)
16. Cross-Modality Neuroimage Synthesis: A Survey. (arXiv:2202.06997v3 [eess.IV] UPDATED)
17. Forward Error Correction applied to JPEG-XS codestreams. (arXiv:2207.04825v2 [eess.IV] UPDATED)
18. Simultaneous self-supervised reconstruction and denoising of sub-sampled MRI data with Noisier2Noise. (arXiv:2210.01696v2 [eess.IV] UPDATED)
## cs.LG
---
**159** new papers in cs.LG:-) 
1. Evaluating k-NN in the Classification of Data Streams with Concept Drift. (arXiv:2210.03119v1 [cs.LG])
2. GBSVM: Granular-ball Support Vector Machine. (arXiv:2210.03120v1 [cs.LG])
3. Temporal Spatial Decomposition and Fusion Network for Time Series Forecasting. (arXiv:2210.03122v1 [cs.LG])
4. Enhancing Mixup-Based Graph Learning for Language Processing via Hybrid Pooling. (arXiv:2210.03123v1 [cs.LG])
5. Learning Transfer Operators by Kernel Density Estimation. (arXiv:2210.03124v1 [cs.LG])
6. Deep Inventory Management. (arXiv:2210.03137v1 [cs.LG])
7. On Distillation of Guided Diffusion Models. (arXiv:2210.03142v1 [cs.CV])
8. Towards Out-of-Distribution Adversarial Robustness. (arXiv:2210.03150v1 [cs.LG])
9. Integrative Imaging Informatics for Cancer Research: Workflow Automation for Neuro-oncology (I3CR-WANO). (arXiv:2210.03151v1 [eess.IV])
10. Comparison of Missing Data Imputation Methods using the Framingham Heart study dataset. (arXiv:2210.03154v1 [cs.LG])
11. Understanding Neural Coding on Latent Manifolds by Sharing Features and Dividing Ensembles. (arXiv:2210.03155v1 [stat.ML])
12. Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models. (arXiv:2210.03162v1 [cs.CL])
13. InfoOT: Information Maximizing Optimal Transport. (arXiv:2210.03164v1 [cs.LG])
14. A Theory of Dynamic Benchmarks. (arXiv:2210.03165v1 [cs.LG])
15. CoGrasp: 6-DoF Grasp Generation for Human-Robot Collaboration. (arXiv:2210.03173v1 [cs.RO])
16. Evaluating Fairness Without Sensitive Attributes: A Framework Using Only Auxiliary Models. (arXiv:2210.03175v1 [cs.LG])
17. Probabilistic Model Incorporating Auxiliary Covariates to Control FDR. (arXiv:2210.03178v1 [stat.ML])
18. A ResNet is All You Need? Modeling A Strong Baseline for Detecting Referable Diabetic Retinopathy in Fundus Images. (arXiv:2210.03180v1 [eess.IV])
19. Enabling Deep Learning on Edge Devices. (arXiv:2210.03204v1 [cs.LG])
20. Synthetic Dataset Generation for Privacy-Preserving Machine Learning. (arXiv:2210.03205v1 [cs.CR])
21. Q-LSTM Language Model -- Decentralized Quantum Multilingual Pre-Trained Language Model for Privacy Protection. (arXiv:2210.03221v1 [cs.LG])
22. NAS-Bench-Suite-Zero: Accelerating Research on Zero Cost Proxies. (arXiv:2210.03230v1 [cs.LG])
23. Dominance-based Rough Set Approach, basic ideas and main trends. (arXiv:2210.03233v1 [cs.AI])
24. Disentangling Mixtures of Unknown Causal Interventions. (arXiv:2210.03242v1 [stat.ML])
25. Network Intrusion Detection System in a Light Bulb. (arXiv:2210.03254v1 [cs.CR])
26. Damage Control During Domain Adaptation for Transducer Based Automatic Speech Recognition. (arXiv:2210.03255v1 [cs.SD])
27. Interpreting County Level COVID-19 Infection and Feature Sensitivity using Deep Learning Time Series Models. (arXiv:2210.03258v1 [cs.LG])
28. Multi-agent Deep Covering Option Discovery. (arXiv:2210.03269v1 [cs.LG])
29. TCNL: Transparent and Controllable Network Learning Via Embedding Human-Guided Concepts. (arXiv:2210.03274v1 [cs.LG])
30. Out-of-Distribution Generalization in Algorithmic Reasoning Through Curriculum Learning. (arXiv:2210.03275v1 [cs.LG])
31. Rethinking Normalization Methods in Federated Learning. (arXiv:2210.03277v1 [cs.LG])
32. Set2Box: Similarity Preserving Representation Learning of Sets. (arXiv:2210.03282v1 [cs.SI])
33. Design Amortization for Bayesian Optimal Experimental Design. (arXiv:2210.03283v1 [cs.LG])
34. Scalable Self-Supervised Representation Learning from Spatiotemporal Motion Trajectories for Multimodal Computer Vision. (arXiv:2210.03289v1 [cs.CV])
35. Understanding Edge-of-Stability Training Dynamics with a Minimalist Example. (arXiv:2210.03294v1 [cs.LG])
36. Preprocessors Matter! Realistic Decision-Based Attacks on Machine Learning Systems. (arXiv:2210.03297v1 [cs.CR])
37. GOLLIC: Learning Global Context beyond Patches for Lossless High-Resolution Image Compression. (arXiv:2210.03301v1 [eess.IV])
38. Data-driven Approach to Differentiating between Depression and Dementia from Noisy Speech and Language Data. (arXiv:2210.03303v1 [cs.CL])
39. Generative Augmented Flow Networks. (arXiv:2210.03308v1 [cs.LG])
40. Scaling Forward Gradient With Local Losses. (arXiv:2210.03310v1 [cs.LG])
41. Distillation-Resistant Watermarking for Model Protection in NLP. (arXiv:2210.03312v1 [cs.CL])
42. AutoML for Climate Change: A Call to Action. (arXiv:2210.03324v1 [cs.LG])
43. Elastic Step DQN: A novel multi-step algorithm to alleviate overestimation in Deep QNetworks. (arXiv:2210.03325v1 [cs.LG])
44. The Ethical Risks of Analyzing Crisis Events on Social Media with Machine Learning. (arXiv:2210.03352v1 [cs.LG])
45. Adversarial network training using higher-order moments in a modified Wasserstein distance. (arXiv:2210.03354v1 [stat.ML])
46. GNM: A General Navigation Model to Drive Any Robot. (arXiv:2210.03370v1 [cs.RO])
47. UU-Tax at SemEval-2022 Task 3: Improving the generalizability of language models for taxonomy classification through data augmentation. (arXiv:2210.03378v1 [cs.CL])
48. Geomagnetic Survey Interpolation with the Machine Learning Approach. (arXiv:2210.03379v1 [physics.geo-ph])
49. Latent Matrices for Tensor Network Decomposition and to Tensor Completion. (arXiv:2210.03392v1 [cs.LG])
50. Research on Self-adaptive Online Vehicle Velocity Prediction Strategy Considering Traffic Information Fusion. (arXiv:2210.03402v1 [eess.SY])
51. TAN without a burn: Scaling Laws of DP-SGD. (arXiv:2210.03403v1 [cs.LG])
52. Event Extraction: A Survey. (arXiv:2210.03419v1 [cs.CL])
53. Certified machine learning: Rigorous a posteriori error bounds for PDE defined PINNs. (arXiv:2210.03426v1 [cs.LG])
54. Monitoring MBE substrate deoxidation via RHEED image-sequence analysis by deep learning. (arXiv:2210.03430v1 [cond-mat.mes-hall])
55. Depersonalized Federated Learning: Tackling Statistical Heterogeneity by Alternating Stochastic Gradient Descent. (arXiv:2210.03444v1 [cs.LG])
56. FastCLIPStyler: Towards fast text-based image style transfer using style representation. (arXiv:2210.03461v1 [cs.CV])
57. Latent Neural ODEs with Sparse Bayesian Multiple Shooting. (arXiv:2210.03466v1 [cs.LG])
58. Algorithmic Trading Using Continuous Action Space Deep Reinforcement Learning. (arXiv:2210.03469v1 [cs.LG])
59. Population-Based Reinforcement Learning for Combinatorial Optimization. (arXiv:2210.03475v1 [cs.AI])
60. CLAD: A realistic Continual Learning benchmark for Autonomous Driving. (arXiv:2210.03482v1 [cs.CV])
61. Multi-objective and multi-fidelity Bayesian optimization of laser-plasma acceleration. (arXiv:2210.03484v1 [physics.acc-ph])
62. AlphaFold Distillation for Improved Inverse Protein Folding. (arXiv:2210.03488v1 [q-bio.BM])
63. Private and Efficient Meta-Learning with Low Rank and Sparse Decomposition. (arXiv:2210.03505v1 [cs.LG])
64. Inferring Smooth Control: Monte Carlo Posterior Policy Iteration with Gaussian Processes. (arXiv:2210.03512v1 [cs.LG])
65. Spiking neural network for nonlinear regression. (arXiv:2210.03515v1 [cs.NE])
66. Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery. (arXiv:2210.03516v1 [cs.NE])
67. Fairness in generative modeling. (arXiv:2210.03517v1 [cs.NE])
68. LGTBIDS: Layer-wise Graph Theory Based Intrusion Detection System in Beyond 5G. (arXiv:2210.03518v1 [cs.CR])
69. HetSyn: Speeding Up Local SGD with Heterogeneous Synchronization. (arXiv:2210.03521v1 [cs.LG])
70. A Unified Hard-Constraint Framework for Solving Geometrically Complex PDEs. (arXiv:2210.03526v1 [cs.LG])
71. Tractable Optimality in Episodic Latent MABs. (arXiv:2210.03528v1 [cs.LG])
72. From plane crashes to algorithmic harm: applicability of safety engineering frameworks for responsible ML. (arXiv:2210.03535v1 [cs.HC])
73. An Overview of Affective Speech Synthesis and Conversion in the Deep Learning Era. (arXiv:2210.03538v1 [cs.SD])
74. A deep learning approach for detection and localization of leaf anomalies. (arXiv:2210.03558v1 [cs.CV])
75. Empowering Graph Representation Learning with Test-Time Graph Transformation. (arXiv:2210.03561v1 [cs.LG])
76. Automated segmentation and morphological characterization of placental histology images based on a single labeled image. (arXiv:2210.03566v1 [eess.IV])
77. Learning Social Navigation from Demonstrations with Conditional Neural Processes. (arXiv:2210.03582v1 [cs.RO])
78. An Investigation into Whitening Loss for Self-supervised Learning. (arXiv:2210.03586v1 [cs.CV])
79. Machine Learning Meets The Herbrand Universe. (arXiv:2210.03590v1 [cs.LG])
80. Label Propagation with Weak Supervision. (arXiv:2210.03594v1 [cs.LG])
81. Unsupervised Few-shot Learning via Deep Laplacian Eigenmaps. (arXiv:2210.03595v1 [cs.LG])
82. 1st ICLR International Workshop on Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data (PAIR^2Struct). (arXiv:2210.03612v1 [stat.ML])
83. ReAct: Synergizing Reasoning and Acting in Language Models. (arXiv:2210.03629v1 [cs.CL])
84. Learnware: Small Models Do Big. (arXiv:2210.03647v1 [cs.LG])
85. How to Enable Uncertainty Estimation in Proximal Policy Optimization. (arXiv:2210.03649v1 [cs.LG])
86. Longtonotes: OntoNotes with Longer Coreference Chains. (arXiv:2210.03650v1 [cs.CL])
87. Understanding the Covariance Structure of Convolutional Filters. (arXiv:2210.03651v1 [cs.CV])
88. CommsVAE: Learning the brain's macroscale communication dynamics using coupled sequential VAEs. (arXiv:2210.03667v1 [q-bio.NC])
89. A Closer Look at Hardware-Friendly Weight Quantization. (arXiv:2210.03671v1 [cs.LG])
90. To tree or not to tree? Assessing the impact of smoothing the decision boundaries. (arXiv:2210.03672v1 [cs.LG])
91. Koopman Neural Forecaster for Time Series with Temporal Distribution Shifts. (arXiv:2210.03675v1 [cs.LG])
92. Novice Type Error Diagnosis with Natural Language Models. (arXiv:2210.03682v1 [cs.PL])
93. NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems. (arXiv:2210.03696v1 [cs.CL])
94. Class-wise and reduced calibration methods. (arXiv:2210.03702v1 [stat.ML])
95. Understanding Practices, Challenges, and Opportunities for User-Driven Algorithm Auditing in Industry Practice. (arXiv:2210.03709v1 [cs.HC])
96. Atomized Deep Learning Models. (arXiv:2210.03728v1 [cs.LG])
97. Knowledge-Grounded Reinforcement Learning. (arXiv:2210.03729v1 [cs.LG])
98. Demystifying Map Space Exploration for NPUs. (arXiv:2210.03731v1 [cs.LG])
99. Autoencoders and Generative Adversarial Networks for Imbalanced Sequence Classification. (arXiv:1901.02514v6 [cs.LG] UPDATED)
100. On the Theory of Dynamic Graph Regression Problem. (arXiv:1903.10699v5 [cs.LG] UPDATED)
101. Sublinear Update Time Randomized Algorithms for Dynamic Graph Regression. (arXiv:1905.11963v3 [cs.LG] UPDATED)
102. Deep Reinforcement Learning meets Graph Neural Networks: exploring a routing optimization use case. (arXiv:1910.07421v3 [cs.NI] UPDATED)
103. Experiments with mmWave Automotive Radar Test-bed. (arXiv:1912.12566v4 [eess.SP] UPDATED)
104. Interpretable Deep Representation Learning from Temporal Multi-view Data. (arXiv:2005.05210v3 [stat.ML] UPDATED)
105. Spectral Image Segmentation with Global Appearance Modeling. (arXiv:2006.06573v2 [cs.CV] UPDATED)
106. Anomaly Awareness. (arXiv:2007.14462v3 [cs.LG] UPDATED)
107. Domain Adaptation for the Segmentation of Confidential Medical Images. (arXiv:2101.00522v3 [cs.CV] UPDATED)
108. A GAN-based Reduced Order Model for Prediction, Data Assimilation and Uncertainty Quantification. (arXiv:2105.13859v3 [cs.LG] UPDATED)
109. Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning. (arXiv:2106.09256v4 [cs.LG] UPDATED)
110. Sparse Bayesian Learning with Diagonal Quasi-Newton Method for Large Scale Classification. (arXiv:2107.08195v4 [cs.LG] UPDATED)
111. Can an AI agent hit a moving target?. (arXiv:2110.02474v2 [econ.TH] UPDATED)
112. On the difficulty of learning chaotic dynamics with RNNs. (arXiv:2110.07238v3 [cs.LG] UPDATED)
113. Bandits with Dynamic Arm-acquisition Costs. (arXiv:2110.12118v3 [cs.LG] UPDATED)
114. The magnitude vector of images. (arXiv:2110.15188v2 [cs.LG] UPDATED)
115. Universal Inference Meets Random Projections: A Scalable Test for Log-concavity. (arXiv:2111.09254v2 [stat.ME] UPDATED)
116. Explainable Biomedical Recommendations via Reinforcement Learning Reasoning on Knowledge Graphs. (arXiv:2111.10625v2 [cs.LG] UPDATED)
117. SSR: An Efficient and Robust Framework for Learning with Unknown Label Noise. (arXiv:2111.11288v2 [cs.CV] UPDATED)
118. ViCE: Improving Dense Representation Learning by Superpixelization and Contrasting Cluster Assignment. (arXiv:2111.12460v3 [cs.CV] UPDATED)
119. Bayesian Persuasion for Algorithmic Recourse. (arXiv:2112.06283v3 [cs.GT] UPDATED)
120. AdaViT: Adaptive Tokens for Efficient Vision Transformer. (arXiv:2112.07658v3 [cs.CV] UPDATED)
121. FLoBC: A Decentralized Blockchain-Based Federated Learning Framework. (arXiv:2112.11873v2 [cs.DC] UPDATED)
122. Class-Aware Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v4 [cs.CV] UPDATED)
123. A Lagrangian Duality Approach to Active Learning. (arXiv:2202.04108v2 [cs.LG] UPDATED)
124. Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models. (arXiv:2202.04173v2 [cs.CL] UPDATED)
125. Degree-Preserving Randomized Response for Graph Neural Networks under Local Differential Privacy. (arXiv:2202.10209v2 [cs.CR] UPDATED)
126. GAN-DUF: Hierarchical Deep Generative Models for Design Under Free-Form Geometric Uncertainty. (arXiv:2202.10558v4 [cs.CE] UPDATED)
127. Evaluating the Consequences of Object (mis)Detection from a Safety and Reliability Perspective: Discussion and Measures. (arXiv:2203.02205v2 [cs.LG] UPDATED)
128. Re-examining Distillation For Continual Object Detection. (arXiv:2204.01407v2 [cs.CV] UPDATED)
129. Efficient Neural Neighborhood Search for Pickup and Delivery Problems. (arXiv:2204.11399v3 [cs.LG] UPDATED)
130. Neural Network Optimal Feedback Control with Guaranteed Local Stability. (arXiv:2205.00394v3 [math.OC] UPDATED)
131. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v4 [cs.LG] UPDATED)
132. Translating Hanja historical documents to understandable Korean and English. (arXiv:2205.10019v2 [cs.CL] UPDATED)
133. Diversity vs. Recognizability: Human-like generalization in one-shot generative models. (arXiv:2205.10370v3 [cs.AI] UPDATED)
134. What You See is What You Classify: Black Box Attributions. (arXiv:2205.11266v2 [cs.CV] UPDATED)
135. Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative Machine Learning. (arXiv:2205.11779v2 [cs.LG] UPDATED)
136. Posterior and Computational Uncertainty in Gaussian Processes. (arXiv:2205.15449v2 [cs.LG] UPDATED)
137. Early Stage Convergence and Global Convergence of Training Mildly Parameterized Neural Networks. (arXiv:2206.02139v2 [cs.LG] UPDATED)
138. Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate Model Predictive Trajectory Tracking. (arXiv:2206.03305v3 [cs.RO] UPDATED)
139. Learning Best Combination for Efficient N:M Sparsity. (arXiv:2206.06662v2 [cs.LG] UPDATED)
140. On the Generalizability and Predictability of Recommender Systems. (arXiv:2206.11886v2 [cs.IR] UPDATED)
141. Physically Consistent Learning of Conservative Lagrangian Systems with Gaussian Processes. (arXiv:2206.12272v2 [cs.LG] UPDATED)
142. A General Recipe for Likelihood-free Bayesian Optimization. (arXiv:2206.13035v2 [cs.LG] UPDATED)
143. CausalAgents: A Robustness Benchmark for Motion Forecasting using Causal Relationships. (arXiv:2207.03586v2 [cs.LG] UPDATED)
144. Retweet-BERT: Political Leaning Detection Using Language Features and Information Diffusion on Social Networks. (arXiv:2207.08349v2 [cs.SI] UPDATED)
145. Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning. (arXiv:2207.09081v2 [cs.LG] UPDATED)
146. What can be learnt with wide convolutional neural networks?. (arXiv:2208.01003v3 [stat.ML] UPDATED)
147. The Alberta Plan for AI Research. (arXiv:2208.11173v2 [cs.AI] UPDATED)
148. FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning in Federated Learning. (arXiv:2208.12268v2 [cs.LG] UPDATED)
149. Estimation of Correlation Matrices from Limited time series Data using Machine Learning. (arXiv:2209.01198v3 [cs.LG] UPDATED)
150. Git Re-Basin: Merging Models modulo Permutation Symmetries. (arXiv:2209.04836v2 [cs.LG] UPDATED)
151. NIERT: Accurate Numerical Interpolation through Unifying Scattered Data Representations using Transformer Encoder. (arXiv:2209.09078v2 [cs.LG] UPDATED)
152. Taking a Respite from Representation Learning for Molecular Property Prediction. (arXiv:2209.13492v2 [q-bio.QM] UPDATED)
153. An efficient encoder-decoder architecture with top-down attention for speech separation. (arXiv:2209.15200v2 [cs.SD] UPDATED)
154. Image-Based Detection of Modifications in Gas Pump PCBs with Deep Convolutional Autoencoders. (arXiv:2210.00100v2 [cs.CV] UPDATED)
155. Causal Knowledge Transfer from Task Affinity. (arXiv:2210.00380v2 [cs.LG] UPDATED)
156. Non-Parametric and Regularized Dynamical Wasserstein Barycenters for Time-Series Analysis. (arXiv:2210.01918v2 [cs.LG] UPDATED)
157. Multiclass Learnability Beyond the PAC Framework: Universal Rates and Partial Concept Classes. (arXiv:2210.02297v2 [cs.LG] UPDATED)
158. Join-Chain Network: A Logical Reasoning View of the Multi-head Attention in Transformer. (arXiv:2210.02729v2 [cs.CL] UPDATED)
159. SynBench: Task-Agnostic Benchmarking of Pretrained Representations using Synthetic Data. (arXiv:2210.02989v2 [cs.LG] UPDATED)
## cs.AI
---
**100** new papers in cs.AI:-) 
1. Evaluating k-NN in the Classification of Data Streams with Concept Drift. (arXiv:2210.03119v1 [cs.LG])
2. GBSVM: Granular-ball Support Vector Machine. (arXiv:2210.03120v1 [cs.LG])
3. Temporal Spatial Decomposition and Fusion Network for Time Series Forecasting. (arXiv:2210.03122v1 [cs.LG])
4. Enhancing Mixup-Based Graph Learning for Language Processing via Hybrid Pooling. (arXiv:2210.03123v1 [cs.LG])
5. On Distillation of Guided Diffusion Models. (arXiv:2210.03142v1 [cs.CV])
6. Towards Out-of-Distribution Adversarial Robustness. (arXiv:2210.03150v1 [cs.LG])
7. Neural Volumetric Mesh Generator. (arXiv:2210.03158v1 [cs.CV])
8. Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models. (arXiv:2210.03162v1 [cs.CL])
9. Gastrointestinal Disorder Detection with a Transformer Based Approach. (arXiv:2210.03168v1 [cs.CV])
10. Evaluating Fairness Without Sensitive Attributes: A Framework Using Only Auxiliary Models. (arXiv:2210.03175v1 [cs.LG])
11. Enabling Deep Learning on Edge Devices. (arXiv:2210.03204v1 [cs.LG])
12. Synthetic Dataset Generation for Privacy-Preserving Machine Learning. (arXiv:2210.03205v1 [cs.CR])
13. NAS-Bench-Suite-Zero: Accelerating Research on Zero Cost Proxies. (arXiv:2210.03230v1 [cs.LG])
14. Dominance-based Rough Set Approach, basic ideas and main trends. (arXiv:2210.03233v1 [cs.AI])
15. Disentangling Mixtures of Unknown Causal Interventions. (arXiv:2210.03242v1 [stat.ML])
16. Unsupervised Domain Adaptation for COVID-19 Information Service with Contrastive Adversarial Domain Mixup. (arXiv:2210.03250v1 [cs.CL])
17. Considerations for Task Allocation in Human-Robot Teams. (arXiv:2210.03259v1 [cs.RO])
18. TCNL: Transparent and Controllable Network Learning Via Embedding Human-Guided Concepts. (arXiv:2210.03274v1 [cs.LG])
19. Scalable Self-Supervised Representation Learning from Spatiotemporal Motion Trajectories for Multimodal Computer Vision. (arXiv:2210.03289v1 [cs.CV])
20. GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow. (arXiv:2210.03296v1 [cs.CV])
21. AutoML for Climate Change: A Call to Action. (arXiv:2210.03324v1 [cs.LG])
22. Explainable AI based Glaucoma Detection using Transfer Learning and LIME. (arXiv:2210.03332v1 [cs.CV])
23. A Unified Framework for Multi-intent Spoken Language Understanding with prompting. (arXiv:2210.03337v1 [cs.CL])
24. The Lifecycle of "Facts": A Survey of Social Bias in Knowledge Graphs. (arXiv:2210.03353v1 [cs.CL])
25. GNM: A General Navigation Model to Drive Any Robot. (arXiv:2210.03370v1 [cs.RO])
26. Pre-trained Adversarial Perturbations. (arXiv:2210.03372v1 [cs.CV])
27. UU-Tax at SemEval-2022 Task 3: Improving the generalizability of language models for taxonomy classification through data augmentation. (arXiv:2210.03378v1 [cs.CL])
28. Zero-shot stance detection based on cross-domain feature **enhancement** by contrastive learning. (arXiv:2210.03380v1 [cs.CL])
29. Temporal Feature Alignment in Contrastive Self-Supervised Learning for Human Activity Recognition. (arXiv:2210.03382v1 [cs.CV])
30. Quantifying Political Bias in News Articles. (arXiv:2210.03404v1 [cs.IR])
31. SpaceQA: Answering Questions about the Design of Space Missions and Space Craft Concepts. (arXiv:2210.03422v1 [cs.CL])
32. Generating Quizzes to Support Training on Quality Management and Assurance in Space Science and Engineering. (arXiv:2210.03427v1 [cs.CL])
33. Advice Conformance Verification by Reinforcement Learning agents for Human-in-the-Loop. (arXiv:2210.03455v1 [cs.AI])
34. FastCLIPStyler: Towards fast text-based image style transfer using style representation. (arXiv:2210.03461v1 [cs.CV])
35. Population-Based Reinforcement Learning for Combinatorial Optimization. (arXiv:2210.03475v1 [cs.AI])
36. Automatic Chain of Thought Prompting in Large Language Models. (arXiv:2210.03493v1 [cs.CL])
37. When one Logic is Not Enough: Integrating First-order Annotations in OWL Ontologies. (arXiv:2210.03497v1 [cs.AI])
38. What Do End-Users Really Want? Investigation of Human-Centered XAI for Mobile Health Apps. (arXiv:2210.03506v1 [cs.HC])
39. Neuroevolution is a Competitive Alternative to Reinforcement Learning for Skill Discovery. (arXiv:2210.03516v1 [cs.NE])
40. Fairness in generative modeling. (arXiv:2210.03517v1 [cs.NE])
41. An Empirical Studies on How the Developers Discussed about Pandas Topics. (arXiv:2210.03519v1 [cs.SE])
42. Do We Need Explainable AI in Companies? Investigation of Challenges, Expectations, and Chances from Employees' Perspective. (arXiv:2210.03527v1 [cs.HC])
43. Treewidth-aware Reductions of Normal ASP to SAT -- Is Normal ASP Harder than SAT after All?. (arXiv:2210.03553v1 [cs.AI])
44. In-situ Model Downloading to Realize Versatile Edge AI in 6G Mobile Networks. (arXiv:2210.03555v1 [cs.IT])
45. Empowering Graph Representation Learning with Test-Time Graph Transformation. (arXiv:2210.03561v1 [cs.LG])
46. How Large Language Models are Transforming Machine-Paraphrased Plagiarism. (arXiv:2210.03568v1 [cs.CL])
47. Machine Learning Meets The Herbrand Universe. (arXiv:2210.03590v1 [cs.LG])
48. 1st ICLR International Workshop on Privacy, Accountability, Interpretability, Robustness, Reasoning on Structured Data (PAIR^2Struct). (arXiv:2210.03612v1 [stat.ML])
49. The $(1+(\lambda,\lambda))$ Global SEMO Algorithm. (arXiv:2210.03618v1 [cs.NE])
50. Pose Guided Human Image Synthesis with Partially Decoupled GAN. (arXiv:2210.03627v1 [cs.CV])
51. GraspCaps: Capsule Networks Are All You Need for Grasping Familiar Objects. (arXiv:2210.03628v1 [cs.RO])
52. ReAct: Synergizing Reasoning and Acting in Language Models. (arXiv:2210.03629v1 [cs.CL])
53. Artificial Intelligence and Natural Language Processing and Understanding in Space: Four ESA Case Studies. (arXiv:2210.03640v1 [cs.CL])
54. Learnware: Small Models Do Big. (arXiv:2210.03647v1 [cs.LG])
55. How to Enable Uncertainty Estimation in Proximal Policy Optimization. (arXiv:2210.03649v1 [cs.LG])
56. Understanding the Covariance Structure of Convolutional Filters. (arXiv:2210.03651v1 [cs.CV])
57. Spatio-temporal Tendency Reasoning for Human Body Pose and Shape Estimation from Videos. (arXiv:2210.03659v1 [cs.CV])
58. Reinforcement Learning Approach for Multi-Agent Flexible Scheduling Problems. (arXiv:2210.03674v1 [cs.AI])
59. Quantitative Metrics for Evaluating Explanations of Video DeepFake Detectors. (arXiv:2210.03683v1 [cs.CV])
60. Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts. (arXiv:2210.03690v1 [cs.CL])
61. NMTSloth: Understanding and Testing Efficiency Degradation of Neural Machine Translation Systems. (arXiv:2210.03696v1 [cs.CL])
62. Understanding Practices, Challenges, and Opportunities for User-Driven Algorithm Auditing in Industry Practice. (arXiv:2210.03709v1 [cs.HC])
63. Atomized Deep Learning Models. (arXiv:2210.03728v1 [cs.LG])
64. Knowledge-Grounded Reinforcement Learning. (arXiv:2210.03729v1 [cs.LG])
65. Stylized innovation: generating timelines by interrogating incrementally available randomised dictionaries. (arXiv:1806.07722v2 [cs.AI] UPDATED)
66. Achilles Heels for AGI/ASI via Decision Theoretic Adversaries. (arXiv:2010.05418v8 [cs.AI] UPDATED)
67. Seeing Differently, Acting Similarly: Heterogeneously Observable Imitation Learning. (arXiv:2106.09256v4 [cs.LG] UPDATED)
68. Design of quantum optical experiments with logic artificial intelligence. (arXiv:2109.13273v3 [quant-ph] UPDATED)
69. User Centered Design (VI): Human Factors Approaches for Intelligent Human-Computer Interaction. (arXiv:2111.04880v4 [cs.HC] UPDATED)
70. Explainable Biomedical Recommendations via Reinforcement Learning Reasoning on Knowledge Graphs. (arXiv:2111.10625v2 [cs.LG] UPDATED)
71. Inherently Explainable Reinforcement Learning in Natural Language. (arXiv:2112.08907v3 [cs.HC] UPDATED)
72. Challenges and Approaches for Mitigating Byzantine Attacks in Federated Learning. (arXiv:2112.14468v2 [cs.CR] UPDATED)
73. Class-Aware Adversarial Transformers for Medical Image Segmentation. (arXiv:2201.10737v4 [cs.CV] UPDATED)
74. What are the best systems? New perspectives on NLP Benchmarking. (arXiv:2202.03799v4 [cs.CL] UPDATED)
75. Exploring the Limits of Domain-Adaptive Training for Detoxifying Large-Scale Language Models. (arXiv:2202.04173v2 [cs.CL] UPDATED)
76. Evaluating the Consequences of Object (mis)Detection from a Safety and Reliability Perspective: Discussion and Measures. (arXiv:2203.02205v2 [cs.LG] UPDATED)
77. Mapping global dynamics of benchmark creation and saturation in artificial intelligence. (arXiv:2203.04592v4 [cs.AI] UPDATED)
78. A Hierarchical N-Gram Framework for Zero-Shot Link Prediction. (arXiv:2204.10293v3 [cs.CL] UPDATED)
79. Efficient Neural Neighborhood Search for Pickup and Delivery Problems. (arXiv:2204.11399v3 [cs.LG] UPDATED)
80. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v4 [cs.LG] UPDATED)
81. AIGenC: AI generalisation via creativity. (arXiv:2205.09738v3 [cs.AI] UPDATED)
82. Translating Hanja historical documents to understandable Korean and English. (arXiv:2205.10019v2 [cs.CL] UPDATED)
83. Diversity vs. Recognizability: Human-like generalization in one-shot generative models. (arXiv:2205.10370v3 [cs.AI] UPDATED)
84. What You See is What You Classify: Black Box Attributions. (arXiv:2205.11266v2 [cs.CV] UPDATED)
85. Wireless Ad Hoc Federated Learning: A Fully Distributed Cooperative Machine Learning. (arXiv:2205.11779v2 [cs.LG] UPDATED)
86. Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate Model Predictive Trajectory Tracking. (arXiv:2206.03305v3 [cs.RO] UPDATED)
87. K-Radar: 4D Radar Object Detection for Autonomous Driving in Various Weather Conditions. (arXiv:2206.08171v2 [cs.CV] UPDATED)
88. On the Generalizability and Predictability of Recommender Systems. (arXiv:2206.11886v2 [cs.IR] UPDATED)
89. Eco-driving for Electric Connected Vehicles at Signalized Intersections: A Parameterized Reinforcement Learning approach. (arXiv:2206.12065v2 [cs.RO] UPDATED)
90. A General Recipe for Likelihood-free Bayesian Optimization. (arXiv:2206.13035v2 [cs.LG] UPDATED)
91. CausalAgents: A Robustness Benchmark for Motion Forecasting using Causal Relationships. (arXiv:2207.03586v2 [cs.LG] UPDATED)
92. Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning. (arXiv:2207.09081v2 [cs.LG] UPDATED)
93. The Alberta Plan for AI Research. (arXiv:2208.11173v2 [cs.AI] UPDATED)
94. FedPrompt: Communication-Efficient and Privacy Preserving Prompt Tuning in Federated Learning. (arXiv:2208.12268v2 [cs.LG] UPDATED)
95. Git Re-Basin: Merging Models modulo Permutation Symmetries. (arXiv:2209.04836v2 [cs.LG] UPDATED)
96. Taking a Respite from Representation Learning for Molecular Property Prediction. (arXiv:2209.13492v2 [q-bio.QM] UPDATED)
97. Image-Based Detection of Modifications in Gas Pump PCBs with Deep Convolutional Autoencoders. (arXiv:2210.00100v2 [cs.CV] UPDATED)
98. Simple Pooling Front-ends For Efficient Audio Classification. (arXiv:2210.00943v2 [eess.AS] UPDATED)
99. Memory in humans and deep language models: Linking hypotheses for model augmentation. (arXiv:2210.01869v2 [cs.CL] UPDATED)
100. Contextualized Generative Retrieval. (arXiv:2210.02068v2 [cs.IR] UPDATED)

