# Your interest papers
---
## cs.CV
---
### S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v1 [cs.CV])
- Authors : Chenhui Yang, Chenxi Huang, Tewodros Legesse, Xin Hong
- Link : [http://arxiv.org/abs/2206.07298](http://arxiv.org/abs/2206.07298)
> ABSTRACT  :  Modern high-performance semantic segmentation methods employ a heavy backbone and dilated convolution to extract the relevant feature. Although extracting features with both contextual and semantic information is critical for the segmentation tasks, it brings a memory footprint and high computation cost for real-time applications. This paper presents a new model to achieve a trade-off between accuracy/speed for real-time road scene semantic segmentation. Specifically, we proposed a lightweight model named Scale-aware Strip Attention Guided Feature Pyramid Network (S\textsuperscript{2}-FPN). Our network consists of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts an attention mechanisms to learn discriminative multi-scale features and help close the semantic gap between different levels. APF uses the scale-aware attention to encode global context with vertical stripping operation and models the long-range dependencies, which helps relate pixels with similar semantic label. In addition, APF employs channel-wise reweighting block (CRB) to emphasize the channel features. Finally, the decoder of S\textsuperscript{2}-FPN then adopts GFU, which is used to fuse features from APF and the encoder. Extensive experiments have been conducted on two challenging semantic segmentation benchmarks, which demonstrate that our approach achieves better accuracy/speed trade-off with different model settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS, 77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and 69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this work will be made available at \url{https://github.com/mohamedac29/S2-FPN  
### SP-ViT: Learning 2D Spatial Priors for Vision Transformers. (arXiv:2206.07662v1 [cs.CV])
- Authors : Yuxuan Zhou, Wangmeng Xiang, Chao Li, Biao Wang, Xihan Wei, **Lei Zhang**, Margret Keuper, Xiansheng Hua
- Link : [http://arxiv.org/abs/2206.07662](http://arxiv.org/abs/2206.07662)
> ABSTRACT  :  Recently, transformers have shown great potential in image classification and established state-of-the-art results on the ImageNet benchmark. However, compared to CNNs, transformers converge slowly and are prone to overfitting in low-data regimes due to the lack of spatial inductive biases. Such spatial inductive biases can be especially beneficial since the 2D structure of an input image is not well preserved in transformers. In this work, we present Spatial Prior-enhanced Self-Attention (SP-SA), a novel variant of vanilla Self-Attention (SA) tailored for vision transformers. Spatial Priors (SPs) are our proposed family of inductive biases that highlight certain groups of spatial relations. Unlike convolutional inductive biases, which are forced to focus exclusively on hard-coded local regions, our proposed SPs are learned by the model itself and take a variety of spatial relations into account. Specifically, the attention score is calculated with emphasis on certain kinds of spatial relations at each head, and such learned spatial foci can be complementary to each other. Based on SP-SA we propose the SP-ViT family, which consistently outperforms other ViT models with similar GFlops or parameters. Our largest model SP-ViT-L achieves a record-breaking 86.3% Top-1 accuracy with a reduction in the number of parameters by almost 50% compared to previous state-of-the-art model (150M for SP-ViT-L vs 271M for CaiT-M-36) among all ImageNet-1K models trained on 224x224 and fine-tuned on 384x384 resolution w/o extra data.  
### Neural Deformable Voxel Grid for Fast Optimization of Dynamic View Synthesis. (arXiv:2206.07698v1 [cs.CV])
- Authors : Xiang Guo, Guanying Chen, Yuchao Dai, Xiaoqing Ye, Jiadai Sun, Xiao Tan, Errui Ding
- Link : [http://arxiv.org/abs/2206.07698](http://arxiv.org/abs/2206.07698)
> ABSTRACT  :  Recently, Neural Radiance Fields (**NeRF**) is revolutionizing the task of novel view synthesis (NVS) for its superior performance. However, **NeRF** and its variants generally require a lengthy per-scene training procedure, where a multi-layer perceptron (MLP) is fitted to the captured images. To remedy the challenge, the voxel-grid representation has been proposed to significantly speed up the training. However, these existing methods can only deal with static scenes. How to develop an efficient and accurate dynamic view synthesis method remains an open problem. Extending the methods for static scenes to dynamic scenes is not straightforward as both the scene geometry and appearance change over time. In this paper, built on top of the recent advances in voxel-grid optimization, we propose a fast deformable radiance field method to handle dynamic scenes. Our method consists of two modules. The first module adopts a deformation grid to store 3D dynamic features, and a light-weight MLP for decoding the deformation that maps a 3D point in observation space to the canonical space using the interpolated features. The second module contains a density and a color grid to model the geometry and density of the scene. The occlusion is explicitly modeled to further improve the rendering quality. Experimental results show that our method achieves comparable performance to D-**NeRF** using only 20 minutes for training, which is more than 70x faster than D-**NeRF**, clearly demonstrating the efficiency of our proposed method.  
### Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v1 [cs.CV])
- Authors : Jiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew Soon, Chen Change
- Link : [http://arxiv.org/abs/2206.07706](http://arxiv.org/abs/2206.07706)
> ABSTRACT  :  We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese framework can learn meaningful representations even using none of the following: (i) extra data, (ii) extra model, (iii) mask token. Experimental results on ImageNet and several robustness benchmarks show the competitive performance and advanced robustness of MFM compared with recent masked image modeling approaches. Furthermore, we also comprehensively investigate the effectiveness of classical image **restoration** tasks for representation learning from a unified frequency perspective and reveal their intriguing relations with our MFM approach. Project page: https://www.mmlab-ntu.com/project/mfm/index.html.  
### PlanarRecon: **Real-time** 3D Plane Detection and Reconstruction from Posed Monocular Videos. (arXiv:2206.07710v1 [cs.CV])
- Authors : Yiming Xie, Matheus Gadelha, Fengting Yang, Xiaowei Zhou, Huaizu Jiang
- Link : [http://arxiv.org/abs/2206.07710](http://arxiv.org/abs/2206.07710)
> ABSTRACT  :  We present PlanarRecon -- a novel framework for globally coherent detection and reconstruction of 3D planes from a posed monocular video. Unlike previous works that detect planes in 2D from a single image, PlanarRecon incrementally detects planes in 3D for each video fragment, which consists of a set of key frames, from a volumetric representation of the scene using neural networks. A learning-based tracking and fusion module is designed to merge planes from previous fragments to form a coherent global plane reconstruction. Such design allows PlanarRecon to integrate observations from multiple views within each fragment and temporal information across different ones, resulting in an accurate and coherent reconstruction of the scene abstraction with low-polygonal geometry. Experiments show that the proposed approach achieves state-of-the-art performances on the ScanNet dataset while being real-time.  
### NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis. (arXiv:2108.03880v2 [cs.CV] UPDATED)
- Authors : Radu Alexandru, Sven Behnke
- Link : [http://arxiv.org/abs/2108.03880](http://arxiv.org/abs/2108.03880)
> ABSTRACT  :  Multi-View Stereo (MVS) is a core task in 3D computer vision. With the surge of novel deep learning methods, learned MVS has surpassed the accuracy of classical approaches, but still relies on building a memory intensive dense cost volume. Novel View Synthesis (NVS) is a parallel line of research and has recently seen an increase in popularity with Neural Radiance Field (**NeRF**) models, which optimize a per scene radiance field. However, **NeRF** methods do not generalize to novel scenes and are slow to train and test. We propose to bridge the gap between these two methodologies with a novel network that can recover 3D scene geometry as a distance function, together with high-resolution color images. Our method uses only a sparse set of images as input and can generalize well to novel scenes. Additionally, we propose a coarse-to-fine sphere tracing approach in order to significantly increase speed. We show on various datasets that our method reaches comparable accuracy to per-scene optimized methods while being able to generalize and running significantly faster. We provide the source code at https://github.com/AIS-Bonn/neural_mvs  
### Human**NeRF**: Free-viewpoint Rendering of Moving People from Monocular Video. (arXiv:2201.04127v2 [cs.CV] UPDATED)
- Authors : Yi Weng, Brian Curless, Ira Kemelmacher
- Link : [http://arxiv.org/abs/2201.04127](http://arxiv.org/abs/2201.04127)
> ABSTRACT  :  We introduce a free-viewpoint rendering method -- Human**NeRF** -- that works on a given monocular video of a human performing complex body motions, e.g. a video from YouTube. Our method enables pausing the video at any frame and rendering the subject from arbitrary new camera viewpoints or even a full 360-degree camera path for that particular frame and body pose. This task is particularly challenging, as it requires synthesizing photorealistic details of the body, as seen from various camera angles that may not exist in the input video, as well as synthesizing fine details such as cloth folds and facial appearance. Our method optimizes for a volumetric representation of the person in a canonical T-pose, in concert with a motion field that maps the estimated canonical representation to every frame of the video via backward warps. The motion field is decomposed into skeletal rigid and non-rigid motions, produced by deep networks. We show significant performance improvements over prior work, and compelling examples of free-viewpoint renderings from monocular video of moving humans in challenging uncontrolled capture scenarios.  
### VRT: A Video **Restoration** Transformer. (arXiv:2201.12288v2 [cs.CV] UPDATED)
- Authors : Jingyun Liang, Jiezhang Cao, Yuchen Fan, Kai Zhang, Rakesh Ranjan, Yawei Li, Radu Timofte, Luc Van
- Link : [http://arxiv.org/abs/2201.12288](http://arxiv.org/abs/2201.12288)
> ABSTRACT  :  Video **restoration** (e.g., video super-resolution) aims to restore high-quality frames from low-quality frames. Different from single image **restoration**, video **restoration** generally requires to utilize temporal information from multiple adjacent but usually misaligned video frames. Existing deep methods generally tackle with this by exploiting a sliding window strategy or a recurrent architecture, which either is restricted by frame-by-frame **restoration** or lacks long-range modelling ability. In this paper, we propose a Video **Restoration** Transformer (VRT) with parallel frame prediction and long-range temporal dependency modelling abilities. More specifically, VRT is composed of multiple scales, each of which consists of two kinds of modules: temporal mutual self attention (TMSA) and parallel warping. TMSA divides the video into small clips, on which mutual attention is applied for joint motion estimation, feature alignment and feature fusion, while self attention is used for feature extraction. To enable cross-clip interactions, the video sequence is shifted for every other layer. Besides, parallel warping is used to further fuse information from neighboring frames by parallel feature warping. Experimental results on five tasks, including video super-resolution, video deblurring, video denoising, video frame interpolation and space-time video super-resolution, demonstrate that VRT outperforms the state-of-the-art methods by large margins ($\textbf{up to 2.16dB}$) on fourteen benchmark datasets.  
### NeMF: Neural Motion Fields for Kinematic Animation. (arXiv:2206.03287v2 [cs.CV] UPDATED)
- Authors : Chengan He, Jun Saito, James Zachary, Holly Rushmeier, Yi Zhou
- Link : [http://arxiv.org/abs/2206.03287](http://arxiv.org/abs/2206.03287)
> ABSTRACT  :  We present an **implicit neural representation** to learn the spatio-temporal space of kinematic motions. Unlike previous work that represents motion as discrete sequential samples, we propose to express the vast motion space as a continuous function over time, hence the name Neural Motion Fields (NeMF). Specifically, we use a neural network to learn this function for miscellaneous sets of motions, which is designed to be a generative model conditioned on a temporal coordinate $t$ and a random vector $z$ for controlling the style. The model is then trained as a Variational Autoencoder (VAE) with motion encoders to sample the latent space. We train our model with diverse human motion dataset and quadruped dataset to prove its versatility, and finally deploy it as a generic motion prior to solve task-agnostic problems and show its superiority in different motion generation and editing applications, such as motion interpolation, in-betweening, and re-navigating. More details can be found on our project page: https://cs.yale.edu/homes/che/projects/nemf/  
## eess.IV
---
### VRT: A Video **Restoration** Transformer. (arXiv:2201.12288v2 [cs.CV] UPDATED)
- Authors : Jingyun Liang, Jiezhang Cao, Yuchen Fan, Kai Zhang, Rakesh Ranjan, Yawei Li, Radu Timofte, Luc Van
- Link : [http://arxiv.org/abs/2201.12288](http://arxiv.org/abs/2201.12288)
> ABSTRACT  :  Video **restoration** (e.g., video super-resolution) aims to restore high-quality frames from low-quality frames. Different from single image **restoration**, video **restoration** generally requires to utilize temporal information from multiple adjacent but usually misaligned video frames. Existing deep methods generally tackle with this by exploiting a sliding window strategy or a recurrent architecture, which either is restricted by frame-by-frame **restoration** or lacks long-range modelling ability. In this paper, we propose a Video **Restoration** Transformer (VRT) with parallel frame prediction and long-range temporal dependency modelling abilities. More specifically, VRT is composed of multiple scales, each of which consists of two kinds of modules: temporal mutual self attention (TMSA) and parallel warping. TMSA divides the video into small clips, on which mutual attention is applied for joint motion estimation, feature alignment and feature fusion, while self attention is used for feature extraction. To enable cross-clip interactions, the video sequence is shifted for every other layer. Besides, parallel warping is used to further fuse information from neighboring frames by parallel feature warping. Experimental results on five tasks, including video super-resolution, video deblurring, video denoising, video frame interpolation and space-time video super-resolution, demonstrate that VRT outperforms the state-of-the-art methods by large margins ($\textbf{up to 2.16dB}$) on fourteen benchmark datasets.  
## cs.LG
---
### Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v1 [cs.IR])
- Authors : Yuta Saito, Thorsten Joachims
- Link : [http://arxiv.org/abs/2206.07247](http://arxiv.org/abs/2206.07247)
> ABSTRACT  :  Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates **exposure** -- and thus economic opportunity -- to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item **exposure** to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond **exposure**. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional **exposure**-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.  
### Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v1 [cs.CV])
- Authors : Jiahao Xie, Wei Li, Xiaohang Zhan, Ziwei Liu, Yew Soon, Chen Change
- Link : [http://arxiv.org/abs/2206.07706](http://arxiv.org/abs/2206.07706)
> ABSTRACT  :  We present Masked Frequency Modeling (MFM), a unified frequency-domain-based approach for self-supervised pre-training of visual models. Instead of randomly inserting mask tokens to the input embeddings in the spatial domain, in this paper, we shift the perspective to the frequency domain. Specifically, MFM first masks out a portion of frequency components of the input image and then predicts the missing frequencies on the frequency spectrum. Our key insight is that predicting masked components in the frequency domain is more ideal to reveal underlying image patterns rather than predicting masked patches in the spatial domain, due to the heavy spatial redundancy. Our findings suggest that with the right configuration of mask-and-predict strategy, both the structural information within high-frequency components and the low-level statistics among low-frequency counterparts are useful in learning good representations. For the first time, MFM demonstrates that, for both ViT and CNN, a simple non-Siamese framework can learn meaningful representations even using none of the following: (i) extra data, (ii) extra model, (iii) mask token. Experimental results on ImageNet and several robustness benchmarks show the competitive performance and advanced robustness of MFM compared with recent masked image modeling approaches. Furthermore, we also comprehensively investigate the effectiveness of classical image **restoration** tasks for representation learning from a unified frequency perspective and reveal their intriguing relations with our MFM approach. Project page: https://www.mmlab-ntu.com/project/mfm/index.html.  
### Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition. (arXiv:2203.05008v2 [cs.CL] UPDATED)
- Authors : Ronny Huang, Cal Peyser, Ruoming Pang, Trevor Strohman, Shankar Kumar
- Link : [http://arxiv.org/abs/2203.05008](http://arxiv.org/abs/2203.05008)
> ABSTRACT  :  Language model fusion helps smart assistants recognize words which are rare in acoustic data but abundant in text-only corpora (typed search logs). However, such corpora have properties that hinder downstream performance, including being (1) too large, (2) beset with domain-mismatched content, and (3) heavy-headed rather than heavy-tailed (excessively many duplicate search queries such as "weather"). We show that three simple strategies for selecting language modeling data can dramatically improve rare-word recognition without harming overall performance. First, to address the heavy-headedness, we downsample the data according to a soft log function, which tunably reduces high frequency (head) sentences. Second, to encourage rare-word **exposure**, we explicitly filter for words rare in the acoustic data. Finally, we tackle domain-mismatch via perplexity-based contrastive selection, filtering for examples matched to the target domain. We down-select a large corpus of web search queries by a factor of 53x and achieve better LM perplexities than without down-selection. When shallow-fused with a state-of-the-art, production speech engine, our LM achieves WER reductions of up to 24% relative on rare-word sentences (without changing overall WER) compared to a baseline LM trained on the raw corpus. These gains are further validated through favorable side-by-side evaluations on live voice search traffic.  
### MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data. (arXiv:2203.12369v5 [cs.SD] UPDATED)
- Authors : George Close, Thomas Hain, Stefan Goetze
- Link : [http://arxiv.org/abs/2203.12369](http://arxiv.org/abs/2203.12369)
> ABSTRACT  :  Training of speech **enhancement** systems often does not incorporate knowledge of human perception and thus can lead to unnatural sounding results. Incorporating psychoacoustically motivated speech perception metrics as part of model training via a predictor network has recently gained interest. However, the performance of such predictors is limited by the distribution of metric scores that appear in the training data. In this work, we propose MetricGAN+/- (an extension of MetricGAN+, one such metric-motivated system) which introduces an additional network - a "de-generator" which attempts to improve the robustness of the prediction network (and by extension of the generator) by ensuring observation of a wider range of metric scores in training. Experimental results on the VoiceBank-DEMAND dataset show relative improvement in PESQ score of 3.8% (3.05 vs 3.22 PESQ score), as well as better generalisation to unseen noise and speech.  
### Deep Learning-based Massive MIMO CSI Acquisition for 5G Evolution and 6G. (arXiv:2206.04967v2 [eess.SP] UPDATED)
- Authors : Xin Wang, Xiaolin Hou, Lan Chen, Yoshihisa Kishiyama, Takahiro Asai
- Link : [http://arxiv.org/abs/2206.04967](http://arxiv.org/abs/2206.04967)
> ABSTRACT  :  Recently, inspired by successful applications in many fields, deep learning (DL) technologies for CSI acquisition have received considerable research interest from both academia and industry. Considering the practical feedback mechanism of 5th generation (5G) New radio (NR) networks, we propose two implementation schemes for artificial intelligence for CSI (AI4CSI), the DL-based receiver and end-to-end design, respectively. The proposed AI4CSI schemes were evaluated in 5G NR networks in terms of spectrum efficiency (SE), feedback overhead, and computational complexity, and compared with legacy schemes. To demonstrate whether these schemes can be used in real-life scenarios, both the modeled-based channel data and practically measured channels were used in our investigations. When DL-based CSI acquisition is applied to the receiver only, which has little air interface impact, it provides approximately 25\% SE gain at a moderate feedback overhead level. It is feasible to deploy it in current 5G networks during 5G evolutions. For the end-to-end DL-based CSI **enhancement**s, the evaluations also demonstrated their additional performance gain on SE, which is 6% -- 26% compared with DL-based receivers and 33% -- 58% compared with legacy CSI schemes. Considering its large impact on air-interface design, it will be a candidate technology for 6th generation (6G) networks, in which an air interface designed by artificial intelligence can be used.  
## cs.AI
---
### Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v1 [cs.IR])
- Authors : Yuta Saito, Thorsten Joachims
- Link : [http://arxiv.org/abs/2206.07247](http://arxiv.org/abs/2206.07247)
> ABSTRACT  :  Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates **exposure** -- and thus economic opportunity -- to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item **exposure** to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond **exposure**. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional **exposure**-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.  
### S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v1 [cs.CV])
- Authors : Chenhui Yang, Chenxi Huang, Tewodros Legesse, Xin Hong
- Link : [http://arxiv.org/abs/2206.07298](http://arxiv.org/abs/2206.07298)
> ABSTRACT  :  Modern high-performance semantic segmentation methods employ a heavy backbone and dilated convolution to extract the relevant feature. Although extracting features with both contextual and semantic information is critical for the segmentation tasks, it brings a memory footprint and high computation cost for real-time applications. This paper presents a new model to achieve a trade-off between accuracy/speed for real-time road scene semantic segmentation. Specifically, we proposed a lightweight model named Scale-aware Strip Attention Guided Feature Pyramid Network (S\textsuperscript{2}-FPN). Our network consists of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts an attention mechanisms to learn discriminative multi-scale features and help close the semantic gap between different levels. APF uses the scale-aware attention to encode global context with vertical stripping operation and models the long-range dependencies, which helps relate pixels with similar semantic label. In addition, APF employs channel-wise reweighting block (CRB) to emphasize the channel features. Finally, the decoder of S\textsuperscript{2}-FPN then adopts GFU, which is used to fuse features from APF and the encoder. Extensive experiments have been conducted on two challenging semantic segmentation benchmarks, which demonstrate that our approach achieves better accuracy/speed trade-off with different model settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS, 77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and 69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this work will be made available at \url{https://github.com/mohamedac29/S2-FPN  
### E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations. (arXiv:2206.07578v1 [cs.AI])
- Authors : Jongwan Kim, DongJin Lee, Byunggook Na, Seongsik Park, Jeonghee Jo, Sungroh Yoon
- Link : [http://arxiv.org/abs/2206.07578](http://arxiv.org/abs/2206.07578)
> ABSTRACT  :  Event cameras respond to brightness changes in the scene asynchronously and independently for every pixel. Due to the properties, these cameras have distinct features: **high dynamic range** (**HDR**), high temporal resolution, and low power consumption. However, the results of event cameras should be processed into an alternative representation for computer vision tasks. Also, they are usually noisy and cause poor performance in areas with few events. In recent years, numerous researchers have attempted to reconstruct videos from events. However, they do not provide good quality videos due to a lack of temporal information from irregular and discontinuous data. To overcome these difficulties, we introduce an E2V-SDE whose dynamics are governed in a latent space by Stochastic differential equations (SDE). Therefore, E2V-SDE can rapidly reconstruct images at arbitrary time steps and make realistic predictions on unseen data. In addition, we successfully adopted a variety of image composition techniques for improving image clarity and temporal consistency. By conducting extensive experiments on simulated and real-scene datasets, we verify that our model outperforms state-of-the-art approaches under various video reconstruction settings. In terms of image quality, the LPIPS score improves by up to 12% and the reconstruction speed is 87% higher than that of ET-Net.  
### A World-Self Model Towards Understanding Intelligence. (arXiv:2203.13762v3 [cs.AI] UPDATED)
- Authors : Yutao Yue
- Link : [http://arxiv.org/abs/2203.13762](http://arxiv.org/abs/2203.13762)
> ABSTRACT  :  The symbolism, connectionism and behaviorism approaches of artificial intelligence have achieved a lot of successes in various tasks, while we still do not have a clear definition of "intelligence" with enough consensus in the community (although there are over 70 different "versions" of definitions). The nature of intelligence is still in **dark**ness. In this work we do not take any of these three traditional approaches, instead we try to identify certain fundamental aspects of the nature of intelligence, and construct a mathematical model to represent and potentially reproduce these fundamental aspects. We first stress the importance of defining the scope of discussion and granularity of investigation. We carefully compare human and artificial intelligence, and qualitatively demonstrate an information abstraction process, which we propose to be the key to connect perception and cognition. We then present the broader idea of "concept", separate the idea of self model out of the world model, and construct a new model called world-self model (WSM). We show the mechanisms of creating and connecting concepts, and the flow of how the WSM receives, processes and outputs information with respect to an arbitrary type of problem to solve. We also consider and discuss the potential computer implementation issues of the proposed theoretical framework, and finally we propose a unified general framework of intelligence based on WSM.  
# Paper List
---
## cs.CV
---
**122** new papers in cs.CV:-) 
1. Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience. (arXiv:2206.07081v1 [cs.LG])
2. TriHorn-Net: A Model for Accurate Depth-Based 3D Hand Pose Estimation. (arXiv:2206.07117v1 [cs.CV])
3. Loss Functions for Classification using Structured Entropy. (arXiv:2206.07122v1 [stat.ML])
4. Self-Supervised Pretraining for Differentially Private Learning. (arXiv:2206.07125v1 [cs.CV])
5. Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v1 [cs.LG])
6. It's Time for Artistic Correspondence in Music and Video. (arXiv:2206.07148v1 [cs.MM])
7. Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut Features. (arXiv:2206.07155v1 [cs.LG])
8. Federated Multi-organ Segmentation with Partially Labeled Data. (arXiv:2206.07156v1 [eess.IV])
9. LAVENDER: Unifying Video-Language Understanding as Masked Language Modeling. (arXiv:2206.07160v1 [cs.CV])
10. Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v1 [cs.CV])
11. DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method. (arXiv:2206.07163v1 [cs.CV])
12. Automated image analysis in large-scale cellular electron microscopy: A literature survey. (arXiv:2206.07171v1 [cs.CV])
13. Measuring Representational Harms in Image Captioning. (arXiv:2206.07173v1 [cs.CY])
14. Proximal Splitting Adversarial Attacks for Semantic Segmentation. (arXiv:2206.07179v1 [cs.LG])
15. Surgical Phase Recognition in Laparoscopic Cholecystectomy. (arXiv:2206.07198v1 [cs.CV])
16. Multimodal Event Graphs: Towards Event Centric Understanding of Multimodal World. (arXiv:2206.07207v1 [cs.CV])
17. A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects. (arXiv:2206.07219v1 [eess.IV])
18. Test-Time Adaptation for Visual Document Understanding. (arXiv:2206.07240v1 [cs.CV])
19. GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds. (arXiv:2206.07255v1 [cs.CV])
20. Self-Supervised Learning of Image Scale and Orientation. (arXiv:2206.07259v1 [cs.CV])
21. On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation. (arXiv:2206.07260v1 [cs.LG])
22. Rethinking Generalization in Few-Shot Classification. (arXiv:2206.07267v1 [cs.CV])
23. Machine vision for vial positioning detection toward the safe automation of material synthesis. (arXiv:2206.07272v1 [cs.CV])
24. ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance Image Reconstructions. (arXiv:2206.07280v1 [eess.IV])
25. Super-resolution image display using diffractive decoders. (arXiv:2206.07281v1 [physics.optics])
26. Human Eyes Inspired Recurrent Neural Networks are More Robust Against Adversarial Noises. (arXiv:2206.07282v1 [cs.CV])
27. Differentiable Top-k Classification Learning. (arXiv:2206.07290v1 [cs.LG])
28. S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v1 [cs.CV])
29. VCT: A Video Compression Transformer. (arXiv:2206.07307v1 [cs.CV])
30. Recent Advances in Scene Image Representation and Classification. (arXiv:2206.07326v1 [cs.CV])
31. Automatic Detection of Rice Disease in Images of Various Leaf Sizes. (arXiv:2206.07344v1 [cs.CV])
32. Unsupervised Capsule Networks of High-Dimension Point Clouds classification. (arXiv:2206.07348v1 [cs.CV])
33. XMorpher: Full Transformer for Deformable Medical Image Registration via Cross Attention. (arXiv:2206.07349v1 [cs.CV])
34. Robust SAR ATR on MSTAR with Deep Learning Models trained on Full Synthetic MOCEM data. (arXiv:2206.07352v1 [cs.AI])
35. Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction. (arXiv:2206.07364v1 [eess.IV])
36. MonoGround: Detecting Monocular 3D Objects from the Ground. (arXiv:2206.07372v1 [cs.CV])
37. The Manifold Hypothesis for Gradient-Based Explanations. (arXiv:2206.07387v1 [cs.LG])
38. Subsurface Depths Structure Maps Reconstruction with Generative Adversarial Networks. (arXiv:2206.07388v1 [physics.geo-ph])
39. Ultra Fast Deep Lane Detection with Hybrid Anchor Driven Ordinal Classification. (arXiv:2206.07389v1 [cs.CV])
40. Efficient Adaptive Ensembling for Image Classification. (arXiv:2206.07394v1 [cs.CV])
41. Interpretable differential diagnosis for Alzheimer's disease and Frontotemporal dementia. (arXiv:2206.07417v1 [eess.IV])
42. Deep Neural Network Pruning for Nuclei Instance Segmentation in Hematoxylin & Eosin-Stained Histological Images. (arXiv:2206.07422v1 [eess.IV])
43. Zero-shot object goal visual navigation. (arXiv:2206.07423v1 [cs.CV])
44. Physically-admissible polarimetric data augmentation for road-scene analysis. (arXiv:2206.07431v1 [cs.CV])
45. Self-Supervised Implicit Attention: Guided Attention by The Model Itself. (arXiv:2206.07434v1 [cs.CV])
46. Forecasting of depth and ego-motion with transformers and self-supervision. (arXiv:2206.07435v1 [cs.CV])
47. VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection. (arXiv:2206.07458v1 [cs.CV])
48. READ: Aggregating Reconstruction Error into Out-of-distribution Detection. (arXiv:2206.07459v1 [cs.CV])
49. Coarse-to-fine Deep Video Coding with Hyperprior-guided Mode Prediction. (arXiv:2206.07460v1 [cs.CV])
50. PolyU-BPCoMa: A Dataset and Benchmark Towards Mobile Colorized Mapping Using a Backpack Multisensorial System. (arXiv:2206.07468v1 [cs.CV])
51. A Survey of Detection Methods for Die Attachment and Wire Bonding Defects in Integrated Circuit Manufacturing. (arXiv:2206.07481v1 [eess.SP])
52. Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation. (arXiv:2206.07510v1 [cs.CV])
53. Body Gesture Recognition to Control a Social Robot. (arXiv:2206.07538v1 [cs.RO])
54. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v1 [q-bio.NC])
55. How to Reduce Change Detection to Semantic Segmentation. (arXiv:2206.07557v1 [cs.CV])
56. A Meta-Analysis of Distributionally-Robust Models. (arXiv:2206.07565v1 [cs.CV])
57. Evaluating object detector ensembles for improving the robustness of artifact detection in endoscopic video streams. (arXiv:2206.07580v1 [cs.CV])
58. BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and Clinical Data. (arXiv:2206.07595v1 [eess.IV])
59. How GNNs Facilitate CNNs in Mining Geometric Information from Large-Scale Medical Images. (arXiv:2206.07599v1 [eess.IV])
60. Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation. (arXiv:2206.07634v1 [cs.CV])
61. Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone. (arXiv:2206.07643v1 [cs.CV])
62. SP-ViT: Learning 2D Spatial Priors for Vision Transformers. (arXiv:2206.07662v1 [cs.CV])
63. CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation. (arXiv:2206.07664v1 [eess.IV])
64. A Unified Sequence Interface for Vision Tasks. (arXiv:2206.07669v1 [cs.CV])
65. AVATAR: Unconstrained Audiovisual Speech Recognition. (arXiv:2206.07684v1 [cs.CV])
66. Residual Sparsity Connection Learning for Efficient Video Super-Resolution. (arXiv:2206.07687v1 [cs.CV])
67. Structured Video Tokens @ Ego4D PNR Temporal Localization Challenge 2022. (arXiv:2206.07689v1 [cs.CV])
68. ELUDE: Generating interpretable explanations via a decomposition into labelled and unlabelled features. (arXiv:2206.07690v1 [cs.CV])
69. A Simple Data Mixing Prior for Improving Self-Supervised Learning. (arXiv:2206.07692v1 [cs.CV])
70. VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids. (arXiv:2206.07695v1 [cs.CV])
71. Diffusion Models for Video Prediction and Infilling. (arXiv:2206.07696v1 [cs.CV])
72. Neural Deformable Voxel Grid for Fast Optimization of Dynamic View Synthesis. (arXiv:2206.07698v1 [cs.CV])
73. Prefix Language Models are Unified Modal Learners. (arXiv:2206.07699v1 [cs.CV])
74. Masked Siamese ConvNets. (arXiv:2206.07700v1 [cs.CV])
75. Waymo Open Dataset: Panoramic Video Panoptic Segmentation. (arXiv:2206.07704v1 [cs.CV])
76. LET-3D-AP: Longitudinal Error Tolerant 3D Average Precision for Camera-Only 3D Detection. (arXiv:2206.07705v1 [cs.CV])
77. Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v1 [cs.CV])
78. Variable Bitrate Neural Fields. (arXiv:2206.07707v1 [cs.CV])
79. PlanarRecon: **Real-time** 3D Plane Detection and Reconstruction from Posed Monocular Videos. (arXiv:2206.07710v1 [cs.CV])
80. You Are How You Walk: Uncooperative MoCap Gait Identification for Video Surveillance with Incomplete and Noisy Data. (arXiv:1706.09443v3 [cs.CV] UPDATED)
81. Towards Understanding Adversarial Robustness of Optical Flow Networks. (arXiv:2103.16255v3 [cs.CV] UPDATED)
82. Graphical Modeling for Multi-Source Domain Adaptation. (arXiv:2104.13057v2 [cs.CV] UPDATED)
83. Vision Transformers with Hierarchical Attention. (arXiv:2106.03180v3 [cs.CV] UPDATED)
84. NeuralMVS: Bridging Multi-View Stereo and Novel View Synthesis. (arXiv:2108.03880v2 [cs.CV] UPDATED)
85. PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery. (arXiv:2109.04352v2 [eess.IV] UPDATED)
86. Ripple Attention for Visual Perception with Sub-quadratic Complexity. (arXiv:2110.02453v2 [cs.CV] UPDATED)
87. Shifting Capsule Networks from the Cloud to the Deep Edge. (arXiv:2110.02911v2 [cs.LG] UPDATED)
88. TLDR: Twin Learning for Dimensionality Reduction. (arXiv:2110.09455v2 [cs.CV] UPDATED)
89. Neural Network Kalman filtering for 3D object tracking from linear array ultrasound data. (arXiv:2111.09631v3 [stat.AP] UPDATED)
90. MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection. (arXiv:2111.13336v5 [cs.CV] UPDATED)
91. Learning a model of shape selectivity in V4 cells reveals shape encoding mechanisms in the brain. (arXiv:2111.14250v3 [q-bio.NC] UPDATED)
92. Facial-Sketch Synthesis: A New Challenge. (arXiv:2112.15439v5 [cs.CV] UPDATED)
93. Weakly-supervised continual learning for class-incremental segmentation. (arXiv:2201.01029v2 [cs.CV] UPDATED)
94. Enhancing Egocentric 3D Pose Estimation with Third Person Views. (arXiv:2201.02017v3 [cs.CV] UPDATED)
95. Human**NeRF**: Free-viewpoint Rendering of Moving People from Monocular Video. (arXiv:2201.04127v2 [cs.CV] UPDATED)
96. Maximizing Self-supervision from Thermal Image for Effective Self-supervised Learning of Depth and Ego-motion. (arXiv:2201.04387v2 [cs.RO] UPDATED)
97. You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v3 [cs.CV] UPDATED)
98. VRT: A Video **Restoration** Transformer. (arXiv:2201.12288v2 [cs.CV] UPDATED)
99. TPC: Transformation-Specific Smoothing for Point Cloud Models. (arXiv:2201.12733v3 [cs.CV] UPDATED)
100. Eikonal Fields for Refractive Novel-View Synthesis. (arXiv:2202.00948v3 [cs.GR] UPDATED)
101. Task Specific Attention is one more thing you need for object detection. (arXiv:2202.09048v4 [cs.CV] UPDATED)
102. Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction. (arXiv:2203.01474v2 [cs.CV] UPDATED)
103. PETR: Position Embedding Transformation for Multi-View 3D Object Detection. (arXiv:2203.05625v2 [cs.CV] UPDATED)
104. Transform your Smartphone into a DSLR Camera: Learning the ISP in the Wild. (arXiv:2203.10636v3 [cs.CV] UPDATED)
105. Associating Objects with Scalable Transformers for Video Object Segmentation. (arXiv:2203.11442v4 [cs.CV] UPDATED)
106. Revisiting Multi-Scale Feature Fusion for Semantic Segmentation. (arXiv:2203.12683v2 [cs.CV] UPDATED)
107. Learning to Reduce Information Bottleneck for Object Detection in Aerial Images. (arXiv:2204.02033v2 [cs.CV] UPDATED)
108. Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v2 [cs.LG] UPDATED)
109. FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and Support-Vector Machines. (arXiv:2204.05112v3 [cs.CV] UPDATED)
110. Multimodal Dual Emotion with Fusion of Visual Sentiment for Rumor Detection. (arXiv:2204.11515v2 [cs.CY] UPDATED)
111. Symbolic Expression Transformer: A Computer Vision Approach for Symbolic Regression. (arXiv:2205.11798v2 [cs.CV] UPDATED)
112. MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose. (arXiv:2205.12583v2 [cs.CV] UPDATED)
113. CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks. (arXiv:2206.01992v4 [cs.CV] UPDATED)
114. Utility of Equivariant Message Passing in Cortical Mesh Segmentation. (arXiv:2206.03164v2 [cs.CV] UPDATED)
115. NeMF: Neural Motion Fields for Kinematic Animation. (arXiv:2206.03287v2 [cs.CV] UPDATED)
116. Delving into the Pre-training Paradigm of Monocular 3D Object Detection. (arXiv:2206.03657v2 [cs.CV] UPDATED)
117. Bringing Image Scene Structure to Video via Frame-Clip Consistency of Object Tokens. (arXiv:2206.06346v2 [cs.CV] UPDATED)
118. Fitting Segmentation Networks on Varying Image Resolutions using Splatting. (arXiv:2206.06445v2 [eess.IV] UPDATED)
119. RF-Next: Efficient Receptive Field Search for Convolutional Neural Networks. (arXiv:2206.06637v2 [cs.CV] UPDATED)
120. Interpretable Gait Recognition by Granger Causality. (arXiv:2206.06714v2 [cs.CV] UPDATED)
121. Efficient Decoder-free Object Detection with Transformers. (arXiv:2206.06829v2 [cs.CV] UPDATED)
122. Semi-Supervised Segmentation of Mitochondria from Electron Microscopy Images Using Spatial Continuity. (arXiv:2206.02392v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**23** new papers in eess.IV:-) 
1. Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning. (arXiv:2206.07050v1 [eess.IV])
2. Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience. (arXiv:2206.07081v1 [cs.LG])
3. Stability of image reconstruction algorithms. (arXiv:2206.07128v1 [math.OC])
4. Federated Multi-organ Segmentation with Partially Labeled Data. (arXiv:2206.07156v1 [eess.IV])
5. DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method. (arXiv:2206.07163v1 [cs.CV])
6. A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects. (arXiv:2206.07219v1 [eess.IV])
7. ERNAS: An Evolutionary Neural Architecture Search for Magnetic Resonance Image Reconstructions. (arXiv:2206.07280v1 [eess.IV])
8. VCT: A Video Compression Transformer. (arXiv:2206.07307v1 [cs.CV])
9. Robust SAR ATR on MSTAR with Deep Learning Models trained on Full Synthetic MOCEM data. (arXiv:2206.07352v1 [cs.AI])
10. Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction. (arXiv:2206.07364v1 [eess.IV])
11. Deep-based Film Grain Removal and Synthesis. (arXiv:2206.07411v1 [eess.IV])
12. Interpretable differential diagnosis for Alzheimer's disease and Frontotemporal dementia. (arXiv:2206.07417v1 [eess.IV])
13. Deep Neural Network Pruning for Nuclei Instance Segmentation in Hematoxylin & Eosin-Stained Histological Images. (arXiv:2206.07422v1 [eess.IV])
14. Coarse-to-fine Deep Video Coding with Hyperprior-guided Mode Prediction. (arXiv:2206.07460v1 [cs.CV])
15. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v1 [q-bio.NC])
16. BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and Clinical Data. (arXiv:2206.07595v1 [eess.IV])
17. How GNNs Facilitate CNNs in Mining Geometric Information from Large-Scale Medical Images. (arXiv:2206.07599v1 [eess.IV])
18. CRISP - Reliable Uncertainty Estimation for Medical Image Segmentation. (arXiv:2206.07664v1 [eess.IV])
19. Residual Sparsity Connection Learning for Efficient Video Super-Resolution. (arXiv:2206.07687v1 [cs.CV])
20. PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery. (arXiv:2109.04352v2 [eess.IV] UPDATED)
21. Neural Network Kalman filtering for 3D object tracking from linear array ultrasound data. (arXiv:2111.09631v3 [stat.AP] UPDATED)
22. VRT: A Video **Restoration** Transformer. (arXiv:2201.12288v2 [cs.CV] UPDATED)
23. Fitting Segmentation Networks on Varying Image Resolutions using Splatting. (arXiv:2206.06445v2 [eess.IV] UPDATED)
## cs.LG
---
**230** new papers in cs.LG:-) 
1. A smile is all you need: Predicting limiting activity coefficients from SMILES with natural language processing. (arXiv:2206.07048v1 [physics.chem-ph])
2. Near-Exact Recovery for Tomographic Inverse Problems via Deep Learning. (arXiv:2206.07050v1 [eess.IV])
3. Applications of Generative Adversarial Networks in Neuroimaging and Clinical Neuroscience. (arXiv:2206.07081v1 [cs.LG])
4. Learning the Structure of Large Networked Systems Obeying Conservation Laws. (arXiv:2206.07083v1 [stat.ML])
5. Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction. (arXiv:2206.07085v1 [cs.LG])
6. Combining Counterfactuals With Shapley Values To Explain Image Models. (arXiv:2206.07087v1 [cs.LG])
7. A Collaboration Strategy in the Mining Pool for Proof-of-Neural-Architecture Consensus. (arXiv:2206.07089v1 [cs.DC])
8. Inverse design of nano-photonic wavelength demultiplexer with a deep neural network approach. (arXiv:2206.07114v1 [physics.optics])
9. Loss Functions for Classification using Structured Entropy. (arXiv:2206.07122v1 [stat.ML])
10. Lazy Queries Can Reduce Variance in Zeroth-order Optimization. (arXiv:2206.07126v1 [cs.LG])
11. Stability of image reconstruction algorithms. (arXiv:2206.07128v1 [math.OC])
12. Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v1 [cs.LG])
13. Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. (arXiv:2206.07137v1 [cs.LG])
14. MBGDT:Robust Mini-Batch Gradient Descent. (arXiv:2206.07139v1 [cs.LG])
15. Flatten the Curve: Efficiently Training Low-Curvature Neural Networks. (arXiv:2206.07144v1 [cs.LG])
16. An Intelligent Assistant for Converting City Requirements to Formal Specification. (arXiv:2206.07152v1 [cs.AI])
17. Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut Features. (arXiv:2206.07155v1 [cs.LG])
18. GraphFM: Improving Large-Scale GNN Training via Feature Momentum. (arXiv:2206.07161v1 [cs.LG])
19. Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v1 [cs.CV])
20. DeepRecon: Joint 2D Cardiac Segmentation and 3D Volume Reconstruction via A Structure-Specific Generative Method. (arXiv:2206.07163v1 [cs.CV])
21. Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learning. (arXiv:2206.07166v1 [cs.LG])
22. Towards Goal, Feasibility, and Diversity-Oriented Deep Generative Models in Design. (arXiv:2206.07170v1 [cs.LG])
23. Proximal Splitting Adversarial Attacks for Semantic Segmentation. (arXiv:2206.07179v1 [cs.LG])
24. To Aggregate or Not? Learning with Separate Noisy Labels. (arXiv:2206.07181v1 [cs.LG])
25. Defending Observation Attacks in Deep Reinforcement Learning via Detection and Denoising. (arXiv:2206.07188v1 [cs.LG])
26. Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous Meme Classification Framework. (arXiv:2206.07190v1 [cs.CL])
27. Machines Explaining Linear Programs. (arXiv:2206.07194v1 [cs.LG])
28. Tearing Apart NOTEARS: Controlling the Graph Prediction via Variance Manipulation. (arXiv:2206.07195v1 [cs.LG])
29. Towards a Solution to Bongard Problems: A Causal Approach. (arXiv:2206.07196v1 [cs.LG])
30. Improving Solar Flare Prediction by Time Series Outlier Detection. (arXiv:2206.07197v1 [cs.LG])
31. Benefits of Additive Noise in Composing Classes with Bounded Capacity. (arXiv:2206.07199v1 [stat.ML])
32. Using Machine Learning to Augment Dynamic Time Warping Based Signal Classification. (arXiv:2206.07200v1 [cs.LG])
33. Attributions Beyond Neural Networks: The Linear Program Case. (arXiv:2206.07203v1 [cs.LG])
34. Explainable expected goal models for performance analysis in football analytics. (arXiv:2206.07212v1 [cs.LG])
35. A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects. (arXiv:2206.07219v1 [eess.IV])
36. Accurate Emotion Strength Assessment for Seen and Unseen Speech Based on Data-Driven Deep Learning. (arXiv:2206.07229v1 [cs.SD])
37. Brownian Noise Reduction: Maximizing Privacy Subject to Accuracy Constraints. (arXiv:2206.07234v1 [cs.LG])
38. Training Discrete Deep Generative Models via Gapped Straight-Through Estimator. (arXiv:2206.07235v1 [cs.LG])
39. Query-Adaptive Predictive Inference with Partial Labels. (arXiv:2206.07236v1 [stat.ML])
40. Location-based Twitter Filtering for the Creation of Low-Resource Language Datasets in Indonesian Local Languages. (arXiv:2206.07238v1 [cs.CL])
41. A Multiple kernel testing procedure for non-proportional hazards in factorial designs. (arXiv:2206.07239v1 [stat.ME])
42. Test-Time Adaptation for Visual Document Understanding. (arXiv:2206.07240v1 [cs.CV])
43. Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v1 [cs.IR])
44. Implicit Regularization or Implicit Conditioning? Exact Risk Trajectories of SGD in High Dimensions. (arXiv:2206.07252v1 [stat.ML])
45. TeKo: Text-Rich Graph Neural Networks with External Knowledge. (arXiv:2206.07253v1 [cs.SI])
46. CLNode: Curriculum Learning for Node Classification. (arXiv:2206.07258v1 [cs.LG])
47. On Enforcing Better Conditioned Meta-Learning for Rapid Few-Shot Adaptation. (arXiv:2206.07260v1 [cs.LG])
48. Latency Control for Keyword Spotting. (arXiv:2206.07261v1 [eess.AS])
49. Resource-Constrained Edge AI with Early Exit Prediction. (arXiv:2206.07269v1 [cs.LG])
50. CARD: Classification and Regression Diffusion Models. (arXiv:2206.07275v1 [stat.ML])
51. ALASCA: Rethinking Label Smoothing for Deep Learning Under Label Noise. (arXiv:2206.07277v1 [cs.LG])
52. Global Convergence of Federated Learning for Mixed Regression. (arXiv:2206.07279v1 [cs.LG])
53. A Survey on Gradient Inversion: Attacks, Defenses and Future Directions. (arXiv:2206.07284v1 [cs.LG])
54. Differentiable Top-k Classification Learning. (arXiv:2206.07290v1 [cs.LG])
55. FOLD-TR: A Scalable and Efficient Inductive Learning Algorithm for Learning To Rank. (arXiv:2206.07295v1 [cs.LG])
56. Knowledge Management System with NLP-Assisted Annotations: A Brief Survey and Outlook. (arXiv:2206.07304v1 [cs.DB])
57. Diffusion Transport Alignment. (arXiv:2206.07305v1 [stat.ML])
58. VCT: A Video Compression Transformer. (arXiv:2206.07307v1 [cs.CV])
59. Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models. (arXiv:2206.07309v1 [cs.LG])
60. Can pruning improve certified robustness of neural networks?. (arXiv:2206.07311v1 [cs.LG])
61. Fast and Reliable Evaluation of Adversarial Robustness with Minimum-Margin Attack. (arXiv:2206.07314v1 [cs.LG])
62. Online Contextual Decision-Making with a Smart Predict-then-Optimize Method. (arXiv:2206.07316v1 [cs.LG])
63. Morphence-2.0: Evasion-Resilient Moving Target Defense Powered by Out-of-Distribution Detection. (arXiv:2206.07321v1 [cs.CR])
64. A Survey : Neural Networks for AMR-to-Text. (arXiv:2206.07328v1 [cs.CL])
65. Detection of magnetohydrodynamic waves by using machine learning. (arXiv:2206.07334v1 [physics.flu-dyn])
66. On Numerical Integration in Neural Ordinary Differential Equations. (arXiv:2206.07335v1 [cs.LG])
67. Cautious Learning of Multiattribute Preferences. (arXiv:2206.07341v1 [cs.AI])
68. Automatic Detection of Rice Disease in Images of Various Leaf Sizes. (arXiv:2206.07344v1 [cs.CV])
69. Modern Machine-Learning Predictive Models for Diagnosing Infectious Diseases. (arXiv:2206.07365v1 [cs.LG])
70. DiffWire: Inductive Graph Rewiring via the Lov\'asz Bound. (arXiv:2206.07369v1 [cs.LG])
71. Lattice Convolutional Networks for Learning Ground States of Quantum Many-Body Systems. (arXiv:2206.07370v1 [quant-ph])
72. Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement Learning. (arXiv:2206.07376v1 [cs.LG])
73. Finite-Sample Guarantees for High-Dimensional DML. (arXiv:2206.07386v1 [econ.EM])
74. The Manifold Hypothesis for Gradient-Based Explanations. (arXiv:2206.07387v1 [cs.LG])
75. Subsurface Depths Structure Maps Reconstruction with Generative Adversarial Networks. (arXiv:2206.07388v1 [physics.geo-ph])
76. "Why Here and Not There?" -- Diverse Contrasting Explanations of Dimensionality Reduction. (arXiv:2206.07391v1 [cs.LG])
77. Automating the resolution of flight conflicts: Deep reinforcement learning in service of air traffic controllers. (arXiv:2206.07403v1 [cs.MA])
78. Hardening DNNs against Transfer Attacks during Network Compression using Greedy Adversarial Pruning. (arXiv:2206.07406v1 [cs.LG])
79. Multi-Objective Hyperparameter Optimization -- An Overview. (arXiv:2206.07438v1 [cs.LG])
80. Predicting Gender via Eye Movements. (arXiv:2206.07442v1 [cs.LG])
81. Understanding and Optimizing Deep Learning Cold-Start Latency on Edge Devices. (arXiv:2206.07446v1 [cs.LG])
82. VisageSynTalk: Unseen Speaker Video-to-Speech Synthesis via Speech-Visage Feature Selection. (arXiv:2206.07458v1 [cs.CV])
83. A Survey of Detection Methods for Die Attachment and Wire Bonding Defects in Integrated Circuit Manufacturing. (arXiv:2206.07481v1 [eess.SP])
84. Blind Estimation of a Doubly Selective OFDM Channel: A Deep Learning Algorithm and Theory. (arXiv:2206.07483v1 [eess.SP])
85. Intelligent analysis of EEG signals to assess consumer decisions: A Study on Neuromarketing. (arXiv:2206.07484v1 [eess.SP])
86. Topological Simplification of Signals for Inference and Approximate Reconstruction. (arXiv:2206.07486v1 [eess.SP])
87. Preliminary study on the impact of EEG density on TMS-EEG classification in Alzheimer's disease. (arXiv:2206.07492v1 [eess.SP])
88. Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation. (arXiv:2206.07510v1 [cs.CV])
89. Investigating Multi-Feature Selection and Ensembling for Audio Classification. (arXiv:2206.07511v1 [cs.SD])
90. A Deep Learning Network for the Classification of Intracardiac Electrograms in Atrial Tachycardia. (arXiv:2206.07515v1 [eess.SP])
91. Binary Single-dimensional Convolutional Neural Network for Seizure Prediction. (arXiv:2206.07518v1 [eess.SP])
92. Smart Meter Data Anomaly Detection using Variational Recurrent Autoencoders with Attention. (arXiv:2206.07519v1 [eess.SP])
93. Principal Trade-off Analysis. (arXiv:2206.07520v1 [cs.GT])
94. QONNX: Representing Arbitrary-Precision Quantized Neural Networks. (arXiv:2206.07527v1 [cs.LG])
95. Corruption-Robust Contextual Search through Density Updates. (arXiv:2206.07528v1 [cs.LG])
96. BaIT: Barometer for Information Trustworthiness. (arXiv:2206.07535v1 [cs.LG])
97. Autonomous Platoon Control with Integrated Deep Reinforcement Learning and Dynamic Programming. (arXiv:2206.07536v1 [eess.SY])
98. Body Gesture Recognition to Control a Social Robot. (arXiv:2206.07538v1 [cs.RO])
99. A Deep Generative Model of Neonatal Cortical Surface Development. (arXiv:2206.07542v1 [q-bio.NC])
100. MPI: Evaluating and Inducing Personality in Pre-trained Language Models. (arXiv:2206.07550v1 [cs.CL])
101. Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation. (arXiv:2206.07551v1 [cs.LG])
102. On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v1 [cs.LG])
103. Bayesian Federated Learning via Predictive Distribution Distillation. (arXiv:2206.07562v1 [cs.LG])
104. A Meta-Analysis of Distributionally-Robust Models. (arXiv:2206.07565v1 [cs.CV])
105. Contrastive Learning as Goal-Conditioned Reinforcement Learning. (arXiv:2206.07568v1 [cs.LG])
106. Calibrating Agent-based Models to Microdata with Graph Neural Networks. (arXiv:2206.07570v1 [cs.MA])
107. A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions. (arXiv:2206.07579v1 [cs.LG])
108. NatGen: Generative pre-training by "Naturalizing" source code. (arXiv:2206.07585v1 [cs.PL])
109. Machine Learning is Abduction Inference. (arXiv:2206.07586v1 [cs.AI])
110. Characteristic kernels on Hilbert spaces, Banach spaces, and on sets of measures. (arXiv:2206.07588v1 [stat.ML])
111. Robust and Sparse Estimation of Linear Regression Coefficients with Heavy-tailed Noises and Covariates. (arXiv:2206.07594v1 [stat.ML])
112. BIO-CXRNET: A Robust Multimodal Stacking Machine Learning Technique for Mortality Risk Prediction of COVID-19 Patients using Chest X-Ray Images and Clinical Data. (arXiv:2206.07595v1 [eess.IV])
113. Sparse Subspace Clustering in Diverse Multiplex Network Model. (arXiv:2206.07602v1 [stat.ML])
114. ARES: Locally Adaptive Reconstruction-based Anomaly Scoring. (arXiv:2206.07604v1 [cs.LG])
115. Epistemic Deep Learning. (arXiv:2206.07609v1 [cs.LG])
116. Rethinking Initialization of the Sinkhorn Algorithm. (arXiv:2206.07630v1 [stat.ML])
117. Clustered Scheduling and Communication Pipelining For Efficient Resource Management Of Wireless Federated Learning. (arXiv:2206.07631v1 [cs.LG])
118. Exploring Chemical Space with Score-based Out-of-distribution Generation. (arXiv:2206.07632v1 [q-bio.BM])
119. Sublinear Algorithms for Hierarchical Clustering. (arXiv:2206.07633v1 [cs.DS])
120. Asynchronous SGD Beats Minibatch SGD Under Arbitrary Delays. (arXiv:2206.07638v1 [math.OC])
121. Statistical and Computational Phase Transitions in Group Testing. (arXiv:2206.07640v1 [stat.ML])
122. Convergence and Price of Anarchy Guarantees of the Softmax Policy Gradient in Markov Potential Games. (arXiv:2206.07642v1 [cs.MA])
123. Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone. (arXiv:2206.07643v1 [cs.CV])
124. Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a Scalable Hyper-Ensemble Solution. (arXiv:2206.07647v1 [cs.LG])
125. Classification of ECG based on Hybrid Features using CNNs for Wearable Applications. (arXiv:2206.07648v1 [eess.SP])
126. Atrial Fibrillation Detection Using Weight-Pruned, Log-Quantised Convolutional Neural Networks. (arXiv:2206.07649v1 [eess.SP])
127. Flexible Raman Amplifier Optimization Based on Machine Learning-aided Physical Stimulated Raman Scattering Model. (arXiv:2206.07650v1 [eess.SP])
128. Two-stage Human Activity Recognition on Microcontrollers with Decision Trees and CNNs. (arXiv:2206.07652v1 [eess.SP])
129. Human Activity Recognition on Time Series Accelerometer Sensor Data using LSTM Recurrent Neural Networks. (arXiv:2206.07654v1 [eess.SP])
130. Classification of EEG Motor Imagery Using Deep Learning for Brain-Computer Interface Systems. (arXiv:2206.07655v1 [eess.SP])
131. Analysis of Augmentations for Contrastive ECG Representation Learning. (arXiv:2206.07656v1 [eess.SP])
132. Experimental Validation of Spectral-Spatial Power Evolution Design Using Raman Amplifiers. (arXiv:2206.07658v1 [cs.LG])
133. Model-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity. (arXiv:2206.07659v1 [cs.LG])
134. A Unified Sequence Interface for Vision Tasks. (arXiv:2206.07669v1 [cs.CV])
135. Wide Bayesian neural networks have a simple weight posterior: theory and accelerated sampling. (arXiv:2206.07673v1 [stat.ML])
136. Learning Large-scale Subsurface Simulations with a Hybrid Graph Network Simulator. (arXiv:2206.07680v1 [cs.LG])
137. Learning to Accelerate Partial Differential Equations via Latent Global Evolution. (arXiv:2206.07681v1 [cs.LG])
138. ELUDE: Generating interpretable explanations via a decomposition into labelled and unlabelled features. (arXiv:2206.07690v1 [cs.CV])
139. Diffusion Models for Video Prediction and Infilling. (arXiv:2206.07696v1 [cs.CV])
140. MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and Accurate Force Fields. (arXiv:2206.07697v1 [stat.ML])
141. Prefix Language Models are Unified Modal Learners. (arXiv:2206.07699v1 [cs.CV])
142. Masked Siamese ConvNets. (arXiv:2206.07700v1 [cs.CV])
143. Masked Frequency Modeling for Self-Supervised Visual Pre-Training. (arXiv:2206.07706v1 [cs.CV])
144. Variable Bitrate Neural Fields. (arXiv:2206.07707v1 [cs.CV])
145. Adaptive Threshold Sampling. (arXiv:1708.04970v2 [stat.ML] UPDATED)
146. BRIDGE: Byzantine-resilient Decentralized Gradient Descent. (arXiv:1908.08098v3 [stat.ML] UPDATED)
147. Double Robustness for Complier Parameters and a Semiparametric Test for Complier Characteristics. (arXiv:1909.05244v6 [stat.ML] UPDATED)
148. FENCE: Feasible Evasion Attacks on Neural Networks in Constrained Environments. (arXiv:1909.10480v4 [cs.CR] UPDATED)
149. Probabilistic Spatial Transformer Networks. (arXiv:2004.03637v2 [cs.LG] UPDATED)
150. The Mean-Squared Error of Double Q-Learning. (arXiv:2007.05034v3 [cs.LG] UPDATED)
151. Can Linear Programs Have Adversarial Examples? A Causal Perspective. (arXiv:2105.12697v5 [cs.LG] UPDATED)
152. Re-evaluating Word Mover's Distance. (arXiv:2105.14403v3 [cs.LG] UPDATED)
153. Sketch-Based Anomaly Detection in Streaming Graphs. (arXiv:2106.04486v2 [cs.DS] UPDATED)
154. Meaningfully Debugging Model Mistakes using Conceptual Counterfactual Explanations. (arXiv:2106.12723v3 [cs.LG] UPDATED)
155. Learning Heuristics for Template-based CEGIS of Loop Invariants with Reinforcement Learning. (arXiv:2107.09766v3 [cs.AI] UPDATED)
156. Training a neural network with exciton-polariton optical nonlinearity. (arXiv:2107.11156v2 [cs.LG] UPDATED)
157. A General Theory for Client Sampling in Federated Learning. (arXiv:2107.12211v4 [cs.LG] UPDATED)
158. A Random Matrix Perspective on Random Tensors. (arXiv:2108.00774v2 [stat.ML] UPDATED)
159. Data-driven discovery of intrinsic dynamics. (arXiv:2108.05928v2 [cs.LG] UPDATED)
160. Learned holographic light transport. (arXiv:2108.08253v3 [physics.optics] UPDATED)
161. EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning. (arXiv:2108.08842v3 [cs.LG] UPDATED)
162. Cascade Watchdog: A Multi-tiered Adversarial Guard for Outlier Detection. (arXiv:2108.09375v3 [cs.LG] UPDATED)
163. Clustering acoustic emission data streams with sequentially appearing clusters using mixture models. (arXiv:2108.11211v3 [stat.ML] UPDATED)
164. Thompson Sampling for Bandits with Clustered Arms. (arXiv:2109.01656v3 [cs.LG] UPDATED)
165. RepNAS: Searching for Efficient Re-parameterizing Blocks. (arXiv:2109.03508v4 [cs.LG] UPDATED)
166. PhysGNN: A Physics-Driven Graph Neural Network Based Model for Predicting Soft Tissue Deformation in Image-Guided Neurosurgery. (arXiv:2109.04352v2 [eess.IV] UPDATED)
167. Deciphering Environmental Air Pollution with Large Scale City Data. (arXiv:2109.04572v2 [cs.LG] UPDATED)
168. Learning Transport Processes with Machine Intelligence. (arXiv:2109.13096v3 [physics.plasm-ph] UPDATED)
169. XAI Establishes a Common Ground Between Machine Learning and Causality. (arXiv:2110.02395v2 [cs.LG] UPDATED)
170. Ripple Attention for Visual Perception with Sub-quadratic Complexity. (arXiv:2110.02453v2 [cs.CV] UPDATED)
171. Shifting Capsule Networks from the Cloud to the Deep Edge. (arXiv:2110.02911v2 [cs.LG] UPDATED)
172. RieszNet and ForestRiesz: Automatic Debiased Machine Learning with Neural Nets and Random Forests. (arXiv:2110.03031v3 [cs.LG] UPDATED)
173. End-To-End Label Uncertainty Modeling for Speech-based Arousal Recognition Using Bayesian Neural Networks. (arXiv:2110.03299v3 [eess.AS] UPDATED)
174. Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information. (arXiv:2110.08420v2 [cs.CL] UPDATED)
175. TLDR: Twin Learning for Dimensionality Reduction. (arXiv:2110.09455v2 [cs.CV] UPDATED)
176. Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm. (arXiv:2110.10017v3 [cs.LG] UPDATED)
177. Private Language Model Adaptation for Speech Recognition. (arXiv:2110.10026v3 [eess.AS] UPDATED)
178. Online Variational Filtering and Parameter Learning. (arXiv:2110.13549v2 [stat.ML] UPDATED)
179. Deep Network Approximation in Terms of Intrinsic Parameters. (arXiv:2111.07964v2 [cs.LG] UPDATED)
180. Large Language Models are not Models of Natural Language: they are Corpus Models. (arXiv:2112.07055v2 [cs.CL] UPDATED)
181. The Dual PC Algorithm for Structure Learning. (arXiv:2112.09036v3 [stat.ML] UPDATED)
182. PDE-Based Optimal Strategy for Unconstrained Online Learning. (arXiv:2201.07877v2 [cs.LG] UPDATED)
183. Born-Infeld (BI) for AI: Energy-Conserving Descent (ECD) for Optimization. (arXiv:2201.11137v2 [cs.LG] UPDATED)
184. Constrained Variational Policy Optimization for Safe Reinforcement Learning. (arXiv:2201.11927v2 [cs.LG] UPDATED)
185. You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v3 [cs.CV] UPDATED)
186. TPC: Transformation-Specific Smoothing for Point Cloud Models. (arXiv:2201.12733v3 [cs.CV] UPDATED)
187. Nystr\"om Kernel Mean Embeddings. (arXiv:2201.13055v2 [stat.ML] UPDATED)
188. GNNRank: Learning Global Rankings from Pairwise Comparisons via Directed Graph Neural Networks. (arXiv:2202.00211v2 [cs.LG] UPDATED)
189. Non-Vacuous Generalisation Bounds for Shallow Neural Networks. (arXiv:2202.01627v3 [cs.LG] UPDATED)
190. Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations. (arXiv:2202.02514v3 [cs.LG] UPDATED)
191. CITRIS: Causal Identifiability from Temporal Intervened Sequences. (arXiv:2202.03169v3 [cs.LG] UPDATED)
192. Scale-free Unconstrained Online Learning for Curved Losses. (arXiv:2202.05630v2 [cs.LG] UPDATED)
193. Branching Reinforcement Learning. (arXiv:2202.07995v2 [cs.LG] UPDATED)
194. Deep Koopman Operator with Control for Nonlinear Systems. (arXiv:2202.08004v2 [cs.RO] UPDATED)
195. Transfer and Marginalize: Explaining Away Label Noise with Privileged Information. (arXiv:2202.09244v2 [cs.LG] UPDATED)
196. HyperPrompt: Prompt-based Task-Conditioning of Transformers. (arXiv:2203.00759v2 [cs.CL] UPDATED)
197. No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds. (arXiv:2203.02502v2 [cs.LG] UPDATED)
198. Open-Ended Knowledge Tracing. (arXiv:2203.03716v2 [cs.CY] UPDATED)
199. Sentence-Select: Large-Scale Language Model Data Selection for Rare-Word Speech Recognition. (arXiv:2203.05008v2 [cs.CL] UPDATED)
200. Achieving Downstream Fairness with Geometric Repair. (arXiv:2203.07490v2 [cs.LG] UPDATED)
201. Nonstationary Temporal Matrix Factorization for Multivariate Time Series Forecasting. (arXiv:2203.10651v2 [cs.LG] UPDATED)
202. MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data. (arXiv:2203.12369v5 [cs.SD] UPDATED)
203. Chain-based Discriminative Autoencoders for Speech Recognition. (arXiv:2203.13687v3 [cs.SD] UPDATED)
204. Offline Reinforcement Learning Under Value and Density-Ratio Realizability: The Power of Gaps. (arXiv:2203.13935v3 [cs.LG] UPDATED)
205. A Survey on Graph Representation Learning Methods. (arXiv:2204.01855v2 [cs.LG] UPDATED)
206. Linear Complexity Randomized Self-attention Mechanism. (arXiv:2204.04667v2 [cs.LG] UPDATED)
207. FastMapSVM: Classifying Complex Objects Using the FastMap Algorithm and Support-Vector Machines. (arXiv:2204.05112v3 [cs.CV] UPDATED)
208. E2E Segmenter: Joint Segmenting and Decoding for Long-Form ASR. (arXiv:2204.10749v2 [cs.SD] UPDATED)
209. VPNets: Volume-preserving neural networks for learning source-free dynamics. (arXiv:2204.13843v2 [cs.LG] UPDATED)
210. Towards Robust Unsupervised Disentanglement of Sequential Data -- A Case Study Using Music Audio. (arXiv:2205.05871v2 [cs.SD] UPDATED)
211. History Compression via Language Models in Reinforcement Learning. (arXiv:2205.12258v2 [cs.LG] UPDATED)
212. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v4 [math.OC] UPDATED)
213. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v4 [cs.LG] UPDATED)
214. NeuPSL: Neural Probabilistic Soft Logic. (arXiv:2205.14268v2 [cs.LG] UPDATED)
215. CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities. (arXiv:2206.03132v2 [cs.AI] UPDATED)
216. Utility of Equivariant Message Passing in Cortical Mesh Segmentation. (arXiv:2206.03164v2 [cs.CV] UPDATED)
217. On the Role of Discount Factor in Offline Reinforcement Learning. (arXiv:2206.03383v2 [cs.LG] UPDATED)
218. Autoregressive Perturbations for Data Poisoning. (arXiv:2206.03693v2 [cs.LG] UPDATED)
219. Words are all you need? Capturing human sensory similarity with textual descriptors. (arXiv:2206.04105v2 [cs.CL] UPDATED)
220. Deep Surrogate Assisted Generation of Environments. (arXiv:2206.04199v2 [cs.AI] UPDATED)
221. Clustering with Queries under Semi-Random Noise. (arXiv:2206.04583v2 [cs.LG] UPDATED)
222. Deep Learning-based Massive MIMO CSI Acquisition for 5G Evolution and 6G. (arXiv:2206.04967v2 [eess.SP] UPDATED)
223. Bayesian Estimation of Differential Privacy. (arXiv:2206.05199v2 [cs.LG] UPDATED)
224. LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks. (arXiv:2206.06565v2 [cs.LG] UPDATED)
225. Bandwidth Enables Generalization in Quantum Kernel Models. (arXiv:2206.06686v2 [quant-ph] UPDATED)
226. Variance Reduction for Policy-Gradient Methods via Empirical Variance Minimization. (arXiv:2206.06827v2 [cs.LG] UPDATED)
227. Neural interval-censored Cox regression with feature selection. (arXiv:2206.06885v2 [stat.ML] UPDATED)
228. Unbiased Recommender Learning from Missing-Not-At-Random Implicit Feedback. (arXiv:1909.03601v3 [stat.ML] CROSS LISTED)
229. Asymmetric Tri-training for Debiasing Missing-Not-At-Random Explicit Feedback. (arXiv:1910.01444v6 [cs.SI] CROSS LISTED)
230. Semi-Supervised Segmentation of Mitochondria from Electron Microscopy Images Using Spatial Continuity. (arXiv:2206.02392v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**101** new papers in cs.AI:-) 
1. Measuring Inconsistency in Declarative Process Specifications. (arXiv:2206.07080v1 [cs.AI])
2. Stability and Generalization of Stochastic Optimization with Nonconvex and Nonsmooth Problems. (arXiv:2206.07082v1 [cs.AI])
3. An Efficient HTN to STRIPS Encoding for Concurrent Plans. (arXiv:2206.07084v1 [cs.AI])
4. Understanding the Generalization Benefit of Normalization Layers: Sharpness Reduction. (arXiv:2206.07085v1 [cs.LG])
5. Plurality Veto: A Simple Voting Rule Achieving Optimal Metric Distortion. (arXiv:2206.07098v1 [cs.GT])
6. Minorities in networks and algorithms. (arXiv:2206.07113v1 [physics.soc-ph])
7. MBGDT:Robust Mini-Batch Gradient Descent. (arXiv:2206.07139v1 [cs.LG])
8. An Intelligent Assistant for Converting City Requirements to Formal Specification. (arXiv:2206.07152v1 [cs.AI])
9. GraphFM: Improving Large-Scale GNN Training via Feature Momentum. (arXiv:2206.07161v1 [cs.LG])
10. Category-Agnostic 6D Pose Estimation with Conditional Neural Processes. (arXiv:2206.07162v1 [cs.CV])
11. Edge Security: Challenges and Issues. (arXiv:2206.07164v1 [cs.CR])
12. Regularizing a Model-based Policy Stationary Distribution to Stabilize Offline Reinforcement Learning. (arXiv:2206.07166v1 [cs.LG])
13. Understanding Narratives through Dimensions of Analogy. (arXiv:2206.07167v1 [cs.AI])
14. Automated image analysis in large-scale cellular electron microscopy: A literature survey. (arXiv:2206.07171v1 [cs.CV])
15. Codec at SemEval-2022 Task 5: Multi-Modal Multi-Transformer Misogynous Meme Classification Framework. (arXiv:2206.07190v1 [cs.CL])
16. A Projection-Based K-space Transformer Network for Undersampled Radial MRI Reconstruction with Limited Training Subjects. (arXiv:2206.07219v1 [eess.IV])
17. Training Discrete Deep Generative Models via Gapped Straight-Through Estimator. (arXiv:2206.07235v1 [cs.LG])
18. Test-Time Adaptation for Visual Document Understanding. (arXiv:2206.07240v1 [cs.CV])
19. An Extractive-and-Abstractive Framework for Source Code Summarization. (arXiv:2206.07245v1 [cs.SE])
20. Quantum computing overview: discrete vs. continuous variable models. (arXiv:2206.07246v1 [quant-ph])
21. Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v1 [cs.IR])
22. Latency Control for Keyword Spotting. (arXiv:2206.07261v1 [eess.AS])
23. Human Heuristics for AI-Generated Language Are Flawed. (arXiv:2206.07271v1 [cs.CL])
24. Machine vision for vial positioning detection toward the safe automation of material synthesis. (arXiv:2206.07272v1 [cs.CV])
25. ALASCA: Rethinking Label Smoothing for Deep Learning Under Label Noise. (arXiv:2206.07277v1 [cs.LG])
26. Text-Aware End-to-end Mispronunciation Detection and Diagnosis. (arXiv:2206.07289v1 [cs.SD])
27. S\textsuperscript{2}-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v1 [cs.CV])
28. From Outcome-Based to Language-Based Preferences. (arXiv:2206.07300v1 [cs.GT])
29. Knowledge Management System with NLP-Assisted Annotations: A Brief Survey and Outlook. (arXiv:2206.07304v1 [cs.DB])
30. Exploiting Cross-domain And Cross-Lingual Ultrasound Tongue Imaging Features For Elderly And Dysarthric Speech Recognition. (arXiv:2206.07327v1 [eess.AS])
31. Cautious Learning of Multiattribute Preferences. (arXiv:2206.07341v1 [cs.AI])
32. Automatic Detection of Rice Disease in Images of Various Leaf Sizes. (arXiv:2206.07344v1 [cs.CV])
33. Unsupervised Capsule Networks of High-Dimension Point Clouds classification. (arXiv:2206.07348v1 [cs.CV])
34. Robust SAR ATR on MSTAR with Deep Learning Models trained on Full Synthetic MOCEM data. (arXiv:2206.07352v1 [cs.AI])
35. The Emotion is Not One-hot Encoding: Learning with Grayscale Label for Emotion Recognition in Conversation. (arXiv:2206.07359v1 [cs.CL])
36. Modern Machine-Learning Predictive Models for Diagnosing Infectious Diseases. (arXiv:2206.07365v1 [cs.LG])
37. DiffWire: Inductive Graph Rewiring via the Lov\'asz Bound. (arXiv:2206.07369v1 [cs.LG])
38. Lattice Convolutional Networks for Learning Ground States of Quantum Many-Body Systems. (arXiv:2206.07370v1 [quant-ph])
39. Mean-Semivariance Policy Optimization via Risk-Averse Reinforcement Learning. (arXiv:2206.07376v1 [cs.LG])
40. "Why Here and Not There?" -- Diverse Contrasting Explanations of Dimensionality Reduction. (arXiv:2206.07391v1 [cs.LG])
41. Zero-shot object goal visual navigation. (arXiv:2206.07423v1 [cs.CV])
42. Physically-admissible polarimetric data augmentation for road-scene analysis. (arXiv:2206.07431v1 [cs.CV])
43. Conformance Checking with Uncertainty via SMT (Extended Version). (arXiv:2206.07461v1 [cs.AI])
44. Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus. (arXiv:2206.07472v1 [cs.AI])
45. Intelligent analysis of EEG signals to assess consumer decisions: A Study on Neuromarketing. (arXiv:2206.07484v1 [eess.SP])
46. Towards ML Methods for Biodiversity: A Novel Wild Bee Dataset and Evaluations of XAI Methods for ML-Assisted Rare Species Annotations. (arXiv:2206.07497v1 [cs.AI])
47. On the complexity of finding set repairs for data-graphs. (arXiv:2206.07504v1 [cs.DB])
48. Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2206.07505v1 [cs.AI])
49. A Deep Learning Network for the Classification of Intracardiac Electrograms in Atrial Tachycardia. (arXiv:2206.07515v1 [eess.SP])
50. Autonomous Platoon Control with Integrated Deep Reinforcement Learning and Dynamic Programming. (arXiv:2206.07536v1 [eess.SY])
51. MPI: Evaluating and Inducing Personality in Pre-trained Language Models. (arXiv:2206.07550v1 [cs.CL])
52. Unknown-Aware Domain Adversarial Learning for Open-Set Domain Adaptation. (arXiv:2206.07551v1 [cs.LG])
53. How to Reduce Change Detection to Semantic Segmentation. (arXiv:2206.07557v1 [cs.CV])
54. Contextualization and Generalization in Entity and Relation Extraction. (arXiv:2206.07558v1 [cs.CL])
55. Contrastive Learning as Goal-Conditioned Reinforcement Learning. (arXiv:2206.07568v1 [cs.LG])
56. AI and Pathology: Steering Treatment and Predicting Outcomes. (arXiv:2206.07573v1 [cs.AI])
57. E2V-SDE: From Asynchronous Events to Fast and Continuous Video Reconstruction via Neural Stochastic Differential Equations. (arXiv:2206.07578v1 [cs.AI])
58. A Comprehensive Survey on Deep Clustering: Taxonomy, Challenges, and Future Directions. (arXiv:2206.07579v1 [cs.LG])
59. NatGen: Generative pre-training by "Naturalizing" source code. (arXiv:2206.07585v1 [cs.PL])
60. Machine Learning is Abduction Inference. (arXiv:2206.07586v1 [cs.AI])
61. ARES: Locally Adaptive Reconstruction-based Anomaly Scoring. (arXiv:2206.07604v1 [cs.LG])
62. Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation. (arXiv:2206.07634v1 [cs.CV])
63. AI Ethics Issues in Real World: Evidence from AI Incident Database. (arXiv:2206.07635v1 [cs.AI])
64. Convergence and Price of Anarchy Guarantees of the Softmax Policy Gradient in Markov Potential Games. (arXiv:2206.07642v1 [cs.MA])
65. Hyperparameter Sensitivity in Deep Outlier Detection: Analysis and a Scalable Hyper-Ensemble Solution. (arXiv:2206.07647v1 [cs.LG])
66. Classification of EEG Motor Imagery Using Deep Learning for Brain-Computer Interface Systems. (arXiv:2206.07655v1 [eess.SP])
67. Analysis of Augmentations for Contrastive ECG Representation Learning. (arXiv:2206.07656v1 [eess.SP])
68. Model-based RL with Optimistic Posterior Sampling: Structural Conditions and Sample Complexity. (arXiv:2206.07659v1 [cs.LG])
69. Region-enhanced Deep Graph Convolutional Networks for Rumor Detection. (arXiv:2206.07665v1 [cs.SI])
70. Masked Siamese ConvNets. (arXiv:2206.07700v1 [cs.CV])
71. On the Eve of True Explainability for OWL Ontologies: Description Logic Proofs with Evee and Evonne (Extended Version). (arXiv:2206.07711v1 [cs.LO])
72. Sketch-Based Anomaly Detection in Streaming Graphs. (arXiv:2106.04486v2 [cs.DS] UPDATED)
73. Brain over Brawn: Using a Stereo Camera to Detect, Track, and Intercept a Faster UAV by Reconstructing the Intruder's Trajectory. (arXiv:2107.00962v2 [cs.RO] UPDATED)
74. Learning Heuristics for Template-based CEGIS of Loop Invariants with Reinforcement Learning. (arXiv:2107.09766v3 [cs.AI] UPDATED)
75. A General Theory for Client Sampling in Federated Learning. (arXiv:2107.12211v4 [cs.LG] UPDATED)
76. EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning. (arXiv:2108.08842v3 [cs.LG] UPDATED)
77. Satisfiability and Containment of Recursive SHACL. (arXiv:2108.13063v2 [cs.AI] UPDATED)
78. Deciphering Environmental Air Pollution with Large Scale City Data. (arXiv:2109.04572v2 [cs.LG] UPDATED)
79. On the Privacy Risks of Deploying Recurrent Neural Networks in Machine Learning Models. (arXiv:2110.03054v3 [cs.CR] UPDATED)
80. Understanding Dataset Difficulty with $\mathcal{V}$-Usable Information. (arXiv:2110.08420v2 [cs.CL] UPDATED)
81. TLDR: Twin Learning for Dimensionality Reduction. (arXiv:2110.09455v2 [cs.CV] UPDATED)
82. Neural Network Compatible Off-Policy Natural Actor-Critic Algorithm. (arXiv:2110.10017v3 [cs.LG] UPDATED)
83. Constrained Variational Policy Optimization for Safe Reinforcement Learning. (arXiv:2201.11927v2 [cs.LG] UPDATED)
84. CITRIS: Causal Identifiability from Temporal Intervened Sequences. (arXiv:2202.03169v3 [cs.LG] UPDATED)
85. DareFightingICE Competition: A Fighting Game Sound Design and AI Competition. (arXiv:2203.01556v2 [cs.HC] UPDATED)
86. No More Than 6ft Apart: Robust K-Means via Radius Upper Bounds. (arXiv:2203.02502v2 [cs.LG] UPDATED)
87. Revisiting Multi-Scale Feature Fusion for Semantic Segmentation. (arXiv:2203.12683v2 [cs.CV] UPDATED)
88. Predicting Personas Using Mechanic Frequencies and Game State Traces. (arXiv:2203.13351v2 [cs.AI] UPDATED)
89. Chain-based Discriminative Autoencoders for Speech Recognition. (arXiv:2203.13687v3 [cs.SD] UPDATED)
90. A World-Self Model Towards Understanding Intelligence. (arXiv:2203.13762v3 [cs.AI] UPDATED)
91. Learning to act: a Reinforcement Learning approach to recommend the best next activities. (arXiv:2203.15398v2 [cs.AI] UPDATED)
92. Handling sign language transcription system with the computer-friendly numerical multilabels. (arXiv:2204.06924v2 [cs.CL] UPDATED)
93. Effectively Incorporating Weighted Cost-to-go Heuristic in Suboptimal CBS. (arXiv:2205.11624v3 [cs.AI] UPDATED)
94. Symbolic Expression Transformer: A Computer Vision Approach for Symbolic Regression. (arXiv:2205.11798v2 [cs.CV] UPDATED)
95. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v4 [math.OC] UPDATED)
96. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v4 [cs.LG] UPDATED)
97. CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks. (arXiv:2206.01992v4 [cs.CV] UPDATED)
98. CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities. (arXiv:2206.03132v2 [cs.AI] UPDATED)
99. Formalization of the principles of brain Programming (Brain Principles Programming). (arXiv:2206.03487v3 [cs.AI] UPDATED)
100. Deep Surrogate Assisted Generation of Environments. (arXiv:2206.04199v2 [cs.AI] UPDATED)
101. X-Risk Analysis for AI Research. (arXiv:2206.05862v2 [cs.CY] UPDATED)

