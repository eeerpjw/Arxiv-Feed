# Your interest papers
---
## cs.CV
---
### Dn**Swin**: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer. (arXiv:2207.13861v1 [cs.CV])
- Authors : Hao Li, Zhijing Yang, Xiaobin Hong, Ziying Zhao, Junyang Chen, Yukai Shi, Jinshan Pan
- Link : [http://arxiv.org/abs/2207.13861](http://arxiv.org/abs/2207.13861)
> ABSTRACT  :  Real-world image denoising is a practical image **restoration** problem that aims to obtain clean images from in-the-wild noisy input. Recently, Vision Transformer (ViT) exhibits a strong ability to capture long-range dependencies and many researchers attempt to apply ViT to image denoising tasks. However, real-world image is an isolated frame that makes the ViT build the long-range dependencies on the internal patches, which divides images into patches and disarranges the noise pattern and gradient continuity. In this article, we propose to resolve this issue by using a continuous Wavelet Sliding-Transformer that builds frequency correspondence under real-world scenes, called Dn**Swin**. Specifically, we first extract the bottom features from noisy input images by using a CNN encoder. The key to Dn**Swin** is to separate high-frequency and low-frequency information from the features and build frequency dependencies. To this end, we propose Wavelet Sliding-Window Transformer that utilizes discrete wavelet transform, self-attention and inverse discrete wavelet transform to extract deep features. Finally, we reconstruct the deep features into denoised images using a CNN decoder. Both quantitative and qualitative evaluations on real-world denoising benchmarks demonstrate that the proposed Dn**Swin** performs favorably against the state-of-the-art methods.  
### Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
- Authors : Qinghua Huang, Lizhi Jia, Guanqing Ren, Xiaoyi Wang, Chunying Liu
- Link : [http://arxiv.org/abs/2207.13868](http://arxiv.org/abs/2207.13868)
> ABSTRACT  :  Ultrasound imaging plays an important role in the diagnosis of vascular lesions. Accurate segmentation of the vascular wall is important for the prevention, diagnosis and treatment of vascular diseases. However, existing methods have inaccurate localization of the vascular wall boundary. Segmentation errors occur in discontinuous vascular wall boundaries and **dark** boundaries. To overcome these problems, we propose a new boundary-delineation network (BDNet). We use the boundary refinement module to re-delineate the boundary of the vascular wall to obtain the correct boundary location. We designed the feature extraction module to extract and fuse multi-scale features and different receptive field features to solve the problem of **dark** boundaries and discontinuous boundaries. We use a new loss function to optimize the model. The interference of class imbalance on model optimization is prevented to obtain finer and smoother boundaries. Finally, to facilitate clinical applications, we design the model to be lightweight. Experimental results show that our model achieves the best segmentation results and significantly reduces memory consumption compared to existing models for the dataset.  
### Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
- Authors : Yuanfan Zhang, Gen Li, Lei Sun
- Link : [http://arxiv.org/abs/2207.13879](http://arxiv.org/abs/2207.13879)
> ABSTRACT  :  Since convolutional neural networks perform well in learning generalizable image priors from large-scale data, these models have been widely used in image denoising tasks. However, the computational complexity increases dramatically as well on complex model. In this paper, We propose a novel lightweight Complementary Attention Module, which includes a density module and a sparse module, which can cooperatively mine dense and sparse features for feature complementary learning to build an efficient lightweight architecture. Moreover, to reduce the loss of details caused by denoising, this paper constructs a gradient-based structure-preserving branch. We utilize gradient-based branches to obtain additional structural priors for denoising, and make the model pay more attention to image geometric details through gradient loss optimization.Based on the above, we propose an efficiently Unet structured network with dual branch, the visual results show that can effectively preserve the structural details of the original image, we evaluate benchmarks including SIDD and DND, where SCANet achieves state-of-the-art performance in PSNR and SSIM while significantly reducing computational cost.  
### CuDi: Curve Distillation for Efficient and Controllable **Exposure** Adjustment. (arXiv:2207.14273v1 [cs.CV])
- Authors : **Chongyi Li**, Chunle Guo, Ruicheng Feng, Shangchen Zhou, Chen Change
- Link : [http://arxiv.org/abs/2207.14273](http://arxiv.org/abs/2207.14273)
> ABSTRACT  :  We present Curve Distillation, CuDi, for efficient and controllable **exposure** adjustment without the requirement of paired or unpaired data during training. Our method inherits the zero-reference learning and curve-based framework from an effective **low-light** image **enhancement** method, Zero-DCE, with further speed up in its inference speed, reduction in its model size, and extension to controllable **exposure** adjustment. The improved inference speed and lightweight model are achieved through novel curve distillation that approximates the time-consuming iterative operation in the conventional curve-based framework by high-order curve's tangent line. The controllable **exposure** adjustment is made possible with a new self-supervised spatial **exposure** control loss that constrains the **exposure** levels of different spatial regions of the output to be close to the brightness distribution of an **exposure** map serving as an input condition. Different from most existing methods that can only correct either underexposed or overexposed photos, our approach corrects both underexposed and overexposed photos with a single model. Notably, our approach can additionally adjust the **exposure** levels of a photo globally or locally with the guidance of an input condition **exposure** map, which can be pre-defined or manually set in the inference stage. Through extensive experiments, we show that our method is appealing for its fast, robust, and flexible performance, outperforming state-of-the-art methods in real scenes. Project page: https://li-chongyi.github.io/CuDi_files/.  
### HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions. (arXiv:2207.14284v1 [cs.CV])
- Authors : Yongming Rao, Wenliang Zhao, Yansong Tang, Jie Zhou, Nam Lim, Jiwen Lu
- Link : [http://arxiv.org/abs/2207.14284](http://arxiv.org/abs/2207.14284)
> ABSTRACT  :  Recent progress in vision Transformers exhibits great success in various tasks driven by the new spatial modeling mechanism based on dot-product self-attention. In this paper, we show that the key ingredients behind the vision Transformers, namely input-adaptive, long-range and high-order spatial interactions, can also be efficiently implemented with a convolution-based framework. We present the Recursive Gated Convolution ($\textit{g}^\textit{n}$Conv) that performs high-order spatial interactions with gated convolutions and recursive designs. The new operation is highly flexible and customizable, which is compatible with various variants of convolution and extends the two-order interactions in self-attention to arbitrary orders without introducing significant extra computation. $\textit{g}^\textit{n}$Conv can serve as a plug-and-play module to improve various vision Transformers and convolution-based models. Based on the operation, we construct a new family of generic vision backbones named HorNet. Extensive experiments on ImageNet classification, COCO object detection and ADE20K semantic segmentation show HorNet outperform **Swin** Transformers and ConvNeXt by a significant margin with similar overall architecture and training configurations. HorNet also shows favorable scalability to more training data and a larger model size. Apart from the effectiveness in visual encoders, we also show $\textit{g}^\textit{n}$Conv can be applied to task-specific decoders and consistently improve dense prediction performance with less computation. Our results demonstrate that $\textit{g}^\textit{n}$Conv can be a new basic module for visual modeling that effectively combines the merits of both vision Transformers and CNNs. Code is available at https://github.com/raoyongming/HorNet  
### TACS: Taxonomy Adaptive Cross-Domain Semantic Segmentation. (arXiv:2109.04813v3 [cs.CV] UPDATED)
- Authors : Rui Gong, Martin Danelljan, Dengxin Dai, Danda Pani, Ajad Chhatkuli, Fisher Yu, Luc Van
- Link : [http://arxiv.org/abs/2109.04813](http://arxiv.org/abs/2109.04813)
> ABSTRACT  :  Traditional domain adaptive semantic segmentation addresses the task of adapting a model to a novel target domain under limited or no additional supervision. While tackling the input domain gap, the standard domain adaptation settings assume no domain change in the output space. In semantic prediction tasks, different datasets are often labeled according to different semantic taxonomies. In many real-world settings, the target domain task requires a different taxonomy than the one imposed by the source domain. We therefore introduce the more general taxonomy adaptive cross-domain semantic segmentation (TACS) problem, allowing for inconsistent taxonomies between the two domains. We further propose an approach that jointly addresses the image-level and label-level domain adaptation. On the label-level, we employ a **bilateral** mixed sampling strategy to augment the target domain, and a relabelling method to unify and align the label spaces. We address the image-level domain gap by proposing an uncertainty-rectified contrastive learning method, leading to more domain-invariant and class-discriminative features. We extensively evaluate the effectiveness of our framework under different TACS settings: open taxonomy, coarse-to-fine taxonomy, and implicitly-overlapping taxonomy. Our approach outperforms the previous state-of-the-art by a large margin, while being capable of adapting to target taxonomies. Our implementation is publicly available at https://github.com/ETHRuiGong/TADA.  
### Ada**NeRF**: Adaptive Sampling for **Real-time** Rendering of Neural Radiance Fields. (arXiv:2207.10312v2 [cs.CV] UPDATED)
- Authors : Andreas Kurz, Thomas Neff, Zhaoyang Lv, Michael Zollh, Markus Steinberger
- Link : [http://arxiv.org/abs/2207.10312](http://arxiv.org/abs/2207.10312)
> ABSTRACT  :  Novel view synthesis has recently been revolutionized by learning neural radiance fields directly from sparse observations. However, rendering images with this new paradigm is slow due to the fact that an accurate quadrature of the volume rendering equation requires a large number of samples for each ray. Previous work has mainly focused on speeding up the network evaluations that are associated with each sample point, e.g., via caching of radiance values into explicit spatial data structures, but this comes at the expense of model compactness. In this paper, we propose a novel dual-network architecture that takes an orthogonal direction by learning how to best reduce the number of required sample points. To this end, we split our network into a sampling and shading network that are jointly trained. Our training scheme employs fixed sample positions along each ray, and incrementally introduces sparsity throughout training to achieve high quality even at low sample counts. After fine-tuning with the target number of samples, the resulting compact neural representation can be rendered in real-time. Our experiments demonstrate that our approach outperforms concurrent compact neural representations in terms of quality and frame rate and performs on par with highly efficient hybrid representations. Code and supplementary material is available at https://thomasneff.github.io/adanerf.  
### Generalizable Patch-Based Neural Rendering. (arXiv:2207.10662v2 [cs.CV] UPDATED)
- Authors : Mohammed Suhail, Carlos Esteves, Leonid Sigal, Ameesh Makadia
- Link : [http://arxiv.org/abs/2207.10662](http://arxiv.org/abs/2207.10662)
> ABSTRACT  :  Neural rendering has received tremendous attention since the advent of Neural Radiance Fields (**NeRF**), and has pushed the state-of-the-art on novel-view synthesis considerably. The recent focus has been on models that overfit to a single scene, and the few attempts to learn models that can synthesize novel views of unseen scenes mostly consist of combining deep convolutional features with a **NeRF**-like model. We propose a different paradigm, where no deep features and no **NeRF**-like volume rendering are needed. Our method is capable of predicting the color of a target ray in a novel scene directly, just from a collection of patches sampled from the scene. We first leverage epipolar geometry to extract patches along the epipolar lines of each reference view. Each patch is linearly projected into a 1D feature vector and a sequence of transformers process the collection. For positional encoding, we parameterize rays as in a light field representation, with the crucial difference that the coordinates are canonicalized with respect to the target ray, which makes our method independent of the reference frame and improves generalization. We show that our approach outperforms the state-of-the-art on novel view synthesis of unseen scenes even when being trained with considerably less data than prior work.  
## eess.IV
---
### Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
- Authors : Qinghua Huang, Lizhi Jia, Guanqing Ren, Xiaoyi Wang, Chunying Liu
- Link : [http://arxiv.org/abs/2207.13868](http://arxiv.org/abs/2207.13868)
> ABSTRACT  :  Ultrasound imaging plays an important role in the diagnosis of vascular lesions. Accurate segmentation of the vascular wall is important for the prevention, diagnosis and treatment of vascular diseases. However, existing methods have inaccurate localization of the vascular wall boundary. Segmentation errors occur in discontinuous vascular wall boundaries and **dark** boundaries. To overcome these problems, we propose a new boundary-delineation network (BDNet). We use the boundary refinement module to re-delineate the boundary of the vascular wall to obtain the correct boundary location. We designed the feature extraction module to extract and fuse multi-scale features and different receptive field features to solve the problem of **dark** boundaries and discontinuous boundaries. We use a new loss function to optimize the model. The interference of class imbalance on model optimization is prevented to obtain finer and smoother boundaries. Finally, to facilitate clinical applications, we design the model to be lightweight. Experimental results show that our model achieves the best segmentation results and significantly reduces memory consumption compared to existing models for the dataset.  
### Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
- Authors : Yuanfan Zhang, Gen Li, Lei Sun
- Link : [http://arxiv.org/abs/2207.13879](http://arxiv.org/abs/2207.13879)
> ABSTRACT  :  Since convolutional neural networks perform well in learning generalizable image priors from large-scale data, these models have been widely used in image denoising tasks. However, the computational complexity increases dramatically as well on complex model. In this paper, We propose a novel lightweight Complementary Attention Module, which includes a density module and a sparse module, which can cooperatively mine dense and sparse features for feature complementary learning to build an efficient lightweight architecture. Moreover, to reduce the loss of details caused by denoising, this paper constructs a gradient-based structure-preserving branch. We utilize gradient-based branches to obtain additional structural priors for denoising, and make the model pay more attention to image geometric details through gradient loss optimization.Based on the above, we propose an efficiently Unet structured network with dual branch, the visual results show that can effectively preserve the structural details of the original image, we evaluate benchmarks including SIDD and DND, where SCANet achieves state-of-the-art performance in PSNR and SSIM while significantly reducing computational cost.  
## cs.LG
---
### Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
- Authors : Qinghua Huang, Lizhi Jia, Guanqing Ren, Xiaoyi Wang, Chunying Liu
- Link : [http://arxiv.org/abs/2207.13868](http://arxiv.org/abs/2207.13868)
> ABSTRACT  :  Ultrasound imaging plays an important role in the diagnosis of vascular lesions. Accurate segmentation of the vascular wall is important for the prevention, diagnosis and treatment of vascular diseases. However, existing methods have inaccurate localization of the vascular wall boundary. Segmentation errors occur in discontinuous vascular wall boundaries and **dark** boundaries. To overcome these problems, we propose a new boundary-delineation network (BDNet). We use the boundary refinement module to re-delineate the boundary of the vascular wall to obtain the correct boundary location. We designed the feature extraction module to extract and fuse multi-scale features and different receptive field features to solve the problem of **dark** boundaries and discontinuous boundaries. We use a new loss function to optimize the model. The interference of class imbalance on model optimization is prevented to obtain finer and smoother boundaries. Finally, to facilitate clinical applications, we design the model to be lightweight. Experimental results show that our model achieves the best segmentation results and significantly reduces memory consumption compared to existing models for the dataset.  
### Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
- Authors : Yuanfan Zhang, Gen Li, Lei Sun
- Link : [http://arxiv.org/abs/2207.13879](http://arxiv.org/abs/2207.13879)
> ABSTRACT  :  Since convolutional neural networks perform well in learning generalizable image priors from large-scale data, these models have been widely used in image denoising tasks. However, the computational complexity increases dramatically as well on complex model. In this paper, We propose a novel lightweight Complementary Attention Module, which includes a density module and a sparse module, which can cooperatively mine dense and sparse features for feature complementary learning to build an efficient lightweight architecture. Moreover, to reduce the loss of details caused by denoising, this paper constructs a gradient-based structure-preserving branch. We utilize gradient-based branches to obtain additional structural priors for denoising, and make the model pay more attention to image geometric details through gradient loss optimization.Based on the above, we propose an efficiently Unet structured network with dual branch, the visual results show that can effectively preserve the structural details of the original image, we evaluate benchmarks including SIDD and DND, where SCANet achieves state-of-the-art performance in PSNR and SSIM while significantly reducing computational cost.  
### Unsupervised Frequent Pattern Mining for CEP. (arXiv:2207.14017v1 [cs.LG])
- Authors : Guy Shapira, Assaf Schuster
- Link : [http://arxiv.org/abs/2207.14017](http://arxiv.org/abs/2207.14017)
> ABSTRACT  :  Complex Event Processing (CEP) is a set of methods that allow efficient knowledge extraction from massive data streams using complex and highly descriptive patterns. Numerous applications, such as online finance, healthcare monitoring and fraud detection use CEP technologies to capture critical alerts, potential threats, or vital notifications in **real time**. As of today, in many fields, patterns are manually defined by human experts. However, desired patterns often contain convoluted relations that are difficult for humans to detect, and human expertise is scarce in many domains.    We present REDEEMER (REinforcement baseD cEp pattErn MinER), a novel reinforcement and active learning approach aimed at mining CEP patterns that allow expansion of the knowledge extracted while reducing the human effort required. This approach includes a novel policy gradient method for vast multivariate spaces and a new way to combine reinforcement and active learning for CEP rule learning while minimizing the number of labels needed for training.    REDEEMER aims to enable CEP integration in domains that could not utilize it before. To the best of our knowledge, REDEEMER is the first system that suggests new CEP rules that were not observed beforehand, and is the first method aimed for increasing pattern knowledge in fields where experts do not possess sufficient information required for CEP tools.    Our experiments on diverse data-sets demonstrate that REDEEMER is able to extend pattern knowledge while outperforming several state-of-the-art reinforcement learning methods for pattern mining.  
## cs.AI
---
# Paper List
---
## cs.CV
---
**90** new papers in cs.CV:-) 
1. Break and Make: Interactive Structural Understanding Using LEGO Bricks. (arXiv:2207.13738v1 [cs.CV])
2. Lighting (In)consistency of Paint by Text. (arXiv:2207.13744v1 [cs.CV])
3. GAUDI: A Neural Architect for Immersive 3D Scene Generation. (arXiv:2207.13751v1 [cs.CV])
4. Deep Learning for Classification of Thyroid Nodules on Ultrasound: Validation on an Independent Dataset. (arXiv:2207.13765v1 [eess.IV])
5. AvatarPoser: Articulated Full-Body Pose Tracking from Sparse Motion Sensing. (arXiv:2207.13784v1 [cs.CV])
6. Learning to Assess Danger from Movies for Cooperative Escape Planning in Hazardous Environments. (arXiv:2207.13791v1 [cs.RO])
7. Look at Adjacent Frames: Video Anomaly Detection without Offline Training. (arXiv:2207.13798v1 [cs.CV])
8. Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields. (arXiv:2207.13807v1 [cs.CV])
9. Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery with Transformers. (arXiv:2207.13820v1 [cs.CV])
10. 3D-Morphomics, Morphological Features on CT scans for lung nodule malignancy diagnosis. (arXiv:2207.13830v1 [eess.IV])
11. Extraction of Coronary Vessels in Fluoroscopic X-Ray Sequences Using Vessel Correspondence Optimization. (arXiv:2207.13837v1 [eess.IV])
12. EEG2Mel: Reconstructing Sound from Brain Responses to Music. (arXiv:2207.13845v1 [cs.SD])
13. Dn**Swin**: Toward Real-World Denoising via Continuous Wavelet Sliding-Transformer. (arXiv:2207.13861v1 [cs.CV])
14. MKANet: A Lightweight Network with Sobel Boundary Loss for Efficient Land-cover Classification of Satellite Remote Sensing Imagery. (arXiv:2207.13866v1 [cs.CV])
15. Generative Steganography Network. (arXiv:2207.13867v1 [cs.CV])
16. Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
17. A Repulsive Force Unit for Garment Collision Handling in Neural Networks. (arXiv:2207.13871v1 [cs.GR])
18. Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
19. SuperVessel: Segmenting High-resolution Vessel from Low-resolution Retinal Image. (arXiv:2207.13882v1 [eess.IV])
20. Why Accuracy Is Not Enough: The Need for Consistency in Object Detection. (arXiv:2207.13890v1 [cs.CV])
21. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v1 [cs.CV])
22. Meta-Learning based Degradation Representation for Blind Super-Resolution. (arXiv:2207.13963v1 [cs.CV])
23. On the Effects of Different Types of Label Noise in Multi-Label Remote Sensing Image Classification. (arXiv:2207.13975v1 [cs.CV])
24. Video Mask Transfiner for High-Quality Video Instance Segmentation. (arXiv:2207.14012v1 [cs.CV])
25. Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer. (arXiv:2207.14024v1 [cs.CV])
26. Separable Quaternion Matrix Factorization for Polarization Images. (arXiv:2207.14039v1 [cs.CV])
27. Robust Self-Tuning Data Association for Geo-Referencing Using Lane Markings. (arXiv:2207.14042v1 [cs.RO])
28. Neural Strands: Learning Hair Geometry and Appearance from Multi-View Images. (arXiv:2207.14067v1 [cs.CV])
29. PEA: Improving the Performance of ReLU Networks for Free by Using Progressive Ensemble Activations. (arXiv:2207.14074v1 [cs.CV])
30. Topological Analysis of Ensembles of Hydrodynamic Turbulent Flows -- An Experimental Study. (arXiv:2207.14080v1 [physics.flu-dyn])
31. Weakly-Supervised Camouflaged Object Detection with Scribble Annotations. (arXiv:2207.14083v1 [cs.CV])
32. CubeMLP: A MLP-based Model for Multimodal Sentiment Analysis and Depression Estimation. (arXiv:2207.14087v1 [cs.MM])
33. Towards Large-Scale Small Object Detection: Survey and Benchmarks. (arXiv:2207.14096v1 [cs.CV])
34. RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation. (arXiv:2207.14166v1 [cs.CV])
35. Content-oriented learned image compression. (arXiv:2207.14168v1 [cs.CV])
36. Semantic-Aligned Matching for Enhanced DETR Convergence and Multi-Scale Feature Fusion. (arXiv:2207.14172v1 [cs.CV])
37. Learning with Limited Annotations: A Survey on Deep Semi-Supervised Learning for Medical Image Segmentation. (arXiv:2207.14191v1 [cs.CV])
38. Mining Cross-Person Cues for Body-Part Interactiveness Learning in HOI Detection. (arXiv:2207.14192v1 [cs.CV])
39. Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric Framework for Exemplar-free Class-Incremental Learning. (arXiv:2207.14202v1 [cs.CV])
40. Humans disagree with the IoU for measuring object detector localization error. (arXiv:2207.14221v1 [cs.CV])
41. Electricity Price Forecasting Model based on Gated Recurrent Units. (arXiv:2207.14225v1 [cs.LG])
42. Visual Recognition by Request. (arXiv:2207.14227v1 [cs.CV])
43. Re-thinking and Re-labeling LIDC-IDRI for Robust Pulmonary Cancer Prediction. (arXiv:2207.14238v1 [eess.IV])
44. Combining human parsing with analytical feature extraction and ranking schemes for high-generalization person reidentification. (arXiv:2207.14243v1 [cs.CV])
45. MonteBoxFinder: Detecting and Filtering Primitives to Fit a Noisy Point Cloud. (arXiv:2207.14268v1 [cs.CV])
46. CuDi: Curve Distillation for Efficient and Controllable **Exposure** Adjustment. (arXiv:2207.14273v1 [cs.CV])
47. The One Where They Reconstructed 3D Humans and Environments in TV Shows. (arXiv:2207.14279v1 [cs.CV])
48. HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions. (arXiv:2207.14284v1 [cs.CV])
49. Depth Field Networks for Generalizable Multi-view Scene Representation. (arXiv:2207.14287v1 [cs.CV])
50. Rewriting Geometric Rules of a GAN. (arXiv:2207.14288v1 [cs.CV])
51. Initialization and Alignment for Adversarial Texture Optimization. (arXiv:2207.14289v1 [cs.CV])
52. DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific Delta. (arXiv:2009.08753v4 [cs.CV] UPDATED)
53. Learning Deep Morphological Networks with Neural Architecture Search. (arXiv:2106.07714v2 [cs.CV] UPDATED)
54. ALLNet: A Hybrid Convolutional Neural Network to Improve Diagnosis of Acute Lymphocytic Leukemia (ALL) in White Blood Cells. (arXiv:2108.08195v2 [cs.CV] UPDATED)
55. Semi-supervised learning for joint SAR and multispectral land cover classification. (arXiv:2108.09075v2 [eess.IV] UPDATED)
56. TACS: Taxonomy Adaptive Cross-Domain Semantic Segmentation. (arXiv:2109.04813v3 [cs.CV] UPDATED)
57. MFNet: Multi-class Few-shot Segmentation Network with Pixel-wise Metric Learning. (arXiv:2111.00232v4 [cs.CV] UPDATED)
58. AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions. (arXiv:2112.00246v5 [cs.CV] UPDATED)
59. Multimodal Entity Tagging with Multimodal Knowledge Base. (arXiv:2201.00693v2 [cs.IR] UPDATED)
60. Snapshot Spectral Compressive Imaging Reconstruction Using Convolution and Contextual Transformer. (arXiv:2201.05768v3 [eess.IV] UPDATED)
61. TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration. (arXiv:2203.00927v2 [cs.CV] UPDATED)
62. The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods. (arXiv:2203.02486v4 [cs.CV] UPDATED)
63. Single-Stream Multi-Level Alignment for Vision-Language Pretraining. (arXiv:2203.14395v3 [cs.CV] UPDATED)
64. mc-BEiT: Multi-choice Discretization for Image BERT Pre-training. (arXiv:2203.15371v4 [cs.CV] UPDATED)
65. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v2 [physics.ao-ph] UPDATED)
66. Demonstrate Once, Imitate Immediately (DOME): Learning Visual Servoing for One-Shot Imitation Learning. (arXiv:2204.02863v2 [cs.RO] UPDATED)
67. ECCV Caption: Correcting False Negatives by Collecting Machine-and-Human-verified Image-Caption Associations for MS-COCO. (arXiv:2204.03359v3 [cs.CV] UPDATED)
68. Improving Few-Shot Part Segmentation using Coarse Supervision. (arXiv:2204.05393v2 [cs.CV] UPDATED)
69. Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly. (arXiv:2204.13631v2 [cs.CV] UPDATED)
70. Distinction Maximization Loss: Efficiently Improving Uncertainty Estimation and Out-of-Distribution Detection by Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v3 [cs.LG] UPDATED)
71. Localized Vision-Language Matching for Open-vocabulary Object Detection. (arXiv:2205.06160v2 [cs.CV] UPDATED)
72. TBraTS: Trusted Brain Tumor Segmentation. (arXiv:2206.09309v3 [eess.IV] UPDATED)
73. Knowledge Distillation with Representative Teacher Keys Based on Attention Mechanism for Image Classification Model Compression. (arXiv:2206.12788v2 [cs.CV] UPDATED)
74. Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v2 [cs.CV] UPDATED)
75. OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning. (arXiv:2207.02261v2 [cs.CV] UPDATED)
76. Towards Realistic Semi-Supervised Learning. (arXiv:2207.02269v2 [cs.CV] UPDATED)
77. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v3 [cs.AI] UPDATED)
78. Towards Grand Unification of Object Tracking. (arXiv:2207.07078v3 [cs.CV] UPDATED)
79. Towards Lightweight Super-Resolution with Dual Regression Learning. (arXiv:2207.07929v3 [cs.CV] UPDATED)
80. OTPose: Occlusion-Aware Transformer for Pose Estimation in Sparsely-Labeled Videos. (arXiv:2207.09725v2 [cs.CV] UPDATED)
81. DeltaGAN: Towards Diverse Few-shot Image Generation with Sample-Specific Delta. (arXiv:2207.10271v3 [cs.CV] UPDATED)
82. Ada**NeRF**: Adaptive Sampling for **Real-time** Rendering of Neural Radiance Fields. (arXiv:2207.10312v2 [cs.CV] UPDATED)
83. Generalizable Patch-Based Neural Rendering. (arXiv:2207.10662v2 [cs.CV] UPDATED)
84. Few-shot Object Counting and Detection. (arXiv:2207.10988v2 [cs.CV] UPDATED)
85. Zero-Shot Video Captioning with Evolving Pseudo-Tokens. (arXiv:2207.11100v2 [cs.CV] UPDATED)
86. Riemannian Geometry Approach for Minimizing Distortion and its Applications. (arXiv:2207.12038v3 [cs.CV] UPDATED)
87. YOLO and Mask R-CNN for Vehicle Number Plate Identification. (arXiv:2207.13165v2 [cs.CV] UPDATED)
88. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v2 [cs.LG] UPDATED)
89. Look Closer to Your Enemy: Learning to Attack via Teacher-student Mimicking. (arXiv:2207.13381v2 [cs.CV] UPDATED)
90. Statistical Keystroke Synthesis for Improved Bot Detection. (arXiv:2207.13394v2 [cs.LG] UPDATED)
## eess.IV
---
**17** new papers in eess.IV:-) 
1. Deep Learning for Classification of Thyroid Nodules on Ultrasound: Validation on an Independent Dataset. (arXiv:2207.13765v1 [eess.IV])
2. 3D-Morphomics, Morphological Features on CT scans for lung nodule malignancy diagnosis. (arXiv:2207.13830v1 [eess.IV])
3. Extraction of Coronary Vessels in Fluoroscopic X-Ray Sequences Using Vessel Correspondence Optimization. (arXiv:2207.13837v1 [eess.IV])
4. Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
5. Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
6. SuperVessel: Segmenting High-resolution Vessel from Low-resolution Retinal Image. (arXiv:2207.13882v1 [eess.IV])
7. Breast shape estimation and correction in CESM biopsy. (arXiv:2207.13917v1 [physics.med-ph])
8. Spotlight on nerves: Portable multispectral optoacoustic imaging of peripheral nerve vascularization and morphology. (arXiv:2207.13978v1 [eess.IV])
9. A Transformer-based Generative Adversarial Network for Brain Tumor Segmentation. (arXiv:2207.14134v1 [eess.IV])
10. RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation. (arXiv:2207.14166v1 [cs.CV])
11. Content-oriented learned image compression. (arXiv:2207.14168v1 [cs.CV])
12. Optimization of Artificial Neural Networks models applied to the identification of images of asteroids' resonant arguments. (arXiv:2207.14181v1 [astro-ph.EP])
13. Re-thinking and Re-labeling LIDC-IDRI for Robust Pulmonary Cancer Prediction. (arXiv:2207.14238v1 [eess.IV])
14. Semi-supervised learning for joint SAR and multispectral land cover classification. (arXiv:2108.09075v2 [eess.IV] UPDATED)
15. Snapshot Spectral Compressive Imaging Reconstruction Using Convolution and Contextual Transformer. (arXiv:2201.05768v3 [eess.IV] UPDATED)
16. TransDARC: Transformer-based Driver Activity Recognition with Latent Space Feature Calibration. (arXiv:2203.00927v2 [cs.CV] UPDATED)
17. TBraTS: Trusted Brain Tumor Segmentation. (arXiv:2206.09309v3 [eess.IV] UPDATED)
## cs.LG
---
**110** new papers in cs.LG:-) 
1. Modelling non-reinforced preferences using selective attention. (arXiv:2207.13699v1 [cs.LG])
2. Remote Medication Status Prediction for Individuals with Parkinson's Disease using Time-series Data from Smartphones. (arXiv:2207.13700v1 [cs.LG])
3. Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-based Policy Learning. (arXiv:2207.13701v1 [cs.LG])
4. Physical Systems Modeled Without Physical Laws. (arXiv:2207.13702v1 [cs.LG])
5. SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation. (arXiv:2207.13703v1 [cs.SD])
6. Distributional Actor-Critic Ensemble for Uncertainty-Aware Continuous Control. (arXiv:2207.13730v1 [cs.LG])
7. Differentially Private Learning of Hawkes Processes. (arXiv:2207.13741v1 [stat.ML])
8. GAUDI: A Neural Architect for Immersive 3D Scene Generation. (arXiv:2207.13751v1 [cs.CV])
9. Deep Learning for Classification of Thyroid Nodules on Ultrasound: Validation on an Independent Dataset. (arXiv:2207.13765v1 [eess.IV])
10. Label-Only Membership Inference Attack against Node-Level Graph Neural Networks. (arXiv:2207.13766v1 [cs.CR])
11. Calibrate: Interactive Analysis of Probabilistic Model Output. (arXiv:2207.13770v1 [cs.HC])
12. Physical Pooling Functions in Graph Neural Networks for Molecular Property Prediction. (arXiv:2207.13779v1 [cs.LG])
13. Learning to Assess Danger from Movies for Cooperative Escape Planning in Hazardous Environments. (arXiv:2207.13791v1 [cs.RO])
14. Towards Sleep Scoring Generalization Through Self-Supervised Meta-Learning. (arXiv:2207.13801v1 [cs.LG])
15. Structural Similarity for Improved Transfer in Reinforcement Learning. (arXiv:2207.13813v1 [cs.LG])
16. Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery with Transformers. (arXiv:2207.13820v1 [cs.CV])
17. Multi-Objective Provisioning of Network Slices using Deep Reinforcement Learning. (arXiv:2207.13821v1 [cs.NI])
18. Dive into Machine Learning Algorithms for Influenza Virus Host Prediction with Hemagglutinin Sequences. (arXiv:2207.13842v1 [cs.LG])
19. Deep Learning-Based Acoustic Mosquito Detection in Noisy Conditions Using Trainable Kernels and Augmentations. (arXiv:2207.13843v1 [cs.SD])
20. Predicting the Output Structure of Sparse Matrix Multiplication with Sampled Compression Ratio. (arXiv:2207.13848v1 [cs.DC])
21. One-Pass Learning via Bridging Orthogonal Gradient Descent and Recursive Least-Squares. (arXiv:2207.13853v1 [cs.LG])
22. Learning to Adapt Classifier for Imbalanced Semi-supervised Learning. (arXiv:2207.13856v1 [cs.LG])
23. Diversity Boosted Learning for Domain Generalization with Large Number of Domains. (arXiv:2207.13865v1 [cs.LG])
24. Extraction of Vascular Wall in Carotid Ultrasound via a Novel Boundary-Delineation Network. (arXiv:2207.13868v1 [eess.IV])
25. p-Adic Statistical Field Theory and Deep Belief Networks. (arXiv:2207.13877v1 [math-ph])
26. Real Image **Restoration** via Structure-preserving Complementarity Attention. (arXiv:2207.13879v1 [eess.IV])
27. Adaptive Second Order Coresets for Data-efficient Machine Learning. (arXiv:2207.13887v1 [cs.LG])
28. Exploiting Negative Preference in Content-based Music Recommendation with Contrastive Learning. (arXiv:2207.13909v1 [cs.IR])
29. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v1 [cs.CV])
30. HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein Language Model as an Alternative. (arXiv:2207.13921v1 [q-bio.BM])
31. PHEMEPlus: Enriching Social Media Rumour Verification with External Evidence. (arXiv:2207.13970v1 [cs.CL])
32. Federated Learning for IoUT: Concepts, Applications, Challenges and Opportunities. (arXiv:2207.13976v1 [cs.LG])
33. ClaSP -- Parameter-free Time Series Segmentation. (arXiv:2207.13987v1 [cs.LG])
34. Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation. (arXiv:2207.14000v1 [cs.CL])
35. Raising Student Completion Rates with Adaptive Curriculum and Contextual Bandits. (arXiv:2207.14003v1 [cs.CL])
36. Unsupervised Frequent Pattern Mining for CEP. (arXiv:2207.14017v1 [cs.LG])
37. Automated Classification of Nanoparticles with Various Ultrastructures and Sizes. (arXiv:2207.14023v1 [cond-mat.mtrl-sci])
38. Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer. (arXiv:2207.14024v1 [cs.CV])
39. Hardness of Agnostically Learning Halfspaces from Worst-Case Lattice Problems. (arXiv:2207.14030v1 [cs.LG])
40. PEA: Improving the Performance of ReLU Networks for Free by Using Progressive Ensemble Activations. (arXiv:2207.14074v1 [cs.CV])
41. Topological Analysis of Ensembles of Hydrodynamic Turbulent Flows -- An Experimental Study. (arXiv:2207.14080v1 [physics.flu-dyn])
42. MarkerMap: nonlinear marker selection for single-cell studies. (arXiv:2207.14106v1 [stat.ML])
43. Classification of FIB/SEM-tomography images for highly porous multiphase materials using random forest classifiers. (arXiv:2207.14114v1 [cond-mat.mtrl-sci])
44. Graph Neural Networks to Predict Sports Outcomes. (arXiv:2207.14124v1 [cs.LG])
45. FedVARP: Tackling the Variance Due to Partial Client Participation in Federated Learning. (arXiv:2207.14130v1 [cs.LG])
46. Learning unseen coexisting attractors. (arXiv:2207.14133v1 [cs.LG])
47. A Transformer-based Generative Adversarial Network for Brain Tumor Segmentation. (arXiv:2207.14134v1 [eess.IV])
48. Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training Teammates. (arXiv:2207.14138v1 [cs.LG])
49. Playing a 2D Game Indefinitely using NEAT and Reinforcement Learning. (arXiv:2207.14140v1 [cs.LG])
50. A Probabilistic Framework for Estimating the Risk of Pedestrian-Vehicle Conflicts at Intersections. (arXiv:2207.14145v1 [cs.LG])
51. RHA-Net: An Encoder-Decoder Network with Residual Blocks and Hybrid Attention Mechanisms for Pavement Crack Segmentation. (arXiv:2207.14166v1 [cs.CV])
52. Optimization of Artificial Neural Networks models applied to the identification of images of asteroids' resonant arguments. (arXiv:2207.14181v1 [astro-ph.EP])
53. CrAM: A Compression-Aware Minimizer. (arXiv:2207.14200v1 [cs.LG])
54. Progressive Voronoi Diagram Subdivision: Towards A Holistic Geometric Framework for Exemplar-free Class-Incremental Learning. (arXiv:2207.14202v1 [cs.CV])
55. Regret Minimization and Convergence to Equilibria in General-sum Markov Games. (arXiv:2207.14211v1 [cs.LG])
56. Gender In Gender Out: A Closer Look at User Attributes in Context-Aware Recommendation. (arXiv:2207.14218v1 [cs.LG])
57. A general framework for multi-step ahead adaptive conformal heteroscedastic time series forecasting. (arXiv:2207.14219v1 [stat.ML])
58. Electricity Price Forecasting Model based on Gated Recurrent Units. (arXiv:2207.14225v1 [cs.LG])
59. Improving the Performance of Robust Control through Event-Triggered Learning. (arXiv:2207.14252v1 [eess.SY])
60. Exploiting and Defending Against the Approximate Linearity of Apple's NeuralHash. (arXiv:2207.14258v1 [cs.CR])
61. Cryptographic Hardness of Learning Halfspaces with Massart Noise. (arXiv:2207.14266v1 [cs.LG])
62. Depth Field Networks for Generalizable Multi-view Scene Representation. (arXiv:2207.14287v1 [cs.CV])
63. Learning with Succinct Common Representation Based on Wyner's Common Information. (arXiv:1905.10945v2 [cs.LG] UPDATED)
64. Inclined Quadrotor Landing using Deep Reinforcement Learning. (arXiv:2103.09043v2 [cs.RO] UPDATED)
65. Learning Deep Morphological Networks with Neural Architecture Search. (arXiv:2106.07714v2 [cs.CV] UPDATED)
66. Test Sample Accuracy Scales with Training Sample Density in Neural Networks. (arXiv:2106.08365v7 [cs.LG] UPDATED)
67. Machine Learning for Stuttering Identification: Review, Challenges and Future Directions. (arXiv:2107.04057v4 [cs.SD] UPDATED)
68. ALLNet: A Hybrid Convolutional Neural Network to Improve Diagnosis of Acute Lymphocytic Leukemia (ALL) in White Blood Cells. (arXiv:2108.08195v2 [cs.CV] UPDATED)
69. Fast Newton method solving KLR based on Multilevel Circulant Matrix with log-linear complexity. (arXiv:2108.08605v3 [cs.LG] UPDATED)
70. Shift-Curvature, SGD, and Generalization. (arXiv:2108.09507v3 [stat.ML] UPDATED)
71. Modeling Item Response Theory with Stochastic Variational Inference. (arXiv:2108.11579v2 [cs.LG] UPDATED)
72. Instance-wise or Class-wise? A Tale of Neighbor Shapley for Concept-based Explanation. (arXiv:2109.01369v4 [cs.LG] UPDATED)
73. General Cross-Architecture Distillation of Pretrained Language Models into Matrix Embeddings. (arXiv:2109.08449v2 [cs.CL] UPDATED)
74. Quantifying Inequality in Underreported Medical Conditions. (arXiv:2110.04133v3 [cs.CY] UPDATED)
75. What Happens after SGD Reaches Zero Loss? --A Mathematical Framework. (arXiv:2110.06914v4 [cs.LG] UPDATED)
76. An iterative clustering algorithm for the Contextual Stochastic Block Model with optimality guarantees. (arXiv:2112.10467v2 [stat.ML] UPDATED)
77. Execute Order 66: Targeted Data Poisoning for Reinforcement Learning. (arXiv:2201.00762v2 [cs.LG] UPDATED)
78. Differentiable Rule Induction with Learned Relational Features. (arXiv:2201.06515v2 [stat.ML] UPDATED)
79. One-Nearest-Neighbor Search is All You Need for Minimax Optimal Regression and Classification. (arXiv:2202.02464v2 [math.ST] UPDATED)
80. Private Convex Optimization via Exponential Mechanism. (arXiv:2203.00263v2 [cs.DS] UPDATED)
81. The Familiarity Hypothesis: Explaining the Behavior of Deep Open Set Methods. (arXiv:2203.02486v4 [cs.CV] UPDATED)
82. Federated Learning Framework Coping with Hierarchical Heterogeneity in Cooperative ITS. (arXiv:2204.00215v3 [cs.LG] UPDATED)
83. On the Universality of Langevin Diffusion for Private Euclidean (Convex) Optimization. (arXiv:2204.01585v3 [cs.LG] UPDATED)
84. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v2 [physics.ao-ph] UPDATED)
85. Pareto-optimal clustering with the primal deterministic information bottleneck. (arXiv:2204.02489v2 [cs.LG] UPDATED)
86. Reinforcement Learning with Intrinsic Affinity for Personalized Prosperity Management. (arXiv:2204.09218v2 [cs.LG] UPDATED)
87. Sound2Synth: Interpreting Sound via FM Synthesizer Parameters Estimation. (arXiv:2205.03043v2 [cs.SD] UPDATED)
88. Distinction Maximization Loss: Efficiently Improving Uncertainty Estimation and Out-of-Distribution Detection by Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v3 [cs.LG] UPDATED)
89. Localized Vision-Language Matching for Open-vocabulary Object Detection. (arXiv:2205.06160v2 [cs.CV] UPDATED)
90. OFedQIT: Communication-Efficient Online Federated Learning via Quantization and Intermittent Transmission. (arXiv:2205.06491v2 [cs.LG] UPDATED)
91. Associative Learning Mechanism for Drug-Target Interaction Prediction. (arXiv:2205.15364v4 [q-bio.BM] UPDATED)
92. Algorithmic Foundation of Deep X-Risk Optimization. (arXiv:2206.00439v4 [cs.LG] UPDATED)
93. Three-dimensional microstructure generation using generative adversarial neural networks in the context of continuum micromechanics. (arXiv:2206.01693v2 [cond-mat.mtrl-sci] UPDATED)
94. Individual Privacy Accounting for Differentially Private Stochastic Gradient Descent. (arXiv:2206.02617v3 [cs.LG] UPDATED)
95. On the fast convergence of minibatch heavy ball momentum. (arXiv:2206.07553v2 [cs.LG] UPDATED)
96. SpeechEQ: Speech Emotion Recognition based on Multi-scale Unified Datasets and Multitask Learning. (arXiv:2206.13101v2 [cs.SD] UPDATED)
97. Generative Modelling With Inverse Heat Dissipation. (arXiv:2206.13397v2 [cs.CV] UPDATED)
98. OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning. (arXiv:2207.02261v2 [cs.CV] UPDATED)
99. Towards Realistic Semi-Supervised Learning. (arXiv:2207.02269v2 [cs.CV] UPDATED)
100. HierarchicalForecast: A Reference Framework for Hierarchical Forecasting in Python. (arXiv:2207.03517v3 [stat.ML] UPDATED)
101. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v3 [cs.AI] UPDATED)
102. QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v3 [quant-ph] UPDATED)
103. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v2 [eess.SY] UPDATED)
104. Metropolis Monte Carlo sampling: convergence, localization transition and optimality. (arXiv:2207.10488v2 [cond-mat.stat-mech] UPDATED)
105. RIBBON: Cost-Effective and QoS-Aware Deep Learning Model Inference using a Diverse Pool of Cloud Computing Instances. (arXiv:2207.11434v2 [cs.DC] UPDATED)
106. $\mu\text{KG}$: A Library for Multi-source Knowledge Graph Embeddings and Applications. (arXiv:2207.11442v2 [cs.CL] UPDATED)
107. VDL-Surrogate: A View-Dependent Latent-based Model for Parameter Space Exploration of Ensemble Simulations. (arXiv:2207.13091v2 [cs.GR] UPDATED)
108. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v2 [cs.LG] UPDATED)
109. INTERACT: Achieving Low Sample and Communication Complexities in Decentralized Bilevel Learning over Networks. (arXiv:2207.13283v2 [cs.LG] UPDATED)
110. Statistical Keystroke Synthesis for Improved Bot Detection. (arXiv:2207.13394v2 [cs.LG] UPDATED)
## cs.AI
---
**60** new papers in cs.AI:-) 
1. Modelling non-reinforced preferences using selective attention. (arXiv:2207.13699v1 [cs.LG])
2. Remote Medication Status Prediction for Individuals with Parkinson's Disease using Time-series Data from Smartphones. (arXiv:2207.13700v1 [cs.LG])
3. Branch Ranking for Efficient Mixed-Integer Programming via Offline Ranking-based Policy Learning. (arXiv:2207.13701v1 [cs.LG])
4. Break and Make: Interactive Structural Understanding Using LEGO Bricks. (arXiv:2207.13738v1 [cs.CV])
5. Lighting (In)consistency of Paint by Text. (arXiv:2207.13744v1 [cs.CV])
6. AvatarPoser: Articulated Full-Body Pose Tracking from Sparse Motion Sensing. (arXiv:2207.13784v1 [cs.CV])
7. Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery with Transformers. (arXiv:2207.13820v1 [cs.CV])
8. Will AI Make Cyber Swords or Shields: A few mathematical models of technological progress. (arXiv:2207.13825v1 [cs.CR])
9. Toward Supporting Perceptual Complementarity in Human-AI Collaboration via Reflection on Unobservables. (arXiv:2207.13834v1 [cs.HC])
10. Measuring Difficulty of Novelty Reaction. (arXiv:2207.13857v1 [cs.AI])
11. A health telemonitoring platform based on data integration from different sources. (arXiv:2207.13913v1 [cs.CY])
12. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v1 [cs.CV])
13. HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein Language Model as an Alternative. (arXiv:2207.13921v1 [q-bio.BM])
14. PHEMEPlus: Enriching Social Media Rumour Verification with External Evidence. (arXiv:2207.13970v1 [cs.CL])
15. Knowing Where and What: Unified Word Block Pretraining for Document Understanding. (arXiv:2207.13979v1 [cs.CL])
16. ClaSP -- Parameter-free Time Series Segmentation. (arXiv:2207.13987v1 [cs.LG])
17. Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation. (arXiv:2207.14000v1 [cs.CL])
18. Raising Student Completion Rates with Adaptive Curriculum and Contextual Bandits. (arXiv:2207.14003v1 [cs.CL])
19. Safety-Enhanced Autonomous Driving Using Interpretable Sensor Fusion Transformer. (arXiv:2207.14024v1 [cs.CV])
20. Entity Type Prediction Leveraging Graph Walks and Entity Descriptions. (arXiv:2207.14094v1 [cs.CL])
21. Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction. (arXiv:2207.14116v1 [cs.CL])
22. A Survey of Syntactic Modelling Structures in Biomedical Ontologies. (arXiv:2207.14119v1 [cs.AI])
23. Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training Teammates. (arXiv:2207.14138v1 [cs.LG])
24. Playing a 2D Game Indefinitely using NEAT and Reinforcement Learning. (arXiv:2207.14140v1 [cs.LG])
25. A Hazard Analysis Framework for Code Synthesis Large Language Models. (arXiv:2207.14157v1 [cs.SE])
26. Do We Need Another Explainable AI Method? Toward Unifying Post-hoc XAI Evaluation Methods into an Interactive and Multi-dimensional Benchmark. (arXiv:2207.14160v1 [cs.SE])
27. Bayesian Optimization-Based Beam Alignment for MmWave MIMO Communication Systems. (arXiv:2207.14174v1 [eess.SP])
28. DoRO: Disambiguation of referred object for embodied agents. (arXiv:2207.14205v1 [cs.RO])
29. Regret Minimization and Convergence to Equilibria in General-sum Markov Games. (arXiv:2207.14211v1 [cs.LG])
30. Physics-informed neural networks for diffraction tomography. (arXiv:2207.14230v1 [physics.optics])
31. Initialization and Alignment for Adversarial Texture Optimization. (arXiv:2207.14289v1 [cs.CV])
32. The Minimum Description Length Principle for Pattern Mining: A Survey. (arXiv:2007.14009v5 [cs.DB] UPDATED)
33. Learning Deep Morphological Networks with Neural Architecture Search. (arXiv:2106.07714v2 [cs.CV] UPDATED)
34. Test Sample Accuracy Scales with Training Sample Density in Neural Networks. (arXiv:2106.08365v7 [cs.LG] UPDATED)
35. ALLNet: A Hybrid Convolutional Neural Network to Improve Diagnosis of Acute Lymphocytic Leukemia (ALL) in White Blood Cells. (arXiv:2108.08195v2 [cs.CV] UPDATED)
36. Abductive Inference and C. S. Peirce: 150 Years Later. (arXiv:2111.08054v2 [econ.EM] UPDATED)
37. Multimodal Entity Tagging with Multimodal Knowledge Base. (arXiv:2201.00693v2 [cs.IR] UPDATED)
38. Execute Order 66: Targeted Data Poisoning for Reinforcement Learning. (arXiv:2201.00762v2 [cs.LG] UPDATED)
39. Visibility-Inspired Models of Touch Sensors for Navigation. (arXiv:2203.04751v2 [cs.RO] UPDATED)
40. A Generative Deep Learning Approach to Stochastic Downscaling of Precipitation Forecasts. (arXiv:2204.02028v2 [physics.ao-ph] UPDATED)
41. Demonstrate Once, Imitate Immediately (DOME): Learning Visual Servoing for One-Shot Imitation Learning. (arXiv:2204.02863v2 [cs.RO] UPDATED)
42. Resource-Aware Distributed Submodular Maximization: A Paradigm for Multi-Robot Decision-Making. (arXiv:2204.07520v2 [math.OC] UPDATED)
43. Reinforcement Learning with Intrinsic Affinity for Personalized Prosperity Management. (arXiv:2204.09218v2 [cs.LG] UPDATED)
44. Active Domain-Invariant Self-Localization Using Ego-Centric and World-Centric Maps. (arXiv:2204.10497v2 [cs.RO] UPDATED)
45. Sound2Synth: Interpreting Sound via FM Synthesizer Parameters Estimation. (arXiv:2205.03043v2 [cs.SD] UPDATED)
46. Distinction Maximization Loss: Efficiently Improving Uncertainty Estimation and Out-of-Distribution Detection by Simply Replacing the Loss and Calibrating. (arXiv:2205.05874v3 [cs.LG] UPDATED)
47. Uncertainty-aware Personal Assistant for Making Personalized Privacy Decisions. (arXiv:2205.06544v4 [cs.AI] UPDATED)
48. Algorithmic Foundation of Deep X-Risk Optimization. (arXiv:2206.00439v4 [cs.LG] UPDATED)
49. Knowledge Distillation with Representative Teacher Keys Based on Attention Mechanism for Image Classification Model Compression. (arXiv:2206.12788v2 [cs.CV] UPDATED)
50. Long-Tail Prediction Uncertainty Aware Trajectory Planning for Self-driving Vehicles. (arXiv:2207.00788v2 [cs.AI] UPDATED)
51. HierarchicalForecast: A Reference Framework for Hierarchical Forecasting in Python. (arXiv:2207.03517v3 [stat.ML] UPDATED)
52. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v3 [cs.AI] UPDATED)
53. Space-based gravitational wave signal detection and extraction with deep neural network. (arXiv:2207.07414v2 [gr-qc] UPDATED)
54. QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v3 [quant-ph] UPDATED)
55. On stabilizing reinforcement learning without Lyapunov functions. (arXiv:2207.08730v2 [eess.SY] UPDATED)
56. A Community-Aware Framework for Social Influence Maximization. (arXiv:2207.08937v2 [cs.SI] UPDATED)
57. Language Model Cascades. (arXiv:2207.10342v2 [cs.CL] UPDATED)
58. $\mu\text{KG}$: A Library for Multi-source Knowledge Graph Embeddings and Applications. (arXiv:2207.11442v2 [cs.CL] UPDATED)
59. VDL-Surrogate: A View-Dependent Latent-based Model for Parameter Space Exploration of Ensemble Simulations. (arXiv:2207.13091v2 [cs.GR] UPDATED)
60. Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v2 [cs.LG] UPDATED)

