# Your interest papers
---
## cs.CV
---
### MoViDNN: A Mobile Platform for Evaluating Video Quality **Enhancement** with Deep Neural Networks. (arXiv:2201.04402v1 [cs.CV])
- Authors : Minh Nguyen, Christian Timmerer
- Link : [http://arxiv.org/abs/2201.04402](http://arxiv.org/abs/2201.04402)
> ABSTRACT  :  Deep neural network (DNN) based approaches have been intensively studied to improve video quality thanks to their fast advancement in recent years. These approaches are designed mainly for desktop devices due to their high computational cost. However, with the increasing performance of mobile devices in recent years, it became possible to execute DNN based approaches in mobile devices. Despite having the required computational power, utilizing DNNs to improve the video quality for mobile devices is still an active research area. In this paper, we propose an open-source mobile platform, namely MoViDNN, to evaluate DNN based video quality **enhancement** methods, such as super-resolution, denoising, and deblocking. Our proposed platform can be used to evaluate the DNN based approaches both objectively and subjectively. For objective evaluation, we report common metrics such as execution time, PSNR, and SSIM. For subjective evaluation, Mean Score Opinion (MOS) is reported. The proposed platform is available publicly at https://github.com/cd-athena/MoViDNN  
### MobileSal: Extremely Efficient RGB-D Salient Object Detection. (arXiv:2012.13095v3 [cs.CV] UPDATED)
- Authors : Huan Wu, Yun Liu, Jun Xu, Wang Bian, Chao Gu, Ming Cheng
- Link : [http://arxiv.org/abs/2012.13095](http://arxiv.org/abs/2012.13095)
> ABSTRACT  :  The high computational cost of neural networks has prevented recent successes in RGB-D salient object detection (SOD) from benefiting real-world applications. Hence, this paper introduces a novel network, MobileSal, which focuses on efficient RGB-D SOD using mobile networks for deep feature extraction. However, mobile networks are less powerful in feature representation than cumbersome networks. To this end, we observe that the depth information of color images can strengthen the feature representation related to SOD if leveraged properly. Therefore, we propose an implicit depth **restoration** (IDR) technique to strengthen the mobile networks' feature representation capability for RGB-D SOD. IDR is only adopted in the training phase and is omitted during testing, so it is computationally free. Besides, we propose compact pyramid refinement (CPR) for efficient multi-level feature aggregation to derive salient objects with clear boundaries. With IDR and CPR incorporated, MobileSal performs favorably against state-of-the-art methods on six challenging RGB-D SOD datasets with much faster speed (450fps for the input size of 320 $\times$ 320) and fewer parameters (6.5M). The code is released at https://mmcheng.net/mobilesal.  
### CharacterGAN: Few-Shot Keypoint Character Animation and Reposing. (arXiv:2102.03141v3 [cs.CV] UPDATED)
- Authors : Tobias Hinz, Matthew Fisher, Oliver Wang, Eli Shechtman, Stefan Wermter
- Link : [http://arxiv.org/abs/2102.03141](http://arxiv.org/abs/2102.03141)
> ABSTRACT  :  We introduce CharacterGAN, a generative model that can be trained on only a few samples (8 - 15) of a given character. Our model generates novel poses based on keypoint locations, which can be modified in **real time** while providing interactive feedback, allowing for intuitive reposing and animation. Since we only have very limited training samples, one of the key challenges lies in how to address (dis)occlusions, e.g. when a hand moves behind or in front of a body. To address this, we introduce a novel layering approach which explicitly splits the input keypoints into different layers which are processed independently. These layers represent different parts of the character and provide a strong implicit bias that helps to obtain realistic results even with strong (dis)occlusions. To combine the features of individual layers we use an adaptive scaling approach conditioned on all keypoints. Finally, we introduce a mask connectivity constraint to reduce distortion artifacts that occur with extreme out-of-distribution poses at test time. We show that our approach outperforms recent baselines and creates realistic animations for diverse characters. We also show that our model can handle discrete state changes, for example a profile facing left or right, that the different layers do indeed learn features specific for the respective keypoints in those layers, and that our model scales to larger datasets when more data is available.  
### Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
- Authors : Anindya Mondal, Mayukhmali Das
- Link : [http://arxiv.org/abs/2109.01879](http://arxiv.org/abs/2109.01879)
> ABSTRACT  :  Moving object detection is important in computer vision. Event-based cameras are bio-inspired cameras that work by mimicking the working of the human eye. These cameras have multiple advantages over conventional frame-based cameras, like reduced latency, **HDR**, reduced motion blur during high motion, low power consumption, etc. In spite of these advantages, event-based cameras are noise-sensitive and have low resolution. Moreover, the task of moving object detection in these cameras is difficult, as event-based sensors lack useful visual features like texture and color. In this paper, we investigate the application of the k-means clustering technique in detecting moving objects in event-based data.  
### Confidence Propagation Cluster: Unleash Full Potential of Object Detectors. (arXiv:2112.00342v3 [cs.CV] UPDATED)
- Authors : Yichun Shen, Wanli Jiang, Zhen Xu, Rundong Li, Junghyun Kwon, Siyi Li
- Link : [http://arxiv.org/abs/2112.00342](http://arxiv.org/abs/2112.00342)
> ABSTRACT  :  It has been a long history that most object detection methods obtain objects by using the non-maximum suppression (NMS) and its improved versions like Soft-NMS to remove redundant bounding boxes. We challenge those NMS-based methods from three aspects: 1) The bounding box with highest confidence value may not be the true positive having the biggest overlap with the ground-truth box. 2) Not only suppression is required for redundant boxes, but also confidence **enhancement** is needed for those true positives. 3) Sorting candidate boxes by confidence values is not necessary so that full parallelism is achievable.    In this paper, inspired by belief propagation (BP), we propose the Confidence Propagation Cluster (CP-Cluster) to replace NMS-based methods, which is fully parallelizable as well as better in accuracy. In CP-Cluster, we borrow the message passing mechanism from BP to penalize redundant boxes and enhance true positives simultaneously in an iterative way until convergence. We verified the effectiveness of CP-Cluster by applying it to various mainstream detectors such as FasterRCNN, SSD, FCOS, YOLOv3, YOLOv5, Centernet etc. Experiments on MS COCO show that our plug and play method, without retraining detectors, is able to steadily improve average mAP of all those state-of-the-art models with a clear margin from 0.2 to 1.9 respectively when compared with NMS-based methods. Source code is available at https://github.com/shenyi0220/CP-Cluster  
### Vision in adverse weather: Augmentation using CycleGANs with various object detectors for robust perception in autonomous racing. (arXiv:2201.03246v2 [cs.CV] UPDATED)
- Authors : Izzeddin Teeti, Valentina Musat, Salman Khan, Alexander Rast, Fabio Cuzzolin, Andrew Bradley
- Link : [http://arxiv.org/abs/2201.03246](http://arxiv.org/abs/2201.03246)
> ABSTRACT  :  In an autonomous driving system, perception - identification of features and objects from the environment - is crucial. In autonomous racing, high speeds and small margins demand rapid and accurate detection systems. During the race, the weather can change abruptly, causing significant degradation in perception, resulting in ineffective manoeuvres. In order to improve detection in adverse weather, deep-learning-based models typically require extensive datasets captured in such conditions - the collection of which is a tedious, laborious, and costly process. However, recent developments in CycleGAN architectures allow the synthesis of highly realistic scenes in multiple weather conditions. To this end, we introduce an approach of using synthesised adverse condition datasets in autonomous racing (generated using CycleGAN) to improve the performance of four out of five state-of-the-art detectors by an average of 42.7 and 4.4 mAP percentage points in the presence of **night**-time conditions and droplets, respectively. Furthermore, we present a comparative analysis of five object detectors - identifying the optimal pairing of detector and training data for use during autonomous racing in challenging conditions.  
## eess.IV
---
### De-Noising of Photoacoustic Microscopy Images by Deep Learning. (arXiv:2201.04302v1 [eess.IV])
- Authors : Da He, Jiasheng Zhou, Xiaoyu Shang, Jiajia Luo, Liang Chen
- Link : [http://arxiv.org/abs/2201.04302](http://arxiv.org/abs/2201.04302)
> ABSTRACT  :  As a hybrid imaging technology, photoacoustic microscopy (PAM) imaging suffers from noise due to the maximum permissible **exposure** of laser intensity, attenuation of ultrasound in the tissue, and the inherent noise of the transducer. De-noising is a post-processing method to reduce noise, and PAM image quality can be recovered. However, previous de-noising techniques usually heavily rely on mathematical priors as well as manually selected parameters, resulting in unsatisfactory and slow de-noising performance for different noisy images, which greatly hinders practical and clinical applications. In this work, we propose a deep learning-based method to remove complex noise from PAM images without mathematical priors and manual selection of settings for different input images. An attention enhanced generative adversarial network is used to extract image features and remove various noises. The proposed method is demonstrated on both synthetic and real datasets, including phantom (leaf veins) and in vivo (mouse ear blood vessels and zebrafish pigment) experiments. The results show that compared with previous PAM de-noising methods, our method exhibits good performance in recovering images qualitatively and quantitatively. In addition, the de-noising speed of 0.016 s is achieved for an image with $256\times256$ pixels. Our approach is effective and practical for the de-noising of PAM images.  
### Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
- Authors : Anindya Mondal, Mayukhmali Das
- Link : [http://arxiv.org/abs/2109.01879](http://arxiv.org/abs/2109.01879)
> ABSTRACT  :  Moving object detection is important in computer vision. Event-based cameras are bio-inspired cameras that work by mimicking the working of the human eye. These cameras have multiple advantages over conventional frame-based cameras, like reduced latency, **HDR**, reduced motion blur during high motion, low power consumption, etc. In spite of these advantages, event-based cameras are noise-sensitive and have low resolution. Moreover, the task of moving object detection in these cameras is difficult, as event-based sensors lack useful visual features like texture and color. In this paper, we investigate the application of the k-means clustering technique in detecting moving objects in event-based data.  
## cs.LG
---
### De-Noising of Photoacoustic Microscopy Images by Deep Learning. (arXiv:2201.04302v1 [eess.IV])
- Authors : Da He, Jiasheng Zhou, Xiaoyu Shang, Jiajia Luo, Liang Chen
- Link : [http://arxiv.org/abs/2201.04302](http://arxiv.org/abs/2201.04302)
> ABSTRACT  :  As a hybrid imaging technology, photoacoustic microscopy (PAM) imaging suffers from noise due to the maximum permissible **exposure** of laser intensity, attenuation of ultrasound in the tissue, and the inherent noise of the transducer. De-noising is a post-processing method to reduce noise, and PAM image quality can be recovered. However, previous de-noising techniques usually heavily rely on mathematical priors as well as manually selected parameters, resulting in unsatisfactory and slow de-noising performance for different noisy images, which greatly hinders practical and clinical applications. In this work, we propose a deep learning-based method to remove complex noise from PAM images without mathematical priors and manual selection of settings for different input images. An attention enhanced generative adversarial network is used to extract image features and remove various noises. The proposed method is demonstrated on both synthetic and real datasets, including phantom (leaf veins) and in vivo (mouse ear blood vessels and zebrafish pigment) experiments. The results show that compared with previous PAM de-noising methods, our method exhibits good performance in recovering images qualitatively and quantitatively. In addition, the de-noising speed of 0.016 s is achieved for an image with $256\times256$ pixels. Our approach is effective and practical for the de-noising of PAM images.  
### Analysis of autocorrelation times in Neural Markov Chain Monte Carlo simulations. (arXiv:2111.10189v2 [cond-mat.stat-mech] UPDATED)
- Authors : Piotr Bia, Piotr Korcyl, Tomasz Stebel
- Link : [http://arxiv.org/abs/2111.10189](http://arxiv.org/abs/2111.10189)
> ABSTRACT  :  We provide a deepened study of autocorrelations in Neural Markov Chain Monte Carlo simulations, a version of the traditional Metropolis algorithm which employs neural networks to provide independent proposals. We illustrate our ideas using the two-dimensional Ising model. We propose several estimates of autocorrelation times, some inspired by analytical results derived for the Metropolized Independent Sampler, which we compare and study as a function of inverse temperature $\beta$. Based on that we propose an alternative loss function and study its impact on the autocorelation times. Furthermore, we investigate the impact of imposing system symmetries ($Z_2$ and/or translational) in the neural network training process on the autocorrelation times. Eventually, we propose a scheme which incorporates partial heat-bath updates. The impact of the above **enhancement**s is discussed for a $16 \times 16$ spin system. The summary of our findings may serve as a guide to the implementation of Neural Markov Chain Monte Carlo simulations of more complicated models.  
## cs.AI
---
### Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
- Authors : Anindya Mondal, Mayukhmali Das
- Link : [http://arxiv.org/abs/2109.01879](http://arxiv.org/abs/2109.01879)
> ABSTRACT  :  Moving object detection is important in computer vision. Event-based cameras are bio-inspired cameras that work by mimicking the working of the human eye. These cameras have multiple advantages over conventional frame-based cameras, like reduced latency, **HDR**, reduced motion blur during high motion, low power consumption, etc. In spite of these advantages, event-based cameras are noise-sensitive and have low resolution. Moreover, the task of moving object detection in these cameras is difficult, as event-based sensors lack useful visual features like texture and color. In this paper, we investigate the application of the k-means clustering technique in detecting moving objects in event-based data.  
# Paper List
---
## cs.CV
---
**60** new papers in cs.CV:-) 
1. Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and Neck Tumor Segmentation and Outcome Prediction in PET/CT Images. (arXiv:2201.04138v1 [eess.IV])
2. HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning. (arXiv:2201.04182v1 [cs.LG])
3. Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics. (arXiv:2201.04194v1 [cs.LG])
4. MDPose: Human Skeletal Motion Reconstruction Using WiFi Micro-Doppler Signatures. (arXiv:2201.04212v1 [cs.CV])
5. Region-based Layout Analysis of Music Score Images. (arXiv:2201.04214v1 [cs.CV])
6. Brain Signals Analysis Based Deep Learning Methods: Recent advances in the study of non-invasive brain signals. (arXiv:2201.04229v1 [q-bio.NC])
7. SmartDet: Context-Aware Dynamic Control of Edge Task Offloading for Mobile Object Detection. (arXiv:2201.04235v1 [cs.DC])
8. Incidents1M: a large-scale dataset of images with natural disasters, damage, and incidents. (arXiv:2201.04236v1 [cs.CV])
9. Dynamical Audio-Visual Navigation: Catching Unheard Moving Sound Sources in Unmapped 3D Environments. (arXiv:2201.04279v1 [cs.CV])
10. Multiview Transformers for Video Recognition. (arXiv:2201.04288v1 [cs.CV])
11. Robust Contrastive Learning against Noisy Views. (arXiv:2201.04309v1 [cs.CV])
12. Knee Cartilage Defect Assessment by Graph Representation and Surface Convolution. (arXiv:2201.04318v1 [eess.IV])
13. Neural Residual Flow Fields for Efficient Video Representations. (arXiv:2201.04329v1 [cs.CV])
14. MDS-Net: A Multi-scale Depth Stratification Based Monocular 3D Object Detection Algorithm. (arXiv:2201.04341v1 [cs.CV])
15. Coarse-to-Fine Embedded PatchMatch and Multi-Scale Dynamic Aggregation for Reference-based Super-Resolution. (arXiv:2201.04358v1 [cs.CV])
16. SCSNet: An Efficient Paradigm for Learning Simultaneously Image Colorization and Super-Resolution. (arXiv:2201.04364v1 [cs.CV])
17. Predicting Alzheimer's Disease Using 3DMgNet. (arXiv:2201.04370v1 [eess.IV])
18. Maximizing Self-supervision from Thermal Image for Effective Self-supervised Learning of Depth and Ego-motion. (arXiv:2201.04387v1 [cs.RO])
19. OCSampler: Compressing Videos to One Clip with Single-step Sampling. (arXiv:2201.04388v1 [cs.CV])
20. Towards Adversarially Robust Deep Image Denoising. (arXiv:2201.04397v1 [eess.IV])
21. MoViDNN: A Mobile Platform for Evaluating Video Quality **Enhancement** with Deep Neural Networks. (arXiv:2201.04402v1 [cs.CV])
22. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v1 [eess.IV])
23. Beyond the Visible: A Survey on Cross-spectral Face Recognition. (arXiv:2201.04435v1 [cs.CV])
24. Real-Time Style Modelling of Human Locomotion via Feature-Wise Transformations and Local Motion Phases. (arXiv:2201.04439v1 [cs.GR])
25. Globally Optimal Multi-Scale Monocular Hand-Eye Calibration Using Dual Quaternions. (arXiv:2201.04473v1 [cs.RO])
26. Depth Estimation from Single-shot Monocular Endoscope Image Using Image Domain Adaptation And Edge-Aware Depth Estimation. (arXiv:2201.04485v1 [eess.IV])
27. SensatUrban: Learning Semantics from Urban-Scale Photogrammetric Point Clouds. (arXiv:2201.04494v1 [cs.CV])
28. Structure and position-aware graph neural network for airway labeling. (arXiv:2201.04532v1 [cs.CV])
29. Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data. (arXiv:2201.04569v1 [cs.CR])
30. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v1 [eess.IV])
31. Sparsely Annotated Object Detection: A Region-based Semi-supervised Approach. (arXiv:2201.04620v1 [cs.CV])
32. Virtual Elastic Objects. (arXiv:2201.04623v1 [cs.CV])
33. Online Continual Learning under Extreme Memory Constraints. (arXiv:2008.01510v3 [cs.CV] UPDATED)
34. MED-TEX: Transferring and Explaining Knowledge with Less Data from Pretrained Medical Imaging Models. (arXiv:2008.02593v3 [cs.CV] UPDATED)
35. MobileSal: Extremely Efficient RGB-D Salient Object Detection. (arXiv:2012.13095v3 [cs.CV] UPDATED)
36. ProxyFAUG: Proximity-based Fingerprint Augmentation. (arXiv:2102.02706v2 [cs.CV] UPDATED)
37. CharacterGAN: Few-Shot Keypoint Character Animation and Reposing. (arXiv:2102.03141v3 [cs.CV] UPDATED)
38. Bayesian imaging using Plug & Play priors: when Langevin meets Tweedie. (arXiv:2103.04715v6 [stat.ME] UPDATED)
39. Learning Domain Invariant Representations for Generalizable Person Re-Identification. (arXiv:2103.15890v3 [cs.CV] UPDATED)
40. Skin3D: Detection and Longitudinal Tracking of Pigmented Skin Lesions in 3D Total-Body Textured Meshes. (arXiv:2105.00374v2 [cs.CV] UPDATED)
41. KVT: k-NN Attention for Boosting Vision Transformers. (arXiv:2106.00515v2 [cs.CV] UPDATED)
42. SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v9 [math.OC] UPDATED)
43. CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects. (arXiv:2108.07368v2 [cs.CV] UPDATED)
44. Deep MRI Reconstruction with Radial Subsampling. (arXiv:2108.07619v3 [eess.IV] UPDATED)
45. Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
46. Self-supervised Product Quantization for Deep Unsupervised Image Retrieval. (arXiv:2109.02244v2 [cs.CV] UPDATED)
47. Scaled ReLU Matters for Training Vision Transformers. (arXiv:2109.03810v2 [cs.CV] UPDATED)
48. IFBiD: Inference-Free Bias Detection. (arXiv:2109.04374v3 [cs.CV] UPDATED)
49. ARKitScenes: A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data. (arXiv:2111.08897v3 [cs.CV] UPDATED)
50. Using Convolutional Neural Networks to Detect Compression Algorithms. (arXiv:2111.09034v2 [cs.CV] UPDATED)
51. Confidence Propagation Cluster: Unleash Full Potential of Object Detectors. (arXiv:2112.00342v3 [cs.CV] UPDATED)
52. HHF: Hashing-guided Hinge Function for Deep Hashing Retrieval. (arXiv:2112.02225v2 [cs.CV] UPDATED)
53. Encouraging Disentangled and Convex Representation with Controllable Interpolation Regularization. (arXiv:2112.03163v2 [cs.CV] UPDATED)
54. Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain. (arXiv:2112.04684v2 [cs.RO] UPDATED)
55. Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity. (arXiv:2112.05883v3 [cs.CV] UPDATED)
56. EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object Detection. (arXiv:2112.11088v3 [cs.CV] UPDATED)
57. The cluster structure function. (arXiv:2201.01222v2 [cs.LG] UPDATED)
58. Effect of Prior-based Losses on Segmentation Performance: A Benchmark. (arXiv:2201.02428v4 [eess.IV] UPDATED)
59. Vision in adverse weather: Augmentation using CycleGANs with various object detectors for robust perception in autonomous racing. (arXiv:2201.03246v2 [cs.CV] UPDATED)
60. Similarity-based Gray-box Adversarial Attack Against Deep Face Recognition. (arXiv:2201.04011v2 [cs.CV] UPDATED)
## eess.IV
---
**16** new papers in eess.IV:-) 
1. Overview of the HECKTOR Challenge at MICCAI 2021: Automatic Head and Neck Tumor Segmentation and Outcome Prediction in PET/CT Images. (arXiv:2201.04138v1 [eess.IV])
2. De-Noising of Photoacoustic Microscopy Images by Deep Learning. (arXiv:2201.04302v1 [eess.IV])
3. Knee Cartilage Defect Assessment by Graph Representation and Surface Convolution. (arXiv:2201.04318v1 [eess.IV])
4. ALTRUIST: Alternating Direction Method of Multipliers for Total Variation Regularization in Ultrasound Strain Imaging. (arXiv:2201.04363v1 [eess.IV])
5. Predicting Alzheimer's Disease Using 3DMgNet. (arXiv:2201.04370v1 [eess.IV])
6. Towards Adversarially Robust Deep Image Denoising. (arXiv:2201.04397v1 [eess.IV])
7. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v1 [eess.IV])
8. Depth Estimation from Single-shot Monocular Endoscope Image Using Image Domain Adaptation And Edge-Aware Depth Estimation. (arXiv:2201.04485v1 [eess.IV])
9. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v1 [eess.IV])
10. MED-TEX: Transferring and Explaining Knowledge with Less Data from Pretrained Medical Imaging Models. (arXiv:2008.02593v3 [cs.CV] UPDATED)
11. ProxyFAUG: Proximity-based Fingerprint Augmentation. (arXiv:2102.02706v2 [cs.CV] UPDATED)
12. Bayesian imaging using Plug & Play priors: when Langevin meets Tweedie. (arXiv:2103.04715v6 [stat.ME] UPDATED)
13. CaraNet: Context Axial Reverse Attention Network for Segmentation of Small Medical Objects. (arXiv:2108.07368v2 [cs.CV] UPDATED)
14. Deep MRI Reconstruction with Radial Subsampling. (arXiv:2108.07619v3 [eess.IV] UPDATED)
15. Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
16. Effect of Prior-based Losses on Segmentation Performance: A Benchmark. (arXiv:2201.02428v4 [eess.IV] UPDATED)
## cs.LG
---
**82** new papers in cs.LG:-) 
1. Learning Robust Policies for Generalized Debris Capture with an Automated Tether-Net System. (arXiv:2201.04180v1 [cs.RO])
2. HyperTransformer: Model Generation for Supervised and Semi-Supervised Few-Shot Learning. (arXiv:2201.04182v1 [cs.LG])
3. Dynamic Price of Parking Service based on Deep Learning. (arXiv:2201.04188v1 [cs.LG])
4. Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics. (arXiv:2201.04194v1 [cs.LG])
5. The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence. (arXiv:2201.04200v1 [econ.GN])
6. Fighting Money-Laundering with Statistics and Machine Learning: An Introduction and Review. (arXiv:2201.04207v1 [stat.ML])
7. A Feature Extraction based Model for Hate Speech Identification. (arXiv:2201.04227v1 [cs.CL])
8. Brain Signals Analysis Based Deep Learning Methods: Recent advances in the study of non-invasive brain signals. (arXiv:2201.04229v1 [q-bio.NC])
9. Leveraging Unlabeled Data to Predict Out-of-Distribution Performance. (arXiv:2201.04234v1 [cs.LG])
10. SmartDet: Context-Aware Dynamic Control of Edge Task Offloading for Mobile Object Detection. (arXiv:2201.04235v1 [cs.DC])
11. Two Wrongs Can Make a Right: A Transfer Learning Approach for Chemical Discovery with Chemical Accuracy. (arXiv:2201.04243v1 [physics.chem-ph])
12. Dynamical Audio-Visual Navigation: Catching Unheard Moving Sound Sources in Unmapped 3D Environments. (arXiv:2201.04279v1 [cs.CV])
13. Evolutionary Action Selection for Gradient-based Policy Learning. (arXiv:2201.04286v1 [cs.NE])
14. Multiview Transformers for Video Recognition. (arXiv:2201.04288v1 [cs.CV])
15. Predicting Terrorist Attacks in the United States using Localized News Data. (arXiv:2201.04292v1 [cs.LG])
16. Adaptive Worker Grouping For Communication-Efficient and Straggler-Tolerant Distributed SGD. (arXiv:2201.04301v1 [cs.IT])
17. De-Noising of Photoacoustic Microscopy Images by Deep Learning. (arXiv:2201.04302v1 [eess.IV])
18. Robust Contrastive Learning against Noisy Views. (arXiv:2201.04309v1 [cs.CV])
19. On the Statistical Complexity of Sample Amplification. (arXiv:2201.04315v1 [math.ST])
20. An Efficient and Adaptive Granular-ball Generation Method in Classification Problem. (arXiv:2201.04343v1 [cs.LG])
21. Preventing Manifold Intrusion with Locality: Local Mixup. (arXiv:2201.04368v1 [cs.LG])
22. Predicting Alzheimer's Disease Using 3DMgNet. (arXiv:2201.04370v1 [eess.IV])
23. Towards Adversarially Robust Deep Image Denoising. (arXiv:2201.04397v1 [eess.IV])
24. RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems. (arXiv:2201.04399v1 [cs.IR])
25. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v1 [eess.IV])
26. Detecting Ransomware Execution in a Timely Manner. (arXiv:2201.04424v1 [cs.CR])
27. Careful! Training Relevance is Real. (arXiv:2201.04429v1 [cs.LG])
28. Multi-task Joint Strategies of Self-supervised Representation Learning on Biomedical Networks for Drug Discovery. (arXiv:2201.04437v1 [cs.LG])
29. Real-Time Style Modelling of Human Locomotion via Feature-Wise Transformations and Local Motion Phases. (arXiv:2201.04439v1 [cs.GR])
30. Intra-domain and cross-domain transfer learning for time series data -- How transferable are the features?. (arXiv:2201.04449v1 [cs.LG])
31. SLISEMAP: Explainable Dimensionality Reduction. (arXiv:2201.04455v1 [cs.LG])
32. Blackbox Post-Processing for Multiclass Fairness. (arXiv:2201.04461v1 [cs.LG])
33. Optimal Fixed-Budget Best Arm Identification using the Augmented Inverse Probability Estimator in Two-Armed Gaussian Bandits with Unknown Variances. (arXiv:2201.04469v1 [stat.ML])
34. Learning to Identify Top Elo Ratings: A Dueling Bandits Approach. (arXiv:2201.04480v1 [cs.LG])
35. Smoothness and continuity of cost functionals for ECG mismatch computation. (arXiv:2201.04487v1 [physics.med-ph])
36. Dyna-T: Dyna-Q and Upper Confidence Bounds Applied to Trees. (arXiv:2201.04502v1 [cs.LG])
37. Exact learning and test theory. (arXiv:2201.04506v1 [cs.CC])
38. Eigenvalue Distribution of Large Random Matrices Arising in Deep Neural Networks: Orthogonal Case. (arXiv:2201.04543v1 [stat.ML])
39. On generalization bounds for deep networks based on loss surface implicit regularization. (arXiv:2201.04545v1 [stat.ML])
40. ECONet: Efficient Convolutional Online Likelihood Network for Scribble-based Interactive Segmentation. (arXiv:2201.04584v1 [eess.IV])
41. Deep Symbolic Regression for Recurrent Sequences. (arXiv:2201.04600v1 [cs.LG])
42. Fine-grained Graph Learning for Multi-view Subspace Clustering. (arXiv:2201.04604v1 [cs.LG])
43. GraphVAMPNet, using graph neural networks and variational approach to markov processes for dynamical modeling of biomolecules. (arXiv:2201.04609v1 [physics.comp-ph])
44. Agent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent Reinforcement Learning. (arXiv:2201.04612v1 [cs.MA])
45. Interacting with Explanations through Critiquing. (arXiv:2005.11067v4 [cs.CL] UPDATED)
46. Improving Disentangled Text Representation Learning with Information-Theoretic Guidance. (arXiv:2006.00693v3 [cs.LG] UPDATED)
47. Online Continual Learning under Extreme Memory Constraints. (arXiv:2008.01510v3 [cs.CV] UPDATED)
48. MED-TEX: Transferring and Explaining Knowledge with Less Data from Pretrained Medical Imaging Models. (arXiv:2008.02593v3 [cs.CV] UPDATED)
49. Extensions to the Proximal Distance Method of Constrained Optimization. (arXiv:2009.00801v2 [math.OC] UPDATED)
50. Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data. (arXiv:2012.02334v5 [cs.LG] UPDATED)
51. Flexible, Non-parametric Modeling Using Regularized Neural Networks. (arXiv:2012.11369v3 [cs.LG] UPDATED)
52. Center Smoothing: Certified Robustness for Networks with Structured Outputs. (arXiv:2102.09701v3 [cs.LG] UPDATED)
53. On Calibration and Out-of-domain Generalization. (arXiv:2102.10395v4 [cs.LG] UPDATED)
54. Efficient and Interpretable Robot Manipulation with Graph Neural Networks. (arXiv:2102.13177v4 [cs.RO] UPDATED)
55. A semi-agnostic ansatz with variable structure for quantum machine learning. (arXiv:2103.06712v2 [quant-ph] UPDATED)
56. Learning Domain Invariant Representations for Generalizable Person Re-Identification. (arXiv:2103.15890v3 [cs.CV] UPDATED)
57. Skin3D: Detection and Longitudinal Tracking of Pigmented Skin Lesions in 3D Total-Body Textured Meshes. (arXiv:2105.00374v2 [cs.CV] UPDATED)
58. Embedding Principle of Loss Landscape of Deep Neural Networks. (arXiv:2105.14573v3 [cs.LG] UPDATED)
59. Who Is the Strongest Enemy? Towards Optimal and Efficient Evasion Attacks in Deep RL. (arXiv:2106.05087v3 [cs.LG] UPDATED)
60. SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients. (arXiv:2106.08208v9 [math.OC] UPDATED)
61. UniTTS: Residual Learning of Unified Embedding Space for Speech Style Control. (arXiv:2106.11171v2 [eess.AS] UPDATED)
62. Test for non-negligible adverse shifts. (arXiv:2107.02990v3 [stat.ML] UPDATED)
63. Entity-Based Knowledge Conflicts in Question Answering. (arXiv:2109.05052v2 [cs.CL] UPDATED)
64. Testing Self-Organized Criticality Across the Main Sequence using Stellar Flares from TESS. (arXiv:2109.07011v2 [astro-ph.SR] UPDATED)
65. Game Theory for Adversarial Attacks and Defenses. (arXiv:2110.06166v3 [cs.LG] UPDATED)
66. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v2 [cs.LG] UPDATED)
67. Holistic Deep Learning. (arXiv:2110.15829v2 [cs.LG] UPDATED)
68. Curriculum Offline Imitation Learning. (arXiv:2111.02056v2 [cs.LG] UPDATED)
69. On Training Implicit Models. (arXiv:2111.05177v4 [cs.LG] UPDATED)
70. Analysis of autocorrelation times in Neural Markov Chain Monte Carlo simulations. (arXiv:2111.10189v2 [cond-mat.stat-mech] UPDATED)
71. Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain. (arXiv:2112.04684v2 [cs.RO] UPDATED)
72. Self-supervised Spatiotemporal Representation Learning by Exploiting Video Continuity. (arXiv:2112.05883v3 [cs.CV] UPDATED)
73. Zero-shot Audio Source Separation through Query-based Learning from Weakly-labeled Data. (arXiv:2112.07891v3 [cs.SD] UPDATED)
74. ColO-RAN: Developing Machine Learning-based xApps for Open RAN Closed-loop Control on Programmable Experimental Platforms. (arXiv:2112.09559v2 [cs.NI] UPDATED)
75. Manifold learning via quantum dynamics. (arXiv:2112.11161v2 [quant-ph] UPDATED)
76. An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation. (arXiv:2201.00436v2 [cs.LG] UPDATED)
77. CEMENT: Incomplete Multi-View Weak-Label Learning with Long-Tailed Labels. (arXiv:2201.01079v3 [cs.LG] UPDATED)
78. The cluster structure function. (arXiv:2201.01222v2 [cs.LG] UPDATED)
79. Improved Input Reprogramming for GAN Conditioning. (arXiv:2201.02692v2 [cs.LG] UPDATED)
80. A Physics-Informed Vector Quantized Autoencoder for Data Compression of Turbulent Flow. (arXiv:2201.03617v2 [physics.flu-dyn] UPDATED)
81. FairEdit: Preserving Fairness in Graph Neural Networks through Greedy Graph Editing. (arXiv:2201.03681v2 [cs.LG] UPDATED)
82. Application of Common Spatial Patterns in Gravitational Waves Detection. (arXiv:2201.04086v1 [gr-qc] CROSS LISTED)
## cs.AI
---
**37** new papers in cs.AI:-) 
1. A Survey on Applications of Digital Human Avatars toward Virtual Co-presence. (arXiv:2201.04168v1 [cs.HC])
2. Learning Robust Policies for Generalized Debris Capture with an Automated Tether-Net System. (arXiv:2201.04180v1 [cs.RO])
3. Dynamic Price of Parking Service based on Deep Learning. (arXiv:2201.04188v1 [cs.LG])
4. Neural Capacitance: A New Perspective of Neural Network Selection via Edge Dynamics. (arXiv:2201.04194v1 [cs.LG])
5. The Turing Trap: The Promise & Peril of Human-Like Artificial Intelligence. (arXiv:2201.04200v1 [econ.GN])
6. Subgoal-Based Explanations for Unreliable Intelligent Decision Support Systems. (arXiv:2201.04204v1 [cs.AI])
7. Benchmarking Deep Reinforcement Learning Algorithms for Vision-based Robotics. (arXiv:2201.04224v1 [cs.RO])
8. A Feature Extraction based Model for Hate Speech Identification. (arXiv:2201.04227v1 [cs.CL])
9. Brain Signals Analysis Based Deep Learning Methods: Recent advances in the study of non-invasive brain signals. (arXiv:2201.04229v1 [q-bio.NC])
10. Safe Equilibrium. (arXiv:2201.04266v1 [cs.GT])
11. Video Intelligence as a component of a Global Security system. (arXiv:2201.04349v1 [cs.AI])
12. RGRecSys: A Toolkit for Robustness Evaluation of Recommender Systems. (arXiv:2201.04399v1 [cs.IR])
13. GateFormer: Speeding Up News Feed Recommendation with Input Gated Transformers. (arXiv:2201.04406v1 [cs.IR])
14. Multi-task Joint Strategies of Self-supervised Representation Learning on Biomedical Networks for Drug Discovery. (arXiv:2201.04437v1 [cs.LG])
15. Real-Time Style Modelling of Human Locomotion via Feature-Wise Transformations and Local Motion Phases. (arXiv:2201.04439v1 [cs.GR])
16. SLISEMAP: Explainable Dimensionality Reduction. (arXiv:2201.04455v1 [cs.LG])
17. Blackbox Post-Processing for Multiclass Fairness. (arXiv:2201.04461v1 [cs.LG])
18. DPCL: a Language Template for Normative Specifications. (arXiv:2201.04477v1 [cs.AI])
19. Dyna-T: Dyna-Q and Upper Confidence Bounds Applied to Trees. (arXiv:2201.04502v1 [cs.LG])
20. Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data. (arXiv:2201.04569v1 [cs.CR])
21. MeTeoR: Practical Reasoning in Datalog with Metric Temporal Operators. (arXiv:2201.04596v1 [cs.AI])
22. Agent-Temporal Attention for Reward Redistribution in Episodic Multi-Agent Reinforcement Learning. (arXiv:2201.04612v1 [cs.MA])
23. Minimizing Robot Navigation-Graph For Position-Based Predictability By Humans. (arXiv:2010.15255v2 [cs.AI] UPDATED)
24. Benchmarking Energy-Conserving Neural Networks for Learning Dynamics from Data. (arXiv:2012.02334v5 [cs.LG] UPDATED)
25. UniTTS: Residual Learning of Unified Embedding Space for Speech Style Control. (arXiv:2106.11171v2 [eess.AS] UPDATED)
26. Moving Object Detection for Event-based Vision using k-means Clustering. (arXiv:2109.01879v4 [cs.CV] UPDATED)
27. Interpretable Directed Diversity: Leveraging Model Explanations for Iterative Crowd Ideation. (arXiv:2109.10149v2 [cs.HC] UPDATED)
28. Non-Parametric Neuro-Adaptive Coordination of Multi-Agent Systems. (arXiv:2110.05125v2 [eess.SY] UPDATED)
29. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v2 [cs.LG] UPDATED)
30. Holistic Deep Learning. (arXiv:2110.15829v2 [cs.LG] UPDATED)
31. Curriculum Offline Imitation Learning. (arXiv:2111.02056v2 [cs.LG] UPDATED)
32. ARKitScenes: A Diverse Real-World Dataset For 3D Indoor Scene Understanding Using Mobile RGB-D Data. (arXiv:2111.08897v3 [cs.CV] UPDATED)
33. Zero-shot Audio Source Separation through Query-based Learning from Weakly-labeled Data. (arXiv:2112.07891v3 [cs.SD] UPDATED)
34. A Survey on Hyperdimensional Computing aka Vector Symbolic Architectures, Part II: Applications, Cognitive Models, and Challenges. (arXiv:2112.15424v2 [cs.AI] UPDATED)
35. An Efficient and Accurate Rough Set for Feature Selection, Classification and Knowledge Representation. (arXiv:2201.00436v2 [cs.LG] UPDATED)
36. Effect of Prior-based Losses on Segmentation Performance: A Benchmark. (arXiv:2201.02428v4 [eess.IV] UPDATED)
37. Improved Input Reprogramming for GAN Conditioning. (arXiv:2201.02692v2 [cs.LG] UPDATED)
