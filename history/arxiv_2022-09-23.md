# Your interest papers
---
## cs.CV
---
### Convolutional Bayesian Kernel Inference for 3D Semantic Mapping. (arXiv:2209.10663v1 [cs.RO])
- Authors : Joey Wilson, Yuewei Fu, Arthur Zhang, Jingyu Song, Andrew Capodieci, Paramsothy Jayakumar, Kira Barton, Maani Ghaffari
- Link : [http://arxiv.org/abs/2209.10663](http://arxiv.org/abs/2209.10663)
> ABSTRACT  :  Robotic perception is currently at a cross-roads between modern methods which operate in an efficient latent space, and classical methods which are mathematically founded and provide interpretable, trustworthy results. In this paper, we introduce a Convolutional Bayesian Kernel Inference (ConvBKI) layer which explicitly performs Bayesian inference within a depthwise separable convolution layer to simultaneously maximize efficiency while maintaining reliability. We apply our layer to the task of 3D semantic mapping, where we learn semantic-geometric probability distributions for LiDAR sensor information in **real time**. We evaluate our network against state-of-the-art semantic mapping algorithms on the KITTI data set, and demonstrate improved latency with comparable semantic results.  
### xView3-SAR: Detecting **Dark** Fishing Activity Using Synthetic Aperture Radar Imagery. (arXiv:2206.00897v3 [cs.CV] UPDATED)
- Authors : Fernando Paolo, ting Tim, Ritwik Gupta, Bryce Goodman, Nirav Patel, Daniel Kuster, David Kroodsma, Jared Dunnmon
- Link : [http://arxiv.org/abs/2206.00897](http://arxiv.org/abs/2206.00897)
> ABSTRACT  :  Unsustainable fishing practices worldwide pose a major threat to marine resources and ecosystems. Identifying vessels that do not show up in conventional monitoring systems -- known as "**dark** vessels" -- is key to managing and securing the health of marine environments. With the rise of satellite-based synthetic aperture radar (SAR) imaging and modern machine learning (ML), it is now possible to automate detection of **dark** vessels day or **night**, under all-weather conditions. SAR images, however, require a domain-specific treatment and are not widely accessible to the ML community. Maritime objects (vessels and offshore infrastructure) are relatively small and sparse, challenging traditional computer vision approaches. We present the largest labeled dataset for training ML models to detect and characterize vessels and ocean structures in SAR imagery. xView3-SAR consists of nearly 1,000 analysis-ready SAR images from the Sentinel-1 mission that are, on average, 29,400-by-24,400 pixels each. The images are annotated using a combination of automated and manual analysis. Co-located bathymetry and wind state rasters accompany every SAR image. We also provide an overview of the xView3 Computer Vision Challenge, an international competition using xView3-SAR for ship detection and characterization at large scale. We release the data at https://iuu.xview.us and code at https://github.com/DIUx-xView to support ongoing development and evaluation of ML approaches for this important application.  
### Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
- Authors : Sanskriti Singh
- Link : [http://arxiv.org/abs/2206.10455](http://arxiv.org/abs/2206.10455)
> ABSTRACT  :  Every year, thousands of innocent people die due to heart attacks. Often undiagnosed heart attacks can hit people by surprise since many current medical plans don't cover the costs to require the searching of calcification on these scans. Only if someone is suspected to have a heart problem, a gated CT scan is taken, otherwise, there's no way for the patient to be aware of a possible heart attack/disease. While nongated CT scans are more periodically taken, it is harder to detect calcification and is usually taken for a purpose other than locating calcification in arteries. In fact, in **real time** coronary artery calcification scores are only calculated on gated CT scans, not nongated CT scans. After training a unet model on the Coronary Calcium and chest CT's gated scans, it received a DICE coefficient of 0.95 on its untouched test set. This model was used to predict on nongated CT scans, performing with a mean absolute error (MAE) of 674.19 and bucket classification accuracy of 41% (5 classes). Through the analysis of the images and the information stored in the images, mathematical equations were derived and used to automatically crop the images around the location of the heart. By performing semi-supervised learning the new cropped nongated scans were able to closely resemble gated CT scans, improving the performance by 91% in MAE (62.38) and 23% in accuracy.  
### Perceptual Quality Assessment for Digital Human Heads. (arXiv:2209.09489v2 [cs.CV] UPDATED)
- Authors : Zicheng Zhang, Yingjie Zhou, Wei Sun, Xiongkuo Min, Guangtao Zhai
- Link : [http://arxiv.org/abs/2209.09489](http://arxiv.org/abs/2209.09489)
> ABSTRACT  :  Digital humans are attracting more and more research interest during the last decade, the generation, representation, rendering, and animation of which have been put into large amounts of effort. However, the quality assessment of digital humans has fallen behind. Therefore, to tackle the challenge of digital human quality assessment issues, we propose the first large-scale quality assessment database for three-dimensional (3D) scanned digital human heads (DHHs). The constructed database consists of 55 reference DHHs and 1,540 distorted DHHs along with the subjective perceptual ratings. Then, a simple yet effective full-reference (FR) projection-based method is proposed to evaluate the visual quality of DHHs. The pretrained **Swin** Transformer tiny is employed for hierarchical feature extraction and the multi-head attention module is utilized for feature fusion. The experimental results reveal that the proposed method exhibits state-of-the-art performance among the mainstream FR metrics, which can provide an effective FR-IQA index for DHHs.  
## eess.IV
---
### A Validation Approach to Over-parameterized Matrix and Image Recovery. (arXiv:2209.10675v1 [math.OC])
- Authors : Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu
- Link : [http://arxiv.org/abs/2209.10675](http://arxiv.org/abs/2209.10675)
> ABSTRACT  :  In this paper, we study the problem of recovering a low-rank matrix from a number of noisy random linear measurements. We consider the setting where the rank of the ground-truth matrix is unknown a prior and use an overspecified factored representation of the matrix variable, where the global optimal solutions overfit and do not correspond to the underlying ground-truth. We then solve the associated nonconvex problem using gradient descent with small random initialization. We show that as long as the measurement operators satisfy the restricted isometry property (RIP) with its rank parameter scaling with the rank of ground-truth matrix rather than scaling with the overspecified matrix variable, gradient descent iterations are on a particular trajectory towards the ground-truth matrix and achieve nearly information-theoretically optimal recovery when stop appropriately. We then propose an efficient early stopping strategy based on the common hold-out method and show that it detects nearly optimal estimator provably. Moreover, experiments show that the proposed validation approach can also be efficiently used for image **restoration** with deep image prior which over-parameterizes an image with a deep network.  
### Compressing Sign Information in DCT-based Image Coding via Deep Sign Retrieval. (arXiv:2209.10712v1 [cs.IT])
- Authors : Kei Suzuki, Chihiro Tsutake, Keita Takahashi, Toshiaki Fujii
- Link : [http://arxiv.org/abs/2209.10712](http://arxiv.org/abs/2209.10712)
> ABSTRACT  :  Compressing the sign information of discrete cosine transform (DCT) coefficients is an intractable problem in image coding schemes due to the equiprobable characteristics of the signs. To overcome this difficulty, we propose an efficient compression method for the sign information called "sign retrieval." This method is inspired by phase retrieval, which is a classical signal **restoration** problem of finding the phase information of discrete Fourier transform coefficients from their magnitudes. The sign information of all DCT coefficients is excluded from a bitstream at the encoder and is complemented at the decoder through our sign retrieval method. We show through experiments that our method outperforms previous ones in terms of the bit amount for the signs and computation cost. Our method, implemented in Python language, is available from https://github.com/ctsutake/dsr.  
### Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
- Authors : Sanskriti Singh
- Link : [http://arxiv.org/abs/2206.10455](http://arxiv.org/abs/2206.10455)
> ABSTRACT  :  Every year, thousands of innocent people die due to heart attacks. Often undiagnosed heart attacks can hit people by surprise since many current medical plans don't cover the costs to require the searching of calcification on these scans. Only if someone is suspected to have a heart problem, a gated CT scan is taken, otherwise, there's no way for the patient to be aware of a possible heart attack/disease. While nongated CT scans are more periodically taken, it is harder to detect calcification and is usually taken for a purpose other than locating calcification in arteries. In fact, in **real time** coronary artery calcification scores are only calculated on gated CT scans, not nongated CT scans. After training a unet model on the Coronary Calcium and chest CT's gated scans, it received a DICE coefficient of 0.95 on its untouched test set. This model was used to predict on nongated CT scans, performing with a mean absolute error (MAE) of 674.19 and bucket classification accuracy of 41% (5 classes). Through the analysis of the images and the information stored in the images, mathematical equations were derived and used to automatically crop the images around the location of the heart. By performing semi-supervised learning the new cropped nongated scans were able to closely resemble gated CT scans, improving the performance by 91% in MAE (62.38) and 23% in accuracy.  
### Perceptual Quality Assessment for Digital Human Heads. (arXiv:2209.09489v2 [cs.CV] UPDATED)
- Authors : Zicheng Zhang, Yingjie Zhou, Wei Sun, Xiongkuo Min, Guangtao Zhai
- Link : [http://arxiv.org/abs/2209.09489](http://arxiv.org/abs/2209.09489)
> ABSTRACT  :  Digital humans are attracting more and more research interest during the last decade, the generation, representation, rendering, and animation of which have been put into large amounts of effort. However, the quality assessment of digital humans has fallen behind. Therefore, to tackle the challenge of digital human quality assessment issues, we propose the first large-scale quality assessment database for three-dimensional (3D) scanned digital human heads (DHHs). The constructed database consists of 55 reference DHHs and 1,540 distorted DHHs along with the subjective perceptual ratings. Then, a simple yet effective full-reference (FR) projection-based method is proposed to evaluate the visual quality of DHHs. The pretrained **Swin** Transformer tiny is employed for hierarchical feature extraction and the multi-head attention module is utilized for feature fusion. The experimental results reveal that the proposed method exhibits state-of-the-art performance among the mainstream FR metrics, which can provide an effective FR-IQA index for DHHs.  
## cs.LG
---
### Benchmarking Apache Spark and Hadoop MapReduce on Big Data Classification. (arXiv:2209.10637v1 [cs.DC])
- Authors : Taha Tekdogan, Ali Cakmak
- Link : [http://arxiv.org/abs/2209.10637](http://arxiv.org/abs/2209.10637)
> ABSTRACT  :  Most of the popular Big Data analytics tools evolved to adapt their working environment to extract valuable information from a vast amount of unstructured data. The ability of data mining techniques to filter this helpful information from Big Data led to the term Big Data Mining. Shifting the scope of data from small-size, structured, and stable data to huge volume, unstructured, and quickly changing data brings many data management challenges. Different tools cope with these challenges in their own way due to their architectural limitations. There are numerous parameters to take into consideration when choosing the right data management framework based on the task at hand. In this paper, we present a comprehensive benchmark for two widely used Big Data analytics tools, namely Apache Spark and Hadoop MapReduce, on a common data mining task, i.e., classification. We employ several evaluation metrics to compare the performance of the benchmarked frameworks, such as execution time, accuracy, and scalability. These metrics are specialized to measure the performance for classification task. To the best of our knowledge, there is no previous study in the literature that employs all these metrics while taking into consideration task-specific concerns. We show that Spark is 5 times faster than MapReduce on training the model. Nevertheless, the performance of Spark degrades when the input workload gets larger. Scaling the environment by additional clusters significantly improves the performance of Spark. However, similar **enhancement** is not observed in Hadoop. Machine learning utility of MapReduce tend to have better accuracy scores than that of Spark, like around 3%, even in small size data sets.  
### A Validation Approach to Over-parameterized Matrix and Image Recovery. (arXiv:2209.10675v1 [math.OC])
- Authors : Lijun Ding, Zhen Qin, Liwei Jiang, Jinxin Zhou, Zhihui Zhu
- Link : [http://arxiv.org/abs/2209.10675](http://arxiv.org/abs/2209.10675)
> ABSTRACT  :  In this paper, we study the problem of recovering a low-rank matrix from a number of noisy random linear measurements. We consider the setting where the rank of the ground-truth matrix is unknown a prior and use an overspecified factored representation of the matrix variable, where the global optimal solutions overfit and do not correspond to the underlying ground-truth. We then solve the associated nonconvex problem using gradient descent with small random initialization. We show that as long as the measurement operators satisfy the restricted isometry property (RIP) with its rank parameter scaling with the rank of ground-truth matrix rather than scaling with the overspecified matrix variable, gradient descent iterations are on a particular trajectory towards the ground-truth matrix and achieve nearly information-theoretically optimal recovery when stop appropriately. We then propose an efficient early stopping strategy based on the common hold-out method and show that it detects nearly optimal estimator provably. Moreover, experiments show that the proposed validation approach can also be efficiently used for image **restoration** with deep image prior which over-parameterizes an image with a deep network.  
### CMGAN: Conformer-Based Metric-GAN for Monaural Speech **Enhancement**. (arXiv:2209.11112v1 [cs.SD])
- Authors : Sherif Abdulatif, Ruizhe Cao, Bin Yang
- Link : [http://arxiv.org/abs/2209.11112](http://arxiv.org/abs/2209.11112)
> ABSTRACT  :  Convolution-augmented transformers (Conformers) are recently proposed in various speech-domain applications, such as automatic speech recognition (ASR) and speech separation, as they can capture both local and global dependencies. In this paper, we propose a conformer-based metric generative adversarial network (CMGAN) for speech **enhancement** (SE) in the time-frequency (TF) domain. The generator encodes the magnitude and complex spectrogram information using two-stage conformer blocks to model both time and frequency dependencies. The decoder then decouples the estimation into a magnitude mask decoder branch to filter out unwanted distortions and a complex refinement branch to further improve the magnitude estimation and implicitly enhance the phase information. Additionally, we include a metric discriminator to alleviate metric mismatch by optimizing the generator with respect to a corresponding evaluation score. Objective and subjective evaluations illustrate that CMGAN is able to show superior performance compared to state-of-the-art methods in three speech **enhancement** tasks (denoising, dereverberation and super-resolution). For instance, quantitative denoising analysis on Voice Bank+DEMAND dataset indicates that CMGAN outperforms various previous models with a margin, i.e., PESQ of 3.41 and SSNR of 11.10 dB.  
### One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label **Enhancement**. (arXiv:2206.00517v2 [cs.LG] UPDATED)
- Authors : Ning Xu, Congyu Qiao, Jiaqi Lv, Xin Geng, Ling Zhang
- Link : [http://arxiv.org/abs/2206.00517](http://arxiv.org/abs/2206.00517)
> ABSTRACT  :  Multi-label learning (MLL) learns from the examples each associated with multiple labels simultaneously, where the high cost of annotating all relevant labels for each training example is challenging for real-world applications. To cope with the challenge, we investigate single-positive multi-label learning (SPMLL) where each example is annotated with only one relevant label and show that one can successfully learn a theoretically grounded multi-label classifier for the problem. In this paper, a novel SPMLL method named {\proposed}, i.e., Single-positive MultI-label learning with Label **Enhancement**, is proposed. Specifically, an unbiased risk estimator is derived, which could be guaranteed to approximately converge to the optimal risk minimizer of fully supervised learning and shows that one positive label of each instance is sufficient to train the predictive model. Then, the corresponding empirical risk estimator is established via recovering the latent soft label as a label **enhancement** process, where the posterior density of the latent soft labels is approximate to the variational Beta density parameterized by an inference model. Experiments on benchmark datasets validate the effectiveness of the proposed method.  
### Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
- Authors : Sanskriti Singh
- Link : [http://arxiv.org/abs/2206.10455](http://arxiv.org/abs/2206.10455)
> ABSTRACT  :  Every year, thousands of innocent people die due to heart attacks. Often undiagnosed heart attacks can hit people by surprise since many current medical plans don't cover the costs to require the searching of calcification on these scans. Only if someone is suspected to have a heart problem, a gated CT scan is taken, otherwise, there's no way for the patient to be aware of a possible heart attack/disease. While nongated CT scans are more periodically taken, it is harder to detect calcification and is usually taken for a purpose other than locating calcification in arteries. In fact, in **real time** coronary artery calcification scores are only calculated on gated CT scans, not nongated CT scans. After training a unet model on the Coronary Calcium and chest CT's gated scans, it received a DICE coefficient of 0.95 on its untouched test set. This model was used to predict on nongated CT scans, performing with a mean absolute error (MAE) of 674.19 and bucket classification accuracy of 41% (5 classes). Through the analysis of the images and the information stored in the images, mathematical equations were derived and used to automatically crop the images around the location of the heart. By performing semi-supervised learning the new cropped nongated scans were able to closely resemble gated CT scans, improving the performance by 91% in MAE (62.38) and 23% in accuracy.  
## cs.AI
---
### MnTTS: An Open-Source Mongolian Text-to-Speech Synthesis Dataset and Accompanied Baseline. (arXiv:2209.10848v1 [cs.SD])
- Authors : Yifan Hu, Pengkai Yin, Rui Liu, Feilong Bao, Guanglai Gao
- Link : [http://arxiv.org/abs/2209.10848](http://arxiv.org/abs/2209.10848)
> ABSTRACT  :  This paper introduces a high-quality open-source text-to-speech (TTS) synthesis dataset for Mongolian, a low-resource language spoken by over 10 million people worldwide. The dataset, named MnTTS, consists of about 8 hours of transcribed audio recordings spoken by a 22-year-old professional female Mongolian announcer. It is the first publicly available dataset developed to promote Mongolian TTS applications in both academia and industry. In this paper, we share our experience by describing the dataset development procedures and faced challenges. To demonstrate the reliability of our dataset, we built a powerful non-autoregressive baseline system based on FastSpeech2 model and HiFi-GAN vocoder, and evaluated it using the subjective mean opinion score (MOS) and **real time** factor (RTF) metrics. Evaluation results show that the powerful baseline system trained on our dataset achieves MOS above 4 and RTF about $3.30\times10^{-1}$, which makes it applicable for practical use. The dataset, training recipe, and pretrained TTS models are freely available \footnote{\label{github}\url{https://github.com/walker-hyf/MnTTS}}.  
### CMGAN: Conformer-Based Metric-GAN for Monaural Speech **Enhancement**. (arXiv:2209.11112v1 [cs.SD])
- Authors : Sherif Abdulatif, Ruizhe Cao, Bin Yang
- Link : [http://arxiv.org/abs/2209.11112](http://arxiv.org/abs/2209.11112)
> ABSTRACT  :  Convolution-augmented transformers (Conformers) are recently proposed in various speech-domain applications, such as automatic speech recognition (ASR) and speech separation, as they can capture both local and global dependencies. In this paper, we propose a conformer-based metric generative adversarial network (CMGAN) for speech **enhancement** (SE) in the time-frequency (TF) domain. The generator encodes the magnitude and complex spectrogram information using two-stage conformer blocks to model both time and frequency dependencies. The decoder then decouples the estimation into a magnitude mask decoder branch to filter out unwanted distortions and a complex refinement branch to further improve the magnitude estimation and implicitly enhance the phase information. Additionally, we include a metric discriminator to alleviate metric mismatch by optimizing the generator with respect to a corresponding evaluation score. Objective and subjective evaluations illustrate that CMGAN is able to show superior performance compared to state-of-the-art methods in three speech **enhancement** tasks (denoising, dereverberation and super-resolution). For instance, quantitative denoising analysis on Voice Bank+DEMAND dataset indicates that CMGAN outperforms various previous models with a margin, i.e., PESQ of 3.41 and SSNR of 11.10 dB.  
# Paper List
---
## cs.CV
---
**92** new papers in cs.CV:-) 
1. GNPM: Geometric-Aware Neural Parametric Models. (arXiv:2209.10621v1 [cs.CV])
2. An Image Processing approach to identify solar plages observed at 393.37 nm by Kodaikanal Solar Observatory. (arXiv:2209.10631v1 [astro-ph.SR])
3. Automated segmentation of intracranial hemorrhages from 3D CT. (arXiv:2209.10648v1 [eess.IV])
4. Convolutional Bayesian Kernel Inference for 3D Semantic Mapping. (arXiv:2209.10663v1 [cs.RO])
5. NashAE: Disentangling Representations through Adversarial Covariance Minimization. (arXiv:2209.10677v1 [cs.LG])
6. Attention Beats Concatenation for Conditioning Neural Fields. (arXiv:2209.10684v1 [cs.CV])
7. PREF: Predictability Regularized Neural Motion Fields. (arXiv:2209.10691v1 [cs.CV])
8. Stochastic Future Prediction in Real World Driving Scenarios. (arXiv:2209.10693v1 [cs.CV])
9. Self-adversarial Multi-scale Contrastive Learning for Semantic Segmentation of Thermal Facial Images. (arXiv:2209.10700v1 [cs.CV])
10. Fair Robust Active Learning by Joint Inconsistency. (arXiv:2209.10729v1 [cs.LG])
11. FusionRCNN: LiDAR-Camera Fusion for Two-stage 3D Object Detection. (arXiv:2209.10733v1 [cs.CV])
12. CCR: Facial Image Editing with Continuity, Consistency and Reversibility. (arXiv:2209.10734v1 [cs.CV])
13. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v1 [cs.CV])
14. Multi-level Adversarial Spatio-temporal Learning for Footstep Pressure based FoG Detection. (arXiv:2209.10770v1 [cs.CV])
15. Deep Lake: a Lakehouse for Deep Learning. (arXiv:2209.10785v1 [cs.DC])
16. A CT-Based Airway Segmentation Using U$^2$-net Trained by the Dice Loss Function. (arXiv:2209.10796v1 [eess.IV])
17. Automated head and neck tumor segmentation from 3D PET/CT. (arXiv:2209.10809v1 [eess.IV])
18. IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion. (arXiv:2209.10811v1 [cs.CV])
19. Color Recommendation for Vector Graphic Documents based on Multi-Palette Representation. (arXiv:2209.10820v1 [cs.CV])
20. Physical Interaction: Reconstructing Hand-object Interactions with Physics. (arXiv:2209.10833v1 [cs.CV])
21. A Spatial-channel-temporal-fused Attention for Spiking Neural Networks. (arXiv:2209.10837v1 [cs.CV])
22. High-order Multi-view Clustering for Generic Data. (arXiv:2209.10838v1 [cs.LG])
23. Detecting Rotated Objects as Gaussian Distributions and Its 3-D Generalization. (arXiv:2209.10839v1 [cs.CV])
24. Identity-Aware Hand Mesh Estimation and Personalization from RGB Images. (arXiv:2209.10840v1 [cs.CV])
25. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v1 [cs.CV])
26. Efficient CNN with uncorrelated Bag of Features pooling. (arXiv:2209.10865v1 [cs.CV])
27. Beyond Voxel Prediction Uncertainty: Identifying brain lesions you can trust. (arXiv:2209.10877v1 [eess.IV])
28. AcroFOD: An Adaptive Method for Cross-domain Few-shot Object Detection. (arXiv:2209.10904v1 [cs.CV])
29. DRKF: Distilled Rotated Kernel Fusion for Efficiently Boosting Rotation Invariance in Image Matching. (arXiv:2209.10907v1 [cs.CV])
30. CONE: An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding. (arXiv:2209.10918v1 [cs.CV])
31. MGTR: End-to-End Mutual Gaze Detection with Transformer. (arXiv:2209.10930v1 [cs.CV])
32. Learning Invariant Representations for Equivariant Neural Networks Using Orthogonal Moments. (arXiv:2209.10944v1 [cs.CV])
33. Implementing and Experimenting with Diffusion Models for Text-to-Image Generation. (arXiv:2209.10948v1 [cs.CV])
34. COVID-19 Detection and Analysis From Lung CT Images using Novel Channel Boosted CNNs. (arXiv:2209.10963v1 [eess.IV])
35. DLUNet: Semi-supervised Learning based Dual-Light UNet for Multi-organ Segmentation. (arXiv:2209.10984v1 [eess.IV])
36. Learning to Simulate Realistic LiDARs. (arXiv:2209.10986v1 [cs.RO])
37. Challenges in Visual Anomaly Detection for Mobile Robots. (arXiv:2209.10995v1 [cs.CV])
38. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v1 [eess.IV])
39. Structure Guided Manifolds for Discovery of Disease Characteristics. (arXiv:2209.11015v1 [eess.IV])
40. Privacy Attacks Against Biometric Models with Fewer Samples: Incorporating the Output of Multiple Models. (arXiv:2209.11020v1 [cs.CV])
41. Google Coral-based edge computing person reidentification using human parsing combined with analytical method. (arXiv:2209.11024v1 [cs.CV])
42. MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation. (arXiv:2209.11047v1 [cs.CV])
43. Deep Learning on Home Drone: Searching for the Optimal Architecture. (arXiv:2209.11064v1 [cs.CV])
44. Uncertainty-aware Perception Models for Off-road Autonomous Unmanned Ground Vehicles. (arXiv:2209.11115v1 [cs.RO])
45. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v1 [cs.RO])
46. Model-Assisted Labeling via Explainability for Visual Inspection of Civil Infrastructures. (arXiv:2209.11159v1 [cs.CV])
47. GET3D: A Generative Model of High Quality 3D Textured Shapes Learned from Images. (arXiv:2209.11163v1 [cs.CV])
48. Poisson Flow Generative Models. (arXiv:2209.11178v1 [cs.LG])
49. Traffic Accident Risk Forecasting using Contextual Vision Transformers. (arXiv:2209.11180v1 [cs.CV])
50. Learning Visual Explanations for DCNN-Based Image Classifiers Using an Attention Mechanism. (arXiv:2209.11189v1 [cs.CV])
51. OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics. (arXiv:2209.11195v1 [eess.IV])
52. Attention is All They Need: Exploring the Media Archaeology of the Computer Vision Research Paper. (arXiv:2209.11200v1 [cs.CY])
53. Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for Sparse Training. (arXiv:2209.11204v1 [cs.LG])
54. Siamese Network-based Lightweight Framework for Tomato Leaf Disease Recognition. (arXiv:2209.11214v1 [cs.CV])
55. UniColor: A Unified Framework for Multi-Modal Colorization with Transformer. (arXiv:2209.11223v1 [cs.CV])
56. VToonify: Controllable High-Resolution Portrait Video Style Transfer. (arXiv:2209.11224v1 [cs.CV])
57. NamedMask: Distilling Segmenters from Complementary Foundation Models. (arXiv:2209.11228v1 [cs.CV])
58. AutoMix: Unveiling the Power of Mixup for Stronger Classifiers. (arXiv:2103.13027v6 [cs.CV] UPDATED)
59. Adaptive Boosting for Domain Adaptation: Towards Robust Predictions in Scene Segmentation. (arXiv:2103.15685v3 [cs.CV] UPDATED)
60. Analyzing Green View Index and Green View Index best path using Google Street View and deep learning. (arXiv:2104.12627v4 [cs.CV] UPDATED)
61. CoSformer: Detecting Co-Salient Object with Transformers. (arXiv:2104.14729v2 [cs.CV] UPDATED)
62. Case-based similar image retrieval for weakly annotated large histopathological images of malignant lymphoma using deep metric learning. (arXiv:2107.03602v3 [cs.CV] UPDATED)
63. TempNet -- Temporal Super Resolution of Radar Rainfall Products with Residual CNNs. (arXiv:2109.09289v2 [cs.CV] UPDATED)
64. Automatic deforestation detectors based on frequentist statistics and their extensions for other spatial objects. (arXiv:2112.01063v2 [cs.CV] UPDATED)
65. Out-of-Distribution Detection Without Class Labels. (arXiv:2112.07662v2 [cs.CV] UPDATED)
66. Ensembles of Vision Transformers as a New Paradigm for Automated Classification in Ecology. (arXiv:2203.01726v2 [cs.CV] UPDATED)
67. Pixel VQ-VAEs for Improved Pixel Art Representation. (arXiv:2203.12130v2 [cs.CV] UPDATED)
68. NeuMan: Neural Human Radiance Field from a Single Video. (arXiv:2203.12575v2 [cs.CV] UPDATED)
69. Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution. (arXiv:2204.01188v3 [cs.CV] UPDATED)
70. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v4 [eess.IV] UPDATED)
71. xView3-SAR: Detecting **Dark** Fishing Activity Using Synthetic Aperture Radar Imagery. (arXiv:2206.00897v3 [cs.CV] UPDATED)
72. Bootstrapping Multi-view Representations for Fake News Detection. (arXiv:2206.05741v3 [cs.CV] UPDATED)
73. HF-NeuS: Improved Surface Reconstruction Using High-Frequency Details. (arXiv:2206.07850v2 [cs.CV] UPDATED)
74. Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
75. River Surface Patch-wise Detector Using Mixture Augmentation for Scum-cover-index. (arXiv:2207.06388v4 [cs.CV] UPDATED)
76. X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval. (arXiv:2207.07285v2 [cs.CV] UPDATED)
77. Human Treelike Tubular Structure Segmentation: A Comprehensive Review and Future Perspectives. (arXiv:2207.11203v2 [eess.IV] UPDATED)
78. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v2 [cs.CV] UPDATED)
79. Counterfactual Intervention Feature Transfer for Visible-Infrared Person Re-identification. (arXiv:2208.00967v2 [cs.CV] UPDATED)
80. Word-Level Fine-Grained Story Visualization. (arXiv:2208.02341v3 [cs.CV] UPDATED)
81. Learning to Generate 3D Shapes from a Single Example. (arXiv:2208.02946v2 [cs.GR] UPDATED)
82. Understanding Attention for Vision-and-Language Tasks. (arXiv:2208.08104v2 [cs.CV] UPDATED)
83. Toward Data-Driven Radar STAP. (arXiv:2209.02890v2 [cs.CV] UPDATED)
84. ISS: Image as Stepping Stone for Text-Guided 3D Shape Generation. (arXiv:2209.04145v4 [cs.CV] UPDATED)
85. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v2 [cs.RO] UPDATED)
86. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v2 [cs.CV] UPDATED)
87. Decentralized Vehicle Coordination: The Berkeley DeepDrive Drone Dataset. (arXiv:2209.08763v2 [cs.RO] UPDATED)
88. NeRF-SOS: Any-View Self-supervised Object Segmentation from Complex Real-World Scenes. (arXiv:2209.08776v3 [cs.CV] UPDATED)
89. Perceptual Quality Assessment for Digital Human Heads. (arXiv:2209.09489v2 [cs.CV] UPDATED)
90. KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution. (arXiv:2209.10305v2 [cs.CV] UPDATED)
91. Gemino: Practical and Robust Neural Compression for Video Conferencing. (arXiv:2209.10507v2 [cs.NI] UPDATED)
92. Equivariant Transporter Network. (arXiv:2202.09400v5 [cs.RO] CROSS LISTED)
## eess.IV
---
**20** new papers in eess.IV:-) 
1. Automated segmentation of intracranial hemorrhages from 3D CT. (arXiv:2209.10648v1 [eess.IV])
2. Phase Aberration Correction for in vivo Ultrasound Localization Microscopy Using a Spatiotemporal Complex-Valued Neural Network. (arXiv:2209.10650v1 [eess.IV])
3. A Validation Approach to Over-parameterized Matrix and Image Recovery. (arXiv:2209.10675v1 [math.OC])
4. Compressing Sign Information in DCT-based Image Coding via Deep Sign Retrieval. (arXiv:2209.10712v1 [cs.IT])
5. A CT-Based Airway Segmentation Using U$^2$-net Trained by the Dice Loss Function. (arXiv:2209.10796v1 [eess.IV])
6. Automated head and neck tumor segmentation from 3D PET/CT. (arXiv:2209.10809v1 [eess.IV])
7. Beyond Voxel Prediction Uncertainty: Identifying brain lesions you can trust. (arXiv:2209.10877v1 [eess.IV])
8. COVID-19 Detection and Analysis From Lung CT Images using Novel Channel Boosted CNNs. (arXiv:2209.10963v1 [eess.IV])
9. DLUNet: Semi-supervised Learning based Dual-Light UNet for Multi-organ Segmentation. (arXiv:2209.10984v1 [eess.IV])
10. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v1 [eess.IV])
11. Structure Guided Manifolds for Discovery of Disease Characteristics. (arXiv:2209.11015v1 [eess.IV])
12. Stochastic Optimization of 3D Non-Cartesian Sampling Trajectory (SNOPY). (arXiv:2209.11030v1 [eess.SP])
13. Blockage Prediction for Mobile UE in RIS-assisted Wireless Networks: A Deep Learning Approach. (arXiv:2209.11088v1 [eess.IV])
14. OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics. (arXiv:2209.11195v1 [eess.IV])
15. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v4 [eess.IV] UPDATED)
16. Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
17. Human Treelike Tubular Structure Segmentation: A Comprehensive Review and Future Perspectives. (arXiv:2207.11203v2 [eess.IV] UPDATED)
18. Autism spectrum disorder classification based on interpersonal neural synchrony: Can classification be improved by dyadic neural biomarkers using unsupervised graph representation learning?. (arXiv:2208.08902v2 [cs.LG] UPDATED)
19. Perceptual Quality Assessment for Digital Human Heads. (arXiv:2209.09489v2 [cs.CV] UPDATED)
20. KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution. (arXiv:2209.10305v2 [cs.CV] UPDATED)
## cs.LG
---
**157** new papers in cs.LG:-) 
1. A Tent L\'evy Flying Sparrow Search Algorithm for Feature Selection: A COVID-19 Case Study. (arXiv:2209.10542v1 [cs.LG])
2. SGC: A semi-supervised pipeline for gene clustering using self-training approach in gene co-expression networks. (arXiv:2209.10545v1 [q-bio.GN])
3. Algorithm-Agnostic Interpretations for Clustering. (arXiv:2209.10578v1 [cs.LG])
4. First-order Policy Optimization for Robust Markov Decision Process. (arXiv:2209.10579v1 [cs.LG])
5. Continuous Mixtures of Tractable Probabilistic Models. (arXiv:2209.10584v1 [cs.LG])
6. Grape Cold Hardiness Prediction via Multi-Task Learning. (arXiv:2209.10585v1 [cs.LG])
7. Assessing ASR Model Quality on Disordered Speech using BERTScore. (arXiv:2209.10591v1 [eess.AS])
8. Learning-Augmented Algorithms for Online Linear and Semidefinite Programming. (arXiv:2209.10614v1 [cs.DS])
9. DeepGraphONet: A Deep Graph Operator Network to Learn and Zero-shot Transfer the Dynamic Response of Networked Systems. (arXiv:2209.10622v1 [cs.LG])
10. SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent Factor Swapping. (arXiv:2209.10623v1 [cs.LG])
11. Seen to Unseen: When Fuzzy Inference System Predicts IoT Device Positioning Labels That Had Not Appeared in Training Phase. (arXiv:2209.10627v1 [cs.LG])
12. Neural Generalized Ordinary Differential Equations with Layer-varying Parameters. (arXiv:2209.10633v1 [cs.LG])
13. Interneurons accelerate learning dynamics in recurrent neural networks for statistical adaptation. (arXiv:2209.10634v1 [q-bio.NC])
14. Benchmarking Apache Spark and Hadoop MapReduce on Big Data Classification. (arXiv:2209.10637v1 [cs.DC])
15. Toy Models of Superposition. (arXiv:2209.10652v1 [cs.LG])
16. Mega: Moving Average Equipped Gated Attention. (arXiv:2209.10655v1 [cs.LG])
17. Explaining Anomalies using Denoising Autoencoders for Financial Tabular Data. (arXiv:2209.10658v1 [cs.LG])
18. Contrastive Learning for Time Series on Dynamic Graphs. (arXiv:2209.10662v1 [cs.LG])
19. Modelling the Frequency of Home Deliveries: An Induced Travel Demand Contribution of Aggrandized E-shopping in Toronto during COVID-19 Pandemics. (arXiv:2209.10664v1 [econ.EM])
20. Adaptive Bias Correction for Improved Subseasonal Forecasting. (arXiv:2209.10666v1 [cs.LG])
21. Modeling Perceptual Loudness of Piano Tone: Theory and Applications. (arXiv:2209.10674v1 [cs.SD])
22. A Validation Approach to Over-parameterized Matrix and Image Recovery. (arXiv:2209.10675v1 [math.OC])
23. NashAE: Disentangling Representations through Adversarial Covariance Minimization. (arXiv:2209.10677v1 [cs.LG])
24. PREF: Predictability Regularized Neural Motion Fields. (arXiv:2209.10691v1 [cs.CV])
25. Stochastic Future Prediction in Real World Driving Scenarios. (arXiv:2209.10693v1 [cs.CV])
26. SPICE, A Dataset of Drug-like Molecules and Peptides for Training Machine Learning Potentials. (arXiv:2209.10702v1 [physics.chem-ph])
27. Review of Time Series Forecasting Methods and Their Applications to Particle Accelerators. (arXiv:2209.10705v1 [physics.acc-ph])
28. Batch Bayesian optimisation via density-ratio estimation with guarantees. (arXiv:2209.10715v1 [cs.LG])
29. Enhanced Decentralized Federated Learning based on Consensus in Connected Vehicles. (arXiv:2209.10722v1 [cs.LG])
30. Fair Robust Active Learning by Joint Inconsistency. (arXiv:2209.10729v1 [cs.LG])
31. In Differential Privacy, There is Truth: On Vote Leakage in Ensemble Private Learning. (arXiv:2209.10732v1 [cs.LG])
32. Enhancing the Inductive Biases of Graph Neural ODE for Modeling Dynamical Systems. (arXiv:2209.10740v1 [cs.LG])
33. Common human diseases prediction using machine learning based on survey data. (arXiv:2209.10750v1 [cs.LG])
34. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v1 [cs.CV])
35. Nesting Forward Automatic Differentiation for Memory-Efficient Deep Neural Network Training. (arXiv:2209.10778v1 [cs.LG])
36. Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation. (arXiv:2209.10780v1 [cs.RO])
37. How Does It Feel? Self-Supervised Costmap Learning for Off-Road Vehicle Traversability. (arXiv:2209.10788v1 [cs.RO])
38. STING: Self-attention based Time-series Imputation Networks using GAN. (arXiv:2209.10801v1 [cs.LG])
39. Robust Forecasting for Robotic Control: A Game-Theoretic Approach. (arXiv:2209.10802v1 [cs.RO])
40. IntereStyle: Encoding an Interest Region for Robust StyleGAN Inversion. (arXiv:2209.10811v1 [cs.CV])
41. Memory-Augmented Graph Neural Networks: A Neuroscience Perspective. (arXiv:2209.10818v1 [cs.LG])
42. Nonsmooth Composite Nonconvex-Concave Minimax Optimization. (arXiv:2209.10825v1 [math.OC])
43. Boosting as Frank-Wolfe. (arXiv:2209.10831v1 [cs.LG])
44. High-order Multi-view Clustering for Generic Data. (arXiv:2209.10838v1 [cs.LG])
45. Detecting Rotated Objects as Gaussian Distributions and Its 3-D Generalization. (arXiv:2209.10839v1 [cs.CV])
46. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v1 [cs.CV])
47. SCALES: From Fairness Principles to Constrained Decision-Making. (arXiv:2209.10860v1 [cs.LG])
48. A novel corrective-source term approach to modeling unknown physics in aluminum extraction process. (arXiv:2209.10861v1 [cs.LG])
49. One-Shot Federated Learning for Model Clustering and Learning in Heterogeneous Environments. (arXiv:2209.10866v1 [cs.LG])
50. Turning Normalizing Flows into Monge Maps with Geodesic Gaussian Preserving Flows. (arXiv:2209.10873v1 [cs.LG])
51. Improving Attention-Based Interpretability of Text Classification Transformers. (arXiv:2209.10876v1 [cs.CL])
52. Beyond Voxel Prediction Uncertainty: Identifying brain lesions you can trust. (arXiv:2209.10877v1 [eess.IV])
53. Non-Negative Matrix Factorization with Scale Data Structure Preservation. (arXiv:2209.10881v1 [cs.LG])
54. Amortized Variational Inference: Towards the Mathematical Foundation and Review. (arXiv:2209.10888v1 [cs.LG])
55. EPIC TTS Models: Empirical Pruning Investigations Characterizing Text-To-Speech Models. (arXiv:2209.10890v1 [eess.AS])
56. mini-ELSA: using Machine Learning to improve space efficiency in Edge Lightweight Searchable Attribute-based encryption for Industry 4.0. (arXiv:2209.10896v1 [cs.LG])
57. Pretraining the Vision Transformer using self-supervised methods for vision based Deep Reinforcement Learning. (arXiv:2209.10901v1 [cs.LG])
58. Vanilla feedforward neural networks as a discretization of dynamic systems. (arXiv:2209.10909v1 [cs.LG])
59. CAMRI Loss: Improving Recall of a Specific Class without Sacrificing Accuracy. (arXiv:2209.10920v1 [cs.LG])
60. Equivariant Transduction through Invariant Alignment. (arXiv:2209.10926v1 [cs.CL])
61. Making Byzantine Decentralized Learning Efficient. (arXiv:2209.10931v1 [cs.LG])
62. Implementing and Experimenting with Diffusion Models for Text-to-Image Generation. (arXiv:2209.10948v1 [cs.CV])
63. XClusters: Explainability-first Clustering. (arXiv:2209.10956v1 [cs.LG])
64. Proximal Point Imitation Learning. (arXiv:2209.10968v1 [cs.LG])
65. Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning. (arXiv:2209.10974v1 [cs.LG])
66. Modeling cognitive load as a self-supervised brain rate with electroencephalography and deep learning. (arXiv:2209.10992v1 [eess.SP])
67. Counterfactual Explanations Using Optimization With Constraint Learning. (arXiv:2209.10997v1 [cs.LG])
68. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v1 [eess.IV])
69. EventNet: Detecting Events in EEG. (arXiv:2209.11007v1 [eess.SP])
70. Fault Detection in Ball Bearings. (arXiv:2209.11041v1 [eess.SP])
71. Inverted Landing in a Small Aerial Robot via Deep Reinforcement Learning for Triggering and Control of Rotational Maneuvers. (arXiv:2209.11043v1 [cs.RO])
72. Cross-domain Voice Activity Detection with Self-Supervised Representations. (arXiv:2209.11061v1 [eess.AS])
73. Deep Learning on Home Drone: Searching for the Optimal Architecture. (arXiv:2209.11064v1 [cs.CV])
74. CMGAN: Conformer-Based Metric-GAN for Monaural Speech **Enhancement**. (arXiv:2209.11112v1 [cs.SD])
75. Uncertainty-aware Perception Models for Off-road Autonomous Unmanned Ground Vehicles. (arXiv:2209.11115v1 [cs.RO])
76. Training neural network ensembles via trajectory sampling. (arXiv:2209.11116v1 [cond-mat.stat-mech])
77. Modern Machine Learning Tools for Monitoring and Control of Industrial Processes: A Survey. (arXiv:2209.11123v1 [cs.LG])
78. A Bibliographic View on Constrained Clustering. (arXiv:2209.11125v1 [cs.LG])
79. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v1 [cs.RO])
80. A Generalist Neural Algorithmic Learner. (arXiv:2209.11142v1 [cs.LG])
81. Structure Learning of Quantum Embeddings. (arXiv:2209.11144v1 [quant-ph])
82. MLGWSC-1: The first Machine Learning Gravitational-Wave Search Mock Data Challenge. (arXiv:2209.11146v1 [astro-ph.IM])
83. EEG-Based Epileptic Seizure Prediction Using Temporal Multi-Channel Transformers. (arXiv:2209.11172v1 [eess.SP])
84. U-Sleep: resilient to AASM guidelines. (arXiv:2209.11173v1 [eess.SP])
85. SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features. (arXiv:2209.11174v1 [eess.SP])
86. Poisson Flow Generative Models. (arXiv:2209.11178v1 [cs.LG])
87. OLIVES Dataset: Ophthalmic Labels for Investigating Visual Eye Semantics. (arXiv:2209.11195v1 [eess.IV])
88. Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for Sparse Training. (arXiv:2209.11204v1 [cs.LG])
89. Beyond Heisenberg Limit Quantum Metrology through Quantum Signal Processing. (arXiv:2209.11207v1 [quant-ph])
90. A Closer Look at Learned Optimization: Stability, Robustness, and Inductive Biases. (arXiv:2209.11208v1 [cs.LG])
91. Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions. (arXiv:2209.11215v1 [cs.LG])
92. Concept Activation Regions: A Generalized Framework For Concept-Based Explanations. (arXiv:2209.11222v1 [cs.LG])
93. VToonify: Controllable High-Resolution Portrait Video Style Transfer. (arXiv:2209.11224v1 [cs.CV])
94. NamedMask: Distilling Segmenters from Complementary Foundation Models. (arXiv:2209.11228v1 [cs.CV])
95. MALTS: Matching After Learning to Stretch. (arXiv:1811.07415v8 [stat.ME] UPDATED)
96. LIMIS: Locally Interpretable Modeling using Instance-wise Subsampling. (arXiv:1909.12367v2 [cs.LG] UPDATED)
97. Macromolecule Classification Based on the Amino-acid Sequence. (arXiv:2001.01717v2 [q-bio.BM] UPDATED)
98. Boosting Simple Learners. (arXiv:2001.11704v6 [cs.LG] UPDATED)
99. Interpretable Meta-Measure for Model Performance. (arXiv:2006.02293v2 [cs.LG] UPDATED)
100. Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles. (arXiv:2103.03786v3 [cs.LG] UPDATED)
101. Amharic Text Clustering Using Encyclopedic Knowledge with Neural Word Embedding. (arXiv:2105.00809v2 [cs.CL] UPDATED)
102. Invariant Policy Learning: A Causal Perspective. (arXiv:2106.00808v4 [cs.LG] UPDATED)
103. Matrix factorisation and the interpretation of geodesic distance. (arXiv:2106.01260v3 [stat.ML] UPDATED)
104. ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense. (arXiv:2106.14300v3 [cs.LG] UPDATED)
105. Ascent Similarity Caching with Approximate Indexes. (arXiv:2107.00957v4 [cs.NI] UPDATED)
106. Chance constrained conic-segmentation support vector machine with uncertain data. (arXiv:2107.13319v2 [cs.LG] UPDATED)
107. TempNet -- Temporal Super Resolution of Radar Rainfall Products with Residual CNNs. (arXiv:2109.09289v2 [cs.CV] UPDATED)
108. Reversible Gromov-Monge Sampler for Simulation-Based Inference. (arXiv:2109.14090v3 [stat.ME] UPDATED)
109. Optimization with Constraint Learning: A Framework and Survey. (arXiv:2110.02121v2 [cs.LG] UPDATED)
110. Explaining Deep Tractable Probabilistic Models: The sum-product network case. (arXiv:2110.09778v2 [cs.LG] UPDATED)
111. Tree density estimation. (arXiv:2111.11971v5 [math.ST] UPDATED)
112. Leveraging Joint-Diagonalization in Transform-Learning NMF. (arXiv:2112.05664v3 [cs.LG] UPDATED)
113. Out-of-Distribution Detection Without Class Labels. (arXiv:2112.07662v2 [cs.CV] UPDATED)
114. Faithiful Embeddings for EL++ Knowledge Bases. (arXiv:2201.09919v2 [cs.AI] UPDATED)
115. Exploiting Independent Instruments: Identification and Distribution Generalization. (arXiv:2202.01864v2 [stat.ML] UPDATED)
116. The Sample Complexity of One-Hidden-Layer Neural Networks. (arXiv:2202.06233v2 [cs.LG] UPDATED)
117. Rethinking Pareto Frontier for Performance Evaluation of Deep Neural Networks. (arXiv:2202.09275v5 [cs.LG] UPDATED)
118. Ensembles of Vision Transformers as a New Paradigm for Automated Classification in Ecology. (arXiv:2203.01726v2 [cs.CV] UPDATED)
119. Variational inference of fractional Brownian motion with linear computational complexity. (arXiv:2203.07961v3 [cs.LG] UPDATED)
120. One-Bit Compressive Sensing: Can We Go Deep and Blind?. (arXiv:2203.11278v2 [eess.SP] UPDATED)
121. Pixel VQ-VAEs for Improved Pixel Art Representation. (arXiv:2203.12130v2 [cs.CV] UPDATED)
122. Amortized Projection Optimization for Sliced Wasserstein Generative Models. (arXiv:2203.13417v3 [stat.ML] UPDATED)
123. Simulator-based explanation and debugging of hazard-triggering events in DNN-based safety-critical systems. (arXiv:2204.00480v2 [cs.SE] UPDATED)
124. Revisiting Sliced Wasserstein on Images: From Vectorization to Convolution. (arXiv:2204.01188v3 [cs.CV] UPDATED)
125. Personalized Prediction of Future Lesion Activity and Treatment Effect in Multiple Sclerosis from Baseline MRI. (arXiv:2204.01702v4 [eess.IV] UPDATED)
126. KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v2 [cs.CL] UPDATED)
127. Gradient-Based Trajectory Optimization With Learned Dynamics. (arXiv:2204.04558v2 [cs.RO] UPDATED)
128. FedKL: Tackling Data Heterogeneity in Federated Reinforcement Learning by Penalizing KL Divergence. (arXiv:2204.08125v3 [cs.LG] UPDATED)
129. Formulating Robustness Against Unforeseen Attacks. (arXiv:2204.13779v2 [cs.LG] UPDATED)
130. Theoretical Analysis of Primal-Dual Algorithm for Non-Convex Stochastic Decentralized Optimization. (arXiv:2205.11979v3 [math.OC] UPDATED)
131. Linear Algorithms for Robust and Scalable Nonparametric Multiclass Probability Estimation. (arXiv:2205.12460v3 [stat.ME] UPDATED)
132. Regularized Gradient Descent Ascent for Two-Player Zero-Sum Markov Games. (arXiv:2205.13746v2 [math.OC] UPDATED)
133. One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label **Enhancement**. (arXiv:2206.00517v2 [cs.LG] UPDATED)
134. Predictive Multiplicity in Probabilistic Classification. (arXiv:2206.01131v2 [cs.LG] UPDATED)
135. Non-Intrusive Reduced Models based on Operator Inference for Chaotic Systems. (arXiv:2206.01604v3 [cs.LG] UPDATED)
136. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v4 [cs.AI] UPDATED)
137. IGN : Implicit Generative Networks. (arXiv:2206.05860v2 [cs.LG] UPDATED)
138. Automated Coronary Calcium Scoring using U-Net Models through Semi-supervised Learning on Non-Gated CT Scans. (arXiv:2206.10455v2 [eess.IV] UPDATED)
139. Graph Trees with Attention. (arXiv:2207.02760v2 [cs.LG] UPDATED)
140. Improved Binary Forward Exploration: Learning Rate Scheduling Method for Stochastic Optimization. (arXiv:2207.04198v3 [cs.LG] UPDATED)
141. Reactive Exploration to Cope with Non-Stationarity in Lifelong Reinforcement Learning. (arXiv:2207.05742v2 [cs.LG] UPDATED)
142. Human Treelike Tubular Structure Segmentation: A Comprehensive Review and Future Perspectives. (arXiv:2207.11203v2 [eess.IV] UPDATED)
143. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v2 [cs.CV] UPDATED)
144. Word-Level Fine-Grained Story Visualization. (arXiv:2208.02341v3 [cs.CV] UPDATED)
145. Personalizing or Not: Dynamically Personalized Federated Learning with Incentives. (arXiv:2208.06192v2 [cs.LG] UPDATED)
146. Estimating individual treatment effects under unobserved confounding using binary instruments. (arXiv:2208.08544v2 [stat.ME] UPDATED)
147. Autism spectrum disorder classification based on interpersonal neural synchrony: Can classification be improved by dyadic neural biomarkers using unsupervised graph representation learning?. (arXiv:2208.08902v2 [cs.LG] UPDATED)
148. ODE: A Data Sampling Method for Practical Federated Learning with Streaming Data and Limited Buffer. (arXiv:2209.00195v2 [cs.LG] UPDATED)
149. Temporal Conditional VAE for Distributional Drift Adaptation in Multivariate Time Series. (arXiv:2209.00654v2 [cs.LG] UPDATED)
150. On the Horizon: Interactive and Compositional Deepfakes. (arXiv:2209.01714v3 [cs.AI] UPDATED)
151. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v2 [cs.RO] UPDATED)
152. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v2 [cs.CV] UPDATED)
153. Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v2 [cs.LG] UPDATED)
154. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v2 [eess.AS] UPDATED)
155. Flashlight: Scalable Link Prediction with Effective Decoders. (arXiv:2209.10100v2 [cs.SI] UPDATED)
156. Equivariant Transporter Network. (arXiv:2202.09400v5 [cs.RO] CROSS LISTED)
157. Parallel Bayesian Optimization of Agent-based Transportation Simulation. (arXiv:2207.05041v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**76** new papers in cs.AI:-) 
1. First-order Policy Optimization for Robust Markov Decision Process. (arXiv:2209.10579v1 [cs.LG])
2. Continuous Mixtures of Tractable Probabilistic Models. (arXiv:2209.10584v1 [cs.LG])
3. DeepVARwT: Deep Learning for a VAR Model with Trend. (arXiv:2209.10587v1 [stat.ME])
4. Current and Near-Term AI as a Potential Existential Risk Factor. (arXiv:2209.10604v1 [cs.CY])
5. SW-VAE: Weakly Supervised Learn Disentangled Representation Via Latent Factor Swapping. (arXiv:2209.10623v1 [cs.LG])
6. Learning from Symmetry: Meta-Reinforcement Learning with Symmetric Data and Language Instructions. (arXiv:2209.10656v1 [cs.AI])
7. Batch Bayesian optimisation via density-ratio estimation with guarantees. (arXiv:2209.10715v1 [cs.LG])
8. Enhanced Decentralized Federated Learning based on Consensus in Connected Vehicles. (arXiv:2209.10722v1 [cs.LG])
9. CCR: Facial Image Editing with Continuity, Consistency and Reversibility. (arXiv:2209.10734v1 [cs.CV])
10. Reinforcement Learning in Computing and Network Convergence Orchestration. (arXiv:2209.10753v1 [cs.NI])
11. INFINITY: A Simple Yet Effective Unsupervised Framework for Graph-Text Mutual Conversion. (arXiv:2209.10754v1 [cs.CL])
12. DRAMA: Joint Risk Localization and Captioning in Driving. (arXiv:2209.10767v1 [cs.CV])
13. Multi-level Adversarial Spatio-temporal Learning for Footstep Pressure based FoG Detection. (arXiv:2209.10770v1 [cs.CV])
14. MUI-TARE: Multi-Agent Cooperative Exploration with Unknown Initial Position. (arXiv:2209.10775v1 [cs.RO])
15. Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation. (arXiv:2209.10780v1 [cs.RO])
16. Deep Lake: a Lakehouse for Deep Learning. (arXiv:2209.10785v1 [cs.DC])
17. STING: Self-attention based Time-series Imputation Networks using GAN. (arXiv:2209.10801v1 [cs.LG])
18. SR-GCL: Session-Based Recommendation with Global Context Enhanced Augmentation in Contrastive Learning. (arXiv:2209.10807v1 [cs.IR])
19. Memory-Augmented Graph Neural Networks: A Neuroscience Perspective. (arXiv:2209.10818v1 [cs.LG])
20. High-order Multi-view Clustering for Generic Data. (arXiv:2209.10838v1 [cs.LG])
21. Detecting Rotated Objects as Gaussian Distributions and Its 3-D Generalization. (arXiv:2209.10839v1 [cs.CV])
22. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v1 [cs.CV])
23. The SpeakIn System Description for CNSRC2022. (arXiv:2209.10846v1 [cs.SD])
24. MnTTS: An Open-Source Mongolian Text-to-Speech Synthesis Dataset and Accompanied Baseline. (arXiv:2209.10848v1 [cs.SD])
25. SCALES: From Fairness Principles to Constrained Decision-Making. (arXiv:2209.10860v1 [cs.LG])
26. Process Modeling and Conformance Checking in Healthcare: A COVID-19 Case Study. (arXiv:2209.10897v1 [cs.DB])
27. A Capability and Skill Model for Heterogeneous Autonomous Robots. (arXiv:2209.10900v1 [cs.AI])
28. An Information Minimization Based Contrastive Learning Model for Unsupervised Sentence Embeddings Learning. (arXiv:2209.10951v1 [cs.CL])
29. Developing, Evaluating and Scaling Learning Agents in Multi-Agent Environments. (arXiv:2209.10958v1 [cs.MA])
30. Modeling cognitive load as a self-supervised brain rate with electroencephalography and deep learning. (arXiv:2209.10992v1 [eess.SP])
31. Over-the-Air Computation over Balanced Numerals. (arXiv:2209.11004v1 [eess.SP])
32. Towards Ontology Reshaping for KG Generation with User-in-the-Loop: Applied to Bosch Welding. (arXiv:2209.11067v1 [cs.AI])
33. Query-based Industrial Analytics over Knowledge Graphs with Ontology Reshaping. (arXiv:2209.11089v1 [cs.DB])
34. Parallel Reinforcement Learning Simulation for Visual Quadrotor Navigation. (arXiv:2209.11094v1 [cs.RO])
35. CMGAN: Conformer-Based Metric-GAN for Monaural Speech **Enhancement**. (arXiv:2209.11112v1 [cs.SD])
36. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v1 [cs.RO])
37. Power Method, Inverse Power Method and Shifted Inverse Power Method Neural Networks for Solving Eigenvalue Problems of Linear Operators. (arXiv:2209.11134v1 [math.NA])
38. A Generalist Neural Algorithmic Learner. (arXiv:2209.11142v1 [cs.LG])
39. EEG-Based Epileptic Seizure Prediction Using Temporal Multi-Channel Transformers. (arXiv:2209.11172v1 [eess.SP])
40. SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features. (arXiv:2209.11174v1 [eess.SP])
41. Traffic Accident Risk Forecasting using Contextual Vision Transformers. (arXiv:2209.11180v1 [cs.CV])
42. Layer Freezing & Data Sieving: Missing Pieces of a Generic Framework for Sparse Training. (arXiv:2209.11204v1 [cs.LG])
43. Learning Dexterous Manipulation from Exemplar Object Trajectories and Pre-Grasps. (arXiv:2209.11221v1 [cs.RO])
44. Concept Activation Regions: A Generalized Framework For Concept-Based Explanations. (arXiv:2209.11222v1 [cs.LG])
45. NamedMask: Distilling Segmenters from Complementary Foundation Models. (arXiv:2209.11228v1 [cs.CV])
46. Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles. (arXiv:2103.03786v3 [cs.LG] UPDATED)
47. AutoMix: Unveiling the Power of Mixup for Stronger Classifiers. (arXiv:2103.13027v6 [cs.CV] UPDATED)
48. Invariant Policy Learning: A Causal Perspective. (arXiv:2106.00808v4 [cs.LG] UPDATED)
49. Population-coding and Dynamic-neurons improved Spiking Actor Network for Reinforcement Learning. (arXiv:2106.07854v3 [cs.AI] UPDATED)
50. ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense. (arXiv:2106.14300v3 [cs.LG] UPDATED)
51. Socially Supervised Representation Learning: the Role of Subjectivity in Learning Efficient Representations. (arXiv:2109.09390v4 [cs.AI] UPDATED)
52. Collaborative Artificial Intelligence Needs Stronger Assurances Driven by Risks. (arXiv:2112.00740v2 [cs.HC] UPDATED)
53. Visual Information Guided Zero-Shot Paraphrase Generation. (arXiv:2201.09107v2 [cs.CL] UPDATED)
54. Faithiful Embeddings for EL++ Knowledge Bases. (arXiv:2201.09919v2 [cs.AI] UPDATED)
55. A Versatile Agent for Fast Learning from Human Instructors. (arXiv:2203.00251v2 [cs.AI] UPDATED)
56. TSAM: A Two-Stream Attention Model for Causal Emotion Entailment. (arXiv:2203.00819v2 [cs.CL] UPDATED)
57. KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v2 [cs.CL] UPDATED)
58. Semantic Structure based Query Graph Prediction for Question Answering over Knowledge Graph. (arXiv:2204.10194v6 [cs.CL] UPDATED)
59. ATST: Audio Representation Learning with Teacher-Student Transformer. (arXiv:2204.12076v2 [eess.AS] UPDATED)
60. Inductive Learning of Complex Knowledge from Raw Data. (arXiv:2205.12735v3 [cs.AI] UPDATED)
61. MAREO: Memory- and Attention- based visual REasOning. (arXiv:2206.04928v4 [cs.AI] UPDATED)
62. IGN : Implicit Generative Networks. (arXiv:2206.05860v2 [cs.LG] UPDATED)
63. Graph Trees with Attention. (arXiv:2207.02760v2 [cs.LG] UPDATED)
64. Reactive Exploration to Cope with Non-Stationarity in Lifelong Reinforcement Learning. (arXiv:2207.05742v2 [cs.LG] UPDATED)
65. A Novel Data Augmentation Technique for Out-of-Distribution Sample Detection using Compounded Corruptions. (arXiv:2207.13916v2 [cs.CV] UPDATED)
66. Learning to Generate 3D Shapes from a Single Example. (arXiv:2208.02946v2 [cs.GR] UPDATED)
67. Personalizing or Not: Dynamically Personalized Federated Learning with Incentives. (arXiv:2208.06192v2 [cs.LG] UPDATED)
68. Multi-AI Complex Systems in Humanitarian Response. (arXiv:2208.11282v2 [cs.CY] UPDATED)
69. Getting Quechua Closer to Final Users through Knowledge Graphs. (arXiv:2208.12608v2 [cs.CY] UPDATED)
70. On the Horizon: Interactive and Compositional Deepfakes. (arXiv:2209.01714v3 [cs.AI] UPDATED)
71. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v2 [cs.RO] UPDATED)
72. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v2 [cs.CV] UPDATED)
73. Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v2 [cs.LG] UPDATED)
74. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v2 [eess.AS] UPDATED)
75. Flashlight: Scalable Link Prediction with Effective Decoders. (arXiv:2209.10100v2 [cs.SI] UPDATED)
76. WeLM: A Well-Read Pre-trained Language Model for Chinese. (arXiv:2209.10372v2 [cs.CL] UPDATED)

