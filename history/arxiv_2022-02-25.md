# Your interest papers
---
## cs.CV
---
### A spectral-spatial fusion anomaly detection method for hyperspectral imagery. (arXiv:2202.11889v1 [eess.IV])
- Authors : Zengfu Hou, Siyuan Cheng, Ting Hu
- Link : [http://arxiv.org/abs/2202.11889](http://arxiv.org/abs/2202.11889)
> ABSTRACT  :  In hyperspectral, high-quality spectral signals convey subtle spectral differences to distinguish similar materials, thereby providing unique advantage for anomaly detection. Hence fine spectra of anomalous pixels can be effectively screened out from heterogeneous background pixels. Since the same materials have similar characteristics in spatial and spectral dimension, detection performance can be significantly enhanced by jointing spatial and spectral information. In this paper, a spectralspatial fusion anomaly detection (SSFAD) method is proposed for hyperspectral imagery. First, original spectral signals are mapped to a local linear background space composed of median and mean with high confidence, where saliency weight and feature **enhancement** strategies are implemented to obtain an initial detection map in spectral domain. Futhermore, to make full use of similarity information of local background around testing pixel, a new detector is designed to extract the local similarity spatial features of patch images in spatial domain. Finally, anomalies are detected by adaptively combining the spectral and spatial detection maps. The experimental results demonstrate that our proposed method has superior detection performance than traditional methods.  
### AFFDEX 2.0: A Real-Time Facial Expression Analysis Toolkit. (arXiv:2202.12059v1 [cs.CV])
- Authors : Mina Bishay, Kenneth Preston, Matthew Strafuss, Graham Page, Jay Turcot, Mohammad Mavadati
- Link : [http://arxiv.org/abs/2202.12059](http://arxiv.org/abs/2202.12059)
> ABSTRACT  :  In this paper we introduce AFFDEX 2.0 - a toolkit for analyzing facial expressions in the wild, that is, it is intended for users aiming to; a) estimate the 3D head pose, b) detect facial Action Units (AUs), c) recognize basic emotions and 2 new emotional states (sentimentality and confusion), and d) detect high-level expressive metrics like blink and attention. AFFDEX 2.0 models are mainly based on Deep Learning, and are trained using a large-scale naturalistic dataset consisting of thousands of participants from different demographic groups. AFFDEX 2.0 is an enhanced version of our previous toolkit [1], that is capable of tracking efficiently faces at more challenging conditions, detecting more accurately facial expressions, and recognizing new emotional states (sentimentality and confusion). AFFDEX 2.0 can process multiple faces in **real time**, and is working across the Windows and Linux platforms.  
### Phrase-Based Affordance Detection via Cyclic **Bilateral** Interaction. (arXiv:2202.12076v1 [cs.CV])
- Authors : Liangsheng Lu, Wei Zhai, Hongchen Luo, Yu Kang, Yang Cao
- Link : [http://arxiv.org/abs/2202.12076](http://arxiv.org/abs/2202.12076)
> ABSTRACT  :  Affordance detection, which refers to perceiving objects with potential action possibilities in images, is a challenging task since the possible affordance depends on the person's purpose in real-world application scenarios. The existing works mainly extract the inherent human-object dependencies from image/video to accommodate affordance properties that change dynamically. In this paper, we explore to perceive affordance from a vision-language perspective and consider the challenging phrase-based affordance detection problem,i.e., given a set of phrases describing the action purposes, all the object regions in a scene with the same affordance should be detected. To this end, we propose a cyclic **bilateral** consistency **enhancement** network (CBCE-Net) to align language and vision features progressively. Specifically, the presented CBCE-Net consists of a mutual guided vision-language module that updates the common features of vision and language in a progressive manner, and a cyclic interaction module (CIM) that facilitates the perception of possible interaction with objects in a cyclic manner. In addition, we extend the public Purpose-driven Affordance Dataset (PAD) by annotating affordance categories with short phrases. The contrastive experimental results demonstrate the superiority of our method over nine typical methods from four relevant fields in terms of both objective metrics and visual quality. The related code and dataset will be released at \url{https://github.com/lulsheng/CBCE-Net}.  
### Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
- Authors : Mangal Prakash, Mauricio Delbracio, **Peyman Milanfar**, Florian Jug
- Link : [http://arxiv.org/abs/2104.01374](http://arxiv.org/abs/2104.01374)
> ABSTRACT  :  Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity **restoration**, that is, obtaining a diverse set of possible **restoration**s given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image **restoration**. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions. Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible **restoration**s all consistent with the given corrupted image.  
### Physics perception in sloshing scenes with guaranteed thermodynamic consistency. (arXiv:2106.13301v3 [cs.CV] UPDATED)
- Authors : Beatriz Moya, Alberto Badias, David Gonzalez, Francisco Chinesta, Elias Cueto
- Link : [http://arxiv.org/abs/2106.13301](http://arxiv.org/abs/2106.13301)
> ABSTRACT  :  Physics perception very often faces the problem that only limited data or partial measurements on the scene are available. In this work, we propose a strategy to learn the full state of sloshing liquids from measurements of the free surface. Our approach is based on recurrent neural networks (RNN) that project the limited information available to a reduced-order manifold so as to not only reconstruct the unknown information, but also to be capable of performing fluid reasoning about future scenarios in **real time**. To obtain physically consistent predictions, we train deep neural networks on the reduced-order manifold that, through the employ of inductive biases, ensure the fulfillment of the principles of thermodynamics. RNNs learn from history the required hidden information to correlate the limited information with the latent space where the simulation occurs. Finally, a decoder returns data back to the high-dimensional manifold, so as to provide the user with insightful information in the form of augmented reality. This algorithm is connected to a computer vision system to test the performance of the proposed methodology with real information, resulting in a system capable of understanding and predicting future states of the observed fluid in real-time.  
### CT-ICP: **Real-time** Elastic LiDAR Odometry with Loop Closure. (arXiv:2109.12979v2 [cs.RO] UPDATED)
- Authors : Pierre Dellenbach, Emmanuel Deschaud, Bastien Jacquet, ois Goulette
- Link : [http://arxiv.org/abs/2109.12979](http://arxiv.org/abs/2109.12979)
> ABSTRACT  :  Multi-beam LiDAR sensors are increasingly used in robotics, particularly with autonomous cars for localization and perception tasks, both relying on the ability to build a precise map of the environment. For this, we propose a new real-time LiDAR-only odometry method called CT-ICP (for Continuous-Time ICP), completed into a full SLAM with a novel loop detection procedure. The core of this method, is the introduction of the combined continuity in the scan matching, and discontinuity between scans. It allows both the elastic distortion of the scan during the registration for increased precision, and the increased robustness to high frequency motions from the discontinuity.    We build a complete SLAM on top of this odometry, using a fast pure LiDAR loop detection based on elevation image 2D matching, providing a pose graph with loop constraints. To show the robustness of the method, we tested it on seven datasets: KITTI, KITTI-raw, KITTI-360, KITTI-CARLA, ParisLuco, Newer College, and NCLT in driving and high-frequency motion scenarios. Both the CT-ICP odometry and the loop detection are made available online. CT-ICP is currently first, among those giving access to a public code, on the KITTI odometry leaderboard, with an average Relative Translation Error (RTE) of 0.59% and an average time per scan of 60ms on a CPU with a single thread.  
### Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization. (arXiv:2201.13256v3 [math.OC] UPDATED)
- Authors : Samuel Hurault, Arthur Leclaire, Nicolas Papadakis
- Link : [http://arxiv.org/abs/2201.13256](http://arxiv.org/abs/2201.13256)
> ABSTRACT  :  Plug-and-Play (PnP) methods solve ill-posed inverse problems through iterative proximal algorithms by replacing a proximal operator by a denoising operation. When applied with deep neural network denoisers, these methods have shown state-of-the-art visual performance for image **restoration** problems. However, their theoretical convergence analysis is still incomplete. Most of the existing convergence results consider nonexpansive denoisers, which is non-realistic, or limit their analysis to strongly convex data-fidelity terms in the inverse problem to solve. Recently, it was proposed to train the denoiser as a gradient descent step on a functional parameterized by a deep neural network. Using such a denoiser guarantees the convergence of the PnP version of the Half-Quadratic-Splitting (PnP-HQS) iterative algorithm. In this paper, we show that this gradient denoiser can actually correspond to the proximal operator of another scalar function. Given this new result, we exploit the convergence theory of proximal algorithms in the nonconvex setting to obtain convergence results for PnP-PGD (Proximal Gradient Descent) and PnP-ADMM (Alternating Direction Method of Multipliers). When built on top of a smooth gradient denoiser, we show that PnP-PGD and PnP-ADMM are convergent and target stationary points of an explicit functional. These convergence results are confirmed with numerical experiments on deblurring, super-resolution and inpainting.  
### LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v2 [cs.CV] UPDATED)
- Authors : Yongjun Zhang, Siyuan Zou, Xinyi Liu, Xu Huang, Yi Wan, Yongxiang Yao
- Link : [http://arxiv.org/abs/2202.09953](http://arxiv.org/abs/2202.09953)
> ABSTRACT  :  The complementary fusion of light detection and ranging (LiDAR) data and image data is a promising but challenging task for generating high-precision and high-density point clouds. This study proposes an innovative LiDAR-guided stereo matching approach called LiDAR-guided stereo matching (LGSM), which considers the spatial consistency represented by continuous disparity or depth changes in the homogeneous region of an image. The LGSM first detects the homogeneous pixels of each LiDAR projection point based on their color or intensity similarity. Next, we propose a riverbed **enhancement** function to optimize the cost volume of the LiDAR projection points and their homogeneous pixels to improve the matching robustness. Our formulation expands the constraint scopes of sparse LiDAR projection points with the guidance of image information to optimize the cost volume of pixels as much as possible. We applied LGSM to semi-global matching and AD-Census on both simulated and real datasets. When the percentage of LiDAR points in the simulated datasets was 0.16%, the matching accuracy of our method achieved a subpixel level, while that of the original stereo matching algorithm was 3.4 pixels. The experimental results show that LGSM is suitable for indoor, street, aerial, and satellite image datasets and provides good transferability across semi-global matching and AD-Census. Furthermore, the qualitative and quantitative evaluations demonstrate that LGSM is superior to two state-of-the-art optimizing cost volume methods, especially in reducing mismatches in difficult matching areas and refining the boundaries of objects.  
## eess.IV
---
### A spectral-spatial fusion anomaly detection method for hyperspectral imagery. (arXiv:2202.11889v1 [eess.IV])
- Authors : Zengfu Hou, Siyuan Cheng, Ting Hu
- Link : [http://arxiv.org/abs/2202.11889](http://arxiv.org/abs/2202.11889)
> ABSTRACT  :  In hyperspectral, high-quality spectral signals convey subtle spectral differences to distinguish similar materials, thereby providing unique advantage for anomaly detection. Hence fine spectra of anomalous pixels can be effectively screened out from heterogeneous background pixels. Since the same materials have similar characteristics in spatial and spectral dimension, detection performance can be significantly enhanced by jointing spatial and spectral information. In this paper, a spectralspatial fusion anomaly detection (SSFAD) method is proposed for hyperspectral imagery. First, original spectral signals are mapped to a local linear background space composed of median and mean with high confidence, where saliency weight and feature **enhancement** strategies are implemented to obtain an initial detection map in spectral domain. Futhermore, to make full use of similarity information of local background around testing pixel, a new detector is designed to extract the local similarity spatial features of patch images in spatial domain. Finally, anomalies are detected by adaptively combining the spectral and spatial detection maps. The experimental results demonstrate that our proposed method has superior detection performance than traditional methods.  
### Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
- Authors : Mangal Prakash, Mauricio Delbracio, **Peyman Milanfar**, Florian Jug
- Link : [http://arxiv.org/abs/2104.01374](http://arxiv.org/abs/2104.01374)
> ABSTRACT  :  Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity **restoration**, that is, obtaining a diverse set of possible **restoration**s given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image **restoration**. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions. Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible **restoration**s all consistent with the given corrupted image.  
### LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v2 [cs.CV] UPDATED)
- Authors : Yongjun Zhang, Siyuan Zou, Xinyi Liu, Xu Huang, Yi Wan, Yongxiang Yao
- Link : [http://arxiv.org/abs/2202.09953](http://arxiv.org/abs/2202.09953)
> ABSTRACT  :  The complementary fusion of light detection and ranging (LiDAR) data and image data is a promising but challenging task for generating high-precision and high-density point clouds. This study proposes an innovative LiDAR-guided stereo matching approach called LiDAR-guided stereo matching (LGSM), which considers the spatial consistency represented by continuous disparity or depth changes in the homogeneous region of an image. The LGSM first detects the homogeneous pixels of each LiDAR projection point based on their color or intensity similarity. Next, we propose a riverbed **enhancement** function to optimize the cost volume of the LiDAR projection points and their homogeneous pixels to improve the matching robustness. Our formulation expands the constraint scopes of sparse LiDAR projection points with the guidance of image information to optimize the cost volume of pixels as much as possible. We applied LGSM to semi-global matching and AD-Census on both simulated and real datasets. When the percentage of LiDAR points in the simulated datasets was 0.16%, the matching accuracy of our method achieved a subpixel level, while that of the original stereo matching algorithm was 3.4 pixels. The experimental results show that LGSM is suitable for indoor, street, aerial, and satellite image datasets and provides good transferability across semi-global matching and AD-Census. Furthermore, the qualitative and quantitative evaluations demonstrate that LGSM is superior to two state-of-the-art optimizing cost volume methods, especially in reducing mismatches in difficult matching areas and refining the boundaries of objects.  
## cs.LG
---
### Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
- Authors : Mangal Prakash, Mauricio Delbracio, **Peyman Milanfar**, Florian Jug
- Link : [http://arxiv.org/abs/2104.01374](http://arxiv.org/abs/2104.01374)
> ABSTRACT  :  Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity **restoration**, that is, obtaining a diverse set of possible **restoration**s given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image **restoration**. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions. Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible **restoration**s all consistent with the given corrupted image.  
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v4 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
### Physics perception in sloshing scenes with guaranteed thermodynamic consistency. (arXiv:2106.13301v3 [cs.CV] UPDATED)
- Authors : Beatriz Moya, Alberto Badias, David Gonzalez, Francisco Chinesta, Elias Cueto
- Link : [http://arxiv.org/abs/2106.13301](http://arxiv.org/abs/2106.13301)
> ABSTRACT  :  Physics perception very often faces the problem that only limited data or partial measurements on the scene are available. In this work, we propose a strategy to learn the full state of sloshing liquids from measurements of the free surface. Our approach is based on recurrent neural networks (RNN) that project the limited information available to a reduced-order manifold so as to not only reconstruct the unknown information, but also to be capable of performing fluid reasoning about future scenarios in **real time**. To obtain physically consistent predictions, we train deep neural networks on the reduced-order manifold that, through the employ of inductive biases, ensure the fulfillment of the principles of thermodynamics. RNNs learn from history the required hidden information to correlate the limited information with the latent space where the simulation occurs. Finally, a decoder returns data back to the high-dimensional manifold, so as to provide the user with insightful information in the form of augmented reality. This algorithm is connected to a computer vision system to test the performance of the proposed methodology with real information, resulting in a system capable of understanding and predicting future states of the observed fluid in real-time.  
### SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing. (arXiv:2110.07205v2 [eess.AS] UPDATED)
- Authors : Junyi Ao, Rui Wang, Long Zhou, Chengyi Wang, Shuo Ren, Yu Wu, Shujie Liu, Tom Ko, Qing Li, Yu Zhang, Zhihua Wei, Yao Qian, Jinyu Li, Furu Wei
- Link : [http://arxiv.org/abs/2110.07205](http://arxiv.org/abs/2110.07205)
> ABSTRACT  :  Motivated by the success of T5 (Text-To-Text Transfer Transformer) in pre-trained natural language processing models, we propose a unified-modal SpeechT5 framework that explores the encoder-decoder pre-training for self-supervised speech/text representation learning. The SpeechT5 framework consists of a shared encoder-decoder network and six modal-specific (speech/text) pre/post-nets. After preprocessing the input speech/text through the pre-nets, the shared encoder-decoder network models the sequence-to-sequence transformation, and then the post-nets generate the output in the speech/text modality based on the output of the decoder. Leveraging large-scale unlabeled speech and text data, we pre-train SpeechT5 to learn a unified-modal representation, hoping to improve the modeling capability for both speech and text. To align the textual and speech information into this unified semantic space, we propose a cross-modal vector quantization approach that randomly mixes up speech/text states with latent units as the interface between encoder and decoder. Extensive evaluations show the superiority of the proposed SpeechT5 framework on a wide variety of spoken language processing tasks, including automatic speech recognition, speech synthesis, speech translation, voice conversion, speech **enhancement**, and speaker identification. We will release our code and model at https://github.com/microsoft/SpeechT5.  
## cs.AI
---
### Phase Continuity: Learning Derivatives of Phase Spectrum for Speech **Enhancement**. (arXiv:2202.11918v1 [cs.SD])
- Authors : Doyeon Kim, Hyewon Han, Kyeong Shin, Whan Chung, Goo Kang
- Link : [http://arxiv.org/abs/2202.11918](http://arxiv.org/abs/2202.11918)
> ABSTRACT  :  Modern neural speech **enhancement** models usually include various forms of phase information in their training loss terms, either explicitly or implicitly. However, these loss terms are typically designed to reduce the distortion of phase spectrum values at specific frequencies, which ensures they do not significantly affect the quality of the enhanced speech. In this paper, we propose an effective phase reconstruction strategy for neural speech **enhancement** that can operate in noisy environments. Specifically, we introduce a phase continuity loss that considers relative phase variations across the time and frequency axes. By including this phase continuity loss in a state-of-the-art neural speech **enhancement** system trained with reconstruction loss and a number of magnitude spectral losses, we show that our proposed method further improves the quality of enhanced speech signals over the baseline, especially when training is done jointly with a magnitude spectrum loss.  
### Phrase-Based Affordance Detection via Cyclic **Bilateral** Interaction. (arXiv:2202.12076v1 [cs.CV])
- Authors : Liangsheng Lu, Wei Zhai, Hongchen Luo, Yu Kang, Yang Cao
- Link : [http://arxiv.org/abs/2202.12076](http://arxiv.org/abs/2202.12076)
> ABSTRACT  :  Affordance detection, which refers to perceiving objects with potential action possibilities in images, is a challenging task since the possible affordance depends on the person's purpose in real-world application scenarios. The existing works mainly extract the inherent human-object dependencies from image/video to accommodate affordance properties that change dynamically. In this paper, we explore to perceive affordance from a vision-language perspective and consider the challenging phrase-based affordance detection problem,i.e., given a set of phrases describing the action purposes, all the object regions in a scene with the same affordance should be detected. To this end, we propose a cyclic **bilateral** consistency **enhancement** network (CBCE-Net) to align language and vision features progressively. Specifically, the presented CBCE-Net consists of a mutual guided vision-language module that updates the common features of vision and language in a progressive manner, and a cyclic interaction module (CIM) that facilitates the perception of possible interaction with objects in a cyclic manner. In addition, we extend the public Purpose-driven Affordance Dataset (PAD) by annotating affordance categories with short phrases. The contrastive experimental results demonstrate the superiority of our method over nine typical methods from four relevant fields in terms of both objective metrics and visual quality. The related code and dataset will be released at \url{https://github.com/lulsheng/CBCE-Net}.  
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v4 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
# Paper List
---
## cs.CV
---
**81** new papers in cs.CV:-) 
1. Think Global, Act Local: Dual-scale Graph Transformer for Vision-and-Language Navigation. (arXiv:2202.11742v1 [cs.CV])
2. Single Image Super-Resolution Methods: A Survey. (arXiv:2202.11763v1 [eess.IV])
3. When do GANs replicate? On the choice of dataset size. (arXiv:2202.11765v1 [cs.LG])
4. Discovering Multiple and Diverse Directions for Cognitive Image Properties. (arXiv:2202.11772v1 [cs.CV])
5. Art Creation with Multi-Conditional StyleGANs. (arXiv:2202.11777v1 [cs.CV])
6. RadioTransformer: A Cascaded Global-Focal Transformer for Visual Attention-guided Disease Classification. (arXiv:2202.11781v1 [cs.CV])
7. Nuclei panoptic segmentation and composition regression with multi-task deep neural networks. (arXiv:2202.11804v1 [eess.IV])
8. A modification of the conjugate direction method for motion estimation. (arXiv:2202.11831v1 [cs.CV])
9. Near Perfect GAN Inversion. (arXiv:2202.11833v1 [cs.CV])
10. Explanatory Paradigms in Neural Networks. (arXiv:2202.11838v1 [cs.LG])
11. CAISE: Conversational Agent for Image Search and Editing. (arXiv:2202.11847v1 [cs.CL])
12. Learning Multi-Object Dynamics with Compositional Neural Radiance Fields. (arXiv:2202.11855v1 [cs.CV])
13. CG-SSD: Corner Guided Single Stage 3D Object Detection from LiDAR Point Cloud. (arXiv:2202.11868v1 [cs.CV])
14. New Benchmark for Household Garbage Image Recognition. (arXiv:2202.11878v1 [cs.CV])
15. A Note on Machine Learning Approach for Computational Imaging. (arXiv:2202.11883v1 [eess.IV])
16. M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction. (arXiv:2202.11884v1 [cs.RO])
17. A spectral-spatial fusion anomaly detection method for hyperspectral imagery. (arXiv:2202.11889v1 [eess.IV])
18. HMD-EgoPose: Head-Mounted Display-Based Egocentric Marker-Less Tool and Hand Pose Estimation for Augmented Surgical Guidance. (arXiv:2202.11891v1 [cs.CV])
19. Controlling Memorability of Face Images. (arXiv:2202.11896v1 [cs.CV])
20. Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling. (arXiv:2202.11898v1 [cs.CV])
21. SLRNet: Semi-Supervised Semantic Segmentation Via Label Reuse for Human Decomposition Images. (arXiv:2202.11900v1 [cs.CV])
22. Uncertainty-driven Planner for Exploration and Navigation. (arXiv:2202.11907v1 [cs.RO])
23. When Transformer Meets Robotic Grasping: Exploits Context for Efficient Grasp Detection. (arXiv:2202.11911v1 [cs.RO])
24. Interpolation-based Contrastive Learning for Few-Label Semi-Supervised Learning. (arXiv:2202.11915v1 [cs.CV])
25. Auto-scaling Vision Transformers without Training. (arXiv:2202.11921v1 [cs.LG])
26. Computer Aided Diagnosis and Out-of-Distribution Detection in Glaucoma Screening Using Color Fundus Photography. (arXiv:2202.11944v1 [cs.CV])
27. Domain Disentangled Generative Adversarial Network for Zero-Shot Sketch-Based 3D Shape Retrieval. (arXiv:2202.11948v1 [cs.CV])
28. SMILE: Sequence-to-Sequence Domain Adaption with Minimizing Latent Entropy for Text Image Recognition. (arXiv:2202.11949v1 [cs.CV])
29. Fully Self-Supervised Learning for Semantic Segmentation. (arXiv:2202.11981v1 [cs.CV])
30. N-QGN: Navigation Map from a Monocular Camera using Quadtree Generating Networks. (arXiv:2202.11982v1 [cs.CV])
31. GIAOTracker: A comprehensive framework for MCMOT with global information and optimizing strategies in VisDrone 2021. (arXiv:2202.11983v1 [cs.CV])
32. Effective Actor-centric Human-object Interaction Detection. (arXiv:2202.11998v1 [cs.CV])
33. Rare Gems: Finding Lottery Tickets at Initialization. (arXiv:2202.12002v1 [cs.LG])
34. Learning to Merge Tokens in Vision Transformers. (arXiv:2202.12015v1 [cs.CV])
35. Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge. (arXiv:2202.12031v1 [cs.CV])
36. AFFDEX 2.0: A Real-Time Facial Expression Analysis Toolkit. (arXiv:2202.12059v1 [cs.CV])
37. Phrase-Based Affordance Detection via Cyclic **Bilateral** Interaction. (arXiv:2202.12076v1 [cs.CV])
38. Data variation-aware medical image segmentation. (arXiv:2202.12099v1 [eess.IV])
39. DeepFusionMOT: A 3D Multi-Object Tracking Framework Based on Camera-LiDAR Fusion with Deep Association. (arXiv:2202.12100v1 [cs.CV])
40. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v1 [eess.IV])
41. Light Robust Monocular Depth Estimation For Outdoor Environment Via Monochrome And Color Camera Fusion. (arXiv:2202.12108v1 [cs.CV])
42. Slow-Fast Visual Tempo Learning for Video-based Action Recognition. (arXiv:2202.12116v1 [cs.CV])
43. A novel unsupervised covid lung lesion segmentation based on the lung tissue identification. (arXiv:2202.12148v1 [eess.IV])
44. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v1 [cs.CR])
45. Measuring CLEVRness: Blackbox testing of Visual Reasoning Models. (arXiv:2202.12162v1 [cs.LG])
46. Transformers in Medical Image Analysis: A Review. (arXiv:2202.12165v1 [cs.CV])
47. FreeSOLO: Learning to Segment Objects without Annotations. (arXiv:2202.12181v1 [cs.CV])
48. Self-Distilled StyleGAN: Towards Generation from Internet Photos. (arXiv:2202.12211v1 [cs.CV])
49. A comparative study of in-air trajectories at short and long distances in online handwriting. (arXiv:2202.12237v1 [cs.CV])
50. On-line signature verification system with failure to enroll managing. (arXiv:2202.12242v1 [cs.CV])
51. EMOTHAW: A novel database for emotional state recognition from handwriting. (arXiv:2202.12245v1 [cs.CV])
52. BLPnet: A new DNN model and Bengali OCR engine for Automatic License Plate Recognition. (arXiv:2202.12250v1 [cs.CV])
53. ISDA: Position-Aware Instance Segmentation with Deformable Attention. (arXiv:2202.12251v1 [cs.CV])
54. A Method for Waste Segregation using Convolutional Neural Networks. (arXiv:2202.12258v1 [cs.CV])
55. Learning from the Pros: Extracting Professional Goalkeeper Technique from Broadcast Footage. (arXiv:2202.12259v1 [cs.CV])
56. Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images. (arXiv:2202.12267v1 [eess.IV])
57. Evaluating Feature Attribution Methods in the Image Domain. (arXiv:2202.12270v1 [cs.CV])
58. Factorizer: A Scalable Interpretable Approach to Context Modeling for Medical Image Segmentation. (arXiv:2202.12295v1 [eess.IV])
59. PSGCNet: A Pyramidal Scale and Global Context Guided Network for Dense Object Counting in Remote Sensing Images. (arXiv:2012.03597v3 [cs.CV] UPDATED)
60. FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation. (arXiv:2012.08512v3 [cs.CV] UPDATED)
61. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v4 [cs.CV] UPDATED)
62. Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
63. Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error. (arXiv:2105.13343v2 [cs.LG] UPDATED)
64. A Hybrid mmWave and Camera System for Long-Range Depth Imaging. (arXiv:2106.07856v3 [cs.CV] UPDATED)
65. Physics perception in sloshing scenes with guaranteed thermodynamic consistency. (arXiv:2106.13301v3 [cs.CV] UPDATED)
66. Feature Importance-aware Transferable Adversarial Attacks. (arXiv:2107.14185v3 [cs.CV] UPDATED)
67. BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks. (arXiv:2109.05539v4 [cs.NE] UPDATED)
68. Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning. (arXiv:2109.05664v3 [cs.CV] UPDATED)
69. CT-ICP: **Real-time** Elastic LiDAR Odometry with Loop Closure. (arXiv:2109.12979v2 [cs.RO] UPDATED)
70. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v2 [eess.IV] UPDATED)
71. 2020 CATARACTS Semantic Segmentation Challenge. (arXiv:2110.10965v2 [eess.IV] UPDATED)
72. INTERN: A New Learning Paradigm Towards General Vision. (arXiv:2111.08687v2 [cs.CV] UPDATED)
73. Lebanon Solar Rooftop Potential Assessment using Buildings Segmentation from Aerial Images. (arXiv:2111.11397v4 [cs.CV] UPDATED)
74. Object-aware Monocular Depth Prediction with Instance Convolutions. (arXiv:2112.01521v2 [cs.CV] UPDATED)
75. SGM3D: Stereo Guided Monocular 3D Object Detection. (arXiv:2112.01914v2 [cs.CV] UPDATED)
76. Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization. (arXiv:2201.13256v3 [math.OC] UPDATED)
77. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v2 [eess.IV] UPDATED)
78. Exploring Structural Sparsity in Neural Image Compression. (arXiv:2202.04595v3 [eess.IV] UPDATED)
79. REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma Assessment. (arXiv:2202.08994v2 [eess.IV] UPDATED)
80. LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v2 [cs.CV] UPDATED)
81. Multi-Teacher Knowledge Distillation for Incremental Implicitly-Refined Classification. (arXiv:2202.11384v2 [cs.CV] UPDATED)
## eess.IV
---
**22** new papers in eess.IV:-) 
1. Co-occurring Diseases Heavily Influence the Performance of Weakly Supervised Learning Models for Classification of Chest CT. (arXiv:2202.11709v1 [eess.IV])
2. ML-based Anomaly Detection in Optical Fiber Monitoring. (arXiv:2202.11756v1 [cs.CR])
3. Single Image Super-Resolution Methods: A Survey. (arXiv:2202.11763v1 [eess.IV])
4. Nuclei panoptic segmentation and composition regression with multi-task deep neural networks. (arXiv:2202.11804v1 [eess.IV])
5. Computational 3D microscopy with optical coherence refraction tomography. (arXiv:2202.11837v1 [physics.optics])
6. A Note on Machine Learning Approach for Computational Imaging. (arXiv:2202.11883v1 [eess.IV])
7. A spectral-spatial fusion anomaly detection method for hyperspectral imagery. (arXiv:2202.11889v1 [eess.IV])
8. Data variation-aware medical image segmentation. (arXiv:2202.12099v1 [eess.IV])
9. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v1 [eess.IV])
10. A novel unsupervised covid lung lesion segmentation based on the lung tissue identification. (arXiv:2202.12148v1 [eess.IV])
11. A Method for Waste Segregation using Convolutional Neural Networks. (arXiv:2202.12258v1 [cs.CV])
12. Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images. (arXiv:2202.12267v1 [eess.IV])
13. Factorizer: A Scalable Interpretable Approach to Context Modeling for Medical Image Segmentation. (arXiv:2202.12295v1 [eess.IV])
14. Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
15. Unsupervised domain adaptation for cross-modality liver segmentation via joint adversarial learning and self-learning. (arXiv:2109.05664v3 [cs.CV] UPDATED)
16. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v2 [eess.IV] UPDATED)
17. 2020 CATARACTS Semantic Segmentation Challenge. (arXiv:2110.10965v2 [eess.IV] UPDATED)
18. Universal Efficient Variable-rate Neural Image Compression. (arXiv:2111.11305v4 [eess.IV] UPDATED)
19. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v2 [eess.IV] UPDATED)
20. Exploring Structural Sparsity in Neural Image Compression. (arXiv:2202.04595v3 [eess.IV] UPDATED)
21. REFUGE2 Challenge: Treasure for Multi-Domain Learning in Glaucoma Assessment. (arXiv:2202.08994v2 [eess.IV] UPDATED)
22. LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v2 [cs.CV] UPDATED)
## cs.LG
---
**187** new papers in cs.LG:-) 
1. Flow-based sampling in the lattice Schwinger model at criticality. (arXiv:2202.11712v1 [hep-lat])
2. Completely Quantum Neural Networks. (arXiv:2202.11727v1 [quant-ph])
3. Using Bayesian Deep Learning to infer Planet Mass from Gaps in Protoplanetary Disks. (arXiv:2202.11730v1 [astro-ph.EP])
4. Truncated LinUCB for Stochastic Linear Bandits. (arXiv:2202.11735v1 [stat.ML])
5. The Need for Interpretable Features: Motivation and Taxonomy. (arXiv:2202.11748v1 [cs.LG])
6. Are All Linear Regions Created Equal?. (arXiv:2202.11749v1 [cs.LG])
7. Analysis of Coronavirus Envelope Protein with Cellular Automata (CA) Model. (arXiv:2202.11752v1 [q-bio.BM])
8. ML-based Anomaly Detection in Optical Fiber Monitoring. (arXiv:2202.11756v1 [cs.CR])
9. Single Image Super-Resolution Methods: A Survey. (arXiv:2202.11763v1 [eess.IV])
10. When do GANs replicate? On the choice of dataset size. (arXiv:2202.11765v1 [cs.LG])
11. Discovering Multiple and Diverse Directions for Cognitive Image Properties. (arXiv:2202.11772v1 [cs.CV])
12. Prune and Tune Ensembles: Low-Cost Ensemble Learning With Sparse Independent Subnetworks. (arXiv:2202.11782v1 [cs.LG])
13. Adversarially-regularized mixed effects deep learning (ARMED) models for improved interpretability, performance, and generalization on clustered data. (arXiv:2202.11783v1 [cs.LG])
14. Generative modeling via tensor train sketching. (arXiv:2202.11788v1 [math.NA])
15. Investigating the effect of binning on causal discovery. (arXiv:2202.11789v1 [cs.LG])
16. Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank Preference Bandits. (arXiv:2202.11795v1 [cs.LG])
17. Training Characteristic Functions with Reinforcement Learning: XAI-methods play Connect Four. (arXiv:2202.11797v1 [cs.LG])
18. Drawing Inductor Layout with a Reinforcement Learning Agent: Method and Application for VCO Inductors. (arXiv:2202.11798v1 [cs.AI])
19. NeuroView-RNN: It's About Time. (arXiv:2202.11811v1 [cs.LG])
20. Benefit of Interpolation in Nearest Neighbor Algorithms. (arXiv:2202.11817v1 [stat.ML])
21. Consistent Dropout for Policy Gradient Reinforcement Learning. (arXiv:2202.11818v1 [cs.LG])
22. Nowcasting the Financial Time Series with Streaming Data Analytics under Apache Spark. (arXiv:2202.11820v1 [cs.LG])
23. Physics-informed neural networks for inverse problems in supersonic flows. (arXiv:2202.11821v1 [math.NA])
24. Differentially Private Speaker Anonymization. (arXiv:2202.11823v1 [cs.SD])
25. Using Deep Learning to Detect Digitally Encoded DNA Trigger for Trojan Malware in Bio-Cyber Attacks. (arXiv:2202.11824v1 [cs.CR])
26. A modification of the conjugate direction method for motion estimation. (arXiv:2202.11831v1 [cs.CV])
27. Sky Computing: Accelerating Geo-distributed Computing in Federated Learning. (arXiv:2202.11836v1 [cs.LG])
28. Explanatory Paradigms in Neural Networks. (arXiv:2202.11838v1 [cs.LG])
29. DC and SA: Robust and Efficient Hyperparameter Optimization of Multi-subnetwork Deep Learning Models. (arXiv:2202.11841v1 [cs.LG])
30. First is Better Than Last for Training Data Influence. (arXiv:2202.11844v1 [cs.LG])
31. Robust Federated Learning with Connectivity Failures: A Semi-Decentralized Framework with Collaborative Relaying. (arXiv:2202.11850v1 [cs.DC])
32. Attainability and Optimality: The Equalized Odds Fairness Revisited. (arXiv:2202.11853v1 [cs.LG])
33. Learning Multi-Object Dynamics with Compositional Neural Radiance Fields. (arXiv:2202.11855v1 [cs.CV])
34. Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose Your Model, Not Your Loss Function. (arXiv:2202.11862v1 [cs.LG])
35. No-Regret Learning in Games is Turing Complete. (arXiv:2202.11871v1 [cs.GT])
36. A Unified Framework for Campaign Performance Forecasting in Online Display Advertising. (arXiv:2202.11877v1 [cs.LG])
37. A Note on Machine Learning Approach for Computational Imaging. (arXiv:2202.11883v1 [eess.IV])
38. Controlling Memorability of Face Images. (arXiv:2202.11896v1 [cs.CV])
39. An Efficient Binary Harris Hawks Optimization based on Quantum SVM for Cancer Classification Tasks. (arXiv:2202.11899v1 [cs.LG])
40. Robust Probabilistic Time Series Forecasting. (arXiv:2202.11910v1 [cs.LG])
41. A Rigorous Study of Integrated Gradients Method and Extensions to Internal Neuron Attributions. (arXiv:2202.11912v1 [cs.LG])
42. Machine Learning for Intrusion Detection in Industrial Control Systems: Applications, Challenges, and Recommendations. (arXiv:2202.11917v1 [cs.CR])
43. Threading the Needle of On and Off-Manifold Value Functions for Shapley Explanations. (arXiv:2202.11919v1 [cs.LG])
44. Auto-scaling Vision Transformers without Training. (arXiv:2202.11921v1 [cs.LG])
45. AutoCl : A Visual Interactive System for Automatic Deep Learning Classifier Recommendation Based on Models Performance. (arXiv:2202.11928v1 [cs.LG])
46. On Learning Mixture Models with Sparse Parameters. (arXiv:2202.11940v1 [cs.LG])
47. XAutoML: A Visual Analytics Tool for Establishing Trust in Automated Machine Learning. (arXiv:2202.11954v1 [cs.LG])
48. All You Need Is Supervised Learning: From Imitation Learning to Meta-RL With Upside Down RL. (arXiv:2202.11960v1 [cs.LG])
49. "Is not the truth the truth?": Analyzing the Impact of User Validations for Bus In/Out Detection in Smartphone-based Surveys. (arXiv:2202.11961v1 [cs.HC])
50. Large Scale Passenger Detection with Smartphone/Bus Implicit Interaction and Multisensory Unsupervised Cause-effect Learning. (arXiv:2202.11962v1 [cs.LG])
51. A general framework for adaptive two-index fusion attribute weighted naive Bayes. (arXiv:2202.11963v1 [cs.LG])
52. A Fair Empirical Risk Minimization with Generalized Entropy. (arXiv:2202.11966v1 [cs.LG])
53. Fine-grained TLS Services Classification with Reject Option. (arXiv:2202.11984v1 [cs.LG])
54. Can deep neural networks learn process model structure? An assessment framework and analysis. (arXiv:2202.11985v1 [cs.LG])
55. Predicting the impact of treatments over time with uncertainty aware neural differential equations. (arXiv:2202.11987v1 [cs.LG])
56. Rare Gems: Finding Lottery Tickets at Initialization. (arXiv:2202.12002v1 [cs.LG])
57. A fair pricing model via adversarial learning. (arXiv:2202.12008v1 [stat.ML])
58. Learning to Merge Tokens in Vision Transformers. (arXiv:2202.12015v1 [cs.CV])
59. Counterfactual Explanations for Predictive Business Process Monitoring. (arXiv:2202.12018v1 [cs.AI])
60. Validating an SVM-based neonatal seizure detection algorithm for generalizability, non-inferiority and clinical efficacy. (arXiv:2202.12023v1 [cs.LG])
61. Evolutionary Multi-Objective Reinforcement Learning Based Trajectory Control and Task Offloading in UAV-Assisted Mobile Edge Computing. (arXiv:2202.12028v1 [eess.SP])
62. Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge. (arXiv:2202.12031v1 [cs.CV])
63. Self-Training: A Survey. (arXiv:2202.12040v1 [cs.LG])
64. Exploring the Unfairness of DP-SGD Across Settings. (arXiv:2202.12058v1 [cs.LG])
65. Interfering Paths in Decision Trees: A Note on Deodata Predictors. (arXiv:2202.12064v1 [cs.LG])
66. Activation Functions: Dive into an optimal activation function. (arXiv:2202.12065v1 [cs.LG])
67. Investigating the Use of One-Class Support Vector Machine for Software Defect Prediction. (arXiv:2202.12074v1 [cs.SE])
68. SQuadMDS: a lean Stochastic Quartet MDS improving global structure preservation in neighbor embedding like t-SNE and UMAP. (arXiv:2202.12087v1 [cs.LG])
69. A Transformer-based Network for Deformable Medical Image Registration. (arXiv:2202.12104v1 [eess.IV])
70. Optimal Learning Rates of Deep Convolutional Neural Networks: Additive Ridge Functions. (arXiv:2202.12119v1 [cs.LG])
71. Temporal Convolution Domain Adaptation Learning for Crops Growth Prediction. (arXiv:2202.12120v1 [cs.LG])
72. Testing Deep Learning Models: A First Comparative Study of Multiple Testing Techniques. (arXiv:2202.12139v1 [cs.SE])
73. Tighter Expected Generalization Error Bounds via Convexity of Information Measures. (arXiv:2202.12150v1 [cs.IT])
74. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v1 [cs.CR])
75. Measuring CLEVRness: Blackbox testing of Visual Reasoning Models. (arXiv:2202.12162v1 [cs.LG])
76. Attentive Temporal Pooling for Conformer-based Streaming Language Identification in Long-form Speech. (arXiv:2202.12163v1 [eess.AS])
77. Attention Enables Zero Approximation Error. (arXiv:2202.12166v1 [cs.LG])
78. Closing the Gap between Single-User and Multi-User VoiceFilter-Lite. (arXiv:2202.12169v1 [eess.AS])
79. Overcoming a Theoretical Limitation of Self-Attention. (arXiv:2202.12172v1 [cs.LG])
80. Collaborative Training of Heterogeneous Reinforcement Learning Agents in Environments with Sparse Rewards: What and When to Share?. (arXiv:2202.12174v1 [cs.LG])
81. Clarifying MCMC-based training of modern EBMs : Contrastive Divergence versus Maximum Likelihood. (arXiv:2202.12176v1 [cs.LG])
82. Quantum Deep Reinforcement Learning for Robot Navigation Tasks. (arXiv:2202.12180v1 [cs.RO])
83. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v1 [cs.LG])
84. Sequential Asset Ranking within Nonstationary Time Series. (arXiv:2202.12186v1 [cs.CE])
85. Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review. (arXiv:2202.12205v1 [cs.AI])
86. BERTVision -- A Parameter-Efficient Approach for Question Answering. (arXiv:2202.12210v1 [cs.CL])
87. Debugging Differential Privacy: A Case Study for Privacy Auditing. (arXiv:2202.12219v1 [cs.LG])
88. An optimal scheduled learning rate for a randomized Kaczmarz algorithm. (arXiv:2202.12224v1 [math.NA])
89. Sample Efficiency of Data Augmentation Consistency Regularization. (arXiv:2202.12230v1 [cs.LG])
90. Bounding Membership Inference. (arXiv:2202.12232v1 [cs.LG])
91. A comparative study of in-air trajectories at short and long distances in online handwriting. (arXiv:2202.12237v1 [cs.CV])
92. On-line signature verification system with failure to enroll managing. (arXiv:2202.12242v1 [cs.CV])
93. Flat latent manifolds for music improvisation between human and machine. (arXiv:2202.12243v1 [cs.SD])
94. EMOTHAW: A novel database for emotional state recognition from handwriting. (arXiv:2202.12245v1 [cs.CV])
95. Exact Community Recovery over Signed Graphs. (arXiv:2202.12255v1 [cs.SI])
96. Integration of neural network and fuzzy logic decision making compared with bilayered neural network in the simulation of daily dew point temperature. (arXiv:2202.12256v1 [cs.LG])
97. A Perceptual Measure for Evaluating the Resynthesis of Automatic Music Transcriptions. (arXiv:2202.12257v1 [cs.SD])
98. On the Omnipresence of Spurious Local Minima in Certain Neural Network Training Problems. (arXiv:2202.12262v1 [cs.LG])
99. Effect Identification in Cluster Causal Diagrams. (arXiv:2202.12263v1 [stat.ME])
100. Clustering Edges in Directed Graphs. (arXiv:2202.12265v1 [cs.SI])
101. Inflation of test accuracy due to data leakage in deep learning-based classification of OCT images. (arXiv:2202.12267v1 [eess.IV])
102. Systematic review of deep learning and machine learning for building energy. (arXiv:2202.12269v1 [cs.LG])
103. Evaluating Feature Attribution Methods in the Image Domain. (arXiv:2202.12270v1 [cs.CV])
104. Partitioned Variational Inference: A framework for probabilistic federated learning. (arXiv:2202.12275v1 [stat.ML])
105. On the influence of roundoff errors on the convergence of the gradient descent method with low-precision floating-point computation. (arXiv:2202.12276v1 [cs.LG])
106. Solving optimization problems with Blackwell approachability. (arXiv:2202.12277v1 [math.OC])
107. Learning Stochastic Dynamics with Statistics-Informed Neural Network. (arXiv:2202.12278v1 [cs.LG])
108. Factorizer: A Scalable Interpretable Approach to Context Modeling for Medical Image Segmentation. (arXiv:2202.12295v1 [eess.IV])
109. Embedded Ensembles: Infinite Width Limit and Operating Regimes. (arXiv:2202.12297v1 [stat.ML])
110. Capturing Failures of Large Language Models via Human Cognitive Biases. (arXiv:2202.12299v1 [cs.CL])
111. Fast Non-Bayesian Poisson Factorization for Implicit-Feedback Recommendations. (arXiv:1811.01908v5 [cs.LG] UPDATED)
112. A Multilayered Block Network Model to Forecast Large Dynamic Transportation Graphs: an Application to US Air Transport. (arXiv:1911.13136v4 [stat.ML] UPDATED)
113. Submodular Maximization in Clean Linear Time. (arXiv:2006.09327v4 [cs.DS] UPDATED)
114. Dynamic Defense Against Byzantine Poisoning Attacks in Federated Learning. (arXiv:2007.15030v2 [cs.LG] UPDATED)
115. Memorizing without overfitting: Bias, variance, and interpolation in over-parameterized models. (arXiv:2010.13933v4 [stat.ML] UPDATED)
116. Policy design in experiments with unknown interference. (arXiv:2011.08174v6 [econ.EM] UPDATED)
117. Probing Predictions on OOD Images via Nearest Categories. (arXiv:2011.08485v4 [cs.LG] UPDATED)
118. Reconfigurable Intelligent Surfaces in Action for Non-Terrestrial Networks. (arXiv:2012.00968v4 [cs.IT] UPDATED)
119. Heterogeneous Graph based Deep Learning for Biomedical Network Link Prediction. (arXiv:2102.01649v4 [cs.SI] UPDATED)
120. Quadric Hypersurface Intersection for Manifold Learning in Feature Space. (arXiv:2102.06186v2 [cs.LG] UPDATED)
121. Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm. (arXiv:2102.12238v3 [cs.LG] UPDATED)
122. Serverless Model Serving for Data Science. (arXiv:2103.02958v2 [cs.DC] UPDATED)
123. Quantitative Performance Assessment of CNN Units via Topological Entropy Calculation. (arXiv:2103.09716v4 [cs.CV] UPDATED)
124. Interpretable Unsupervised Diversity Denoising and Artefact Removal. (arXiv:2104.01374v2 [eess.IV] UPDATED)
125. Multivariate Deep Evidential Regression. (arXiv:2104.06135v4 [cs.LG] UPDATED)
126. MLDemon: Deployment Monitoring for Machine Learning Systems. (arXiv:2104.13621v5 [cs.LG] UPDATED)
127. Intelligent Zero Trust Architecture for 5G/6G Networks: Principles, Challenges, and the Role of Machine Learning in the context of O-RAN. (arXiv:2105.01478v2 [cs.NI] UPDATED)
128. Sobolev Norm Learning Rates for Conditional Mean Embeddings. (arXiv:2105.07446v3 [stat.ML] UPDATED)
129. Drawing Multiple Augmentation Samples Per Image During Training Efficiently Decreases Test Error. (arXiv:2105.13343v2 [cs.LG] UPDATED)
130. A Simple and General Debiased Machine Learning Theorem with Finite Sample Guarantees. (arXiv:2105.15197v2 [stat.ML] UPDATED)
131. Enterprise-Scale Search: Accelerating Inference for Sparse Extreme Multi-Label Ranking Trees. (arXiv:2106.02697v3 [cs.LG] UPDATED)
132. TENGraD: Time-Efficient Natural Gradient Descent with Exact Fisher-Block Inversion. (arXiv:2106.03947v3 [cs.LG] UPDATED)
133. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v4 [cs.LG] UPDATED)
134. HODA: Hardness-Oriented Detection of Model Extraction Attacks. (arXiv:2106.11424v2 [cs.LG] UPDATED)
135. Physics perception in sloshing scenes with guaranteed thermodynamic consistency. (arXiv:2106.13301v3 [cs.CV] UPDATED)
136. Disentanglement via Mechanism Sparsity Regularization: A New Principle for Nonlinear ICA. (arXiv:2107.10098v3 [stat.ML] UPDATED)
137. On Multimarginal Partial Optimal Transport: Equivalent Forms and Computational Complexity. (arXiv:2108.07992v2 [stat.ML] UPDATED)
138. High-quality Thermal Gibbs Sampling with Quantum Annealing Hardware. (arXiv:2109.01690v2 [quant-ph] UPDATED)
139. BioLCNet: Reward-modulated Locally Connected Spiking Neural Networks. (arXiv:2109.05539v4 [cs.NE] UPDATED)
140. Symbolic Brittleness in Sequence Models: on Systematic Generalization in Symbolic Mathematics. (arXiv:2109.13986v2 [cs.LG] UPDATED)
141. Formalizing the Generalization-Forgetting Trade-off in Continual Learning. (arXiv:2109.14035v3 [cs.LG] UPDATED)
142. Online Graph Learning in Dynamic Environments. (arXiv:2110.05023v2 [cs.LG] UPDATED)
143. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v2 [eess.IV] UPDATED)
144. Couple Learning for semi-supervised sound event detection. (arXiv:2110.05809v3 [cs.LG] UPDATED)
145. SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing. (arXiv:2110.07205v2 [eess.AS] UPDATED)
146. Simultaneous Missing Value Imputation and Structure Learning with Groups. (arXiv:2110.08223v2 [cs.LG] UPDATED)
147. In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications. (arXiv:2110.09461v2 [cs.AI] UPDATED)
148. A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits. (arXiv:2110.11819v4 [cs.LG] UPDATED)
149. Conditionally Gaussian PAC-Bayes. (arXiv:2110.11886v2 [cs.LG] UPDATED)
150. Covariance-Generalized Matching Component Analysis for Data Fusion and Transfer Learning. (arXiv:2110.13194v2 [cs.LG] UPDATED)
151. Resampling Base Distributions of Normalizing Flows. (arXiv:2110.15828v2 [stat.ML] UPDATED)
152. Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization. (arXiv:2111.00705v2 [cs.LG] UPDATED)
153. Robust Deep Learning from Crowds with Belief Propagation. (arXiv:2111.00734v2 [cs.LG] UPDATED)
154. Identifying causal relations in tweets using deep learning: Use case on diabetes-related tweets from 2017-2021. (arXiv:2111.01225v4 [cs.CL] UPDATED)
155. Equivariant Deep Dynamical Model for Motion Prediction. (arXiv:2111.01892v2 [cs.LG] UPDATED)
156. Self-Supervised Radio-Visual Representation Learning for 6G Sensing. (arXiv:2111.02887v2 [cs.NI] UPDATED)
157. Fast and Scalable Spike and Slab Variable Selection in High-Dimensional Gaussian Processes. (arXiv:2111.04558v2 [stat.ML] UPDATED)
158. Double Control Variates for Gradient Estimation in Discrete Latent Variable Models. (arXiv:2111.05300v2 [stat.ML] UPDATED)
159. INTERN: A New Learning Paradigm Towards General Vision. (arXiv:2111.08687v2 [cs.CV] UPDATED)
160. Universal Efficient Variable-rate Neural Image Compression. (arXiv:2111.11305v4 [eess.IV] UPDATED)
161. Adaptive Multi-Goal Exploration. (arXiv:2111.12045v2 [cs.LG] UPDATED)
162. Object-aware Monocular Depth Prediction with Instance Convolutions. (arXiv:2112.01521v2 [cs.CV] UPDATED)
163. Real-world challenges for multi-agent reinforcement learning in grid-interactive buildings. (arXiv:2112.06127v2 [cs.LG] UPDATED)
164. Step-unrolled Denoising Autoencoders for Text Generation. (arXiv:2112.06749v2 [cs.CL] UPDATED)
165. An Alternate Policy Gradient Estimator for Softmax Policies. (arXiv:2112.11622v2 [cs.LG] UPDATED)
166. A Survey on Interpretable Reinforcement Learning. (arXiv:2112.13112v2 [cs.LG] UPDATED)
167. Separation of Scales and a Thermodynamic Description of Feature Learning in Some CNNs. (arXiv:2112.15383v2 [stat.ML] UPDATED)
168. Analyzing Micro-Founded General Equilibrium Models with Many Agents using Deep Reinforcement Learning. (arXiv:2201.01163v2 [cs.GT] UPDATED)
169. Block Policy Mirror Descent. (arXiv:2201.05756v2 [cs.LG] UPDATED)
170. Neighborhood Region Smoothing Regularization for Finding Flat Minima In Deep Neural Networks. (arXiv:2201.06064v2 [cs.LG] UPDATED)
171. Time Series Generation with Masked Autoencoder. (arXiv:2201.07006v2 [cs.LG] UPDATED)
172. Cognitive Explainers of Graph Neural Networks Based on Medical Concepts. (arXiv:2201.07798v2 [cs.LG] UPDATED)
173. Reinforcement Learning for Personalized Drug Discovery and Design for Complex Diseases: A Systems Pharmacology Perspective. (arXiv:2201.08894v3 [q-bio.BM] UPDATED)
174. Multiscale Generative Models: Improving Performance of a Generative Model Using Feedback from Other Dependent Generative Models. (arXiv:2201.09644v2 [cs.LG] UPDATED)
175. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v2 [eess.IV] UPDATED)
176. Fourier Representations for Black-Box Optimization over Categorical Variables. (arXiv:2202.03712v2 [cs.LG] UPDATED)
177. Exploring Structural Sparsity in Neural Image Compression. (arXiv:2202.04595v3 [eess.IV] UPDATED)
178. Robust Bayesian Inference for Simulator-based Models via the MMD Posterior Bootstrap. (arXiv:2202.04744v2 [stat.ME] UPDATED)
179. Learning Latent Causal Dynamics. (arXiv:2202.04828v4 [stat.ML] UPDATED)
180. Game of Privacy: Towards Better Federated Platform Collaboration under Privacy Restriction. (arXiv:2202.05139v2 [cs.LG] UPDATED)
181. Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning. (arXiv:2202.05338v2 [cs.CY] UPDATED)
182. Learning from distinctive candidates to optimize reduced-precision convolution program on tensor cores. (arXiv:2202.06819v2 [cs.LG] UPDATED)
183. Quantifying Memorization Across Neural Language Models. (arXiv:2202.07646v2 [cs.LG] UPDATED)
184. On Optimal Early Stopping: Over-informative versus Under-informative Parametrization. (arXiv:2202.09885v2 [cs.LG] UPDATED)
185. Personalized PATE: Differential Privacy for Machine Learning with Individual Privacy Guarantees. (arXiv:2202.10517v2 [cs.LG] UPDATED)
186. Ligandformer: A Graph Neural Network for Predicting Compound Property with Robust Interpretation. (arXiv:2202.10873v3 [q-bio.BM] UPDATED)
187. Study of Feature Importance for Quantum Machine Learning Models. (arXiv:2202.11204v2 [quant-ph] UPDATED)
## cs.AI
---
**78** new papers in cs.AI:-) 
1. When do GANs replicate? On the choice of dataset size. (arXiv:2202.11765v1 [cs.LG])
2. From Unstructured Text to Causal Knowledge Graphs: A Transformer-Based Approach. (arXiv:2202.11768v1 [cs.AI])
3. Art Creation with Multi-Conditional StyleGANs. (arXiv:2202.11777v1 [cs.CV])
4. Exploiting Correlation to Achieve Faster Learning Rates in Low-Rank Preference Bandits. (arXiv:2202.11795v1 [cs.LG])
5. Drawing Inductor Layout with a Reinforcement Learning Agent: Method and Application for VCO Inductors. (arXiv:2202.11798v1 [cs.AI])
6. Investigations of Performance and Bias in Human-AI Teamwork in Hiring. (arXiv:2202.11812v1 [cs.HC])
7. Consistent Dropout for Policy Gradient Reinforcement Learning. (arXiv:2202.11818v1 [cs.LG])
8. Near Perfect GAN Inversion. (arXiv:2202.11833v1 [cs.CV])
9. Sky Computing: Accelerating Geo-distributed Computing in Federated Learning. (arXiv:2202.11836v1 [cs.LG])
10. CAISE: Conversational Agent for Image Search and Editing. (arXiv:2202.11847v1 [cs.CL])
11. Loss as the Inconsistency of a Probabilistic Dependency Graph: Choose Your Model, Not Your Loss Function. (arXiv:2202.11862v1 [cs.LG])
12. M2I: From Factored Marginal Trajectory Prediction to Interactive Prediction. (arXiv:2202.11884v1 [cs.RO])
13. Improving Robustness of Convolutional Neural Networks Using Element-Wise Activation Scaling. (arXiv:2202.11898v1 [cs.CV])
14. Program Synthesis for the OEIS. (arXiv:2202.11908v1 [cs.AI])
15. When Transformer Meets Robotic Grasping: Exploits Context for Efficient Grasp Detection. (arXiv:2202.11911v1 [cs.RO])
16. Phase Continuity: Learning Derivatives of Phase Spectrum for Speech **Enhancement**. (arXiv:2202.11918v1 [cs.SD])
17. Threading the Needle of On and Off-Manifold Value Functions for Shapley Explanations. (arXiv:2202.11919v1 [cs.LG])
18. Temporal Efficient Training of Spiking Neural Network via Gradient Re-weighting. (arXiv:2202.11946v1 [cs.NE])
19. XAutoML: A Visual Analytics Tool for Establishing Trust in Automated Machine Learning. (arXiv:2202.11954v1 [cs.LG])
20. Cognitive Semantic Communication Systems Driven by Knowledge Graph. (arXiv:2202.11958v1 [cs.AI])
21. All You Need Is Supervised Learning: From Imitation Learning to Meta-RL With Upside Down RL. (arXiv:2202.11960v1 [cs.LG])
22. Rare Gems: Finding Lottery Tickets at Initialization. (arXiv:2202.12002v1 [cs.LG])
23. IBIA: Bayesian Inference via Incremental Build-Infer-Approximate operations on Clique Trees. (arXiv:2202.12003v1 [cs.AI])
24. Parameterized Intractability for Multi-Winner Election under the Chamberlin-Courant Rule and the Monroe Rule. (arXiv:2202.12006v1 [cs.MA])
25. A fair pricing model via adversarial learning. (arXiv:2202.12008v1 [stat.ML])
26. Counterfactual Explanations for Predictive Business Process Monitoring. (arXiv:2202.12018v1 [cs.AI])
27. Assessing generalisability of deep learning-based polyp detection and segmentation methods through a computer vision challenge. (arXiv:2202.12031v1 [cs.CV])
28. Metacognitive Agents for Ethical Decision Support: Conceptual Model and Research Roadmap. (arXiv:2202.12039v1 [cs.AI])
29. Investigating the Use of One-Class Support Vector Machine for Software Defect Prediction. (arXiv:2202.12074v1 [cs.SE])
30. Phrase-Based Affordance Detection via Cyclic **Bilateral** Interaction. (arXiv:2202.12076v1 [cs.CV])
31. KESA: A Knowledge Enhanced Approach For Sentiment Analysis. (arXiv:2202.12093v1 [cs.CL])
32. From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems. (arXiv:2202.12107v1 [cs.AI])
33. Prompt for Extraction? PAIE: Prompting Argument Interaction for Event Argument Extraction. (arXiv:2202.12109v1 [cs.CL])
34. Towards Effective and Robust Neural Trojan Defenses via Input Filtering. (arXiv:2202.12154v1 [cs.CR])
35. Measuring CLEVRness: Blackbox testing of Visual Reasoning Models. (arXiv:2202.12162v1 [cs.LG])
36. Collaborative Training of Heterogeneous Reinforcement Learning Agents in Environments with Sparse Rewards: What and When to Share?. (arXiv:2202.12174v1 [cs.LG])
37. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v1 [cs.LG])
38. Situational Graphs for Robot Navigation in Structured Indoor Environments. (arXiv:2202.12197v1 [cs.RO])
39. Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review. (arXiv:2202.12205v1 [cs.AI])
40. BLPnet: A new DNN model and Bengali OCR engine for Automatic License Plate Recognition. (arXiv:2202.12250v1 [cs.CV])
41. Learning from the Pros: Extracting Professional Goalkeeper Technique from Broadcast Footage. (arXiv:2202.12259v1 [cs.CV])
42. Self-organising Urban Traffic control on micro-level using Reinforcement Learning and Agent-based Modelling. (arXiv:2202.12260v1 [cs.AI])
43. Effect Identification in Cluster Causal Diagrams. (arXiv:2202.12263v1 [stat.ME])
44. Matching Papers and Reviewers at Large Conferences. (arXiv:2202.12273v1 [cs.AI])
45. Learning Stochastic Dynamics with Statistics-Informed Neural Network. (arXiv:2202.12278v1 [cs.LG])
46. Toward More Meaningful Resources for Lower-resourced Languages. (arXiv:2202.12288v1 [cs.CL])
47. Capturing Failures of Large Language Models via Human Cognitive Biases. (arXiv:2202.12299v1 [cs.CL])
48. The Square Root Agreement Rule for Incentivizing Truthful Feedback on Online Platforms. (arXiv:1507.07045v5 [cs.GT] UPDATED)
49. Dynamic Defense Against Byzantine Poisoning Attacks in Federated Learning. (arXiv:2007.15030v2 [cs.LG] UPDATED)
50. Heterogeneous Graph based Deep Learning for Biomedical Network Link Prediction. (arXiv:2102.01649v4 [cs.SI] UPDATED)
51. Serverless Model Serving for Data Science. (arXiv:2103.02958v2 [cs.DC] UPDATED)
52. RetGen: A Joint framework for Retrieval and Grounded Text Generation Modeling. (arXiv:2105.06597v4 [cs.CL] UPDATED)
53. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v4 [cs.LG] UPDATED)
54. A Theory of Consciousness from a Theoretical Computer Science Perspective: Insights from the Conscious Turing Machine. (arXiv:2107.13704v7 [cs.AI] UPDATED)
55. Formalizing the Generalization-Forgetting Trade-off in Continual Learning. (arXiv:2109.14035v3 [cs.LG] UPDATED)
56. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v2 [eess.IV] UPDATED)
57. In a Nutshell, the Human Asked for This: Latent Goals for Following Temporal Specifications. (arXiv:2110.09461v2 [cs.AI] UPDATED)
58. Resampling Base Distributions of Normalizing Flows. (arXiv:2110.15828v2 [stat.ML] UPDATED)
59. Communication-Compressed Adaptive Gradient Method for Distributed Nonconvex Optimization. (arXiv:2111.00705v2 [cs.LG] UPDATED)
60. Robust Deep Learning from Crowds with Belief Propagation. (arXiv:2111.00734v2 [cs.LG] UPDATED)
61. Identifying causal relations in tweets using deep learning: Use case on diabetes-related tweets from 2017-2021. (arXiv:2111.01225v4 [cs.CL] UPDATED)
62. Equivariant Deep Dynamical Model for Motion Prediction. (arXiv:2111.01892v2 [cs.LG] UPDATED)
63. The Partially Observable History Process. (arXiv:2111.08102v2 [cs.AI] UPDATED)
64. INTERN: A New Learning Paradigm Towards General Vision. (arXiv:2111.08687v2 [cs.CV] UPDATED)
65. Real-world challenges for multi-agent reinforcement learning in grid-interactive buildings. (arXiv:2112.06127v2 [cs.LG] UPDATED)
66. An Alternate Policy Gradient Estimator for Softmax Policies. (arXiv:2112.11622v2 [cs.LG] UPDATED)
67. A Survey on Interpretable Reinforcement Learning. (arXiv:2112.13112v2 [cs.LG] UPDATED)
68. Analyzing Micro-Founded General Equilibrium Models with Many Agents using Deep Reinforcement Learning. (arXiv:2201.01163v2 [cs.GT] UPDATED)
69. Block Policy Mirror Descent. (arXiv:2201.05756v2 [cs.LG] UPDATED)
70. Cognitive Explainers of Graph Neural Networks Based on Medical Concepts. (arXiv:2201.07798v2 [cs.LG] UPDATED)
71. Model-Free Reinforcement Learning for Symbolic Automata-encoded Objectives. (arXiv:2202.02404v2 [cs.AI] UPDATED)
72. Fourier Representations for Black-Box Optimization over Categorical Variables. (arXiv:2202.03712v2 [cs.LG] UPDATED)
73. Learning Latent Causal Dynamics. (arXiv:2202.04828v4 [stat.ML] UPDATED)
74. Accountability in an Algorithmic Society: Relationality, Responsibility, and Robustness in Machine Learning. (arXiv:2202.05338v2 [cs.CY] UPDATED)
75. Learning from distinctive candidates to optimize reduced-precision convolution program on tensor cores. (arXiv:2202.06819v2 [cs.LG] UPDATED)
76. Geometric Algebra based Embeddings for Static and Temporal Knowledge Graph Completion. (arXiv:2202.09464v2 [cs.AI] UPDATED)
77. Reward Modeling for Mitigating Toxicity in Transformer-based Language Models. (arXiv:2202.09662v3 [cs.CL] UPDATED)
78. DeepShovel: An Online Collaborative Platform for Data Extraction in Geoscience Literature with AI Assistance. (arXiv:2202.10163v2 [cs.HC] UPDATED)

