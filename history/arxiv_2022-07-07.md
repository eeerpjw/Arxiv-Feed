# Your interest papers
---
## cs.CV
---
### Array Camera Image Fusion using Physics-Aware Transformers. (arXiv:2207.02250v1 [cs.CV])
- Authors : Qian Huang, Minghao Hu, David Jones
- Link : [http://arxiv.org/abs/2207.02250](http://arxiv.org/abs/2207.02250)
> ABSTRACT  :  We demonstrate a physics-aware transformer for feature-based data fusion from cameras with diverse resolution, color spaces, focal planes, focal lengths, and **exposure**. We also demonstrate a scalable solution for synthetic training data generation for the transformer using open-source computer graphics software. We demonstrate image synthesis on arrays with diverse spectral responses, instantaneous field of view and frame rate.  
### Effectivity of super resolution convolutional neural network for the **enhancement** of land cover classification from medium resolution satellite images. (arXiv:2207.02301v1 [cs.CV])
- Authors : Pritom Bose, Debolina Halder, Oliur Rahman, Turash Haque
- Link : [http://arxiv.org/abs/2207.02301](http://arxiv.org/abs/2207.02301)
> ABSTRACT  :  In the modern world, satellite images play a key role in forest management and degradation monitoring. For a precise quantification of forest land cover changes, the availability of spatially fine resolution data is a necessity. Since 1972, NASAs LANDSAT Satellites are providing terrestrial images covering every corner of the earth, which have been proved to be a highly useful resource for terrestrial change analysis and have been used in numerous other sectors. However, freely accessible satellite images are, generally, of medium to low resolution which is a major hindrance to the precision of the analysis. Hence, we performed a comprehensive study to prove our point that, **enhancement** of resolution by Super-Resolution Convolutional Neural Network (SRCNN) will lessen the chance of misclassification of pixels, even under the established recognition methods. We tested the method on original LANDSAT-7 images of different regions of Sundarbans and their upscaled versions which were produced by bilinear interpolation, bicubic interpolation, and SRCNN respectively and it was discovered that SRCNN outperforms the others by a significant amount.  
### S**NeRF**: Stylized Neural Implicit Representations for 3D Scenes. (arXiv:2207.02363v1 [cs.CV])
- Authors : Thu Nguyen, Feng Liu, Lei Xiao
- Link : [http://arxiv.org/abs/2207.02363](http://arxiv.org/abs/2207.02363)
> ABSTRACT  :  This paper presents a stylized novel view synthesis method. Applying state-of-the-art stylization methods to novel views frame by frame often causes jittering artifacts due to the lack of cross-view consistency. Therefore, this paper investigates 3D scene stylization that provides a strong inductive bias for consistent novel view synthesis. Specifically, we adopt the emerging neural radiance fields (**NeRF**) as our choice of 3D scene representation for their capability to render high-quality novel views for a variety of scenes. However, as rendering a novel view from a **NeRF** requires a large number of samples, training a stylized **NeRF** requires a large amount of GPU memory that goes beyond an off-the-shelf GPU capacity. We introduce a new training method to address this problem by alternating the **NeRF** and stylization optimization steps. Such a method enables us to make full use of our hardware memory capacity to both generate images at higher resolution and adopt more expressive image style transfer methods. Our experiments show that our method produces stylized **NeRF**s for a wide range of content, including indoor, outdoor and dynamic scenes, and synthesizes high-quality novel views with cross-view consistency.  
### **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
- Authors : Jiahao Huang, Xiaodan Xing, Zhifan Gao, Guang Yang
- Link : [http://arxiv.org/abs/2207.02390](http://arxiv.org/abs/2207.02390)
> ABSTRACT  :  Fast MRI aims to reconstruct a high fidelity image from partially observed measurements. Exuberant development in fast MRI using deep learning has been witnessed recently. Meanwhile, novel deep learning paradigms, e.g., Transformer based models, are fast-growing in natural language processing and promptly developed for computer vision and medical image analysis due to their prominent performance. Nevertheless, due to the complexity of the Transformer, the application of fast MRI may not be straightforward. The main obstacle is the computational cost of the self-attention layer, which is the core part of the Transformer, can be expensive for high resolution MRI inputs. In this study, we propose a new Transformer architecture for solving fast MRI that coupled Shifted Windows Transformer with U-Net to reduce the network complexity. We incorporate deformable attention to construe the explainability of our reconstruction model. We empirically demonstrate that our method achieves consistently superior performance on the fast MRI task. Besides, compared to state-of-the-art Transformer models, our method has fewer network parameters while revealing explainability. The code is publicly available at https://github.com/ayanglab/SDAUT.  
### A Novel Hybrid Endoscopic Dataset for Evaluating Machine Learning-based Photometric Image **Enhancement** Models. (arXiv:2207.02396v1 [eess.IV])
- Authors : Axel Garcia, Ricardo Espinosa, Gilberto Ochoa, Thomas Bazin, Luis Eduardo, Dominique Lamarque, Christian Daul
- Link : [http://arxiv.org/abs/2207.02396](http://arxiv.org/abs/2207.02396)
> ABSTRACT  :  Endoscopy is the most widely used medical technique for cancer and polyp detection inside hollow organs. However, images acquired by an endoscope are frequently affected by illumination artefacts due to the enlightenment source orientation. There exist two major issues when the endoscope's light source pose suddenly changes: overexposed and underexposed tissue areas are produced. These two scenarios can result in misdiagnosis due to the lack of information in the affected zones or hamper the performance of various computer vision methods (e.g., SLAM, structure from motion, optical flow) used during the non invasive examination. The aim of this work is two-fold: i) to introduce a new synthetically generated data-set generated by a generative adversarial techniques and ii) and to explore both shallow based and deep learning-based image-**enhancement** methods in overexposed and underexposed lighting conditions. Best quantitative results (i.e., metric based results), were obtained by the deep-learnnig-based LMSPEC method,besides a running time around 7.6 fps)  
### Multi-area Target Individual Detection with Free Drawing on Video. (arXiv:2207.02467v1 [cs.CV])
- Authors : Jinwei Lin
- Link : [http://arxiv.org/abs/2207.02467](http://arxiv.org/abs/2207.02467)
> ABSTRACT  :  This paper has provided a novel design idea and some implementation methods to make a **real time** detection of multi-areas with multiple detecting areas that are generated by the **real time** drawing on the screen display of the video. The drawing on the video will remain the output as polylines, and the colors of the outlines will change when the stage of drawing or detecting is changed. The shape of the drawn area is free to be customized and real-time effective. The configuration of the drawn areas can be renewed and the detecting areas are working individually. The detection result should be shown with a GUI designed by Tkinter. The object recognition model was developed on YOLOv5 but can be changed to others, which means the core design and implementation idea of this paper is model-independent. With PIL and OpenCV and Tkinter, the drawing effect is **real time** and efficient. The design and code of this research is basic and can be extended to be implemented in numerous monitoring and detecting situations.  
### Learning Regularized Multi-Scale Feature Flow for **High Dynamic Range** Imaging. (arXiv:2207.02539v1 [cs.CV])
- Authors : Qian Ye, Masanori Suganuma, Jun Xiao, Takayuki Okatani
- Link : [http://arxiv.org/abs/2207.02539](http://arxiv.org/abs/2207.02539)
> ABSTRACT  :  Reconstructing ghosting-free **high dynamic range** (**HDR**) images of dynamic scenes from a set of multi-**exposure** images is a challenging task, especially with large object motion and occlusions, leading to visible artifacts using existing methods. To address this problem, we propose a deep network that tries to learn multi-scale feature flow guided by the regularized loss. It first extracts multi-scale features and then aligns features from non-reference images. After alignment, we use residual channel attention blocks to merge the features from different images. Extensive qualitative and quantitative comparisons show that our approach achieves state-of-the-art performance and produces excellent results where color artifacts and geometric distortions are significantly reduced.  
### VMRF: View Matching Neural Radiance Fields. (arXiv:2207.02621v1 [cs.CV])
- Authors : Jiahui Zhang, Fangneng Zhan, Rongliang Wu, Yingchen Yu, Wenqing Zhang, Bai Song, Xiaoqin Zhang, Shijian Lu
- Link : [http://arxiv.org/abs/2207.02621](http://arxiv.org/abs/2207.02621)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**) have demonstrated very impressive performance in novel view synthesis via implicitly modelling 3D representations from multi-view 2D images. However, most existing studies train **NeRF** models with either reasonable camera pose initialization or manually-crafted camera pose distributions which are often unavailable or hard to acquire in various real-world data. We design VMRF, an innovative view matching **NeRF** that enables effective **NeRF** training without requiring prior knowledge in camera poses or camera pose distributions. VMRF introduces a view matching scheme, which exploits unbalanced optimal transport to produce a feature transport plan for mapping a rendered image with randomly initialized camera pose to the corresponding real image. With the feature transport plan as the guidance, a novel pose calibration technique is designed which rectifies the initially randomized camera poses by predicting relative pose transformations between the pair of rendered and real images. Extensive experiments over a number of synthetic and real datasets show that the proposed VMRF outperforms the state-of-the-art qualitatively and quantitatively by large margins.  
### Learning Discriminative Shrinkage Deep Networks for Image Deconvolution. (arXiv:2111.13876v2 [cs.CV] UPDATED)
- Authors : Hung Kuo, Jinshan Pan, Yi Chien, Hsuan Yang
- Link : [http://arxiv.org/abs/2111.13876](http://arxiv.org/abs/2111.13876)
> ABSTRACT  :  Most existing methods usually formulate the non-blind deconvolution problem into a maximum-a-posteriori framework and address it by manually designing kinds of regularization terms and data terms of the latent clear images. However, explicitly designing these two terms is quite challenging and usually leads to complex optimization problems which are difficult to solve. In this paper, we propose an effective non-blind deconvolution approach by learning discriminative shrinkage functions to implicitly model these terms. In contrast to most existing methods that use deep convolutional neural networks (CNNs) or radial basis functions to simply learn the regularization term, we formulate both the data term and regularization term and split the deconvolution model into data-related and regularization-related sub-problems according to the alternating direction method of multipliers. We explore the properties of the Maxout function and develop a deep CNN model with a Maxout layer to learn discriminative shrinkage functions to directly approximate the solutions of these two sub-problems. Moreover, given the fast-Fourier-transform-based image **restoration** usually leads to ringing artifacts while conjugate-gradient-based approach is time-consuming, we develop the Conjugate Gradient Network to restore the latent clear images effectively and efficiently. Experimental results show that the proposed method performs favorably against the state-of-the-art ones in terms of efficiency and accuracy.  
### Deep Learning Serves Traffic Safety Analysis: A Forward-looking Review. (arXiv:2203.10939v2 [cs.CV] UPDATED)
- Authors : Abolfazl Razi, Xiwen Chen, Huayu Li, Hao Wang, Brendan Russo, Yan Chen, Hongbin Yu
- Link : [http://arxiv.org/abs/2203.10939](http://arxiv.org/abs/2203.10939)
> ABSTRACT  :  This paper explores Deep Learning (DL) methods that are used or have the potential to be used for traffic video analysis, emphasizing driving safety for both Autonomous Vehicles (AVs) and human-operated vehicles. We present a typical processing pipeline, which can be used to understand and interpret traffic videos by extracting operational safety metrics and providing general hints and guidelines to improve traffic safety. This processing framework includes several steps, including video **enhancement**, video stabilization, semantic and incident segmentation, object detection and classification, trajectory extraction, speed estimation, event analysis, modeling and anomaly detection. Our main goal is to guide traffic analysts to develop their own custom-built processing frameworks by selecting the best choices for each step and offering new designs for the lacking modules by providing a comparative analysis of the most successful conventional and DL-based algorithms proposed for each step. We also review existing open-source tools and public datasets that can help train DL models. To be more specific, we review exemplary traffic problems and mentioned requires steps for each problem. Besides, we investigate connections to the closely related research areas of drivers' cognition evaluation, Crowd-sourcing-based monitoring systems, Edge Computing in roadside infrastructures, Automated Driving Systems (ADS)-equipped vehicles, and highlight the missing gaps. Finally, we review commercial implementations of traffic monitoring systems, their future outlook, and open problems and remaining challenges for widespread use of such systems.  
### Expression-preserving face frontalization improves visually assisted speech processing. (arXiv:2204.02810v3 [cs.CV] UPDATED)
- Authors : Zhiqi Kang, Mostafa Sadeghi, Radu Horaud, Xavier Alameda
- Link : [http://arxiv.org/abs/2204.02810](http://arxiv.org/abs/2204.02810)
> ABSTRACT  :  Face frontalization consists of synthesizing a frontally-viewed face from an arbitrarily-viewed one. The main contribution of this paper is a frontalization methodology that preserves non-rigid facial deformations in order to boost the performance of visually assisted speech communication. The method alternates between the estimation of (i)~the rigid transformation (scale, rotation, and translation) and (ii)~the non-rigid deformation between an arbitrarily-viewed face and a face model. The method has two important merits: it can deal with non-Gaussian errors in the data and it incorporates a dynamical face deformation model. For that purpose, we use the generalized Student t-distribution in combination with a linear dynamic system in order to account for both rigid head motions and time-varying facial deformations caused by speech production. We propose to use the zero-mean normalized cross-correlation (ZNCC) score to evaluate the ability of the method to preserve facial expressions. The method is thoroughly evaluated and compared with several state of the art methods, either based on traditional geometric models or on deep learning. Moreover, we show that the method, when incorporated into deep learning pipelines, namely lip reading and speech **enhancement**, improves word recognition and speech intelligibilty scores by a considerable margin. Supplemental material is accessible at https://team.inria.fr/robotlearn/research/facefrontalization-benchmark/  
### Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation. (arXiv:2205.14141v2 [cs.CV] UPDATED)
- Authors : Yixuan Wei, Han Hu, Zhenda Xie, Zheng Zhang, Yue Cao, Jianmin Bao, Dong Chen, Baining Guo
- Link : [http://arxiv.org/abs/2205.14141](http://arxiv.org/abs/2205.14141)
> ABSTRACT  :  Masked image modeling (MIM) learns representations with remarkably good fine-tuning performances, overshadowing previous prevalent pre-training approaches such as image classification, instance contrastive learning, and image-text alignment. In this paper, we show that the inferior fine-tuning performance of these pre-training approaches can be significantly improved by a simple post-processing in the form of feature distillation (FD). The feature distillation converts the old representations to new representations that have a few desirable properties just like those representations produced by MIM. These properties, which we aggregately refer to as optimization friendliness, are identified and analyzed by a set of attention- and optimization-related diagnosis tools. With these properties, the new representations show strong fine-tuning performance. Specifically, the contrastive self-supervised learning methods are made as competitive in fine-tuning as the state-of-the-art masked image modeling (MIM) algorithms. The CLIP models' fine-tuning performance is also significantly improved, with a CLIP ViT-L model reaching \textbf{89.0%} top-1 accuracy on ImageNet-1K classification. On the 3-billion-parameter **Swin**V2-G model, the fine-tuning accuracy on ADE20K semantic segmentation is improved by +1.5 mIoU to \textbf{61.4 mIoU}, creating a new record. More importantly, our work provides a way for the future research to focus more effort on the generality and scalability of the learnt representations without being pre-occupied with optimization friendliness since it can be enhanced rather easily. The code will be available at https://github.com/**Swin**Transformer/Feature-Distillation.  
## eess.IV
---
### Array Camera Image Fusion using Physics-Aware Transformers. (arXiv:2207.02250v1 [cs.CV])
- Authors : Qian Huang, Minghao Hu, David Jones
- Link : [http://arxiv.org/abs/2207.02250](http://arxiv.org/abs/2207.02250)
> ABSTRACT  :  We demonstrate a physics-aware transformer for feature-based data fusion from cameras with diverse resolution, color spaces, focal planes, focal lengths, and **exposure**. We also demonstrate a scalable solution for synthetic training data generation for the transformer using open-source computer graphics software. We demonstrate image synthesis on arrays with diverse spectral responses, instantaneous field of view and frame rate.  
### Effectivity of super resolution convolutional neural network for the **enhancement** of land cover classification from medium resolution satellite images. (arXiv:2207.02301v1 [cs.CV])
- Authors : Pritom Bose, Debolina Halder, Oliur Rahman, Turash Haque
- Link : [http://arxiv.org/abs/2207.02301](http://arxiv.org/abs/2207.02301)
> ABSTRACT  :  In the modern world, satellite images play a key role in forest management and degradation monitoring. For a precise quantification of forest land cover changes, the availability of spatially fine resolution data is a necessity. Since 1972, NASAs LANDSAT Satellites are providing terrestrial images covering every corner of the earth, which have been proved to be a highly useful resource for terrestrial change analysis and have been used in numerous other sectors. However, freely accessible satellite images are, generally, of medium to low resolution which is a major hindrance to the precision of the analysis. Hence, we performed a comprehensive study to prove our point that, **enhancement** of resolution by Super-Resolution Convolutional Neural Network (SRCNN) will lessen the chance of misclassification of pixels, even under the established recognition methods. We tested the method on original LANDSAT-7 images of different regions of Sundarbans and their upscaled versions which were produced by bilinear interpolation, bicubic interpolation, and SRCNN respectively and it was discovered that SRCNN outperforms the others by a significant amount.  
### **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
- Authors : Jiahao Huang, Xiaodan Xing, Zhifan Gao, Guang Yang
- Link : [http://arxiv.org/abs/2207.02390](http://arxiv.org/abs/2207.02390)
> ABSTRACT  :  Fast MRI aims to reconstruct a high fidelity image from partially observed measurements. Exuberant development in fast MRI using deep learning has been witnessed recently. Meanwhile, novel deep learning paradigms, e.g., Transformer based models, are fast-growing in natural language processing and promptly developed for computer vision and medical image analysis due to their prominent performance. Nevertheless, due to the complexity of the Transformer, the application of fast MRI may not be straightforward. The main obstacle is the computational cost of the self-attention layer, which is the core part of the Transformer, can be expensive for high resolution MRI inputs. In this study, we propose a new Transformer architecture for solving fast MRI that coupled Shifted Windows Transformer with U-Net to reduce the network complexity. We incorporate deformable attention to construe the explainability of our reconstruction model. We empirically demonstrate that our method achieves consistently superior performance on the fast MRI task. Besides, compared to state-of-the-art Transformer models, our method has fewer network parameters while revealing explainability. The code is publicly available at https://github.com/ayanglab/SDAUT.  
### A Novel Hybrid Endoscopic Dataset for Evaluating Machine Learning-based Photometric Image **Enhancement** Models. (arXiv:2207.02396v1 [eess.IV])
- Authors : Axel Garcia, Ricardo Espinosa, Gilberto Ochoa, Thomas Bazin, Luis Eduardo, Dominique Lamarque, Christian Daul
- Link : [http://arxiv.org/abs/2207.02396](http://arxiv.org/abs/2207.02396)
> ABSTRACT  :  Endoscopy is the most widely used medical technique for cancer and polyp detection inside hollow organs. However, images acquired by an endoscope are frequently affected by illumination artefacts due to the enlightenment source orientation. There exist two major issues when the endoscope's light source pose suddenly changes: overexposed and underexposed tissue areas are produced. These two scenarios can result in misdiagnosis due to the lack of information in the affected zones or hamper the performance of various computer vision methods (e.g., SLAM, structure from motion, optical flow) used during the non invasive examination. The aim of this work is two-fold: i) to introduce a new synthetically generated data-set generated by a generative adversarial techniques and ii) and to explore both shallow based and deep learning-based image-**enhancement** methods in overexposed and underexposed lighting conditions. Best quantitative results (i.e., metric based results), were obtained by the deep-learnnig-based LMSPEC method,besides a running time around 7.6 fps)  
## cs.LG
---
### A Tutorial on the Spectral Theory of Markov Chains. (arXiv:2207.02296v1 [cs.LG])
- Authors : Eddie Seabrook, Laurenz Wiskott
- Link : [http://arxiv.org/abs/2207.02296](http://arxiv.org/abs/2207.02296)
> ABSTRACT  :  Markov chains are a class of probabilistic models that have achieved widespread application in the quantitative sciences. This is in part due to their versatility, but is compounded by the ease with which they can be probed analytically. This tutorial provides an in-depth introduction to Markov chains, and explores their connection to graphs and random walks. We utilize tools from linear algebra and graph theory to describe the transition matrices of different types of Markov chains, with a particular focus on exploring properties of the eigenvalues and eigenvectors corresponding to these matrices. The results presented are relevant to a number of methods in machine learning and data mining, which we describe at various stages. Rather than being a novel academic study in its own right, this text presents a collection of known results, together with some new concepts. Moreover, the tutorial focuses on offering intuition to readers rather than formal understanding, and only assumes basic **exposure** to concepts from linear algebra and probability theory. It is therefore accessible to students and researchers from a wide variety of disciplines.  
### **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
- Authors : Jiahao Huang, Xiaodan Xing, Zhifan Gao, Guang Yang
- Link : [http://arxiv.org/abs/2207.02390](http://arxiv.org/abs/2207.02390)
> ABSTRACT  :  Fast MRI aims to reconstruct a high fidelity image from partially observed measurements. Exuberant development in fast MRI using deep learning has been witnessed recently. Meanwhile, novel deep learning paradigms, e.g., Transformer based models, are fast-growing in natural language processing and promptly developed for computer vision and medical image analysis due to their prominent performance. Nevertheless, due to the complexity of the Transformer, the application of fast MRI may not be straightforward. The main obstacle is the computational cost of the self-attention layer, which is the core part of the Transformer, can be expensive for high resolution MRI inputs. In this study, we propose a new Transformer architecture for solving fast MRI that coupled Shifted Windows Transformer with U-Net to reduce the network complexity. We incorporate deformable attention to construe the explainability of our reconstruction model. We empirically demonstrate that our method achieves consistently superior performance on the fast MRI task. Besides, compared to state-of-the-art Transformer models, our method has fewer network parameters while revealing explainability. The code is publicly available at https://github.com/ayanglab/SDAUT.  
### Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation. (arXiv:2205.14141v2 [cs.CV] UPDATED)
- Authors : Yixuan Wei, Han Hu, Zhenda Xie, Zheng Zhang, Yue Cao, Jianmin Bao, Dong Chen, Baining Guo
- Link : [http://arxiv.org/abs/2205.14141](http://arxiv.org/abs/2205.14141)
> ABSTRACT  :  Masked image modeling (MIM) learns representations with remarkably good fine-tuning performances, overshadowing previous prevalent pre-training approaches such as image classification, instance contrastive learning, and image-text alignment. In this paper, we show that the inferior fine-tuning performance of these pre-training approaches can be significantly improved by a simple post-processing in the form of feature distillation (FD). The feature distillation converts the old representations to new representations that have a few desirable properties just like those representations produced by MIM. These properties, which we aggregately refer to as optimization friendliness, are identified and analyzed by a set of attention- and optimization-related diagnosis tools. With these properties, the new representations show strong fine-tuning performance. Specifically, the contrastive self-supervised learning methods are made as competitive in fine-tuning as the state-of-the-art masked image modeling (MIM) algorithms. The CLIP models' fine-tuning performance is also significantly improved, with a CLIP ViT-L model reaching \textbf{89.0%} top-1 accuracy on ImageNet-1K classification. On the 3-billion-parameter **Swin**V2-G model, the fine-tuning accuracy on ADE20K semantic segmentation is improved by +1.5 mIoU to \textbf{61.4 mIoU}, creating a new record. More importantly, our work provides a way for the future research to focus more effort on the generality and scalability of the learnt representations without being pre-occupied with optimization friendliness since it can be enhanced rather easily. The code will be available at https://github.com/**Swin**Transformer/Feature-Distillation.  
## cs.AI
---
### Deep Learning Serves Traffic Safety Analysis: A Forward-looking Review. (arXiv:2203.10939v2 [cs.CV] UPDATED)
- Authors : Abolfazl Razi, Xiwen Chen, Huayu Li, Hao Wang, Brendan Russo, Yan Chen, Hongbin Yu
- Link : [http://arxiv.org/abs/2203.10939](http://arxiv.org/abs/2203.10939)
> ABSTRACT  :  This paper explores Deep Learning (DL) methods that are used or have the potential to be used for traffic video analysis, emphasizing driving safety for both Autonomous Vehicles (AVs) and human-operated vehicles. We present a typical processing pipeline, which can be used to understand and interpret traffic videos by extracting operational safety metrics and providing general hints and guidelines to improve traffic safety. This processing framework includes several steps, including video **enhancement**, video stabilization, semantic and incident segmentation, object detection and classification, trajectory extraction, speed estimation, event analysis, modeling and anomaly detection. Our main goal is to guide traffic analysts to develop their own custom-built processing frameworks by selecting the best choices for each step and offering new designs for the lacking modules by providing a comparative analysis of the most successful conventional and DL-based algorithms proposed for each step. We also review existing open-source tools and public datasets that can help train DL models. To be more specific, we review exemplary traffic problems and mentioned requires steps for each problem. Besides, we investigate connections to the closely related research areas of drivers' cognition evaluation, Crowd-sourcing-based monitoring systems, Edge Computing in roadside infrastructures, Automated Driving Systems (ADS)-equipped vehicles, and highlight the missing gaps. Finally, we review commercial implementations of traffic monitoring systems, their future outlook, and open problems and remaining challenges for widespread use of such systems.  
# Paper List
---
## cs.CV
---
**108** new papers in cs.CV:-) 
1. Guiding Machine Perception with Psychophysics. (arXiv:2207.02241v1 [cs.CV])
2. Video-based Surgical Skills Assessment using Long term Tool Tracking. (arXiv:2207.02247v1 [cs.CV])
3. Array Camera Image Fusion using Physics-Aware Transformers. (arXiv:2207.02250v1 [cs.CV])
4. OSFormer: One-Stage Camouflaged Instance Segmentation with Transformers. (arXiv:2207.02255v1 [cs.CV])
5. OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning. (arXiv:2207.02261v1 [cs.CV])
6. Towards Realistic Semi-Supervised Learning. (arXiv:2207.02269v1 [cs.CV])
7. Leveraging Trajectory Prediction for Pedestrian Video Anomaly Detection. (arXiv:2207.02279v1 [cs.CV])
8. BiPOCO: Bi-Directional Trajectory Prediction with Pose Constraints for Pedestrian Anomaly Detection. (arXiv:2207.02281v1 [cs.CV])
9. Effectivity of super resolution convolutional neural network for the **enhancement** of land cover classification from medium resolution satellite images. (arXiv:2207.02301v1 [cs.CV])
10. A Deep Ensemble Learning Approach to Lung CT Segmentation for COVID-19 Severity Assessment. (arXiv:2207.02322v1 [eess.IV])
11. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v1 [eess.IV])
12. Weakly Supervised Grounding for VQA in Vision-Language Transformers. (arXiv:2207.02334v1 [cs.CV])
13. Multi-Label Retinal Disease Classification using Transformers. (arXiv:2207.02335v1 [cs.CV])
14. Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms. (arXiv:2207.02337v1 [cs.LG])
15. Generalization to translation shifts: a study in architectures and augmentations. (arXiv:2207.02349v1 [cs.CV])
16. S**NeRF**: Stylized Neural Implicit Representations for 3D Scenes. (arXiv:2207.02363v1 [cs.CV])
17. Unsupervised Learning for Human Sensing Using Radio Signals. (arXiv:2207.02370v1 [cs.CV])
18. Domain Adaptive Video Segmentation via Temporal Pseudo Supervision. (arXiv:2207.02372v1 [cs.CV])
19. 3DG-STFM: 3D Geometric Guided Student-Teacher Feature Matching. (arXiv:2207.02375v1 [cs.CV])
20. A Comprehensive Review on Deep Supervision: Theories and Applications. (arXiv:2207.02376v1 [cs.CV])
21. Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising. (arXiv:2207.02377v1 [eess.IV])
22. **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
23. Query-Efficient Adversarial Attack Based on Latin Hypercube Sampling. (arXiv:2207.02391v1 [cs.CV])
24. AutoSpeed: A Linked Autoencoder Approach for Pulse-Echo Speed-of-Sound Imaging for Medical Ultrasound. (arXiv:2207.02392v1 [eess.IV])
25. A Novel Hybrid Endoscopic Dataset for Evaluating Machine Learning-based Photometric Image **Enhancement** Models. (arXiv:2207.02396v1 [eess.IV])
26. Spatial Transformation for Image Composition via Correspondence Learning. (arXiv:2207.02398v1 [cs.CV])
27. Learning Apparent Diffusion Coefficient Maps from Undersampled Radial k-Space Diffusion-Weighted MRI in Mice using a Deep CNN-Transformer Model in Conjunction with a Monoexponential Model. (arXiv:2207.02399v1 [eess.IV])
28. Chairs Can be Stood on: Overcoming Object Bias in Human-Object Interaction Detection. (arXiv:2207.02400v1 [cs.CV])
29. White Matter Tracts are Point Clouds: Neuropsychological Score Prediction and Critical Region Localization via Geometric Deep Learning. (arXiv:2207.02402v1 [cs.CV])
30. A Deep Model for Partial Multi-Label Image Classification with Curriculum Based Disambiguation. (arXiv:2207.02410v1 [cs.CV])
31. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. (arXiv:2207.02425v1 [cs.CV])
32. DCT-Net: Domain-Calibrated Translation for Portrait Stylization. (arXiv:2207.02426v1 [cs.CV])
33. GAMa: Cross-view Video Geo-localization. (arXiv:2207.02431v1 [cs.CV])
34. Complementary Bi-directional Feature Compression for Indoor 360{\deg} Semantic Segmentation with Self-distillation. (arXiv:2207.02437v1 [cs.CV])
35. GLENet: Boosting 3D Object Detectors with Generative Label Uncertainty Estimation. (arXiv:2207.02466v1 [cs.CV])
36. Multi-area Target Individual Detection with Free Drawing on Video. (arXiv:2207.02467v1 [cs.CV])
37. Multi-Contrast MRI Segmentation Trained on Synthetic Images. (arXiv:2207.02469v1 [eess.IV])
38. Two-stage Decision Improves Open-Set Panoptic Segmentation. (arXiv:2207.02504v1 [cs.CV])
39. Identifying and Mitigating Flaws of Deep Perceptual Similarity Metrics. (arXiv:2207.02512v1 [cs.CV])
40. Lightweight Encoder-Decoder Architecture for Foot Ulcer Segmentation. (arXiv:2207.02515v1 [eess.IV])
41. Semi-Perspective Decoupled Heatmaps for 3D Robot Pose Estimation from Depth Maps. (arXiv:2207.02519v1 [cs.CV])
42. Unsupervised Domain Adaptation through Shape Modeling for Medical Image Segmentation. (arXiv:2207.02529v1 [cs.CV])
43. Learning Regularized Multi-Scale Feature Flow for **High Dynamic Range** Imaging. (arXiv:2207.02539v1 [cs.CV])
44. Dense Teacher: Dense Pseudo-Labels for Semi-supervised Object Detection. (arXiv:2207.02541v1 [cs.CV])
45. Light-weight spatio-temporal graphs for segmentation and ejection fraction prediction in cardiac ultrasound. (arXiv:2207.02549v1 [cs.CV])
46. Is the U-Net Directional-Relationship Aware?. (arXiv:2207.02574v1 [cs.CV])
47. PIC 4th Challenge: Semantic-Assisted Multi-Feature Encoding and Multi-Head Decoding for Dense Video Captioning. (arXiv:2207.02583v1 [cs.CV])
48. FAST-VQA: Efficient End-to-end Video Quality Assessment with Fragment Sampling. (arXiv:2207.02595v1 [cs.CV])
49. Predicting is not Understanding: Recognizing and Addressing Underspecification in Machine Learning. (arXiv:2207.02598v1 [cs.LG])
50. GFNet: Geometric Flow Network for 3D Point Cloud Semantic Segmentation. (arXiv:2207.02605v1 [cs.CV])
51. DenseHybrid: Hybrid Anomaly Detection for Dense Open-set Recognition. (arXiv:2207.02606v1 [cs.CV])
52. VMRF: View Matching Neural Radiance Fields. (arXiv:2207.02621v1 [cs.CV])
53. Knowing Earlier what Right Means to You: A Comprehensive VQA Dataset for Grounding Relative Directions via Multi-Task Learning. (arXiv:2207.02624v1 [cs.CV])
54. Difference in Euclidean Norm Can Cause Semantic Divergence in Batch Normalization. (arXiv:2207.02625v1 [cs.CV])
55. Context Sensing Attention Network for Video-based Person Re-identification. (arXiv:2207.02631v1 [cs.CV])
56. Network Pruning via Feature Shift Minimization. (arXiv:2207.02632v1 [cs.CV])
57. Adversarial Robustness of Visual Dialog. (arXiv:2207.02639v1 [cs.CV])
58. Gaze-Vergence-Controlled See-Through Vision in Augmented Reality. (arXiv:2207.02645v1 [cs.CV])
59. Perceptual Quality Assessment of Omnidirectional Images. (arXiv:2207.02674v1 [cs.CV])
60. Team PKU-WICT-MIPL PIC Makeup Temporal Video Grounding Challenge 2022 Technical Report. (arXiv:2207.02687v1 [cs.CV])
61. YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors. (arXiv:2207.02696v1 [cs.CV])
62. Spike Calibration: Fast and Accurate Conversion of Spiking Neural Network for Object Detection and Segmentation. (arXiv:2207.02702v1 [cs.CV])
63. Histopathology DatasetGAN: Synthesizing Large-Resolution Histopathology Datasets. (arXiv:2207.02712v1 [eess.IV])
64. Open- and Closed-Loop Neural Network Verification using Polynomial Zonotopes. (arXiv:2207.02715v1 [cs.CV])
65. Deep Learning approach for Classifying Trusses and Runners of Strawberries. (arXiv:2207.02721v1 [cs.CV])
66. Real-Time Gesture Recognition with Virtual Glove Markers. (arXiv:2207.02729v1 [cs.CV])
67. STVGFormer: Spatio-Temporal Video Grounding with Static-Dynamic Cross-Modal Understanding. (arXiv:2207.02756v1 [cs.CV])
68. Local Relighting of Real Scenes. (arXiv:2207.02774v1 [cs.CV])
69. Cross-receptive Focused Inference Network for Lightweight Image Super-Resolution. (arXiv:2207.02796v1 [cs.CV])
70. The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning. (arXiv:2207.02797v1 [eess.IV])
71. Delving into Sequential Patches for Deepfake Detection. (arXiv:2207.02803v1 [cs.CV])
72. DPODv2: Dense Correspondence-Based 6 DoF Pose Estimation. (arXiv:2207.02805v1 [cs.CV])
73. Multi-View Object Pose Refinement With Differentiable Renderer. (arXiv:2207.02811v1 [cs.CV])
74. Towards Counterfactual Image Manipulation via CLIP. (arXiv:2207.02812v1 [cs.CV])
75. Localization Uncertainty Estimation for Anchor-Free Object Detection. (arXiv:2006.15607v6 [cs.CV] UPDATED)
76. Deep Contrastive Patch-Based Subspace Learning for Camera Image Signal Processing. (arXiv:2104.00253v3 [eess.IV] UPDATED)
77. Self-supervised Detransformation Autoencoder for Representation Learning in Open Set Recognition. (arXiv:2105.13557v2 [cs.LG] UPDATED)
78. Object Wake-up: 3D Object Rigging from a Single Image. (arXiv:2108.02708v3 [cs.CV] UPDATED)
79. DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v5 [cs.LG] UPDATED)
80. NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks. (arXiv:2110.05668v4 [cs.CV] UPDATED)
81. A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detection: Solutions and Future Challenges. (arXiv:2110.14051v3 [cs.CV] UPDATED)
82. Adversarial Mask: Real-World Universal Adversarial Attack on Face Recognition Models. (arXiv:2111.10759v2 [cs.CV] UPDATED)
83. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v4 [eess.IV] UPDATED)
84. Learning Discriminative Shrinkage Deep Networks for Image Deconvolution. (arXiv:2111.13876v2 [cs.CV] UPDATED)
85. Toward Minimal Misalignment at Minimal Cost in One-Stage and Anchor-Free Object Detection. (arXiv:2112.08902v3 [cs.CV] UPDATED)
86. Adversarial Masking for Self-Supervised Learning. (arXiv:2201.13100v3 [cs.CV] UPDATED)
87. Learning with Neighbor Consistency for Noisy Labels. (arXiv:2202.02200v2 [cs.CV] UPDATED)
88. GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v4 [cs.CV] UPDATED)
89. FUNQUE: Fusion of Unified Quality Evaluators. (arXiv:2202.11241v2 [cs.CV] UPDATED)
90. AssistQ: Affordance-centric Question-driven Task Completion for Egocentric Assistant. (arXiv:2203.04203v4 [cs.CV] UPDATED)
91. City-wide Street-to-Satellite Image Geolocalization of a Mobile Ground Agent. (arXiv:2203.05612v2 [cs.CV] UPDATED)
92. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v4 [cs.CV] UPDATED)
93. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v2 [cs.CV] UPDATED)
94. Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion. (arXiv:2203.09855v4 [cs.CV] UPDATED)
95. Deep Learning Serves Traffic Safety Analysis: A Forward-looking Review. (arXiv:2203.10939v2 [cs.CV] UPDATED)
96. Cell segmentation from telecentric bright-field transmitted light microscopy images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v3 [q-bio.QM] UPDATED)
97. A Computational Architecture for Machine Consciousness and Artificial Superintelligence: Updating Working Memory Iteratively. (arXiv:2203.17255v2 [q-bio.NC] UPDATED)
98. Expression-preserving face frontalization improves visually assisted speech processing. (arXiv:2204.02810v3 [cs.CV] UPDATED)
99. From 2D Images to 3D Model:Weakly Supervised Multi-View Face Reconstruction with Deep Fusion. (arXiv:2204.03842v2 [cs.CV] UPDATED)
100. SHREC 2022: pothole and crack detection in the road pavement using images and RGB-D data. (arXiv:2205.13326v3 [cs.CV] UPDATED)
101. Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation. (arXiv:2205.14141v2 [cs.CV] UPDATED)
102. Vision GNN: An Image is Worth Graph of Nodes. (arXiv:2206.00272v2 [cs.CV] UPDATED)
103. Uncertainty-aware Panoptic Segmentation. (arXiv:2206.14554v2 [cs.CV] UPDATED)
104. Progressive Latent Replay for efficient Generative Rehearsal. (arXiv:2207.01562v2 [cs.CV] UPDATED)
105. Adaptive Fine-Grained Sketch-Based Image Retrieval. (arXiv:2207.01723v2 [cs.CV] UPDATED)
106. Bayesian approaches for Quantifying Clinicians' Variability in Medical Image Quantification. (arXiv:2207.01868v2 [eess.IV] UPDATED)
107. Latents2Segments: Disentangling the Latent Space of Generative Models for Semantic Segmentation of Face Images. (arXiv:2207.01871v2 [cs.CV] UPDATED)
108. Multi-modal Robustness Analysis Against Language and Visual Perturbations. (arXiv:2207.02159v2 [cs.CV] UPDATED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. Transfer Learning for Rapid Extraction of Thickness from Optical Spectra of Semiconductor Thin Films. (arXiv:2207.02209v1 [cs.LG])
2. Improving Trustworthiness of AI Disease Severity Rating in Medical Imaging with Ordinal Conformal Prediction Sets. (arXiv:2207.02238v1 [cs.LG])
3. Array Camera Image Fusion using Physics-Aware Transformers. (arXiv:2207.02250v1 [cs.CV])
4. Effectivity of super resolution convolutional neural network for the **enhancement** of land cover classification from medium resolution satellite images. (arXiv:2207.02301v1 [cs.CV])
5. A Deep Ensemble Learning Approach to Lung CT Segmentation for COVID-19 Severity Assessment. (arXiv:2207.02322v1 [eess.IV])
6. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v1 [eess.IV])
7. Patch-wise Deep Metric Learning for Unsupervised Low-Dose CT Denoising. (arXiv:2207.02377v1 [eess.IV])
8. **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
9. AutoSpeed: A Linked Autoencoder Approach for Pulse-Echo Speed-of-Sound Imaging for Medical Ultrasound. (arXiv:2207.02392v1 [eess.IV])
10. A Novel Hybrid Endoscopic Dataset for Evaluating Machine Learning-based Photometric Image **Enhancement** Models. (arXiv:2207.02396v1 [eess.IV])
11. Learning Apparent Diffusion Coefficient Maps from Undersampled Radial k-Space Diffusion-Weighted MRI in Mice using a Deep CNN-Transformer Model in Conjunction with a Monoexponential Model. (arXiv:2207.02399v1 [eess.IV])
12. Highly accurate quantum optimization algorithm for CT image reconstructions based on sinogram patterns. (arXiv:2207.02448v1 [quant-ph])
13. Multi-Contrast MRI Segmentation Trained on Synthetic Images. (arXiv:2207.02469v1 [eess.IV])
14. Lightweight Encoder-Decoder Architecture for Foot Ulcer Segmentation. (arXiv:2207.02515v1 [eess.IV])
15. Modeling the HEVC Encoding Energy Using the Encoder Processing Time. (arXiv:2207.02676v1 [eess.IV])
16. Histopathology DatasetGAN: Synthesizing Large-Resolution Histopathology Datasets. (arXiv:2207.02712v1 [eess.IV])
17. The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning. (arXiv:2207.02797v1 [eess.IV])
18. Deep Contrastive Patch-Based Subspace Learning for Camera Image Signal Processing. (arXiv:2104.00253v3 [eess.IV] UPDATED)
19. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v4 [eess.IV] UPDATED)
20. Quantitative phase imaging through an ultra-thin lensless fiber endoscope. (arXiv:2112.12055v3 [physics.optics] UPDATED)
21. FUNQUE: Fusion of Unified Quality Evaluators. (arXiv:2202.11241v2 [cs.CV] UPDATED)
22. Cell segmentation from telecentric bright-field transmitted light microscopy images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v3 [q-bio.QM] UPDATED)
23. Bayesian approaches for Quantifying Clinicians' Variability in Medical Image Quantification. (arXiv:2207.01868v2 [eess.IV] UPDATED)
24. ImageBox3: No-Server Tile Serving to Traverse Whole Slide Images on the Web. (arXiv:2207.01734v2 [q-bio.QM] CROSS LISTED)
## cs.LG
---
**135** new papers in cs.LG:-) 
1. Transfer Learning for Rapid Extraction of Thickness from Optical Spectra of Semiconductor Thin Films. (arXiv:2207.02209v1 [cs.LG])
2. Improving Trustworthiness of AI Disease Severity Rating in Medical Imaging with Ordinal Conformal Prediction Sets. (arXiv:2207.02238v1 [cs.LG])
3. Guiding Machine Perception with Psychophysics. (arXiv:2207.02241v1 [cs.CV])
4. State-Augmented Learnable Algorithms for Resource Management in Wireless Networks. (arXiv:2207.02242v1 [cs.LG])
5. Learning Task Embeddings for Teamwork Adaptation in Multi-Agent Reinforcement Learning. (arXiv:2207.02249v1 [cs.MA])
6. Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia. (arXiv:2207.02253v1 [cs.CL])
7. OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning. (arXiv:2207.02261v1 [cs.CV])
8. Ultra-Low-Bitrate Speech Coding with Pretrained Transformers. (arXiv:2207.02262v1 [cs.SD])
9. Towards Realistic Semi-Supervised Learning. (arXiv:2207.02269v1 [cs.CV])
10. Cooperative Distribution Alignment via JSD Upper Bound. (arXiv:2207.02286v1 [cs.LG])
11. Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs. (arXiv:2207.02295v1 [cs.NI])
12. A Tutorial on the Spectral Theory of Markov Chains. (arXiv:2207.02296v1 [cs.LG])
13. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v1 [eess.IV])
14. Unified Embeddings of Structural and Functional Connectome via a Function-Constrained Structural Graph Variational Auto-Encoder. (arXiv:2207.02328v1 [q-bio.NC])
15. Multi-Label Retinal Disease Classification using Transformers. (arXiv:2207.02335v1 [cs.CV])
16. Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms. (arXiv:2207.02337v1 [cs.LG])
17. Rethinking the Importance of Sampling in Physics-informed Neural Networks. (arXiv:2207.02338v1 [cs.LG])
18. Many-body localized hidden Born machine. (arXiv:2207.02346v1 [quant-ph])
19. Generalization to translation shifts: a study in architectures and augmentations. (arXiv:2207.02349v1 [cs.CV])
20. Instance-optimal PAC Algorithms for Contextual Bandits. (arXiv:2207.02357v1 [stat.ML])
21. Linear Jamming Bandits: Sample-Efficient Learning for Non-Coherent Digital Jamming. (arXiv:2207.02365v1 [cs.LG])
22. Text Enriched Sparse Hyperbolic Graph Convolutional Networks. (arXiv:2207.02368v1 [cs.IR])
23. Ensemble feature selection with clustering for analysis of high-dimensional, correlated clinical data in the search for Alzheimer's disease biomarkers. (arXiv:2207.02380v1 [cs.LG])
24. **Swin** Deformable Attention U-Net Transformer (SDAUT) for Explainable Fast MRI. (arXiv:2207.02390v1 [cs.CV])
25. Query-Efficient Adversarial Attack Based on Latin Hypercube Sampling. (arXiv:2207.02391v1 [cs.CV])
26. AutoSpeed: A Linked Autoencoder Approach for Pulse-Echo Speed-of-Sound Imaging for Medical Ultrasound. (arXiv:2207.02392v1 [eess.IV])
27. Careful seeding for the k-medoids algorithm with incremental k++ cluster construction. (arXiv:2207.02404v1 [cs.LG])
28. A Deep Model for Partial Multi-Label Image Classification with Curriculum Based Disambiguation. (arXiv:2207.02410v1 [cs.CV])
29. BioTABQA: Instruction Learning for Biomedical Table Question Answering. (arXiv:2207.02419v1 [cs.CL])
30. Composite FORCE learning of chaotic echo state networks for time-series prediction. (arXiv:2207.02420v1 [cs.LG])
31. GAMa: Cross-view Video Geo-localization. (arXiv:2207.02431v1 [cs.CV])
32. EEPT: Early Discovery of Emerging Entities in Twitter with Semantic Similarity. (arXiv:2207.02434v1 [cs.CL])
33. PAC Prediction Sets for Meta-Learning. (arXiv:2207.02440v1 [cs.LG])
34. Transformers are Adaptable Task Planners. (arXiv:2207.02442v1 [cs.RO])
35. Distillation to Enhance the Portability of Risk Models Across Institutions with Large Patient Claims Database. (arXiv:2207.02445v1 [cs.LG])
36. Nonparametric Factor Trajectory Learning for Dynamic Tensor Decomposition. (arXiv:2207.02446v1 [cs.LG])
37. Information Compression and Performance Evaluation of Tic-Tac-Toe's Evaluation Function Using Singular Value Decomposition. (arXiv:2207.02449v1 [cs.LG])
38. Ordinal Regression via Binary Preference vs Simple Regression: Statistical and Experimental Perspectives. (arXiv:2207.02454v1 [cs.LG])
39. Multi-Contrast MRI Segmentation Trained on Synthetic Images. (arXiv:2207.02469v1 [eess.IV])
40. Quantitative Assessment of DESIS Hyperspectral Data for Plant Biodiversity Estimation in Australia. (arXiv:2207.02482v1 [cs.LG])
41. Pure Transformers are Powerful Graph Learners. (arXiv:2207.02505v1 [cs.LG])
42. Compositional Generalization in Grounded Language Learning via Induced Model Sparsity. (arXiv:2207.02518v1 [cs.CL])
43. Transformers discover an elementary calculation system exploiting local attention and grid-like problem representation. (arXiv:2207.02536v1 [cs.LG])
44. Tractable Dendritic RNNs for Reconstructing Nonlinear Dynamical Systems. (arXiv:2207.02542v1 [cs.LG])
45. AI-enhanced iterative solvers for accelerating the solution of large scale parametrized linear systems of equations. (arXiv:2207.02543v1 [math.NA])
46. Simple and Efficient Heterogeneous Graph Neural Network. (arXiv:2207.02547v1 [cs.LG])
47. voxel2vec: A Natural Language Processing Approach to Learning Distributed Representations for Scientific Data. (arXiv:2207.02565v1 [cs.LG])
48. Instance-Dependent Near-Optimal Policy Identification in Linear MDPs via Online Experiment Design. (arXiv:2207.02575v1 [cs.LG])
49. Cascaded Deep Hybrid Models for Multistep Household Energy Consumption Forecasting. (arXiv:2207.02589v1 [cs.LG])
50. Predicting is not Understanding: Recognizing and Addressing Underspecification in Machine Learning. (arXiv:2207.02598v1 [cs.LG])
51. When does SGD favor flat minima? A quantitative characterization via linear stability. (arXiv:2207.02628v1 [stat.ML])
52. Effective and Efficient Training for Sequential Recommendation using Recency Sampling. (arXiv:2207.02643v1 [cs.IR])
53. Scaling Private Deep Learning with Low-Rank and Sparse Gradients. (arXiv:2207.02699v1 [cs.LG])
54. Histopathology DatasetGAN: Synthesizing Large-Resolution Histopathology Datasets. (arXiv:2207.02712v1 [eess.IV])
55. Variational Flow Graphical Model. (arXiv:2207.02722v1 [stat.ML])
56. Pre-training Transformers for Molecular Property Prediction Using Reaction Prediction. (arXiv:2207.02724v1 [cs.LG])
57. Towards the Use of Saliency Maps for Explaining Low-Quality Electrocardiograms to End Users. (arXiv:2207.02726v1 [cs.LG])
58. A Hybrid Approach for Binary Classification of Imbalanced Data. (arXiv:2207.02738v1 [cs.LG])
59. Robust Counterfactual Explanations for Tree-Based Ensembles. (arXiv:2207.02739v1 [cs.LG])
60. Graph Trees with Attention. (arXiv:2207.02760v1 [cs.LG])
61. BFE and AdaBFE: A New Approach in Learning Rate Automation for Stochastic Optimization. (arXiv:2207.02763v1 [cs.LG])
62. Enhancing Adversarial Attacks on Single-Layer NVM Crossbar-Based Neural Networks with Power Consumption Information. (arXiv:2207.02764v1 [cs.LG])
63. DIWIFT: Discovering Instance-wise Influential Features for Tabular Data. (arXiv:2207.02773v1 [cs.LG])
64. Astroconformer: Inferring Surface Gravity of Stars from Stellar Light Curves with Transformer. (arXiv:2207.02787v1 [astro-ph.SR])
65. Private Matrix Approximation and Geometry of Unitary Orbits. (arXiv:2207.02794v1 [cs.DS])
66. The Intrinsic Manifolds of Radiological Images and their Role in Deep Learning. (arXiv:2207.02797v1 [eess.IV])
67. A multi-task network approach for calculating discrimination-free insurance prices. (arXiv:2207.02799v1 [cs.LG])
68. Improved conformalized quantile regression. (arXiv:2207.02808v1 [stat.ML])
69. Strong Heuristics for Named Entity Linking. (arXiv:2207.02824v1 [cs.CL])
70. Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods. (arXiv:2207.02829v1 [math.OC])
71. When does Bias Transfer in Transfer Learning?. (arXiv:2207.02842v1 [cs.LG])
72. Quantum Logic Gate Synthesis as a Markov Decision Process. (arXiv:1912.12002v2 [quant-ph] UPDATED)
73. Federated Neural Architecture Search. (arXiv:2002.06352v5 [cs.LG] UPDATED)
74. MoTiAC: Multi-Objective Actor-Critics for Real-Time Bidding. (arXiv:2002.07408v2 [cs.AI] UPDATED)
75. Clustering with Semidefinite Programming and Fixed Point Iteration. (arXiv:2012.09202v3 [math.OC] UPDATED)
76. Novel Techniques to Assess Predictive Systems and Reduce Their Alarm Burden. (arXiv:2102.05691v3 [cs.LG] UPDATED)
77. Predicting Kidney Transplant Survival using Multiple Feature Representations for HLAs. (arXiv:2103.03305v2 [cs.LG] UPDATED)
78. Landscape analysis for shallow neural networks: complete classification of critical points for affine target functions. (arXiv:2103.10922v3 [cs.LG] UPDATED)
79. Deep Contrastive Patch-Based Subspace Learning for Camera Image Signal Processing. (arXiv:2104.00253v3 [eess.IV] UPDATED)
80. Topological Information Retrieval with Dilation-Invariant Bottleneck Comparative Measures. (arXiv:2104.01672v3 [stat.ML] UPDATED)
81. Self-supervised Detransformation Autoencoder for Representation Learning in Open Set Recognition. (arXiv:2105.13557v2 [cs.LG] UPDATED)
82. Frustratingly Easy Transferability Estimation. (arXiv:2106.09362v4 [cs.LG] UPDATED)
83. Machine Learning for Stuttering Identification: Review, Challenges and Future Directions. (arXiv:2107.04057v3 [cs.SD] UPDATED)
84. ADAST: Attentive Cross-domain EEG-based Sleep Staging Framework with Iterative Self-Training. (arXiv:2107.04470v4 [cs.LG] UPDATED)
85. Epistemic Neural Networks. (arXiv:2107.08924v5 [cs.LG] UPDATED)
86. DexMV: Imitation Learning for Dexterous Manipulation from Human Videos. (arXiv:2108.05877v5 [cs.LG] UPDATED)
87. Fast Density Estimation for Density-based Clustering Methods. (arXiv:2109.11383v3 [cs.LG] UPDATED)
88. Avoiding Forgetting and Allowing Forward Transfer in Continual Learning via Sparse Networks. (arXiv:2110.05329v3 [cs.LG] UPDATED)
89. NAS-Bench-360: Benchmarking Neural Architecture Search on Diverse Tasks. (arXiv:2110.05668v4 [cs.CV] UPDATED)
90. A Heterogeneous Graph Based Framework for Multimodal Neuroimaging Fusion Learning. (arXiv:2110.08465v4 [cs.LG] UPDATED)
91. Expectation Distance-based Distributional Clustering for Noise-Robustness. (arXiv:2110.08871v3 [cs.LG] UPDATED)
92. Deep Learning Approximation of Diffeomorphisms via Linear-Control Systems. (arXiv:2110.12393v2 [math.OC] UPDATED)
93. On the Effects of Artificial Data Modification. (arXiv:2110.13968v2 [cs.LG] UPDATED)
94. A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detection: Solutions and Future Challenges. (arXiv:2110.14051v3 [cs.CV] UPDATED)
95. SE(3) Equivariant Graph Neural Networks with Complete Local Frames. (arXiv:2110.14811v2 [cs.CE] UPDATED)
96. Reconstructing Nonlinear Dynamical Systems from Multi-Modal Time Series. (arXiv:2111.02922v3 [cs.LG] UPDATED)
97. Adversarial Mask: Real-World Universal Adversarial Attack on Face Recognition Models. (arXiv:2111.10759v2 [cs.CV] UPDATED)
98. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v4 [eess.IV] UPDATED)
99. Neural network stochastic differential equation models with applications to financial data forecasting. (arXiv:2111.13164v5 [cs.LG] UPDATED)
100. Enabling Fast Deep Learning on Tiny Energy-Harvesting IoT Devices. (arXiv:2111.14051v3 [cs.LG] UPDATED)
101. Fast Sparse Decision Tree Optimization via Reference Ensembles. (arXiv:2112.00798v7 [cs.LG] UPDATED)
102. Trading with the Momentum Transformer: An Intelligent and Interpretable Architecture. (arXiv:2112.08534v2 [cs.LG] UPDATED)
103. Two-Sample Testing in Reinforcement Learning. (arXiv:2201.08078v2 [cs.LG] UPDATED)
104. Stochastic normalizing flows as non-equilibrium transformations. (arXiv:2201.08862v3 [hep-lat] UPDATED)
105. Adversarial Masking for Self-Supervised Learning. (arXiv:2201.13100v3 [cs.CV] UPDATED)
106. Learning with Neighbor Consistency for Noisy Labels. (arXiv:2202.02200v2 [cs.CV] UPDATED)
107. Adversarially Trained Actor Critic for Offline Reinforcement Learning. (arXiv:2202.02446v2 [cs.LG] UPDATED)
108. Benchmarking of DL Libraries and Models on Mobile Devices. (arXiv:2202.06512v2 [cs.LG] UPDATED)
109. Speech Denoising in the Waveform Domain with Self-Attention. (arXiv:2202.07790v2 [cs.SD] UPDATED)
110. The rise of the lottery heroes: why zero-shot pruning is hard. (arXiv:2202.12400v2 [cs.LG] UPDATED)
111. Architectural Optimization and Feature Learning for High-Dimensional Time Series Datasets. (arXiv:2202.13486v2 [cs.LG] UPDATED)
112. Unfolding AIS transmission behavior for vessel movement modeling on noisy data leveraging machine learning. (arXiv:2202.13867v2 [cs.LG] UPDATED)
113. A Recurrent Differentiable Engine for Modeling Tensegrity Robots Trainable with Low-Frequency Data. (arXiv:2203.00041v2 [cs.RO] UPDATED)
114. Detecting and Diagnosing Terrestrial Gravitational-Wave Mimics Through Feature Learning. (arXiv:2203.05086v2 [astro-ph.IM] UPDATED)
115. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v4 [cs.CV] UPDATED)
116. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v2 [cs.CV] UPDATED)
117. SingAug: Data Augmentation for Singing Voice Synthesis with Cycle-consistent Training Strategy. (arXiv:2203.17001v2 [eess.AS] UPDATED)
118. SAAC: Safe Reinforcement Learning as an Adversarial Game of Actor-Critics. (arXiv:2204.09424v2 [cs.LG] UPDATED)
119. Flow Completion Network: Inferring the Fluid Dynamics from Incomplete Flow Information using Graph Neural Networks. (arXiv:2205.04739v2 [physics.flu-dyn] UPDATED)
120. Artificial Intelligence-Assisted Optimization and Multiphase Analysis of Polygon PEM Fuel Cells. (arXiv:2205.06768v2 [cs.NE] UPDATED)
121. Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation. (arXiv:2205.14141v2 [cs.CV] UPDATED)
122. Evaluating Robustness to Dataset Shift via Parametric Robustness Sets. (arXiv:2205.15947v2 [cs.LG] UPDATED)
123. LADDER: Latent Boundary-guided Adversarial Training. (arXiv:2206.03717v2 [cs.LG] UPDATED)
124. Investigation of stellar magnetic activity using variational autoencoder based on low-resolution spectroscopic survey. (arXiv:2206.07257v3 [astro-ph.SR] UPDATED)
125. NatGen: Generative pre-training by "Naturalizing" source code. (arXiv:2206.07585v2 [cs.PL] UPDATED)
126. Powershap: A Power-full Shapley Feature Selection Method. (arXiv:2206.08394v2 [cs.LG] UPDATED)
127. Motley: Benchmarking Heterogeneity and Personalization in Federated Learning. (arXiv:2206.09262v2 [cs.LG] UPDATED)
128. Characterizing and Mitigating the Difficulty in Training Physics-informed Artificial Neural Networks under Pointwise Constraints. (arXiv:2206.09321v2 [cs.LG] UPDATED)
129. Learning Controllable 3D Level Generators. (arXiv:2206.13623v2 [cs.AI] UPDATED)
130. Integral Probability Metrics PAC-Bayes Bounds. (arXiv:2207.00614v2 [stat.ML] UPDATED)
131. Unsupervised Recurrent Federated Learning for Edge Popularity Prediction in Privacy-Preserving Mobile Edge Computing Networks. (arXiv:2207.00755v2 [cs.MM] UPDATED)
132. Progressive Latent Replay for efficient Generative Rehearsal. (arXiv:2207.01562v2 [cs.CV] UPDATED)
133. Bayesian approaches for Quantifying Clinicians' Variability in Medical Image Quantification. (arXiv:2207.01868v2 [eess.IV] UPDATED)
134. Multi-Scored Sleep Databases: How to Exploit the Multiple-Labels in Automated Sleep Scoring. (arXiv:2207.01910v2 [cs.LG] UPDATED)
135. Deep Learning-based automated classification of Chinese Speech Sound Disorders. (arXiv:2205.11748v4 [cs.SD] CROSS LISTED)
## cs.AI
---
**59** new papers in cs.AI:-) 
1. Learning Task Embeddings for Teamwork Adaptation in Multi-Agent Reinforcement Learning. (arXiv:2207.02249v1 [cs.MA])
2. Putting the Con in Context: Identifying Deceptive Actors in the Game of Mafia. (arXiv:2207.02253v1 [cs.CL])
3. Admissibility in Strength-based Argumentation: Complexity and Algorithms (Extended Version with Proofs). (arXiv:2207.02258v1 [cs.AI])
4. Pretraining on Interactions for Learning Grounded Affordance Representations. (arXiv:2207.02272v1 [cs.CL])
5. Cooperative Distribution Alignment via JSD Upper Bound. (arXiv:2207.02286v1 [cs.LG])
6. Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs. (arXiv:2207.02295v1 [cs.NI])
7. Learning Classifier Systems for Self-Explaining Socio-Technical-Systems. (arXiv:2207.02300v1 [cs.HC])
8. A Dataset on Malicious Paper Bidding in Peer Review. (arXiv:2207.02303v1 [cs.CR])
9. Multi-Label Retinal Disease Classification using Transformers. (arXiv:2207.02335v1 [cs.CV])
10. Federated and Transfer Learning: A Survey on Adversaries and Defense Mechanisms. (arXiv:2207.02337v1 [cs.LG])
11. Rethinking the Importance of Sampling in Physics-informed Neural Networks. (arXiv:2207.02338v1 [cs.LG])
12. A Comprehensive Review on Deep Supervision: Theories and Applications. (arXiv:2207.02376v1 [cs.CV])
13. Query-Efficient Adversarial Attack Based on Latin Hypercube Sampling. (arXiv:2207.02391v1 [cs.CV])
14. BioTABQA: Instruction Learning for Biomedical Table Question Answering. (arXiv:2207.02419v1 [cs.CL])
15. Self-Constrained Inference Optimization on Structural Groups for Human Pose Estimation. (arXiv:2207.02425v1 [cs.CV])
16. Multi-Target Search in Euclidean Space with Ray Shooting (Full Version). (arXiv:2207.02436v1 [cs.CG])
17. Transformers are Adaptable Task Planners. (arXiv:2207.02442v1 [cs.RO])
18. Distillation to Enhance the Portability of Risk Models Across Institutions with Large Patient Claims Database. (arXiv:2207.02445v1 [cs.LG])
19. Information Compression and Performance Evaluation of Tic-Tac-Toe's Evaluation Function Using Singular Value Decomposition. (arXiv:2207.02449v1 [cs.LG])
20. Brain-inspired probabilistic generative model for double articulation analysis of spoken language. (arXiv:2207.02457v1 [q-bio.NC])
21. A Learning System for Motion Planning of Free-Float Dual-Arm Space Manipulator towards Non-Cooperative Object. (arXiv:2207.02464v1 [cs.RO])
22. Pure Transformers are Powerful Graph Learners. (arXiv:2207.02505v1 [cs.LG])
23. The Role of Complex NLP in Transformers for Text Ranking?. (arXiv:2207.02522v1 [cs.CL])
24. Transformers discover an elementary calculation system exploiting local attention and grid-like problem representation. (arXiv:2207.02536v1 [cs.LG])
25. AI-enhanced iterative solvers for accelerating the solution of large scale parametrized linear systems of equations. (arXiv:2207.02543v1 [math.NA])
26. Securing Optimized Code Against Power Side Channels. (arXiv:2207.02614v1 [cs.CR])
27. Difference in Euclidean Norm Can Cause Semantic Divergence in Batch Normalization. (arXiv:2207.02625v1 [cs.CV])
28. On the Complexity of Rational Verification. (arXiv:2207.02637v1 [cs.LO])
29. Reforming an Envy-Free Matching. (arXiv:2207.02641v1 [cs.GT])
30. Effective and Efficient Training for Sequential Recommendation using Recency Sampling. (arXiv:2207.02643v1 [cs.IR])
31. Planning Courses for Student Success at the American College of Greece. (arXiv:2207.02659v1 [cs.AI])
32. Spike Calibration: Fast and Accurate Conversion of Spiking Neural Network for Object Detection and Segmentation. (arXiv:2207.02702v1 [cs.CV])
33. Deep Learning approach for Classifying Trusses and Runners of Strawberries. (arXiv:2207.02721v1 [cs.CV])
34. Variational Flow Graphical Model. (arXiv:2207.02722v1 [stat.ML])
35. Towards the Use of Saliency Maps for Explaining Low-Quality Electrocardiograms to End Users. (arXiv:2207.02726v1 [cs.LG])
36. Real-Time Gesture Recognition with Virtual Glove Markers. (arXiv:2207.02729v1 [cs.CV])
37. Robust Counterfactual Explanations for Tree-Based Ensembles. (arXiv:2207.02739v1 [cs.LG])
38. Graph Trees with Attention. (arXiv:2207.02760v1 [cs.LG])
39. A multi-task network approach for calculating discrimination-free insurance prices. (arXiv:2207.02799v1 [cs.LG])
40. MoTiAC: Multi-Objective Actor-Critics for Real-Time Bidding. (arXiv:2002.07408v2 [cs.AI] UPDATED)
41. Predicting Kidney Transplant Survival using Multiple Feature Representations for HLAs. (arXiv:2103.03305v2 [cs.LG] UPDATED)
42. Epistemic Neural Networks. (arXiv:2107.08924v5 [cs.LG] UPDATED)
43. Dependability Analysis of Deep Reinforcement Learning based Robotics and Autonomous Systems through Probabilistic Model Checking. (arXiv:2109.06523v2 [cs.RO] UPDATED)
44. Exploration of Artificial Intelligence-oriented Power System Dynamic Simulators. (arXiv:2110.00931v4 [eess.SY] UPDATED)
45. Avoiding Forgetting and Allowing Forward Transfer in Continual Learning via Sparse Networks. (arXiv:2110.05329v3 [cs.LG] UPDATED)
46. SE(3) Equivariant Graph Neural Networks with Complete Local Frames. (arXiv:2110.14811v2 [cs.CE] UPDATED)
47. Fast Sparse Decision Tree Optimization via Reference Ensembles. (arXiv:2112.00798v7 [cs.LG] UPDATED)
48. The rise of the lottery heroes: why zero-shot pruning is hard. (arXiv:2202.12400v2 [cs.LG] UPDATED)
49. Unfolding AIS transmission behavior for vessel movement modeling on noisy data leveraging machine learning. (arXiv:2202.13867v2 [cs.LG] UPDATED)
50. A Recurrent Differentiable Engine for Modeling Tensegrity Robots Trainable with Low-Frequency Data. (arXiv:2203.00041v2 [cs.RO] UPDATED)
51. Self-Normalized Density Map (SNDM) for Counting Microbiological Objects. (arXiv:2203.09474v2 [cs.CV] UPDATED)
52. Deep Learning Serves Traffic Safety Analysis: A Forward-looking Review. (arXiv:2203.10939v2 [cs.CV] UPDATED)
53. SAAC: Safe Reinforcement Learning as an Adversarial Game of Actor-Critics. (arXiv:2204.09424v2 [cs.LG] UPDATED)
54. Ontology Reuse: the Real Test of Ontological Design. (arXiv:2205.02892v2 [cs.SE] UPDATED)
55. NatGen: Generative pre-training by "Naturalizing" source code. (arXiv:2206.07585v2 [cs.PL] UPDATED)
56. An F-shape Click Model for Information Retrieval on Multi-block Mobile Pages. (arXiv:2206.08604v2 [cs.IR] UPDATED)
57. Learning Controllable 3D Level Generators. (arXiv:2206.13623v2 [cs.AI] UPDATED)
58. Unsupervised Recurrent Federated Learning for Edge Popularity Prediction in Privacy-Preserving Mobile Edge Computing Networks. (arXiv:2207.00755v2 [cs.MM] UPDATED)
59. Plan Execution for Multi-Agent Path Finding with Indoor Quadcopters. (arXiv:2207.01752v2 [cs.AI] UPDATED)

