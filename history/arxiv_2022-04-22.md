# Your interest papers
---
## cs.CV
---
### MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v1 [eess.IV])
- Authors : Haseeb Nazki, Ognjen Arandjelovi, InHwa Um, David Harrison
- Link : [http://arxiv.org/abs/2204.09782](http://arxiv.org/abs/2204.09782)
> ABSTRACT  :  Histopathology relies on the analysis of microscopic tissue images to diagnose disease. A crucial part of tissue preparation is staining whereby a dye is used to make the salient tissue components more distinguishable. However, differences in laboratory protocols and scanning devices result in significant confounding appearance variation in the corresponding images. This variation increases both human error and the inter-rater variability, as well as hinders the performance of automatic or semi-automatic methods. In the present paper we introduce an unsupervised adversarial network to translate (and hence normalize) whole slide images across multiple data acquisition domains. Our key contributions are: (i) an adversarial architecture which learns across multiple domains with a single generator-discriminator network using an information flow branch which optimizes for perceptual loss, and (ii) the inclusion of an additional feature extraction network during training which guides the transformation network to keep all the structural features in the tissue image intact. We: (i) demonstrate the effectiveness of the proposed method firstly on H\&amp;E slides of 120 cases of kidney cancer, as well as (ii) show the benefits of the approach on more general problems, such as flexible illumination based natural image **enhancement** and light source adaptation.  
### Parametric Level-sets Enhanced To Improve Reconstruction (PaLEnTIR). (arXiv:2204.09815v1 [math.NA])
- Authors : Ege Ozsar, Misha Kilmer, Eric Miller, Eric de, Arvind Saibaba
- Link : [http://arxiv.org/abs/2204.09815](http://arxiv.org/abs/2204.09815)
> ABSTRACT  :  In this paper, we consider the **restoration** and reconstruction of piecewise constant objects in two and three dimensions using PaLEnTIR, a significantly enhanced Parametric level set (PaLS) model relative to the current state-of-the-art. The primary contribution of this paper is a new PaLS formulation which requires only a single level set function to recover a scene with piecewise constant objects possessing multiple unknown contrasts. Our model offers distinct advantages over current approaches to the multi-contrast, multi-object problem, all of which require multiple level sets and explicit estimation of the contrast magnitudes. Given upper and lower bounds on the contrast, our approach is able to recover objects with any distribution of contrasts and eliminates the need to know either the number of contrasts in a given scene or their values. We provide an iterative process for finding these space-varying contrast limits. Relative to most PaLS methods which employ radial basis functions (RBFs), our model makes use of non-isotropic basis functions, thereby expanding the class of shapes that a PaLS model of a given complexity can approximate. Finally, PaLEnTIR improves the conditioning of the Jacobian matrix required as part of the parameter identification process and consequently accelerates the optimization methods by controlling the magnitude of the PaLS expansion coefficients, fixing the centers of the basis functions, and the uniqueness of parametric to image mappings provided by the new parameterization. We demonstrate the performance of the new approach using both 2D and 3D variants of X-ray computed tomography, diffuse optical tomography (DOT), denoising, deconvolution problems. Application to experimental sparse CT data and simulated data with different types of noise are performed to further validate the proposed method.  
### Unsupervised Video Interpolation by Learning Multilayered 2.5D Motion Fields. (arXiv:2204.09900v1 [cs.CV])
- Authors : Ziang Cheng, Shihao Jiang, Hongdong Li
- Link : [http://arxiv.org/abs/2204.09900](http://arxiv.org/abs/2204.09900)
> ABSTRACT  :  The problem of video frame interpolation is to increase the temporal resolution of a low frame-rate video, by interpolating novel frames between existing temporally sparse frames. This paper presents a self-supervised approach to video frame interpolation that requires only a single video. We pose the video as a set of layers. Each layer is parameterized by two implicit neural networks -- one for learning a static frame and the other for a time-varying motion field corresponding to video dynamics. Together they represent an occlusion-free subset of the scene with a pseudo-depth channel. To model inter-layer occlusions, all layers are lifted to the 2.5D space so that the frontal layer occludes distant layers. This is done by assigning each layer a depth channel, which we call `pseudo-depth', whose partial order defines the occlusion between layers. The pseudo-depths are converted to visibility values through a fully differentiable SoftMin function so that closer layers are more visible than layers in a distance. On the other hand, we parameterize the video motions by solving an ordinary differentiable equation (ODE) defined on a time-varying neural velocity field that guarantees valid motions. This **implicit neural representation** learns the video as a space-time continuum, allowing frame interpolation at any temporal resolution. We demonstrate the effectiveness of our method on real-world datasets, where our method achieves comparable performance to state-of-the-arts that require ground truth labels for training.  
### CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation. (arXiv:2204.09914v1 [cs.CV])
- Authors : Xiaoyan Li, Gang Zhang, Hongyu Pan, Zhenhua Wang
- Link : [http://arxiv.org/abs/2204.09914](http://arxiv.org/abs/2204.09914)
> ABSTRACT  :  LiDAR semantic segmentation essential for advanced autonomous driving is required to be accurate, fast, and easy-deployed on mobile platforms. Previous point-based or sparse voxel-based methods are far away from real-time applications since time-consuming neighbor searching or sparse 3D convolution are employed. Recent 2D projection-based methods, including range view and multi-view fusion, can run in **real time**, but suffer from lower accuracy due to information loss during the 2D projection. Besides, to improve the performance, previous methods usually adopt test time augmentation (TTA), which further slows down the inference process. To achieve a better speed-accuracy trade-off, we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both effectiveness and efficiency mainly by the following two techniques: 1) the novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D projected grid for efficiency, while summarizes both 2D and 3D features on 3D point for minimal information loss; 2) the proposed transformation consistency loss narrows the gap between the single-time model inference and TTA. The experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the CPGNet without ensemble models or TTA is comparable with the state-of-the-art RPVNet, while it runs 4.7 times faster.  
### Progressive Training of A Two-Stage Framework for Video **Restoration**. (arXiv:2204.09924v1 [cs.CV])
- Authors : Meisong Zheng, Qunliang Xing, Minglang Qiao, Mai Xu, Lai Jiang, Huaida Liu, Ying Chen
- Link : [http://arxiv.org/abs/2204.09924](http://arxiv.org/abs/2204.09924)
> ABSTRACT  :  As a widely studied task, video **restoration** aims to enhance the quality of the videos with multiple potential degradations, such as noises, blurs and compression artifacts. Among video **restoration**s, compressed video quality **enhancement** and video super-resolution are two of the main tacks with significant values in practical scenarios. Recently, recurrent neural networks and transformers attract increasing research interests in this field, due to their impressive capability in sequence-to-sequence modeling. However, the training of these models is not only costly but also relatively hard to converge, with gradient exploding and vanishing problems. To cope with these problems, we proposed a two-stage framework including a multi-frame recurrent network and a single-frame transformer. Besides, multiple training strategies, such as transfer learning and progressive training, are developed to shorten the training time and improve the model performance. Benefiting from the above technical contributions, our solution wins two champions and a runner-up in the NTIRE 2022 super-resolution and quality **enhancement** of compressed video challenges.  
### Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v1 [cs.CV])
- Authors : Dihan Zheng, Xiaowen Zhang, Kaisheng Ma, Chenglong Bao
- Link : [http://arxiv.org/abs/2204.10090](http://arxiv.org/abs/2204.10090)
> ABSTRACT  :  Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from the unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. Our approach is based on a carefully designed probabilistic graphical model in which the clean and corrupted data domains are conditionally independent. Using variational inference, we maximize the evidence lower bound (ELBO) to estimate the joint probability density function. Furthermore, we show that the ELBO is computable without paired samples under the inference invariant assumption. This property provides the mathematical rationale of our approach in the unpaired setting. Finally, we apply our method to real-world image denoising and super-resolution tasks and train the models using the synthetic data generated by the LUD-VAE. Experimental results validate the advantages of our method over other learnable approaches.  
### Toward Fast, Flexible, and Robust Low-Light Image **Enhancement**. (arXiv:2204.10137v1 [cs.CV])
- Authors : Long Ma, Tengyu Ma, Risheng Liu, Xin Fan, Zhongxuan Luo
- Link : [http://arxiv.org/abs/2204.10137](http://arxiv.org/abs/2204.10137)
> ABSTRACT  :  Existing **low-light** image **enhancement** techniques are mostly not only difficult to deal with both visual quality and computational efficiency but also commonly invalid in unknown complex scenarios. In this paper, we develop a new Self-Calibrated Illumination (SCI) learning framework for fast, flexible, and robust brightening images in real-world **low-light** scenarios. To be specific, we establish a cascaded illumination learning process with weight sharing to handle this task. Considering the computational burden of the cascaded pattern, we construct the self-calibrated module which realizes the convergence between results of each stage, producing the gains that only use the single basic block for inference (yet has not been exploited in previous works), which drastically diminishes computation cost. We then define the unsupervised training loss to elevate the model capability that can adapt to general scenes. Further, we make comprehensive explorations to excavate SCI's inherent properties (lacking in existing works) including operation-insensitive adaptability (acquiring stable performance under the settings of different simple operations) and model-irrelevant generality (can be applied to illumination-based existing works to improve performance). Finally, plenty of experiments and ablation studies fully indicate our superiority in both quality and efficiency. Applications on **low-light** face detection and **night**time semantic segmentation fully reveal the latent practical values for SCI. The source code is available at https://github.com/vis-opt-group/SCI.  
### An Examination of Bias of Facial Analysis based BMI Prediction Models. (arXiv:2204.10262v1 [cs.CV])
- Authors : Hera Siddiqui, Ajita Rattani, Karl Ricanek, Twyla Hill
- Link : [http://arxiv.org/abs/2204.10262](http://arxiv.org/abs/2204.10262)
> ABSTRACT  :  Obesity is one of the most important public health problems that the world is facing today. A recent trend is in the development of intervention tools that predict BMI using facial images for weight monitoring and management to combat obesity. Most of these studies used BMI annotated facial image datasets that mainly consisted of Caucasian subjects. Research on bias evaluation of face-based gender-, age-classification, and face recognition systems suggest that these technologies perform poorly for women, **dark**-skinned people, and older adults. The bias of facial analysis-based BMI prediction tools has not been studied until now. This paper evaluates the bias of facial-analysis-based BMI prediction models across Caucasian and African-American Males and Females. Experimental investigations on the gender, race, and BMI balanced version of the modified MORPH-II dataset suggested that the error rate in BMI prediction was least for Black Males and highest for White Females. Further, the psychology-related facial features correlated with weight suggested that as the BMI increases, the changes in the facial region are more prominent for Black Males and the least for White Females. This is the reason for the least error rate of the facial analysis-based BMI prediction tool for Black Males and highest for White Females.  
### FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer. (arXiv:2111.13824v2 [cs.CV] UPDATED)
- Authors : Yang Lin, Tianyu Zhang, Peiqin Sun, Zheng Li, Shuchang Zhou
- Link : [http://arxiv.org/abs/2111.13824](http://arxiv.org/abs/2111.13824)
> ABSTRACT  :  Network quantization significantly reduces model inference complexity and has been widely used in real-world deployments. However, most existing quantization methods have been developed mainly on Convolutional Neural Networks (CNN), and suffer severe degradation when applied to fully quantized vision transformers. In this work, we demonstrate that many of these difficulties arise because of serious inter-channel variation in LayerNorm inputs, and present, Power-of-Two Factor (PTF), a systematic method to reduce the performance degradation and inference complexity of fully quantized vision transformers. In addition, observing an extreme non-uniform distribution in attention maps, we propose Log-Int-Softmax (LIS) to sustain that and simplify inference by using 4-bit quantization and the BitShift operator. Comprehensive experiments on various transformer-based architectures and benchmarks show that our Fully Quantized Vision Transformer (FQ-ViT) outperforms previous works while even using lower bit-width on attention maps. For instance, we reach 84.89% top-1 accuracy with ViT-L on ImageNet and 50.8 mAP with Cascade Mask R-CNN (**Swin**-S) on COCO. To our knowledge, we are the first to achieve lossless accuracy degradation (~1%) on fully quantized vision transformers. Code is available at https://github.com/linyang-zhh/FQ-ViT.  
### MantissaCam: Learning Snapshot High-dynamic-range Imaging with Perceptually-based In-pixel Irradiance Encoding. (arXiv:2112.05221v2 [eess.IV] UPDATED)
- Authors : Piotr Dudek, Gordon Wetzstein
- Link : [http://arxiv.org/abs/2112.05221](http://arxiv.org/abs/2112.05221)
> ABSTRACT  :  The ability to image high-dynamic-range (**HDR**) scenes is crucial in many computer vision applications. The dynamic range of conventional sensors, however, is fundamentally limited by their well capacity, resulting in saturation of bright scene parts. To overcome this limitation, emerging sensors offer in-pixel processing capabilities to encode the incident irradiance. Among the most promising encoding schemes is modulo wrapping, which results in a computational photography problem where the **HDR** scene is computed by an irradiance unwrapping algorithm from the wrapped low-dynamic-range (LDR) sensor image. Here, we design a neural network--based algorithm that outperforms previous irradiance unwrapping methods and we design a perceptually inspired "mantissa" encoding scheme that more efficiently wraps an **HDR** scene into an LDR sensor. Combined with our reconstruction framework, MantissaCam achieves state-of-the-art results among modulo-type snapshot **HDR** imaging approaches. We demonstrate the efficacy of our method in simulation and show benefits of our algorithm on modulo images captured with a prototype implemented with a programmable sensor.  
### Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v2 [eess.IV] UPDATED)
- Authors : Nico Messikommer, Stamatios Georgoulis, Daniel Gehrig, Stepan Tulyakov, Julius Erbach, Alfredo Bochicchio, Yuanyou Li, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.06622](http://arxiv.org/abs/2203.06622)
> ABSTRACT  :  Modern **high dynamic range** (**HDR**) imaging pipelines align and fuse multiple low dynamic range (LDR) images captured at different **exposure** times. While these methods work well in static scenes, dynamic scenes remain a challenge since the LDR images still suffer from saturation and noise. In such scenarios, event cameras would be a valid complement, thanks to their higher temporal resolution and dynamic range. In this paper, we propose the first multi-bracket **HDR** pipeline combining a standard camera with an event camera. Our results show better overall robustness when using events, with improvements in PSNR by up to 5dB on synthetic data and up to 0.7dB on real-world data. We also introduce a new dataset containing bracketed LDR images with aligned events and **HDR** ground truth.  
### Sat-**NeRF**: Learning Multi-View Satellite Photogrammetry With Transient Objects and Shadow Modeling Using RPC Cameras. (arXiv:2203.08896v2 [cs.CV] UPDATED)
- Authors : Roger Mar, Gabriele Facciolo, Thibaud Ehret
- Link : [http://arxiv.org/abs/2203.08896](http://arxiv.org/abs/2203.08896)
> ABSTRACT  :  We introduce the Satellite Neural Radiance Field (Sat-**NeRF**), a new end-to-end model for learning multi-view satellite photogrammetry in the wild. Sat-**NeRF** combines some of the latest trends in neural rendering with native satellite camera models, represented by rational polynomial coefficient (RPC) functions. The proposed method renders new views and infers surface models of similar quality to those obtained with traditional state-of-the-art stereo pipelines. Multi-date images exhibit significant changes in appearance, mainly due to varying shadows and transient objects (cars, vegetation). Robustness to these challenges is achieved by a shadow-aware irradiance model and uncertainty weighting to deal with transient phenomena that cannot be explained by the position of the sun. We evaluate Sat-**NeRF** using WorldView-3 images from different locations and stress the advantages of applying a bundle adjustment to the satellite camera models prior to training. This boosts the network performance and can optionally be used to extract additional cues for depth supervision.  
### Efficient Linear Attention for Fast and Accurate Keypoint Matching. (arXiv:2204.07731v2 [cs.CV] UPDATED)
- Authors : Suwichaya Suwanwimolkul, Satoshi Komorita
- Link : [http://arxiv.org/abs/2204.07731](http://arxiv.org/abs/2204.07731)
> ABSTRACT  :  Recently Transformers have provided state-of-the-art performance in sparse matching, crucial to realize high-performance 3D vision applications. Yet, these Transformers lack efficiency due to the quadratic computational complexity of their attention mechanism. To solve this problem, we employ an efficient linear attention for the linear computational complexity. Then, we propose a new attentional aggregation that achieves high accuracy by aggregating both the global and local information from sparse keypoints. To further improve the efficiency, we propose the joint learning of feature matching and description. Our learning enables simpler and faster matching than Sinkhorn, often used in matching the learned descriptors from Transformers. Our method achieves competitive performance with only 0.84M learnable parameters against the bigger SOTAs, SuperGlue (12M parameters) and SGMNet (30M parameters), on three benchmarks, HPatch, ETH, and Aachen Day-**Night**.  
### MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment. (arXiv:2204.08958v2 [cs.CV] UPDATED)
- Authors : Sidi Yang, Tianhe Wu, Shuwei Shi, Shanshan Lao, Yuan Gong, Mingdeng Cao, Jiahao Wang, Yujiu Yang
- Link : [http://arxiv.org/abs/2204.08958](http://arxiv.org/abs/2204.08958)
> ABSTRACT  :  No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual quality of images in accordance with human subjective perception. Unfortunately, existing NR-IQA methods are far from meeting the needs of predicting accurate quality scores on GAN-based distortion images. To this end, we propose Multi-dimension Attention Network for no-reference Image Quality Assessment (MANIQA) to improve the performance on GAN-based distortion. We firstly extract features via ViT, then to strengthen global and local interactions, we propose the Transposed Attention Block (TAB) and the Scale **Swin** Transformer Block (SSTB). These two modules apply attention mechanisms across the channel and spatial dimension, respectively. In this multi-dimensional manner, the modules cooperatively increase the interaction among different regions of images globally and locally. Finally, a dual branch structure for patch-weighted quality prediction is applied to predict the final score depending on the weight of each patch's score. Experimental results demonstrate that MANIQA outperforms state-of-the-art methods on four standard datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our method ranked first place in the final testing phase of the NTIRE 2022 Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and models are available at https://github.com/IIGROUP/MANIQA.  
### Rendering **Night**time Image Via Cascaded Color and Brightness Compensation. (arXiv:2204.08970v2 [cs.CV] UPDATED)
- Authors : Zhihao Li, Si Yi, Zhan Ma
- Link : [http://arxiv.org/abs/2204.08970](http://arxiv.org/abs/2204.08970)
> ABSTRACT  :  Image signal processing (ISP) is crucial for camera imaging, and neural networks (NN) solutions are extensively deployed for daytime scenes. The lack of sufficient **night**time image dataset and insights on **night**time illumination characteristics poses a great challenge for high-quality rendering using existing NN ISPs. To tackle it, we first built a high-resolution **night**time RAW-RGB (NR2R) dataset with white balance and tone mapping annotated by expert professionals. Meanwhile, to best capture the characteristics of **night**time illumination light sources, we develop the CBUnet, a two-stage NN ISP to cascade the compensation of color and brightness attributes. Experiments show that our method has better visual quality compared to traditional ISP pipeline, and is ranked at the second place in the NTIRE 2022 **Night** Photography Rendering Challenge for two tracks by respective People's and Professional Photographer's choices. The code and relevant materials are avaiable on our website: https://njuvision.github.io/CBUnet.  
### ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)
- Authors : Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.10016](http://arxiv.org/abs/2203.10016)
> ABSTRACT  :  Retrieving accurate semantic information in challenging **high dynamic range** (**HDR**) and high-speed conditions remains an open challenge for image-based algorithms due to severe image degradations. Event cameras promise to address these challenges since they feature a much higher dynamic range and are resilient to motion blur. Nonetheless, semantic segmentation with event cameras is still in its infancy which is chiefly due to the novelty of the sensor, and the lack of high-quality, labeled datasets. In this work, we introduce ESS, which tackles this problem by directly transferring the semantic segmentation task from existing labeled image datasets to unlabeled events via unsupervised domain adaptation (UDA). Compared to existing UDA methods, our approach aligns recurrent, motion-invariant event embeddings with image embeddings. For this reason, our method neither requires video data nor per-pixel alignment between images and events and, crucially, does not need to hallucinate motion from still images. Additionally, to spur further research in event-based semantic segmentation, we introduce DSEC-Semantic, the first large-scale event-based dataset with fine-grained labels. We show that using image labels alone, ESS outperforms existing UDA approaches, and when combined with event labels, it even outperforms state-of-the-art supervised approaches on both DDD17 and DSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount of existing labeled image datasets and paves the way for new and exciting research directions in new fields previously inaccessible for event cameras.  
## eess.IV
---
### MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v1 [eess.IV])
- Authors : Haseeb Nazki, Ognjen Arandjelovi, InHwa Um, David Harrison
- Link : [http://arxiv.org/abs/2204.09782](http://arxiv.org/abs/2204.09782)
> ABSTRACT  :  Histopathology relies on the analysis of microscopic tissue images to diagnose disease. A crucial part of tissue preparation is staining whereby a dye is used to make the salient tissue components more distinguishable. However, differences in laboratory protocols and scanning devices result in significant confounding appearance variation in the corresponding images. This variation increases both human error and the inter-rater variability, as well as hinders the performance of automatic or semi-automatic methods. In the present paper we introduce an unsupervised adversarial network to translate (and hence normalize) whole slide images across multiple data acquisition domains. Our key contributions are: (i) an adversarial architecture which learns across multiple domains with a single generator-discriminator network using an information flow branch which optimizes for perceptual loss, and (ii) the inclusion of an additional feature extraction network during training which guides the transformation network to keep all the structural features in the tissue image intact. We: (i) demonstrate the effectiveness of the proposed method firstly on H\&amp;E slides of 120 cases of kidney cancer, as well as (ii) show the benefits of the approach on more general problems, such as flexible illumination based natural image **enhancement** and light source adaptation.  
### Parametric Level-sets Enhanced To Improve Reconstruction (PaLEnTIR). (arXiv:2204.09815v1 [math.NA])
- Authors : Ege Ozsar, Misha Kilmer, Eric Miller, Eric de, Arvind Saibaba
- Link : [http://arxiv.org/abs/2204.09815](http://arxiv.org/abs/2204.09815)
> ABSTRACT  :  In this paper, we consider the **restoration** and reconstruction of piecewise constant objects in two and three dimensions using PaLEnTIR, a significantly enhanced Parametric level set (PaLS) model relative to the current state-of-the-art. The primary contribution of this paper is a new PaLS formulation which requires only a single level set function to recover a scene with piecewise constant objects possessing multiple unknown contrasts. Our model offers distinct advantages over current approaches to the multi-contrast, multi-object problem, all of which require multiple level sets and explicit estimation of the contrast magnitudes. Given upper and lower bounds on the contrast, our approach is able to recover objects with any distribution of contrasts and eliminates the need to know either the number of contrasts in a given scene or their values. We provide an iterative process for finding these space-varying contrast limits. Relative to most PaLS methods which employ radial basis functions (RBFs), our model makes use of non-isotropic basis functions, thereby expanding the class of shapes that a PaLS model of a given complexity can approximate. Finally, PaLEnTIR improves the conditioning of the Jacobian matrix required as part of the parameter identification process and consequently accelerates the optimization methods by controlling the magnitude of the PaLS expansion coefficients, fixing the centers of the basis functions, and the uniqueness of parametric to image mappings provided by the new parameterization. We demonstrate the performance of the new approach using both 2D and 3D variants of X-ray computed tomography, diffuse optical tomography (DOT), denoising, deconvolution problems. Application to experimental sparse CT data and simulated data with different types of noise are performed to further validate the proposed method.  
### Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v1 [cs.CV])
- Authors : Dihan Zheng, Xiaowen Zhang, Kaisheng Ma, Chenglong Bao
- Link : [http://arxiv.org/abs/2204.10090](http://arxiv.org/abs/2204.10090)
> ABSTRACT  :  Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from the unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. Our approach is based on a carefully designed probabilistic graphical model in which the clean and corrupted data domains are conditionally independent. Using variational inference, we maximize the evidence lower bound (ELBO) to estimate the joint probability density function. Furthermore, we show that the ELBO is computable without paired samples under the inference invariant assumption. This property provides the mathematical rationale of our approach in the unpaired setting. Finally, we apply our method to real-world image denoising and super-resolution tasks and train the models using the synthetic data generated by the LUD-VAE. Experimental results validate the advantages of our method over other learnable approaches.  
### MantissaCam: Learning Snapshot High-dynamic-range Imaging with Perceptually-based In-pixel Irradiance Encoding. (arXiv:2112.05221v2 [eess.IV] UPDATED)
- Authors : Piotr Dudek, Gordon Wetzstein
- Link : [http://arxiv.org/abs/2112.05221](http://arxiv.org/abs/2112.05221)
> ABSTRACT  :  The ability to image high-dynamic-range (**HDR**) scenes is crucial in many computer vision applications. The dynamic range of conventional sensors, however, is fundamentally limited by their well capacity, resulting in saturation of bright scene parts. To overcome this limitation, emerging sensors offer in-pixel processing capabilities to encode the incident irradiance. Among the most promising encoding schemes is modulo wrapping, which results in a computational photography problem where the **HDR** scene is computed by an irradiance unwrapping algorithm from the wrapped low-dynamic-range (LDR) sensor image. Here, we design a neural network--based algorithm that outperforms previous irradiance unwrapping methods and we design a perceptually inspired "mantissa" encoding scheme that more efficiently wraps an **HDR** scene into an LDR sensor. Combined with our reconstruction framework, MantissaCam achieves state-of-the-art results among modulo-type snapshot **HDR** imaging approaches. We demonstrate the efficacy of our method in simulation and show benefits of our algorithm on modulo images captured with a prototype implemented with a programmable sensor.  
### Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v2 [eess.IV] UPDATED)
- Authors : Nico Messikommer, Stamatios Georgoulis, Daniel Gehrig, Stepan Tulyakov, Julius Erbach, Alfredo Bochicchio, Yuanyou Li, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.06622](http://arxiv.org/abs/2203.06622)
> ABSTRACT  :  Modern **high dynamic range** (**HDR**) imaging pipelines align and fuse multiple low dynamic range (LDR) images captured at different **exposure** times. While these methods work well in static scenes, dynamic scenes remain a challenge since the LDR images still suffer from saturation and noise. In such scenarios, event cameras would be a valid complement, thanks to their higher temporal resolution and dynamic range. In this paper, we propose the first multi-bracket **HDR** pipeline combining a standard camera with an event camera. Our results show better overall robustness when using events, with improvements in PSNR by up to 5dB on synthetic data and up to 0.7dB on real-world data. We also introduce a new dataset containing bracketed LDR images with aligned events and **HDR** ground truth.  
### MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment. (arXiv:2204.08958v2 [cs.CV] UPDATED)
- Authors : Sidi Yang, Tianhe Wu, Shuwei Shi, Shanshan Lao, Yuan Gong, Mingdeng Cao, Jiahao Wang, Yujiu Yang
- Link : [http://arxiv.org/abs/2204.08958](http://arxiv.org/abs/2204.08958)
> ABSTRACT  :  No-Reference Image Quality Assessment (NR-IQA) aims to assess the perceptual quality of images in accordance with human subjective perception. Unfortunately, existing NR-IQA methods are far from meeting the needs of predicting accurate quality scores on GAN-based distortion images. To this end, we propose Multi-dimension Attention Network for no-reference Image Quality Assessment (MANIQA) to improve the performance on GAN-based distortion. We firstly extract features via ViT, then to strengthen global and local interactions, we propose the Transposed Attention Block (TAB) and the Scale **Swin** Transformer Block (SSTB). These two modules apply attention mechanisms across the channel and spatial dimension, respectively. In this multi-dimensional manner, the modules cooperatively increase the interaction among different regions of images globally and locally. Finally, a dual branch structure for patch-weighted quality prediction is applied to predict the final score depending on the weight of each patch's score. Experimental results demonstrate that MANIQA outperforms state-of-the-art methods on four standard datasets (LIVE, TID2013, CSIQ, and KADID-10K) by a large margin. Besides, our method ranked first place in the final testing phase of the NTIRE 2022 Perceptual Image Quality Assessment Challenge Track 2: No-Reference. Codes and models are available at https://github.com/IIGROUP/MANIQA.  
### Rendering **Night**time Image Via Cascaded Color and Brightness Compensation. (arXiv:2204.08970v2 [cs.CV] UPDATED)
- Authors : Zhihao Li, Si Yi, Zhan Ma
- Link : [http://arxiv.org/abs/2204.08970](http://arxiv.org/abs/2204.08970)
> ABSTRACT  :  Image signal processing (ISP) is crucial for camera imaging, and neural networks (NN) solutions are extensively deployed for daytime scenes. The lack of sufficient **night**time image dataset and insights on **night**time illumination characteristics poses a great challenge for high-quality rendering using existing NN ISPs. To tackle it, we first built a high-resolution **night**time RAW-RGB (NR2R) dataset with white balance and tone mapping annotated by expert professionals. Meanwhile, to best capture the characteristics of **night**time illumination light sources, we develop the CBUnet, a two-stage NN ISP to cascade the compensation of color and brightness attributes. Experiments show that our method has better visual quality compared to traditional ISP pipeline, and is ranked at the second place in the NTIRE 2022 **Night** Photography Rendering Challenge for two tracks by respective People's and Professional Photographer's choices. The code and relevant materials are avaiable on our website: https://njuvision.github.io/CBUnet.  
## cs.LG
---
### BABD: A Bitcoin Address Behavior Dataset for Address Behavior Pattern Analysis. (arXiv:2204.05746v2 [cs.CR] UPDATED)
- Authors : Yuexin Xiang, Yuchen Lei, Ding Bao, Wei Ren, Tiantian Li, Qingqing Yang, Wenmao Liu, Tianqing Zhu, Kwang Raymond
- Link : [http://arxiv.org/abs/2204.05746](http://arxiv.org/abs/2204.05746)
> ABSTRACT  :  Cryptocurrencies are no longer just the preferred option for cybercriminal activities on **dark**nets, due to the increasing adoption in mainstream applications. This is partly due to the transparency associated with the underpinning ledgers, where any individual can access the record of a transaction record on the public ledger. In this paper, we build a dataset comprising Bitcoin transactions between 12 July 2019 and 26 May 2021. This dataset (hereafter referred to as BABD-13) contains 13 types of Bitcoin addresses, 5 categories of indicators with 148 features, and 544,462 labeled data. We then use our proposed dataset on common machine learning models, namely: k-nearest neighbors algorithm, decision tree, random forest, multilayer perceptron, and XGBoost. The results show that the accuracy rates of these machine learning models on our proposed dataset are between 93.24% and 96.71%. We also analyze the proposed features and their relationships from the experiments, and propose a k-hop subgraph generation algorithm to extract a k-hop subgraph from the entire Bitcoin transaction graph constructed by the directed heterogeneous multigraph starting from a specific Bitcoin address node (e.g., a known transaction associated with a criminal investigation).  
### ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)
- Authors : Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.10016](http://arxiv.org/abs/2203.10016)
> ABSTRACT  :  Retrieving accurate semantic information in challenging **high dynamic range** (**HDR**) and high-speed conditions remains an open challenge for image-based algorithms due to severe image degradations. Event cameras promise to address these challenges since they feature a much higher dynamic range and are resilient to motion blur. Nonetheless, semantic segmentation with event cameras is still in its infancy which is chiefly due to the novelty of the sensor, and the lack of high-quality, labeled datasets. In this work, we introduce ESS, which tackles this problem by directly transferring the semantic segmentation task from existing labeled image datasets to unlabeled events via unsupervised domain adaptation (UDA). Compared to existing UDA methods, our approach aligns recurrent, motion-invariant event embeddings with image embeddings. For this reason, our method neither requires video data nor per-pixel alignment between images and events and, crucially, does not need to hallucinate motion from still images. Additionally, to spur further research in event-based semantic segmentation, we introduce DSEC-Semantic, the first large-scale event-based dataset with fine-grained labels. We show that using image labels alone, ESS outperforms existing UDA approaches, and when combined with event labels, it even outperforms state-of-the-art supervised approaches on both DDD17 and DSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount of existing labeled image datasets and paves the way for new and exciting research directions in new fields previously inaccessible for event cameras.  
## cs.AI
---
# Paper List
---
## cs.CV
---
**127** new papers in cs.CV:-) 
1. Spatially-Preserving Flattening for Location-Aware Classification of Findings in Chest X-Rays. (arXiv:2204.09676v1 [eess.IV])
2. FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow. (arXiv:2204.09679v1 [cs.CV])
3. Complete identification of complex salt-geometries from inaccurate migrated images using Deep Learning. (arXiv:2204.09710v1 [physics.geo-ph])
4. Transformer Decoders with MultiModal Regularization for Cross-Modal Food Retrieval. (arXiv:2204.09730v1 [cs.CV])
5. Time-based Self-supervised Learning for Wireless Capsule Endoscopy. (arXiv:2204.09773v1 [cs.CV])
6. Attention in Reasoning: Dataset, Analysis, and Modeling. (arXiv:2204.09774v1 [cs.CV])
7. Multi-Focus Image Fusion based on Gradient Transform. (arXiv:2204.09777v1 [cs.CV])
8. Multi-Scale Features and Parallel Transformers Based Image Quality Assessment. (arXiv:2204.09779v1 [cs.CV])
9. MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v1 [eess.IV])
10. SELMA: SEmantic Large-scale Multimodal Acquisitions in Variable Weather, Daytime and Viewpoints. (arXiv:2204.09788v1 [cs.CV])
11. Multimodal Gaussian Mixture Model for Realtime Roadside LiDAR Object Detection. (arXiv:2204.09804v1 [cs.CV])
12. Parametric Level-sets Enhanced To Improve Reconstruction (PaLEnTIR). (arXiv:2204.09815v1 [math.NA])
13. Making the Most of Text Semantics to Improve Biomedical Vision--Language Processing. (arXiv:2204.09817v1 [cs.CV])
14. SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification. (arXiv:2204.09826v1 [cs.CV])
15. Fast AdvProp. (arXiv:2204.09838v1 [cs.CV])
16. Multiscale Analysis for Improving Texture Classification. (arXiv:2204.09841v1 [cs.CV])
17. Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation. (arXiv:2204.09847v1 [cs.CV])
18. Weakly Aligned Feature Fusion for Multimodal Object Detection. (arXiv:2204.09848v1 [cs.CV])
19. Self-Supervised Learning to Guide Scientifically Relevant Categorization of Martian Terrain Images. (arXiv:2204.09854v1 [cs.CV])
20. Remote Sensing Cross-Modal Text-Image Retrieval Based on Global and Local Information. (arXiv:2204.09860v1 [cs.CV])
21. Pixel2Mesh++: 3D Mesh Generation and Refinement from Multi-View Images. (arXiv:2204.09866v1 [cs.CV])
22. Exploring a Fine-Grained Multiscale Method for Cross-Modal Remote Sensing Image Retrieval. (arXiv:2204.09868v1 [cs.CV])
23. Physics vs. Learned Priors: Rethinking Camera and Algorithm Design for Task-Specific Imaging. (arXiv:2204.09871v1 [cs.CV])
24. Persistent-Transient Duality in Human Behavior Modeling. (arXiv:2204.09875v1 [cs.CV])
25. CNLL: A Semi-supervised Approach For Continual Noisy Label Learning. (arXiv:2204.09881v1 [cs.CV])
26. Color Invariant Skin Segmentation. (arXiv:2204.09882v1 [cs.CV])
27. Unsupervised Video Interpolation by Learning Multilayered 2.5D Motion Fields. (arXiv:2204.09900v1 [cs.CV])
28. Beyond the Prototype: Divide-and-conquer Proxies for Few-shot Segmentation. (arXiv:2204.09903v1 [cs.CV])
29. Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])
30. An Efficient End-to-End Deep Neural Network for Interstitial Lung Disease Recognition and Classification. (arXiv:2204.09909v1 [eess.IV])
31. CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation. (arXiv:2204.09914v1 [cs.CV])
32. Perception Visualization: Seeing Through the Eyes of a DNN. (arXiv:2204.09920v1 [cs.CV])
33. Progressive Training of A Two-Stage Framework for Video **Restoration**. (arXiv:2204.09924v1 [cs.CV])
34. Multi-scale Knowledge Distillation for Unsupervised Person Re-Identification. (arXiv:2204.09931v1 [cs.CV])
35. Domain Invariant Model with Graph Convolutional Network for Mammogram Classification. (arXiv:2204.09954v1 [cs.CV])
36. Referring Expression Comprehension via Cross-Level Multi-Modal Fusion. (arXiv:2204.09957v1 [cs.CV])
37. ChildPredictor: A Child Face Prediction Framework with Disentangled Learning. (arXiv:2204.09962v1 [cs.CV])
38. Transformer-Guided Convolutional Neural Network for Cross-View Geolocalization. (arXiv:2204.09967v1 [cs.CV])
39. DGECN: A Depth-Guided Edge Convolutional Network for End-to-End 6D Pose Estimation. (arXiv:2204.09983v1 [cs.CV])
40. Arbitrary Bit-width Network: A Joint Layer-Wise Quantization and Adaptive Inference Approach. (arXiv:2204.09992v1 [cs.CV])
41. On Learning the Invisible in Photoacoustic Tomography with Flat Directionally Sensitive Detector. (arXiv:2204.10001v1 [eess.IV])
42. Fluctuation-based Outlier Detection. (arXiv:2204.10007v1 [cs.LG])
43. Towards Fewer Labels: Support Pair Active Learning for Person Re-identification. (arXiv:2204.10008v1 [cs.CV])
44. Understanding the Domain Gap in LiDAR Object Detection Networks. (arXiv:2204.10024v1 [cs.CV])
45. Is Neuron Coverage Needed to Make Person Detection More Robust?. (arXiv:2204.10027v1 [cs.CV])
46. A New Dataset and Transformer for Stereoscopic Video Super-Resolution. (arXiv:2204.10039v1 [cs.CV])
47. Implicit Shape Completion via Adversarial Shape Priors. (arXiv:2204.10060v1 [cs.CV])
48. Absolute Wrong Makes Better: Boosting Weakly Supervised Object Detection via Negative Deterministic Information. (arXiv:2204.10068v1 [cs.CV])
49. Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v1 [cs.CV])
50. R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction. (arXiv:2204.10095v1 [cs.CV])
51. GAF-NAU: Gramian Angular Field encoded Neighborhood Attention U-Net for Pixel-Wise Hyperspectral Image Classification. (arXiv:2204.10099v1 [cs.CV])
52. Working memory inspired hierarchical video decomposition with transformative representations. (arXiv:2204.10105v1 [cs.CV])
53. Deep Model-Based Super-Resolution with Non-uniform Blur. (arXiv:2204.10109v1 [cs.CV])
54. OSSO: Obtaining Skeletal Shape from Outside. (arXiv:2204.10129v1 [cs.CV])
55. Toward Fast, Flexible, and Robust Low-Light Image **Enhancement**. (arXiv:2204.10137v1 [cs.CV])
56. Multiple EffNet/ResNet Architectures for Melanoma Classification. (arXiv:2204.10142v1 [eess.IV])
57. A case for using rotation invariant features in state of the art feature matchers. (arXiv:2204.10144v1 [cs.CV])
58. WebFace260M: A Benchmark for Million-Scale Deep Face Recognition. (arXiv:2204.10149v1 [cs.CV])
59. A Multi-Person Video Dataset Annotation Method of Spatio-Temporally Actions. (arXiv:2204.10160v1 [cs.CV])
60. Automated analysis of fibrous cap in intravascular optical coherence tomography images of coronary arteries. (arXiv:2204.10162v1 [cs.LG])
61. BTranspose: Bottleneck Transformers for Human Pose Estimation with Self-Supervised Pre-Training. (arXiv:2204.10209v1 [cs.LG])
62. SmartPortraits: Depth Powered Handheld Smartphone Dataset of Human Portraits for State Estimation, Reconstruction and Synthesis. (arXiv:2204.10211v1 [cs.CV])
63. OCTOPUS -- optical coherence tomography plaque and stent analysis software. (arXiv:2204.10212v1 [eess.IV])
64. Planes vs. Chairs: Category-guided 3D shape learning without any 3D cues. (arXiv:2204.10235v1 [cs.CV])
65. HEATGait: Hop-Extracted Adjacency Technique in Graph Convolution based Gait Recognition. (arXiv:2204.10238v1 [cs.CV])
66. An Examination of Bias of Facial Analysis based BMI Prediction Models. (arXiv:2204.10262v1 [cs.CV])
67. DooDLeNet: Double DeepLab Enhanced Feature Fusion for Thermal-color Semantic Segmentation. (arXiv:2204.10266v1 [cs.LG])
68. Share With Thy Neighbors: Single-View Reconstruction by Cross-Instance Consistency. (arXiv:2204.10310v1 [cs.CV])
69. Unsupervised Human Action Recognition with Skeletal Graph Laplacian and Self-Supervised Viewpoints Invariance. (arXiv:2204.10312v1 [cs.CV])
70. Adversarial Contrastive Learning by Permuting Cluster Assignments. (arXiv:2204.10314v1 [cs.LG])
71. Feature anomaly detection system (FADS) for intelligent manufacturing. (arXiv:2204.10318v1 [cs.CV])
72. TorchSparse: Efficient Point Cloud Inference Engine. (arXiv:2204.10319v1 [cs.LG])
73. SelfD: Self-Learning Large-Scale Driving Policies From the Web. (arXiv:2204.10320v1 [cs.CV])
74. Learning Future Object Prediction with a Spatiotemporal Detection Transformer. (arXiv:2204.10321v1 [cs.CV])
75. A Survey on Deep Hashing Methods. (arXiv:2003.03369v4 [cs.CV] UPDATED)
76. SAM: Self-supervised Learning of Pixel-wise Anatomical Embeddings in Radiological Images. (arXiv:2012.02383v2 [cs.CV] UPDATED)
77. F-SIOL-310: A Robotic Dataset and Benchmark for Few-Shot Incremental Object Learning. (arXiv:2103.12242v3 [cs.RO] UPDATED)
78. Discrete Cosine Transform Network for Guided Depth Map Super-Resolution. (arXiv:2104.06977v3 [cs.CV] UPDATED)
79. Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview. (arXiv:2105.14291v2 [cs.CV] UPDATED)
80. Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets. (arXiv:2106.04180v2 [cs.CV] UPDATED)
81. Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface. (arXiv:2107.06393v2 [cs.CV] UPDATED)
82. On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v2 [cs.LG] UPDATED)
83. The CORSMAL benchmark for the prediction of the properties of containers. (arXiv:2107.12719v3 [cs.MM] UPDATED)
84. Raising context awareness in motion forecasting. (arXiv:2109.08048v2 [cs.CV] UPDATED)
85. Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets. (arXiv:2109.13514v2 [cs.CV] UPDATED)
86. A transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain MRI. (arXiv:2110.03588v6 [eess.IV] UPDATED)
87. Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity. (arXiv:2111.05329v3 [cs.CV] UPDATED)
88. Deep Domain Adaptation for Pavement Crack Detection. (arXiv:2111.10101v2 [cs.CV] UPDATED)
89. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v5 [cs.CV] UPDATED)
90. FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer. (arXiv:2111.13824v2 [cs.CV] UPDATED)
91. Dual Cluster Contrastive learning for Object Re-Identification. (arXiv:2112.04662v3 [cs.CV] UPDATED)
92. MantissaCam: Learning Snapshot High-dynamic-range Imaging with Perceptually-based In-pixel Irradiance Encoding. (arXiv:2112.05221v2 [eess.IV] UPDATED)
93. Human-vehicle Cooperative Visual Perception for Autonomous Driving under Complex Road and Traffic Scenarios. (arXiv:2112.09298v2 [cs.CV] UPDATED)
94. NICE-SLAM: Neural Implicit Scalable Encoding for SLAM. (arXiv:2112.12130v2 [cs.CV] UPDATED)
95. Debiased Learning from Naturally Imbalanced Pseudo-Labels. (arXiv:2201.01490v2 [cs.LG] UPDATED)
96. Tackling the Class Imbalance Problem of Deep Learning Based Head and Neck Organ Segmentation. (arXiv:2201.01636v2 [cs.CV] UPDATED)
97. SRVIO: Super Robust Visual Inertial Odometry for dynamic environments and challenging Loop-closure conditions. (arXiv:2201.05386v2 [cs.CV] UPDATED)
98. AutoAlign: Pixel-Instance Feature Aggregation for Multi-Modal 3D Object Detection. (arXiv:2201.06493v2 [cs.CV] UPDATED)
99. Resistance Training using Prior Bias: toward Unbiased Scene Graph Generation. (arXiv:2201.06794v2 [cs.CV] UPDATED)
100. Self-supervised Video Representation Learning with Cascade Positive Retrieval. (arXiv:2201.07989v4 [cs.CV] UPDATED)
101. Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch. (arXiv:2201.09367v3 [cs.GR] UPDATED)
102. Learning to Hash Naturally Sorts. (arXiv:2201.13322v2 [cs.CV] UPDATED)
103. Causal Scene BERT: Improving object detection by searching for challenging groups of data. (arXiv:2202.03651v2 [cs.CV] UPDATED)
104. Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)
105. Energy-Efficient Parking Analytics System using Deep Reinforcement Learning. (arXiv:2202.08973v2 [cs.CV] UPDATED)
106. OUR-GAN: One-shot Ultra-high-Resolution Generative Adversarial Networks. (arXiv:2202.13799v2 [cs.CV] UPDATED)
107. Update Compression for Deep Neural Networks on the Edge. (arXiv:2203.04516v2 [cs.CV] UPDATED)
108. Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v2 [eess.IV] UPDATED)
109. Sat-**NeRF**: Learning Multi-View Satellite Photogrammetry With Transient Objects and Shadow Modeling Using RPC Cameras. (arXiv:2203.08896v2 [cs.CV] UPDATED)
110. On Triangulation as a Form of Self-Supervision for 3D Human Pose Estimation. (arXiv:2203.15865v2 [cs.CV] UPDATED)
111. Efficient Linear Attention for Fast and Accurate Keypoint Matching. (arXiv:2204.07731v2 [cs.CV] UPDATED)
112. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)
113. Mapping LiDAR and Camera Measurements in a Dual Top-View Grid Representation Tailored for Automated Vehicles. (arXiv:2204.07887v2 [cs.CV] UPDATED)
114. Vision-Language Pre-Training for Multimodal Aspect-Based Sentiment Analysis. (arXiv:2204.07955v2 [cs.CV] UPDATED)
115. NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v2 [cs.CV] UPDATED)
116. MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration. (arXiv:2204.08058v2 [cs.CV] UPDATED)
117. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)
118. Not All Tokens Are Equal: Human-centric Visual Analysis via Token Clustering Transformer. (arXiv:2204.08680v3 [cs.CV] UPDATED)
119. Modeling Missing Annotations for Incremental Learning in Object Detection. (arXiv:2204.08766v2 [cs.CV] UPDATED)
120. An Efficient Domain-Incremental Learning Approach to Drive in All Weather Conditions. (arXiv:2204.08817v2 [cs.CV] UPDATED)
121. MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment. (arXiv:2204.08958v2 [cs.CV] UPDATED)
122. Rendering **Night**time Image Via Cascaded Color and Brightness Compensation. (arXiv:2204.08970v2 [cs.CV] UPDATED)
123. Reconstruction-Aware Prior Distillation for Semi-supervised Point Cloud Completion. (arXiv:2204.09186v2 [cs.CV] UPDATED)
124. Sound-Guided Semantic Video Generation. (arXiv:2204.09273v2 [cs.CV] UPDATED)
125. Situational Perception Guided Image Matting. (arXiv:2204.09276v2 [cs.CV] UPDATED)
126. Sequential Point Clouds: A Survey. (arXiv:2204.09337v2 [cs.CV] UPDATED)
127. ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**32** new papers in eess.IV:-) 
1. Spatially-Preserving Flattening for Location-Aware Classification of Findings in Chest X-Rays. (arXiv:2204.09676v1 [eess.IV])
2. FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow. (arXiv:2204.09679v1 [cs.CV])
3. Delamination prediction in composite panels using unsupervised-feature learning methods with wavelet-enhanced guided wave representations. (arXiv:2204.09764v1 [eess.SP])
4. Multi-Scale Features and Parallel Transformers Based Image Quality Assessment. (arXiv:2204.09779v1 [cs.CV])
5. MultiPathGAN: Structure Preserving Stain Normalization using Unsupervised Multi-domain Adversarial Network with Perception Loss. (arXiv:2204.09782v1 [eess.IV])
6. Parametric Level-sets Enhanced To Improve Reconstruction (PaLEnTIR). (arXiv:2204.09815v1 [math.NA])
7. Physics vs. Learned Priors: Rethinking Camera and Algorithm Design for Task-Specific Imaging. (arXiv:2204.09871v1 [cs.CV])
8. An Efficient End-to-End Deep Neural Network for Interstitial Lung Disease Recognition and Classification. (arXiv:2204.09909v1 [eess.IV])
9. Dynamic Tomography Reconstruction by Projection-Domain Separable Modeling. (arXiv:2204.09935v1 [eess.IV])
10. ChildPredictor: A Child Face Prediction Framework with Disentangled Learning. (arXiv:2204.09962v1 [cs.CV])
11. On Learning the Invisible in Photoacoustic Tomography with Flat Directionally Sensitive Detector. (arXiv:2204.10001v1 [eess.IV])
12. Generative Compression for Face Video: A Hybrid Scheme. (arXiv:2204.10055v1 [eess.IV])
13. Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v1 [cs.CV])
14. GAF-NAU: Gramian Angular Field encoded Neighborhood Attention U-Net for Pixel-Wise Hyperspectral Image Classification. (arXiv:2204.10099v1 [cs.CV])
15. Deep Model-Based Super-Resolution with Non-uniform Blur. (arXiv:2204.10109v1 [cs.CV])
16. Multiple EffNet/ResNet Architectures for Melanoma Classification. (arXiv:2204.10142v1 [eess.IV])
17. A Bitstream Feature Based Model for Video Decoding Energy Estimation. (arXiv:2204.10151v1 [eess.IV])
18. OCTOPUS -- optical coherence tomography plaque and stent analysis software. (arXiv:2204.10212v1 [eess.IV])
19. The 2021 NIST Speaker Recognition Evaluation. (arXiv:2204.10242v1 [eess.AS])
20. DooDLeNet: Double DeepLab Enhanced Feature Fusion for Thermal-color Semantic Segmentation. (arXiv:2204.10266v1 [cs.LG])
21. A General Destriping Framework for Remote Sensing Images Using Flatness Constraint. (arXiv:2104.02845v4 [eess.IV] UPDATED)
22. A transformer-based deep learning approach for classifying brain metastases into primary organ sites using clinical whole brain MRI. (arXiv:2110.03588v6 [eess.IV] UPDATED)
23. MantissaCam: Learning Snapshot High-dynamic-range Imaging with Perceptually-based In-pixel Irradiance Encoding. (arXiv:2112.05221v2 [eess.IV] UPDATED)
24. Learning a microlocal prior for limited-angle tomography. (arXiv:2201.00656v4 [eess.IV] UPDATED)
25. Tackling the Class Imbalance Problem of Deep Learning Based Head and Neck Organ Segmentation. (arXiv:2201.01636v2 [cs.CV] UPDATED)
26. Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)
27. OUR-GAN: One-shot Ultra-high-Resolution Generative Adversarial Networks. (arXiv:2202.13799v2 [cs.CV] UPDATED)
28. Multi-Bracket **High Dynamic Range** Imaging with Event Cameras. (arXiv:2203.06622v2 [eess.IV] UPDATED)
29. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)
30. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)
31. MANIQA: Multi-dimension Attention Network for No-Reference Image Quality Assessment. (arXiv:2204.08958v2 [cs.CV] UPDATED)
32. Rendering **Night**time Image Via Cascaded Color and Brightness Compensation. (arXiv:2204.08970v2 [cs.CV] UPDATED)
## cs.LG
---
**138** new papers in cs.LG:-) 
1. FS-NCSR: Increasing Diversity of the Super-Resolution Space via Frequency Separation and Noise-Conditioned Normalizing Flow. (arXiv:2204.09679v1 [cs.CV])
2. Generative Pre-Trained Transformers for Biologically Inspired Design. (arXiv:2204.09714v1 [cs.CL])
3. Scaling Language Model Size in Cross-Device Federated Learning. (arXiv:2204.09715v1 [cs.CL])
4. Matching Writers to Content Writing Tasks. (arXiv:2204.09718v1 [cs.CL])
5. A majorization-minimization algorithm for nonnegative binary matrix factorization. (arXiv:2204.09741v1 [cs.LG])
6. Federated Learning for Energy-limited Wireless Networks: A Partial Model Aggregation Approach. (arXiv:2204.09746v1 [cs.LG])
7. A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines. (arXiv:2204.09772v1 [cs.AI])
8. Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations. (arXiv:2204.09781v1 [cs.DL])
9. Sample-Efficient Reinforcement Learning for POMDPs with Linear Function Approximations. (arXiv:2204.09787v1 [cs.LG])
10. Wrapped Distributions on homogeneous Riemannian manifolds. (arXiv:2204.09790v1 [math.ST])
11. Assessing Machine Learning Algorithms for Near-Real Time Bus Ridership Prediction During Extreme Weather. (arXiv:2204.09792v1 [stat.AP])
12. Exact Formulas for Finite-Time Estimation Errors of Decentralized Temporal Difference Learning with Linear Function Approximation. (arXiv:2204.09801v1 [cs.LG])
13. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v1 [cs.LG])
14. fairDMS: Rapid Model Training by Data and Model Reuse. (arXiv:2204.09805v1 [cs.LG])
15. Deep transfer learning for partial differential equations under conditional shift with DeepONet. (arXiv:2204.09810v1 [cs.LG])
16. A Revealing Large-Scale Evaluation of Unsupervised Anomaly Detection Algorithms. (arXiv:2204.09825v1 [cs.LG])
17. Relevance-guided Unsupervised Discovery of Abilities with Quality-Diversity Algorithms. (arXiv:2204.09828v1 [cs.NE])
18. Accurate Molecular-Orbital-Based Machine Learning Energies via Unsupervised Clustering of Chemical Space. (arXiv:2204.09831v1 [physics.chem-ph])
19. Memory Bounds for the Experts Problem. (arXiv:2204.09837v1 [cs.DS])
20. Multi-Tier Platform for Cognizing Massive Electroencephalogram. (arXiv:2204.09840v1 [eess.SP])
21. FedCL: Federated Contrastive Learning for Privacy-Preserving Recommendation. (arXiv:2204.09850v1 [cs.LG])
22. CNLL: A Semi-supervised Approach For Continual Noisy Label Learning. (arXiv:2204.09881v1 [cs.CV])
23. Inducing Gaussian Process Networks. (arXiv:2204.09889v1 [cs.LG])
24. Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])
25. MRAM-based Analog Sigmoid Function for In-memory Computing. (arXiv:2204.09918v1 [cs.ET])
26. Perception Visualization: Seeing Through the Eyes of a DNN. (arXiv:2204.09920v1 [cs.CV])
27. FastDiff: A Fast Conditional Diffusion Model for High-Quality Speech Synthesis. (arXiv:2204.09934v1 [eess.AS])
28. Ultra Marginal Feature Importance. (arXiv:2204.09938v1 [stat.ML])
29. Hybrid Cloud-Edge Collaborative Data Anomaly Detection in Industrial Sensor Networks. (arXiv:2204.09942v1 [cs.CR])
30. Towards Reliable Neural Generative Modeling of Detectors. (arXiv:2204.09947v1 [physics.ins-det])
31. Merging of neural networks. (arXiv:2204.09973v1 [cs.LG])
32. Eliminating Backdoor Triggers for Deep Neural Networks Using Attention Relation Graph Distillation. (arXiv:2204.09975v1 [cs.LG])
33. A data filling methodology for time series based on CNN and (Bi)LSTM neural networks. (arXiv:2204.09994v1 [cs.LG])
34. Fluctuation-based Outlier Detection. (arXiv:2204.10007v1 [cs.LG])
35. MedFACT: Modeling Medical Feature Correlations in Patient Health Representation Learning via Feature Clustering. (arXiv:2204.10011v1 [cs.LG])
36. Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation. (arXiv:2204.10020v1 [eess.AS])
37. Scalable Sensitivity and Uncertainty Analysis for Causal-Effect Estimates of Continuous-Valued Interventions. (arXiv:2204.10022v1 [cs.LG])
38. Understanding the Domain Gap in LiDAR Object Detection Networks. (arXiv:2204.10024v1 [cs.CV])
39. Is Neuron Coverage Needed to Make Person Detection More Robust?. (arXiv:2204.10027v1 [cs.CV])
40. A Learned Index for Exact Similarity Search in Metric Spaces. (arXiv:2204.10028v1 [cs.DB])
41. DropMessage: Unifying Random Dropping for Graph Neural Networks. (arXiv:2204.10037v1 [cs.LG])
42. Robustness of Machine Learning Models Beyond Adversarial Attacks. (arXiv:2204.10046v1 [cs.LG])
43. On Distribution Shift in Learning-based Bug Detectors. (arXiv:2204.10049v1 [cs.LG])
44. Detecting Topology Attacks against Graph Neural Networks. (arXiv:2204.10072v1 [cs.LG])
45. A two-level machine learning framework for predictive maintenance: comparison of learning formulations. (arXiv:2204.10083v1 [cs.LG])
46. Working memory inspired hierarchical video decomposition with transformative representations. (arXiv:2204.10105v1 [cs.CV])
47. Physical Modeling using Recurrent Neural Networks with Fast Convolutional Layers. (arXiv:2204.10125v1 [cs.SD])
48. Learnable Model Augmentation Self-Supervised Learning for Sequential Recommendation. (arXiv:2204.10128v1 [cs.IR])
49. Automated analysis of fibrous cap in intravascular optical coherence tomography images of coronary arteries. (arXiv:2204.10162v1 [cs.LG])
50. Evolution and use of data science vocabulary. How much have we changed in 13 years?. (arXiv:2204.10174v1 [cs.DL])
51. Scale Dependencies and Self-Similarity Through Wavelet Scattering Covariance. (arXiv:2204.10177v1 [physics.data-an])
52. Distributed Learning for Vehicular Dynamic Spectrum Access in Autonomous Driving. (arXiv:2204.10179v1 [cs.NI])
53. Multi-Component Optimization and Efficient Deployment of Neural-Networks on Resource-Constrained IoT Hardware. (arXiv:2204.10183v1 [cs.LG])
54. INSPIRE: Distributed Bayesian Optimization for ImproviNg SPatIal REuse in Dense WLANs. (arXiv:2204.10184v1 [cs.NI])
55. Social Media Sentiment Analysis for Cryptocurrency Market Prediction. (arXiv:2204.10185v1 [cs.CL])
56. Neural Topic Modeling of Psychotherapy Sessions. (arXiv:2204.10189v1 [cs.CL])
57. Condition Monitoring of Transformer Bushings Using Computational Intelligence. (arXiv:2204.10193v1 [cs.LG])
58. IIITDWD-ShankarB@ Dravidian-CodeMixi-HASOC2021: mBERT based model for identification of offensive content in south Indian languages. (arXiv:2204.10195v1 [cs.CL])
59. Unsupervised Numerical Reasoning to Extract Phenotypes from Clinical Text by Leveraging External Knowledge. (arXiv:2204.10202v1 [cs.CL])
60. BTranspose: Bottleneck Transformers for Human Pose Estimation with Self-Supervised Pre-Training. (arXiv:2204.10209v1 [cs.LG])
61. OCTOPUS -- optical coherence tomography plaque and stent analysis software. (arXiv:2204.10212v1 [eess.IV])
62. Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks. (arXiv:2204.10222v1 [cs.LG])
63. The Silent Problem -- Machine Learning Model Failure -- How to Diagnose and Fix Ailing Machine Learning Models. (arXiv:2204.10227v1 [cs.LG])
64. The NIST CTS Speaker Recognition Challenge. (arXiv:2204.10228v1 [eess.AS])
65. Handling Imbalanced Classification Problems With Support Vector Machines via Evolutionary Bilevel Optimization. (arXiv:2204.10231v1 [cs.LG])
66. A Sandbox Tool to Bias(Stress)-Test Fairness Algorithms. (arXiv:2204.10233v1 [cs.LG])
67. The 2021 NIST Speaker Recognition Evaluation. (arXiv:2204.10242v1 [eess.AS])
68. Revisiting Gaussian mixture critic in off-policy reinforcement learning: a sample-based approach. (arXiv:2204.10256v1 [cs.LG])
69. DooDLeNet: Double DeepLab Enhanced Feature Fusion for Thermal-color Semantic Segmentation. (arXiv:2204.10266v1 [cs.LG])
70. Out-of-distribution generalization for learning quantum dynamics. (arXiv:2204.10268v1 [quant-ph])
71. Dynamical simulation via quantum machine learning with provable generalization. (arXiv:2204.10269v1 [quant-ph])
72. Deep learning techniques for energy clustering in the CMS ECAL. (arXiv:2204.10277v1 [hep-ex])
73. Addressing Tactic Volatility in Self-Adaptive Systems Using Evolved Recurrent Neural Networks and Uncertainty Reduction Tactics. (arXiv:2204.10308v1 [cs.LG])
74. Adversarial Contrastive Learning by Permuting Cluster Assignments. (arXiv:2204.10314v1 [cs.LG])
75. Feature anomaly detection system (FADS) for intelligent manufacturing. (arXiv:2204.10318v1 [cs.CV])
76. TorchSparse: Efficient Point Cloud Inference Engine. (arXiv:2204.10319v1 [cs.LG])
77. Learning Future Object Prediction with a Spatiotemporal Detection Transformer. (arXiv:2204.10321v1 [cs.CV])
78. Backplay: "Man muss immer umkehren". (arXiv:1807.06919v5 [cs.LG] UPDATED)
79. Modeling and Predicting Popularity Dynamics via Deep Learning Attention Mechanism. (arXiv:1811.02117v2 [cs.SI] UPDATED)
80. Exploring Structural Sparsity of Deep Networks via Inverse Scale Spaces. (arXiv:1905.09449v5 [cs.LG] UPDATED)
81. Towards Resolving Propensity Contradiction in Offline Recommender Learning. (arXiv:1910.07295v6 [stat.ML] UPDATED)
82. Conditional Hierarchical Bayesian Tucker Decomposition for Genetic Data Analysis. (arXiv:1911.12426v4 [cs.LG] UPDATED)
83. Why I'm not Answering: Understanding Determinants of Classification of an Abstaining Classifier for Cancer Pathology Reports. (arXiv:2009.05094v5 [cs.LG] UPDATED)
84. Conditionally Adaptive Multi-Task Learning: Improving Transfer Learning in NLP Using Fewer Parameters & Less Data. (arXiv:2009.09139v3 [cs.LG] UPDATED)
85. Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data. (arXiv:2010.03622v5 [cs.LG] UPDATED)
86. An Improved Transfer Model: Randomized Transferable Machine. (arXiv:2011.13629v2 [cs.LG] UPDATED)
87. Deep Bayesian Active Learning, A Brief Survey on Recent Advances. (arXiv:2012.08044v2 [cs.LG] UPDATED)
88. Intact-VAE: Estimating Treatment Effects under Unobserved Confounding. (arXiv:2101.06662v3 [stat.ML] UPDATED)
89. Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective. (arXiv:2103.03113v3 [cs.LG] UPDATED)
90. Lessons on Parameter Sharing across Layers in Transformers. (arXiv:2104.06022v3 [cs.CL] UPDATED)
91. Holmes: An Efficient and Lightweight Semantic Based Anomalous Email Detector. (arXiv:2104.08044v11 [cs.CR] UPDATED)
92. Why Do Pretrained Language Models Help in Downstream Tasks? An Analysis of Head and Prompt Tuning. (arXiv:2106.09226v2 [cs.LG] UPDATED)
93. Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface. (arXiv:2107.06393v2 [cs.CV] UPDATED)
94. On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v2 [cs.LG] UPDATED)
95. Random Dilated Shapelet Transform: A New Approach for Time Series Shapelets. (arXiv:2109.13514v2 [cs.CV] UPDATED)
96. A manifold learning approach for gesture recognition from micro-Doppler radar measurements. (arXiv:2110.01670v4 [cs.LG] UPDATED)
97. From Stars to Subgraphs: Uplifting Any GNN with Local Structure Awareness. (arXiv:2110.03753v3 [cs.LG] UPDATED)
98. Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v6 [cs.GT] UPDATED)
99. The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization. (arXiv:2110.07732v3 [cs.LG] UPDATED)
100. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v5 [cs.LG] UPDATED)
101. Scalable One-Pass Optimisation of High-Dimensional Weight-Update Hyperparameters by Implicit Differentiation. (arXiv:2110.10461v3 [cs.LG] UPDATED)
102. TND-NAS: Towards Non-Differentiable Objectives in Differentiable Neural Architecture Search. (arXiv:2111.03892v2 [cs.LG] UPDATED)
103. Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity. (arXiv:2111.05329v3 [cs.CV] UPDATED)
104. Bayesian Learning via Neural Schr\"odinger-F\"ollmer Flows. (arXiv:2111.10510v8 [stat.ML] UPDATED)
105. Anti-Jamming Games in Multi-Band Wireless Ad Hoc Networks. (arXiv:2111.11178v2 [cs.IT] UPDATED)
106. Fink: early supernovae Ia classification using active learning. (arXiv:2111.11438v2 [astro-ph.IM] UPDATED)
107. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v5 [cs.CV] UPDATED)
108. DeepGate: Learning Neural Representations of Logic Gates. (arXiv:2111.14616v3 [cs.LG] UPDATED)
109. Surfer100: Generating Surveys From Web Resources on Wikipedia-style. (arXiv:2112.06377v2 [cs.CL] UPDATED)
110. Debiased Learning from Naturally Imbalanced Pseudo-Labels. (arXiv:2201.01490v2 [cs.LG] UPDATED)
111. Sketch2PQ: Freeform Planar Quadrilateral Mesh Design via a Single Sketch. (arXiv:2201.09367v3 [cs.GR] UPDATED)
112. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v3 [cs.LG] UPDATED)
113. Learning to Hash Naturally Sorts. (arXiv:2201.13322v2 [cs.CV] UPDATED)
114. Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)
115. Energy-Efficient Parking Analytics System using Deep Reinforcement Learning. (arXiv:2202.08973v2 [cs.CV] UPDATED)
116. NetSentry: A Deep Learning Approach to Detecting Incipient Large-scale Network Attacks. (arXiv:2202.09873v2 [cs.CR] UPDATED)
117. OUR-GAN: One-shot Ultra-high-Resolution Generative Adversarial Networks. (arXiv:2202.13799v2 [cs.CV] UPDATED)
118. Path sampling of recurrent neural networks by incorporating known physics. (arXiv:2203.00597v2 [cond-mat.dis-nn] UPDATED)
119. Linear convergence of a policy gradient method for finite horizon continuous time stochastic control problems. (arXiv:2203.11758v2 [math.OC] UPDATED)
120. Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions. (arXiv:2203.12235v2 [cs.CL] UPDATED)
121. Does Audio Deepfake Detection Generalize?. (arXiv:2203.16263v3 [cs.SD] UPDATED)
122. A System for Interactive Examination of Learned Security Policies. (arXiv:2204.01126v2 [cs.CR] UPDATED)
123. BABD: A Bitcoin Address Behavior Dataset for Address Behavior Pattern Analysis. (arXiv:2204.05746v2 [cs.CR] UPDATED)
124. A Unified Cascaded Encoder ASR Model for Dynamic Model Sizes. (arXiv:2204.06164v2 [eess.AS] UPDATED)
125. Decentralized Collaborative Learning Framework for Next POI Recommendation. (arXiv:2204.06516v2 [cs.IR] UPDATED)
126. Brazilian Court Documents Clustered by Similarity Together Using Natural Language Processing Approaches with Transformers. (arXiv:2204.07182v2 [cs.AI] UPDATED)
127. Accurate detection of sepsis at ED triage using machine learning with clinical natural language processing. (arXiv:2204.07657v2 [cs.LG] UPDATED)
128. Persua: A Visual Interactive System to Enhance the Persuasiveness of Arguments in Online Discussion. (arXiv:2204.07741v2 [cs.HC] UPDATED)
129. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)
130. NICO++: Towards Better Benchmarking for Domain Generalization. (arXiv:2204.08040v2 [cs.CV] UPDATED)
131. STONet: A Neural-Operator-Driven Spatio-temporal Network. (arXiv:2204.08414v2 [cs.LG] UPDATED)
132. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)
133. Learning Forward Dynamics Model and Informed Trajectory Sampler for Safe Quadruped Navigation. (arXiv:2204.08647v3 [cs.RO] UPDATED)
134. Radio Galaxy Zoo: Using semi-supervised learning to leverage large unlabelled data-sets for radio galaxy classification under data-set shift. (arXiv:2204.08816v3 [astro-ph.GA] UPDATED)
135. A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation. (arXiv:2204.09579v2 [cs.LG] UPDATED)
136. Deep Learning meets Nonparametric Regression: Are Weight-Decayed DNNs Locally Adaptive?. (arXiv:2204.09664v2 [cs.LG] UPDATED)
137. ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV] CROSS LISTED)
138. Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v3 [cs.LG] CROSS LISTED)
## cs.AI
---
**84** new papers in cs.AI:-) 
1. TropeTwist: Trope-based Narrative Structure Generation. (arXiv:2204.09672v1 [cs.AI])
2. Spatially-Preserving Flattening for Location-Aware Classification of Findings in Chest X-Rays. (arXiv:2204.09676v1 [eess.IV])
3. Domain Specific Fine-tuning of Denoising Sequence-to-Sequence Models for Natural Language Summarization. (arXiv:2204.09716v1 [cs.CL])
4. LSTM-RASA Based Agri Farm Assistant for Farmers. (arXiv:2204.09717v1 [cs.CL])
5. Matching Writers to Content Writing Tasks. (arXiv:2204.09718v1 [cs.CL])
6. Recent Progress in Conversational AI. (arXiv:2204.09719v1 [cs.CL])
7. When Does Syntax Mediate Neural Language Model Performance? Evidence from Dropout Probes. (arXiv:2204.09722v1 [cs.CL])
8. ARLIF-IDS -- Attention augmented Real-Time Isolation Forest Intrusion Detection System. (arXiv:2204.09737v1 [cs.CR])
9. A Hierarchical Bayesian Approach to Inverse Reinforcement Learning with Symbolic Reward Machines. (arXiv:2204.09772v1 [cs.AI])
10. SELMA: SEmantic Large-scale Multimodal Acquisitions in Variable Weather, Daytime and Viewpoints. (arXiv:2204.09788v1 [cs.CV])
11. Multiply-and-Fire (MNF): An Event-driven Sparse Neural Network Accelerator. (arXiv:2204.09797v1 [cs.AR])
12. GUARD: Graph Universal Adversarial Defense. (arXiv:2204.09803v1 [cs.LG])
13. A Revealing Large-Scale Evaluation of Unsupervised Anomaly Detection Algorithms. (arXiv:2204.09825v1 [cs.LG])
14. SimMC: Simple Masked Contrastive Learning of Skeleton Representations for Unsupervised Person Re-Identification. (arXiv:2204.09826v1 [cs.CV])
15. Relevance-guided Unsupervised Discovery of Abilities with Quality-Diversity Algorithms. (arXiv:2204.09828v1 [cs.NE])
16. Sample-Based Bounds for Coherent Risk Measures: Applications to Policy Synthesis and Verification. (arXiv:2204.09833v1 [cs.AI])
17. 6GAN: IPv6 Multi-Pattern Target Generation via Generative Adversarial Nets with Reinforcement Learning. (arXiv:2204.09839v1 [cs.NI])
18. The Risks of Machine Learning Systems. (arXiv:2204.09852v1 [cs.CY])
19. A Model-Agnostic Data Manipulation Method for Persona-based Dialogue Generation. (arXiv:2204.09867v1 [cs.CL])
20. Persistent-Transient Duality in Human Behavior Modeling. (arXiv:2204.09875v1 [cs.CV])
21. Infographics Wizard: Flexible Infographics Authoring and Design Exploration. (arXiv:2204.09904v1 [cs.HC])
22. SinTra: Learning an inspiration model from a single multi-track music segment. (arXiv:2204.09917v1 [cs.SD])
23. Sonic Interactions in Virtual Environments: the Egocentric Audio Perspective of the Digital Twin. (arXiv:2204.09919v1 [cs.HC])
24. Perception Visualization: Seeing Through the Eyes of a DNN. (arXiv:2204.09920v1 [cs.CV])
25. Multi-scale Knowledge Distillation for Unsupervised Person Re-Identification. (arXiv:2204.09931v1 [cs.CV])
26. Planning for Temporally Extended Goals in Pure-Past Linear Temporal Logic: A Polynomial Reduction to Standard Planning. (arXiv:2204.09960v1 [cs.AI])
27. Using consumer feedback from location-based services in PoI recommender systems for people with autism. (arXiv:2204.09969v1 [cs.IR])
28. Revisiting initial sets in abstract argumentation. (arXiv:2204.09985v1 [cs.AI])
29. MedFACT: Modeling Medical Feature Correlations in Patient Health Representation Learning via Feature Clustering. (arXiv:2204.10011v1 [cs.LG])
30. Path-Specific Objectives for Safer Agent Incentives. (arXiv:2204.10018v1 [cs.AI])
31. Standing on the Shoulders of Giant Frozen Language Models. (arXiv:2204.10019v1 [cs.CL])
32. DropMessage: Unifying Random Dropping for Graph Neural Networks. (arXiv:2204.10037v1 [cs.LG])
33. Resilient robot teams: a review integrating decentralised control, change-detection, and learning. (arXiv:2204.10063v1 [cs.RO])
34. R2-Trans:Fine-Grained Visual Categorization with Redundancy Reduction. (arXiv:2204.10095v1 [cs.CV])
35. Working memory inspired hierarchical video decomposition with transformative representations. (arXiv:2204.10105v1 [cs.CV])
36. Features of Explainability: How users understand counterfactual and causal explanations for categorical and continuous features in XAI. (arXiv:2204.10152v1 [cs.HC])
37. Gated Multimodal Fusion with Contrastive Learning for Turn-taking Prediction in Human-robot Dialogue. (arXiv:2204.10172v1 [eess.AS])
38. Probing Script Knowledge from Pre-Trained Models. (arXiv:2204.10176v1 [cs.CL])
39. Doctor XAvIer: Explainable Diagnosis using Physician-Patient Dialogues and XAI Evaluation. (arXiv:2204.10178v1 [cs.CL])
40. WordAlchemy: A transformer-based Reverse Dictionary. (arXiv:2204.10181v1 [cs.CL])
41. Neural Topic Modeling of Psychotherapy Sessions. (arXiv:2204.10189v1 [cs.CL])
42. Residue-Based Natural Language Adversarial Attack Detection. (arXiv:2204.10192v1 [cs.CL])
43. Condition Monitoring of Transformer Bushings Using Computational Intelligence. (arXiv:2204.10193v1 [cs.LG])
44. Semantic Structure based Query Graph Prediction for Question Answering over Knowledge Graph. (arXiv:2204.10194v1 [cs.CL])
45. Multimodal Hate Speech Detection from Bengali Memes and Texts. (arXiv:2204.10196v1 [cs.CL])
46. Context-Aware Language Modeling for Goal-Oriented Dialogue Systems. (arXiv:2204.10198v1 [cs.CL])
47. An Exploratory Study on Code Attention in BERT. (arXiv:2204.10200v1 [cs.SE])
48. Usage-based learning of grammatical categories. (arXiv:2204.10201v1 [cs.CL])
49. Learning spatiotemporal features from incomplete data for traffic flow prediction using hybrid deep neural networks. (arXiv:2204.10222v1 [cs.LG])
50. Handling Imbalanced Classification Problems With Support Vector Machines via Evolutionary Bilevel Optimization. (arXiv:2204.10231v1 [cs.LG])
51. Revisiting Gaussian mixture critic in off-policy reinforcement learning: a sample-based approach. (arXiv:2204.10256v1 [cs.LG])
52. A Hierarchical N-Gram Framework for Zero-Shot Link Prediction. (arXiv:2204.10293v1 [cs.CL])
53. Learning to Fold Real Garments with One Arm: A Case Study in Cloud-Based Robotics Research. (arXiv:2204.10297v1 [cs.RO])
54. Adversarial Contrastive Learning by Permuting Cluster Assignments. (arXiv:2204.10314v1 [cs.LG])
55. Feature anomaly detection system (FADS) for intelligent manufacturing. (arXiv:2204.10318v1 [cs.CV])
56. SelfD: Self-Learning Large-Scale Driving Policies From the Web. (arXiv:2204.10320v1 [cs.CV])
57. Backplay: "Man muss immer umkehren". (arXiv:1807.06919v5 [cs.LG] UPDATED)
58. An Improved Transfer Model: Randomized Transferable Machine. (arXiv:2011.13629v2 [cs.LG] UPDATED)
59. Towards Deepening Graph Neural Networks: A GNTK-based Optimization Perspective. (arXiv:2103.03113v3 [cs.LG] UPDATED)
60. Model-Based Offline Planning with Trajectory Pruning. (arXiv:2105.07351v3 [cs.AI] UPDATED)
61. Image2Point: 3D Point-Cloud Understanding with Pretrained 2D ConvNets. (arXiv:2106.04180v2 [cs.CV] UPDATED)
62. Hybrid Memoised Wake-Sleep: Approximate Inference at the Discrete-Continuous Interface. (arXiv:2107.06393v2 [cs.CV] UPDATED)
63. On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v2 [cs.LG] UPDATED)
64. CoMPM: Context Modeling with Speaker's Pre-trained Memory Tracking for Emotion Recognition in Conversation. (arXiv:2108.11626v3 [cs.CL] UPDATED)
65. Do What Nature Did To Us: Evolving Plastic Recurrent Neural Networks For Task Generalization. (arXiv:2109.03554v3 [cs.AI] UPDATED)
66. Raising context awareness in motion forecasting. (arXiv:2109.08048v2 [cs.CV] UPDATED)
67. The Neural Data Router: Adaptive Control Flow in Transformers Improves Systematic Generalization. (arXiv:2110.07732v3 [cs.LG] UPDATED)
68. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v5 [cs.LG] UPDATED)
69. TND-NAS: Towards Non-Differentiable Objectives in Differentiable Neural Architecture Search. (arXiv:2111.03892v2 [cs.LG] UPDATED)
70. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v5 [cs.CV] UPDATED)
71. DeepGate: Learning Neural Representations of Logic Gates. (arXiv:2111.14616v3 [cs.LG] UPDATED)
72. Hybrid Curriculum Learning for Emotion Recognition in Conversation. (arXiv:2112.11718v2 [cs.CL] UPDATED)
73. Learning Higher-Order Programs without Meta-Interpretive Learning. (arXiv:2112.14603v3 [cs.AI] UPDATED)
74. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v3 [cs.LG] UPDATED)
75. Graph Convolutional Networks for Multi-modality Medical Imaging: Methods, Architectures, and Clinical Applications. (arXiv:2202.08916v3 [eess.IV] UPDATED)
76. Energy-Efficient Parking Analytics System using Deep Reinforcement Learning. (arXiv:2202.08973v2 [cs.CV] UPDATED)
77. Brazilian Court Documents Clustered by Similarity Together Using Natural Language Processing Approaches with Transformers. (arXiv:2204.07182v2 [cs.AI] UPDATED)
78. Visual Attention Methods in Deep Learning: An In-Depth Survey. (arXiv:2204.07756v2 [cs.CV] UPDATED)
79. MUGEN: A Playground for Video-Audio-Text Multimodal Understanding and GENeration. (arXiv:2204.08058v2 [cs.CV] UPDATED)
80. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images. (arXiv:2204.08454v3 [cs.CV] UPDATED)
81. Sound-Guided Semantic Video Generation. (arXiv:2204.09273v2 [cs.CV] UPDATED)
82. A Survey and Perspective on Artificial Intelligence for Security-Aware Electronic Design Automation. (arXiv:2204.09579v2 [cs.LG] UPDATED)
83. Perceiving the World: Question-guided Reinforcement Learning for Text-based Games. (arXiv:2204.09597v2 [cs.CL] UPDATED)
84. Learning to Accelerate by the Methods of Step-size Planning. (arXiv:2204.01705v3 [cs.LG] CROSS LISTED)

