# Your interest papers
---
## cs.CV
---
### Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
- Authors : Varun Mannam, Jacob Brandt, Scott Howard
- Link : [http://arxiv.org/abs/2201.00820](http://arxiv.org/abs/2201.00820)
> ABSTRACT  :  Fluorescence microscopy has been a significant tool to observe long-term imaging of embryos (in vivo) growth over time. However, cumulative **exposure** is phototoxic to such sensitive live samples. While techniques like light-sheet fluorescence microscopy (LSFM) allow for reduced **exposure**, it is not well suited for deep imaging models. Other computational techniques are computationally expensive and often lack **restoration** quality. To address this challenge, one can use various low-dosage imaging techniques that are developed to achieve the 3D volume reconstruction using a few slices in the axial direction (z-axis); however, they often lack **restoration** quality. Also, acquiring dense images (with small steps) in the axial direction is computationally expensive. To address this challenge, we present a compressive sensing (CS) based approach to fully reconstruct 3D volumes with the same signal-to-noise ratio (SNR) with less than half of the excitation dosage. We present the theory and experimentally validate the approach. To demonstrate our technique, we capture a 3D volume of the RFP labeled neurons in the zebrafish embryo spinal cord (30um thickness) with the axial sampling of 0.1um using a confocal microscope. From the results, we observe the CS-based approach achieves accurate 3D volume reconstruction from less than 20% of the entire stack optical sections. The developed CS-based methodology in this work can be easily applied to other deep imaging modalities such as two-photon and light-sheet microscopy, where reducing sample photo-toxicity is a critical challenge.  
### Interactive Attention AI to translate **low light** photos to captions for **night** scene understanding in women safety. (arXiv:2201.00969v1 [cs.CV])
- Authors : Arun Muthuraj
- Link : [http://arxiv.org/abs/2201.00969](http://arxiv.org/abs/2201.00969)
> ABSTRACT  :  There is amazing progress in Deep Learning based models for Image captioning and Low Light image **enhancement**. For the first time in literature, this paper develops a Deep Learning model that translates **night** scenes to sentences, opening new possibilities for AI applications in the safety of visually impaired women. Inspired by Image Captioning and Visual Question Answering, a novel Interactive Image Captioning is developed. A user can make the AI focus on any chosen person of interest by influencing the attention scoring. Attention context vectors are computed from CNN feature vectors and user-provided start word. The Encoder-Attention-Decoder neural network learns to produce captions from low brightness images. This paper demonstrates how women safety can be enabled by researching a novel AI capability in the Interactive Vision-Language model for perception of the environment in the **night**.  
### MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v1 [eess.IV])
- Authors : Xinyi Ying, Yingqian Wang, Longguang Wang, Weidong Sheng, Li Liu, Zaipin Lin, Shilin Zho
- Link : [http://arxiv.org/abs/2201.01014](http://arxiv.org/abs/2201.01014)
> ABSTRACT  :  Infrared small target super-resolution (SR) aims to recover reliable and detailed high-resolution image with highcontrast targets from its low-resolution counterparts. Since the infrared small target lacks color and fine structure information, it is significant to exploit the supplementary information among sequence images to enhance the target. In this paper, we propose the first infrared small target SR method named local motion and contrast prior driven deep network (MoCoPnet) to integrate the domain knowledge of infrared small target into deep network, which can mitigate the intrinsic feature scarcity of infrared small targets. Specifically, motivated by the local motion prior in the spatio-temporal dimension, we propose a local spatiotemporal attention module to perform implicit frame alignment and incorporate the local spatio-temporal information to enhance the local features (especially for small targets). Motivated by the local contrast prior in the spatial dimension, we propose a central difference residual group to incorporate the central difference convolution into the feature extraction backbone, which can achieve center-oriented gradient-aware feature extraction to further improve the target contrast. Extensive experiments have demonstrated that our method can recover accurate spatial dependency and improve the target contrast. Comparative results show that MoCoPnet can outperform the state-of-the-art video SR and single image SR methods in terms of both SR performance and target **enhancement**. Based on the SR results, we further investigate the influence of SR on infrared small target detection and the experimental results demonstrate that MoCoPnet promotes the detection performance. The code is available at https://github.com/XinyiYing/MoCoPnet.  
### What Hinders Perceptual Quality of PSNR-oriented Methods?. (arXiv:2201.01034v1 [eess.IV])
- Authors : Tianshuo Xu, Peng Mi, Xiawu Zheng, Lijiang Li, Fei Chao, Guannan Jiang, Wei Zhang, Yiyi Zhou, Rongrong Ji
- Link : [http://arxiv.org/abs/2201.01034](http://arxiv.org/abs/2201.01034)
> ABSTRACT  :  In this paper, we discover two factors that inhibit POMs from achieving high perceptual quality: 1) center-oriented optimization (COO) problem and 2) model's low-frequency tendency. First, POMs tend to generate an SR image whose position in the feature space is closest to the distribution center of all potential high-resolution (HR) images, resulting in such POMs losing high-frequency details. Second, $90\%$ area of an image consists of low-frequency signals; in contrast, human perception relies on an image's high-frequency details. However, POMs apply the same calculation to process different-frequency areas, so that POMs tend to restore the low-frequency regions. Based on these two factors, we propose a Detail Enhanced Contrastive Loss (DECLoss), by combining a high-frequency **enhancement** module and spatial contrastive learning module, to reduce the influence of the COO problem and low-Frequency tendency. Experimental results show the efficiency and effectiveness when applying DECLoss on several regular SR models. E.g, in EDSR, our proposed method achieves 3.60$\times$ faster learning speed compared to a GAN-based method with a subtle degradation in visual quality. In addition, our final results show that an SR network equipped with our DECLoss generates more realistic and visually pleasing textures compared to state-of-the-art methods. %The source code of the proposed method is included in the supplementary material and will be made publicly available in the future.  
### Short Range Correlation Transformer for Occluded Person Re-Identification. (arXiv:2201.01090v1 [cs.CV])
- Authors : Yunbin Zhao, Songhao Zhu, Dongsheng Wang, Zhiwei Liang
- Link : [http://arxiv.org/abs/2201.01090](http://arxiv.org/abs/2201.01090)
> ABSTRACT  :  Occluded person re-identification is one of the challenging areas of computer vision, which faces problems such as inefficient feature representation and low recognition accuracy. Convolutional neural network pays more attention to the extraction of local features, therefore it is difficult to extract features of occluded pedestrians and the effect is not so satisfied. Recently, vision transformer is introduced into the field of re-identification and achieves the most advanced results by constructing the relationship of global features between patch sequences. However, the performance of vision transformer in extracting local features is inferior to that of convolutional neural network. Therefore, we design a partial feature transformer-based person re-identification framework named PFT. The proposed PFT utilizes three modules to enhance the efficiency of vision transformer. (1) Patch full dimension **enhancement** module. We design a learnable tensor with the same size as patch sequences, which is full-dimensional and deeply embedded in patch sequences to enrich the diversity of training samples. (2) Fusion and reconstruction module. We extract the less important part of obtained patch sequences, and fuse them with original patch sequence to reconstruct the original patch sequences. (3) Spatial Slicing Module. We slice and group patch sequences from spatial direction, which can effectively improve the short-range correlation of patch sequences. Experimental results over occluded and holistic re-identification datasets demonstrate that the proposed PFT network achieves superior performance consistently and outperforms the state-of-the-art methods.  
### Online Multi-Object Tracking with Unsupervised Re-Identification Learning and Occlusion Estimation. (arXiv:2201.01297v1 [cs.CV])
- Authors : Qiankun Liu, Dongdong Chen, Qi Chu, Lu Yuan, Bin Liu, **Lei Zhang**, Nenghai Yu
- Link : [http://arxiv.org/abs/2201.01297](http://arxiv.org/abs/2201.01297)
> ABSTRACT  :  Occlusion between different objects is a typical challenge in Multi-Object Tracking (MOT), which often leads to inferior tracking results due to the missing detected objects. The common practice in multi-object tracking is re-identifying the missed objects after their reappearance. Though tracking performance can be boosted by the re-identification, the annotation of identity is required to train the model. In addition, such practice of re-identification still can not track those highly occluded objects when they are missed by the detector. In this paper, we focus on online multi-object tracking and design two novel modules, the unsupervised re-identification learning module and the occlusion estimation module, to handle these problems. Specifically, the proposed unsupervised re-identification learning module does not require any (pseudo) identity information nor suffer from the scalability issue. The proposed occlusion estimation module tries to predict the locations where occlusions happen, which are used to estimate the positions of missed objects by the detector. Our study shows that, when applied to state-of-the-art MOT methods, the proposed unsupervised re-identification learning is comparable to supervised re-identification learning, and the tracking performance is further improved by the proposed occlusion estimation module.  
### Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v2 [cs.CV] UPDATED)
- Authors : Yifan Jiang, Bart Wronski, Ben Mildenhall, Jon Barron, Zhangyang Wang, Tianfan Xue
- Link : [http://arxiv.org/abs/2201.00392](http://arxiv.org/abs/2201.00392)
> ABSTRACT  :  Many image processing networks apply a single set of static convolutional kernels across the entire input image, which is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Recent works in classification, segmentation, and image **restoration** have demonstrated that dynamic kernels outperform static kernels at modeling local image statistics. However, these works often adopt per-pixel convolution kernels, which introduce high memory and computation costs. To achieve spatial-varying processing without significant overhead, we present Malleable Convolution (MalleConv), as an efficient variant of dynamic convolution. The weights of MalleConv are dynamically produced by an efficient predictor network capable of generating content-dependent outputs at specific spatial locations. Unlike previous works, MalleConv generates a much smaller set of spatially-varying kernels from input, which enlarges the network's receptive field and significantly reduces computational and memory costs. These kernels are then applied to a full-resolution feature map through an efficient slice-and-conv operator with minimum memory overhead. We further build an efficient denoising network using MalleConv, coined as MalleNet. It achieves high quality results without very deep architecture, e.g., reaching 8.91x faster speed compared to the best performed denoising algorithms (SwinIR), while maintaining similar performance. We also show that a single MalleConv added to a standard convolution-based backbone can contribute significantly to reducing the computational cost or boosting image quality at a similar cost. Project page: https://yifanjiang.net/MalleConv.html  
## eess.IV
---
### Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
- Authors : Varun Mannam, Jacob Brandt, Scott Howard
- Link : [http://arxiv.org/abs/2201.00820](http://arxiv.org/abs/2201.00820)
> ABSTRACT  :  Fluorescence microscopy has been a significant tool to observe long-term imaging of embryos (in vivo) growth over time. However, cumulative **exposure** is phototoxic to such sensitive live samples. While techniques like light-sheet fluorescence microscopy (LSFM) allow for reduced **exposure**, it is not well suited for deep imaging models. Other computational techniques are computationally expensive and often lack **restoration** quality. To address this challenge, one can use various low-dosage imaging techniques that are developed to achieve the 3D volume reconstruction using a few slices in the axial direction (z-axis); however, they often lack **restoration** quality. Also, acquiring dense images (with small steps) in the axial direction is computationally expensive. To address this challenge, we present a compressive sensing (CS) based approach to fully reconstruct 3D volumes with the same signal-to-noise ratio (SNR) with less than half of the excitation dosage. We present the theory and experimentally validate the approach. To demonstrate our technique, we capture a 3D volume of the RFP labeled neurons in the zebrafish embryo spinal cord (30um thickness) with the axial sampling of 0.1um using a confocal microscope. From the results, we observe the CS-based approach achieves accurate 3D volume reconstruction from less than 20% of the entire stack optical sections. The developed CS-based methodology in this work can be easily applied to other deep imaging modalities such as two-photon and light-sheet microscopy, where reducing sample photo-toxicity is a critical challenge.  
### MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v1 [eess.IV])
- Authors : Xinyi Ying, Yingqian Wang, Longguang Wang, Weidong Sheng, Li Liu, Zaipin Lin, Shilin Zho
- Link : [http://arxiv.org/abs/2201.01014](http://arxiv.org/abs/2201.01014)
> ABSTRACT  :  Infrared small target super-resolution (SR) aims to recover reliable and detailed high-resolution image with highcontrast targets from its low-resolution counterparts. Since the infrared small target lacks color and fine structure information, it is significant to exploit the supplementary information among sequence images to enhance the target. In this paper, we propose the first infrared small target SR method named local motion and contrast prior driven deep network (MoCoPnet) to integrate the domain knowledge of infrared small target into deep network, which can mitigate the intrinsic feature scarcity of infrared small targets. Specifically, motivated by the local motion prior in the spatio-temporal dimension, we propose a local spatiotemporal attention module to perform implicit frame alignment and incorporate the local spatio-temporal information to enhance the local features (especially for small targets). Motivated by the local contrast prior in the spatial dimension, we propose a central difference residual group to incorporate the central difference convolution into the feature extraction backbone, which can achieve center-oriented gradient-aware feature extraction to further improve the target contrast. Extensive experiments have demonstrated that our method can recover accurate spatial dependency and improve the target contrast. Comparative results show that MoCoPnet can outperform the state-of-the-art video SR and single image SR methods in terms of both SR performance and target **enhancement**. Based on the SR results, we further investigate the influence of SR on infrared small target detection and the experimental results demonstrate that MoCoPnet promotes the detection performance. The code is available at https://github.com/XinyiYing/MoCoPnet.  
### What Hinders Perceptual Quality of PSNR-oriented Methods?. (arXiv:2201.01034v1 [eess.IV])
- Authors : Tianshuo Xu, Peng Mi, Xiawu Zheng, Lijiang Li, Fei Chao, Guannan Jiang, Wei Zhang, Yiyi Zhou, Rongrong Ji
- Link : [http://arxiv.org/abs/2201.01034](http://arxiv.org/abs/2201.01034)
> ABSTRACT  :  In this paper, we discover two factors that inhibit POMs from achieving high perceptual quality: 1) center-oriented optimization (COO) problem and 2) model's low-frequency tendency. First, POMs tend to generate an SR image whose position in the feature space is closest to the distribution center of all potential high-resolution (HR) images, resulting in such POMs losing high-frequency details. Second, $90\%$ area of an image consists of low-frequency signals; in contrast, human perception relies on an image's high-frequency details. However, POMs apply the same calculation to process different-frequency areas, so that POMs tend to restore the low-frequency regions. Based on these two factors, we propose a Detail Enhanced Contrastive Loss (DECLoss), by combining a high-frequency **enhancement** module and spatial contrastive learning module, to reduce the influence of the COO problem and low-Frequency tendency. Experimental results show the efficiency and effectiveness when applying DECLoss on several regular SR models. E.g, in EDSR, our proposed method achieves 3.60$\times$ faster learning speed compared to a GAN-based method with a subtle degradation in visual quality. In addition, our final results show that an SR network equipped with our DECLoss generates more realistic and visually pleasing textures compared to state-of-the-art methods. %The source code of the proposed method is included in the supplementary material and will be made publicly available in the future.  
### Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v2 [cs.CV] UPDATED)
- Authors : Yifan Jiang, Bart Wronski, Ben Mildenhall, Jon Barron, Zhangyang Wang, Tianfan Xue
- Link : [http://arxiv.org/abs/2201.00392](http://arxiv.org/abs/2201.00392)
> ABSTRACT  :  Many image processing networks apply a single set of static convolutional kernels across the entire input image, which is sub-optimal for natural images, as they often consist of heterogeneous visual patterns. Recent works in classification, segmentation, and image **restoration** have demonstrated that dynamic kernels outperform static kernels at modeling local image statistics. However, these works often adopt per-pixel convolution kernels, which introduce high memory and computation costs. To achieve spatial-varying processing without significant overhead, we present Malleable Convolution (MalleConv), as an efficient variant of dynamic convolution. The weights of MalleConv are dynamically produced by an efficient predictor network capable of generating content-dependent outputs at specific spatial locations. Unlike previous works, MalleConv generates a much smaller set of spatially-varying kernels from input, which enlarges the network's receptive field and significantly reduces computational and memory costs. These kernels are then applied to a full-resolution feature map through an efficient slice-and-conv operator with minimum memory overhead. We further build an efficient denoising network using MalleConv, coined as MalleNet. It achieves high quality results without very deep architecture, e.g., reaching 8.91x faster speed compared to the best performed denoising algorithms (SwinIR), while maintaining similar performance. We also show that a single MalleConv added to a standard convolution-based backbone can contribute significantly to reducing the computational cost or boosting image quality at a similar cost. Project page: https://yifanjiang.net/MalleConv.html  
## cs.LG
---
### Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
- Authors : Varun Mannam, Jacob Brandt, Scott Howard
- Link : [http://arxiv.org/abs/2201.00820](http://arxiv.org/abs/2201.00820)
> ABSTRACT  :  Fluorescence microscopy has been a significant tool to observe long-term imaging of embryos (in vivo) growth over time. However, cumulative **exposure** is phototoxic to such sensitive live samples. While techniques like light-sheet fluorescence microscopy (LSFM) allow for reduced **exposure**, it is not well suited for deep imaging models. Other computational techniques are computationally expensive and often lack **restoration** quality. To address this challenge, one can use various low-dosage imaging techniques that are developed to achieve the 3D volume reconstruction using a few slices in the axial direction (z-axis); however, they often lack **restoration** quality. Also, acquiring dense images (with small steps) in the axial direction is computationally expensive. To address this challenge, we present a compressive sensing (CS) based approach to fully reconstruct 3D volumes with the same signal-to-noise ratio (SNR) with less than half of the excitation dosage. We present the theory and experimentally validate the approach. To demonstrate our technique, we capture a 3D volume of the RFP labeled neurons in the zebrafish embryo spinal cord (30um thickness) with the axial sampling of 0.1um using a confocal microscope. From the results, we observe the CS-based approach achieves accurate 3D volume reconstruction from less than 20% of the entire stack optical sections. The developed CS-based methodology in this work can be easily applied to other deep imaging modalities such as two-photon and light-sheet microscopy, where reducing sample photo-toxicity is a critical challenge.  
### Interactive Attention AI to translate **low light** photos to captions for **night** scene understanding in women safety. (arXiv:2201.00969v1 [cs.CV])
- Authors : Arun Muthuraj
- Link : [http://arxiv.org/abs/2201.00969](http://arxiv.org/abs/2201.00969)
> ABSTRACT  :  There is amazing progress in Deep Learning based models for Image captioning and Low Light image **enhancement**. For the first time in literature, this paper develops a Deep Learning model that translates **night** scenes to sentences, opening new possibilities for AI applications in the safety of visually impaired women. Inspired by Image Captioning and Visual Question Answering, a novel Interactive Image Captioning is developed. A user can make the AI focus on any chosen person of interest by influencing the attention scoring. Attention context vectors are computed from CNN feature vectors and user-provided start word. The Encoder-Attention-Decoder neural network learns to produce captions from low brightness images. This paper demonstrates how women safety can be enabled by researching a novel AI capability in the Interactive Vision-Language model for perception of the environment in the **night**.  
### Towards Fair Recommendation in Two-Sided Platforms. (arXiv:2201.01180v1 [cs.IR])
- Authors : Arpita Biswas, Niloy Ganguly, Abhijnan Chakraborty
- Link : [http://arxiv.org/abs/2201.01180](http://arxiv.org/abs/2201.01180)
> ABSTRACT  :  Many online platforms today (such as Amazon, Netflix, Spotify, LinkedIn, and AirBnB) can be thought of as two-sided markets with producers and customers of goods and services. Traditionally, recommendation services in these platforms have focused on maximizing customer satisfaction by tailoring the results according to the personalized preferences of individual customers. However, our investigation reinforces the fact that such customer-centric design of these services may lead to unfair distribution of **exposure** to the producers, which may adversely impact their well-being. On the other hand, a pure producer-centric design might become unfair to the customers. As more and more people are depending on such platforms to earn a living, it is important to ensure fairness to both producers and customers. In this work, by mapping a fair personalized recommendation problem to a constrained version of the problem of fairly allocating indivisible goods, we propose to provide fairness guarantees for both sides. Formally, our proposed {\em FairRec} algorithm guarantees Maxi-Min Share ($\alpha$-MMS) of **exposure** for the producers, and Envy-Free up to One Item (EF1) fairness for the customers. Extensive evaluations over multiple real-world datasets show the effectiveness of {\em FairRec} in ensuring two-sided fairness while incurring a marginal loss in overall recommendation quality. Finally, we present a modification of FairRec (named as FairRecPlus) that at the cost of additional computation time, improves the recommendation performance for the customers, while maintaining the same fairness guarantees.  
### Adaptive Template **Enhancement** for Improved Person Recognition using Small Datasets. (arXiv:2201.01218v1 [eess.SP])
- Authors : Su Yang, Sanaul Hoque, Farzin Deravi
- Link : [http://arxiv.org/abs/2201.01218](http://arxiv.org/abs/2201.01218)
> ABSTRACT  :  A novel instance-based method for the classification of electroencephalography (EEG) signals is presented and evaluated in this paper. The non-stationary nature of the EEG signals, coupled with the demanding task of pattern recognition with limited training data as well as the potentially noisy signal acquisition conditions, have motivated the work reported in this study. The proposed adaptive template **enhancement** mechanism transforms the feature-level instances by treating each feature dimension separately, hence resulting in improved class separation and better query-class matching. The proposed new instance-based learning algorithm is compared with a few related algorithms in a number of scenarios. A clinical grade 64-electrode EEG database, as well as a low-quality (high-noise level) EEG database obtained with a low-cost system using a single dry sensor have been used for evaluations in biometric person recognition. The proposed approach demonstrates significantly improved classification accuracy in both identification and verification scenarios. In particular, this new method is seen to provide a good classification performance for noisy EEG data, indicating its potential suitability for a wide range of applications.  
## cs.AI
---
### Short Range Correlation Transformer for Occluded Person Re-Identification. (arXiv:2201.01090v1 [cs.CV])
- Authors : Yunbin Zhao, Songhao Zhu, Dongsheng Wang, Zhiwei Liang
- Link : [http://arxiv.org/abs/2201.01090](http://arxiv.org/abs/2201.01090)
> ABSTRACT  :  Occluded person re-identification is one of the challenging areas of computer vision, which faces problems such as inefficient feature representation and low recognition accuracy. Convolutional neural network pays more attention to the extraction of local features, therefore it is difficult to extract features of occluded pedestrians and the effect is not so satisfied. Recently, vision transformer is introduced into the field of re-identification and achieves the most advanced results by constructing the relationship of global features between patch sequences. However, the performance of vision transformer in extracting local features is inferior to that of convolutional neural network. Therefore, we design a partial feature transformer-based person re-identification framework named PFT. The proposed PFT utilizes three modules to enhance the efficiency of vision transformer. (1) Patch full dimension **enhancement** module. We design a learnable tensor with the same size as patch sequences, which is full-dimensional and deeply embedded in patch sequences to enrich the diversity of training samples. (2) Fusion and reconstruction module. We extract the less important part of obtained patch sequences, and fuse them with original patch sequence to reconstruct the original patch sequences. (3) Spatial Slicing Module. We slice and group patch sequences from spatial direction, which can effectively improve the short-range correlation of patch sequences. Experimental results over occluded and holistic re-identification datasets demonstrate that the proposed PFT network achieves superior performance consistently and outperforms the state-of-the-art methods.  
### Towards Fair Recommendation in Two-Sided Platforms. (arXiv:2201.01180v1 [cs.IR])
- Authors : Arpita Biswas, Niloy Ganguly, Abhijnan Chakraborty
- Link : [http://arxiv.org/abs/2201.01180](http://arxiv.org/abs/2201.01180)
> ABSTRACT  :  Many online platforms today (such as Amazon, Netflix, Spotify, LinkedIn, and AirBnB) can be thought of as two-sided markets with producers and customers of goods and services. Traditionally, recommendation services in these platforms have focused on maximizing customer satisfaction by tailoring the results according to the personalized preferences of individual customers. However, our investigation reinforces the fact that such customer-centric design of these services may lead to unfair distribution of **exposure** to the producers, which may adversely impact their well-being. On the other hand, a pure producer-centric design might become unfair to the customers. As more and more people are depending on such platforms to earn a living, it is important to ensure fairness to both producers and customers. In this work, by mapping a fair personalized recommendation problem to a constrained version of the problem of fairly allocating indivisible goods, we propose to provide fairness guarantees for both sides. Formally, our proposed {\em FairRec} algorithm guarantees Maxi-Min Share ($\alpha$-MMS) of **exposure** for the producers, and Envy-Free up to One Item (EF1) fairness for the customers. Extensive evaluations over multiple real-world datasets show the effectiveness of {\em FairRec} in ensuring two-sided fairness while incurring a marginal loss in overall recommendation quality. Finally, we present a modification of FairRec (named as FairRecPlus) that at the cost of additional computation time, improves the recommendation performance for the customers, while maintaining the same fairness guarantees.  
### A Constraint Programming Approach to Weighted Isomorphic Mapping of Fragment-based Shape Signatures. (arXiv:2112.10892v2 [cs.AI] UPDATED)
- Authors : Thierry Petit
- Link : [http://arxiv.org/abs/2112.10892](http://arxiv.org/abs/2112.10892)
> ABSTRACT  :  Fragment-based shape signature techniques have proven to be powerful tools for computer-aided drug design. They allow scientists to search for target molecules with some similarity to a known active compound. They do not require reference to the full underlying chemical structure, which is essential to deal with chemical databases containing millions of compounds. However, finding the optimal match of a part of the fragmented compound can be time-consuming. In this paper, we use constraint programming to solve this specific problem. It involves finding a weighted assignment of fragments subject to connectivity constraints. Our experiments demonstrate the practical relevance of our approach and open new perspectives, including generating multiple, diverse solutions. Our approach constitutes an original use of a constraint solver in a **real time** setting, where propagation allows to avoid an enumeration of weighted paths. The model must remain robust to the addition of constraints making some instances not tractable. This particular context requires the use of unusual criteria for the choice of the model: lightweight, standard propagation algorithms, data structures without prohibitive constant cost. The objective is not to design new, complex algorithms to solve difficult instances.  
# Paper List
---
## cs.CV
---
**72** new papers in cs.CV:-) 
1. Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
2. Runway Extraction and Improved Mapping from Space Imagery. (arXiv:2201.00848v1 [cs.CV])
3. Delving into Sample Loss Curve to Embrace Noisy and Imbalanced Data. (arXiv:2201.00849v1 [cs.LG])
4. Gaussian-Hermite Moment Invariants of General Vector Functions to Rotation-Affine Transform. (arXiv:2201.00877v1 [cs.CV])
5. Rice Diseases Detection and Classification Using Attention Based Neural Network and Bayesian Optimization. (arXiv:2201.00893v1 [cs.CV])
6. A Gradient Mapping Guided Explainable Deep Neural Network for Extracapsular Extension Identification in 3D Head and Neck Cancer Computed Tomography Images. (arXiv:2201.00895v1 [eess.IV])
7. External Attention Assisted Multi-Phase Splenic Vascular Injury Segmentation with Limited Data. (arXiv:2201.00942v1 [eess.IV])
8. HWRCNet: Handwritten Word Recognition in JPEG Compressed Domain using CNN-BiLSTM Network. (arXiv:2201.00947v1 [cs.CV])
9. Stain Normalized Breast Histopathology Image Recognition using Convolutional Neural Networks for Cancer Detection. (arXiv:2201.00957v1 [eess.IV])
10. AI visualization in Nanoscale Microscopy. (arXiv:2201.00966v1 [cs.CV])
11. Interactive Attention AI to translate **low light** photos to captions for **night** scene understanding in women safety. (arXiv:2201.00969v1 [cs.CV])
12. StyleM: Stylized Metrics for Image Captioning Built with Contrastive N-grams. (arXiv:2201.00975v1 [cs.CV])
13. Underwater Object Classification and Detection: first results and open challenges. (arXiv:2201.00977v1 [cs.CV])
14. PyramidTNT: Improved Transformer-in-Transformer Baselines with Pyramid Architecture. (arXiv:2201.00978v1 [cs.CV])
15. Variational Stacked Local Attention Networks for Diverse Video Captioning. (arXiv:2201.00985v1 [cs.CV])
16. Attention Mechanism Meets with Hybrid Dense Network for Hyperspectral Image Classification. (arXiv:2201.01001v1 [cs.CV])
17. Multi-Representation Adaptation Network for Cross-domain Image Classification. (arXiv:2201.01002v1 [cs.CV])
18. Aligning Domain-specific Distribution and Classifier for Cross-domain Classification from Multiple Sources. (arXiv:2201.01003v1 [cs.LG])
19. Learning to Generate Novel Classes for Deep Metric Learning. (arXiv:2201.01008v1 [cs.CV])
20. MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v1 [eess.IV])
21. Detailed Facial Geometry Recovery from Multi-view Images by Learning an Implicit Function. (arXiv:2201.01016v1 [cs.CV])
22. Weakly-supervised continual learning for class-incremental segmentation. (arXiv:2201.01029v1 [cs.CV])
23. A Robust Visual Sampling Model Inspired by Receptive Field. (arXiv:2201.01030v1 [cs.CV])
24. What Hinders Perceptual Quality of PSNR-oriented Methods?. (arXiv:2201.01034v1 [eess.IV])
25. Sound and Visual Representation Learning with Multiple Pretraining Tasks. (arXiv:2201.01046v1 [cs.CV])
26. DIAL: Deep Interactive and Active Learning for Semantic Segmentation in Remote Sensing. (arXiv:2201.01047v1 [cs.CV])
27. Towards Unsupervised Open World Semantic Segmentation. (arXiv:2201.01073v1 [cs.CV])
28. Towards Understanding and Harnessing the Effect of Image Transformation in Adversarial Detection. (arXiv:2201.01080v1 [cs.CV])
29. Identifying the exterior image of buildings on a 3D map and extracting elevation information using deep learning and digital image processing. (arXiv:2201.01081v1 [cs.CV])
30. Learning Quality-aware Representation for Multi-person Pose Regression. (arXiv:2201.01087v1 [cs.CV])
31. Short Range Correlation Transformer for Occluded Person Re-Identification. (arXiv:2201.01090v1 [cs.CV])
32. Towards Transferable Unrestricted Adversarial Examples with Minimum Changes. (arXiv:2201.01102v1 [cs.CV])
33. Data Augmentation for Depression Detection Using Skeleton-Based Gait Information. (arXiv:2201.01115v1 [cs.CV])
34. DeepVisualInsight: Time-Travelling Visualization for Spatio-Temporal Causality of Deep Classification Training. (arXiv:2201.01155v1 [cs.LG])
35. DeepFGS: Fine-Grained Scalable Coding for Learned Image Compression. (arXiv:2201.01173v1 [eess.IV])
36. Automated 3D reconstruction of LoD2 and LoD1 models for all 10 million buildings of the Netherlands. (arXiv:2201.01191v1 [cs.CV])
37. The cluster structure function. (arXiv:2201.01222v1 [cs.LG])
38. Robust Semi-supervised Federated Learning for Images Automatic Recognition in Internet of Drones. (arXiv:2201.01230v1 [cs.LG])
39. Transfer Learning for Retinal Vascular Disease Detection: A Pilot Study with Diabetic Retinopathy and Retinopathy of Prematurity. (arXiv:2201.01250v1 [cs.LG])
40. Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images. (arXiv:2201.01266v1 [eess.IV])
41. Local Quadruple Pattern: A Novel Descriptor for Facial Image Recognition and Retrieval. (arXiv:2201.01275v1 [cs.CV])
42. Local Directional Gradient Pattern: A Local Descriptor for Face Recognition. (arXiv:2201.01276v1 [cs.CV])
43. Self-supervised Learning from 100 Million Medical Images. (arXiv:2201.01283v1 [cs.CV])
44. A Transformer-Based Siamese Network for Change Detection. (arXiv:2201.01293v1 [cs.CV])
45. 3DVSR: 3D EPI Volume-based Approach for Angular and Spatial Light field Image Super-resolution. (arXiv:2201.01294v1 [cs.CV])
46. Online Multi-Object Tracking with Unsupervised Re-Identification Learning and Occlusion Estimation. (arXiv:2201.01297v1 [cs.CV])
47. Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via Geometry-Aware Adversarial Learning. (arXiv:2008.05058v4 [cs.CV] UPDATED)
48. Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization. (arXiv:2008.08170v5 [math.OC] UPDATED)
49. Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training. (arXiv:2103.00673v2 [cs.CV] UPDATED)
50. A Survey On Universal Adversarial Attack. (arXiv:2103.01498v2 [cs.LG] UPDATED)
51. On the effectiveness of adversarial training against common corruptions. (arXiv:2103.02325v2 [cs.LG] UPDATED)
52. Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic Segmentation. (arXiv:2103.11594v3 [cs.CV] UPDATED)
53. Deep Implicit Statistical Shape Models for 3D Medical Image Delineation. (arXiv:2104.02847v2 [cs.CV] UPDATED)
54. Shadow Generation for Composite Image in Real-world Scenes. (arXiv:2104.10338v2 [cs.CV] UPDATED)
55. Cross-Domain and Disentangled Face Manipulation with 3D Guidance. (arXiv:2104.11228v2 [cs.CV] UPDATED)
56. Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v2 [cs.CV] UPDATED)
57. Tensor feature hallucination for few-shot learning. (arXiv:2106.05321v2 [cs.CV] UPDATED)
58. VisBuddy -- A Smart Wearable Assistant for the Visually Challenged. (arXiv:2108.07761v3 [cs.CV] UPDATED)
59. Anchor DETR: Query Design for Transformer-Based Object Detection. (arXiv:2109.07107v2 [cs.CV] UPDATED)
60. Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks. (arXiv:2110.03825v4 [cs.LG] UPDATED)
61. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v6 [eess.IV] UPDATED)
62. Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements. (arXiv:2111.13630v2 [eess.IV] UPDATED)
63. Decomposing the Deep: Finding Class Specific Filters in Deep CNNs. (arXiv:2112.07719v2 [cs.CV] UPDATED)
64. Positional Encoding Augmented GAN for the Assessment of Wind Flow for Pedestrian Comfort in Urban Areas. (arXiv:2112.08447v2 [cs.CV] UPDATED)
65. Visual Microfossil Identification via Deep Metric Learning. (arXiv:2112.09490v2 [cs.CV] UPDATED)
66. Dual Path Structural Contrastive Embeddings for Learning Novel Objects. (arXiv:2112.12359v3 [cs.CV] UPDATED)
67. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v3 [eess.IV] UPDATED)
68. Associative Adversarial Learning Based on Selective Attack. (arXiv:2112.13989v2 [cs.CV] UPDATED)
69. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v2 [eess.IV] UPDATED)
70. On the Cross-dataset Generalization in License Plate Recognition. (arXiv:2201.00267v2 [cs.CV] UPDATED)
71. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v2 [cs.CV] UPDATED)
72. Revisiting Open World Object Detection. (arXiv:2201.00471v2 [cs.CV] UPDATED)
## eess.IV
---
**22** new papers in eess.IV:-) 
1. Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
2. A Gradient Mapping Guided Explainable Deep Neural Network for Extracapsular Extension Identification in 3D Head and Neck Cancer Computed Tomography Images. (arXiv:2201.00895v1 [eess.IV])
3. External Attention Assisted Multi-Phase Splenic Vascular Injury Segmentation with Limited Data. (arXiv:2201.00942v1 [eess.IV])
4. HWRCNet: Handwritten Word Recognition in JPEG Compressed Domain using CNN-BiLSTM Network. (arXiv:2201.00947v1 [cs.CV])
5. Stain Normalized Breast Histopathology Image Recognition using Convolutional Neural Networks for Cancer Detection. (arXiv:2201.00957v1 [eess.IV])
6. Attention Mechanism Meets with Hybrid Dense Network for Hyperspectral Image Classification. (arXiv:2201.01001v1 [cs.CV])
7. MoCoPnet: Exploring Local Motion and Contrast Priors for Infrared Small Target Super-Resolution. (arXiv:2201.01014v1 [eess.IV])
8. What Hinders Perceptual Quality of PSNR-oriented Methods?. (arXiv:2201.01034v1 [eess.IV])
9. DIAL: Deep Interactive and Active Learning for Semantic Segmentation in Remote Sensing. (arXiv:2201.01047v1 [cs.CV])
10. DeepFGS: Fine-Grained Scalable Coding for Learned Image Compression. (arXiv:2201.01173v1 [eess.IV])
11. Automated 3D reconstruction of LoD2 and LoD1 models for all 10 million buildings of the Netherlands. (arXiv:2201.01191v1 [cs.CV])
12. ExAID: A Multimodal Explanation Framework for Computer-Aided Diagnosis of Skin Lesions. (arXiv:2201.01249v1 [cs.AI])
13. Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images. (arXiv:2201.01266v1 [eess.IV])
14. 3DVSR: 3D EPI Volume-based Approach for Angular and Spatial Light field Image Super-resolution. (arXiv:2201.01294v1 [cs.CV])
15. Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training. (arXiv:2103.00673v2 [cs.CV] UPDATED)
16. Shadow Generation for Composite Image in Real-world Scenes. (arXiv:2104.10338v2 [cs.CV] UPDATED)
17. Objective crystallographic symmetry classifications of noisy and noise-free 2D periodic patterns with strong Fedorov type pseudosymmetries. (arXiv:2108.00829v4 [eess.IV] UPDATED)
18. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v6 [eess.IV] UPDATED)
19. Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements. (arXiv:2111.13630v2 [eess.IV] UPDATED)
20. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v3 [eess.IV] UPDATED)
21. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v2 [eess.IV] UPDATED)
22. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v2 [cs.CV] UPDATED)
## cs.LG
---
**109** new papers in cs.LG:-) 
1. Multivariate Time Series Regression with Graph Neural Networks. (arXiv:2201.00818v1 [cs.LG])
2. Low dosage 3D volume fluorescence microscopy imaging using compressive sensing. (arXiv:2201.00820v1 [eess.IV])
3. Deriving discriminative classifiers from generative models. (arXiv:2201.00844v1 [stat.ML])
4. Runway Extraction and Improved Mapping from Space Imagery. (arXiv:2201.00848v1 [cs.CV])
5. Delving into Sample Loss Curve to Embrace Noisy and Imbalanced Data. (arXiv:2201.00849v1 [cs.LG])
6. Monitoring and Anomaly Detection Actor-Critic Based Controlled Sensing. (arXiv:2201.00879v1 [cs.LG])
7. Biased Hypothesis Formation From Projection Pursuit. (arXiv:2201.00889v1 [cs.LG])
8. Deep neural networks for smooth approximation of physics with higher order and continuity B-spline base functions. (arXiv:2201.00904v1 [math.NA])
9. Classifying Autism from Crowdsourced Semi-Structured Speech Recordings: A Machine Learning Approach. (arXiv:2201.00927v1 [cs.SD])
10. An unfeasability view of neural network learning. (arXiv:2201.00945v1 [cs.LG])
11. Neural Piecewise-Constant Delay Differential Equations. (arXiv:2201.00960v1 [cs.LG])
12. Nipping in the Bud: Detection, Diffusion and Mitigation of Hate Speech on Social Media. (arXiv:2201.00961v1 [cs.SI])
13. Interactive Attention AI to translate **low light** photos to captions for **night** scene understanding in women safety. (arXiv:2201.00969v1 [cs.CV])
14. Submix: Practical Private Prediction for Large-Scale Language Models. (arXiv:2201.00971v1 [cs.LG])
15. Survey on the Convergence of Machine Learning and Blockchain. (arXiv:2201.00976v1 [cs.LG])
16. Multi-Representation Adaptation Network for Cross-domain Image Classification. (arXiv:2201.01002v1 [cs.CV])
17. Aligning Domain-specific Distribution and Classifier for Cross-domain Classification from Multiple Sources. (arXiv:2201.01003v1 [cs.LG])
18. Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection. (arXiv:2201.01004v1 [cs.LG])
19. Learning to Generate Novel Classes for Deep Metric Learning. (arXiv:2201.01008v1 [cs.CV])
20. CHERRY: a Computational metHod for accuratE pRediction of virus-pRokarYotic interactions using a graph encoder-decoder model. (arXiv:2201.01018v1 [q-bio.GN])
21. Learning Operators with Coupled Attention. (arXiv:2201.01032v1 [cs.LG])
22. Supervised Homogeneity Fusion: a Combinatorial Approach. (arXiv:2201.01036v1 [stat.ML])
23. McXai: Local model-agnostic explanation as two games. (arXiv:2201.01044v1 [cs.LG])
24. Trusting Machine Learning Results from Medical Procedures in the Operating Room. (arXiv:2201.01060v1 [cs.LG])
25. FROTE: Feedback Rule-Driven Oversampling for Editing Models. (arXiv:2201.01070v1 [cs.LG])
26. CEMENT: Incomplete Multi-View Weak-Label Learning with Long Tail Labels. (arXiv:2201.01079v1 [cs.LG])
27. A Heterogeneous In-Memory Computing Cluster For Flexible End-to-End Inference of Real-World Deep Neural Networks. (arXiv:2201.01089v1 [cs.AR])
28. Generating synthetic mobility data for a realistic population with RNNs to improve utility and privacy. (arXiv:2201.01139v1 [cs.LG])
29. Predicting Influenza A Viral Host Using PSSM and Word Embeddings. (arXiv:2201.01140v1 [cs.CL])
30. Evolutionary Multitasking AUC Optimization. (arXiv:2201.01145v1 [cs.LG])
31. Parity-based Cumulative Fairness-aware Boosting. (arXiv:2201.01148v1 [cs.LG])
32. DeepVisualInsight: Time-Travelling Visualization for Spatio-Temporal Causality of Deep Classification Training. (arXiv:2201.01155v1 [cs.LG])
33. Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning. (arXiv:2201.01163v1 [cs.GT])
34. Interpretable Low-Resource Legal Decision Making. (arXiv:2201.01164v1 [cs.LG])
35. Neural Myerson Auction for Truthful and Energy-Efficient Autonomous Aerial Data Delivery. (arXiv:2201.01170v1 [cs.GT])
36. Towards Fair Recommendation in Two-Sided Platforms. (arXiv:2201.01180v1 [cs.IR])
37. Modelling Cournot Games as Multi-agent Multi-armed Bandits. (arXiv:2201.01182v1 [cs.GT])
38. Graph Neural Networks: a bibliometrics overview. (arXiv:2201.01188v1 [cs.LG])
39. Two-level Graph Neural Network. (arXiv:2201.01190v1 [cs.LG])
40. Super-resolution in Molecular Dynamics Trajectory Reconstruction with Bi-Directional Neural Networks. (arXiv:2201.01195v1 [physics.comp-ph])
41. Rxn Hypergraph: a Hypergraph Attention Model for Chemical Reaction Representation. (arXiv:2201.01196v1 [cs.LG])
42. Quantifying Uncertainty in Deep Learning Approaches to Radio Galaxy Classification. (arXiv:2201.01203v1 [astro-ph.CO])
43. AutoBalance: Optimized Loss Functions for Imbalanced Data. (arXiv:2201.01212v1 [cs.LG])
44. Adaptive Template **Enhancement** for Improved Person Recognition using Small Datasets. (arXiv:2201.01218v1 [eess.SP])
45. A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning. (arXiv:2201.01221v1 [cs.LG])
46. The cluster structure function. (arXiv:2201.01222v1 [cs.LG])
47. Robust Semi-supervised Federated Learning for Images Automatic Recognition in Internet of Drones. (arXiv:2201.01230v1 [cs.LG])
48. COVID-19 Disease Progression Prediction via Audio Signals: A Longitudinal Study. (arXiv:2201.01232v1 [cs.SD])
49. On the Minimal Adversarial Perturbation for Deep Neural Networks with Provable Estimation Error. (arXiv:2201.01235v1 [cs.LG])
50. Efficient Quantum Feature Extraction for CNN-based Learning. (arXiv:2201.01246v1 [quant-ph])
51. Value Functions Factorization with Latent State Information Sharing in Decentralized Multi-Agent Policy Gradients. (arXiv:2201.01247v1 [cs.MA])
52. ExAID: A Multimodal Explanation Framework for Computer-Aided Diagnosis of Skin Lesions. (arXiv:2201.01249v1 [cs.AI])
53. Transfer Learning for Retinal Vascular Disease Detection: A Pilot Study with Diabetic Retinopathy and Retinopathy of Prematurity. (arXiv:2201.01250v1 [cs.LG])
54. Swin UNETR: Swin Transformers for Semantic Segmentation of Brain Tumors in MRI Images. (arXiv:2201.01266v1 [eess.IV])
55. Resilience Aspects in Distributed Wireless Electroencephalographic Sampling. (arXiv:2201.01272v1 [eess.SP])
56. Automated Graph Machine Learning: Approaches, Libraries and Directions. (arXiv:2201.01288v1 [cs.LG])
57. Self-directed Machine Learning. (arXiv:2201.01289v1 [cs.LG])
58. 3DVSR: 3D EPI Volume-based Approach for Angular and Spatial Light field Image Super-resolution. (arXiv:2201.01294v1 [cs.CV])
59. Deep learning architectures for nonlinear operator functions and nonlinear inverse problems. (arXiv:1912.11090v3 [math.OC] UPDATED)
60. Statistical and Topological Properties of Sliced Probability Divergences. (arXiv:2003.05783v3 [stat.ML] UPDATED)
61. Marginal likelihood computation for model selection and hypothesis testing: an extensive review. (arXiv:2005.08334v4 [stat.CO] UPDATED)
62. Learning to Play No-Press Diplomacy with Best Response Policy Iteration. (arXiv:2006.04635v4 [cs.LG] UPDATED)
63. Kendall transformation: a robust representation of continuous data for information theory. (arXiv:2006.15991v2 [cs.LG] UPDATED)
64. Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via Geometry-Aware Adversarial Learning. (arXiv:2008.05058v4 [cs.CV] UPDATED)
65. Accelerated Zeroth-Order and First-Order Momentum Methods from Mini to Minimax Optimization. (arXiv:2008.08170v5 [math.OC] UPDATED)
66. Adaptive and Multiple Time-scale Eligibility Traces for Online Deep Reinforcement Learning. (arXiv:2008.10040v2 [cs.RO] UPDATED)
67. Combat Data Shift in Few-shot Learning with Knowledge Graph. (arXiv:2101.11354v3 [cs.LG] UPDATED)
68. Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training. (arXiv:2103.00673v2 [cs.CV] UPDATED)
69. A Survey On Universal Adversarial Attack. (arXiv:2103.01498v2 [cs.LG] UPDATED)
70. On the effectiveness of adversarial training against common corruptions. (arXiv:2103.02325v2 [cs.LG] UPDATED)
71. Self-supervised representation learning from 12-lead ECG data. (arXiv:2103.12676v2 [eess.SP] UPDATED)
72. Neural Transfer Learning for Repairing Security Vulnerabilities in C Code. (arXiv:2104.08308v3 [cs.SE] UPDATED)
73. Neural Mean Discrepancy for Efficient Out-of-Distribution Detection. (arXiv:2104.11408v3 [cs.LG] UPDATED)
74. Differentially Private Transferrable Deep Learning with Membership-Mappings. (arXiv:2105.04615v3 [cs.LG] UPDATED)
75. Discovering Diverse Nearly Optimal Policies with Successor Features. (arXiv:2106.00669v2 [cs.AI] UPDATED)
76. Towards Deeper Deep Reinforcement Learning with Spectral Normalization. (arXiv:2106.01151v4 [cs.LG] UPDATED)
77. Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning. (arXiv:2106.01854v3 [cs.LG] UPDATED)
78. Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v2 [cs.CV] UPDATED)
79. Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v4 [cs.LG] UPDATED)
80. Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting. (arXiv:2106.09276v2 [stat.ML] UPDATED)
81. Variance-Aware Off-Policy Evaluation with Linear Function Approximation. (arXiv:2106.11960v2 [cs.LG] UPDATED)
82. Fast Approximation of the Sliced-Wasserstein Distance Using Concentration of Random Projections. (arXiv:2106.15427v2 [stat.ML] UPDATED)
83. Compensation Learning. (arXiv:2107.11921v4 [cs.LG] UPDATED)
84. Multimodal Co-learning: Challenges, Applications with Datasets, Recent Advances and Future Directions. (arXiv:2107.13782v3 [cs.LG] UPDATED)
85. Sequoia: A Software Framework to Unify Continual Learning Research. (arXiv:2108.01005v3 [cs.LG] UPDATED)
86. Graph Neural Networks With Lifting-based Adaptive Graph Wavelets. (arXiv:2108.01660v3 [cs.LG] UPDATED)
87. APReL: A Library for Active Preference-based Reward Learning Algorithms. (arXiv:2108.07259v2 [cs.LG] UPDATED)
88. Towards a Rigorous Evaluation of Time-series Anomaly Detection. (arXiv:2109.05257v2 [cs.LG] UPDATED)
89. Machine Learning-Based COVID-19 Patients Triage Algorithm using Patient-Generated Health Data from Nationwide Multicenter Database. (arXiv:2109.09001v3 [cs.LG] UPDATED)
90. PluGeN: Multi-Label Conditional Generation From Pre-Trained Models. (arXiv:2109.09011v2 [cs.LG] UPDATED)
91. Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration. (arXiv:2109.14285v3 [cs.LG] UPDATED)
92. Semi-relaxed Gromov-Wasserstein divergence with applications on graphs. (arXiv:2110.02753v2 [cs.LG] UPDATED)
93. Exploring Architectural Ingredients of Adversarially Robust Deep Neural Networks. (arXiv:2110.03825v4 [cs.LG] UPDATED)
94. Efficient Multi-Organ Segmentation Using SpatialConfiguration-Net with Low GPU Memory Requirements. (arXiv:2111.13630v2 [eess.IV] UPDATED)
95. Hierarchical Learning to Solve Partial Differential Equations Using Physics-Informed Neural Networks. (arXiv:2112.01254v2 [cs.LG] UPDATED)
96. Building a great multi-lingual teacher with sparsely-gated mixture of experts for speech recognition. (arXiv:2112.05820v3 [cs.CL] UPDATED)
97. Non Asymptotic Bounds for Optimization via Online Multiplicative Stochastic Gradient Descent. (arXiv:2112.07110v5 [stat.ML] UPDATED)
98. Positional Encoding Augmented GAN for the Assessment of Wind Flow for Pedestrian Comfort in Urban Areas. (arXiv:2112.08447v2 [cs.CV] UPDATED)
99. Visual Microfossil Identification via Deep Metric Learning. (arXiv:2112.09490v2 [cs.CV] UPDATED)
100. Common Misconceptions about Population Data. (arXiv:2112.10912v2 [cs.DB] UPDATED)
101. Extending CLIP for Category-to-image Retrieval in E-commerce. (arXiv:2112.11294v2 [cs.IR] UPDATED)
102. Profile Guided Optimization without Profiles: A Machine Learning Approach. (arXiv:2112.14679v2 [cs.PL] UPDATED)
103. On the Role of Neural Collapse in Transfer Learning. (arXiv:2112.15121v2 [cs.LG] UPDATED)
104. Learned Coarse Models for Efficient Turbulence Simulation. (arXiv:2112.15275v2 [physics.flu-dyn] UPDATED)
105. Calibrated Hyperspectral Image Reconstruction via Graph-based Self-Tuning Network. (arXiv:2112.15362v2 [eess.IV] UPDATED)
106. Transfer learning of phase transitions in percolation and directed percolation. (arXiv:2112.15516v3 [cond-mat.stat-mech] UPDATED)
107. A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More. (arXiv:2112.15594v2 [cs.LG] UPDATED)
108. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v2 [cs.LG] UPDATED)
109. Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI. (arXiv:2201.00650v2 [cs.LG] UPDATED)
## cs.AI
---
**61** new papers in cs.AI:-) 
1. Delving into Sample Loss Curve to Embrace Noisy and Imbalanced Data. (arXiv:2201.00849v1 [cs.LG])
2. Adaptive Model Predictive Control of Wheeled Mobile Robots. (arXiv:2201.00863v1 [cs.RO])
3. Neural Piecewise-Constant Delay Differential Equations. (arXiv:2201.00960v1 [cs.LG])
4. AI visualization in Nanoscale Microscopy. (arXiv:2201.00966v1 [cs.CV])
5. Submix: Practical Private Prediction for Large-Scale Language Models. (arXiv:2201.00971v1 [cs.LG])
6. StyleM: Stylized Metrics for Image Captioning Built with Contrastive N-grams. (arXiv:2201.00975v1 [cs.CV])
7. MDFEND: Multi-domain Fake News Detection. (arXiv:2201.00987v1 [cs.CL])
8. Multi-Representation Adaptation Network for Cross-domain Image Classification. (arXiv:2201.01002v1 [cs.CV])
9. Aligning Domain-specific Distribution and Classifier for Cross-domain Classification from Multiple Sources. (arXiv:2201.01003v1 [cs.LG])
10. Modeling Users' Behavior Sequences with Hierarchical Explainable Network for Cross-domain Fraud Detection. (arXiv:2201.01004v1 [cs.LG])
11. A integrating critic-waspas group decision making method under interval-valued q-rung orthogonal fuzzy enviroment. (arXiv:2201.01027v1 [cs.AI])
12. Learning Operators with Coupled Attention. (arXiv:2201.01032v1 [cs.LG])
13. McXai: Local model-agnostic explanation as two games. (arXiv:2201.01044v1 [cs.LG])
14. FROTE: Feedback Rule-Driven Oversampling for Editing Models. (arXiv:2201.01070v1 [cs.LG])
15. Towards Understanding and Harnessing the Effect of Image Transformation in Adversarial Detection. (arXiv:2201.01080v1 [cs.CV])
16. Short Range Correlation Transformer for Occluded Person Re-Identification. (arXiv:2201.01090v1 [cs.CV])
17. Learning Complex Spatial Behaviours in ABM: An Experimental Observational Study. (arXiv:2201.01099v1 [cs.MA])
18. Parity-based Cumulative Fairness-aware Boosting. (arXiv:2201.01148v1 [cs.LG])
19. DeepVisualInsight: Time-Travelling Visualization for Spatio-Temporal Causality of Deep Classification Training. (arXiv:2201.01155v1 [cs.LG])
20. Finding General Equilibria in Many-Agent Economic Simulations Using Deep Reinforcement Learning. (arXiv:2201.01163v1 [cs.GT])
21. Interpretable Low-Resource Legal Decision Making. (arXiv:2201.01164v1 [cs.LG])
22. Neural Myerson Auction for Truthful and Energy-Efficient Autonomous Aerial Data Delivery. (arXiv:2201.01170v1 [cs.GT])
23. Towards Fair Recommendation in Two-Sided Platforms. (arXiv:2201.01180v1 [cs.IR])
24. Modelling Cournot Games as Multi-agent Multi-armed Bandits. (arXiv:2201.01182v1 [cs.GT])
25. Graph Neural Networks: a bibliometrics overview. (arXiv:2201.01188v1 [cs.LG])
26. Two-level Graph Neural Network. (arXiv:2201.01190v1 [cs.LG])
27. Super-resolution in Molecular Dynamics Trajectory Reconstruction with Bi-Directional Neural Networks. (arXiv:2201.01195v1 [physics.comp-ph])
28. Rxn Hypergraph: a Hypergraph Attention Model for Chemical Reaction Representation. (arXiv:2201.01196v1 [cs.LG])
29. Speech-to-SQL: Towards Speech-driven SQL Query Generation From Natural Language Question. (arXiv:2201.01209v1 [cs.DB])
30. A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning. (arXiv:2201.01221v1 [cs.LG])
31. Robust Semi-supervised Federated Learning for Images Automatic Recognition in Internet of Drones. (arXiv:2201.01230v1 [cs.LG])
32. On the Minimal Adversarial Perturbation for Deep Neural Networks with Provable Estimation Error. (arXiv:2201.01235v1 [cs.LG])
33. ExAID: A Multimodal Explanation Framework for Computer-Aided Diagnosis of Skin Lesions. (arXiv:2201.01249v1 [cs.AI])
34. Automated Graph Machine Learning: Approaches, Libraries and Directions. (arXiv:2201.01288v1 [cs.LG])
35. Self-directed Machine Learning. (arXiv:2201.01289v1 [cs.LG])
36. Learning to Play No-Press Diplomacy with Best Response Policy Iteration. (arXiv:2006.04635v4 [cs.LG] UPDATED)
37. Reinforcement Learning with Dual-Observation for General Video Game Playing. (arXiv:2011.05622v2 [cs.AI] UPDATED)
38. Artificial Intelligence Development Races in Heterogeneous Settings. (arXiv:2012.15234v3 [cs.AI] UPDATED)
39. Combat Data Shift in Few-shot Learning with Knowledge Graph. (arXiv:2101.11354v3 [cs.LG] UPDATED)
40. The Yin-Yang dataset. (arXiv:2102.08211v2 [cs.AI] UPDATED)
41. Convolutional Normalization: Improving Deep Convolutional Network Robustness and Training. (arXiv:2103.00673v2 [cs.CV] UPDATED)
42. On the effectiveness of adversarial training against common corruptions. (arXiv:2103.02325v2 [cs.LG] UPDATED)
43. Deep Implicit Statistical Shape Models for 3D Medical Image Delineation. (arXiv:2104.02847v2 [cs.CV] UPDATED)
44. Differentially Private Transferrable Deep Learning with Membership-Mappings. (arXiv:2105.04615v3 [cs.LG] UPDATED)
45. Discovering Diverse Nearly Optimal Policies with Successor Features. (arXiv:2106.00669v2 [cs.AI] UPDATED)
46. Modeling Influencer Marketing Campaigns in Social Networks. (arXiv:2106.01750v2 [cs.AI] UPDATED)
47. Multimodal Co-learning: Challenges, Applications with Datasets, Recent Advances and Future Directions. (arXiv:2107.13782v3 [cs.LG] UPDATED)
48. Graph Neural Networks With Lifting-based Adaptive Graph Wavelets. (arXiv:2108.01660v3 [cs.LG] UPDATED)
49. APReL: A Library for Active Preference-based Reward Learning Algorithms. (arXiv:2108.07259v2 [cs.LG] UPDATED)
50. Towards a Rigorous Evaluation of Time-series Anomaly Detection. (arXiv:2109.05257v2 [cs.LG] UPDATED)
51. Machine Learning-Based COVID-19 Patients Triage Algorithm using Patient-Generated Health Data from Nationwide Multicenter Database. (arXiv:2109.09001v3 [cs.LG] UPDATED)
52. Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration. (arXiv:2109.14285v3 [cs.LG] UPDATED)
53. The CaLiGraph Ontology as a Challenge for OWL Reasoners. (arXiv:2110.05028v2 [cs.AI] UPDATED)
54. Building a great multi-lingual teacher with sparsely-gated mixture of experts for speech recognition. (arXiv:2112.05820v3 [cs.CL] UPDATED)
55. Positional Encoding Augmented GAN for the Assessment of Wind Flow for Pedestrian Comfort in Urban Areas. (arXiv:2112.08447v2 [cs.CV] UPDATED)
56. Visual Microfossil Identification via Deep Metric Learning. (arXiv:2112.09490v2 [cs.CV] UPDATED)
57. A Constraint Programming Approach to Weighted Isomorphic Mapping of Fragment-based Shape Signatures. (arXiv:2112.10892v2 [cs.AI] UPDATED)
58. A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More. (arXiv:2112.15594v2 [cs.LG] UPDATED)
59. A Lightweight and Accurate Spatial-Temporal Transformer for Traffic Forecasting. (arXiv:2201.00008v2 [cs.LG] UPDATED)
60. An EEG-based approach for Parkinson's disease diagnosis using Capsule network. (arXiv:2201.00628v2 [eess.SP] UPDATED)
61. Deep Learning Interviews: Hundreds of fully solved job interview questions from a wide range of key topics in AI. (arXiv:2201.00650v2 [cs.LG] UPDATED)
