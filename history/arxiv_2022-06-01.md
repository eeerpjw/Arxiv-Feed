# Your interest papers
---
## cs.CV
---
### GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v1 [cs.CV])
- Authors : Peng Zheng, Huazhu Fu, Ping Fan, Qi Fan, Jie Qin, Luc Van
- Link : [http://arxiv.org/abs/2205.15469](http://arxiv.org/abs/2205.15469)
> ABSTRACT  :  In this paper, we present a novel end-to-end group collaborative learning network, termed GCoNet+, which can effectively and efficiently (250 fps) identify co-salient objects in natural scenes. The proposed GCoNet+ achieves the new state-of-the-art performance for co-salient object detection (CoSOD) through mining consensus representations based on the following two essential criteria: 1) intra-group compactness to better formulate the consistency among co-salient objects by capturing their inherent shared attributes using our novel group affinity module (GAM); 2) inter-group separability to effectively suppress the influence of noisy objects on the output by introducing our new group collaborating module (GCM) conditioning on the inconsistent consensus. To further improve the accuracy, we design a series of simple yet effective components as follows: i) a recurrent auxiliary classification module (RACM) promoting the model learning at the semantic level; ii) a confidence **enhancement** module (CEM) helping the model to improve the quality of the final predictions; and iii) a group-based symmetric triplet (GST) loss guiding the model to learn more discriminative features. Extensive experiments on three challenging benchmarks, i.e., CoCA, CoSOD3k, and CoSal2015, demonstrate that our GCoNet+ outperforms the existing 12 cutting-edge models. Code has been released at https://github.com/ZhengPeng7/GCoNet_plus.  
### Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
- Authors : Peter Sutor, Dehao Yuan, Douglas Summers, Cornelia Fermuller, Yiannis Aloimonos
- Link : [http://arxiv.org/abs/2205.15534](http://arxiv.org/abs/2205.15534)
> ABSTRACT  :  Hyperdimensional Computing affords simple, yet powerful operations to create long Hyperdimensional Vectors (hypervectors) that can efficiently encode information, be used for learning, and are dynamic enough to be modified on the fly. In this paper, we explore the notion of using binary hypervectors to directly encode the final, classifying output signals of neural networks in order to fuse differing networks together at the symbolic level. This allows multiple neural networks to work together to solve a problem, with little additional overhead. Output signals just before classification are encoded as hypervectors and bundled together through consensus summation to train a classification hypervector. This process can be performed iteratively and even on single neural networks by instead making a consensus of multiple classification hypervectors. We find that this outperforms the state of the art, or is on a par with it, while using very little overhead, as hypervector operations are extremely fast and efficient in comparison to the neural networks. This consensus process can learn online and even grow or lose models in **real time**. Hypervectors act as memories that can be stored, and even further bundled together over time, affording life long learning capabilities. Additionally, this consensus structure inherits the benefits of Hyperdimensional Computing, without sacrificing the performance of modern Machine Learning. This technique can be extrapolated to virtually any neural model, and requires little modification to employ - one simply requires recording the output signals of networks when presented with a testing example.  
### Sub-Image Histogram Equalization using Coot Optimization Algorithm for Segmentation and Parameter Selection. (arXiv:2205.15565v1 [cs.CV])
- Authors : Emre Can, Umut Kuran, Mehmet Bilal
- Link : [http://arxiv.org/abs/2205.15565](http://arxiv.org/abs/2205.15565)
> ABSTRACT  :  Contrast **enhancement** is very important in terms of assessing images in an objective way. Contrast **enhancement** is also significant for various algorithms including supervised and unsupervised algorithms for accurate classification of samples. Some contrast **enhancement** algorithms solve this problem by addressing the low contrast issue. Mean and variance based sub-image histogram equalization (MVSIHE) algorithm is one of these contrast **enhancement**s methods proposed in the literature. It has different parameters which need to be tuned in order to achieve optimum results. With this motivation, in this study, we employed one of the most recent optimization algorithms, namely, coot optimization algorithm (COA) for selecting appropriate parameters for the MVSIHE algorithm. Blind/referenceless image spatial quality evaluator (BRISQUE) and natural image quality evaluator (NIQE) metrics are used for evaluating fitness of the coot swarm population. The results show that the proposed method can be used in the field of biomedical image processing.  
### Decomposing **NeRF** for Editing via Feature Field Distillation. (arXiv:2205.15585v1 [cs.CV])
- Authors : Sosuke Kobayashi, Eiichi Matsumoto, Vincent Sitzmann
- Link : [http://arxiv.org/abs/2205.15585](http://arxiv.org/abs/2205.15585)
> ABSTRACT  :  Emerging neural radiance fields (**NeRF**) are a promising scene representation for computer graphics, enabling high-quality 3D reconstruction and novel view synthesis from image observations. However, editing a scene represented by a **NeRF** is challenging, as the underlying connectionist representations such as MLPs or voxel grids are not object-centric or compositional. In particular, it has been difficult to selectively edit specific regions or objects. In this work, we tackle the problem of semantic scene decomposition of **NeRF**s to enable query-based local editing of the represented 3D scenes. We propose to distill the knowledge of off-the-shelf, self-supervised 2D image feature extractors such as CLIP-LSeg or DINO into a 3D feature field optimized in parallel to the radiance field. Given a user-specified query of various modalities such as text, an image patch, or a point-and-click selection, 3D feature fields semantically decompose 3D space without the need for re-training and enable us to semantically select and edit regions in the radiance field. Our experiments validate that the distilled feature fields (DFFs) can transfer recent progress in 2D vision and language foundation models to 3D scene representations, enabling convincing 3D segmentation and selective editing of emerging neural graphics representations.  
### Novel View Synthesis for High-fidelity Headshot Scenes. (arXiv:2205.15595v1 [cs.CV])
- Authors : Satoshi Tsutsui, Weijia Mao, Sijing Lin, Yunyi Zhu, Murong Ma, Mike Zheng
- Link : [http://arxiv.org/abs/2205.15595](http://arxiv.org/abs/2205.15595)
> ABSTRACT  :  Rendering scenes with a high-quality human face from arbitrary viewpoints is a practical and useful technique for many real-world applications. Recently, Neural Radiance Fields (**NeRF**), a rendering technique that uses neural networks to approximate classical ray tracing, have been considered as one of the promising approaches for synthesizing novel views from a sparse set of images. We find that **NeRF** can render new views while maintaining geometric consistency, but it does not properly maintain skin details, such as moles and pores. These details are important particularly for faces because when we look at an image of a face, we are much more sensitive to details than when we look at other objects. On the other hand, 3D Morpable Models (3DMMs) based on traditional meshes and textures can perform well in terms of skin detail despite that it has less precise geometry and cannot cover the head and the entire scene with background. Based on these observations, we propose a method to use both **NeRF** and 3DMM to synthesize a high-fidelity novel view of a scene with a face. Our method learns a Generative Adversarial Network (GAN) to mix a **NeRF**-synthesized image and a 3DMM-rendered image and produces a photorealistic scene with a face preserving the skin details. Experiments with various real-world scenes demonstrate the effectiveness of our approach. The code will be available on https://github.com/showlab/headshot .  
### DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes. (arXiv:2205.15723v1 [cs.CV])
- Authors : Wei Liu, Pei Cao, Weijia Mao, Wenqiao Zhang, David Junhao, Jussi Keppo, Ying Shan, Xiaohu Qie, Mike Zheng
- Link : [http://arxiv.org/abs/2205.15723](http://arxiv.org/abs/2205.15723)
> ABSTRACT  :  Modeling dynamic scenes is important for many applications such as virtual reality and telepresence. Despite achieving unprecedented fidelity for novel view synthesis in dynamic scenes, existing methods based on Neural Radiance Fields (**NeRF**) suffer from slow convergence (i.e., model training time measured in days). In this paper, we present DeVRF, a novel representation to accelerate learning dynamic radiance fields. The core of DeVRF is to model both the 3D canonical space and 4D deformation field of a dynamic, non-rigid scene with explicit and discrete voxel-based representations. However, it is quite challenging to train such a representation which has a large number of model parameters, often resulting in overfitting issues. To overcome this challenge, we devise a novel static-to-dynamic learning paradigm together with a new data capture setup that is convenient to deploy in practice. This paradigm unlocks efficient learning of deformable radiance fields via utilizing the 3D volumetric canonical space learnt from multi-view static images to ease the learning of 4D voxel deformation field with only few-view dynamic sequences. To further improve the efficiency of our DeVRF and its synthesized novel view's quality, we conduct thorough explorations and identify a set of strategies. We evaluate DeVRF on both synthetic and real-world dynamic scenes with different types of deformation. Experiments demonstrate that DeVRF achieves two orders of magnitude speedup (100x faster) with on-par high-fidelity results compared to the previous state-of-the-art approaches. The code and dataset will be released in https://github.com/showlab/DeVRF.  
### SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v1 [cs.CV])
- Authors : 
- Link : [http://arxiv.org/abs/2205.15764](http://arxiv.org/abs/2205.15764)
> ABSTRACT  :  Novel view synthesis is a long-standing problem. In this work, we consider a variant of the problem where we are given only a few context views sparsely covering a scene or an object. The goal is to predict novel viewpoints in the scene, which requires learning priors. The current state of the art is based on Neural Radiance Fields (**NeRF**s), and while achieving impressive results, the methods suffer from long training times as they require evaluating thousands of 3D point samples via a deep neural network for each image. We propose a 2D-only method that maps multiple context views and a query pose to a new image in a single pass of a neural network. Our model uses a two-stage architecture consisting of a codebook and a transformer model. The codebook is used to embed individual images into a smaller latent space, and the transformer solves the view synthesis task in this more compact space. To train our model efficiently, we introduce a novel branching attention mechanism that allows us to use the same model not only for neural rendering but also for camera pose estimation. Experimental results on real-world scenes show that our approach is competitive compared to **NeRF**-based methods while not reasoning in 3D, and it is faster to train.  
### SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections. (arXiv:2205.15768v1 [cs.CV])
- Authors : Mark Boss, Andreas Engelhardt, Abhishek Kar, Yuanzhen Li, Deqing Sun, Varun Jampani
- Link : [http://arxiv.org/abs/2205.15768](http://arxiv.org/abs/2205.15768)
> ABSTRACT  :  Inverse rendering of an object under entirely unknown capture conditions is a fundamental challenge in computer vision and graphics. Neural approaches such as **NeRF** have achieved photorealistic results on novel view synthesis, but they require known camera poses. Solving this problem with unknown camera poses is highly challenging as it requires joint optimization over shape, radiance, and pose. This problem is exacerbated when the input images are captured in the wild with varying backgrounds and illuminations. Standard pose estimation techniques fail in such image collections in the wild due to very few estimated correspondences across images. Furthermore, **NeRF** cannot relight a scene under any illumination, as it operates on radiance (the product of reflectance and illumination). We propose a joint optimization framework to estimate the shape, BRDF, and per-image camera pose and illumination. Our method works on in-the-wild online image collections of an object and produces relightable 3D assets for several use-cases such as AR/VR. To our knowledge, our method is the first to tackle this severely unconstrained task with minimal user interaction. Project page: https://markboss.me/publication/2022-samurai/ Video: https://youtu.be/LlYuGDjXp-8  
### D$^2$**NeRF**: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video. (arXiv:2205.15838v1 [cs.CV])
- Authors : Tianhao Wu, Fangcheng Zhong, Andrea Tagliasacchi, Forrester Cole, Cengiz Oztireli
- Link : [http://arxiv.org/abs/2205.15838](http://arxiv.org/abs/2205.15838)
> ABSTRACT  :  Given a monocular video, segmenting and decoupling dynamic objects while recovering the static environment is a widely studied problem in machine intelligence. Existing solutions usually approach this problem in the image domain, limiting their performance and understanding of the environment. We introduce Decoupled Dynamic Neural Radiance Field (D$^2$**NeRF**), a self-supervised approach that takes a monocular video and learns a 3D scene representation which decouples moving objects, including their shadows, from the static background. Our method represents the moving objects and the static background by two separate neural radiance fields with only one allowing for temporal changes. A naive implementation of this approach leads to the dynamic component taking over the static one as the representation of the former is inherently more general and prone to overfitting. To this end, we propose a novel loss to promote correct separation of phenomena. We further propose a shadow field network to detect and decouple dynamically moving shadows. We introduce a new dataset containing various dynamic objects and shadows and demonstrate that our method can achieve better performance than state-of-the-art approaches in decoupling dynamic and static 3D objects, occlusion and shadow removal, and image segmentation for moving objects.  
### Investigating Outdoor Recognition Performance of Infrared Beacons for Infrastructure-based Localization. (arXiv:2104.09335v2 [cs.CV] UPDATED)
- Authors : Alexandru Kampmann, Michael Lamberti, Nikola Petrovic, Stefan Kowalewski, Bassam Alrifaee
- Link : [http://arxiv.org/abs/2104.09335](http://arxiv.org/abs/2104.09335)
> ABSTRACT  :  This paper demonstrates a system comprised of infrared beacons and a camera equipped with an optical band-pass filter. Our system can reliably detect and identify individual beacons at 100m distance regardless of lighting conditions. We describe the camera and beacon design as well as the image processing pipeline in detail. In our experiments, we investigate and demonstrate the ability of the system to recognize our beacons in both daytime and **night**time conditions. High precision localization is a key enabler for automated vehicles but remains unsolved, despite strong recent improvements. Our low-cost, infrastructure-based approach is a potential step towards solving the localization problem. All datasets are made available here https://embedded.rwth-aachen.de/doku.php?id=forschung:mobility:infralocalization:concept.  
### Creating synthetic **night**-time visible-light meteorological satellite images using the GAN method. (arXiv:2108.04330v3 [cs.CV] UPDATED)
- Authors : Wencong Cheng, Beijing Aviation, Meteorological Institute
- Link : [http://arxiv.org/abs/2108.04330](http://arxiv.org/abs/2108.04330)
> ABSTRACT  :  Meteorology satellite visible light images is critical for meteorology support and forecast. However, there is no such kind of data during **night** time. To overcome this, we propose a method based on deep learning to create synthetic satellite visible light images during **night**. Specifically, to produce more realistic products, we train a Generative Adversarial Networks (GAN) model to generate visible light images given the corresponding satellite infrared images and numerical weather prediction(NWP) products. To better model the nonlinear relationship from infrared data and NWP products to visible light images, we propose to use the channel-wise attention mechanics, e.g., SEBlock to quantitative weight the input channels. The experiments based on the ECMWF NWP products and FY-4A meteorology satellite visible light and infrared channels date show that the proposed methods can be effective to create realistic synthetic satellite visible light images during **night**.  
### CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
- Authors : Emanuel Slany, Yannik Ott, Stephan Scheele, Jan Paulus, Ute Schmid
- Link : [http://arxiv.org/abs/2204.02661](http://arxiv.org/abs/2204.02661)
> ABSTRACT  :  Would you trust physicians if they cannot explain their decisions to you? Medical diagnostics using machine learning gained enormously in importance within the last decade. However, without further **enhancement**s many state-of-the-art machine learning methods are not suitable for medical application. The most important reasons are insufficient data set quality and the black-box behavior of machine learning algorithms such as Deep Learning models. Consequently, end-users cannot correct the model's decisions and the corresponding explanations. The latter is crucial for the trustworthiness of machine learning in the medical domain. The research field explainable interactive machine learning searches for methods that address both shortcomings. This paper extends the explainable and interactive CAIPI algorithm and provides an interface to simplify human-in-the-loop approaches for image classification. The interface enables the end-user (1) to investigate and (2) to correct the model's prediction and explanation, and (3) to influence the data set quality. After CAIPI optimization with only a single counterexample per iteration, the model achieves an accuracy of $97.48\%$ on the Medical MNIST and $95.02\%$ on the Fashion MNIST. This accuracy is approximately equal to state-of-the-art Deep Learning optimization procedures. Besides, CAIPI reduces the labeling effort by approximately $80\%$.  
### PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection. (arXiv:2205.07403v3 [cs.CV] UPDATED)
- Authors : Guangsheng Shi, Ruifeng Li, Chao Ma
- Link : [http://arxiv.org/abs/2205.07403](http://arxiv.org/abs/2205.07403)
> ABSTRACT  :  **Real-time** and high-performance 3D object detection is of critical importance for autonomous driving. Recent top-performing 3D object detectors mainly rely on point-based or 3D voxel-based convolutions, which are both computationally inefficient for onboard deployment. In contrast, pillar-based methods use solely 2D convolutions, which consume less computation resources, but they lag far behind their voxel-based counterparts in detection accuracy. In this paper, by examining the primary performance gap between pillar- and voxel-based detectors, we develop a real-time and high-performance pillar-based detector, dubbed PillarNet. The proposed PillarNet consists of a powerful encoder network for effective pillar feature learning, a neck network for spatial-semantic feature fusion and the commonly used detect head. Using only 2D convolutions, PillarNet is flexible to an optional pillar size and compatible with classical 2D CNN backbones, such as VGGNet and ResNet.Additionally, PillarNet benefits from our designed orientation-decoupled IoU regression loss along with the IoU-aware prediction branch. Extensive experimental results on large-scale nuScenes Dataset and Waymo Open Dataset demonstrate that the proposed PillarNet performs well over the state-of-the-art 3D detectors in terms of effectiveness and efficiency. The source code is available at https://github.com/agent-sgs/PillarNet.git.  
## eess.IV
---
### Sub-Image Histogram Equalization using Coot Optimization Algorithm for Segmentation and Parameter Selection. (arXiv:2205.15565v1 [cs.CV])
- Authors : Emre Can, Umut Kuran, Mehmet Bilal
- Link : [http://arxiv.org/abs/2205.15565](http://arxiv.org/abs/2205.15565)
> ABSTRACT  :  Contrast **enhancement** is very important in terms of assessing images in an objective way. Contrast **enhancement** is also significant for various algorithms including supervised and unsupervised algorithms for accurate classification of samples. Some contrast **enhancement** algorithms solve this problem by addressing the low contrast issue. Mean and variance based sub-image histogram equalization (MVSIHE) algorithm is one of these contrast **enhancement**s methods proposed in the literature. It has different parameters which need to be tuned in order to achieve optimum results. With this motivation, in this study, we employed one of the most recent optimization algorithms, namely, coot optimization algorithm (COA) for selecting appropriate parameters for the MVSIHE algorithm. Blind/referenceless image spatial quality evaluator (BRISQUE) and natural image quality evaluator (NIQE) metrics are used for evaluating fitness of the coot swarm population. The results show that the proposed method can be used in the field of biomedical image processing.  
### CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
- Authors : Emanuel Slany, Yannik Ott, Stephan Scheele, Jan Paulus, Ute Schmid
- Link : [http://arxiv.org/abs/2204.02661](http://arxiv.org/abs/2204.02661)
> ABSTRACT  :  Would you trust physicians if they cannot explain their decisions to you? Medical diagnostics using machine learning gained enormously in importance within the last decade. However, without further **enhancement**s many state-of-the-art machine learning methods are not suitable for medical application. The most important reasons are insufficient data set quality and the black-box behavior of machine learning algorithms such as Deep Learning models. Consequently, end-users cannot correct the model's decisions and the corresponding explanations. The latter is crucial for the trustworthiness of machine learning in the medical domain. The research field explainable interactive machine learning searches for methods that address both shortcomings. This paper extends the explainable and interactive CAIPI algorithm and provides an interface to simplify human-in-the-loop approaches for image classification. The interface enables the end-user (1) to investigate and (2) to correct the model's prediction and explanation, and (3) to influence the data set quality. After CAIPI optimization with only a single counterexample per iteration, the model achieves an accuracy of $97.48\%$ on the Medical MNIST and $95.02\%$ on the Fashion MNIST. This accuracy is approximately equal to state-of-the-art Deep Learning optimization procedures. Besides, CAIPI reduces the labeling effort by approximately $80\%$.  
## cs.LG
---
### Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
- Authors : Peter Sutor, Dehao Yuan, Douglas Summers, Cornelia Fermuller, Yiannis Aloimonos
- Link : [http://arxiv.org/abs/2205.15534](http://arxiv.org/abs/2205.15534)
> ABSTRACT  :  Hyperdimensional Computing affords simple, yet powerful operations to create long Hyperdimensional Vectors (hypervectors) that can efficiently encode information, be used for learning, and are dynamic enough to be modified on the fly. In this paper, we explore the notion of using binary hypervectors to directly encode the final, classifying output signals of neural networks in order to fuse differing networks together at the symbolic level. This allows multiple neural networks to work together to solve a problem, with little additional overhead. Output signals just before classification are encoded as hypervectors and bundled together through consensus summation to train a classification hypervector. This process can be performed iteratively and even on single neural networks by instead making a consensus of multiple classification hypervectors. We find that this outperforms the state of the art, or is on a par with it, while using very little overhead, as hypervector operations are extremely fast and efficient in comparison to the neural networks. This consensus process can learn online and even grow or lose models in **real time**. Hypervectors act as memories that can be stored, and even further bundled together over time, affording life long learning capabilities. Additionally, this consensus structure inherits the benefits of Hyperdimensional Computing, without sacrificing the performance of modern Machine Learning. This technique can be extrapolated to virtually any neural model, and requires little modification to employ - one simply requires recording the output signals of networks when presented with a testing example.  
### Generalised Implicit Neural Representations. (arXiv:2205.15674v1 [cs.LG])
- Authors : Daniele Grattarola, Pierre Vandergheynst
- Link : [http://arxiv.org/abs/2205.15674](http://arxiv.org/abs/2205.15674)
> ABSTRACT  :  We consider the problem of learning **implicit neural representation**s (INRs) for signals on non-Euclidean domains. In the Euclidean case, INRs are trained on a discrete sampling of a signal over a regular lattice. Here, we assume that the continuous signal exists on some unknown topological space from which we sample a discrete graph. In the absence of a coordinate system to identify the sampled nodes, we propose approximating their location with a spectral embedding of the graph. This allows us to train INRs without knowing the underlying continuous domain, which is the case for most graph signals in nature, while also making the INRs equivariant under the symmetry group of the domain. We show experiments with our method on various real-world signals on non-Euclidean domains.  
### SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v1 [cs.CV])
- Authors : 
- Link : [http://arxiv.org/abs/2205.15764](http://arxiv.org/abs/2205.15764)
> ABSTRACT  :  Novel view synthesis is a long-standing problem. In this work, we consider a variant of the problem where we are given only a few context views sparsely covering a scene or an object. The goal is to predict novel viewpoints in the scene, which requires learning priors. The current state of the art is based on Neural Radiance Fields (**NeRF**s), and while achieving impressive results, the methods suffer from long training times as they require evaluating thousands of 3D point samples via a deep neural network for each image. We propose a 2D-only method that maps multiple context views and a query pose to a new image in a single pass of a neural network. Our model uses a two-stage architecture consisting of a codebook and a transformer model. The codebook is used to embed individual images into a smaller latent space, and the transformer solves the view synthesis task in this more compact space. To train our model efficiently, we introduce a novel branching attention mechanism that allows us to use the same model not only for neural rendering but also for camera pose estimation. Experimental results on real-world scenes show that our approach is competitive compared to **NeRF**-based methods while not reasoning in 3D, and it is faster to train.  
### SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections. (arXiv:2205.15768v1 [cs.CV])
- Authors : Mark Boss, Andreas Engelhardt, Abhishek Kar, Yuanzhen Li, Deqing Sun, Varun Jampani
- Link : [http://arxiv.org/abs/2205.15768](http://arxiv.org/abs/2205.15768)
> ABSTRACT  :  Inverse rendering of an object under entirely unknown capture conditions is a fundamental challenge in computer vision and graphics. Neural approaches such as **NeRF** have achieved photorealistic results on novel view synthesis, but they require known camera poses. Solving this problem with unknown camera poses is highly challenging as it requires joint optimization over shape, radiance, and pose. This problem is exacerbated when the input images are captured in the wild with varying backgrounds and illuminations. Standard pose estimation techniques fail in such image collections in the wild due to very few estimated correspondences across images. Furthermore, **NeRF** cannot relight a scene under any illumination, as it operates on radiance (the product of reflectance and illumination). We propose a joint optimization framework to estimate the shape, BRDF, and per-image camera pose and illumination. Our method works on in-the-wild online image collections of an object and produces relightable 3D assets for several use-cases such as AR/VR. To our knowledge, our method is the first to tackle this severely unconstrained task with minimal user interaction. Project page: https://markboss.me/publication/2022-samurai/ Video: https://youtu.be/LlYuGDjXp-8  
### CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
- Authors : Emanuel Slany, Yannik Ott, Stephan Scheele, Jan Paulus, Ute Schmid
- Link : [http://arxiv.org/abs/2204.02661](http://arxiv.org/abs/2204.02661)
> ABSTRACT  :  Would you trust physicians if they cannot explain their decisions to you? Medical diagnostics using machine learning gained enormously in importance within the last decade. However, without further **enhancement**s many state-of-the-art machine learning methods are not suitable for medical application. The most important reasons are insufficient data set quality and the black-box behavior of machine learning algorithms such as Deep Learning models. Consequently, end-users cannot correct the model's decisions and the corresponding explanations. The latter is crucial for the trustworthiness of machine learning in the medical domain. The research field explainable interactive machine learning searches for methods that address both shortcomings. This paper extends the explainable and interactive CAIPI algorithm and provides an interface to simplify human-in-the-loop approaches for image classification. The interface enables the end-user (1) to investigate and (2) to correct the model's prediction and explanation, and (3) to influence the data set quality. After CAIPI optimization with only a single counterexample per iteration, the model achieves an accuracy of $97.48\%$ on the Medical MNIST and $95.02\%$ on the Fashion MNIST. This accuracy is approximately equal to state-of-the-art Deep Learning optimization procedures. Besides, CAIPI reduces the labeling effort by approximately $80\%$.  
## cs.AI
---
### Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
- Authors : Peter Sutor, Dehao Yuan, Douglas Summers, Cornelia Fermuller, Yiannis Aloimonos
- Link : [http://arxiv.org/abs/2205.15534](http://arxiv.org/abs/2205.15534)
> ABSTRACT  :  Hyperdimensional Computing affords simple, yet powerful operations to create long Hyperdimensional Vectors (hypervectors) that can efficiently encode information, be used for learning, and are dynamic enough to be modified on the fly. In this paper, we explore the notion of using binary hypervectors to directly encode the final, classifying output signals of neural networks in order to fuse differing networks together at the symbolic level. This allows multiple neural networks to work together to solve a problem, with little additional overhead. Output signals just before classification are encoded as hypervectors and bundled together through consensus summation to train a classification hypervector. This process can be performed iteratively and even on single neural networks by instead making a consensus of multiple classification hypervectors. We find that this outperforms the state of the art, or is on a par with it, while using very little overhead, as hypervector operations are extremely fast and efficient in comparison to the neural networks. This consensus process can learn online and even grow or lose models in **real time**. Hypervectors act as memories that can be stored, and even further bundled together over time, affording life long learning capabilities. Additionally, this consensus structure inherits the benefits of Hyperdimensional Computing, without sacrificing the performance of modern Machine Learning. This technique can be extrapolated to virtually any neural model, and requires little modification to employ - one simply requires recording the output signals of networks when presented with a testing example.  
### Generalised Implicit Neural Representations. (arXiv:2205.15674v1 [cs.LG])
- Authors : Daniele Grattarola, Pierre Vandergheynst
- Link : [http://arxiv.org/abs/2205.15674](http://arxiv.org/abs/2205.15674)
> ABSTRACT  :  We consider the problem of learning **implicit neural representation**s (INRs) for signals on non-Euclidean domains. In the Euclidean case, INRs are trained on a discrete sampling of a signal over a regular lattice. Here, we assume that the continuous signal exists on some unknown topological space from which we sample a discrete graph. In the absence of a coordinate system to identify the sampled nodes, we propose approximating their location with a spectral embedding of the graph. This allows us to train INRs without knowing the underlying continuous domain, which is the case for most graph signals in nature, while also making the INRs equivariant under the symmetry group of the domain. We show experiments with our method on various real-world signals on non-Euclidean domains.  
### Hierarchically Constrained Adaptive Ad **Exposure** in Feeds. (arXiv:2205.15759v1 [cs.AI])
- Authors : Dagui Chen, Qi Yan, Chunjie Chen, Zhenzhe Zheng, Yangsu Liu, Zhenjia Ma, Chuan Yu, Jian Xu, Bo Zheng
- Link : [http://arxiv.org/abs/2205.15759](http://arxiv.org/abs/2205.15759)
> ABSTRACT  :  A contemporary feed application usually provides blended results of organic items and sponsored items~(ads) to users. Conventionally, ads are exposed at fixed positions. Such a static **exposure** strategy is inefficient due to ignoring users' personalized preferences towards ads. To this end, adaptive ad **exposure** has become an appealing strategy to boost the overall performance of the feed. However, existing approaches to implementing the adaptive ad **exposure** still suffer from several limitations: 1) they usually fall into sub-optimal solutions because of only focusing on request-level optimization without consideration of the long-term application-level performance and constraints, 2) they neglect the necessity of keeping the game-theoretical properties of ad auctions, which may lead to anarchy in bidding, and 3) they can hardly be deployed in large-scale applications due to high computational complexity. In this paper, we focus on long-term performance optimization under hierarchical constraints in feeds and formulate the adaptive ad **exposure** as a Dynamic Knapsack Problem. We propose an effective approach: Hierarchically Constrained Adaptive Ad **Exposure**~(HCA2E). We present that HCA2E possesses desired game-theoretical properties, computational efficiency, and performance robustness. Comprehensive offline and online experiments on a leading e-commerce application demonstrate the significant performance superiority of HCA2E over representative baselines. HCA2E has also been deployed on this application to serve millions of daily users.  
### An adaptive admittance controller for collaborative drilling with a robot based on subtask classification via deep learning. (arXiv:2205.14457v2 [cs.RO] UPDATED)
- Authors : Berk Guler, Alireza Madani, Yusuf Aydin, Cagatay Basdogan
- Link : [http://arxiv.org/abs/2205.14457](http://arxiv.org/abs/2205.14457)
> ABSTRACT  :  In this paper, we propose a supervised learning approach based on an Artificial Neural Network (ANN) model for real-time classification of subtasks in a physical human-robot interaction (pHRI) task involving contact with a stiff environment. In this regard, we consider three subtasks for a given pHRI task: Idle, Driving, and Contact. Based on this classification, the parameters of an admittance controller that regulates the interaction between human and robot are adjusted adaptively in **real time** to make the robot more transparent to the operator (i.e. less resistant) during the Driving phase and more stable during the Contact phase. The Idle phase is primarily used to detect the initiation of task. Experimental results have shown that the ANN model can learn to detect the subtasks under different admittance controller conditions with an accuracy of 98% for 12 participants. Finally, we show that the admittance adaptation based on the proposed subtask classifier leads to 20% lower human effort (i.e. higher transparency) in the Driving phase and 25% lower oscillation amplitude (i.e. higher stability) during drilling in the Contact phase compared to an admittance controller with fixed parameters.  
# Paper List
---
## cs.CV
---
**134** new papers in cs.CV:-) 
1. Parameter-Efficient and Student-Friendly Knowledge Distillation. (arXiv:2205.15308v1 [cs.LG])
2. Searching for the Essence of Adversarial Perturbations. (arXiv:2205.15357v1 [cs.LG])
3. Revisiting Audio Pattern Recognition for Asthma Medication Adherence: Evaluation with the RDA Benchmark Suite. (arXiv:2205.15360v1 [cs.SD])
4. TubeFormer-DeepLab: Video Mask Transformer. (arXiv:2205.15361v1 [cs.CV])
5. Dictionary Learning with Accumulator Neurons. (arXiv:2205.15386v1 [cs.CV])
6. VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis. (arXiv:2205.15401v1 [cs.GR])
7. Gator: Customizable Channel Pruning of Neural Networks with Gating. (arXiv:2205.15404v1 [cs.CV])
8. Grid HTM: Hierarchical Temporal Memory for Anomaly Detection in Videos. (arXiv:2205.15407v1 [cs.CV])
9. LiDAR-aid Inertial Poser: Large-scale Human Motion Capture by Sparse Inertial and LiDAR Sensors. (arXiv:2205.15410v1 [cs.CV])
10. PolypConnect: Image inpainting for generating realistic gastrointestinal tract images with polyps. (arXiv:2205.15413v1 [eess.IV])
11. Fitting and recognition of geometric primitives in segmented 3D point clouds using a localized voting procedure. (arXiv:2205.15426v1 [cs.CV])
12. Segmentation Consistency Training: Out-of-Distribution Generalization for Medical Image Segmentation. (arXiv:2205.15428v1 [cs.CV])
13. Exploring Advances in Transformers and CNN for Skin Lesion Diagnosis on Small Datasets. (arXiv:2205.15442v1 [cs.CV])
14. Continual Object Detection: A review of definitions, strategies, and challenges. (arXiv:2205.15445v1 [cs.CV])
15. HeatER: An Efficient and Unified Network for Human Reconstruction via Heatmap-based TransformER. (arXiv:2205.15448v1 [cs.CV])
16. MVMO: A Multi-Object Dataset for Wide Baseline Multi-View Semantic Segmentation. (arXiv:2205.15452v1 [cs.CV])
17. Registering Image Volumes using 3D SIFT and Discrete SP-Symmetry. (arXiv:2205.15456v1 [cs.CV])
18. Few-Shot Diffusion Models. (arXiv:2205.15463v1 [cs.CV])
19. GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector. (arXiv:2205.15469v1 [cs.CV])
20. Introduction of a tree-based technique for efficient and real-time label retrieval in the object tracking system. (arXiv:2205.15477v1 [cs.CV])
21. Joint Spatial-Temporal and Appearance Modeling with Transformer for Multiple Object Tracking. (arXiv:2205.15495v1 [cs.CV])
22. ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts. (arXiv:2205.15509v1 [cs.CV])
23. IDE-3D: Interactive Disentangled Editing for High-Resolution 3D-aware Portrait Synthesis. (arXiv:2205.15517v1 [cs.CV])
24. Variational Transfer Learning using Cross-Domain Latent Modulation. (arXiv:2205.15523v1 [cs.LG])
25. Pseudo-Data based Self-Supervised Federated Learning for Classification of Histopathological Images. (arXiv:2205.15530v1 [cs.CV])
26. itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection. (arXiv:2205.15531v1 [cs.CV])
27. Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
28. DeepDefacer: Automatic Removal of Facial Features via U-Net Image Segmentation. (arXiv:2205.15536v1 [cs.CV])
29. AI-based automated Meibomian gland segmentation, classification and reflection correction in infrared Meibography. (arXiv:2205.15543v1 [q-bio.QM])
30. Mask2Hand: Learning to Predict the 3D Hand Pose and Shape from Shadow. (arXiv:2205.15553v1 [cs.CV])
31. iFS-RCNN: An Incremental Few-shot Instance Segmenter. (arXiv:2205.15562v1 [cs.CV])
32. Sub-Image Histogram Equalization using Coot Optimization Algorithm for Segmentation and Parameter Selection. (arXiv:2205.15565v1 [cs.CV])
33. Hierarchical Spherical CNNs with Lifting-based Adaptive Wavelets for Pooling and Unpooling. (arXiv:2205.15571v1 [cs.CV])
34. 3PSDF: Three-Pole Signed Distance Function for Learning Surfaces with Arbitrary Topologies. (arXiv:2205.15572v1 [cs.CV])
35. MontageGAN: Generation and Assembly of Multiple Components by GANs. (arXiv:2205.15577v1 [cs.CV])
36. An Effective Fusion Method to Enhance the Robustness of CNN. (arXiv:2205.15582v1 [cs.CV])
37. Decomposing **NeRF** for Editing via Feature Field Distillation. (arXiv:2205.15585v1 [cs.CV])
38. Novel View Synthesis for High-fidelity Headshot Scenes. (arXiv:2205.15595v1 [cs.CV])
39. Generative Aging of Brain Images with Diffeomorphic Registration. (arXiv:2205.15607v1 [eess.IV])
40. Weakly-supervised Action Transition Learning for Stochastic Human Motion Prediction. (arXiv:2205.15608v1 [cs.CV])
41. Bag of Tricks for Domain Adaptive Multi-Object Tracking. (arXiv:2205.15609v1 [cs.CV])
42. Contrastive Centroid Supervision Alleviates Domain Shift in Medical Image Classification. (arXiv:2205.15658v1 [cs.CV])
43. ViT-BEVSeg: A Hierarchical Transformer Network for Monocular Birds-Eye-View Segmentation. (arXiv:2205.15667v1 [cs.CV])
44. Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v1 [cs.LG])
45. Automatic Relation-aware Graph Network Proliferation. (arXiv:2205.15678v1 [cs.LG])
46. Self-Supervised Learning for Building Damage Assessment from Large-scale xBD Satellite Imagery Benchmark Datasets. (arXiv:2205.15688v1 [cs.CV])
47. Progressive Multi-scale Consistent Network for Multi-class Fundus Lesion Segmentation. (arXiv:2205.15720v1 [eess.IV])
48. One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching. (arXiv:2205.15721v1 [cs.CV])
49. DeVRF: Fast Deformable Voxel Radiance Fields for Dynamic Scenes. (arXiv:2205.15723v1 [cs.CV])
50. Transformers for Multi-Object Tracking on Point Clouds. (arXiv:2205.15730v1 [cs.CV])
51. Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning. (arXiv:2205.15746v1 [cs.LG])
52. Adversarial synthesis based data-augmentation for code-switched spoken language identification. (arXiv:2205.15747v1 [eess.AS])
53. Non-Iterative Recovery from Nonlinear Observations using Generative Models. (arXiv:2205.15749v1 [cs.LG])
54. Investigating the Role of Image Retrieval for Visual Localization -- An exhaustive benchmark. (arXiv:2205.15761v1 [cs.CV])
55. SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v1 [cs.CV])
56. SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections. (arXiv:2205.15768v1 [cs.CV])
57. Concept-level Debugging of Part-Prototype Networks. (arXiv:2205.15769v1 [cs.LG])
58. The hybrid approach -- Convolutional Neural Networks and Expectation Maximization Algorithm -- for Tomographic Reconstruction of Hyperspectral Images. (arXiv:2205.15772v1 [eess.IV])
59. Co-Training for Unsupervised Domain Adaptation of Semantic Segmentation Models. (arXiv:2205.15781v1 [cs.CV])
60. A Survey of Deep Fake Detection for Trial Courts. (arXiv:2205.15792v1 [cs.CV])
61. Contrasting quadratic assignments for set-based representation learning. (arXiv:2205.15814v1 [cs.CV])
62. Unsupervised Image Representation Learning with Deep Latent Particles. (arXiv:2205.15821v1 [cs.CV])
63. Surface Analysis with Vision Transformers. (arXiv:2205.15836v1 [cs.CV])
64. D$^2$**NeRF**: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video. (arXiv:2205.15838v1 [cs.CV])
65. Geo-Neus: Geometry-Consistent Neural Implicit Surfaces Learning for Multi-view Reconstruction. (arXiv:2205.15848v1 [cs.CV])
66. Snapture -- A Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition. (arXiv:2205.15862v1 [cs.CV])
67. Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern Recognition on Neuromorphic Hardware. (arXiv:2205.15864v1 [cs.CV])
68. A Review of Mobile Mapping Systems: From Sensors to Applications. (arXiv:2205.15865v1 [cs.CV])
69. Median Pixel Difference Convolutional Network for Robust Face Recognition. (arXiv:2205.15867v1 [cs.CV])
70. CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers. (arXiv:2205.15868v1 [cs.CV])
71. 3D-model ShapeNet Core Classification using Meta-Semantic Learning. (arXiv:2205.15869v1 [cs.CV])
72. FaIRCoP: Facial Image Retrieval using Contrastive Personalization. (arXiv:2205.15870v1 [cs.CV])
73. From Keypoints to Object Landmarks via Self-Training Correspondence: A novel approach to Unsupervised Landmark Discovery. (arXiv:2205.15895v1 [cs.CV])
74. Inferring 3D change detection from bitemporal optical images. (arXiv:2205.15903v1 [eess.IV])
75. SAR Despeckling Using Overcomplete Convolutional Networks. (arXiv:2205.15906v1 [cs.CV])
76. A Competitive Method for Dog Nose-print Re-identification. (arXiv:2205.15934v1 [cs.CV])
77. Skeleton-based Action Recognition via Temporal-Channel Aggregation. (arXiv:2205.15936v1 [cs.CV])
78. Voxel Field Fusion for 3D Object Detection. (arXiv:2205.15938v1 [cs.CV])
79. Memory-efficient Segmentation of High-resolution Volumetric MicroCT Images. (arXiv:2205.15941v1 [eess.IV])
80. Two-Dimensional Quantum Material Identification via Self-Attention and Soft-labeling in Deep Learning. (arXiv:2205.15948v1 [cs.CV])
81. CropMix: Sampling a Rich Input Distribution via Multi-Scale Cropping. (arXiv:2205.15955v1 [cs.CV])
82. FedHarmony: Unlearning Scanner Bias with Distributed Data. (arXiv:2205.15970v1 [cs.LG])
83. Text2Human: Text-Driven Controllable Human Image Generation. (arXiv:2205.15996v1 [cs.CV])
84. TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving. (arXiv:2205.15997v1 [cs.CV])
85. Cascade Luminance and Chrominance for Image Retouching: More Like Artist. (arXiv:2205.15999v1 [cs.CV])
86. What Knowledge Gets Distilled in Knowledge Distillation?. (arXiv:2205.16004v1 [cs.CV])
87. Improved Vector Quantized Diffusion Models. (arXiv:2205.16007v1 [cs.CV])
88. Kymatio: Scattering Transforms in Python. (arXiv:1812.11214v3 [cs.LG] UPDATED)
89. PDE-based Group Equivariant Convolutional Neural Networks. (arXiv:2001.09046v6 [cs.LG] UPDATED)
90. CoRe: Color Regression for Multicolor Fashion Garments. (arXiv:2010.02849v2 [cs.CV] UPDATED)
91. Generalized Few-shot Semantic Segmentation. (arXiv:2010.05210v4 [cs.CV] UPDATED)
92. Investigating Outdoor Recognition Performance of Infrared Beacons for Infrastructure-based Localization. (arXiv:2104.09335v2 [cs.CV] UPDATED)
93. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v3 [cs.CV] UPDATED)
94. On the potential of sequential and non-sequential regression models for Sentinel-1-based biomass prediction in Tanzanian miombo forests. (arXiv:2106.15020v2 [cs.LG] UPDATED)
95. Creating synthetic **night**-time visible-light meteorological satellite images using the GAN method. (arXiv:2108.04330v3 [cs.CV] UPDATED)
96. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v9 [cs.CV] UPDATED)
97. Eyes Tell All: Irregular Pupil Shapes Reveal GAN-generated Faces. (arXiv:2109.00162v4 [cs.CV] UPDATED)
98. Learning to Ground Visual Objects for Visual Dialog. (arXiv:2109.06013v3 [cs.CV] UPDATED)
99. Deep Visual Navigation under Partial Observability. (arXiv:2109.07752v3 [cs.RO] UPDATED)
100. GoG: Relation-aware Graph-over-Graph Network for Visual Dialog. (arXiv:2109.08475v2 [cs.CL] UPDATED)
101. KD-VLP: Improving End-to-End Vision-and-Language Pretraining with Object Knowledge Distillation. (arXiv:2109.10504v2 [cs.CV] UPDATED)
102. RWN: Robust Watermarking Network for Image Cropping Localization. (arXiv:2110.05687v2 [cs.CV] UPDATED)
103. LoveDA: A Remote Sensing Land-Cover Dataset for Domain Adaptive Semantic Segmentation. (arXiv:2110.08733v6 [cs.CV] UPDATED)
104. Dense Prediction with Attentive Feature Aggregation. (arXiv:2111.00770v2 [cs.CV] UPDATED)
105. Exploring Representational Alignment with Human Perception Using Identically Represented Inputs. (arXiv:2111.14726v2 [cs.CV] UPDATED)
106. Multiview Transformers for Video Recognition. (arXiv:2201.04288v4 [cs.CV] UPDATED)
107. DICP: Doppler Iterative Closest Point Algorithm. (arXiv:2201.11944v2 [cs.RO] UPDATED)
108. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v4 [cs.CV] UPDATED)
109. A General Deep Learning framework for Neuron Instance Segmentation based on Efficient UNet and Morphological Post-processing. (arXiv:2202.08682v2 [eess.IV] UPDATED)
110. Structured Pruning is All You Need for Pruning CNNs at Initialization. (arXiv:2203.02549v2 [cs.CV] UPDATED)
111. DrawingInStyles: Portrait Image Generation and Editing with Spatially Conditioned StyleGAN. (arXiv:2203.02762v3 [cs.GR] UPDATED)
112. Model-Agnostic Multitask Fine-tuning for Few-shot Vision-Language Transfer Learning. (arXiv:2203.04904v2 [cs.MM] UPDATED)
113. Semi-supervised Semantic Segmentation with Error Localization Network. (arXiv:2204.02078v2 [cs.CV] UPDATED)
114. CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
115. Permutation-Invariant Relational Network for Multi-person 3D Pose Estimation. (arXiv:2204.04913v2 [cs.CV] UPDATED)
116. MultiEarth 2022 -- Multimodal Learning for Earth and Environment Workshop and Challenge. (arXiv:2204.07649v3 [cs.CV] UPDATED)
117. Weighted Bayesian Gaussian Mixture Model for Roadside LiDAR Object Detection. (arXiv:2204.09804v2 [cs.CV] UPDATED)
118. Language Models Can See: Plugging Visual Controls in Text Generation. (arXiv:2205.02655v2 [cs.CV] UPDATED)
119. Augmentations: An Insight into their Effectiveness on Convolution Neural Networks. (arXiv:2205.04064v2 [cs.LG] UPDATED)
120. The Impact of Partial Occlusion on Pedestrian Detectability. (arXiv:2205.04812v4 [cs.CV] UPDATED)
121. An Objective Method for Pedestrian Occlusion Level Classification. (arXiv:2205.05412v2 [cs.CV] UPDATED)
122. PillarNet: Real-Time and High-Performance Pillar-based 3D Object Detection. (arXiv:2205.07403v3 [cs.CV] UPDATED)
123. ColonFormer: An Efficient Transformer based Method for Colon Polyp Segmentation. (arXiv:2205.08473v2 [cs.CV] UPDATED)
124. Bayesian Convolutional Neural Networks for Limited Data Hyperspectral Remote Sensing Image Classification. (arXiv:2205.09250v2 [cs.CV] UPDATED)
125. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v2 [cs.CV] UPDATED)
126. HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text Retrieval. (arXiv:2205.12105v2 [cs.CV] UPDATED)
127. Real-Time Video Deblurring via Lightweight Motion Compensation. (arXiv:2205.12634v2 [cs.CV] UPDATED)
128. V-Doc : Visual questions answers with Documents. (arXiv:2205.13724v2 [cs.AI] UPDATED)
129. Video2StyleGAN: Disentangling Local and Global Variations in a Video. (arXiv:2205.13996v2 [cs.CV] UPDATED)
130. Multi-Task Learning with Multi-query Transformer for Dense Prediction. (arXiv:2205.14354v2 [cs.CV] UPDATED)
131. PSNet: Fast Data Structuring for Hierarchical Deep Learning on Point Cloud. (arXiv:2205.14965v2 [cs.CV] UPDATED)
132. Deblurring Photographs of Characters Using Deep Neural Networks. (arXiv:2205.15053v2 [cs.CV] UPDATED)
133. EAMM: One-Shot Emotional Talking Face via Audio-Based Emotion-Aware Motion Model. (arXiv:2205.15278v2 [cs.CV] UPDATED)
134. Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer. (arXiv:2205.15290v2 [cs.CV] UPDATED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. PolypConnect: Image inpainting for generating realistic gastrointestinal tract images with polyps. (arXiv:2205.15413v1 [eess.IV])
2. DeepDefacer: Automatic Removal of Facial Features via U-Net Image Segmentation. (arXiv:2205.15536v1 [cs.CV])
3. AI-based automated Meibomian gland segmentation, classification and reflection correction in infrared Meibography. (arXiv:2205.15543v1 [q-bio.QM])
4. Sub-Image Histogram Equalization using Coot Optimization Algorithm for Segmentation and Parameter Selection. (arXiv:2205.15565v1 [cs.CV])
5. MontageGAN: Generation and Assembly of Multiple Components by GANs. (arXiv:2205.15577v1 [cs.CV])
6. Generative Aging of Brain Images with Diffeomorphic Registration. (arXiv:2205.15607v1 [eess.IV])
7. Optimizing Intermediate Representations of Generative Models for Phase Retrieval. (arXiv:2205.15617v1 [cs.LG])
8. Progressive Multi-scale Consistent Network for Multi-class Fundus Lesion Segmentation. (arXiv:2205.15720v1 [eess.IV])
9. The hybrid approach -- Convolutional Neural Networks and Expectation Maximization Algorithm -- for Tomographic Reconstruction of Hyperspectral Images. (arXiv:2205.15772v1 [eess.IV])
10. Median Pixel Difference Convolutional Network for Robust Face Recognition. (arXiv:2205.15867v1 [cs.CV])
11. Learning brain MRI quality control: a multi-factorial generalization problem. (arXiv:2205.15898v1 [stat.ML])
12. Inferring 3D change detection from bitemporal optical images. (arXiv:2205.15903v1 [eess.IV])
13. SAR Despeckling Using Overcomplete Convolutional Networks. (arXiv:2205.15906v1 [cs.CV])
14. PhD Thesis. Computer-Aided Assessment of Tuberculosis with Radiological Imaging: From rule-based methods to Deep Learning. (arXiv:2205.15909v1 [eess.IV])
15. Memory-efficient Segmentation of High-resolution Volumetric MicroCT Images. (arXiv:2205.15941v1 [eess.IV])
16. CropMix: Sampling a Rich Input Distribution via Multi-Scale Cropping. (arXiv:2205.15955v1 [cs.CV])
17. A General Deep Learning framework for Neuron Instance Segmentation based on Efficient UNet and Morphological Post-processing. (arXiv:2202.08682v2 [eess.IV] UPDATED)
18. CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
19. The Impact of Partial Occlusion on Pedestrian Detectability. (arXiv:2205.04812v4 [cs.CV] UPDATED)
20. Sensing Time Effectiveness for Fitness to Drive Evaluation in Neurological Patients. (arXiv:2205.08942v2 [eess.IV] UPDATED)
21. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v2 [cs.CV] UPDATED)
## cs.LG
---
**218** new papers in cs.LG:-) 
1. Improvements to Supervised EM Learning of Shared Kernel Models by Feature Space Partitioning. (arXiv:2205.15304v1 [cs.LG])
2. A Design Space for Explainable Ranking and Ranking Models. (arXiv:2205.15305v1 [cs.LG])
3. A Unified Weight Initialization Paradigm for Tensorial Convolutional Neural Networks. (arXiv:2205.15307v1 [cs.LG])
4. Parameter-Efficient and Student-Friendly Knowledge Distillation. (arXiv:2205.15308v1 [cs.LG])
5. Mean Field inference of CRFs based on GAT. (arXiv:2205.15312v1 [cs.LG])
6. Chefs' Random Tables: Non-Trigonometric Random Features. (arXiv:2205.15317v1 [cs.LG])
7. Learning Adaptive Propagation for Knowledge Graph Reasoning. (arXiv:2205.15319v1 [cs.LG])
8. Payday loans -- blessing or growth suppressor? Machine Learning Analysis. (arXiv:2205.15320v1 [econ.GN])
9. Superposing Many Tickets into One: A Performance Booster for Sparse Neural Network Training. (arXiv:2205.15322v1 [cs.LG])
10. Searching for the Essence of Adversarial Perturbations. (arXiv:2205.15357v1 [cs.LG])
11. Associative Learning Mechanism for Drug-Target Interaction Prediction. (arXiv:2205.15364v1 [q-bio.BM])
12. Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning. (arXiv:2205.15367v1 [cs.LG])
13. Infinite-dimensional optimization and Bayesian nonparametric learning of stochastic differential equations. (arXiv:2205.15368v1 [stat.ML])
14. Optimistic Whittle Index Policy: Online Learning for Restless Bandits. (arXiv:2205.15372v1 [cs.LG])
15. Reinforcement Learning with a Terminator. (arXiv:2205.15376v1 [cs.LG])
16. Truly Deterministic Policy Optimization. (arXiv:2205.15379v1 [cs.AI])
17. Attention Flows for General Transformers. (arXiv:2205.15389v1 [cs.LG])
18. A hybrid approach to seismic deblending: when physics meets self-supervision. (arXiv:2205.15395v1 [physics.geo-ph])
19. Minimax Optimal Online Imitation Learning via Replay Estimation. (arXiv:2205.15397v1 [cs.LG])
20. Designing Rewards for Fast Learning. (arXiv:2205.15400v1 [cs.LG])
21. Neural Optimal Transport with General Cost Functionals. (arXiv:2205.15403v1 [cs.LG])
22. Grid HTM: Hierarchical Temporal Memory for Anomaly Detection in Videos. (arXiv:2205.15407v1 [cs.CV])
23. Painful intelligence: What AI can tell us about human suffering. (arXiv:2205.15409v1 [cs.LG])
24. PolypConnect: Image inpainting for generating realistic gastrointestinal tract images with polyps. (arXiv:2205.15413v1 [eess.IV])
25. Fooling SHAP with Stealthily Biased Sampling. (arXiv:2205.15419v1 [cs.LG])
26. Connecting adversarial attacks and optimal transport for domain adaptation. (arXiv:2205.15424v1 [cs.LG])
27. Segmentation Consistency Training: Out-of-Distribution Generalization for Medical Image Segmentation. (arXiv:2205.15428v1 [cs.CV])
28. Learning Risk-Averse Equilibria in Multi-Agent Systems. (arXiv:2205.15434v1 [cs.LG])
29. Fairness in the First Stage of Two-Stage Recommender Systems. (arXiv:2205.15436v1 [cs.IR])
30. FBM: Fast-Bit Allocation for Mixed-Precision Quantization. (arXiv:2205.15437v1 [cs.LG])
31. StyleTTS: A Style-Based Generative Model for Natural and Diverse Text-to-Speech Synthesis. (arXiv:2205.15439v1 [eess.AS])
32. Continual Object Detection: A review of definitions, strategies, and challenges. (arXiv:2205.15445v1 [cs.CV])
33. Holistic Generalized Linear Models. (arXiv:2205.15447v1 [stat.ML])
34. Posterior and Computational Uncertainty in Gaussian Processes. (arXiv:2205.15449v1 [cs.LG])
35. GLDQN: Explicitly Parameterized Quantile Reinforcement Learning for Waste Reduction. (arXiv:2205.15455v1 [cs.LG])
36. Bayesian Active Learning for Scanning Probe Microscopy: from Gaussian Processes to Hypothesis Learning. (arXiv:2205.15458v1 [cond-mat.mtrl-sci])
37. Critic Sequential Monte Carlo. (arXiv:2205.15460v1 [stat.ML])
38. Few-Shot Diffusion Models. (arXiv:2205.15463v1 [cs.CV])
39. Data Banzhaf: A Data Valuation Framework with Maximal Robustness to Learning Stochasticity. (arXiv:2205.15466v1 [cs.LG])
40. Post-hoc Concept Bottleneck Models. (arXiv:2205.15480v1 [cs.LG])
41. Sepsis Prediction with Temporal Convolutional Networks. (arXiv:2205.15492v1 [cs.LG])
42. Certifying Some Distributional Fairness with Subpopulation Decomposition. (arXiv:2205.15494v1 [cs.LG])
43. Rethinking Graph Neural Networks for Anomaly Detection. (arXiv:2205.15508v1 [cs.LG])
44. Molecular Dipole Moment Learning via Rotationally Equivariant Gaussian Process Regression with Derivatives in Molecular-orbital-based Machine Learning. (arXiv:2205.15510v1 [physics.chem-ph])
45. Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game. (arXiv:2205.15512v1 [cs.LG])
46. Variational Transfer Learning using Cross-Domain Latent Modulation. (arXiv:2205.15523v1 [cs.LG])
47. itKD: Interchange Transfer-based Knowledge Distillation for 3D Object Detection. (arXiv:2205.15531v1 [cs.CV])
48. Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
49. DeepDefacer: Automatic Removal of Facial Features via U-Net Image Segmentation. (arXiv:2205.15536v1 [cs.CV])
50. MACE: An Efficient Model-Agnostic Framework for Counterfactual Explanation. (arXiv:2205.15540v1 [cs.AI])
51. Robust Projection based Anomaly Extraction (RPE) in Univariate Time-Series. (arXiv:2205.15548v1 [stat.ML])
52. VC Theoretical Explanation of Double Descent. (arXiv:2205.15549v1 [stat.ML])
53. Graph-level Neural Networks: Current Progress and Future Directions. (arXiv:2205.15555v1 [cs.LG])
54. Secure Federated Clustering. (arXiv:2205.15564v1 [cs.LG])
55. Few-Shot Unlearning by Model Inversion. (arXiv:2205.15567v1 [cs.LG])
56. HW-Aware Initialization of DNN Auto-Tuning to Improve Exploration Time and Robustness. (arXiv:2205.15568v1 [cs.LG])
57. GSR: A Generalized Symbolic Regression Approach. (arXiv:2205.15569v1 [cs.LG])
58. A Computation and Communication Efficient Method for Distributed Nonconvex Problems in the Partial Participation Setting. (arXiv:2205.15580v1 [cs.LG])
59. Comparing interpretation methods in mental state decoding analyses with deep learning models. (arXiv:2205.15581v1 [q-bio.NC])
60. Semantic Autoencoder and Its Potential Usage for Adversarial Attack. (arXiv:2205.15592v1 [cs.LG])
61. Individual health-disease phase diagrams for disease prevention based on machine learning. (arXiv:2205.15598v1 [cs.LG])
62. GlanceNets: Interpretabile, Leak-proof Concept-based Models. (arXiv:2205.15612v1 [cs.LG])
63. Communication-Efficient Distributionally Robust Decentralized Learning. (arXiv:2205.15614v1 [cs.LG])
64. Optimizing Intermediate Representations of Generative Models for Phase Retrieval. (arXiv:2205.15617v1 [cs.LG])
65. Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks. (arXiv:2205.15619v1 [cs.LG])
66. k-Means Maximum Entropy Exploration. (arXiv:2205.15623v1 [cs.LG])
67. Scalable Distributional Robustness in a Class of Non Convex Optimization with Guarantees. (arXiv:2205.15624v1 [cs.LG])
68. Differentiable Invariant Causal Discovery. (arXiv:2205.15638v1 [cs.LG])
69. Label-Enhanced Graph Neural Network for Semi-supervised Node Classification. (arXiv:2205.15653v1 [cs.LG])
70. Sample-Efficient, Exploration-Based Policy Optimisation for Routing Problems. (arXiv:2205.15656v1 [cs.LG])
71. The CLRS Algorithmic Reasoning Benchmark. (arXiv:2205.15659v1 [cs.LG])
72. Multi-task Optimization Based Co-training for Electricity Consumption Prediction. (arXiv:2205.15663v1 [cs.LG])
73. Generalised Implicit Neural Representations. (arXiv:2205.15674v1 [cs.LG])
74. Contrastive Representation Learning for 3D Protein Structures. (arXiv:2205.15675v1 [q-bio.BM])
75. Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v1 [cs.LG])
76. Automatic Relation-aware Graph Network Proliferation. (arXiv:2205.15678v1 [cs.LG])
77. Simulation-Based Inference with WALDO: Perfectly Calibrated Confidence Regions Using Any Prediction or Posterior Estimation Algorithm. (arXiv:2205.15680v1 [stat.ML])
78. Static Scheduling with Predictions Learned through Efficient Exploration. (arXiv:2205.15695v1 [cs.LG])
79. A novel approach to rating transition modelling via Machine Learning and SDEs on Lie groups. (arXiv:2205.15699v1 [q-fin.RM])
80. Provable General Function Class Representation Learning in Multitask Bandits and MDPs. (arXiv:2205.15701v1 [cs.LG])
81. Lessons Learned from Data-Driven Building Control Experiments: Contrasting Gaussian Process-based MPC, Bilevel DeePC, and Deep Reinforcement Learning. (arXiv:2205.15703v1 [eess.SY])
82. Mitigating Dataset Bias by Using Per-sample Gradient. (arXiv:2205.15704v1 [cs.LG])
83. Multilingual Transformers for Product Matching -- Experiments and a New Benchmark in Polish. (arXiv:2205.15712v1 [cs.CL])
84. Multi-Agent Learning of Numerical Methods for Hyperbolic PDEs with Factored Dec-MDP. (arXiv:2205.15716v1 [cs.LG])
85. One Loss for Quantization: Deep Hashing with Discrete Wasserstein Distributional Matching. (arXiv:2205.15721v1 [cs.CV])
86. Transformers for Multi-Object Tracking on Point Clouds. (arXiv:2205.15730v1 [cs.CV])
87. ViNNPruner: Visual Interactive Pruning for Deep Learning. (arXiv:2205.15731v1 [cs.LG])
88. Template based Graph Neural Network with Optimal Transport Distances. (arXiv:2205.15733v1 [cs.LG])
89. Mixture GAN For Modulation Classification Resiliency Against Adversarial Attacks. (arXiv:2205.15743v1 [cs.LG])
90. HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks. (arXiv:2205.15745v1 [cs.LG])
91. Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning. (arXiv:2205.15746v1 [cs.LG])
92. Adversarial synthesis based data-augmentation for code-switched spoken language identification. (arXiv:2205.15747v1 [eess.AS])
93. Non-Iterative Recovery from Nonlinear Observations using Generative Models. (arXiv:2205.15749v1 [cs.LG])
94. Variable importance without impossible data. (arXiv:2205.15750v1 [cs.LG])
95. Hierarchies of Reward Machines. (arXiv:2205.15752v1 [cs.LG])
96. Investigating the Role of Image Retrieval for Visual Localization -- An exhaustive benchmark. (arXiv:2205.15761v1 [cs.CV])
97. Knowledge Enhanced Neural Networks for relational domains. (arXiv:2205.15762v1 [cs.LG])
98. Exact Feature Collisions in Neural Networks. (arXiv:2205.15763v1 [cs.LG])
99. SymFormer: End-to-end symbolic regression using transformer-based architecture. (arXiv:2205.15764v1 [cs.CV])
100. Strategic Classification with Graph Neural Networks. (arXiv:2205.15765v1 [cs.LG])
101. SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections. (arXiv:2205.15768v1 [cs.CV])
102. Concept-level Debugging of Part-Prototype Networks. (arXiv:2205.15769v1 [cs.LG])
103. Likelihood-Free Inference with Generative Neural Networks via Scoring Rule Minimization. (arXiv:2205.15784v1 [stat.CO])
104. A Meta Reinforcement Learning Approach for Predictive Autoscaling in the Cloud. (arXiv:2205.15795v1 [cs.LG])
105. AdaTask: Adaptive Multitask Online Learning. (arXiv:2205.15802v1 [cs.LG])
106. Feature Learning in $L_{2}$-regularized DNNs: Attraction/Repulsion and Sparsity. (arXiv:2205.15809v1 [stat.ML])
107. Unsupervised Image Representation Learning with Deep Latent Particles. (arXiv:2205.15821v1 [cs.CV])
108. Graph Backup: Data Efficient Backup Exploiting Markovian Transitions. (arXiv:2205.15824v1 [cs.LG])
109. Robust Anytime Learning of Markov Decision Processes. (arXiv:2205.15827v1 [cs.AI])
110. Attribution-based Explanations that Provide Recourse Cannot be Robust. (arXiv:2205.15834v1 [stat.ML])
111. Surface Analysis with Vision Transformers. (arXiv:2205.15836v1 [cs.CV])
112. Predicting Day-Ahead Stock Returns using Search Engine Query Volumes: An Application of Gradient Boosted Decision Trees to the S&P 100. (arXiv:2205.15853v1 [econ.EM])
113. coVariance Neural Networks. (arXiv:2205.15856v1 [cs.LG])
114. Automatic Diagnosis of Schizophrenia and Attention Deficit Hyperactivity Disorder in rs-fMRI Modality using Convolutional Autoencoder Model and Interval Type-2 Fuzzy Regression. (arXiv:2205.15858v1 [cs.LG])
115. A Reduction to Binary Approach for Debiasing Multiclass Datasets. (arXiv:2205.15860v1 [cs.LG])
116. Snapture -- A Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition. (arXiv:2205.15862v1 [cs.CV])
117. CogVideo: Large-scale Pretraining for Text-to-Video Generation via Transformers. (arXiv:2205.15868v1 [cs.CV])
118. SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series. (arXiv:2205.15875v1 [cs.LG])
119. Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games. (arXiv:2205.15879v1 [cs.AI])
120. Compressed Hierarchical Representations for Multi-Task Learning and Task Clustering. (arXiv:2205.15882v1 [cs.LG])
121. One Policy is Enough: Parallel Exploration with a Single Policy is Minimax Optimal for Reward-Free Reinforcement Learning. (arXiv:2205.15891v1 [cs.LG])
122. VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series Forecasting. (arXiv:2205.15894v1 [cs.LG])
123. FedWalk: Communication Efficient Federated Unsupervised Node Embedding with Differential Privacy. (arXiv:2205.15896v1 [cs.DC])
124. Learning brain MRI quality control: a multi-factorial generalization problem. (arXiv:2205.15898v1 [stat.ML])
125. Variational inference via Wasserstein gradient flows. (arXiv:2205.15902v1 [stat.ML])
126. Online Meta-Learning in Adversarial Multi-Armed Bandits. (arXiv:2205.15921v1 [cs.LG])
127. Continuous Temporal Graph Networks for Event-Based Graph Data. (arXiv:2205.15924v1 [cs.LG])
128. Inducing bias is simpler than you think. (arXiv:2205.15935v1 [cs.LG])
129. Minimax Classification under Concept Drift with Multidimensional Adaptation and Performance Guarantees. (arXiv:2205.15942v1 [stat.ML])
130. Hide and Seek: on the Stealthiness of Attacks against Deep Learning Systems. (arXiv:2205.15944v1 [cs.CR])
131. Evaluating Robustness to Dataset Shift via Parametric Robustness Sets. (arXiv:2205.15947v1 [cs.LG])
132. Hollywood Identity Bias Dataset: A Context Oriented Bias Analysis of Movie Dialogues. (arXiv:2205.15951v1 [cs.CL])
133. Knowledge Graph -- Deep Learning: A Case Study in Question Answering in Aviation Safety Domain. (arXiv:2205.15952v1 [cs.CL])
134. Timing is Everything: Learning to Act Selectively with Costly Actions and Budgetary Constraints. (arXiv:2205.15953v1 [cs.LG])
135. You Can't Count on Luck: Why Decision Transformers Fail in Stochastic Environments. (arXiv:2205.15967v1 [cs.LG])
136. FedHarmony: Unlearning Scanner Bias with Distributed Data. (arXiv:2205.15970v1 [cs.LG])
137. Semi-Supervised Cross-Silo Advertising with Partial Knowledge Transfer. (arXiv:2205.15987v1 [cs.LG])
138. A deep learning approach to halo merger tree construction. (arXiv:2205.15988v1 [astro-ph.GA])
139. Private Federated Submodel Learning with Sparsification. (arXiv:2205.15992v1 [cs.IT])
140. TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving. (arXiv:2205.15997v1 [cs.CV])
141. Learning (Very) Simple Generative Models Is Hard. (arXiv:2205.16003v1 [cs.LG])
142. What Knowledge Gets Distilled in Knowledge Distillation?. (arXiv:2205.16004v1 [cs.CV])
143. Kymatio: Scattering Transforms in Python. (arXiv:1812.11214v3 [cs.LG] UPDATED)
144. Cross-view kernel transfer. (arXiv:1910.05964v2 [cs.LG] UPDATED)
145. PDE-based Group Equivariant Convolutional Neural Networks. (arXiv:2001.09046v6 [cs.LG] UPDATED)
146. Fast Predictive Uncertainty for Classification with Bayesian Deep Networks. (arXiv:2003.01227v4 [cs.LG] UPDATED)
147. Nonconvex regularization for sparse neural networks. (arXiv:2004.11515v2 [math.OC] UPDATED)
148. Diversity Policy Gradient for Sample Efficient Quality-Diversity Optimization. (arXiv:2006.08505v5 [cs.AI] UPDATED)
149. A Closer Look at Invalid Action Masking in Policy Gradient Algorithms. (arXiv:2006.14171v3 [cs.LG] UPDATED)
150. Forward and inverse reinforcement learning sharing network weights and hyperparameters. (arXiv:2008.07284v2 [cs.LG] UPDATED)
151. Neural Topic Model via Optimal Transport. (arXiv:2008.13537v3 [cs.IR] UPDATED)
152. Regret Bounds and Reinforcement Learning Exploration of EXP-based Algorithms. (arXiv:2009.09538v2 [cs.LG] UPDATED)
153. CoRe: Color Regression for Multicolor Fashion Garments. (arXiv:2010.02849v2 [cs.CV] UPDATED)
154. Fixed-MAML for Few Shot Classification in Multilingual Speech Emotion Recognition. (arXiv:2101.01356v2 [cs.SD] UPDATED)
155. QLSD: Quantised Langevin stochastic dynamics for Bayesian federated learning. (arXiv:2106.00797v3 [cs.LG] UPDATED)
156. Intrinsic Dimension Estimation Using Wasserstein Distances. (arXiv:2106.04018v2 [stat.ML] UPDATED)
157. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v3 [cs.CV] UPDATED)
158. Generate, Annotate, and Learn: NLP with Synthetic Text. (arXiv:2106.06168v3 [cs.LG] UPDATED)
159. FairCanary: Rapid Continuous Explainable Fairness. (arXiv:2106.07057v3 [cs.LG] UPDATED)
160. Goal-Aware Neural SAT Solver. (arXiv:2106.07162v2 [cs.LG] UPDATED)
161. Mixture of Virtual-Kernel Experts for Multi-Objective User Profile Modeling. (arXiv:2106.07356v2 [cs.IR] UPDATED)
162. On the potential of sequential and non-sequential regression models for Sentinel-1-based biomass prediction in Tanzanian miombo forests. (arXiv:2106.15020v2 [cs.LG] UPDATED)
163. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v4 [cs.LG] UPDATED)
164. A Topological Perspective on Causal Inference. (arXiv:2107.08558v3 [cs.AI] UPDATED)
165. Implicitly Regularized RL with Implicit Q-Values. (arXiv:2108.07041v2 [cs.LG] UPDATED)
166. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v9 [cs.CV] UPDATED)
167. Multiscale modeling of inelastic materials with Thermodynamics-based Artificial Neural Networks (TANN). (arXiv:2108.13137v3 [cond-mat.mtrl-sci] UPDATED)
168. Thompson Sampling for Bandits with Clustered Arms. (arXiv:2109.01656v2 [cs.LG] UPDATED)
169. Neural Network Guided Evolutionary Fuzzing for Finding Traffic Violations of Autonomous Vehicles. (arXiv:2109.06126v3 [cs.SE] UPDATED)
170. Deep Visual Navigation under Partial Observability. (arXiv:2109.07752v3 [cs.RO] UPDATED)
171. Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep Multi-Agent Reinforcement Learning for Collision Avoidance. (arXiv:2109.15266v3 [cs.RO] UPDATED)
172. EdgeML: Towards Network-Accelerated Federated Learning over Wireless Edge. (arXiv:2111.09410v4 [cs.NI] UPDATED)
173. The Computational Drug Repositioning without Negative Sampling. (arXiv:2111.14696v3 [cs.LG] UPDATED)
174. Exploring Representational Alignment with Human Perception Using Identically Represented Inputs. (arXiv:2111.14726v2 [cs.CV] UPDATED)
175. Machine learning a manifold. (arXiv:2112.07673v2 [hep-ph] UPDATED)
176. A Neural Network Solves, Explains, and Generates University Math Problems by Program Synthesis and Few-Shot Learning at Human Level. (arXiv:2112.15594v4 [cs.LG] UPDATED)
177. Multiview Transformers for Video Recognition. (arXiv:2201.04288v4 [cs.CV] UPDATED)
178. Optimal Best Arm Identification in Two-Armed Bandits with a Fixed Budget under a Small Gap. (arXiv:2201.04469v6 [stat.ML] UPDATED)
179. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v6 [cs.LG] UPDATED)
180. ReLSO: A Transformer-based Model for Latent Space Optimization and Generation of Proteins. (arXiv:2201.09948v2 [cs.LG] UPDATED)
181. Crystal structure prediction with machine learning-based element substitution. (arXiv:2201.11188v2 [cond-mat.mtrl-sci] UPDATED)
182. The Effect of Diversity in Meta-Learning. (arXiv:2201.11775v2 [cs.LG] UPDATED)
183. Rethinking Learning Dynamics in RL using Adversarial Networks. (arXiv:2201.11783v2 [cs.LG] UPDATED)
184. Accelerated Quality-Diversity for Robotics through Massive Parallelism. (arXiv:2202.01258v2 [cs.NE] UPDATED)
185. Proportional Fairness in Federated Learning. (arXiv:2202.01666v2 [cs.LG] UPDATED)
186. Optimal Transport of Classifiers to Fairness. (arXiv:2202.03814v2 [cs.LG] UPDATED)
187. Smoothed Online Learning is as Easy as Statistical Learning. (arXiv:2202.04690v3 [stat.ML] UPDATED)
188. Escaping Saddle Points with Bias-Variance Reduced Local Perturbed SGD for Communication Efficient Nonconvex Distributed Learning. (arXiv:2202.06083v2 [cs.LG] UPDATED)
189. An algorithmic solution to the Blotto game using multi-marginal couplings. (arXiv:2202.07318v2 [cs.GT] UPDATED)
190. On the Implicit Bias Towards Minimal Depth of Deep Neural Networks. (arXiv:2202.09028v8 [cs.LG] UPDATED)
191. UAV-Aided Decentralized Learning over Mesh Networks. (arXiv:2203.01008v2 [cs.IT] UPDATED)
192. Neural Galerkin Scheme with Active Learning for High-Dimensional Evolution Equations. (arXiv:2203.01360v3 [math.NA] UPDATED)
193. Doubly-Robust Estimation for Correcting Position-Bias in Click Feedback for Unbiased Learning to Rank. (arXiv:2203.17118v2 [cs.LG] UPDATED)
194. Efficient Test-Time Model Adaptation without Forgetting. (arXiv:2204.02610v2 [cs.LG] UPDATED)
195. CAIPI in Practice: Towards Explainable Interactive Medical Image Classification. (arXiv:2204.02661v2 [cs.LG] UPDATED)
196. Polynomial-time Sparse Deconvolution. (arXiv:2204.07879v2 [cs.LG] UPDATED)
197. A Data-Driven Method for Automated Data Superposition with Applications in Soft Matter Science. (arXiv:2204.09521v2 [physics.data-an] UPDATED)
198. On the Optimization of Margin Distribution. (arXiv:2204.14118v2 [cs.LG] UPDATED)
199. Augmentations: An Insight into their Effectiveness on Convolution Neural Networks. (arXiv:2205.04064v2 [cs.LG] UPDATED)
200. Protecting Data from all Parties: Combining FHE and DP in Federated Learning. (arXiv:2205.04330v2 [cs.CR] UPDATED)
201. Gold-standard solutions to the Schr\"odinger equation using deep learning: How much physics do we need?. (arXiv:2205.09438v2 [cs.LG] UPDATED)
202. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v2 [cs.CV] UPDATED)
203. Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic Treatment Regimes. (arXiv:2205.09852v2 [cs.LG] UPDATED)
204. Learning to branch with Tree MDPs. (arXiv:2205.11107v2 [cs.LG] UPDATED)
205. Causal Machine Learning for Healthcare and Precision Medicine. (arXiv:2205.11402v2 [cs.LG] UPDATED)
206. Privacy-Preserving Wavelet Neural Network with Fully Homomorphic Encryption. (arXiv:2205.13265v2 [cs.LG] UPDATED)
207. Fairness in Recommendation: A Survey. (arXiv:2205.13619v3 [cs.IR] UPDATED)
208. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v2 [cs.LG] UPDATED)
209. Will Bilevel Optimizers Benefit from Loops. (arXiv:2205.14224v2 [cs.LG] UPDATED)
210. Differentially Private Covariance Revisited. (arXiv:2205.14324v2 [cs.CR] UPDATED)
211. Granular Generalized Variable Precision Rough Sets and Rational Approximations. (arXiv:2205.14365v2 [cs.AI] UPDATED)
212. Non-stationary Transformers: Rethinking the Stationarity in Time Series Forecasting. (arXiv:2205.14415v2 [cs.LG] UPDATED)
213. Independent and Decentralized Learning in Markov Potential Games. (arXiv:2205.14590v2 [cs.LG] UPDATED)
214. L3Cube-MahaNLP: Marathi Natural Language Processing Datasets, Models, and Library. (arXiv:2205.14728v2 [cs.CL] UPDATED)
215. Unbalanced CO-Optimal Transport. (arXiv:2205.14923v2 [stat.ML] UPDATED)
216. Data-driven Numerical Invariant Synthesis with Automatic Generation of Attributes. (arXiv:2205.14943v2 [cs.PL] UPDATED)
217. PAC Generalization via Invariant Representations. (arXiv:2205.15196v2 [cs.LG] UPDATED)
218. Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer. (arXiv:2205.15290v2 [cs.CV] UPDATED)
## cs.AI
---
**112** new papers in cs.AI:-) 
1. A Unified Weight Initialization Paradigm for Tensorial Convolutional Neural Networks. (arXiv:2205.15307v1 [cs.LG])
2. Parameter-Efficient and Student-Friendly Knowledge Distillation. (arXiv:2205.15308v1 [cs.LG])
3. Mean Field inference of CRFs based on GAT. (arXiv:2205.15312v1 [cs.LG])
4. Chefs' Random Tables: Non-Trigonometric Random Features. (arXiv:2205.15317v1 [cs.LG])
5. Learning Adaptive Propagation for Knowledge Graph Reasoning. (arXiv:2205.15319v1 [cs.LG])
6. Superposing Many Tickets into One: A Performance Booster for Sparse Neural Network Training. (arXiv:2205.15322v1 [cs.LG])
7. Non-Markovian Reward Modelling from Trajectory Labels via Interpretable Multiple Instance Learning. (arXiv:2205.15367v1 [cs.LG])
8. Guided-TTS 2: A Diffusion Model for High-quality Adaptive Text-to-Speech with Untranscribed Data. (arXiv:2205.15370v1 [cs.SD])
9. Reinforcement Learning with a Terminator. (arXiv:2205.15376v1 [cs.LG])
10. Truly Deterministic Policy Optimization. (arXiv:2205.15379v1 [cs.AI])
11. Designing Rewards for Fast Learning. (arXiv:2205.15400v1 [cs.LG])
12. Painful intelligence: What AI can tell us about human suffering. (arXiv:2205.15409v1 [cs.LG])
13. A portfolio-based analysis method for competition results. (arXiv:2205.15414v1 [cs.AI])
14. Learning Risk-Averse Equilibria in Multi-Agent Systems. (arXiv:2205.15434v1 [cs.LG])
15. HeatER: An Efficient and Unified Network for Human Reconstruction via Heatmap-based TransformER. (arXiv:2205.15448v1 [cs.CV])
16. GLDQN: Explicitly Parameterized Quantile Reinforcement Learning for Waste Reduction. (arXiv:2205.15455v1 [cs.LG])
17. A Unifying Framework for Causal Explanation of Sequential Decision Making. (arXiv:2205.15462v1 [cs.AI])
18. Introduction of a tree-based technique for efficient and real-time label retrieval in the object tracking system. (arXiv:2205.15477v1 [cs.CV])
19. Learning to Represent Programs with Code Hierarchies. (arXiv:2205.15479v1 [cs.SE])
20. Post-hoc Concept Bottleneck Models. (arXiv:2205.15480v1 [cs.LG])
21. Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking. (arXiv:2205.15503v1 [cs.CL])
22. ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts. (arXiv:2205.15509v1 [cs.CV])
23. A Unified Framework for Emotion Identification and Generation in Dialogues. (arXiv:2205.15513v1 [cs.CL])
24. Variational Transfer Learning using Cross-Domain Latent Modulation. (arXiv:2205.15523v1 [cs.LG])
25. Gluing Neural Networks Symbolically Through Hyperdimensional Computing. (arXiv:2205.15534v1 [cs.SC])
26. MACE: An Efficient Model-Agnostic Framework for Counterfactual Explanation. (arXiv:2205.15540v1 [cs.AI])
27. Refining Low-Resource Unsupervised Translation by Language Disentanglement of Multilingual Model. (arXiv:2205.15544v1 [cs.CL])
28. Robust Projection based Anomaly Extraction (RPE) in Univariate Time-Series. (arXiv:2205.15548v1 [stat.ML])
29. GSR: A Generalized Symbolic Regression Approach. (arXiv:2205.15569v1 [cs.LG])
30. Hierarchical Spherical CNNs with Lifting-based Adaptive Wavelets for Pooling and Unpooling. (arXiv:2205.15571v1 [cs.CV])
31. Individual health-disease phase diagrams for disease prevention based on machine learning. (arXiv:2205.15598v1 [cs.LG])
32. Weakly-supervised Action Transition Learning for Stochastic Human Motion Prediction. (arXiv:2205.15608v1 [cs.CV])
33. Communication-Efficient Distributionally Robust Decentralized Learning. (arXiv:2205.15614v1 [cs.LG])
34. Meta-ticket: Finding optimal subnetworks for few-shot learning within randomly initialized neural networks. (arXiv:2205.15619v1 [cs.LG])
35. Multi-task Optimization Based Co-training for Electricity Consumption Prediction. (arXiv:2205.15663v1 [cs.LG])
36. Generalised Implicit Neural Representations. (arXiv:2205.15674v1 [cs.LG])
37. Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v1 [cs.LG])
38. Automatic Relation-aware Graph Network Proliferation. (arXiv:2205.15678v1 [cs.LG])
39. Why are NLP Models Fumbling at Elementary Math? A Survey of Deep Learning based Word Problem Solvers. (arXiv:2205.15683v1 [cs.CL])
40. Self-Supervised Learning for Building Damage Assessment from Large-scale xBD Satellite Imagery Benchmark Datasets. (arXiv:2205.15688v1 [cs.CV])
41. Fast-Spanning Ant Colony Optimisation (FaSACO) for Mobile Robot Coverage Path Planning. (arXiv:2205.15691v1 [cs.RO])
42. An Informational Space Based Semantic Analysis for Scientific Texts. (arXiv:2205.15696v1 [cs.CL])
43. Provable General Function Class Representation Learning in Multitask Bandits and MDPs. (arXiv:2205.15701v1 [cs.LG])
44. Attribute Exploration with Multiple Contradicting Partial Experts. (arXiv:2205.15714v1 [cs.AI])
45. Multi-Agent Learning of Numerical Methods for Hyperbolic PDEs with Factored Dec-MDP. (arXiv:2205.15716v1 [cs.LG])
46. Mixture GAN For Modulation Classification Resiliency Against Adversarial Attacks. (arXiv:2205.15743v1 [cs.LG])
47. HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks. (arXiv:2205.15745v1 [cs.LG])
48. Omni-Granular Ego-Semantic Propagation for Self-Supervised Graph Representation Learning. (arXiv:2205.15746v1 [cs.LG])
49. Variable importance without impossible data. (arXiv:2205.15750v1 [cs.LG])
50. Hierarchies of Reward Machines. (arXiv:2205.15752v1 [cs.LG])
51. Hierarchically Constrained Adaptive Ad **Exposure** in Feeds. (arXiv:2205.15759v1 [cs.AI])
52. Investigating the Role of Image Retrieval for Visual Localization -- An exhaustive benchmark. (arXiv:2205.15761v1 [cs.CV])
53. Knowledge Enhanced Neural Networks for relational domains. (arXiv:2205.15762v1 [cs.LG])
54. A Survey of Deep Fake Detection for Trial Courts. (arXiv:2205.15792v1 [cs.CV])
55. Feature Learning in $L_{2}$-regularized DNNs: Attraction/Repulsion and Sparsity. (arXiv:2205.15809v1 [stat.ML])
56. GateNLP-UShef at SemEval-2022 Task 8: Entity-Enriched Siamese Transformer for Multilingual News Article Similarity. (arXiv:2205.15812v1 [cs.CL])
57. Unsupervised Image Representation Learning with Deep Latent Particles. (arXiv:2205.15821v1 [cs.CV])
58. Robust Anytime Learning of Markov Decision Processes. (arXiv:2205.15827v1 [cs.AI])
59. Snapture -- A Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition. (arXiv:2205.15862v1 [cs.CV])
60. Justifying Social-Choice Mechanism Outcome for Improving Participant Satisfaction. (arXiv:2205.15863v1 [cs.GT])
61. Braille Letter Reading: A Benchmark for Spatio-Temporal Pattern Recognition on Neuromorphic Hardware. (arXiv:2205.15864v1 [cs.CV])
62. 3D-model ShapeNet Core Classification using Meta-Semantic Learning. (arXiv:2205.15869v1 [cs.CV])
63. FaIRCoP: Facial Image Retrieval using Contrastive Personalization. (arXiv:2205.15870v1 [cs.CV])
64. Simplex Neural Population Learning: Any-Mixture Bayes-Optimality in Symmetric Zero-sum Games. (arXiv:2205.15879v1 [cs.AI])
65. VQ-AR: Vector Quantized Autoregressive Probabilistic Time Series Forecasting. (arXiv:2205.15894v1 [cs.LG])
66. Enhanced Teaching-Learning-based Optimization for 3D Path Planning of Multicopter UAVs. (arXiv:2205.15913v1 [cs.RO])
67. Uzbek Sentiment Analysis based on local Restaurant Reviews. (arXiv:2205.15930v1 [cs.CL])
68. A Competitive Method for Dog Nose-print Re-identification. (arXiv:2205.15934v1 [cs.CV])
69. Hide and Seek: on the Stealthiness of Attacks against Deep Learning Systems. (arXiv:2205.15944v1 [cs.CR])
70. Two-Dimensional Quantum Material Identification via Self-Attention and Soft-labeling in Deep Learning. (arXiv:2205.15948v1 [cs.CV])
71. Knowledge Graph -- Deep Learning: A Case Study in Question Answering in Aviation Safety Domain. (arXiv:2205.15952v1 [cs.CL])
72. You Can't Count on Luck: Why Decision Transformers Fail in Stochastic Environments. (arXiv:2205.15967v1 [cs.LG])
73. TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving. (arXiv:2205.15997v1 [cs.CV])
74. Diversity Policy Gradient for Sample Efficient Quality-Diversity Optimization. (arXiv:2006.08505v5 [cs.AI] UPDATED)
75. A Closer Look at Invalid Action Masking in Policy Gradient Algorithms. (arXiv:2006.14171v3 [cs.LG] UPDATED)
76. Forward and inverse reinforcement learning sharing network weights and hyperparameters. (arXiv:2008.07284v2 [cs.LG] UPDATED)
77. Regret Bounds and Reinforcement Learning Exploration of EXP-based Algorithms. (arXiv:2009.09538v2 [cs.LG] UPDATED)
78. Efficient Deviation Types and Learning for Hindsight Rationality in Extensive-Form Games: Corrections. (arXiv:2102.06973v4 [cs.GT] UPDATED)
79. QLSD: Quantised Langevin stochastic dynamics for Bayesian federated learning. (arXiv:2106.00797v3 [cs.LG] UPDATED)
80. Simulated Adversarial Testing of Face Recognition Models. (arXiv:2106.04569v3 [cs.CV] UPDATED)
81. Goal-Aware Neural SAT Solver. (arXiv:2106.07162v2 [cs.LG] UPDATED)
82. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v4 [cs.LG] UPDATED)
83. A Topological Perspective on Causal Inference. (arXiv:2107.08558v3 [cs.AI] UPDATED)
84. Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep Multi-Agent Reinforcement Learning for Collision Avoidance. (arXiv:2109.15266v3 [cs.RO] UPDATED)
85. RWN: Robust Watermarking Network for Image Cropping Localization. (arXiv:2110.05687v2 [cs.CV] UPDATED)
86. Zero-shot Voice Conversion via Self-supervised Prosody Representation Learning. (arXiv:2110.14422v2 [cs.SD] UPDATED)
87. The $n$-queens completion problem. (arXiv:2111.11402v2 [math.CO] UPDATED)
88. The Computational Drug Repositioning without Negative Sampling. (arXiv:2111.14696v3 [cs.LG] UPDATED)
89. Exploring Representational Alignment with Human Perception Using Identically Represented Inputs. (arXiv:2111.14726v2 [cs.CV] UPDATED)
90. Making sense of electrical vehicle discussions using sentiment analysis on closely related news and user comments. (arXiv:2112.12327v3 [cs.CL] UPDATED)
91. A Neural Network Solves, Explains, and Generates University Math Problems by Program Synthesis and Few-Shot Learning at Human Level. (arXiv:2112.15594v4 [cs.LG] UPDATED)
92. From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI. (arXiv:2201.08164v2 [cs.AI] UPDATED)
93. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v6 [cs.LG] UPDATED)
94. MVP-Net: Multiple View Pointwise Semantic Segmentation of Large-Scale Point Clouds. (arXiv:2201.12769v4 [cs.CV] UPDATED)
95. Accelerated Quality-Diversity for Robotics through Massive Parallelism. (arXiv:2202.01258v2 [cs.NE] UPDATED)
96. Proportional Fairness in Federated Learning. (arXiv:2202.01666v2 [cs.LG] UPDATED)
97. Multi-Objective Quality Diversity Optimization. (arXiv:2202.03057v2 [cs.AI] UPDATED)
98. Strategy Synthesis for Zero-sum Neuro-symbolic Concurrent Stochastic Games. (arXiv:2202.06255v2 [cs.AI] UPDATED)
99. Augmentations: An Insight into their Effectiveness on Convolution Neural Networks. (arXiv:2205.04064v2 [cs.LG] UPDATED)
100. Discovering Dynamic Functional Brain Networks via Spatial and Channel-wise Attention. (arXiv:2205.09576v2 [cs.CV] UPDATED)
101. Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic Treatment Regimes. (arXiv:2205.09852v2 [cs.LG] UPDATED)
102. Computable Artificial General Intelligence. (arXiv:2205.10513v3 [cs.AI] UPDATED)
103. Causal Machine Learning for Healthcare and Precision Medicine. (arXiv:2205.11402v2 [cs.LG] UPDATED)
104. Fairness in Recommendation: A Survey. (arXiv:2205.13619v3 [cs.IR] UPDATED)
105. V-Doc : Visual questions answers with Documents. (arXiv:2205.13724v2 [cs.AI] UPDATED)
106. Machine Learning-Based User Scheduling in Integrated Satellite-HAPS-Ground Networks. (arXiv:2205.13958v2 [cs.AI] UPDATED)
107. What Dense Graph Do You Need for Self-Attention?. (arXiv:2205.14014v2 [cs.LG] UPDATED)
108. Cycle Mutation: Evolving Permutations via Cycle Induction. (arXiv:2205.14125v2 [cs.NE] UPDATED)
109. Granular Generalized Variable Precision Rough Sets and Rational Approximations. (arXiv:2205.14365v2 [cs.AI] UPDATED)
110. An adaptive admittance controller for collaborative drilling with a robot based on subtask classification via deep learning. (arXiv:2205.14457v2 [cs.RO] UPDATED)
111. Independent and Decentralized Learning in Markov Potential Games. (arXiv:2205.14590v2 [cs.LG] UPDATED)
112. Zero-Shot and Few-Shot Learning for Lung Cancer Multi-Label Classification using Vision Transformer. (arXiv:2205.15290v2 [cs.CV] UPDATED)

