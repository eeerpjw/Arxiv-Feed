# Your interest papers
---
## cs.CV
---
### Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework. (arXiv:2203.11991v1 [cs.CV])
- Authors : Botao Ye, Hong Chang, Bingpeng Ma, Shiguang Shan
- Link : [http://arxiv.org/abs/2203.11991](http://arxiv.org/abs/2203.11991)
> ABSTRACT  :  The current popular two-stream, two-stage tracking framework extracts the template and the search region features separately and then performs relation modeling, thus the extracted features lack the awareness of the target and have limited target-background discriminability. To tackle the above issue, we propose a novel one-stream tracking (OSTrack) framework that unifies feature learning and relation modeling by bridging the template-search image pairs with bidirectional information flows. In this way, discriminative target-oriented features can be dynamically extracted by mutual guidance. Since no extra heavy relation modeling module is needed and the implementation is highly parallelized, the proposed tracker runs at a fast speed. To further improve the inference efficiency, an in-network candidate early elimination module is proposed based on the strong similarity prior calculated in the one-stream framework. As a unified framework, OSTrack achieves state-of-the-art performance on multiple benchmarks, in particular, it shows impressive results on the one-shot tracking benchmark GOT-10k, i.e., achieving 73.7% AO, improving the existing best result (**Swin**Track) by 4.3%. Besides, our method maintains a good performance-speed trade-off and shows faster convergence. The code and models will be available at https://github.com/botaoye/OSTrack.  
### Unifying Motion Deblurring and Frame Interpolation with Events. (arXiv:2203.12178v1 [cs.CV])
- Authors : Xiang Zhang, Lei Yu
- Link : [http://arxiv.org/abs/2203.12178](http://arxiv.org/abs/2203.12178)
> ABSTRACT  :  Slow shutter speed and long **exposure** time of frame-based cameras often cause visual blur and loss of inter-frame information, degenerating the overall quality of captured videos. To this end, we present a unified framework of event-based motion deblurring and frame interpolation for blurry video **enhancement**, where the extremely low latency of events is leveraged to alleviate motion blur and facilitate intermediate frame prediction. Specifically, the mapping relation between blurry frames and sharp latent images is first predicted by a learnable double integral network, and a fusion network is then proposed to refine the coarse results via utilizing the information from consecutive blurry inputs and the concurrent events. By exploring the mutual constraints among blurry frames, latent images, and event streams, we further propose a self-supervised learning framework to enable network training with real-world blurry videos and events. Extensive experiments demonstrate that our method compares favorably against the state-of-the-art approaches and achieves remarkable performance on both synthetic and real-world datasets.  
### Event-Based Dense Reconstruction Pipeline. (arXiv:2203.12270v1 [cs.CV])
- Authors : Kun Xiao, Guohui Wang, Yi Chen, Jinghong Nan, Yongfeng Xie
- Link : [http://arxiv.org/abs/2203.12270](http://arxiv.org/abs/2203.12270)
> ABSTRACT  :  Event cameras are a new type of sensors that are different from traditional cameras. Each pixel is triggered asynchronously by event. The trigger event is the change of the brightness irradiated on the pixel. If the increment or decrement of brightness is higher than a certain threshold, an event is output. Compared with traditional cameras, event cameras have the advantages of **high dynamic range** and no motion blur. Since events are caused by the apparent motion of intensity edges, the majority of 3D reconstructed maps consist only of scene edges, i.e., semi-dense maps, which is not enough for some applications. In this paper, we propose a pipeline to realize event-based dense reconstruction. First, deep learning is used to reconstruct intensity images from events. And then, structure from motion (SfM) is used to estimate camera intrinsic, extrinsic and sparse point cloud. Finally, multi-view stereo (MVS) is used to complete dense reconstruction.  
### Self-supervised **HDR** Imaging from Motion and **Exposure** Cues. (arXiv:2203.12311v1 [cs.CV])
- Authors : Michal Nazarczuk, Sibi Catley, Ales Leonardis, rez Pellitero
- Link : [http://arxiv.org/abs/2203.12311](http://arxiv.org/abs/2203.12311)
> ABSTRACT  :  Recent **High Dynamic Range** (**HDR**) techniques extend the capabilities of current cameras where scenes with a wide range of illumination can not be accurately captured with a single low-dynamic-range (LDR) image. This is generally accomplished by capturing several LDR images with varying **exposure** values whose information is then incorporated into a merged **HDR** image. While such approaches work well for static scenes, dynamic scenes pose several challenges, mostly related to the difficulty of finding reliable pixel correspondences. Data-driven approaches tackle the problem by learning an end-to-end mapping with paired LDR-**HDR** training data, but in practice generating such **HDR** ground-truth labels for dynamic scenes is time-consuming and requires complex procedures that assume control of certain dynamic elements of the scene (e.g. actor pose) and repeatable lighting conditions (stop-motion capturing). In this work, we propose a novel self-supervised approach for learnable **HDR** estimation that alleviates the need for **HDR** ground-truth labels. We propose to leverage the internal statistics of LDR images to create **HDR** pseudo-labels. We separately exploit static and well-exposed parts of the input images, which in conjunction with synthetic illumination clipping and motion augmentation provide high quality training examples. Experimental results show that the **HDR** models trained using our proposed self-supervision approach achieve performance competitive with those trained under full supervision, and are to a large extent superior to previous methods that equally do not require any supervision.  
### **Real-time** Object Detection for Streaming Perception. (arXiv:2203.12338v1 [cs.CV])
- Authors : Jinrong Yang, Songtao Liu, Zeming Li, Xiaoping Li, Jian Sun
- Link : [http://arxiv.org/abs/2203.12338](http://arxiv.org/abs/2203.12338)
> ABSTRACT  :  Autonomous driving requires the model to perceive the environment and (re)act within a low latency for safety. While past works ignore the inevitable changes in the environment after processing, streaming perception is proposed to jointly evaluate the latency and accuracy into a single metric for video online perception. In this paper, instead of searching trade-offs between accuracy and speed like previous works, we point out that endowing real-time models with the ability to predict the future is the key to dealing with this problem. We build a simple and effective framework for streaming perception. It equips a novel DualFlow Perception module (DFP), which includes dynamic and static flows to capture the moving trend and basic detection feature for streaming prediction. Further, we introduce a Trend-Aware Loss (TAL) combined with a trend factor to generate adaptive weights for objects with different moving speeds. Our simple method achieves competitive performance on Argoverse-HD dataset and improves the AP by 4.9% compared to the strong baseline, validating its effectiveness. Our code will be made available at https://github.com/yancie-yjr/StreamYOLO.  
### GAN Inversion: A Survey. (arXiv:2101.05278v5 [cs.CV] UPDATED)
- Authors : Weihao Xia, Yulun Zhang, Yujiu Yang, Hao Xue, Bolei Zhou, Hsuan Yang
- Link : [http://arxiv.org/abs/2101.05278](http://arxiv.org/abs/2101.05278)
> ABSTRACT  :  GAN inversion aims to invert a given image back into the latent space of a pretrained GAN model, for the image to be faithfully reconstructed from the inverted code by the generator. As an emerging technique to bridge the real and fake image domains, GAN inversion plays an essential role in enabling the pretrained GAN models such as StyleGAN and BigGAN to be used for real image editing applications. Meanwhile, GAN inversion also provides insights on the interpretation of GAN's latent space and how the realistic images can be generated. In this paper, we provide an overview of GAN inversion with a focus on its recent algorithms and applications. We cover important techniques of GAN inversion and their applications to image **restoration** and image manipulation. We further elaborate on some trends and challenges for future directions.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v4 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
### Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v2 [eess.IV] UPDATED)
- Authors : Ziwei Luo, Haibin Huang, Lei Yu, Youwei Li, Haoqiang Fan, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2202.07508](http://arxiv.org/abs/2202.07508)
> ABSTRACT  :  In this paper, we tackle the problem of blind image super-resolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel-based high-resolution image **restoration**. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low-resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yield a more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high-resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements against state-of-the-art methods.  
### Exploring and Evaluating Image **Restoration** Potential in Dynamic Scenes. (arXiv:2203.11754v2 [cs.CV] UPDATED)
- Authors : Cheng Zhang, Shaolin Su, Yu Zhu, Qingsen Yan, Jinqiu Sun, Yanning Zhang
- Link : [http://arxiv.org/abs/2203.11754](http://arxiv.org/abs/2203.11754)
> ABSTRACT  :  In dynamic scenes, images often suffer from dynamic blur due to superposition of motions or low signal-noise ratio resulted from quick shutter speed when avoiding motions. Recovering sharp and clean results from the captured images heavily depends on the ability of **restoration** methods and the quality of the input. Although existing research on image **restoration** focuses on developing models for obtaining better restored results, fewer have studied to evaluate how and which input image leads to superior restored quality. In this paper, to better study an image's potential value that can be explored for **restoration**, we propose a novel concept, referring to image **restoration** potential (IRP). Specifically, We first establish a dynamic scene imaging dataset containing composite distortions and applied image **restoration** processes to validate the rationality of the existence to IRP. Based on this dataset, we investigate several properties of IRP and propose a novel deep model to accurately predict IRP values. By gradually distilling and selective fusing the degradation features, the proposed model shows its superiority in IRP prediction. Thanks to the proposed model, we are then able to validate how various image **restoration** related applications are benefited from IRP prediction. We show the potential usages of IRP as a filtering principle to select valuable frames, an auxiliary guidance to improve **restoration** models, and even an indicator to optimize camera settings for capturing better images under dynamic scenarios.  
## eess.IV
---
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
### U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v4 [cs.CV] UPDATED)
- Authors : Lintao Peng, Chunli Zhu, Liheng Bian
- Link : [http://arxiv.org/abs/2111.11843](http://arxiv.org/abs/2111.11843)
> ABSTRACT  :  The light absorption and scattering of underwater impurities lead to poor underwater imaging quality. The existing data-driven based underwater image **enhancement** (UIE) techniques suffer from the lack of a large-scale dataset containing various underwater scenes and high-fidelity reference images. Besides, the inconsistent attenuation in different color channels and space areas is not fully considered for boosted **enhancement**. In this work, we constructed a large-scale underwater image (LSUI) dataset including 5004 image pairs, and reported an U-shape Transformer network where the transformer model is for the first time introduced to the UIE task. The U-shape Transformer is integrated with a channel-wise multi-scale feature fusion transformer (CMSFFT) module and a spatial-wise global feature modeling transformer (SGFMT) module, which reinforce the network's attention to the color channels and space areas with more serious attenuation. Meanwhile, in order to further improve the contrast and saturation, a novel loss function combining RGB, LAB and LCH color spaces is designed following the human vision principle. The extensive experiments on available datasets validate the state-of-the-art performance of the reported technique with more than 2dB superiority.  
### Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v2 [eess.IV] UPDATED)
- Authors : Ziwei Luo, Haibin Huang, Lei Yu, Youwei Li, Haoqiang Fan, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2202.07508](http://arxiv.org/abs/2202.07508)
> ABSTRACT  :  In this paper, we tackle the problem of blind image super-resolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel-based high-resolution image **restoration**. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low-resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yield a more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high-resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements against state-of-the-art methods.  
## cs.LG
---
### MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data. (arXiv:2203.12369v1 [cs.SD])
- Authors : George Close, Thomas Hain, Stefan Goetze
- Link : [http://arxiv.org/abs/2203.12369](http://arxiv.org/abs/2203.12369)
> ABSTRACT  :  Training of speech **enhancement** systems often does not incorporate knowledge of human perception and thus can lead to unnatural sounding results. Incorporating psychoacoustically motivated speech perception metrics as part of model training via a predictor network has recently gained interest. However, the performance of such predictors is limited by the distribution of metric scores that appear in the training data.In this work, we propose MetricGAN+/- (an extension of MetricGAN+, one such metric-motivated system) which introduces an additional network - a "de-generator" which attempts to improve the robustness of the prediction network (and by extension of the generator) by ensuring observation of a wider range of metric scores in training. Experimental results on the VoiceBank-DEMAND dataset show relative improvement in PESQ score of $3.8\%$ ($3.05$ vs $3.22$ PESQ score), as well as better generalisation to unseen noise and speech.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
## cs.AI
---
### Muscle Vision: Real Time Keypoint Based Pose Classification of Physical Exercises. (arXiv:2203.12111v1 [cs.AI])
- Authors : Alex Moran, Bart Gebka, Joshua Goldshteyn, Autumn Beyer, Nathan Johnson, Alexander Neuwirth
- Link : [http://arxiv.org/abs/2203.12111](http://arxiv.org/abs/2203.12111)
> ABSTRACT  :  Recent advances in machine learning technology have enabled highly portable and performant models for many common tasks, especially in image recognition. One emerging field, 3D human pose recognition extrapolated from video, has now advanced to the point of enabling real-time software applications with robust enough output to support downstream machine learning tasks. In this work we propose a new machine learning pipeline and web interface that performs human pose recognition on a live video feed to detect when common exercises are performed and classify them accordingly. We present a model interface capable of webcam input with live display of classification results. Our main contributions include a keypoint and time series based lightweight approach for classifying a selected set of fitness exercises and a web-based software application for obtaining and visualizing the results in **real time**.  
### FullSubNet+: Channel Attention FullSubNet with Complex Spectrograms for Speech **Enhancement**. (arXiv:2203.12188v1 [cs.SD])
- Authors : Jun Chen, Zilin Wang, Deyi Tuo, Zhiyong Wu, Shiyin Kang, Helen Meng
- Link : [http://arxiv.org/abs/2203.12188](http://arxiv.org/abs/2203.12188)
> ABSTRACT  :  Previously proposed FullSubNet has achieved outstanding performance in Deep Noise Suppression (DNS) Challenge and attracted much attention. However, it still encounters issues such as input-output mismatch and coarse processing for frequency bands. In this paper, we propose an extended single-channel real-time speech **enhancement** framework called FullSubNet+ with following significant improvements. First, we design a lightweight multi-scale time sensitive channel attention (MulCA) module which adopts multi-scale convolution and channel attention mechanism to help the network focus on more discriminative frequency bands for noise reduction. Then, to make full use of the phase information in noisy speech, our model takes all the magnitude, real and imaginary spectrograms as inputs. Moreover, by replacing the long short-term memory (LSTM) layers in original full-band model with stacked temporal convolutional network (TCN) blocks, we design a more efficient full-band module called full-band extractor. The experimental results in DNS Challenge dataset show the superior performance of our FullSubNet+, which reaches the state-of-the-art (SOTA) performance and outperforms other existing speech **enhancement** approaches.  
### Socially Fair Mitigation of Misinformation on Social Networks via Constraint Stochastic Optimization. (arXiv:2203.12537v1 [cs.SI])
- Authors : Ahmed Abouzeid, Christoffer Granmo, Christian Webersik, Morten Goodwin
- Link : [http://arxiv.org/abs/2203.12537](http://arxiv.org/abs/2203.12537)
> ABSTRACT  :  Recent social networks' misinformation mitigation approaches tend to investigate how to reduce misinformation by considering a whole-network statistical scale. However, unbalanced misinformation **exposure**s among individuals urge to study fair allocation of mitigation resources. Moreover, the network has random dynamics which change over time. Therefore, we introduce a stochastic and non-stationary knapsack problem, and we apply its resolution to mitigate misinformation in social network campaigns. We further propose a generic misinformation mitigation algorithm that is robust to different social networks' misinformation statistics, allowing a promising impact in real-world scenarios. A novel loss function ensures fair mitigation among users. We achieve fairness by intelligently allocating a mitigation incentivization budget to the knapsack, and optimizing the loss function. To this end, a team of Learning Automata (LA) drives the budget allocation. Each LA is associated with a user and learns to minimize its **exposure** to misinformation by performing a non-stationary and stochastic walk over its state space. Our results show how our LA-based method is robust and outperforms similar misinformation mitigation methods in how the mitigation is fairly influencing the network users.  
# Paper List
---
## cs.CV
---
**133** new papers in cs.CV:-) 
1. CM-GAN: Image Inpainting with Cascaded Modulation GAN and Object-Aware Training. (arXiv:2203.11947v1 [cs.CV])
2. Learning Patch-to-Cluster Attention in Vision Transformer. (arXiv:2203.11987v1 [cs.CV])
3. Joint Feature Learning and Relation Modeling for Tracking: A One-Stream Framework. (arXiv:2203.11991v1 [cs.CV])
4. Learning Geodesic-Aware Local Features from RGB-D Images. (arXiv:2203.12016v1 [cs.CV])
5. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v1 [cs.LG])
6. Self-supervision through Random Segments with Autoregressive Coding (RandSAC). (arXiv:2203.12054v1 [cs.CV])
7. WayFAST: Traversability Predictive Navigation for Field Robots. (arXiv:2203.12071v1 [cs.RO])
8. DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification. (arXiv:2203.12081v1 [cs.CV])
9. PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo. (arXiv:2203.12082v1 [cs.CV])
10. Deep Portrait Delighting. (arXiv:2203.12088v1 [cs.CV])
11. FxP-QNet: A Post-Training Quantizer for the Design of Mixed Low-Precision DNNs with Dynamic Fixed-Point Representation. (arXiv:2203.12091v1 [cs.NE])
12. Fast on-line signature recognition based on VQ with time modeling. (arXiv:2203.12104v1 [cs.CV])
13. Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer Tissue Biopsy Samples. (arXiv:2203.12112v1 [cs.AI])
14. GOSS: Towards Generalized Open-set Semantic Segmentation. (arXiv:2203.12116v1 [cs.CV])
15. Visual Prompt Tuning. (arXiv:2203.12119v1 [cs.CV])
16. Contrastive Transformer-based Multiple Instance Learning for Weakly Supervised Polyp Frame Detection. (arXiv:2203.12121v1 [cs.CV])
17. Pixel VQ-VAEs for Improved Pixel Art Representation. (arXiv:2203.12130v1 [cs.CV])
18. Semi-Supervised Hybrid Spine Network for Segmentation of Spine MR Images. (arXiv:2203.12151v1 [cs.CV])
19. Comprehensive Benchmark Datasets for Amharic Scene Text Detection and Recognition. (arXiv:2203.12165v1 [cs.CV])
20. Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing. (arXiv:2203.12175v1 [cs.CV])
21. Unifying Motion Deblurring and Frame Interpolation with Events. (arXiv:2203.12178v1 [cs.CV])
22. Learning to Censor by Noisy Sampling. (arXiv:2203.12192v1 [cs.CV])
23. Self-Supervised Robust Scene Flow Estimation via the Alignment of Probability Density Functions. (arXiv:2203.12193v1 [cs.CV])
24. Biceph-Net: A robust and lightweight framework for the diagnosis of Alzheimer's disease using 2D-MRI scans and deep similarity learning. (arXiv:2203.12197v1 [cs.CV])
25. Deep Frequency Filtering for Domain Generalization. (arXiv:2203.12198v1 [cs.CV])
26. Interpretable Prediction of Lung Squamous Cell Carcinoma Recurrence With Self-supervised Learning. (arXiv:2203.12204v1 [cs.CV])
27. Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection. (arXiv:2203.12208v1 [cs.CV])
28. Physics-Driven Deep Learning for Computational Magnetic Resonance Imaging. (arXiv:2203.12215v1 [eess.IV])
29. Training-free Transformer Architecture Search. (arXiv:2203.12217v1 [cs.CV])
30. Efficient Few-Shot Object Detection via Knowledge Inheritance. (arXiv:2203.12224v1 [cs.CV])
31. Negative Selection by Clustering for Contrastive Learning in Human Activity Recognition. (arXiv:2203.12230v1 [cs.CV])
32. A Multi-Characteristic Learning Method with Micro-Doppler Signatures for Pedestrian Identification. (arXiv:2203.12236v1 [eess.SP])
33. A Method of Data Augmentation to Train a Small Area Fingerprint Recognition Deep Neural Network with a Normal Fingerprint Database. (arXiv:2203.12241v1 [cs.CV])
34. Scale-Equivalent Distillation for Semi-Supervised Object Detection. (arXiv:2203.12244v1 [cs.CV])
35. Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition. (arXiv:2203.12247v1 [cs.CV])
36. Event-Based Dense Reconstruction Pipeline. (arXiv:2203.12270v1 [cs.CV])
37. DAN: a Segmentation-free Document Attention Network for Handwritten Document Recognition. (arXiv:2203.12273v1 [cs.CV])
38. Cell segmentation from telecentric bright-field transmitted light microscopic images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v1 [q-bio.QM])
39. Lane detection with Position Embedding. (arXiv:2203.12301v1 [cs.CV])
40. Domain-Generalized Textured Surface Anomaly Detection. (arXiv:2203.12304v1 [cs.CV])
41. Self-supervised **HDR** Imaging from Motion and **Exposure** Cues. (arXiv:2203.12311v1 [cs.CV])
42. Autofocus for Event Cameras. (arXiv:2203.12321v1 [cs.CV])
43. DR.VIC: Decomposition and Reasoning for Video Individual Counting. (arXiv:2203.12335v1 [cs.CV])
44. Binary Morphological Neural Network. (arXiv:2203.12337v1 [cs.CV])
45. **Real-time** Object Detection for Streaming Perception. (arXiv:2203.12338v1 [cs.CV])
46. Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin. (arXiv:2203.12341v1 [cs.CV])
47. How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs. (arXiv:2203.12344v1 [cs.CV])
48. Robust Text Line Detection in Historical Documents: Learning and Evaluation Methods. (arXiv:2203.12346v1 [cs.CV])
49. Hyper-Spectral Imaging for Overlapping Plastic Flakes Segmentation. (arXiv:2203.12350v1 [cs.CV])
50. Transformer-based Multimodal Information Fusion for Facial Expression Analysis. (arXiv:2203.12367v1 [cs.CV])
51. On the (Limited) Generalization of MasterFace Attacks and Its Relation to the Capacity of Face Representations. (arXiv:2203.12387v1 [cs.CV])
52. U-Boost NAS: Utilization-Boosted Differentiable Neural Architecture Search. (arXiv:2203.12412v1 [cs.LG])
53. An Attention-based Method for Action Unit Detection at the 3rd ABAW Competition. (arXiv:2203.12428v1 [cs.CV])
54. SMEMO: Social Memory for Trajectory Forecasting. (arXiv:2203.12446v1 [cs.CV])
55. MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels. (arXiv:2203.12454v1 [cs.CV])
56. Activation-Based Sampling for Pixel- to Image-Level Aggregation in Weakly-Supervised Segmentation. (arXiv:2203.12459v1 [cs.CV])
57. 3D Adapted Random Forest Vision (3DARFV) for Untangling Heterogeneous-Fabric Exceeding Deep Learning Semantic Segmentation Efficiency at the Utmost Accuracy. (arXiv:2203.12469v1 [cs.CV])
58. Adaptively Re-weighting Multi-Loss Untrained Transformer for Sparse-View Cone-Beam CT Reconstruction. (arXiv:2203.12476v1 [cs.CV])
59. A Deep Learning Framework to Reconstruct Face under Mask. (arXiv:2203.12482v1 [cs.CV])
60. CroMo: Cross-Modal Learning for Monocular Depth Estimation. (arXiv:2203.12485v1 [cs.CV])
61. Refine-Net: Normal Refinement Neural Network for Noisy Point Clouds. (arXiv:2203.12514v1 [cs.CV])
62. Multi-label Transformer for Action Unit Detection. (arXiv:2203.12531v1 [cs.CV])
63. GriTS: Grid table similarity metric for table structure recognition. (arXiv:2203.12555v1 [cs.LG])
64. DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation. (arXiv:2203.12560v1 [cs.CV])
65. Your "Attention" Deserves Attention: A Self-Diversified Multi-Channel Attention for Facial Action Analysis. (arXiv:2203.12570v1 [cs.CV])
66. NeuMan: Neural Human Radiance Field from a Single Video. (arXiv:2203.12575v1 [cs.CV])
67. R3M: A Universal Visual Representation for Robot Manipulation. (arXiv:2203.12601v1 [cs.RO])
68. VideoMAE: Masked Autoencoders are Data-Efficient Learners for Self-Supervised Video Pre-Training. (arXiv:2203.12602v1 [cs.CV])
69. Improving the Fairness of Chest X-ray Classifiers. (arXiv:2203.12609v1 [cs.LG])
70. StructToken : Rethinking Semantic Segmentation with Structural Prior. (arXiv:2203.12612v1 [cs.CV])
71. A Hybrid Mesh-neural Representation for 3D Transparent Object Reconstruction. (arXiv:2203.12613v1 [cs.CV])
72. Unsupervised Salient Object Detection with Spectral Cluster Voting. (arXiv:2203.12614v1 [cs.CV])
73. Inferring Restaurant Styles by Mining Crowd Sourced Photos from User-Review Websites. (arXiv:1611.06301v3 [cs.CV] UPDATED)
74. Non-Volume Preserving-based Fusion to Group-Level Emotion Recognition on Crowd Videos. (arXiv:1811.11849v4 [cs.CV] UPDATED)
75. Face Completion with Semantic Knowledge and Collaborative Adversarial Learning. (arXiv:1812.03252v3 [cs.CV] UPDATED)
76. More Knowledge is Better: Cross-Modality Volume Completion and 3D+2D Segmentation for Intracardiac Echocardiography Contouring. (arXiv:1812.03507v3 [cs.CV] UPDATED)
77. Skin Disease Classification versus Skin Lesion Characterization: Achieving Robust Diagnosis using Multi-label Deep Neural Networks. (arXiv:1812.03520v3 [cs.CV] UPDATED)
78. A Deep Multi-task Learning Approach to Skin Lesion Classification. (arXiv:1812.03527v3 [cs.CV] UPDATED)
79. Generative Mask Pyramid Network for CT/CBCT Metal Artifact Reduction with Joint Projection-Sinogram Correction. (arXiv:1907.00294v4 [eess.IV] UPDATED)
80. On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited. (arXiv:2003.05597v4 [cs.CV] UPDATED)
81. Incremental Few-Shot Object Detection for Robotics. (arXiv:2005.02641v2 [cs.CV] UPDATED)
82. Rethinking Anticipation Tasks: Uncertainty-aware Anticipation of Sparse Surgical Instrument Usage for Context-aware Assistance. (arXiv:2007.00548v3 [cs.CV] UPDATED)
83. Representation Decomposition for Image Manipulation and Beyond. (arXiv:2011.00788v2 [cs.CV] UPDATED)
84. PLAD: Learning to Infer Shape Programs with Pseudo-Labels and Approximate Distributions. (arXiv:2011.13045v4 [cs.CV] UPDATED)
85. GAN Inversion: A Survey. (arXiv:2101.05278v5 [cs.CV] UPDATED)
86. Countering Malicious DeepFakes: Survey, Battleground, and Horizon. (arXiv:2103.00218v3 [cs.CV] UPDATED)
87. FIBER: Fill-in-the-Blanks as a Challenging Video Understanding Evaluation Framework. (arXiv:2104.04182v3 [cs.CV] UPDATED)
88. SQN: Weakly-Supervised Semantic Segmentation of Large-Scale 3D Point Clouds. (arXiv:2104.04891v2 [cs.CV] UPDATED)
89. ShapeMOD: Macro Operation Discovery for 3D Shape Programs. (arXiv:2104.06392v3 [cs.GR] UPDATED)
90. Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v4 [eess.IV] UPDATED)
91. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
92. The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape Regions with Approximate Inference. (arXiv:2106.12026v3 [cs.CV] UPDATED)
93. FastSHAP: Real-Time Shapley Value Estimation. (arXiv:2107.07436v3 [stat.ML] UPDATED)
94. Human Pose and Shape Estimation from Single Polarization Images. (arXiv:2108.06834v2 [cs.CV] UPDATED)
95. Sensor Data Augmentation by Resampling for Contrastive Learning in Human Activity Recognition. (arXiv:2109.02054v2 [cs.HC] UPDATED)
96. Towards Autonomous Crop-Agnostic Visual Navigation in Arable Fields. (arXiv:2109.11936v2 [cs.RO] UPDATED)
97. Explainability-Aware One Point Attack for Point Cloud Neural Networks. (arXiv:2110.04158v3 [cs.CV] UPDATED)
98. UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection. (arXiv:2111.08644v2 [cs.CV] UPDATED)
99. Local Texture Estimator for Implicit Representation Function. (arXiv:2111.08918v4 [cs.CV] UPDATED)
100. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v10 [cs.CV] UPDATED)
101. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v4 [cs.CV] UPDATED)
102. Extracting Triangular 3D Models, Materials, and Lighting From Images. (arXiv:2111.12503v3 [cs.CV] UPDATED)
103. QMagFace: Simple and Accurate Quality-Aware Face Recognition. (arXiv:2111.13475v3 [cs.CV] UPDATED)
104. Ranking Distance Calibration for Cross-Domain Few-Shot Learning. (arXiv:2112.00260v2 [cs.CV] UPDATED)
105. Learning Transformer Features for Image Quality Assessment. (arXiv:2112.00485v2 [cs.CV] UPDATED)
106. PartImageNet: A Large, High-Quality Dataset of Parts. (arXiv:2112.00933v2 [cs.CV] UPDATED)
107. Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training. (arXiv:2112.03552v3 [cs.CV] UPDATED)
108. Watermarking Images in Self-Supervised Latent Spaces. (arXiv:2112.09581v2 [cs.CV] UPDATED)
109. Generalized Few-Shot Semantic Segmentation: All You Need is Fine-Tuning. (arXiv:2112.10982v2 [cs.CV] UPDATED)
110. Omni-Seg: A Single Dynamic Network for Multi-label Renal Pathology Image Segmentation using Partially Labeled Data. (arXiv:2112.12665v2 [eess.IV] UPDATED)
111. Improving the Behaviour of Vision Transformers with Token-consistent Stochastic Layers. (arXiv:2112.15111v2 [cs.CV] UPDATED)
112. TransVPR: Transformer-based place recognition with multi-level attention aggregation. (arXiv:2201.02001v3 [cs.CV] UPDATED)
113. ImpliCity: City Modeling from Satellite Images with Deep Implicit Occupancy Fields. (arXiv:2201.09968v2 [cs.CV] UPDATED)
114. Anomaly Detection via Reverse Distillation from One-Class Embedding. (arXiv:2201.10703v2 [cs.CV] UPDATED)
115. Learning Robust Convolutional Neural Networks with Relevant Feature Focusing via Explanations. (arXiv:2202.04237v2 [cs.CV] UPDATED)
116. Adversarial Fine-tuning for Backdoor Defense: Connecting Backdoor Attacks to Adversarial Attacks. (arXiv:2202.06312v2 [cs.CV] UPDATED)
117. Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v2 [eess.IV] UPDATED)
118. Ditto: Building Digital Twins of Articulated Objects from Interaction. (arXiv:2202.08227v2 [cs.CV] UPDATED)
119. A Comprehensive Review of Computer Vision in Sports: Open Issues, Future Trends and Research Directions. (arXiv:2203.02281v2 [cs.CV] UPDATED)
120. Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon. (arXiv:2203.03818v3 [cs.CV] UPDATED)
121. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v4 [cs.CV] UPDATED)
122. Hierarchical Memory Learning for Fine-Grained Scene Graph Generation. (arXiv:2203.06907v3 [cs.CV] UPDATED)
123. Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation. (arXiv:2203.07697v4 [cs.CV] UPDATED)
124. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v3 [cs.CV] UPDATED)
125. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v2 [cs.CV] UPDATED)
126. Multi-similarity based Hyperrelation Network for few-shot segmentation. (arXiv:2203.09550v2 [cs.CV] UPDATED)
127. Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation. (arXiv:2203.09653v2 [cs.CV] UPDATED)
128. Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion. (arXiv:2203.09855v2 [cs.CV] UPDATED)
129. Unidirectional Thin Adapter for Efficient Adaptation of Deep Neural Networks. (arXiv:2203.10463v2 [cs.CV] UPDATED)
130. CLIP meets GamePhysics: Towards bug identification in gameplay videos using zero-shot transfer learning. (arXiv:2203.11096v2 [cs.CV] UPDATED)
131. No Pain, Big Gain: Classify Dynamic Point Cloud Sequences with Static Models by Fitting Feature-level Space-time Surfaces. (arXiv:2203.11113v2 [cs.CV] UPDATED)
132. Channel Self-Supervision for Online Knowledge Distillation. (arXiv:2203.11660v2 [cs.CV] UPDATED)
133. Exploring and Evaluating Image **Restoration** Potential in Dynamic Scenes. (arXiv:2203.11754v2 [cs.CV] UPDATED)
## eess.IV
---
**17** new papers in eess.IV:-) 
1. A Quantitative Comparison between Shannon and Tsallis Havrda Charvat Entropies Applied to Cancer Outcome Prediction. (arXiv:2203.11943v1 [eess.IV])
2. A hybrid quantum image edge detector for the NISQ era. (arXiv:2203.12072v1 [quant-ph])
3. Physics-Driven Deep Learning for Computational Magnetic Resonance Imaging. (arXiv:2203.12215v1 [eess.IV])
4. Cell segmentation from telecentric bright-field transmitted light microscopic images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v1 [q-bio.QM])
5. Activation-Based Sampling for Pixel- to Image-Level Aggregation in Weakly-Supervised Segmentation. (arXiv:2203.12459v1 [cs.CV])
6. Sampling Theorems for Unsupervised Learning in Linear Inverse Problems. (arXiv:2203.12513v1 [stat.ML])
7. Scatter Ptychography. (arXiv:2203.12561v1 [eess.IV])
8. Improving the Fairness of Chest X-ray Classifiers. (arXiv:2203.12609v1 [cs.LG])
9. Generative Mask Pyramid Network for CT/CBCT Metal Artifact Reduction with Joint Projection-Sinogram Correction. (arXiv:1907.00294v4 [eess.IV] UPDATED)
10. Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v4 [eess.IV] UPDATED)
11. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
12. Local Texture Estimator for Implicit Representation Function. (arXiv:2111.08918v4 [cs.CV] UPDATED)
13. U-shape Transformer for Underwater Image **Enhancement**. (arXiv:2111.11843v4 [cs.CV] UPDATED)
14. Learning Transformer Features for Image Quality Assessment. (arXiv:2112.00485v2 [cs.CV] UPDATED)
15. Omni-Seg: A Single Dynamic Network for Multi-label Renal Pathology Image Segmentation using Partially Labeled Data. (arXiv:2112.12665v2 [eess.IV] UPDATED)
16. Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v2 [eess.IV] UPDATED)
17. A Comprehensive Review of Computer Vision in Sports: Open Issues, Future Trends and Research Directions. (arXiv:2203.02281v2 [cs.CV] UPDATED)
## cs.LG
---
**143** new papers in cs.LG:-) 
1. A Quantitative Comparison between Shannon and Tsallis Havrda Charvat Entropies Applied to Cancer Outcome Prediction. (arXiv:2203.11943v1 [eess.IV])
2. Scalable Deep Reinforcement Learning Algorithms for Mean Field Games. (arXiv:2203.11973v1 [cs.LG])
3. Resonance in Weight Space: Covariate Shift Can Drive Divergence of SGD with Momentum. (arXiv:2203.11992v1 [cs.LG])
4. Federated Self-Supervised Learning for Acoustic Event Classification. (arXiv:2203.11997v1 [cs.SD])
5. Text Transformations in Contrastive Self-Supervised Learning: A Review. (arXiv:2203.12000v1 [cs.CL])
6. Merging Knockout and Round-Robin Tournaments: A Flexible Linear Elimination Tournament Design. (arXiv:2203.12011v1 [cs.GT])
7. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v1 [cs.LG])
8. Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing. (arXiv:2203.12026v1 [cs.SE])
9. Bioplastic Design using Multitask Deep Neural Networks. (arXiv:2203.12033v1 [cond-mat.mtrl-sci])
10. Review of Metrics to Measure the Stability, Robustness and Resilience of Reinforcement Learning. (arXiv:2203.12048v1 [cs.LG])
11. WayFAST: Traversability Predictive Navigation for Field Robots. (arXiv:2203.12071v1 [cs.RO])
12. DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification. (arXiv:2203.12081v1 [cs.CV])
13. Deep Portrait Delighting. (arXiv:2203.12088v1 [cs.CV])
14. Toward Physically Realizable Quantum Neural Networks. (arXiv:2203.12092v1 [quant-ph])
15. Learning curves for the multi-class teacher-student perceptron. (arXiv:2203.12094v1 [stat.ML])
16. Learning by non-interfering feedback chemical signaling in physical networks. (arXiv:2203.12098v1 [cond-mat.soft])
17. Fast on-line signature recognition based on VQ with time modeling. (arXiv:2203.12104v1 [cs.CV])
18. An Empirical Study on Learning and Improving the Search Objective for Unsupervised Paraphrasing. (arXiv:2203.12106v1 [cs.CL])
19. An Optical Controlling Environment and Reinforcement Learning Benchmarks. (arXiv:2203.12114v1 [cs.LG])
20. NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty. (arXiv:2203.12117v1 [cs.AI])
21. Matrix Completion with Heterogonous Cost. (arXiv:2203.12120v1 [cs.LG])
22. Pixel VQ-VAEs for Improved Pixel Art Representation. (arXiv:2203.12130v1 [cs.CV])
23. Should Machine Learning Models Report to Us When They Are Clueless?. (arXiv:2203.12131v1 [cs.LG])
24. Wasserstein Distributionally Robust Optimization via Wasserstein Barycenters. (arXiv:2203.12136v1 [stat.ML])
25. Out of Distribution Detection, Generalization, and Robustness Triangle with Maximum Probability Theorem. (arXiv:2203.12145v1 [cs.LG])
26. 3D-EDM: Early Detection Model for 3D-Printer Faults. (arXiv:2203.12147v1 [cs.LG])
27. An Emulation Framework for Fire Front Spread. (arXiv:2203.12160v1 [cs.LG])
28. An Adaptive Gradient Method with Energy and Momentum. (arXiv:2203.12191v1 [math.OC])
29. Learning to Censor by Noisy Sampling. (arXiv:2203.12192v1 [cs.CV])
30. Biceph-Net: A robust and lightweight framework for the diagnosis of Alzheimer's disease using 2D-MRI scans and deep similarity learning. (arXiv:2203.12197v1 [cs.CV])
31. Physics-Driven Deep Learning for Computational Magnetic Resonance Imaging. (arXiv:2203.12215v1 [eess.IV])
32. Modality Competition: What Makes Joint Training of Multi-modal Network Fail in Deep Learning? (Provably). (arXiv:2203.12221v1 [cs.LG])
33. Geometry-Aware Supertagging with Heterogeneous Dynamic Convolutions. (arXiv:2203.12235v1 [cs.CL])
34. A Multi-Characteristic Learning Method with Micro-Doppler Signatures for Pedestrian Identification. (arXiv:2203.12236v1 [eess.SP])
35. New Distinguishers for Negation-Limited Weak Pseudorandom Functions. (arXiv:2203.12246v1 [cs.CC])
36. Node Representation Learning in Graph via Node-to-Neighbourhood Mutual Information Maximization. (arXiv:2203.12265v1 [cs.LG])
37. PEAR: Personalized Re-ranking with Contextualized Transformer for Recommendation. (arXiv:2203.12267v1 [cs.IR])
38. Efficient Fully Distributed Federated Learning with Adaptive Local Links. (arXiv:2203.12281v1 [cs.LG])
39. Increasing the accuracy and resolution of precipitation forecasts using deep generative models. (arXiv:2203.12297v1 [stat.ML])
40. Input-specific Attention Subnetworks for Adversarial Detection. (arXiv:2203.12298v1 [cs.CL])
41. NavDreams: Towards Camera-Only RL Navigation Among Humans. (arXiv:2203.12299v1 [cs.RO])
42. Wider or Deeper Neural Network Architecture for Acoustic Scene Classification with Mismatched Recording Devices. (arXiv:2203.12314v1 [cs.SD])
43. The BP Dependency Function: a Generic Measure of Dependence between Random Variables. (arXiv:2203.12329v1 [stat.ML])
44. Towards explaining the generalization gap in neural networks using topological data analysis. (arXiv:2203.12330v1 [cs.LG])
45. Binary Morphological Neural Network. (arXiv:2203.12337v1 [cs.CV])
46. Ethereum Fraud Detection with Heterogeneous Graph Neural Networks. (arXiv:2203.12363v1 [cs.LG])
47. MetricGAN+/-: Increasing Robustness of Noise Reduction on Unseen Data. (arXiv:2203.12369v1 [cs.SD])
48. Dynamically-Scaled Deep Canonical Correlation Analysis. (arXiv:2203.12377v1 [cs.LG])
49. Verification of safety critical control policies using kernel methods. (arXiv:2203.12407v1 [eess.SY])
50. U-Boost NAS: Utilization-Boosted Differentiable Neural Architecture Search. (arXiv:2203.12412v1 [cs.LG])
51. Federated Learning Approach for Lifetime Prediction of Semiconductor Lasers. (arXiv:2203.12414v1 [cs.LG])
52. A Hybrid CNN-LSTM Approach for Laser Remaining Useful Life Prediction. (arXiv:2203.12415v1 [cs.LG])
53. Collaborative Self Organizing Map with DeepNNs for Fake Task Prevention in Mobile Crowdsensing. (arXiv:2203.12434v1 [cs.NE])
54. Deep Multi-View Learning for Tire Recommendation. (arXiv:2203.12451v1 [cs.LG])
55. Reducing overestimating and underestimating volatility via the augmented blending-ARCH model. (arXiv:2203.12456v1 [q-fin.ST])
56. Activation-Based Sampling for Pixel- to Image-Level Aggregation in Weakly-Supervised Segmentation. (arXiv:2203.12459v1 [cs.CV])
57. 3D Adapted Random Forest Vision (3DARFV) for Untangling Heterogeneous-Fabric Exceeding Deep Learning Semantic Segmentation Efficiency at the Utmost Accuracy. (arXiv:2203.12469v1 [cs.CV])
58. A Deep Learning Framework to Reconstruct Face under Mask. (arXiv:2203.12482v1 [cs.CV])
59. Quantum-enhanced Markov chain Monte Carlo. (arXiv:2203.12497v1 [quant-ph])
60. A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v1 [cs.LG])
61. Sampling Theorems for Unsupervised Learning in Linear Inverse Problems. (arXiv:2203.12513v1 [stat.ML])
62. Semi-Supervised Graph Learning Meets Dimensionality Reduction. (arXiv:2203.12522v1 [cs.LG])
63. A Deep Learning Approach to Probabilistic Forecasting of Weather. (arXiv:2203.12529v1 [stat.ML])
64. Pathways: Asynchronous Distributed Dataflow for ML. (arXiv:2203.12533v1 [cs.DC])
65. Constrained Clustering and Multiple Kernel Learning without Pairwise Constraint Relaxation. (arXiv:2203.12546v1 [cs.LG])
66. GriTS: Grid table similarity metric for table structure recognition. (arXiv:2203.12555v1 [cs.LG])
67. A Top-down Supervised Learning Approach to Hierarchical Multi-label Classification in Networks. (arXiv:2203.12569v1 [cs.LG])
68. Mitigating Gender Bias in Distilled Language Models via Counterfactual Role Reversal. (arXiv:2203.12574v1 [cs.CL])
69. Minimax Regret for Cascading Bandits. (arXiv:2203.12577v1 [cs.LG])
70. TransSleep: Transitioning-aware Attention-based Deep Neural Network for Sleep Staging. (arXiv:2203.12590v1 [cs.LG])
71. Your Policy Regularizer is Secretly an Adversary. (arXiv:2203.12592v1 [cs.LG])
72. Deep Learning based Intelligent Coin-tap Test for Defect Recognition. (arXiv:2203.12594v1 [eess.SP])
73. PhysioMTL: Personalizing Physiological Patterns using Optimal Transport Multi-Task Regression. (arXiv:2203.12595v1 [eess.SP])
74. ZOOMER: Boosting Retrieval on Web-scale Graphs by Regions of Interest. (arXiv:2203.12596v1 [cs.IR])
75. R3M: A Universal Visual Representation for Robot Manipulation. (arXiv:2203.12601v1 [cs.RO])
76. Optical Fiber Fault Detection and Localization in a Noisy OTDR Trace Based on Denoising Convolutional Autoencoder and Bidirectional Long Short-Term Memory. (arXiv:2203.12604v1 [eess.SP])
77. Improving the Fairness of Chest X-ray Classifiers. (arXiv:2203.12609v1 [cs.LG])
78. AI Poincar\'{e} 2.0: Machine Learning Conservation Laws from Differential Equations. (arXiv:2203.12610v1 [cs.LG])
79. Unsupervised Pre-Training on Patient Population Graphs for Patient-Level Predictions. (arXiv:2203.12616v1 [cs.LG])
80. On the Efficiency of Entropic Regularized Algorithms for Optimal Transport. (arXiv:1906.01437v8 [cs.DS] UPDATED)
81. The Unreasonable Effectiveness of Greedy Algorithms in Multi-Armed Bandit with Many Arms. (arXiv:2002.10121v3 [cs.LG] UPDATED)
82. Regret and Belief Complexity Trade-off in Gaussian Process Bandits via Information Thresholding. (arXiv:2003.10550v3 [cs.LG] UPDATED)
83. From calibration to parameter learning: Harnessing the scaling effects of big data in geoscientific modeling. (arXiv:2007.15751v6 [cs.LG] UPDATED)
84. PLAD: Learning to Infer Shape Programs with Pseudo-Labels and Approximate Distributions. (arXiv:2011.13045v4 [cs.CV] UPDATED)
85. Deep Graph Neural Networks with Shallow Subgraph Samplers. (arXiv:2012.01380v3 [cs.LG] UPDATED)
86. Synthesizing Decentralized Controllers with Graph Neural Networks and Imitation Learning. (arXiv:2012.14906v4 [cs.LG] UPDATED)
87. Improving Approximate Optimal Transport Distances using Quantization. (arXiv:2102.12731v2 [cs.LG] UPDATED)
88. Coordination Among Neural Modules Through a Shared Global Workspace. (arXiv:2103.01197v2 [cs.LG] UPDATED)
89. Neural Production Systems: Learning Rule-Governed Visual Dynamics. (arXiv:2103.01937v3 [cs.AI] UPDATED)
90. Online Adversarial Attacks. (arXiv:2103.02014v4 [cs.LG] UPDATED)
91. Encrypted Linear Contextual Bandit. (arXiv:2103.09927v2 [cs.LG] UPDATED)
92. Query Driven-Graph Neural Networks for Community Search: From Non-Attributed, Attributed, to Interactive Attributed. (arXiv:2104.03583v2 [cs.DB] UPDATED)
93. Coupling streaming AI and HPC ensembles to achieve 100-1000x faster biomolecular simulations. (arXiv:2104.04797v3 [cs.DC] UPDATED)
94. ShapeMOD: Macro Operation Discovery for 3D Shape Programs. (arXiv:2104.06392v3 [cs.GR] UPDATED)
95. Fast quantum state reconstruction via accelerated non-convex programming. (arXiv:2104.07006v4 [quant-ph] UPDATED)
96. Programmable 3D snapshot microscopy with Fourier convolutional networks. (arXiv:2104.10611v4 [eess.IV] UPDATED)
97. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v6 [cs.CV] UPDATED)
98. LGGNet: Learning from Local-Global-Graph Representations for Brain-Computer Interface. (arXiv:2105.02786v2 [cs.NE] UPDATED)
99. Online Statistical Inference for Parameters Estimation with Linear-Equality Constraints. (arXiv:2105.10315v2 [stat.ML] UPDATED)
100. Learning and Generalization in Overparameterized Normalizing Flows. (arXiv:2106.10535v2 [cs.LG] UPDATED)
101. The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape Regions with Approximate Inference. (arXiv:2106.12026v3 [cs.CV] UPDATED)
102. FastSHAP: Real-Time Shapley Value Estimation. (arXiv:2107.07436v3 [stat.ML] UPDATED)
103. Stein Variational Gradient Descent with Multiple Kernel. (arXiv:2107.09338v2 [cs.LG] UPDATED)
104. Adaptive Verifiable Coded Computing: Towards Fast, Secure and Private Distributed Machine Learning. (arXiv:2107.12958v2 [cs.DC] UPDATED)
105. Learning more skills through optimistic exploration. (arXiv:2107.14226v5 [cs.LG] UPDATED)
106. PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management. (arXiv:2108.05818v3 [cs.LG] UPDATED)
107. Private Multi-Task Learning: Formulation and Applications to Federated Learning. (arXiv:2108.12978v2 [cs.LG] UPDATED)
108. Scale-invariant representation of machine learning. (arXiv:2109.02914v2 [cs.LG] UPDATED)
109. FedIPR: Ownership Verification for Federated Deep Neural Network Models. (arXiv:2109.13236v2 [cs.LG] UPDATED)
110. UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning. (arXiv:2110.07577v2 [cs.CL] UPDATED)
111. An Empirical Survey of the Effectiveness of Debiasing Techniques for Pre-trained Language Models. (arXiv:2110.08527v2 [cs.CL] UPDATED)
112. Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation. (arXiv:2110.08727v2 [cs.LG] UPDATED)
113. Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond. (arXiv:2110.10342v2 [cs.LG] UPDATED)
114. Adjacency constraint for efficient hierarchical reinforcement learning. (arXiv:2111.00213v2 [cs.LG] UPDATED)
115. A multi-task learning-based optimization approach for finding diverse sets of material microstructures with desired properties and its application to texture optimization. (arXiv:2111.00916v3 [cond-mat.mtrl-sci] UPDATED)
116. Towards an Understanding of Default Policies in Multitask Policy Optimization. (arXiv:2111.02994v4 [cs.LG] UPDATED)
117. UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection. (arXiv:2111.08644v2 [cs.CV] UPDATED)
118. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v10 [cs.CV] UPDATED)
119. Ranking Distance Calibration for Cross-Domain Few-Shot Learning. (arXiv:2112.00260v2 [cs.CV] UPDATED)
120. Graph Neural Networks for Charged Particle Tracking on FPGAs. (arXiv:2112.02048v3 [physics.ins-det] UPDATED)
121. Learning over All Stabilizing Nonlinear Controllers for a Partially-Observed Linear System. (arXiv:2112.04219v2 [eess.SY] UPDATED)
122. FedSoft: Soft Clustered Federated Learning with Proximal Local Updating. (arXiv:2112.06053v2 [cs.LG] UPDATED)
123. Top $K$ Ranking for Multi-Armed Bandit with Noisy Evaluations. (arXiv:2112.06517v3 [cs.LG] UPDATED)
124. An overview of active learning methods for insurance with fairness appreciation. (arXiv:2112.09466v2 [stat.ML] UPDATED)
125. Watermarking Images in Self-Supervised Latent Spaces. (arXiv:2112.09581v2 [cs.CV] UPDATED)
126. Improving Subgraph Recognition with Variational Graph Information Bottleneck. (arXiv:2112.09899v2 [cs.LG] UPDATED)
127. Generalized Few-Shot Semantic Segmentation: All You Need is Fine-Tuning. (arXiv:2112.10982v2 [cs.CV] UPDATED)
128. Ensemble Recognition in Reproducing Kernel Hilbert Spaces through Aggregated Measurements. (arXiv:2112.14307v2 [cs.LG] UPDATED)
129. Planning in Observable POMDPs in Quasipolynomial Time. (arXiv:2201.04735v2 [cs.LG] UPDATED)
130. Asymptotic self-similar blow up profile for 3-D Euler via physics-informed neural networks. (arXiv:2201.06780v2 [math.AP] UPDATED)
131. Models for information propagation on graphs. (arXiv:2201.07577v2 [math.NA] UPDATED)
132. Learning Robust Convolutional Neural Networks with Relevant Feature Focusing via Explanations. (arXiv:2202.04237v2 [cs.CV] UPDATED)
133. Reduced order modeling for flow and transport problems with Barlow Twins self-supervised learning. (arXiv:2202.05460v2 [cs.CE] UPDATED)
134. Retrieval-Augmented Reinforcement Learning. (arXiv:2202.08417v3 [cs.LG] UPDATED)
135. Nemo: Guiding and Contextualizing Weak Supervision for Interactive Data Programming. (arXiv:2203.01382v2 [cs.LG] UPDATED)
136. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v3 [cs.CV] UPDATED)
137. Improving Word Translation via Two-Stage Contrastive Learning. (arXiv:2203.08307v2 [cs.CL] UPDATED)
138. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v2 [cs.CV] UPDATED)
139. Leveraging Adversarial Examples to Quantify Membership Information Leakage. (arXiv:2203.09566v2 [cs.LG] UPDATED)
140. A Study on Robustness to Perturbations for Representations of Environmental Sound. (arXiv:2203.10425v2 [cs.SD] UPDATED)
141. No Pain, Big Gain: Classify Dynamic Point Cloud Sequences with Static Models by Fitting Feature-level Space-time Surfaces. (arXiv:2203.11113v2 [cs.CV] UPDATED)
142. Root-aligned SMILES for Molecular Retrosynthesis Prediction. (arXiv:2203.11444v2 [cs.LG] UPDATED)
143. Out-of-distribution Generalization with Causal Invariant Transformations. (arXiv:2203.11528v2 [stat.ML] UPDATED)
## cs.AI
---
**84** new papers in cs.AI:-) 
1. Maximum Entropy of Random Permutation Set. (arXiv:2203.11941v1 [cs.IT])
2. A Factor-Based Framework for Decision-Making Competency Self-Assessment. (arXiv:2203.11981v1 [cs.AI])
3. Generative Modeling Helps Weak Supervision (and Vice Versa). (arXiv:2203.12023v1 [cs.LG])
4. Machine Learning Testing in an ADAS Case Study Using Simulation-Integrated Bio-Inspired Search-Based Testing. (arXiv:2203.12026v1 [cs.SE])
5. Review of Metrics to Measure the Stability, Robustness and Resilience of Reinforcement Learning. (arXiv:2203.12048v1 [cs.LG])
6. Self-supervision through Random Segments with Autoregressive Coding (RandSAC). (arXiv:2203.12054v1 [cs.CV])
7. A Unified Substrate for Body-Brain Co-evolution. (arXiv:2203.12066v1 [cs.RO])
8. WayFAST: Traversability Predictive Navigation for Field Robots. (arXiv:2203.12071v1 [cs.RO])
9. A hybrid quantum image edge detector for the NISQ era. (arXiv:2203.12072v1 [quant-ph])
10. DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification. (arXiv:2203.12081v1 [cs.CV])
11. FxP-QNet: A Post-Training Quantizer for the Design of Mixed Low-Precision DNNs with Dynamic Fixed-Point Representation. (arXiv:2203.12091v1 [cs.NE])
12. Music Generation Using an LSTM. (arXiv:2203.12105v1 [cs.SD])
13. An Empirical Study on Learning and Improving the Search Objective for Unsupervised Paraphrasing. (arXiv:2203.12106v1 [cs.CL])
14. Muscle Vision: Real Time Keypoint Based Pose Classification of Physical Exercises. (arXiv:2203.12111v1 [cs.AI])
15. Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer Tissue Biopsy Samples. (arXiv:2203.12112v1 [cs.AI])
16. NovGrid: A Flexible Grid World for Evaluating Agent Response to Novelty. (arXiv:2203.12117v1 [cs.AI])
17. Approximate Inference for Stochastic Planning in Factored Spaces. (arXiv:2203.12139v1 [cs.AI])
18. Semi-Supervised Hybrid Spine Network for Segmentation of Spine MR Images. (arXiv:2203.12151v1 [cs.CV])
19. Converse - A Tree-Based Modular Task-Oriented Dialogue System. (arXiv:2203.12187v1 [cs.CL])
20. FullSubNet+: Channel Attention FullSubNet with Complex Spectrograms for Speech **Enhancement**. (arXiv:2203.12188v1 [cs.SD])
21. Privacy-Preserving Personalized Fitness Recommender System (P3FitRec): A Multi-level Deep Learning Approach. (arXiv:2203.12200v1 [cs.AI])
22. Efficient Few-Shot Object Detection via Knowledge Inheritance. (arXiv:2203.12224v1 [cs.CV])
23. Negative Selection by Clustering for Contrastive Learning in Human Activity Recognition. (arXiv:2203.12230v1 [cs.CV])
24. A Method of Data Augmentation to Train a Small Area Fingerprint Recognition Deep Neural Network with a Normal Fingerprint Database. (arXiv:2203.12241v1 [cs.CV])
25. Scale-Equivalent Distillation for Semi-Supervised Object Detection. (arXiv:2203.12244v1 [cs.CV])
26. Certified Symmetry and Dominance Breaking for Combinatorial Optimisation (Including Appendices). (arXiv:2203.12275v1 [cs.AI])
27. Mining Latent Relationships among Clients: Peer-to-peer Federated Learning with Adaptive Neighbor Matching. (arXiv:2203.12285v1 [cs.AI])
28. Resource allocation optimization using artificial intelligence methods in various computing paradigms: A Review. (arXiv:2203.12315v1 [cs.AI])
29. Trust and Reliance in XAI - Distinguishing Between Attitudinal and Behavioral Measures. (arXiv:2203.12318v1 [cs.HC])
30. An Extensible Logic Embedding Tool for Lightweight Non-Classical Reasoning. (arXiv:2203.12352v1 [cs.AI])
31. MONAI Label: A framework for AI-assisted Interactive Labeling of 3D Medical Images. (arXiv:2203.12362v1 [cs.AI])
32. A Blueprint for Four-states Quantum Formal System. (arXiv:2203.12385v1 [cs.FL])
33. U-Boost NAS: Utilization-Boosted Differentiable Neural Architecture Search. (arXiv:2203.12412v1 [cs.LG])
34. Collaborative Self Organizing Map with DeepNNs for Fake Task Prevention in Mobile Crowdsensing. (arXiv:2203.12434v1 [cs.NE])
35. M-SENA: An Integrated Platform for Multimodal Sentiment Analysis. (arXiv:2203.12441v1 [cs.AI])
36. MT-UDA: Towards Unsupervised Cross-modality Medical Image Segmentation with Limited Source Labels. (arXiv:2203.12454v1 [cs.CV])
37. Planning Landscape Analysis for Self-Adaptive Systems. (arXiv:2203.12472v1 [cs.SE])
38. A Deep Learning Framework to Reconstruct Face under Mask. (arXiv:2203.12482v1 [cs.CV])
39. An Algorithmic Introduction to Savings Circles. (arXiv:2203.12486v1 [cs.GT])
40. An Example of the SAM+ Algorithm for Learning Action Models for Stochastic Worlds. (arXiv:2203.12499v1 [cs.AI])
41. A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v1 [cs.LG])
42. A Survey on Cross-Lingual Summarization. (arXiv:2203.12515v1 [cs.CL])
43. Exact methods and lower bounds for the Oven Scheduling Problem. (arXiv:2203.12517v1 [cs.AI])
44. Semi-Supervised Graph Learning Meets Dimensionality Reduction. (arXiv:2203.12522v1 [cs.LG])
45. Socially Fair Mitigation of Misinformation on Social Networks via Constraint Stochastic Optimization. (arXiv:2203.12537v1 [cs.SI])
46. Constrained Clustering and Multiple Kernel Learning without Pairwise Constraint Relaxation. (arXiv:2203.12546v1 [cs.LG])
47. TransSleep: Transitioning-aware Attention-based Deep Neural Network for Sleep Staging. (arXiv:2203.12590v1 [cs.LG])
48. Web Page Content Extraction Based on Multi-feature Fusion. (arXiv:2203.12591v1 [cs.IR])
49. Semantic Similarity Computing for Scientific Academic Conferences fused with domain features. (arXiv:2203.12593v1 [cs.IR])
50. ZOOMER: Boosting Retrieval on Web-scale Graphs by Regions of Interest. (arXiv:2203.12596v1 [cs.IR])
51. Learning Personalized Item-to-Item Recommendation Metric via Implicit Feedback. (arXiv:2203.12598v1 [cs.IR])
52. R3M: A Universal Visual Representation for Robot Manipulation. (arXiv:2203.12601v1 [cs.RO])
53. Rationally Biased Learning. (arXiv:1709.02256v3 [cs.AI] UPDATED)
54. On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited. (arXiv:2003.05597v4 [cs.CV] UPDATED)
55. Relational Dynamic Bayesian Network Modeling for Uncertainty Quantification and Propagation in Airline Disruption Management. (arXiv:2102.05147v3 [cs.AI] UPDATED)
56. Coordination Among Neural Modules Through a Shared Global Workspace. (arXiv:2103.01197v2 [cs.LG] UPDATED)
57. Neural Production Systems: Learning Rule-Governed Visual Dynamics. (arXiv:2103.01937v3 [cs.AI] UPDATED)
58. Meta-Learning for Fast Cross-Lingual Adaptation in Dependency Parsing. (arXiv:2104.04736v3 [cs.CL] UPDATED)
59. SQN: Weakly-Supervised Semantic Segmentation of Large-Scale 3D Point Clouds. (arXiv:2104.04891v2 [cs.CV] UPDATED)
60. ShapeMOD: Macro Operation Discovery for 3D Shape Programs. (arXiv:2104.06392v3 [cs.GR] UPDATED)
61. Learning and Generalization in Overparameterized Normalizing Flows. (arXiv:2106.10535v2 [cs.LG] UPDATED)
62. The Neurally-Guided Shape Parser: Grammar-based Labeling of 3D Shape Regions with Approximate Inference. (arXiv:2106.12026v3 [cs.CV] UPDATED)
63. Learning more skills through optimistic exploration. (arXiv:2107.14226v5 [cs.LG] UPDATED)
64. From Statistical Relational to Neural Symbolic Artificial Intelligence: a Survey. (arXiv:2108.11451v2 [cs.AI] UPDATED)
65. Convolutional Neural Networks Demystified: A Matched Filtering Perspective Based Tutorial. (arXiv:2108.11663v3 [cs.IT] UPDATED)
66. Generalized dynamic cognitive hierarchy models for strategic driving behavior. (arXiv:2109.09861v2 [cs.AI] UPDATED)
67. FedIPR: Ownership Verification for Federated Deep Neural Network Models. (arXiv:2109.13236v2 [cs.LG] UPDATED)
68. UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning. (arXiv:2110.07577v2 [cs.CL] UPDATED)
69. Graph-less Neural Networks: Teaching Old MLPs New Tricks via Distillation. (arXiv:2110.08727v2 [cs.LG] UPDATED)
70. Big Data Testing Techniques: Taxonomy, Challenges and Future Trends. (arXiv:2111.02853v2 [cs.AI] UPDATED)
71. Triples-to-Text Generation with Reinforcement Learning Based Graph-augmented Neural Networks. (arXiv:2111.10545v3 [cs.CL] UPDATED)
72. QMagFace: Simple and Accurate Quality-Aware Face Recognition. (arXiv:2111.13475v3 [cs.CV] UPDATED)
73. Bootstrapping ViTs: Towards Liberating Vision Transformers from Pre-training. (arXiv:2112.03552v3 [cs.CV] UPDATED)
74. Improving Subgraph Recognition with Variational Graph Information Bottleneck. (arXiv:2112.09899v2 [cs.LG] UPDATED)
75. Learning Robust Convolutional Neural Networks with Relevant Feature Focusing via Explanations. (arXiv:2202.04237v2 [cs.CV] UPDATED)
76. Ditto: Building Digital Twins of Articulated Objects from Interaction. (arXiv:2202.08227v2 [cs.CV] UPDATED)
77. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v4 [cs.CV] UPDATED)
78. Improving Word Translation via Two-Stage Contrastive Learning. (arXiv:2203.08307v2 [cs.CL] UPDATED)
79. Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework. (arXiv:2203.09053v2 [cs.CL] UPDATED)
80. One-Shot Adaptation of GAN in Just One CLIP. (arXiv:2203.09301v2 [cs.CV] UPDATED)
81. A Study on Robustness to Perturbations for Representations of Environmental Sound. (arXiv:2203.10425v2 [cs.SD] UPDATED)
82. Unidirectional Thin Adapter for Efficient Adaptation of Deep Neural Networks. (arXiv:2203.10463v2 [cs.CV] UPDATED)
83. Integrity Fingerprinting of DNN with Double Black-box Design and Verification. (arXiv:2203.10902v2 [cs.CR] UPDATED)
84. No Pain, Big Gain: Classify Dynamic Point Cloud Sequences with Static Models by Fitting Feature-level Space-time Surfaces. (arXiv:2203.11113v2 [cs.CV] UPDATED)

