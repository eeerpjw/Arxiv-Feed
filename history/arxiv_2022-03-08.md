# Your interest papers
---
## cs.CV
---
### Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images. (arXiv:2203.02571v1 [eess.IV])
- Authors : Qianyun Lu, Boris Murmann
- Link : [http://arxiv.org/abs/2203.02571](http://arxiv.org/abs/2203.02571)
> ABSTRACT  :  This paper studies the merits of applying log-gradient input images to convolutional neural networks (CNNs) for tinyML computer vision (CV). We show that log gradients enable: (i) aggressive 1.5-bit quantization of first-layer inputs, (ii) potential CNN resource reductions, and (iii) inherent robustness to illumination changes (1.7% accuracy loss across 1/32...8 brightness variation vs. up to 10% for JPEG). We establish these results using the PASCAL RAW image data set and through a combination of experiments using neural architecture search and a fixed three-layer network. The latter reveal that training on log-gradient images leads to higher filter similarity, making the CNN more prunable. The combined benefits of aggressive first-layer quantization, CNN resource reductions, and operation without tight **exposure** control and image signal processing (ISP) are helpful for pushing tinyML CV toward its ultimate efficiency limits.  
### Newton-PnP: **Real-time** Visual Navigation for Autonomous Toy-Drones. (arXiv:2203.02686v1 [cs.CV])
- Authors : Ibrahim Jubran, Fares Fares, Yuval Alfassi, Firas Ayoub, Dan Feldman
- Link : [http://arxiv.org/abs/2203.02686](http://arxiv.org/abs/2203.02686)
> ABSTRACT  :  The Perspective-n-Point problem aims to estimate the relative pose between a calibrated monocular camera and a known 3D model, by aligning pairs of 2D captured image points to their corresponding 3D points in the model. We suggest an algorithm that runs on weak IoT devices in real-time but still provides provable theoretical guarantees for both running time and correctness. Existing solvers provide only one of these requirements. Our main motivation was to turn the popular DJI's Tello Drone (&lt;90gr, &lt;\$100) into an autonomous drone that navigates in an indoor environment with no external human/laptop/sensor, by simply attaching a Raspberry PI Zero (&lt;9gr, &lt;\$25) to it. This tiny micro-processor takes as input a real-time video from a tiny RGB camera, and runs our PnP solver on-board. Extensive experimental results, open source code, and a demonstration video are included.  
### Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
- Authors : Perla Mayo, Nantheera Anantrasirichai, Duangdao Palasuwan, Alin Achim
- Link : [http://arxiv.org/abs/2203.02940](http://arxiv.org/abs/2203.02940)
> ABSTRACT  :  Automatic detection of parasitic eggs in microscopy images has the potential to increase the efficiency of human experts whilst also providing an objective assessment. The time saved by such a process would both help ensure a prompt treatment to patients, and off-load excessive work from experts' shoulders. Advances in deep learning inspired us to exploit successful architectures for detection, adapting them to tackle a different domain. We propose a framework that exploits two such state-of-the-art models. Specifically, we demonstrate results produced by both a Generative Adversarial Network (GAN) and Faster-RCNN, for image **enhancement** and object detection respectively, on microscopy images of varying quality. The use of these techniques yields encouraging results, though further improvements are still needed for certain egg types whose detection still proves challenging. As a result, a new dataset has been created and made publicly available, providing an even wider range of classes and variability.  
### Semantic-Aware Latent Space Exploration for Face Image **Restoration**. (arXiv:2203.03005v1 [cs.CV])
- Authors : Yanhui Guo, Fangzhou Luo, Xiaolin Wu
- Link : [http://arxiv.org/abs/2203.03005](http://arxiv.org/abs/2203.03005)
> ABSTRACT  :  For image **restoration**, most existing deep learning based methods tend to overfit the training data leading to bad results when encountering unseen degradations out of the assumptions for training. To improve the robustness, generative adversarial network (GAN) prior based methods have been proposed, revealing a promising capability to restore photo-realistic and high-quality results. But these methods suffer from semantic confusion, especially on semantically significant images such as face images. In this paper, we propose a semantic-aware latent space exploration method for image **restoration** (SAIR). By explicitly modeling referenced semantics information, SAIR can consistently restore severely degraded images not only to high-resolution highly-realistic looks but also to correct semantics. Quantitative and qualitative experiments collectively demonstrate the effectiveness of the proposed SAIR. Our code can be found in https://github.com/Liamkuo/SAIR.  
### Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v1 [cs.CV])
- Authors : Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, Christian Claudel
- Link : [http://arxiv.org/abs/2203.03057](http://arxiv.org/abs/2203.03057)
> ABSTRACT  :  Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in **real time** of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen here \url{https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo}. Code is available at \url{https://github.com/abduallahmohamed/Social-Implicit}.  
### Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
- Authors : Fakrul Islam, Ehsan Abadi, Saman Sotoudeh, Paul Segars, Ehsan Samei
- Link : [http://arxiv.org/abs/2203.03074](http://arxiv.org/abs/2203.03074)
> ABSTRACT  :  Research studies of artificial intelligence models in medical imaging have been hampered by poor generalization. This problem has been especially concerning over the last year with numerous applications of deep learning for COVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for objective evaluation of these models. In this work utilizing the VITs, we created the CVIT-COVID dataset including 180 virtually imaged computed tomography (CT) images from simulated COVID-19 and normal phantom models under different COVID-19 morphology and imaging properties. We evaluated the performance of an open-source, deep-learning model from the University of Waterloo trained with multi-institutional data and an in-house model trained with the open clinical dataset called MosMed. We further validated the model's performance against open clinical data of 305 CT images to understand virtual vs. real clinical data performance. The open-source model was published with nearly perfect performance on the original Waterloo dataset but showed a consistent performance drop in external testing on another clinical dataset (AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model achieved an AUC of 0.87 while testing on the internal test set (MosMed test set). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on clinical and our simulated CVIT-COVID dataset. The VIT framework offered control over imaging conditions, allowing us to show there was no change in performance as CT **exposure** was changed from 28.5 to 57 mAs. The VIT framework also provided voxel-level ground truth, revealing that performance of in-house model was much higher at AUC=0.87 for diffuse COVID-19 infection size &gt;2.65% lung volume versus AUC=0.52 for focal disease with &lt;2.65% volume. The virtual imaging framework enabled these uniquely rigorous analyses of model performance.  
### Behavior Recognition Based on the Integration of Multigranular Motion Features. (arXiv:2203.03097v1 [cs.CV])
- Authors : Lizong Zhang, Yiming Wang, Bei Hui, Xiujian Zhang, Sijuan Liu, Shuxin Feng
- Link : [http://arxiv.org/abs/2203.03097](http://arxiv.org/abs/2203.03097)
> ABSTRACT  :  The recognition of behaviors in videos usually requires a combinatorial analysis of the spatial information about objects and their dynamic action information in the temporal dimension. Specifically, behavior recognition may even rely more on the modeling of temporal information containing short-range and long-range motions; this contrasts with computer vision tasks involving images that focus on the understanding of spatial information. However, current solutions fail to jointly and comprehensively analyze short-range motion between adjacent frames and long-range temporal aggregations at large scales in videos. In this paper, we propose a novel behavior recognition method based on the integration of multigranular (IMG) motion features. In particular, we achieve reliable motion information modeling through the synergy of a channel attention-based short-term motion feature **enhancement** module (CMEM) and a cascaded long-term motion feature integration module (CLIM). We evaluate our model on several action recognition benchmarks such as HMDB51, Something-Something and UCF101. The experimental results demonstrate that our approach outperforms the previous state-of-the-art methods, which confirms its effectiveness and efficiency.  
### Geometry **Enhancement**s from Visual Content: Going Beyond Ground Truth. (arXiv:2012.08248v3 [cs.CV] UPDATED)
- Authors : Liran Azaria, Dan Raviv
- Link : [http://arxiv.org/abs/2012.08248](http://arxiv.org/abs/2012.08248)
> ABSTRACT  :  This work presents a new cyclic architecture that extracts high-frequency patterns from images and re-insert them as geometric features. This procedure allows us to enhance the resolution of low-cost depth sensors capturing fine details on the one hand and being loyal to the scanned ground truth on the other. We present state-of-the-art results for depth super-resolution tasks and as well as visually attractive, enhanced generated 3D models.  
### FBSNet: A Fast **Bilateral** Symmetrical Network for Real-Time Semantic Segmentation. (arXiv:2109.00699v3 [cs.CV] UPDATED)
- Authors : Guangwei Gao, Guoan Xu, Juncheng Li, Yi Yu, Huimin Lu, Jian Yang
- Link : [http://arxiv.org/abs/2109.00699](http://arxiv.org/abs/2109.00699)
> ABSTRACT  :  **Real-time** semantic segmentation, which can be visually understood as the pixel-level classification task on the input image, currently has broad application prospects, especially in the fast-developing fields of autonomous driving and drone navigation. However, the huge burden of calculation together with redundant parameters are still the obstacles to its technological development. In this paper, we propose a Fast **Bilateral** Symmetrical Network (FBSNet) to alleviate the above challenges. Specifically, FBSNet employs a symmetrical encoder-decoder structure with two branches, semantic information branch and spatial detail branch. The Semantic Information Branch (SIB) is the main branch with semantic architecture to acquire the contextual information of the input image and meanwhile acquire sufficient receptive field. While the Spatial Detail Branch (SDB) is a shallow and simple network used to establish local dependencies of each pixel for preserving details, which is essential for restoring the original resolution during the decoding phase. Meanwhile, a Feature Aggregation Module (FAM) is designed to effectively combine the output of these two branches. Experimental results of Cityscapes and CamVid show that the proposed FBSNet can strike a good balance between accuracy and efficiency. Specifically, it obtains 70.9\% and 68.9\% mIoU along with the inference speed of 90 fps and 120 fps on these two test datasets, respectively, with only 0.62 million parameters on a single RTX 2080Ti GPU. The code is available at https://github.com/IVIPLab/FBSNet.  
### Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v2 [cs.CV] UPDATED)
- Authors : Penglei Gao, Xi Yang, Rui Zhang, Kaizhu Huang, Yujie Geng
- Link : [http://arxiv.org/abs/2201.11403](http://arxiv.org/abs/2201.11403)
> ABSTRACT  :  While most present image outpainting conducts horizontal extrapolation, we study the generalised image outpainting problem that extrapolates visual context all-side around a given image. To this end, we develop a novel transformer-based generative adversarial network called U-Transformer able to extend image borders with plausible structure and details even for complicated scenery images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular **Swin** Transformer blocks. As such, our novel framework can better cope with image long-range dependencies which are crucially important for generalised image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor network to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.  
## eess.IV
---
### Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images. (arXiv:2203.02571v1 [eess.IV])
- Authors : Qianyun Lu, Boris Murmann
- Link : [http://arxiv.org/abs/2203.02571](http://arxiv.org/abs/2203.02571)
> ABSTRACT  :  This paper studies the merits of applying log-gradient input images to convolutional neural networks (CNNs) for tinyML computer vision (CV). We show that log gradients enable: (i) aggressive 1.5-bit quantization of first-layer inputs, (ii) potential CNN resource reductions, and (iii) inherent robustness to illumination changes (1.7% accuracy loss across 1/32...8 brightness variation vs. up to 10% for JPEG). We establish these results using the PASCAL RAW image data set and through a combination of experiments using neural architecture search and a fixed three-layer network. The latter reveal that training on log-gradient images leads to higher filter similarity, making the CNN more prunable. The combined benefits of aggressive first-layer quantization, CNN resource reductions, and operation without tight **exposure** control and image signal processing (ISP) are helpful for pushing tinyML CV toward its ultimate efficiency limits.  
### Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
- Authors : Perla Mayo, Nantheera Anantrasirichai, Duangdao Palasuwan, Alin Achim
- Link : [http://arxiv.org/abs/2203.02940](http://arxiv.org/abs/2203.02940)
> ABSTRACT  :  Automatic detection of parasitic eggs in microscopy images has the potential to increase the efficiency of human experts whilst also providing an objective assessment. The time saved by such a process would both help ensure a prompt treatment to patients, and off-load excessive work from experts' shoulders. Advances in deep learning inspired us to exploit successful architectures for detection, adapting them to tackle a different domain. We propose a framework that exploits two such state-of-the-art models. Specifically, we demonstrate results produced by both a Generative Adversarial Network (GAN) and Faster-RCNN, for image **enhancement** and object detection respectively, on microscopy images of varying quality. The use of these techniques yields encouraging results, though further improvements are still needed for certain egg types whose detection still proves challenging. As a result, a new dataset has been created and made publicly available, providing an even wider range of classes and variability.  
### Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
- Authors : Fakrul Islam, Ehsan Abadi, Saman Sotoudeh, Paul Segars, Ehsan Samei
- Link : [http://arxiv.org/abs/2203.03074](http://arxiv.org/abs/2203.03074)
> ABSTRACT  :  Research studies of artificial intelligence models in medical imaging have been hampered by poor generalization. This problem has been especially concerning over the last year with numerous applications of deep learning for COVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for objective evaluation of these models. In this work utilizing the VITs, we created the CVIT-COVID dataset including 180 virtually imaged computed tomography (CT) images from simulated COVID-19 and normal phantom models under different COVID-19 morphology and imaging properties. We evaluated the performance of an open-source, deep-learning model from the University of Waterloo trained with multi-institutional data and an in-house model trained with the open clinical dataset called MosMed. We further validated the model's performance against open clinical data of 305 CT images to understand virtual vs. real clinical data performance. The open-source model was published with nearly perfect performance on the original Waterloo dataset but showed a consistent performance drop in external testing on another clinical dataset (AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model achieved an AUC of 0.87 while testing on the internal test set (MosMed test set). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on clinical and our simulated CVIT-COVID dataset. The VIT framework offered control over imaging conditions, allowing us to show there was no change in performance as CT **exposure** was changed from 28.5 to 57 mAs. The VIT framework also provided voxel-level ground truth, revealing that performance of in-house model was much higher at AUC=0.87 for diffuse COVID-19 infection size &gt;2.65% lung volume versus AUC=0.52 for focal disease with &lt;2.65% volume. The virtual imaging framework enabled these uniquely rigorous analyses of model performance.  
## cs.LG
---
### Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
- Authors : Perla Mayo, Nantheera Anantrasirichai, Duangdao Palasuwan, Alin Achim
- Link : [http://arxiv.org/abs/2203.02940](http://arxiv.org/abs/2203.02940)
> ABSTRACT  :  Automatic detection of parasitic eggs in microscopy images has the potential to increase the efficiency of human experts whilst also providing an objective assessment. The time saved by such a process would both help ensure a prompt treatment to patients, and off-load excessive work from experts' shoulders. Advances in deep learning inspired us to exploit successful architectures for detection, adapting them to tackle a different domain. We propose a framework that exploits two such state-of-the-art models. Specifically, we demonstrate results produced by both a Generative Adversarial Network (GAN) and Faster-RCNN, for image **enhancement** and object detection respectively, on microscopy images of varying quality. The use of these techniques yields encouraging results, though further improvements are still needed for certain egg types whose detection still proves challenging. As a result, a new dataset has been created and made publicly available, providing an even wider range of classes and variability.  
### Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v1 [cs.CV])
- Authors : Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, Christian Claudel
- Link : [http://arxiv.org/abs/2203.03057](http://arxiv.org/abs/2203.03057)
> ABSTRACT  :  Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in **real time** of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen here \url{https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo}. Code is available at \url{https://github.com/abduallahmohamed/Social-Implicit}.  
### Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
- Authors : Fakrul Islam, Ehsan Abadi, Saman Sotoudeh, Paul Segars, Ehsan Samei
- Link : [http://arxiv.org/abs/2203.03074](http://arxiv.org/abs/2203.03074)
> ABSTRACT  :  Research studies of artificial intelligence models in medical imaging have been hampered by poor generalization. This problem has been especially concerning over the last year with numerous applications of deep learning for COVID-19 diagnosis. Virtual imaging trials (VITs) could provide a solution for objective evaluation of these models. In this work utilizing the VITs, we created the CVIT-COVID dataset including 180 virtually imaged computed tomography (CT) images from simulated COVID-19 and normal phantom models under different COVID-19 morphology and imaging properties. We evaluated the performance of an open-source, deep-learning model from the University of Waterloo trained with multi-institutional data and an in-house model trained with the open clinical dataset called MosMed. We further validated the model's performance against open clinical data of 305 CT images to understand virtual vs. real clinical data performance. The open-source model was published with nearly perfect performance on the original Waterloo dataset but showed a consistent performance drop in external testing on another clinical dataset (AUC=0.77) and our simulated CVIT-COVID dataset (AUC=0.55). The in-house model achieved an AUC of 0.87 while testing on the internal test set (MosMed test set). However, performance dropped to an AUC of 0.65 and 0.69 when evaluated on clinical and our simulated CVIT-COVID dataset. The VIT framework offered control over imaging conditions, allowing us to show there was no change in performance as CT **exposure** was changed from 28.5 to 57 mAs. The VIT framework also provided voxel-level ground truth, revealing that performance of in-house model was much higher at AUC=0.87 for diffuse COVID-19 infection size &gt;2.65% lung volume versus AUC=0.52 for focal disease with &lt;2.65% volume. The virtual imaging framework enabled these uniquely rigorous analyses of model performance.  
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v6 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
### Generative Modeling with Optimal Transport Maps. (arXiv:2110.02999v2 [cs.LG] UPDATED)
- Authors : Litu Rout, Alexander Korotin, Evgeny Burnaev
- Link : [http://arxiv.org/abs/2110.02999](http://arxiv.org/abs/2110.02999)
> ABSTRACT  :  With the discovery of Wasserstein GANs, Optimal Transport (OT) has become a powerful tool for large-scale generative modeling tasks. In these tasks, OT cost is typically used as the loss for training GANs. In contrast to this approach, we show that the OT map itself can be used as a generative model, providing comparable performance. Previous analogous approaches consider OT maps as generative models only in the latent spaces due to their poor performance in the original high-dimensional ambient space. In contrast, we apply OT maps directly in the ambient space, e.g., a space of high-dimensional images. First, we derive a min-max optimization algorithm to efficiently compute OT maps for the quadratic cost (Wasserstein-2 distance). Next, we extend the approach to the case when the input and output distributions are located in the spaces of different dimensions and derive error bounds for the computed OT map. We evaluate the algorithm on image generation and unpaired image **restoration** tasks. In particular, we consider denoising, colorization, and inpainting, where the optimality of the **restoration** map is a desired attribute, since the output (restored) image is expected to be close to the input (degraded) one.  
## cs.AI
---
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v6 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
# Paper List
---
## cs.CV
---
**136** new papers in cs.CV:-) 
1. ARM 4-BIT PQ: SIMD-based Acceleration for Approximate Nearest Neighbor Search on ARM. (arXiv:2203.02505v1 [cs.LG])
2. Cellular Segmentation and Composition in Routine Histology Images using Deep Learning. (arXiv:2203.02510v1 [q-bio.QM])
3. BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation. (arXiv:2203.02533v1 [eess.IV])
4. Structured Pruning is All You Need for Pruning CNNs at Initialization. (arXiv:2203.02549v1 [cs.CV])
5. Building 3D Generative Models from Minimal Data. (arXiv:2203.02554v1 [cs.CV])
6. UVCGAN: UNet Vision Transformer cycle-consistent GAN for unpaired image-to-image translation. (arXiv:2203.02557v1 [cs.CV])
7. Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images. (arXiv:2203.02571v1 [eess.IV])
8. Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning. (arXiv:2203.02573v1 [cs.CV])
9. Style-ERD: Responsive and Coherent Online Motion Style Transfer. (arXiv:2203.02574v1 [cs.CV])
10. Online Learning of Reusable Abstract Models for Object Goal Navigation. (arXiv:2203.02583v1 [cs.CV])
11. Concept-based Explanations for Out-Of-Distribution Detectors. (arXiv:2203.02586v1 [cs.LG])
12. A Quality Index Metric and Method for Online Self-Assessment of Autonomous Vehicles Sensory Perception. (arXiv:2203.02588v1 [cs.CV])
13. Geodesic Gramian Denoising Applied to the Images Contaminated With Noise Sampled From Diverse Probability Distributions. (arXiv:2203.02600v1 [eess.IV])
14. Plant Species Recognition with Optimized 3D Polynomial Neural Networks and Variably Overlapping Time-Coherent Sliding Window. (arXiv:2203.02611v1 [cs.CV])
15. How to Train Unstable Looped Tensor Network. (arXiv:2203.02617v1 [cs.LG])
16. Important Object Identification with Semi-Supervised Learning for Autonomous Driving. (arXiv:2203.02634v1 [cs.CV])
17. Training privacy-preserving video analytics pipelines by suppressing features that reveal information about private attributes. (arXiv:2203.02635v1 [cs.CV])
18. Boosting Crowd Counting via Multifaceted Attention. (arXiv:2203.02636v1 [cs.CV])
19. Cluster-based Contrastive Disentangling for Generalized Zero-Shot Learning. (arXiv:2203.02648v1 [cs.CV])
20. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v1 [cs.LG])
21. A Large-scale Comprehensive Dataset and Copy-overlap Aware Evaluation Protocol for Segment-level Video Copy Detection. (arXiv:2203.02654v1 [cs.CV])
22. Audio-visual speech separation based on joint feature representation with cross-modal attention. (arXiv:2203.02655v1 [cs.SD])
23. Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers. (arXiv:2203.02664v1 [cs.CV])
24. Cross Language Image Matching for Weakly Supervised Semantic Segmentation. (arXiv:2203.02668v1 [cs.CV])
25. Newton-PnP: **Real-time** Visual Navigation for Autonomous Toy-Drones. (arXiv:2203.02686v1 [cs.CV])
26. Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection. (arXiv:2203.02688v1 [cs.CV])
27. Federated and Generalized Person Re-identification through Domain and Feature Hallucinating. (arXiv:2203.02689v1 [cs.CV])
28. IDmUNet: A new image decomposition induced network for sparse feature segmentation. (arXiv:2203.02690v1 [eess.IV])
29. High-resolution Coastline Extraction in SAR Images via MISP-GGD Superpixel Segmentation. (arXiv:2203.02708v1 [eess.IV])
30. Towards Efficient and Scalable Sharpness-Aware Minimization. (arXiv:2203.02714v1 [cs.LG])
31. A Novel Dual Dense Connection Network for Video Super-resolution. (arXiv:2203.02723v1 [eess.IV])
32. An End-to-End Approach for Seam Carving Detection using Deep Neural Networks. (arXiv:2203.02728v1 [cs.CV])
33. MaxDropoutV2: An Improved Method to Drop out Neurons in Convolutional Neural Networks. (arXiv:2203.02740v1 [cs.LG])
34. MetaFormer: A Unified Meta Framework for Fine-Grained Recognition. (arXiv:2203.02751v1 [cs.CV])
35. DrawingInStyles: Portrait Image Generation and Editing with Spatially Conditioned StyleGAN. (arXiv:2203.02762v1 [cs.GR])
36. Bridging the Gap Between Learning in Discrete and Continuous Environments for Vision-and-Language Navigation. (arXiv:2203.02764v1 [cs.CV])
37. Towards Robust Part-aware Instance Segmentation for Industrial Bin Picking. (arXiv:2203.02767v1 [cs.CV])
38. Don't Be So Dense: Sparse-to-Sparse GAN Training Without Sacrificing Performance. (arXiv:2203.02770v1 [cs.CV])
39. Rib Suppression in Digital Chest Tomosynthesis. (arXiv:2203.02772v1 [eess.IV])
40. Adversarial Dual-Student with Differentiable Spatial Warping for Semi-Supervised Semantic Segmentation. (arXiv:2203.02792v1 [cs.CV])
41. Machine Learning Applications in Diagnosis, Treatment and Prognosis of Lung Cancer. (arXiv:2203.02794v1 [cs.LG])
42. Evaluation of Dirichlet Process Gaussian Mixtures for Segmentation on Noisy Hyperspectral Images. (arXiv:2203.02820v1 [cs.CV])
43. Region Proposal Rectification Towards Robust Instance Segmentation of Biological Images. (arXiv:2203.02846v1 [cs.CV])
44. Towards Self-Supervised Category-Level Object Pose and Size Estimation. (arXiv:2203.02884v1 [cs.CV])
45. Multi-class Token Transformer for Weakly Supervised Semantic Segmentation. (arXiv:2203.02891v1 [cs.CV])
46. A Robust Framework of Chromosome Straightening with ViT-Patch GAN. (arXiv:2203.02901v1 [cs.CV])
47. Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation. (arXiv:2203.02909v1 [cs.CV])
48. Exploring Dual-task Correlation for Pose Guided Person Image Generation. (arXiv:2203.02910v1 [cs.CV])
49. PanFormer: a Transformer Based Model for Pan-sharpening. (arXiv:2203.02916v1 [cs.CV])
50. Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation. (arXiv:2203.02925v1 [cs.CV])
51. Evaluation of Interpretability Methods and Perturbation Artifacts in Deep Neural Networks. (arXiv:2203.02928v1 [cs.LG])
52. Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
53. On Steering Multi-Annotations per Sample for Multi-Task Learning. (arXiv:2203.02946v1 [cs.CV])
54. Precise Point Spread Function Estimation. (arXiv:2203.02953v1 [cs.CV])
55. A Perspective on Robotic Telepresence and Teleoperation using Cognition: Are we there yet?. (arXiv:2203.02959v1 [cs.RO])
56. Exploring Optical-Flow-Guided Motion and Detection-Based Appearance for Temporal Sentence Grounding. (arXiv:2203.02966v1 [cs.CV])
57. Dynamic Key-value Memory Enhanced Multi-step Graph Reasoning for Knowledge-based Visual Question Answering. (arXiv:2203.02985v1 [cs.CV])
58. Modeling Coreference Relations in Visual Dialog. (arXiv:2203.02986v1 [cs.CV])
59. Semantic-Aware Latent Space Exploration for Face Image **Restoration**. (arXiv:2203.03005v1 [cs.CV])
60. Learnable Irrelevant Modality Dropout for Multimodal Action Recognition on Modality-Specific Annotated Videos. (arXiv:2203.03014v1 [cs.CV])
61. Highly Accurate Dichotomous Image Segmentation. (arXiv:2203.03041v1 [cs.CV])
62. Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v1 [cs.CV])
63. Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
64. GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction. (arXiv:2203.03079v1 [cs.CV])
65. HAR-GCNN: Deep Graph CNNs for Human Activity Recognition From Highly Unlabeled Mobile Sensor Data. (arXiv:2203.03087v1 [cs.CV])
66. CPPF: Towards Robust Category-Level 9D Pose Estimation in the Wild. (arXiv:2203.03089v1 [cs.CV])
67. Behavior Recognition Based on the Integration of Multigranular Motion Features. (arXiv:2203.03097v1 [cs.CV])
68. Differentially Private Federated Learning with Local Regularization and Sparsification. (arXiv:2203.03106v1 [cs.LG])
69. Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer. (arXiv:2203.03121v1 [cs.CV])
70. MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning. (arXiv:2203.03137v1 [cs.CV])
71. End-to-end video instance segmentation via spatial-temporal graph neural networks. (arXiv:2203.03145v1 [cs.CV])
72. On the Construction of Distribution-Free Prediction Intervals for an Image Regression Problem in Semiconductor Manufacturing. (arXiv:2203.03150v1 [cs.CV])
73. SingleSketch2Mesh : Generating 3D Mesh model from Sketch. (arXiv:2203.03157v1 [cs.CV])
74. Satellite Image-based Localization via Learned Embeddings. (arXiv:1704.01133v2 [cs.RO] UPDATED)
75. Theme-Aware Aesthetic Distribution Prediction with Full Resolution Photos. (arXiv:1908.01308v2 [cs.CV] UPDATED)
76. Information Compensation for Deep Conditional Generative Networks. (arXiv:2001.08559v3 [cs.LG] UPDATED)
77. EBBINNOT: A Hardware Efficient Hybrid Event-Frame Tracker for Stationary Dynamic Vision Sensors. (arXiv:2006.00422v3 [cs.CV] UPDATED)
78. EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks. (arXiv:2006.04270v5 [cs.LG] UPDATED)
79. VisImages: A Fine-Grained Expert-Annotated Visualization Dataset. (arXiv:2007.04584v5 [cs.CV] UPDATED)
80. Flower: A Friendly Federated Learning Research Framework. (arXiv:2007.14390v5 [cs.LG] UPDATED)
81. Generating Out of Distribution Adversarial Attack using Latent Space Poisoning. (arXiv:2012.05027v2 [cs.CV] UPDATED)
82. Geometry **Enhancement**s from Visual Content: Going Beyond Ground Truth. (arXiv:2012.08248v3 [cs.CV] UPDATED)
83. Noisy Label Learning for Large-scale Medical Image Classification. (arXiv:2103.04053v3 [cs.CV] UPDATED)
84. Deep Neural Networks Learn Meta-Structures from Noisy Labels in Semantic Segmentation. (arXiv:2103.11594v4 [cs.CV] UPDATED)
85. InfinityGAN: Towards Infinite-Pixel Image Synthesis. (arXiv:2104.03963v3 [cs.CV] UPDATED)
86. Visual Grounding with Transformers. (arXiv:2105.04281v2 [cs.CV] UPDATED)
87. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v4 [cs.CV] UPDATED)
88. I2C2W: Image-to-Character-to-Word Transformers for Accurate Scene Text Recognition. (arXiv:2105.08383v2 [cs.CV] UPDATED)
89. A structured latent space for human body motion generation. (arXiv:2106.04387v3 [cs.CV] UPDATED)
90. Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification. (arXiv:2106.05517v3 [cs.CV] UPDATED)
91. Anatomy-XNet: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v2 [eess.IV] UPDATED)
92. Delving Deep into the Generalization of Vision Transformers under Distribution Shifts. (arXiv:2106.07617v3 [cs.CV] UPDATED)
93. Scene Transformer: A unified architecture for predicting multiple agent trajectories. (arXiv:2106.08417v3 [cs.CV] UPDATED)
94. ResViT: Residual vision transformers for multi-modal medical image synthesis. (arXiv:2106.16031v3 [eess.IV] UPDATED)
95. A review on vision-based analysis for automatic dietary assessment. (arXiv:2108.02947v2 [cs.CV] UPDATED)
96. Towards to Robust and Generalized Medical Image Segmentation Framework. (arXiv:2108.03823v6 [cs.CV] UPDATED)
97. Uncertify: Attacks Against Neural Network Certification. (arXiv:2108.11299v2 [cs.LG] UPDATED)
98. FBSNet: A Fast **Bilateral** Symmetrical Network for Real-Time Semantic Segmentation. (arXiv:2109.00699v3 [cs.CV] UPDATED)
99. Single-Camera 3D Head Fitting for Mixed Reality Clinical Applications. (arXiv:2109.02740v2 [cs.CV] UPDATED)
100. Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting. (arXiv:2109.14128v3 [cs.CV] UPDATED)
101. Adaptive Early-Learning Correction for Segmentation from Noisy Annotations. (arXiv:2110.03740v2 [cs.CV] UPDATED)
102. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v2 [cs.RO] UPDATED)
103. TSGB: Target-Selective Gradient Backprop for Probing CNN Visual Saliency. (arXiv:2110.05182v2 [cs.CV] UPDATED)
104. Learning Optimal Conformal Classifiers. (arXiv:2110.09192v2 [cs.LG] UPDATED)
105. Automated Scoring System of HER2 in Pathological Images under the Microscope. (arXiv:2110.12900v2 [q-bio.QM] UPDATED)
106. Self-supervised GAN Detector. (arXiv:2111.06575v2 [cs.CV] UPDATED)
107. Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection. (arXiv:2111.09099v5 [cs.CV] UPDATED)
108. IntraQ: Learning Synthetic Images with Intra-Class Heterogeneity for Zero-Shot Network Quantization. (arXiv:2111.09136v3 [cs.CV] UPDATED)
109. CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation. (arXiv:2111.10502v2 [cs.CV] UPDATED)
110. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v6 [cs.CV] UPDATED)
111. Lepard: Learning partial point cloud matching in rigid and deformable scenes. (arXiv:2111.12591v2 [cs.CV] UPDATED)
112. Maximum Consensus by Weighted Influences of Monotone Boolean Functions. (arXiv:2112.00953v4 [cs.CV] UPDATED)
113. Equal Bits: Enforcing Equally Distributed Binary Network Weights. (arXiv:2112.03406v2 [cs.LG] UPDATED)
114. TCGL: Temporal Contrastive Graph for Self-supervised Video Representation Learning. (arXiv:2112.03587v3 [cs.CV] UPDATED)
115. Early Stopping for Deep Image Prior. (arXiv:2112.06074v2 [cs.CV] UPDATED)
116. JoJoGAN: One Shot Face Stylization. (arXiv:2112.11641v4 [cs.CV] UPDATED)
117. Reflash Dropout in Image Super-Resolution. (arXiv:2112.12089v2 [cs.CV] UPDATED)
118. Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation and Focal Loss. (arXiv:2201.01501v2 [cs.CV] UPDATED)
119. Point-NeRF: Point-based Neural Radiance Fields. (arXiv:2201.08845v2 [cs.CV] UPDATED)
120. Learning to Minimize the Remainder in Supervised Learning. (arXiv:2201.09193v2 [cs.CV] UPDATED)
121. Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v2 [cs.CV] UPDATED)
122. Low-confidence Samples Matter for Domain Adaptation. (arXiv:2202.02802v2 [cs.CV] UPDATED)
123. Hyper-relationship Learning Network for Scene Graph Generation. (arXiv:2202.07271v2 [cs.CV] UPDATED)
124. A Review of Emerging Research Directions in Abstract Visual Reasoning. (arXiv:2202.10284v2 [cs.AI] UPDATED)
125. CG-SSD: Corner Guided Single Stage 3D Object Detection from LiDAR Point Cloud. (arXiv:2202.11868v2 [cs.CV] UPDATED)
126. TeachAugment: Data Augmentation Optimization Using Teacher Knowledge. (arXiv:2202.12513v2 [cs.CV] UPDATED)
127. Name Your Style: An Arbitrary Artist-aware Image Style Transfer. (arXiv:2202.13562v2 [cs.CV] UPDATED)
128. Adversarial samples for deep monocular 6D object pose estimation. (arXiv:2203.00302v2 [cs.CV] UPDATED)
129. OVE6D: Object Viewpoint Encoding for Depth-based 6D Object Pose Estimation. (arXiv:2203.01072v2 [cs.CV] UPDATED)
130. 3D Human Motion Prediction: A Survey. (arXiv:2203.01593v2 [cs.CV] UPDATED)
131. Syntax-Aware Network for Handwritten Mathematical Expression Recognition. (arXiv:2203.01601v2 [cs.CV] UPDATED)
132. DenseUNets with feedback non-local attention for the segmentation of specular microscopy images of the corneal endothelium with Fuchs dystrophy. (arXiv:2203.01882v2 [eess.IV] UPDATED)
133. TCTrack: Temporal Contexts for Aerial Tracking. (arXiv:2203.01885v2 [cs.CV] UPDATED)
134. NUQ: A Noise Metric for Diffusion MRI via Uncertainty Discrepancy Quantification. (arXiv:2203.01921v2 [eess.IV] UPDATED)
135. Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and no Retraining. (arXiv:2203.01969v2 [eess.IV] UPDATED)
136. Fast Neural Architecture Search for Lightweight Dense Prediction Networks. (arXiv:2203.01994v2 [cs.CV] UPDATED)
## eess.IV
---
**35** new papers in eess.IV:-) 
1. Parallel Fourier Ptychography reconstruction. (arXiv:2203.02507v1 [eess.IV])
2. Cellular Segmentation and Composition in Routine Histology Images using Deep Learning. (arXiv:2203.02510v1 [q-bio.QM])
3. BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation. (arXiv:2203.02533v1 [eess.IV])
4. Improved Wavelets for Image Compression from Unitary Circuits. (arXiv:2203.02556v1 [eess.IV])
5. UVCGAN: UNet Vision Transformer cycle-consistent GAN for unpaired image-to-image translation. (arXiv:2203.02557v1 [cs.CV])
6. Improving the Energy Efficiency and Robustness of tinyML Computer Vision using Log-Gradient Input Images. (arXiv:2203.02571v1 [eess.IV])
7. Virtual Histological Staining of Label-Free Total Absorption Photoacoustic Remote Sensing (TA-PARS). (arXiv:2203.02584v1 [eess.IV])
8. A Quality Index Metric and Method for Online Self-Assessment of Autonomous Vehicles Sensory Perception. (arXiv:2203.02588v1 [cs.CV])
9. Geodesic Gramian Denoising Applied to the Images Contaminated With Noise Sampled From Diverse Probability Distributions. (arXiv:2203.02600v1 [eess.IV])
10. IDmUNet: A new image decomposition induced network for sparse feature segmentation. (arXiv:2203.02690v1 [eess.IV])
11. High-resolution Coastline Extraction in SAR Images via MISP-GGD Superpixel Segmentation. (arXiv:2203.02708v1 [eess.IV])
12. A Novel Dual Dense Connection Network for Video Super-resolution. (arXiv:2203.02723v1 [eess.IV])
13. Rib Suppression in Digital Chest Tomosynthesis. (arXiv:2203.02772v1 [eess.IV])
14. Machine Learning Applications in Diagnosis, Treatment and Prognosis of Lung Cancer. (arXiv:2203.02794v1 [cs.LG])
15. Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
16. Precise Point Spread Function Estimation. (arXiv:2203.02953v1 [cs.CV])
17. Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
18. Undersampled MRI Reconstruction with Side Information-Guided Normalisation. (arXiv:2203.03196v1 [eess.IV])
19. Visually Supervised Speaker Detection and Localization via Microphone Array. (arXiv:2203.03291v1 [eess.AS])
20. A novel shape-based loss function for machine learning-based seminal organ segmentation in medical imaging. (arXiv:2203.03336v1 [physics.med-ph])
21. Joint brain tumor segmentation from multi MR sequences through a deep convolutional neural network. (arXiv:2203.03338v1 [physics.med-ph])
22. CoNIC Solution. (arXiv:2203.03415v1 [eess.IV])
23. A Deep Learning Framework for Nuclear Segmentation and Classification in Histopathological Images. (arXiv:2203.03420v1 [eess.IV])
24. Compression of user generated content using denoised references. (arXiv:2203.03553v1 [eess.IV])
25. EBBINNOT: A Hardware Efficient Hybrid Event-Frame Tracker for Stationary Dynamic Vision Sensors. (arXiv:2006.00422v3 [cs.CV] UPDATED)
26. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v4 [cs.CV] UPDATED)
27. Anatomy-XNet: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v2 [eess.IV] UPDATED)
28. ResViT: Residual vision transformers for multi-modal medical image synthesis. (arXiv:2106.16031v3 [eess.IV] UPDATED)
29. Automated Scoring System of HER2 in Pathological Images under the Microscope. (arXiv:2110.12900v2 [q-bio.QM] UPDATED)
30. Unrolling PALM for sparse semi-blind source separation. (arXiv:2112.05694v2 [astro-ph.IM] UPDATED)
31. Early Stopping for Deep Image Prior. (arXiv:2112.06074v2 [cs.CV] UPDATED)
32. Name Your Style: An Arbitrary Artist-aware Image Style Transfer. (arXiv:2202.13562v2 [cs.CV] UPDATED)
33. DenseUNets with feedback non-local attention for the segmentation of specular microscopy images of the corneal endothelium with Fuchs dystrophy. (arXiv:2203.01882v2 [eess.IV] UPDATED)
34. NUQ: A Noise Metric for Diffusion MRI via Uncertainty Discrepancy Quantification. (arXiv:2203.01921v2 [eess.IV] UPDATED)
35. Robust Segmentation of Brain MRI in the Wild with Hierarchical CNNs and no Retraining. (arXiv:2203.01969v2 [eess.IV] UPDATED)
## cs.LG
---
**233** new papers in cs.LG:-) 
1. ARM 4-BIT PQ: SIMD-based Acceleration for Approximate Nearest Neighbor Search on ARM. (arXiv:2203.02505v1 [cs.LG])
2. Non-linear predictive vector quantization of speech. (arXiv:2203.02506v1 [cs.LG])
3. Cellular Segmentation and Composition in Routine Histology Images using Deep Learning. (arXiv:2203.02510v1 [q-bio.QM])
4. Machine Learning for CUDA+MPI Design Rules. (arXiv:2203.02530v1 [cs.PF])
5. BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation. (arXiv:2203.02533v1 [eess.IV])
6. Evolving symbolic density functionals. (arXiv:2203.02540v1 [cs.NE])
7. A streamable large-scale clinical EEG dataset for Deep Learning. (arXiv:2203.02552v1 [cs.LG])
8. Building 3D Generative Models from Minimal Data. (arXiv:2203.02554v1 [cs.CV])
9. Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning. (arXiv:2203.02573v1 [cs.CV])
10. Style-ERD: Responsive and Coherent Online Motion Style Transfer. (arXiv:2203.02574v1 [cs.CV])
11. Machine Learning Simulates Agent-Based Model Towards Policy. (arXiv:2203.02576v1 [cs.MA])
12. Concept-based Explanations for Out-Of-Distribution Detectors. (arXiv:2203.02586v1 [cs.LG])
13. A Small Gain Analysis of Single Timescale Actor Critic. (arXiv:2203.02591v1 [math.OC])
14. Sparsity-Inducing Categorical Prior Improves Robustness of the Information Bottleneck. (arXiv:2203.02592v1 [stat.ML])
15. Geodesic Gramian Denoising Applied to the Images Contaminated With Noise Sampled From Diverse Probability Distributions. (arXiv:2203.02600v1 [eess.IV])
16. Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v1 [stat.ML])
17. Plant Species Recognition with Optimized 3D Polynomial Neural Networks and Variably Overlapping Time-Coherent Sliding Window. (arXiv:2203.02611v1 [cs.CV])
18. How to Train Unstable Looped Tensor Network. (arXiv:2203.02617v1 [cs.LG])
19. Low-cost prediction of molecular and transition state partition functions via machine learning. (arXiv:2203.02621v1 [physics.chem-ph])
20. Scaling R-GCN Training with Graph Summarization. (arXiv:2203.02622v1 [cs.LG])
21. Target Network and Truncation Overcome The Deadly triad in $Q$-Learning. (arXiv:2203.02628v1 [cs.LG])
22. Important Object Identification with Semi-Supervised Learning for Autonomous Driving. (arXiv:2203.02634v1 [cs.CV])
23. Training privacy-preserving video analytics pipelines by suppressing features that reveal information about private attributes. (arXiv:2203.02635v1 [cs.CV])
24. Safe Reinforcement Learning for Legged Locomotion. (arXiv:2203.02638v1 [cs.RO])
25. Acceleration of Federated Learning with Alleviated Forgetting in Local Training. (arXiv:2203.02645v1 [cs.LG])
26. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v1 [cs.LG])
27. Unfreeze with Care: Space-Efficient Fine-Tuning of Semantic Parsing Models. (arXiv:2203.02652v1 [cs.CL])
28. Audio-visual speech separation based on joint feature representation with cross-modal attention. (arXiv:2203.02655v1 [cs.SD])
29. Deep Partial Multiplex Network Embedding. (arXiv:2203.02656v1 [cs.LG])
30. Koopman operator for time-dependent reliability analysis. (arXiv:2203.02658v1 [stat.ML])
31. A Similarity-based Framework for Classification Task. (arXiv:2203.02669v1 [cs.LG])
32. ECMG: Exemplar-based Commit Message Generation. (arXiv:2203.02700v1 [cs.SE])
33. Meta Mirror Descent: Optimiser Learning for Fast Convergence. (arXiv:2203.02711v1 [cs.LG])
34. Towards Efficient and Scalable Sharpness-Aware Minimization. (arXiv:2203.02714v1 [cs.LG])
35. Bayesian Learning Approach to Model Predictive Control. (arXiv:2203.02720v1 [cs.LG])
36. A Novel Dual Dense Connection Network for Video Super-resolution. (arXiv:2203.02723v1 [eess.IV])
37. MaxDropoutV2: An Improved Method to Drop out Neurons in Convolutional Neural Networks. (arXiv:2203.02740v1 [cs.LG])
38. Flurry: a Fast Framework for Reproducible Multi-layered Provenance Graph Representation Learning. (arXiv:2203.02744v1 [cs.CR])
39. The Impact of Differential Privacy on Group Disparity Mitigation. (arXiv:2203.02745v1 [cs.CR])
40. Don't Be So Dense: Sparse-to-Sparse GAN Training Without Sacrificing Performance. (arXiv:2203.02770v1 [cs.CV])
41. A Robust Spectral Algorithm for Overcomplete Tensor Decomposition. (arXiv:2203.02790v1 [cs.LG])
42. Machine Learning Applications in Diagnosis, Treatment and Prognosis of Lung Cancer. (arXiv:2203.02794v1 [cs.LG])
43. Object-centric Process Predictive Analytics. (arXiv:2203.02801v1 [cs.LG])
44. Off-Policy Evaluation in Embedded Spaces. (arXiv:2203.02807v1 [cs.LG])
45. Fuzzy Forests For Feature Selection in High-Dimensional Survey Data: An Application to the 2020 U.S. Presidential Election. (arXiv:2203.02818v1 [cs.LG])
46. Bathymetry Inversion using a Deep-Learning-Based Surrogate for Shallow Water Equations Solvers. (arXiv:2203.02821v1 [physics.flu-dyn])
47. Distributional Hardness Against Preconditioned Lasso via Erasure-Robust Designs. (arXiv:2203.02824v1 [cs.DS])
48. Recursive Monte Carlo and Variational Inference with Auxiliary Variables. (arXiv:2203.02836v1 [cs.LG])
49. Algorithmic Regularization in Model-free Overparametrized Asymmetric Matrix Factorization. (arXiv:2203.02839v1 [cs.LG])
50. Recursive Reasoning Graph for Multi-Agent Reinforcement Learning. (arXiv:2203.02844v1 [cs.LG])
51. Graph Neural Network Potential for Magnetic Materials. (arXiv:2203.02853v1 [physics.comp-ph])
52. Hybrid Deep Learning Model using SPCAGAN Augmentation for Insider Threat Analysis. (arXiv:2203.02855v1 [cs.CR])
53. Leveraging Reward Gradients For Reinforcement Learning in Differentiable Physics Simulations. (arXiv:2203.02857v1 [cs.LG])
54. Compartmental Models for COVID-19 and Control via Policy Interventions. (arXiv:2203.02860v1 [stat.ML])
55. Fully Decentralized, Scalable Gaussian Processes for Multi-Agent Federated Learning. (arXiv:2203.02865v1 [stat.ML])
56. Diffusion Maps : Using the Semigroup Property for Parameter Tuning. (arXiv:2203.02867v1 [stat.ML])
57. MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication. (arXiv:2203.02877v1 [cs.AI])
58. Watch from sky: machine-learning-based multi-UAV network for predictive police surveillance. (arXiv:2203.02892v1 [cs.LG])
59. Depthwise Convolution for Multi-Agent Communication with Enhanced Mean-Field Approximation. (arXiv:2203.02896v1 [cs.LG])
60. Domain Adaptation with Factorizable Joint Shift. (arXiv:2203.02902v1 [cs.LG])
61. GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation. (arXiv:2203.02923v1 [q-bio.QM])
62. Enabling Automated Machine Learning for Model-Driven AI Engineering. (arXiv:2203.02927v1 [cs.SE])
63. Evaluation of Interpretability Methods and Perturbation Artifacts in Deep Neural Networks. (arXiv:2203.02928v1 [cs.LG])
64. Detection of Parasitic Eggs from Microscopy Images and the emergence of a new dataset. (arXiv:2203.02940v1 [cs.CV])
65. On Steering Multi-Annotations per Sample for Multi-Task Learning. (arXiv:2203.02946v1 [cs.CV])
66. On the importance of stationarity, strong baselines and benchmarks in transport prediction problems. (arXiv:2203.02954v1 [stat.ML])
67. Towards a Responsible AI Development Lifecycle: Lessons From Information Security. (arXiv:2203.02958v1 [cs.AI])
68. A Perspective on Robotic Telepresence and Teleoperation using Cognition: Are we there yet?. (arXiv:2203.02959v1 [cs.RO])
69. Smoothing with the Best Rectangle Window is Optimal for All Tapered Rectangle Windows. (arXiv:2203.02997v1 [stat.ML])
70. Offline Deep Reinforcement Learning for Dynamic Pricing of Consumer Credit. (arXiv:2203.03003v1 [cs.LG])
71. Coresets for Data Discretization and Sine Wave Fitting. (arXiv:2203.03009v1 [cs.LG])
72. Hierarchically Structured Scheduling and Execution of Tasks in a Multi-Agent Environment. (arXiv:2203.03021v1 [cs.LG])
73. HEAR 2021: Holistic Evaluation of Audio Representations. (arXiv:2203.03022v1 [cs.SD])
74. A Unified View of SDP-based Neural Network Verification through Completely Positive Programming. (arXiv:2203.03034v1 [math.OC])
75. Frames for Graph Signals on the Symmetric Group: A Representation Theoretic Approach. (arXiv:2203.03036v1 [eess.SP])
76. Scalable Uncertainty Quantification for Deep Operator Networks using Randomized Priors. (arXiv:2203.03048v1 [cs.LG])
77. Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v1 [cs.CV])
78. Is Bayesian Model-Agnostic Meta Learning Better than Model-Agnostic Meta Learning, Provably?. (arXiv:2203.03059v1 [cs.LG])
79. Leashing the Inner Demons: Self-Detoxification for Language Models. (arXiv:2203.03072v1 [cs.CL])
80. ILDAE: Instance-Level Difficulty Analysis of Evaluation Data. (arXiv:2203.03073v1 [cs.CL])
81. Virtual vs. Reality: External Validation of COVID-19 Classifiers using XCAT Phantoms for Chest Computed Tomography. (arXiv:2203.03074v1 [eess.IV])
82. Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation. (arXiv:2203.03078v1 [cs.LG])
83. GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction. (arXiv:2203.03079v1 [cs.CV])
84. HAR-GCNN: Deep Graph CNNs for Human Activity Recognition From Highly Unlabeled Mobile Sensor Data. (arXiv:2203.03087v1 [cs.CV])
85. SurvSet: An open-source time-to-event dataset repository. (arXiv:2203.03094v1 [stat.ML])
86. Singular Value Perturbation and Deep Network Optimization. (arXiv:2203.03099v1 [cs.LG])
87. HintNet: Hierarchical Knowledge Transfer Networks for Traffic Accident Forecasting on Heterogeneous Spatio-Temporal Data. (arXiv:2203.03100v1 [cs.LG])
88. Prediction of transport property via machine learning molecular movements. (arXiv:2203.03103v1 [physics.chem-ph])
89. Differentially Private Federated Learning with Local Regularization and Sparsification. (arXiv:2203.03106v1 [cs.LG])
90. Combining Individual and Joint Networking Behavior for Intelligent IoT Analytics. (arXiv:2203.03109v1 [cs.LG])
91. Cascaded Gaps: Towards Gap-Dependent Regret for Risk-Sensitive Reinforcement Learning. (arXiv:2203.03110v1 [cs.LG])
92. Matrix Decomposition Perspective for Accuracy Assessment of Item Response Theory. (arXiv:2203.03112v1 [stat.CO])
93. Kernel Packet: An Exact and Scalable Algorithm for Gaussian Process Regression with Mat\'ern Correlations. (arXiv:2203.03116v1 [stat.ML])
94. Searching for Robust Neural Architectures via Comprehensive and Reliable Evaluation. (arXiv:2203.03128v1 [cs.LG])
95. On the Construction of Distribution-Free Prediction Intervals for an Image Regression Problem in Semiconductor Manufacturing. (arXiv:2203.03150v1 [cs.CV])
96. Fast Community Detection based on Graph Autoencoder Reconstruction. (arXiv:2203.03151v1 [cs.SI])
97. Risk Bounds of Multi-Pass SGD for Least Squares in the Interpolation Regime. (arXiv:2203.03159v1 [cs.LG])
98. Detecting data-driven robust statistical arbitrage strategies with deep neural networks. (arXiv:2203.03179v1 [q-fin.CP])
99. Satellite Image-based Localization via Learned Embeddings. (arXiv:1704.01133v2 [cs.RO] UPDATED)
100. Deep Dynamic Boosted Forest. (arXiv:1804.07270v4 [cs.LG] UPDATED)
101. Information Compensation for Deep Conditional Generative Networks. (arXiv:2001.08559v3 [cs.LG] UPDATED)
102. Optimal Exact Matrix Completion Under new Parametrization. (arXiv:2002.02431v3 [cs.LG] UPDATED)
103. EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks. (arXiv:2006.04270v5 [cs.LG] UPDATED)
104. P3GM: Private High-Dimensional Data Release via Privacy Preserving Phased Generative Model. (arXiv:2006.12101v4 [cs.LG] UPDATED)
105. Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach. (arXiv:2007.04833v3 [cs.IR] UPDATED)
106. Flower: A Friendly Federated Learning Research Framework. (arXiv:2007.14390v5 [cs.LG] UPDATED)
107. Anomaly Detection by Recombining Gated Unsupervised Experts. (arXiv:2008.13763v4 [cs.LG] UPDATED)
108. Sparsifying Transformer Models with Trainable Representation Pooling. (arXiv:2009.05169v4 [cs.CL] UPDATED)
109. On the Fairness of Causal Algorithmic Recourse. (arXiv:2010.06529v5 [cs.LG] UPDATED)
110. A New Bandit Setting Balancing Information from State Evolution and Corrupted Context. (arXiv:2011.07989v3 [cs.LG] UPDATED)
111. Improved rates for prediction and identification of partially observed linear dynamical systems. (arXiv:2011.10006v3 [cs.LG] UPDATED)
112. What is a meaningful representation of protein sequences?. (arXiv:2012.02679v4 [q-bio.BM] UPDATED)
113. Generating Out of Distribution Adversarial Attack using Latent Space Poisoning. (arXiv:2012.05027v2 [cs.CV] UPDATED)
114. Privacy Amplification by Decentralization. (arXiv:2012.05326v4 [cs.LG] UPDATED)
115. Regularization in network optimization via trimmed stochastic gradient descent with noisy label. (arXiv:2012.11073v2 [cs.LG] UPDATED)
116. Double-Adversarial Activation Anomaly Detection: Adversarial Autoencoders are Anomaly Generators. (arXiv:2101.04645v3 [cs.LG] UPDATED)
117. Ensemble perspective for understanding temporal credit assignment. (arXiv:2102.03740v2 [cond-mat.dis-nn] UPDATED)
118. Sequential change-point detection for mutually exciting point processes over networks. (arXiv:2102.05724v2 [stat.ML] UPDATED)
119. On the Last Iterate Convergence of Momentum Methods. (arXiv:2102.07002v2 [cs.LG] UPDATED)
120. On Feature Collapse and Deep Kernel Learning for Single Forward Pass Uncertainty. (arXiv:2102.11409v3 [cs.LG] UPDATED)
121. A Local Method for Identifying Causal Relations under Markov Equivalence. (arXiv:2102.12685v2 [stat.ML] UPDATED)
122. Neuron Coverage-Guided Domain Generalization. (arXiv:2103.00229v2 [cs.LG] UPDATED)
123. Neural tensor contractions and the expressive power of deep neural quantum states. (arXiv:2103.10293v3 [quant-ph] UPDATED)
124. STL Robustness Risk over Discrete-Time Stochastic Processes. (arXiv:2104.01503v4 [eess.SY] UPDATED)
125. Minimax Kernel Machine Learning for a Class of Doubly Robust Functionals with Application to Proximal Causal Inference. (arXiv:2104.02929v3 [stat.ML] UPDATED)
126. GPU Semiring Primitives for Sparse Neighborhood Methods. (arXiv:2104.06357v2 [cs.LG] UPDATED)
127. Learning Latent Graph Dynamics for Visual Manipulation of Deformable Objects. (arXiv:2104.12149v2 [cs.RO] UPDATED)
128. FedProto: Federated Prototype Learning across Heterogeneous Clients. (arXiv:2105.00243v4 [cs.LG] UPDATED)
129. Momentum Contrastive Voxel-wise Representation Learning for Semi-supervised Volumetric Medical Image Segmentation. (arXiv:2105.07059v4 [cs.CV] UPDATED)
130. Active Hierarchical Exploration with Stable Subgoal Representation Learning. (arXiv:2105.14750v3 [cs.LG] UPDATED)
131. Node-Variant Graph Filters in Graph Neural Networks. (arXiv:2106.00089v2 [cs.LG] UPDATED)
132. Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v3 [cs.LG] UPDATED)
133. MURANA: A Generic Framework for Stochastic Variance-Reduced Optimization. (arXiv:2106.03056v2 [math.OC] UPDATED)
134. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v6 [cs.LG] UPDATED)
135. Thompson Sampling with a Mixture Prior. (arXiv:2106.05608v2 [cs.LG] UPDATED)
136. Anatomy-XNet: A Semi-Supervised Anatomy Aware Convolutional Neural Network for Thoracic Disease Classification. (arXiv:2106.05915v2 [eess.IV] UPDATED)
137. LocoProp: Enhancing BackProp via Local Loss Optimization. (arXiv:2106.06199v2 [cs.LG] UPDATED)
138. Federated Learning with Buffered Asynchronous Aggregation. (arXiv:2106.06639v4 [cs.LG] UPDATED)
139. Scene Transformer: A unified architecture for predicting multiple agent trajectories. (arXiv:2106.08417v3 [cs.CV] UPDATED)
140. Random Effect Bandits. (arXiv:2106.12200v2 [cs.LG] UPDATED)
141. You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks. (arXiv:2106.13264v2 [cs.LG] UPDATED)
142. Scale Mixtures of Neural Network Gaussian Processes. (arXiv:2107.01408v2 [stat.ML] UPDATED)
143. Polynomial Time Reinforcement Learning in Factored State MDPs with Linear Value Functions. (arXiv:2107.05187v2 [cs.LG] UPDATED)
144. Sparse Bayesian Learning with Diagonal Quasi-Newton Method for Large Scale Classification. (arXiv:2107.08195v3 [cs.LG] UPDATED)
145. Temporal-Relational Hypergraph Tri-Attention Networks for Stock Trend Prediction. (arXiv:2107.14033v2 [q-fin.ST] UPDATED)
146. Can You Hear It? Backdoor Attacks via Ultrasonic Triggers. (arXiv:2107.14569v3 [cs.CR] UPDATED)
147. The application of adaptive minimum match k-nearest neighbors to identify at-risk students in health professions education. (arXiv:2108.07709v2 [cs.CY] UPDATED)
148. Automated Identification of Cell Populations in Flow Cytometry Data with Transformers. (arXiv:2108.10072v2 [q-bio.QM] UPDATED)
149. Uncertify: Attacks Against Neural Network Certification. (arXiv:2108.11299v2 [cs.LG] UPDATED)
150. Fine-Tuning Pretrained Language Models With Label Attention for Biomedical Text Classification. (arXiv:2108.11809v3 [cs.CL] UPDATED)
151. Active Inference and Epistemic Value in Graphical Models. (arXiv:2109.00541v2 [stat.ML] UPDATED)
152. You Only Hear Once: A YOLO-like Algorithm for Audio Segmentation and Sound Event Detection. (arXiv:2109.00962v2 [eess.AS] UPDATED)
153. Learning Neural Causal Models with Active Interventions. (arXiv:2109.02429v2 [stat.ML] UPDATED)
154. Direct Random Search for Fine Tuning of Deep Reinforcement Learning Policies. (arXiv:2109.05604v2 [cs.RO] UPDATED)
155. The Grammar-Learning Trajectories of Neural Language Models. (arXiv:2109.06096v2 [cs.CL] UPDATED)
156. The Curse Revisited: When are Distances Informative for the Ground Truth in Noisy High-Dimensional Data?. (arXiv:2109.10569v5 [cs.LG] UPDATED)
157. Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators. (arXiv:2109.14830v2 [cs.AI] UPDATED)
158. Predicting Flat-Fading Channels via Meta-Learned Closed-Form Linear Filters and Equilibrium Propagation. (arXiv:2110.00414v2 [cs.IT] UPDATED)
159. xFAIR: Better Fairness via Model-based Rebalancing of Protected Attributes. (arXiv:2110.01109v2 [cs.LG] UPDATED)
160. An Improved Genetic Algorithm and Its Application in Neural Network Adversarial Attack. (arXiv:2110.01818v5 [cs.NE] UPDATED)
161. Geometric Transformers for Protein Interface Contact Prediction. (arXiv:2110.02423v5 [cs.LG] UPDATED)
162. Deep Reinforcement Learning for Solving the Heterogeneous Capacitated Vehicle Routing Problem. (arXiv:2110.02629v2 [cs.LG] UPDATED)
163. Generative Modeling with Optimal Transport Maps. (arXiv:2110.02999v2 [cs.LG] UPDATED)
164. Frame Averaging for Invariant and Equivariant Network Design. (arXiv:2110.03336v2 [cs.LG] UPDATED)
165. Adaptive Early-Learning Correction for Segmentation from Noisy Annotations. (arXiv:2110.03740v2 [cs.CV] UPDATED)
166. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v2 [cs.RO] UPDATED)
167. TSGB: Target-Selective Gradient Backprop for Probing CNN Visual Saliency. (arXiv:2110.05182v2 [cs.CV] UPDATED)
168. Disentangling intrinsic motion from neighbourhood effects in heterogeneous collective motion. (arXiv:2110.05864v2 [cs.LG] UPDATED)
169. Infinitely Divisible Noise in the Low Privacy Regime. (arXiv:2110.06559v3 [cs.LG] UPDATED)
170. Provable RL with Exogenous Distractors via Multistep Inverse Dynamics. (arXiv:2110.08847v2 [cs.LG] UPDATED)
171. Learning Optimal Conformal Classifiers. (arXiv:2110.09192v2 [cs.LG] UPDATED)
172. Topologically Regularized Data Embeddings. (arXiv:2110.09193v4 [cs.LG] UPDATED)
173. A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits. (arXiv:2110.11819v5 [cs.LG] UPDATED)
174. Learning Stochastic Shortest Path with Linear Function Approximation. (arXiv:2110.12727v2 [cs.LG] UPDATED)
175. Applications of Multi-Agent Reinforcement Learning in Future Internet: A Comprehensive Survey. (arXiv:2110.13484v2 [cs.AI] UPDATED)
176. An Operator Theoretic Perspective on Pruning Deep Neural Networks. (arXiv:2110.14856v2 [cs.LG] UPDATED)
177. Towards Fine-Grained Reasoning for Fake News Detection. (arXiv:2110.15064v4 [cs.CL] UPDATED)
178. Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction. (arXiv:2111.00064v2 [cs.LG] UPDATED)
179. Efficiently Modeling Long Sequences with Structured State Spaces. (arXiv:2111.00396v2 [cs.LG] UPDATED)
180. A Johnson--Lindenstrauss Framework for Randomly Initialized CNNs. (arXiv:2111.02155v2 [cs.LG] UPDATED)
181. Maillard Sampling: Boltzmann Exploration Done Optimally. (arXiv:2111.03290v2 [stat.ML] UPDATED)
182. Hierarchical Bayesian Bandits. (arXiv:2111.06929v2 [cs.LG] UPDATED)
183. Fast Yet Effective Machine Unlearning. (arXiv:2111.08947v3 [cs.LG] UPDATED)
184. Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection. (arXiv:2111.09099v5 [cs.CV] UPDATED)
185. L-Verse: Bidirectional Generation Between Image and Text. (arXiv:2111.11133v6 [cs.CV] UPDATED)
186. Maximum Consensus by Weighted Influences of Monotone Boolean Functions. (arXiv:2112.00953v4 [cs.CV] UPDATED)
187. Equal Bits: Enforcing Equally Distributed Binary Network Weights. (arXiv:2112.03406v2 [cs.LG] UPDATED)
188. Generative Adversarial Networks for Labeled Data Creation for Structural Monitoring and Damage Detection. (arXiv:2112.03478v3 [cs.LG] UPDATED)
189. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. (arXiv:2112.04906v2 [math.OC] UPDATED)
190. Unrolling PALM for sparse semi-blind source separation. (arXiv:2112.05694v2 [astro-ph.IM] UPDATED)
191. Early Stopping for Deep Image Prior. (arXiv:2112.06074v2 [cs.CV] UPDATED)
192. Fast Computation of Generalized Eigenvectors for Manifold Graph Embedding. (arXiv:2112.07862v2 [eess.SP] UPDATED)
193. Torch.fx: Practical Program Capture and Transformation for Deep Learning in Python. (arXiv:2112.08429v2 [cs.LG] UPDATED)
194. Information Field Theory and Artificial Intelligence. (arXiv:2112.10133v3 [stat.ML] UPDATED)
195. ViNMT: Neural Machine Translation Toolkit. (arXiv:2112.15272v4 [cs.CL] UPDATED)
196. ECOD: Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions. (arXiv:2201.00382v2 [cs.LG] UPDATED)
197. McXai: Local model-agnostic explanation as two games. (arXiv:2201.01044v2 [cs.LG] UPDATED)
198. Deep Fusion of Lead-lag Graphs: Application to Cryptocurrencies. (arXiv:2201.02040v2 [cs.LG] UPDATED)
199. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v4 [cs.LG] UPDATED)
200. VGAER: Graph Neural Network Reconstruction based Community Detection. (arXiv:2201.04066v4 [cs.SI] UPDATED)
201. Sequential Recommendation via Stochastic Self-Attention. (arXiv:2201.06035v2 [cs.IR] UPDATED)
202. A New Look at Dynamic Regret for Non-Stationary Stochastic Bandits. (arXiv:2201.06532v2 [cs.LG] UPDATED)
203. Dual Space Graph Contrastive Learning. (arXiv:2201.07409v2 [cs.LG] UPDATED)
204. On the Convergence Rates of Policy Gradient Methods. (arXiv:2201.07443v2 [math.OC] UPDATED)
205. Learning to Minimize the Remainder in Supervised Learning. (arXiv:2201.09193v2 [cs.CV] UPDATED)
206. Performance Analysis of Electrical Machines Using a Hybrid Data- and Physics-Driven Model. (arXiv:2201.09603v2 [cs.LG] UPDATED)
207. STOPS: Short-Term-based Volatility-controlled Policy Search and its Global Convergence. (arXiv:2201.09857v3 [cs.LG] UPDATED)
208. SPIRAL: Self-supervised Perturbation-Invariant Representation Learning for Speech Pre-Training. (arXiv:2201.10207v3 [eess.AS] UPDATED)
209. Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning. (arXiv:2202.00907v3 [cs.RO] UPDATED)
210. Who will Leave a Pediatric Weight Management Program and When? -- A machine learning approach for predicting attrition patterns. (arXiv:2202.01765v3 [cs.LG] UPDATED)
211. Handling Distribution Shifts on Graphs: An Invariance Perspective. (arXiv:2202.02466v3 [cs.LG] UPDATED)
212. Low-confidence Samples Matter for Domain Adaptation. (arXiv:2202.02802v2 [cs.CV] UPDATED)
213. Smoothed Online Learning is as Easy as Statistical Learning. (arXiv:2202.04690v2 [stat.ML] UPDATED)
214. Group-Agent Reinforcement Learning with A Distributed Deep Solution. (arXiv:2202.05135v2 [cs.LG] UPDATED)
215. Measuring dissimilarity with diffeomorphism invariance. (arXiv:2202.05614v2 [stat.ML] UPDATED)
216. Finding Dynamics Preserving Adversarial Winning Tickets. (arXiv:2202.06488v3 [cs.LG] UPDATED)
217. Transformers in Time Series: A Survey. (arXiv:2202.07125v3 [cs.LG] UPDATED)
218. CycleGAN for Undamaged-to-Damaged Domain Translation for Structural Health Monitoring and Damage Detection. (arXiv:2202.07831v4 [cs.LG] UPDATED)
219. A Review of Emerging Research Directions in Abstract Visual Reasoning. (arXiv:2202.10284v2 [cs.AI] UPDATED)
220. NetRCA: An Effective Network Fault Cause Localization Algorithm. (arXiv:2202.11269v2 [cs.LG] UPDATED)
221. A fair pricing model via adversarial learning. (arXiv:2202.12008v2 [stat.ML] UPDATED)
222. A Perceptual Measure for Evaluating the Resynthesis of Automatic Music Transcriptions. (arXiv:2202.12257v2 [cs.SD] UPDATED)
223. Deep Learning, Natural Language Processing, and Explainable Artificial Intelligence in the Biomedical Domain. (arXiv:2202.12678v2 [cs.AI] UPDATED)
224. Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v2 [cs.LG] UPDATED)
225. Weakly Supervised Correspondence Learning. (arXiv:2203.00904v2 [cs.RO] UPDATED)
226. A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems. (arXiv:2203.01387v2 [cs.LG] UPDATED)
227. Adaptive Gradient Methods with Local Guarantees. (arXiv:2203.01400v2 [cs.LG] UPDATED)
228. KamNet: An Integrated Spatiotemporal Deep Neural Network for Rare Event Search in KamLAND-Zen. (arXiv:2203.01870v3 [physics.ins-det] UPDATED)
229. DenseUNets with feedback non-local attention for the segmentation of specular microscopy images of the corneal endothelium with Fuchs dystrophy. (arXiv:2203.01882v2 [eess.IV] UPDATED)
230. NUQ: A Noise Metric for Diffusion MRI via Uncertainty Discrepancy Quantification. (arXiv:2203.01921v2 [eess.IV] UPDATED)
231. X2T: Training an X-to-Text Typing Interface with Online Learning from User Feedback. (arXiv:2203.02072v2 [cs.HC] UPDATED)
232. Boosting the Performance of Quantum Annealers using Machine Learning. (arXiv:2203.02360v2 [quant-ph] UPDATED)
233. Probably approximately correct quantum source coding. (arXiv:2112.06841v1 [quant-ph] CROSS LISTED)
## cs.AI
---
**97** new papers in cs.AI:-) 
1. BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation. (arXiv:2203.02533v1 [eess.IV])
2. Building 3D Generative Models from Minimal Data. (arXiv:2203.02554v1 [cs.CV])
3. Bayesian Optimization Meets Hybrid Zero Dynamics: Safe Parameter Learning for Bipedal Locomotion Control. (arXiv:2203.02570v1 [cs.RO])
4. Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning. (arXiv:2203.02573v1 [cs.CV])
5. Chance-Constrained Optimization in Contact-Rich Systems for Robust Manipulation. (arXiv:2203.02616v1 [cs.RO])
6. Scaling R-GCN Training with Graph Summarization. (arXiv:2203.02622v1 [cs.LG])
7. Important Object Identification with Semi-Supervised Learning for Autonomous Driving. (arXiv:2203.02634v1 [cs.CV])
8. Safe Reinforcement Learning for Legged Locomotion. (arXiv:2203.02638v1 [cs.RO])
9. Acceleration of Federated Learning with Alleviated Forgetting in Local Training. (arXiv:2203.02645v1 [cs.LG])
10. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v1 [cs.LG])
11. Just Rank: Rethinking Evaluation with Word and Sentence Similarities. (arXiv:2203.02679v1 [cs.CL])
12. The Proof is in the Pudding: Using Automated Theorem Proving to Generate Cooking Recipes. (arXiv:2203.02683v1 [cs.CL])
13. Better Approximation Guarantees for the NSGA-II by Using the Current Crowding Distance. (arXiv:2203.02693v1 [cs.NE])
14. Boosting the Learning for Ranking Patterns. (arXiv:2203.02696v1 [cs.AI])
15. ECMG: Exemplar-based Commit Message Generation. (arXiv:2203.02700v1 [cs.SE])
16. Towards Efficient and Scalable Sharpness-Aware Minimization. (arXiv:2203.02714v1 [cs.LG])
17. Towards Robust Part-aware Instance Segmentation for Industrial Bin Picking. (arXiv:2203.02767v1 [cs.CV])
18. Boosting human decision-making with AI-generated decision aids. (arXiv:2203.02776v1 [cs.AI])
19. Tabula: Efficiently Computing Nonlinear Activation Functions for Secure Neural Network Inference. (arXiv:2203.02833v1 [cs.CR])
20. Leveraging Pre-trained BERT for Audio Captioning. (arXiv:2203.02838v1 [eess.AS])
21. Recursive Reasoning Graph for Multi-Agent Reinforcement Learning. (arXiv:2203.02844v1 [cs.LG])
22. Hybrid Deep Learning Model using SPCAGAN Augmentation for Insider Threat Analysis. (arXiv:2203.02855v1 [cs.CR])
23. MIRROR: Differentiable Deep Social Projection for Assistive Human-Robot Communication. (arXiv:2203.02877v1 [cs.AI])
24. A Survey for Solving Mixed Integer Programming via Machine Learning. (arXiv:2203.02878v1 [cs.AI])
25. Focus on the Target's Vocabulary: Masked Label Smoothing for Machine Translation. (arXiv:2203.02889v1 [cs.CL])
26. Watch from sky: machine-learning-based multi-UAV network for predictive police surveillance. (arXiv:2203.02892v1 [cs.LG])
27. Depthwise Convolution for Multi-Agent Communication with Enhanced Mean-Field Approximation. (arXiv:2203.02896v1 [cs.LG])
28. A Robust Framework of Chromosome Straightening with ViT-Patch GAN. (arXiv:2203.02901v1 [cs.CV])
29. Enabling Automated Machine Learning for Model-Driven AI Engineering. (arXiv:2203.02927v1 [cs.SE])
30. Single microphone speaker extraction using unified time-frequency Siamese-Unet. (arXiv:2203.02941v1 [cs.SD])
31. What does it mean to represent? Mental representations as falsifiable memory patterns. (arXiv:2203.02956v1 [cs.AI])
32. Towards a Responsible AI Development Lifecycle: Lessons From Information Security. (arXiv:2203.02958v1 [cs.AI])
33. A Perspective on Robotic Telepresence and Teleoperation using Cognition: Are we there yet?. (arXiv:2203.02959v1 [cs.RO])
34. Dynamic Key-value Memory Enhanced Multi-step Graph Reasoning for Knowledge-based Visual Question Answering. (arXiv:2203.02985v1 [cs.CV])
35. Modeling Coreference Relations in Visual Dialog. (arXiv:2203.02986v1 [cs.CV])
36. HEAR 2021: Holistic Evaluation of Audio Representations. (arXiv:2203.03022v1 [cs.SD])
37. Recent Advances in Neural Text Generation: A Task-Agnostic Survey. (arXiv:2203.03047v1 [cs.CL])
38. Story Point Effort Estimation by Text Level Graph Neural Network. (arXiv:2203.03062v1 [cs.SE])
39. Diversifying Agent's Behaviors in Interactive Decision Models. (arXiv:2203.03068v1 [cs.AI])
40. Leashing the Inner Demons: Self-Detoxification for Language Models. (arXiv:2203.03072v1 [cs.CL])
41. ILDAE: Instance-Level Difficulty Analysis of Evaluation Data. (arXiv:2203.03073v1 [cs.CL])
42. Fast and Data Efficient Reinforcement Learning from Pixels via Non-Parametric Value Approximation. (arXiv:2203.03078v1 [cs.LG])
43. HAR-GCNN: Deep Graph CNNs for Human Activity Recognition From Highly Unlabeled Mobile Sensor Data. (arXiv:2203.03087v1 [cs.CV])
44. Systematic Comparison of Path Planning Algorithms using PathBench. (arXiv:2203.03092v1 [cs.RO])
45. Mismatch between Multi-turn Dialogue and its Evaluation Metric in Dialogue State Tracking. (arXiv:2203.03123v1 [cs.CL])
46. Searching for Robust Neural Architectures via Comprehensive and Reliable Evaluation. (arXiv:2203.03128v1 [cs.LG])
47. Input-Tuning: Adapting Unfamiliar Inputs to Frozen Pretrained Models. (arXiv:2203.03131v1 [cs.CL])
48. Automatic Calibration Framework of Agent-Based Models for Dynamic and Heterogeneous Parameters. (arXiv:2203.03147v1 [cs.AI])
49. Fast Community Detection based on Graph Autoencoder Reconstruction. (arXiv:2203.03151v1 [cs.SI])
50. Scalable Verification of GNN-based Job Schedulers. (arXiv:2203.03153v1 [cs.AI])
51. A Rule-Based Model for Victim Prediction. (arXiv:2001.01391v3 [cs.AI] UPDATED)
52. A theory of interaction semantics. (arXiv:2007.06258v2 [cs.AI] UPDATED)
53. Bits and Pieces: Understanding Information Decomposition from Part-whole Relationships and Formal Logic. (arXiv:2008.09535v2 [cs.AI] UPDATED)
54. A Three-Stage Algorithm for the Large Scale Dynamic Vehicle Routing Problem with an Industry 4.0 Approach. (arXiv:2008.11719v3 [cs.AI] UPDATED)
55. On the Fairness of Causal Algorithmic Recourse. (arXiv:2010.06529v5 [cs.LG] UPDATED)
56. Efficient Deviation Types and Learning for Hindsight Rationality in Extensive-Form Games. (arXiv:2102.06973v3 [cs.GT] UPDATED)
57. Dependency Parsing as MRC-based Span-Span Prediction. (arXiv:2105.07654v2 [cs.CL] UPDATED)
58. Active Hierarchical Exploration with Stable Subgoal Representation Learning. (arXiv:2105.14750v3 [cs.LG] UPDATED)
59. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v6 [cs.LG] UPDATED)
60. Thompson Sampling with a Mixture Prior. (arXiv:2106.05608v2 [cs.LG] UPDATED)
61. Meta-control of social learning strategies. (arXiv:2106.10015v2 [cs.SI] UPDATED)
62. You are AllSet: A Multiset Function Framework for Hypergraph Neural Networks. (arXiv:2106.13264v2 [cs.LG] UPDATED)
63. Leveraging Human Knowledge to Learn Quadruped Locomotion Policies. (arXiv:2107.10969v2 [cs.RO] UPDATED)
64. Is My Model Using The Right Evidence? Systematic Probes for Examining Evidence-Based Tabular Reasoning. (arXiv:2108.00578v3 [cs.CL] UPDATED)
65. Multi-objective Conflict-based Search Using Safe-interval Path Planning. (arXiv:2108.00745v3 [cs.RO] UPDATED)
66. Towards to Robust and Generalized Medical Image Segmentation Framework. (arXiv:2108.03823v6 [cs.CV] UPDATED)
67. The Grammar-Learning Trajectories of Neural Language Models. (arXiv:2109.06096v2 [cs.CL] UPDATED)
68. Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting. (arXiv:2109.14128v3 [cs.CV] UPDATED)
69. Reinforcement Learning for Classical Planning: Viewing Heuristics as Dense Reward Generators. (arXiv:2109.14830v2 [cs.AI] UPDATED)
70. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v2 [cs.RO] UPDATED)
71. Automated Scoring System of HER2 in Pathological Images under the Microscope. (arXiv:2110.12900v2 [q-bio.QM] UPDATED)
72. Applications of Multi-Agent Reinforcement Learning in Future Internet: A Comprehensive Survey. (arXiv:2110.13484v2 [cs.AI] UPDATED)
73. Confidence Composition for Monitors of Verification Assumptions. (arXiv:2111.03782v2 [cs.LO] UPDATED)
74. Self-supervised GAN Detector. (arXiv:2111.06575v2 [cs.CV] UPDATED)
75. Hierarchical Bayesian Bandits. (arXiv:2111.06929v2 [cs.LG] UPDATED)
76. Variational Autoencoders for Precoding Matrices with High Spectral Efficiency. (arXiv:2111.15626v6 [eess.SP] UPDATED)
77. Generative Adversarial Networks for Labeled Data Creation for Structural Monitoring and Damage Detection. (arXiv:2112.03478v3 [cs.LG] UPDATED)
78. Enhancing Column Generation by a Machine-Learning-Based Pricing Heuristic for Graph Coloring. (arXiv:2112.04906v2 [math.OC] UPDATED)
79. McXai: Local model-agnostic explanation as two games. (arXiv:2201.01044v2 [cs.LG] UPDATED)
80. Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation and Focal Loss. (arXiv:2201.01501v2 [cs.CV] UPDATED)
81. PocketNN: Integer-only Training and Inference of Neural Networks via Direct Feedback Alignment and Pocket Activations in Pure C++. (arXiv:2201.02863v4 [cs.LG] UPDATED)
82. VGAER: Graph Neural Network Reconstruction based Community Detection. (arXiv:2201.04066v4 [cs.SI] UPDATED)
83. Sequential Recommendation via Stochastic Self-Attention. (arXiv:2201.06035v2 [cs.IR] UPDATED)
84. Using Deep Learning to Bootstrap Abstractions for Hierarchical Robot Planning. (arXiv:2202.00907v3 [cs.RO] UPDATED)
85. Handling Distribution Shifts on Graphs: An Invariance Perspective. (arXiv:2202.02466v3 [cs.LG] UPDATED)
86. Transformers in Time Series: A Survey. (arXiv:2202.07125v3 [cs.LG] UPDATED)
87. CycleGAN for Undamaged-to-Damaged Domain Translation for Structural Health Monitoring and Damage Detection. (arXiv:2202.07831v4 [cs.LG] UPDATED)
88. A Review of Emerging Research Directions in Abstract Visual Reasoning. (arXiv:2202.10284v2 [cs.AI] UPDATED)
89. NetRCA: An Effective Network Fault Cause Localization Algorithm. (arXiv:2202.11269v2 [cs.LG] UPDATED)
90. A fair pricing model via adversarial learning. (arXiv:2202.12008v2 [stat.ML] UPDATED)
91. DoCoGen: Domain Counterfactual Generation for Low Resource Domain Adaptation. (arXiv:2202.12350v2 [cs.CL] UPDATED)
92. Deep Learning, Natural Language Processing, and Explainable Artificial Intelligence in the Biomedical Domain. (arXiv:2202.12678v2 [cs.AI] UPDATED)
93. Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v2 [cs.LG] UPDATED)
94. Weakly Supervised Correspondence Learning. (arXiv:2203.00904v2 [cs.RO] UPDATED)
95. A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems. (arXiv:2203.01387v2 [cs.LG] UPDATED)
96. Crossed-Time Delay Neural Network for Speaker Recognition. (arXiv:2006.00452v3 [eess.AS] CROSS LISTED)
97. MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial Intelligence. (arXiv:2107.06708v1 [cs.SE] CROSS LISTED)

