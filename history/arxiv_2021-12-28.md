# Your interest papers
---
## cs.CV
---
### Self-Gated Memory Recurrent Network for Efficient Scalable HDR Deghosting. (arXiv:2112.13050v1 [cs.CV])
- Authors : Ram Prabhakar, Susmit Agrawal, Venkatesh Babu
- Link : [http://arxiv.org/abs/2112.13050](http://arxiv.org/abs/2112.13050)
> ABSTRACT  :  We propose a novel recurrent network-based **HDR** deghosting method for fusing arbitrary length dynamic sequences. The proposed method uses convolutional and recurrent architectures to generate visually pleasing, ghosting-free **HDR** images. We introduce a new recurrent cell architecture, namely Self-Gated Memory (SGM) cell, that outperforms the standard LSTM cell while containing fewer parameters and having faster running times. In the SGM cell, the information flow through a gate is controlled by multiplying the gate's output by a function of itself. Additionally, we use two SGM cells in a bidirectional setting to improve output quality. The proposed approach achieves state-of-the-art performance compared to existing **HDR** deghosting methods quantitatively across three publicly available datasets while simultaneously achieving scalability to fuse variable-length input sequence without necessitating re-training. Through extensive ablations, we demonstrate the importance of individual components in our proposed approach. The code is available at https://val.cds.iisc.ac.in/**HDR**/**HDR**RNN/index.html.  
### Invertible Network for Unpaired Low-light Image Enhancement. (arXiv:2112.13107v1 [cs.CV])
- Authors : Jize Zhang, Haolin Wang, Xiaohe Wu, Wangmeng Zuo
- Link : [http://arxiv.org/abs/2112.13107](http://arxiv.org/abs/2112.13107)
> ABSTRACT  :  Existing unpaired **low-light** image **enhancement** approaches prefer to employ the two-way GAN framework, in which two CNN generators are deployed for **enhancement** and degradation separately. However, such data-driven models ignore the inherent characteristics of transformation between the low and normal light images, leading to unstable training and artifacts. Here, we propose to leverage the invertible network to enhance **low-light** image in forward process and degrade the normal-light one inversely with unpaired learning. The generated and real images are then fed into discriminators for adversarial learning. In addition to the adversarial loss, we design various loss functions to ensure the stability of training and preserve more image details. Particularly, a reversibility loss is introduced to alleviate the over-exposure problem. Moreover, we present a progressive self-guided **enhancement** process for **low-light** images and achieve favorable performance against the SOTAs.  
### DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks. (arXiv:2112.13191v1 [eess.IV])
- Authors : Ziyang Liu, Zhengguo Li, Xingming Wu, Zhong Liu, Weihai Chen
- Link : [http://arxiv.org/abs/2112.13191](http://arxiv.org/abs/2112.13191)
> ABSTRACT  :  The generative adversarial network (GAN) is successfully applied to study the perceptual single image superresolution (SISR). However, the GAN often tends to generate images with high frequency details being inconsistent with the real ones. Inspired by conventional detail **enhancement** algorithms, we propose a novel prior knowledge, the detail prior, to assist the GAN in alleviating this problem and restoring more realistic details. The proposed method, named DSRGAN, includes a well designed detail extraction algorithm to capture the most important high frequency information from images. Then, two discriminators are utilized for supervision on image-domain and detail-domain **restoration**s, respectively. The DSRGAN merges the restored detail into the final output via a detail **enhancement** manner. The special design of DSRGAN takes advantages from both the model-based conventional algorithm and the data-driven deep learning network. Experimental results demonstrate that the DSRGAN outperforms the state-of-the-art SISR methods on perceptual metrics and achieves comparable results in terms of fidelity metrics simultaneously. Following the DSRGAN, it is feasible to incorporate other conventional image processing algorithms into a deep learning network to form a model-based deep SISR.  
### Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression. (arXiv:2112.13227v1 [eess.IV])
- Authors : Mu Li, **Kede Ma**, Jinxing Li, David Zhang
- Link : [http://arxiv.org/abs/2112.13227](http://arxiv.org/abs/2112.13227)
> ABSTRACT  :  Although equirectangular projection (ERP) is a convenient form to store omnidirectional images (also known as 360-degree images), it is neither equal-area nor conformal, thus not friendly to subsequent visual communication. In the context of image compression, ERP will over-sample and deform things and stuff near the poles, making it difficult for perceptually optimal bit allocation. In conventional 360-degree image compression, techniques such as region-wise packing and tiled representation are introduced to alleviate the over-sampling problem, achieving limited success. In this paper, we make one of the first attempts to learn deep neural networks for omnidirectional image compression. We first describe parametric pseudocylindrical representation as a generalization of common pseudocylindrical map projections. A computationally tractable greedy method is presented to determine the (sub)-optimal configuration of the pseudocylindrical representation in terms of a novel proxy objective for rate-distortion performance. We then propose pseudocylindrical convolutions for 360-degree image compression. Under reasonable constraints on the parametric representation, the pseudocylindrical convolution can be efficiently implemented by standard convolution with the so-called pseudocylindrical padding. To demonstrate the feasibility of our idea, we implement an end-to-end 360-degree image compression system, consisting of the learned pseudocylindrical representation, an analysis transform, a non-uniform quantizer, a synthesis transform, and an entropy model. Experimental results on $19,790$ omnidirectional images show that our method achieves consistently better rate-distortion performance than the competing methods. Moreover, the visual quality by our method is significantly improved for all images at all bitrates.  
### Estimating Parameters of the Tree Root in Heterogeneous Soil Environments via Mask-Guided Multi-Polarimetric Integration Neural Network. (arXiv:2112.13494v1 [cs.CV])
- Authors : Han Sun, Yee Hui, Qiqi Dai, **Chongyi Li**, Genevieve Ow, Mohamed Lokman, Mohd Yusof
- Link : [http://arxiv.org/abs/2112.13494](http://arxiv.org/abs/2112.13494)
> ABSTRACT  :  Ground-penetrating radar (GPR) has been used as a non-destructive tool for tree root inspection. Estimating root-related parameters from GPR radargrams greatly facilitates root health monitoring and imaging. However, the task of estimating root-related parameters is challenging as the root reflection is a complex function of multiple root parameters and root orientations. Existing methods can only estimate a single root parameter at a time without considering the influence of other parameters and root orientations, resulting in limited estimation accuracy under different root conditions. In addition, soil heterogeneity introduces clutter in GPR radargrams, making the data processing and interpretation even harder. To address these issues, a novel neural network architecture, called mask-guided multi-polarimetric integration neural network (MMI-Net), is proposed to automatically and simultaneously estimate multiple root-related parameters in heterogeneous soil environments. The MMI-Net includes two sub-networks: a MaskNet that predicts a mask to highlight the root reflection area to eliminate interfering environmental clutter, and a ParaNet that uses the predicted mask as guidance to integrate, extract, and emphasize informative features in multi-polarimetric radargrams for accurate estimation of five key root-related parameters. The parameters include the root depth, diameter, relative permittivity, horizontal and vertical orientation angles. Experimental results demonstrate that the proposed MMI-Net achieves high estimation accuracy in these root-related parameters. This is the first work that takes the combined contributions of root parameters and spatial orientations into account and simultaneously estimates multiple root-related parameters. The data and code implemented in the paper can be found at https://haihan-sun.github.io/GPR.html.  
### Image Edge Restoring Filter. (arXiv:2112.13540v1 [cs.CV])
- Authors : Qian Liu, Yongpeng Li, Zhihang Wang
- Link : [http://arxiv.org/abs/2112.13540](http://arxiv.org/abs/2112.13540)
> ABSTRACT  :  In computer vision, image processing and computer graphics, image smoothing filtering is a very basic and important task and to be expected possessing good edge-preserving smoothing property. Here we address the problem that the edge-preserving ability of many popular local smoothing filters needs to be improved. In this paper, we propose the image Edge Restoring Filter (ERF) to restore the blur edge pixels in the output of local smoothing filters to be clear. The proposed filter can been implemented after many local smoothing filter (such as Box filter, Gaussian filter, Bilateral Filter, Guided Filter and so on). The combinations of "original local smoothing filters + ERF" have better edge-preserving smoothing property than the original local smoothing filters. Experiments on image smoothing, image denoising and image **enhancement** demonstrate the excellent edges restoring ability of the proposed filter and good edgepreserving smoothing property of the combination "original local smoothing filters + ERF". The proposed filter would benefit a great variety of applications given that smoothing filtering is a high frequently used and fundamental operation.  
### IceNet for Interactive Contrast Enhancement. (arXiv:2109.05838v2 [eess.IV] UPDATED)
- Authors : Keunsoo Ko, Su Kim
- Link : [http://arxiv.org/abs/2109.05838](http://arxiv.org/abs/2109.05838)
> ABSTRACT  :  A CNN-based interactive contrast **enhancement** algorithm, called IceNet, is proposed in this work, which enables a user to adjust image contrast easily according to his or her preference. Specifically, a user provides a parameter for controlling the global brightness and two types of scribbles to darken or brighten local regions in an image. Then, given these annotations, IceNet estimates a gamma map for the pixel-wise gamma correction. Finally, through color **restoration**, an enhanced image is obtained. The user may provide annotations iteratively to obtain a satisfactory image. IceNet is also capable of producing a personalized enhanced image automatically, which can serve as a basis for further adjustment if so desired. Moreover, to train IceNet effectively and reliably, we propose three differentiable losses. Extensive experiments show that IceNet can provide users with satisfactorily enhanced images.  
## eess.IV
---
### Invertible Network for Unpaired Low-light Image Enhancement. (arXiv:2112.13107v1 [cs.CV])
- Authors : Jize Zhang, Haolin Wang, Xiaohe Wu, Wangmeng Zuo
- Link : [http://arxiv.org/abs/2112.13107](http://arxiv.org/abs/2112.13107)
> ABSTRACT  :  Existing unpaired **low-light** image **enhancement** approaches prefer to employ the two-way GAN framework, in which two CNN generators are deployed for **enhancement** and degradation separately. However, such data-driven models ignore the inherent characteristics of transformation between the low and normal light images, leading to unstable training and artifacts. Here, we propose to leverage the invertible network to enhance **low-light** image in forward process and degrade the normal-light one inversely with unpaired learning. The generated and real images are then fed into discriminators for adversarial learning. In addition to the adversarial loss, we design various loss functions to ensure the stability of training and preserve more image details. Particularly, a reversibility loss is introduced to alleviate the over-exposure problem. Moreover, we present a progressive self-guided **enhancement** process for **low-light** images and achieve favorable performance against the SOTAs.  
### DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks. (arXiv:2112.13191v1 [eess.IV])
- Authors : Ziyang Liu, Zhengguo Li, Xingming Wu, Zhong Liu, Weihai Chen
- Link : [http://arxiv.org/abs/2112.13191](http://arxiv.org/abs/2112.13191)
> ABSTRACT  :  The generative adversarial network (GAN) is successfully applied to study the perceptual single image superresolution (SISR). However, the GAN often tends to generate images with high frequency details being inconsistent with the real ones. Inspired by conventional detail **enhancement** algorithms, we propose a novel prior knowledge, the detail prior, to assist the GAN in alleviating this problem and restoring more realistic details. The proposed method, named DSRGAN, includes a well designed detail extraction algorithm to capture the most important high frequency information from images. Then, two discriminators are utilized for supervision on image-domain and detail-domain **restoration**s, respectively. The DSRGAN merges the restored detail into the final output via a detail **enhancement** manner. The special design of DSRGAN takes advantages from both the model-based conventional algorithm and the data-driven deep learning network. Experimental results demonstrate that the DSRGAN outperforms the state-of-the-art SISR methods on perceptual metrics and achieves comparable results in terms of fidelity metrics simultaneously. Following the DSRGAN, it is feasible to incorporate other conventional image processing algorithms into a deep learning network to form a model-based deep SISR.  
### Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression. (arXiv:2112.13227v1 [eess.IV])
- Authors : Mu Li, **Kede Ma**, Jinxing Li, David Zhang
- Link : [http://arxiv.org/abs/2112.13227](http://arxiv.org/abs/2112.13227)
> ABSTRACT  :  Although equirectangular projection (ERP) is a convenient form to store omnidirectional images (also known as 360-degree images), it is neither equal-area nor conformal, thus not friendly to subsequent visual communication. In the context of image compression, ERP will over-sample and deform things and stuff near the poles, making it difficult for perceptually optimal bit allocation. In conventional 360-degree image compression, techniques such as region-wise packing and tiled representation are introduced to alleviate the over-sampling problem, achieving limited success. In this paper, we make one of the first attempts to learn deep neural networks for omnidirectional image compression. We first describe parametric pseudocylindrical representation as a generalization of common pseudocylindrical map projections. A computationally tractable greedy method is presented to determine the (sub)-optimal configuration of the pseudocylindrical representation in terms of a novel proxy objective for rate-distortion performance. We then propose pseudocylindrical convolutions for 360-degree image compression. Under reasonable constraints on the parametric representation, the pseudocylindrical convolution can be efficiently implemented by standard convolution with the so-called pseudocylindrical padding. To demonstrate the feasibility of our idea, we implement an end-to-end 360-degree image compression system, consisting of the learned pseudocylindrical representation, an analysis transform, a non-uniform quantizer, a synthesis transform, and an entropy model. Experimental results on $19,790$ omnidirectional images show that our method achieves consistently better rate-distortion performance than the competing methods. Moreover, the visual quality by our method is significantly improved for all images at all bitrates.  
### A Trained Regularization Approach Based on Born Iterative Method for Electromagnetic Imaging. (arXiv:2112.13367v1 [eess.IV])
- Authors : Abdulla Desmal
- Link : [http://arxiv.org/abs/2112.13367](http://arxiv.org/abs/2112.13367)
> ABSTRACT  :  A trained-based Born iterative method (TBIM) is developed for electromagnetic imaging (EMI) applications. The proposed TBIM consists of a nested loop; the outer loop executes TBIM iteration steps, while the inner loop executes a trained iterative shrinkage thresholding algorithm (TISTA). The applied TISTA runs linear Landweber iterations implemented with a trained regularization network designed based on U-net architecture. A normalization process was imposed in TISTA that made TISTA training applicable within the proposed TBIM. The iterative utilization of the regularization network in TISTA is a bottleneck that demands high memory allocation through the training process. Therefore TISTA within each TBIM step was trained separately. The TISTA regularization network in each TBIM step was initialized using the weights from the previous TBIM step. The above approach achieved high-quality image **restoration** after running few TBIM steps while maintained low memory allocation through the training process. The proposed framework can be extended to Newton or quasi-Newton schemes, where within each Newton iteration, a linear ill-posed problem is optimized that differs from one example to another. The numerical results illustrated in this work show the superiority of the proposed TBIM compared to the conventional sparse-based Born iterative method (SBIM).  
### IceNet for Interactive Contrast Enhancement. (arXiv:2109.05838v2 [eess.IV] UPDATED)
- Authors : Keunsoo Ko, Su Kim
- Link : [http://arxiv.org/abs/2109.05838](http://arxiv.org/abs/2109.05838)
> ABSTRACT  :  A CNN-based interactive contrast **enhancement** algorithm, called IceNet, is proposed in this work, which enables a user to adjust image contrast easily according to his or her preference. Specifically, a user provides a parameter for controlling the global brightness and two types of scribbles to darken or brighten local regions in an image. Then, given these annotations, IceNet estimates a gamma map for the pixel-wise gamma correction. Finally, through color **restoration**, an enhanced image is obtained. The user may provide annotations iteratively to obtain a satisfactory image. IceNet is also capable of producing a personalized enhanced image automatically, which can serve as a basis for further adjustment if so desired. Moreover, to train IceNet effectively and reliably, we propose three differentiable losses. Extensive experiments show that IceNet can provide users with satisfactorily enhanced images.  
## cs.LG
---
### Machine Learning-based Efficient Ventricular Tachycardia Detection Model of ECG Signal. (arXiv:2112.12956v1 [eess.SP])
- Authors : Pampa Howladar, Manodipan Sahoo
- Link : [http://arxiv.org/abs/2112.12956](http://arxiv.org/abs/2112.12956)
> ABSTRACT  :  In primary diagnosis and analysis of heart defects, an ECG signal plays a significant role. This paper presents a model for the prediction of ventricular tachycardia arrhythmia using noise filtering, a unique set of ECG features, and a machine learning-based classifier model. Before signal feature extraction, we detrend and denoise the signal to eliminate the noise for detecting features properly. After that necessary features have been extracted and necessary parameters related to these features are measured. Using these parameters, we prepared one efficient multiclass classifier model using a machine learning approach that can classify different types of ventricular tachycardia arrhythmias efficiently. Our results indicate that Logistic regression and Decision tree-based models are the most efficient machine learning models for detecting ventricular tachycardia arrhythmia. In order to diagnose heart diseases and find care for a patient, an early, reliable diagnosis of different types of arrhythmia is necessary. By implementing our proposed method, this work deals with the problem of reducing the misclassification of the critical signal related to ventricular tachycardia very efficiently. Experimental findings demonstrate satisfactory **enhancement**s and demonstrate high resilience to the algorithm that we have proposed. With this assistance, doctors can assess this type of arrhythmia of a patient early and take the right decision at the proper time.  
### A Trained Regularization Approach Based on Born Iterative Method for Electromagnetic Imaging. (arXiv:2112.13367v1 [eess.IV])
- Authors : Abdulla Desmal
- Link : [http://arxiv.org/abs/2112.13367](http://arxiv.org/abs/2112.13367)
> ABSTRACT  :  A trained-based Born iterative method (TBIM) is developed for electromagnetic imaging (EMI) applications. The proposed TBIM consists of a nested loop; the outer loop executes TBIM iteration steps, while the inner loop executes a trained iterative shrinkage thresholding algorithm (TISTA). The applied TISTA runs linear Landweber iterations implemented with a trained regularization network designed based on U-net architecture. A normalization process was imposed in TISTA that made TISTA training applicable within the proposed TBIM. The iterative utilization of the regularization network in TISTA is a bottleneck that demands high memory allocation through the training process. Therefore TISTA within each TBIM step was trained separately. The TISTA regularization network in each TBIM step was initialized using the weights from the previous TBIM step. The above approach achieved high-quality image **restoration** after running few TBIM steps while maintained low memory allocation through the training process. The proposed framework can be extended to Newton or quasi-Newton schemes, where within each Newton iteration, a linear ill-posed problem is optimized that differs from one example to another. The numerical results illustrated in this work show the superiority of the proposed TBIM compared to the conventional sparse-based Born iterative method (SBIM).  
### Mind the Gap: Cross-Lingual Information Retrieval with Hierarchical Knowledge Enhancement. (arXiv:2112.13510v1 [cs.IR])
- Authors : Fuwei Zhang, Zhao Zhang, Xiang Ao, Dehong Gao, Fuzhen Zhuang, Yi Wei, Qing He
- Link : [http://arxiv.org/abs/2112.13510](http://arxiv.org/abs/2112.13510)
> ABSTRACT  :  Cross-Lingual Information Retrieval (CLIR) aims to rank the documents written in a language different from the user's query. The intrinsic gap between different languages is an essential challenge for CLIR. In this paper, we introduce the multilingual knowledge graph (KG) to the CLIR task due to the sufficient information of entities in multiple languages. It is regarded as a "silver bullet" to simultaneously perform explicit alignment between queries and documents and also broaden the representations of queries. And we propose a model named CLIR with hierarchical knowledge **enhancement** (HIKE) for our task. The proposed model encodes the textual information in queries, documents and the KG with multilingual BERT, and incorporates the KG information in the query-document matching process with a hierarchical information fusion mechanism. Particularly, HIKE first integrates the entities and their neighborhood in KG into query representations with a knowledge-level fusion, then combines the knowledge from both source and target languages to further mitigate the linguistic gap with a language-level fusion. Finally, experimental results demonstrate that HIKE achieves substantial improvements over state-of-the-art competitors.  
### Graph Signal Restoration Using Nested Deep Algorithm Unrolling. (arXiv:2106.15910v2 [eess.SP] UPDATED)
- Authors : Masatoshi Nagahama, Koki Yamada, Yuichi Tanaka
- Link : [http://arxiv.org/abs/2106.15910](http://arxiv.org/abs/2106.15910)
> ABSTRACT  :  Graph signal processing is a ubiquitous task in many applications such as sensor, social, transportation and brain networks, point cloud processing, and graph neural networks. Often, graph signals are corrupted in the sensing process, thus requiring **restoration**. In this paper, we propose two graph signal **restoration** methods based on deep algorithm unrolling (DAU). First, we present a graph signal denoiser by unrolling iterations of the alternating direction method of multiplier (ADMM). We then suggest a general **restoration** method for linear degradation by unrolling iterations of Plug-and-Play ADMM (PnP-ADMM). In the second approach, the unrolled ADMM-based denoiser is incorporated as a submodule, leading to a nested DAU structure. The parameters in the proposed denoising/**restoration** methods are trainable in an end-to-end manner. Our approach is interpretable and keeps the number of parameters small since we only tune graph-independent regularization parameters. We overcome two main challenges in existing graph signal **restoration** methods: 1) limited performance of convex optimization algorithms due to fixed parameters which are often determined manually. 2) large number of parameters of graph neural networks that result in difficulty of training. Several experiments for graph signal denoising and interpolation are performed on synthetic and real-world data. The proposed methods show performance improvements over several existing techniques in terms of root mean squared error in both tasks.  
### An Investigation on Learning, Polluting, and Unlearning the Spam Emails for Lifelong Learning. (arXiv:2111.14609v2 [cs.LG] UPDATED)
- Authors : Nishchal Parne, Kyathi Puppaala, Nithish Bhupathi, Ripon Patgiri
- Link : [http://arxiv.org/abs/2111.14609](http://arxiv.org/abs/2111.14609)
> ABSTRACT  :  Machine unlearning for security is studied in this context. Several spam email detection methods exist, each of which employs a different algorithm to detect undesired spam emails. But these models are vulnerable to attacks. Many attackers exploit the model by polluting the data, which are trained to the model in various ways. So to act deftly in such situations model needs to readily unlearn the polluted data without the need for retraining. Retraining is impractical in most cases as there is already a massive amount of data trained to the model in the past, which needs to be trained again just for removing a small amount of polluted data, which is often significantly less than 1%. This problem can be solved by developing unlearning frameworks for all spam detection models. In this research, unlearning module is integrated into spam detection models that are based on Naive Bayes, Decision trees, and Random Forests algorithms. To assess the benefits of unlearning over retraining, three spam detection models are polluted and exploited by taking attackers' positions and proving models' vulnerability. Reduction in accuracy and true positive rates are shown in each case showing the effect of pollution on models. Then unlearning modules are integrated into the models, and polluted data is unlearned; on testing the models after unlearning, **restoration** of performance is seen. Also, unlearning and retraining times are compared with different pollution data sizes on all models. On analyzing the findings, it can be concluded that unlearning is considerably superior to retraining. Results show that unlearning is fast, easy to implement, easy to use, and effective.  
## cs.AI
---
### An Investigation on Learning, Polluting, and Unlearning the Spam Emails for Lifelong Learning. (arXiv:2111.14609v2 [cs.LG] UPDATED)
- Authors : Nishchal Parne, Kyathi Puppaala, Nithish Bhupathi, Ripon Patgiri
- Link : [http://arxiv.org/abs/2111.14609](http://arxiv.org/abs/2111.14609)
> ABSTRACT  :  Machine unlearning for security is studied in this context. Several spam email detection methods exist, each of which employs a different algorithm to detect undesired spam emails. But these models are vulnerable to attacks. Many attackers exploit the model by polluting the data, which are trained to the model in various ways. So to act deftly in such situations model needs to readily unlearn the polluted data without the need for retraining. Retraining is impractical in most cases as there is already a massive amount of data trained to the model in the past, which needs to be trained again just for removing a small amount of polluted data, which is often significantly less than 1%. This problem can be solved by developing unlearning frameworks for all spam detection models. In this research, unlearning module is integrated into spam detection models that are based on Naive Bayes, Decision trees, and Random Forests algorithms. To assess the benefits of unlearning over retraining, three spam detection models are polluted and exploited by taking attackers' positions and proving models' vulnerability. Reduction in accuracy and true positive rates are shown in each case showing the effect of pollution on models. Then unlearning modules are integrated into the models, and polluted data is unlearned; on testing the models after unlearning, **restoration** of performance is seen. Also, unlearning and retraining times are compared with different pollution data sizes on all models. On analyzing the findings, it can be concluded that unlearning is considerably superior to retraining. Results show that unlearning is fast, easy to implement, easy to use, and effective.  
# Paper List
---
## cs.CV
---
**136** new papers in cs.CV:-) 
1. Self-Attention Generative Adversarial Network for Iterative Reconstruction of CT Images. (arXiv:2112.12810v1 [eess.IV])
2. MDN-VO: Estimating Visual Odometry with Confidence. (arXiv:2112.12812v1 [cs.CV])
3. Multi-Camera Sensor Fusion for Visual Odometry using Deep Uncertainty Estimation. (arXiv:2112.12818v1 [cs.CV])
4. Dense anomaly detection by robust learning on synthetic negative data. (arXiv:2112.12833v1 [cs.CV])
5. Faster Deep Ensemble Averaging for Quantification of DNA Damage from Comet Assay Images With Uncertainty Estimates. (arXiv:2112.12839v1 [q-bio.QM])
6. Understanding the impact of class imbalance on the performance of chest x-ray image classifiers. (arXiv:2112.12843v1 [cs.CV])
7. HSPACE: Synthetic Parametric Humans Animated in Complex Environments. (arXiv:2112.12867v1 [cs.CV])
8. A formal approach to good practices in Pseudo-Labeling for Unsupervised Domain Adaptive Re-Identification. (arXiv:2112.12887v1 [cs.CV])
9. Cluster-guided Image Synthesis with Unconditional Models. (arXiv:2112.12911v1 [cs.CV])
10. Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition. (arXiv:2112.12916v1 [cs.CV])
11. Multi-initialization Optimization Network for Accurate 3D Human Pose and Shape Estimation. (arXiv:2112.12917v1 [cs.CV])
12. Not All Voxels Are Equal: Semantic Scene Completion from the Point-Voxel Perspective. (arXiv:2112.12925v1 [cs.CV])
13. Learning Aligned Cross-Modal Representation for Generalized Zero-Shot Classification. (arXiv:2112.12927v1 [cs.CV])
14. Realtime Global Attention Network for Semantic Segmentation. (arXiv:2112.12939v1 [cs.CV])
15. Deep ensembles in bioimage segmentation. (arXiv:2112.12955v1 [cs.CV])
16. SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v1 [cs.CV])
17. Doppler velocity-based algorithm for Clustering and Velocity Estimation of moving objects. (arXiv:2112.12984v1 [cs.RO])
18. iSeg3D: An Interactive 3D Shape Segmentation Tool. (arXiv:2112.12988v1 [cs.CV])
19. Domain-Aware Continual Zero-Shot Learning. (arXiv:2112.12989v1 [cs.CV])
20. US-GAN: On the importance of Ultimate Skip Connection for Facial Expression Synthesis. (arXiv:2112.13002v1 [cs.CV])
21. Continuous Spectral Reconstruction from RGB Images via Implicit Neural Representation. (arXiv:2112.13003v1 [cs.CV])
22. Benchmarking Pedestrian Odometry: The Brown Pedestrian Odometry Dataset (BPOD). (arXiv:2112.13018v1 [cs.CV])
23. Grounding Linguistic Commands to Navigable Regions. (arXiv:2112.13031v1 [cs.CV])
24. Channel-Wise Attention-Based Network for Self-Supervised Monocular Depth Estimation. (arXiv:2112.13047v1 [cs.CV])
25. Self-Gated Memory Recurrent Network for Efficient Scalable HDR Deghosting. (arXiv:2112.13050v1 [cs.CV])
26. Generalized Wasserstein Dice Loss, Test-time Augmentation, and Transformers for the BraTS 2021 challenge. (arXiv:2112.13054v1 [eess.IV])
27. NIP: Neuron-level Inverse Perturbation Against Adversarial Attacks. (arXiv:2112.13060v1 [cs.CV])
28. CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing. (arXiv:2112.13064v1 [cs.CR])
29. Virtuoso: Video-based Intelligence for real-time tuning on SOCs. (arXiv:2112.13076v1 [cs.CV])
30. Multi-Scale Feature Fusion: Learning Better Semantic Segmentation for Road Pothole Detection. (arXiv:2112.13082v1 [cs.CV])
31. SimViT: Exploring a Simple Vision Transformer with sliding windows. (arXiv:2112.13085v1 [cs.CV])
32. Invertible Network for Unpaired Low-light Image Enhancement. (arXiv:2112.13107v1 [cs.CV])
33. Ultrasound Speckle Suppression and Denoising using MRI-derived Normalizing Flow Priors. (arXiv:2112.13110v1 [eess.SP])
34. The Curse of Zero Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence. (arXiv:2112.13121v1 [cs.LG])
35. Does MAML Only Work via Feature Re-use? A Data Centric Perspective. (arXiv:2112.13137v1 [cs.LG])
36. Reconstructing Compact Building Models from Point Clouds Using Deep Implicit Fields. (arXiv:2112.13142v1 [cs.CV])
37. Fast and Scalable Computation of the Forward and Inverse Discrete Periodic Radon Transform. (arXiv:2112.13149v1 [cs.AR])
38. Fast 2D Convolutions and Cross-Correlations Using Scalable Architectures. (arXiv:2112.13150v1 [cs.AR])
39. Semantic Clustering based Deduction Learning for Image Recognition and Classification. (arXiv:2112.13165v1 [cs.CV])
40. DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks. (arXiv:2112.13191v1 [eess.IV])
41. Network-Aware 5G Edge Computing for Object Detection: Augmenting Wearables to "See'' More, Farther and Faster. (arXiv:2112.13194v1 [eess.IV])
42. Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression. (arXiv:2112.13227v1 [eess.IV])
43. Evolutionary Generation of Visual Motion Illusions. (arXiv:2112.13243v1 [cs.NE])
44. Artifact Reduction in Fundus Imaging using Cycle Consistent Adversarial Neural Networks. (arXiv:2112.13264v1 [eess.IV])
45. Unsupervised Clustering Active Learning for Person Re-identification. (arXiv:2112.13308v1 [cs.CV])
46. Learning Cross-Scale Prediction for Efficient Neural Video Compression. (arXiv:2112.13309v1 [eess.IV])
47. Miti-DETR: Object Detection based on Transformers with Mitigatory Self-Attention Convergence. (arXiv:2112.13310v1 [cs.CV])
48. Continuous Offline Handwriting Recognition using Deep Learning Models. (arXiv:2112.13328v1 [cs.CV])
49. It\^{o}-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives. (arXiv:2112.13339v1 [stat.ML])
50. AlertTrap: A study on object detection in remote insects trap monitoring system using on-the-edge deep learning platform. (arXiv:2112.13341v1 [cs.CV])
51. Delivery Issues Identification from Customer Feedback Data. (arXiv:2112.13372v1 [cs.CL])
52. Sinogram upsampling using Primal-Dual UNet for undersampled CT and radial MRI reconstruction. (arXiv:2112.13443v1 [eess.IV])
53. PreDisM: Pre-Disaster Modelling With CNN Ensembles for At-Risk Communities. (arXiv:2112.13465v1 [cs.CV])
54. Video Joint Modelling Based on Hierarchical Transformer for Co-summarization. (arXiv:2112.13478v1 [cs.CV])
55. A Compact Neural Network-based Algorithm for Robust Image Watermarking. (arXiv:2112.13491v1 [cs.CV])
56. Vision Transformer for Small-Size Datasets. (arXiv:2112.13492v1 [cs.CV])
57. Estimating Parameters of the Tree Root in Heterogeneous Soil Environments via Mask-Guided Multi-Polarimetric Integration Neural Network. (arXiv:2112.13494v1 [cs.CV])
58. MSHT: Multi-stage Hybrid Transformer for the ROSE Image Analysis of Pancreatic Cancer. (arXiv:2112.13513v1 [eess.IV])
59. Dual Contrastive Learning for General Face Forgery Detection. (arXiv:2112.13522v1 [cs.CV])
60. Learning Generative Vision Transformer with Energy-Based Latent Space for Saliency Prediction. (arXiv:2112.13528v1 [cs.CV])
61. Adversarial Attack for Asynchronous Event-based Data. (arXiv:2112.13534v1 [cs.CV])
62. Meta-Learned Feature Critics for Domain Generalized Semantic Segmentation. (arXiv:2112.13538v1 [cs.CV])
63. Few-Shot Classification in Unseen Domains by Episodic Meta-Learning Across Visual Domains. (arXiv:2112.13539v1 [cs.CV])
64. Image Edge Restoring Filter. (arXiv:2112.13540v1 [cs.CV])
65. ViR:the Vision Reservoir. (arXiv:2112.13545v1 [cs.CV])
66. PRIME: A Few Primitives Can Boost Robustness to Common Corruptions. (arXiv:2112.13547v1 [cs.CV])
67. Responsive Listening Head Generation: A Benchmark Dataset and Baseline. (arXiv:2112.13548v1 [cs.CV])
68. Learning Robust and Lightweight Model through Separable Structured Transformations. (arXiv:2112.13551v1 [cs.CV])
69. Classification of Histopathology Images of Lung Cancer Using Convolutional Neural Network (CNN). (arXiv:2112.13553v1 [eess.IV])
70. DAM-AL: Dilated Attention Mechanism with Attention Loss for 3D Infant Brain Image Segmentation. (arXiv:2112.13559v1 [eess.IV])
71. Hard Example Guided Hashing for Image Retrieval. (arXiv:2112.13565v1 [cs.CV])
72. Vegetation Stratum Occupancy Prediction from Airborne LiDAR 3D Point Clouds. (arXiv:2112.13583v1 [cs.CV])
73. Multimodal Image Synthesis and Editing: A Survey. (arXiv:2112.13592v1 [cs.CV])
74. Depth estimation of endoscopy using sim-to-real transfer. (arXiv:2112.13595v1 [eess.IV])
75. An Empirical Study of Adder Neural Networks for Object Detection. (arXiv:2112.13608v1 [cs.CV])
76. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v1 [eess.IV])
77. AdaptivePose: Human Parts as Adaptive Points. (arXiv:2112.13635v1 [cs.CV])
78. Self-normalized Classification of Parkinson's Disease DaTscan Images. (arXiv:2112.13637v1 [eess.IV])
79. Understanding the Perceived Quality of Video Predictions. (arXiv:2005.00356v5 [eess.IV] UPDATED)
80. Attentive WaveBlock: Complementarity-enhanced Mutual Networks for Unsupervised Domain Adaptation in Person Re-identification and Beyond. (arXiv:2006.06525v3 [cs.CV] UPDATED)
81. The Elements of End-to-end Deep Face Recognition: A Survey of Recent Advances. (arXiv:2009.13290v4 [cs.CV] UPDATED)
82. Distributionally Robust Learning for Uncertainty Calibration under Domain Shift. (arXiv:2010.05784v3 [cs.LG] UPDATED)
83. Hand-Based Person Identification using Global and Part-Aware Deep Feature Representation Learning. (arXiv:2101.05260v7 [cs.CV] UPDATED)
84. Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning. (arXiv:2101.08732v2 [cs.LG] UPDATED)
85. Anytime 3D Object Reconstruction using Multi-modal Variational Autoencoder. (arXiv:2101.10391v3 [cs.CV] UPDATED)
86. Uncertainty-Aware Semi-Supervised Method Using Large Unlabeled and Limited Labeled COVID-19 Data. (arXiv:2102.06388v2 [eess.IV] UPDATED)
87. Reconstructing Recognizable 3D Face Shapes based on 3D Morphable Models. (arXiv:2104.03515v2 [cs.CV] UPDATED)
88. Skeleton-based Hand-Gesture Recognition with Lightweight Graph Convolutional Networks. (arXiv:2104.04255v2 [cs.CV] UPDATED)
89. Learning from 2D: Contrastive Pixel-to-Point Knowledge Transfer for 3D Pretraining. (arXiv:2104.04687v3 [cs.CV] UPDATED)
90. Learning Chebyshev Basis in Graph Convolutional Networks for Skeleton-based Action Recognition. (arXiv:2104.05482v2 [cs.CV] UPDATED)
91. Time series forecasting of new cases and new deaths rate for COVID-19 using deep learning methods. (arXiv:2104.15007v3 [cs.LG] UPDATED)
92. Non-contact Pain Recognition from Video Sequences with Remote Physiological Measurements Prediction. (arXiv:2105.08822v2 [cs.CV] UPDATED)
93. Unsupervised Visual Representation Learning by Online Constrained K-Means. (arXiv:2105.11527v2 [cs.CV] UPDATED)
94. Robust Mutual Learning for Semi-supervised Semantic Segmentation. (arXiv:2106.00609v2 [cs.CV] UPDATED)
95. ViTAE: Vision Transformer Advanced by Exploring Intrinsic Inductive Bias. (arXiv:2106.03348v4 [cs.CV] UPDATED)
96. Improved Transformer for High-Resolution GANs. (arXiv:2106.07631v3 [cs.CV] UPDATED)
97. Action Transformer: A Self-Attention Model for Short-Time Pose-Based Human Action Recognition. (arXiv:2107.00606v5 [cs.CV] UPDATED)
98. CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v3 [cs.LG] UPDATED)
99. eGHWT: The Extended Generalized Haar-Walsh Transform. (arXiv:2107.05121v3 [eess.SP] UPDATED)
100. ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A case study for skin lesion classification. (arXiv:2107.12734v2 [cs.CV] UPDATED)
101. Discovering "Semantics" in Super-Resolution Networks. (arXiv:2108.00406v2 [cs.CV] UPDATED)
102. Multi-Branch with Attention Network for Hand-Based Person Recognition. (arXiv:2108.02234v2 [cs.CV] UPDATED)
103. Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v2 [cs.CV] UPDATED)
104. Panoptic nuScenes: A Large-Scale Benchmark for LiDAR Panoptic Segmentation and Tracking. (arXiv:2109.03805v3 [cs.CV] UPDATED)
105. IceNet for Interactive Contrast Enhancement. (arXiv:2109.05838v2 [eess.IV] UPDATED)
106. LGD: Label-guided Self-distillation for Object Detection. (arXiv:2109.11496v2 [cs.CV] UPDATED)
107. Joint Progressive and Coarse-to-fine Registration of Brain MRI via Deformation Field Integration and Non-Rigid Feature Fusion. (arXiv:2109.12384v2 [eess.IV] UPDATED)
108. Unsolved Problems in ML Safety. (arXiv:2109.13916v3 [cs.LG] UPDATED)
109. 3D Pose Transfer with Correspondence Learning and Mesh Refinement. (arXiv:2109.15025v6 [cs.CV] UPDATED)
110. Domain-Specific Bias Filtering for Single Labeled Domain Generalization. (arXiv:2110.00726v2 [cs.CV] UPDATED)
111. Optimized U-Net for Brain Tumor Segmentation. (arXiv:2110.03352v2 [eess.IV] UPDATED)
112. Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v3 [cs.CV] UPDATED)
113. Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study. (arXiv:2111.00698v5 [eess.IV] UPDATED)
114. Recognizing Vector Graphics without Rasterization. (arXiv:2111.03281v3 [cs.CV] UPDATED)
115. Rethink Dilated Convolution for Real-time Semantic Segmentation. (arXiv:2111.09957v2 [cs.CV] UPDATED)
116. Denoised Internal Models: a Brain-Inspired Autoencoder against Adversarial Attacks. (arXiv:2111.10844v3 [cs.CV] UPDATED)
117. Computer Vision User Entity Behavior Analytics. (arXiv:2111.13176v2 [cs.CV] UPDATED)
118. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v3 [cs.CV] UPDATED)
119. High Quality Segmentation for Ultra High-resolution Images. (arXiv:2111.14482v3 [cs.CV] UPDATED)
120. Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v2 [cs.CV] UPDATED)
121. Diffusion Models for Implicit Image Segmentation Ensembles. (arXiv:2112.03145v2 [cs.CV] UPDATED)
122. Top-Down Deep Clustering with Multi-generator GANs. (arXiv:2112.03398v2 [cs.LG] UPDATED)
123. Activation to Saliency: Forming High-Quality Labels for Completely Unsupervised Salient Object Detection. (arXiv:2112.03650v3 [cs.CV] UPDATED)
124. MinkLoc3D-SI: 3D LiDAR place recognition with sparse convolutions, spherical coordinates, and intensity. (arXiv:2112.06539v2 [cs.RO] UPDATED)
125. Ensemble CNN Networks for GBM Tumors Segmentation using Multi-parametric MRI. (arXiv:2112.06554v2 [cs.CV] UPDATED)
126. Simple and Robust Loss Design for Multi-Label Learning with Missing Labels. (arXiv:2112.07368v2 [cs.LG] UPDATED)
127. Homography Decomposition Networks for Planar Object Tracking. (arXiv:2112.07909v3 [cs.CV] UPDATED)
128. DeePaste -- Inpainting for Pasting. (arXiv:2112.10600v2 [cs.CV] UPDATED)
129. MPViT: Multi-Path Vision Transformer for Dense Prediction. (arXiv:2112.11010v2 [cs.CV] UPDATED)
130. EPNet++: Cascade Bi-directional Fusion for Multi-Modal 3D Object Detection. (arXiv:2112.11088v2 [cs.CV] UPDATED)
131. Efficient Registration of Forest Point Clouds by Global Matching of Relative Stem Positions. (arXiv:2112.11121v2 [cs.CV] UPDATED)
132. YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles. (arXiv:2112.11798v2 [cs.CV] UPDATED)
133. A Discriminative Single-Shot Segmentation Network for Visual Object Tracking. (arXiv:2112.11846v2 [cs.CV] UPDATED)
134. Dual Path Structural Contrastive Embeddings for Learning Novel Objects. (arXiv:2112.12359v2 [cs.CV] UPDATED)
135. LaTr: Layout-Aware Transformer for Scene-Text VQA. (arXiv:2112.12494v2 [cs.CV] UPDATED)
136. BANMo: Building Animatable 3D Neural Models from Many Casual Videos. (arXiv:2112.12761v2 [cs.CV] UPDATED)
## eess.IV
---
**38** new papers in eess.IV:-) 
1. Self-Attention Generative Adversarial Network for Iterative Reconstruction of CT Images. (arXiv:2112.12810v1 [eess.IV])
2. Faster Deep Ensemble Averaging for Quantification of DNA Damage from Comet Assay Images With Uncertainty Estimates. (arXiv:2112.12839v1 [q-bio.QM])
3. US-GAN: On the importance of Ultimate Skip Connection for Facial Expression Synthesis. (arXiv:2112.13002v1 [cs.CV])
4. Generalized Wasserstein Dice Loss, Test-time Augmentation, and Transformers for the BraTS 2021 challenge. (arXiv:2112.13054v1 [eess.IV])
5. Invertible Network for Unpaired Low-light Image Enhancement. (arXiv:2112.13107v1 [cs.CV])
6. Fast and Scalable Computation of the Forward and Inverse Discrete Periodic Radon Transform. (arXiv:2112.13149v1 [cs.AR])
7. Fast 2D Convolutions and Cross-Correlations Using Scalable Architectures. (arXiv:2112.13150v1 [cs.AR])
8. DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks. (arXiv:2112.13191v1 [eess.IV])
9. Network-Aware 5G Edge Computing for Object Detection: Augmenting Wearables to "See'' More, Farther and Faster. (arXiv:2112.13194v1 [eess.IV])
10. Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression. (arXiv:2112.13227v1 [eess.IV])
11. Artifact Reduction in Fundus Imaging using Cycle Consistent Adversarial Neural Networks. (arXiv:2112.13264v1 [eess.IV])
12. Deep-learned speckle pattern and its application to ghost imaging. (arXiv:2112.13293v1 [eess.IV])
13. Imaging through scattering media via spatial-temporal encoded pattern illumination. (arXiv:2112.13303v1 [physics.optics])
14. Learning Cross-Scale Prediction for Efficient Neural Video Compression. (arXiv:2112.13309v1 [eess.IV])
15. A Trained Regularization Approach Based on Born Iterative Method for Electromagnetic Imaging. (arXiv:2112.13367v1 [eess.IV])
16. Deep Curriculum Learning for PolSAR Image Classification. (arXiv:2112.13426v1 [eess.IV])
17. Sinogram upsampling using Primal-Dual UNet for undersampled CT and radial MRI reconstruction. (arXiv:2112.13443v1 [eess.IV])
18. Bilingual Speech Recognition by Estimating Speaker Geometry from Video Data. (arXiv:2112.13463v1 [cs.SD])
19. MSHT: Multi-stage Hybrid Transformer for the ROSE Image Analysis of Pancreatic Cancer. (arXiv:2112.13513v1 [eess.IV])
20. Classification of Histopathology Images of Lung Cancer Using Convolutional Neural Network (CNN). (arXiv:2112.13553v1 [eess.IV])
21. DAM-AL: Dilated Attention Mechanism with Attention Loss for 3D Infant Brain Image Segmentation. (arXiv:2112.13559v1 [eess.IV])
22. Depth estimation of endoscopy using sim-to-real transfer. (arXiv:2112.13595v1 [eess.IV])
23. Generation of Synthetic Rat Brain MRI scans with a 3D Enhanced Alpha-GAN. (arXiv:2112.13626v1 [eess.IV])
24. Self-normalized Classification of Parkinson's Disease DaTscan Images. (arXiv:2112.13637v1 [eess.IV])
25. Radiomic biomarker extracted from PI-RADS 3 patients support more e\`icient and robust prostate cancer diagnosis: a multi-center study. (arXiv:2112.13686v1 [eess.IV])
26. Infant Brain Age Classification: 2D CNN Outperforms 3D CNN in Small Dataset. (arXiv:2112.13811v1 [eess.IV])
27. Understanding the Perceived Quality of Video Predictions. (arXiv:2005.00356v5 [eess.IV] UPDATED)
28. Uncertainty-Aware Semi-Supervised Method Using Large Unlabeled and Limited Labeled COVID-19 Data. (arXiv:2102.06388v2 [eess.IV] UPDATED)
29. Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v2 [cs.CV] UPDATED)
30. IceNet for Interactive Contrast Enhancement. (arXiv:2109.05838v2 [eess.IV] UPDATED)
31. Joint Progressive and Coarse-to-fine Registration of Brain MRI via Deformation Field Integration and Non-Rigid Feature Fusion. (arXiv:2109.12384v2 [eess.IV] UPDATED)
32. Optimized U-Net for Brain Tumor Segmentation. (arXiv:2110.03352v2 [eess.IV] UPDATED)
33. Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study. (arXiv:2111.00698v5 [eess.IV] UPDATED)
34. Recognizing Vector Graphics without Rasterization. (arXiv:2111.03281v3 [cs.CV] UPDATED)
35. Rethink Dilated Convolution for Real-time Semantic Segmentation. (arXiv:2111.09957v2 [cs.CV] UPDATED)
36. Ensemble CNN Networks for GBM Tumors Segmentation using Multi-parametric MRI. (arXiv:2112.06554v2 [cs.CV] UPDATED)
37. Quantitative phase imaging through an ultra-thin lensless fiber endoscope. (arXiv:2112.12055v2 [physics.optics] UPDATED)
38. Artifacts in optical projection tomography due to refractive index mismatch: model and correction. (arXiv:2112.12602v2 [physics.optics] UPDATED)
## cs.LG
---
**221** new papers in cs.LG:-) 
1. Understanding and Measuring Robustness of Multimodal Learning. (arXiv:2112.12792v1 [cs.LG])
2. A Multi-View Framework for BGP Anomaly Detection via Graph Attention Network. (arXiv:2112.12793v1 [cs.LG])
3. Bi-Directional Recurrent Neural Ordinary Differential Equations for Social Media Text Classification. (arXiv:2112.12809v1 [cs.LG])
4. Graph Few-shot Class-incremental Learning. (arXiv:2112.12819v1 [cs.LG])
5. Faster Deep Ensemble Averaging for Quantification of DNA Damage from Comet Assay Images With Uncertainty Estimates. (arXiv:2112.12839v1 [q-bio.QM])
6. Reinforced Meta-path Selection for Recommendation on Heterogeneous Information Networks. (arXiv:2112.12845v1 [cs.IR])
7. SoK: Privacy-preserving Deep Learning with Homomorphic Encryption. (arXiv:2112.12855v1 [cs.CR])
8. Sparsified Secure Aggregation for Privacy-Preserving Federated Learning. (arXiv:2112.12872v1 [cs.LG])
9. A machine learning analysis of the relationship between some underlying medical conditions and COVID-19 susceptibility. (arXiv:2112.12901v1 [cs.LG])
10. Optimal Variable Clustering for High-Dimensional Matrix Valued Data. (arXiv:2112.12909v1 [stat.ML])
11. TSAX is Trending. (arXiv:2112.12912v1 [cs.LG])
12. Spoiler in a Textstack: How Much Can Transformers Help?. (arXiv:2112.12913v1 [cs.CL])
13. Constrained tensor factorization for computational phenotyping and mortality prediction in patients with cancer. (arXiv:2112.12933v1 [cs.LG])
14. Counterfactual Memorization in Neural Language Models. (arXiv:2112.12938v1 [cs.CL])
15. Supraventricular Tachycardia Detection and Classification Model of ECG signal Using Machine Learning. (arXiv:2112.12953v1 [eess.SP])
16. Machine Learning-based Efficient Ventricular Tachycardia Detection Model of ECG Signal. (arXiv:2112.12956v1 [eess.SP])
17. Optimal Model Averaging of Support Vector Machines in Diverging Model Spaces. (arXiv:2112.12961v1 [stat.ML])
18. Error-bounded Approximate Time Series Joins using Compact Dictionary Representations of Time Series. (arXiv:2112.12965v1 [cs.DB])
19. Machine learning for Earth System Science (ESS): A survey, status and future directions for South Asia. (arXiv:2112.12966v1 [cs.LG])
20. SGTR: End-to-end Scene Graph Generation with Transformer. (arXiv:2112.12970v1 [cs.CV])
21. Integrating Physics-Based Modeling with Machine Learning for Lithium-Ion Batteries. (arXiv:2112.12979v1 [cs.CE])
22. Disentanglement by Cyclic Reconstruction. (arXiv:2112.12980v1 [cs.LG])
23. DeepGANTT: A Scalable Deep Learning Scheduler for Backscatter Networks. (arXiv:2112.12985v1 [cs.LG])
24. Is Importance Weighting Incompatible with Interpolating Classifiers?. (arXiv:2112.12986v1 [cs.LG])
25. Domain-Aware Continual Zero-Shot Learning. (arXiv:2112.12989v1 [cs.CV])
26. Toeplitz Least Squares Problems, Fast Algorithms and Big Data. (arXiv:2112.12994v1 [stat.ML])
27. DP-UTIL: Comprehensive Utility Analysis of Differential Privacy in Machine Learning. (arXiv:2112.12998v1 [cs.CR])
28. Total Energy Shaping with Neural Interconnection and Damping Assignment -- Passivity Based Control. (arXiv:2112.12999v1 [eess.SY])
29. Stochastic Learning Equation using Monotone Increasing Resolution of Quantization. (arXiv:2112.13006v1 [cs.LG])
30. A machine learning pipeline for autonomous numerical analytic continuation of Dyson-Schwinger equations. (arXiv:2112.13011v1 [hep-ph])
31. Noninvasive Fetal Electrocardiography: Models, Technologies and Algorithms. (arXiv:2112.13021v1 [q-bio.QM])
32. DARTS without a Validation Set: Optimizing the Marginal Likelihood. (arXiv:2112.13023v1 [cs.LG])
33. Gaussian Process Bandits with Aggregated Feedback. (arXiv:2112.13029v1 [cs.LG])
34. Channel-Wise Attention-Based Network for Self-Supervised Monocular Depth Estimation. (arXiv:2112.13047v1 [cs.CV])
35. Tri-Transformer Hawkes Process: Three Heads are better than one. (arXiv:2112.13058v1 [cs.LG])
36. Dual Hierarchical Attention Networks for Bi-typed Heterogeneous Graph Learning. (arXiv:2112.13078v1 [cs.LG])
37. Multi-Scale Feature Fusion: Learning Better Semantic Segmentation for Road Pothole Detection. (arXiv:2112.13082v1 [cs.CV])
38. Faster Rates for Compressed Federated Learning with Client-Variance Reduction. (arXiv:2112.13097v1 [cs.LG])
39. Fine-Tuning Data Structures for Analytical Query Processing. (arXiv:2112.13099v1 [cs.DB])
40. Accelerated and instance-optimal policy evaluation with linear function approximation. (arXiv:2112.13109v1 [stat.ML])
41. Measuring Quality of DNA Sequence Data via Degradation. (arXiv:2112.13111v1 [stat.ML])
42. A Survey on Interpretable Reinforcement Learning. (arXiv:2112.13112v1 [cs.LG])
43. Application of Markov Structure of Genomes to Outlier Identification and Read Classification. (arXiv:2112.13117v1 [q-bio.GN])
44. The Curse of Zero Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence. (arXiv:2112.13121v1 [cs.LG])
45. Does MAML Only Work via Feature Re-use? A Data Centric Perspective. (arXiv:2112.13137v1 [cs.LG])
46. On the Unreasonable Efficiency of State Space Clustering in Personalization Tasks. (arXiv:2112.13141v1 [cs.LG])
47. A Neural Framework for Learning Subgraph and Graph Similarity Measures. (arXiv:2112.13143v1 [cs.LG])
48. Cyberattack Detection in Large-Scale Smart Grids using Chebyshev Graph Convolutional Networks. (arXiv:2112.13166v1 [cs.CR])
49. AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands. (arXiv:2112.13168v1 [q-bio.QM])
50. Gradient Leakage Attack Resilient Deep Learning. (arXiv:2112.13178v1 [cs.LG])
51. DBC-Forest: Deep forest with binning confidence screening. (arXiv:2112.13182v1 [cs.LG])
52. A comparative study on machine learning models combining with outlier detection and balanced sampling methods for credit scoring. (arXiv:2112.13196v1 [cs.LG])
53. A Spectral Method for Joint Community Detection and Orthogonal Group Synchronization. (arXiv:2112.13199v1 [stat.ML])
54. Neural Network Module Decomposition and Recomposition. (arXiv:2112.13208v1 [cs.LG])
55. Explainable Artificial Intelligence for Pharmacovigilance: What Features Are Important When Predicting Adverse Outcomes?. (arXiv:2112.13210v1 [q-bio.QM])
56. NeuronFair: Interpretable White-Box Fairness Testing through Biased Neuron Identification. (arXiv:2112.13214v1 [cs.LG])
57. Continual Learning for Unsupervised Anomaly Detection in Continuous Auditing of Financial Accounting Data. (arXiv:2112.13215v1 [cs.LG])
58. N-Omniglot: a Large-scale Dataset for Spatio-Temporal Sparse Few-shot Learning. (arXiv:2112.13230v1 [cs.NE])
59. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v1 [cs.CR])
60. Towards Federated Learning on Time-Evolving Heterogeneous Data. (arXiv:2112.13246v1 [cs.LG])
61. Reactive Message Passing for Scalable Bayesian Inference. (arXiv:2112.13251v1 [cs.LG])
62. On Dynamic Pricing with Covariates. (arXiv:2112.13254v1 [cs.LG])
63. Deeper Clinical Document Understanding Using Relation Extraction. (arXiv:2112.13259v1 [cs.CL])
64. Artifact Reduction in Fundus Imaging using Cycle Consistent Adversarial Neural Networks. (arXiv:2112.13264v1 [eess.IV])
65. Task and Model Agnostic Adversarial Attack on Graph Neural Networks. (arXiv:2112.13267v1 [cs.LG])
66. Over-Parametrized Matrix Factorization in the Presence of Spurious Stationary Points. (arXiv:2112.13269v1 [cs.LG])
67. Learning Linear Complementarity Systems. (arXiv:2112.13284v1 [cs.LG])
68. Pedagogical Rule Extraction for Learning Interpretable Models. (arXiv:2112.13285v1 [cs.LG])
69. Prevalence Threshold and bounds in the Accuracy of Binary Classification Systems. (arXiv:2112.13289v1 [stat.ML])
70. Silent Bugs in Deep Learning Frameworks: An Empirical Study of Keras and TensorFlow. (arXiv:2112.13314v1 [cs.SE])
71. Efficient Diversity-Driven Ensemble for Deep Neural Networks. (arXiv:2112.13316v1 [cs.LG])
72. Continuous Offline Handwriting Recognition using Deep Learning Models. (arXiv:2112.13328v1 [cs.CV])
73. MPCLeague: Robust MPC Platform for Privacy-Preserving Machine Learning. (arXiv:2112.13338v1 [cs.CR])
74. It\^{o}-Taylor Sampling Scheme for Denoising Diffusion Probabilistic Models using Ideal Derivatives. (arXiv:2112.13339v1 [stat.ML])
75. The Quantum Version of Prediction for Binary Classification Problem by Ensemble Methods. (arXiv:2112.13346v1 [quant-ph])
76. Novel Dual-Channel Long Short-Term Memory Compressed Capsule Networks for Emotion Recognition. (arXiv:2112.13350v1 [cs.SD])
77. Novel Hybrid DNN Approaches for Speaker Verification in Emotional and Stressful Talking Environments. (arXiv:2112.13353v1 [cs.SD])
78. AIDA: An Active Inference-based Design Agent for Audio Processing Algorithms. (arXiv:2112.13366v1 [eess.AS])
79. A Trained Regularization Approach Based on Born Iterative Method for Electromagnetic Imaging. (arXiv:2112.13367v1 [eess.IV])
80. FRuDA: Framework for Distributed Adversarial Domain Adaptation. (arXiv:2112.13381v1 [cs.LG])
81. Will You Dance To The Challenge? Predicting User Participation of TikTok Challenges. (arXiv:2112.13384v1 [cs.LG])
82. Reducing Planning Complexity of General Reinforcement Learning with Non-Markovian Abstractions. (arXiv:2112.13386v1 [cs.AI])
83. Omitted Variable Bias in Machine Learned Causal Models. (arXiv:2112.13398v1 [econ.EM])
84. Abstractions of General Reinforcement Learning. (arXiv:2112.13404v1 [cs.AI])
85. Perlin Noise Improve Adversarial Robustness. (arXiv:2112.13408v1 [cs.LG])
86. Generative Kernel Continual learning. (arXiv:2112.13410v1 [cs.LG])
87. Reinforcement Learning with Dynamic Convex Risk Measures. (arXiv:2112.13414v1 [cs.LG])
88. Attribute Inference Attack of Speech Emotion Recognition in Federated Learning Settings. (arXiv:2112.13416v1 [cs.CR])
89. Neuro-Symbolic Hierarchical Rule Induction. (arXiv:2112.13418v1 [cs.LG])
90. New Methods & Metrics for LFQA tasks. (arXiv:2112.13432v1 [cs.CL])
91. Sinogram upsampling using Primal-Dual UNet for undersampled CT and radial MRI reconstruction. (arXiv:2112.13443v1 [eess.IV])
92. A CNN-BiLSTM Model with Attention Mechanism for Earthquake Prediction. (arXiv:2112.13444v1 [cs.LG])
93. Acoustic scene classification using auditory datasets. (arXiv:2112.13450v1 [cs.SD])
94. ToxTree: descriptor-based machine learning models for both hERG and Nav1.5 cardiotoxicity liability predictions. (arXiv:2112.13467v1 [cs.LG])
95. Learning Optimization Proxies for Large-Scale Security-Constrained Economic Dispatch. (arXiv:2112.13469v1 [cs.LG])
96. The Statistical Complexity of Interactive Decision Making. (arXiv:2112.13487v1 [cs.LG])
97. Deep Treatment-Adaptive Network for Causal Inference. (arXiv:2112.13502v1 [cs.LG])
98. Block Modeling-Guided Graph Convolutional Neural Networks. (arXiv:2112.13507v1 [cs.LG])
99. Mind the Gap: Cross-Lingual Information Retrieval with Hierarchical Knowledge Enhancement. (arXiv:2112.13510v1 [cs.IR])
100. MSHT: Multi-stage Hybrid Transformer for the ROSE Image Analysis of Pancreatic Cancer. (arXiv:2112.13513v1 [eess.IV])
101. Anomaly Detection using Capsule Networks for High-dimensional Datasets. (arXiv:2112.13514v1 [cs.LG])
102. Can Reinforcement Learning Find Stackelberg-Nash Equilibria in General-Sum Markov Games with Myopic Followers?. (arXiv:2112.13521v1 [cs.LG])
103. Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic. (arXiv:2112.13530v1 [cs.LG])
104. Sparsest Univariate Learning Models Under Lipschitz Constraint. (arXiv:2112.13542v1 [cs.LG])
105. FitAct: Error Resilient Deep Neural Networks via Fine-Grained Post-Trainable Activation Functions. (arXiv:2112.13544v1 [cs.LG])
106. ViR:the Vision Reservoir. (arXiv:2112.13545v1 [cs.CV])
107. PRIME: A Few Primitives Can Boost Robustness to Common Corruptions. (arXiv:2112.13547v1 [cs.CV])
108. Powerful Graph Convolutioal Networks with Adaptive Propagation Mechanism for Homophily and Heterophily. (arXiv:2112.13562v1 [cs.LG])
109. A probabilistic model for fast-to-evaluate 2D crack path prediction in heterogeneous materials. (arXiv:2112.13578v1 [cs.LG])
110. Survival Analysis of the Compressor Station Based on Hawkes Process with Weibull Base Intensity. (arXiv:2112.13581v1 [cs.LG])
111. Learn Layer-wise Connections in Graph Neural Networks. (arXiv:2112.13585v1 [cs.LG])
112. Multi-modal Attention Network for Stock Movements Prediction. (arXiv:2112.13593v1 [cs.LG])
113. Over-the-Air Multi-Task Federated Learning Over MIMO Interference Channel. (arXiv:2112.13603v1 [eess.SP])
114. Extracting knowledge from features with multilevel abstraction. (arXiv:2112.13642v1 [cs.LG])
115. Move As You Like: Image Animation in E-Commerce Scenario. (arXiv:2112.13647v1 [cs.GR])
116. Generating and Exploring S-Box Multivariate Quadratic Equation Systems with SageMath. (arXiv:1506.04319v4 [cs.CR] UPDATED)
117. AI-Aided Online Adaptive OFDM Receiver: Design and Experimental Results. (arXiv:1812.06638v3 [eess.SP] UPDATED)
118. RKHSMetaMod: An R package to estimate the Hoeffding decomposition of a complex model by solving RKHS ridge group sparse optimization problem. (arXiv:1905.13695v6 [stat.ML] UPDATED)
119. Pre-train and Learn: Preserve Global Information for Graph Neural Networks. (arXiv:1910.12241v2 [cs.LG] UPDATED)
120. Higher Criticism for Discriminating Word-Frequency Tables and Testing Authorship. (arXiv:1911.01208v4 [cs.CL] UPDATED)
121. Natural Actor-Critic Converges Globally for Hierarchical Linear Quadratic Regulator. (arXiv:1912.06875v2 [cs.LG] UPDATED)
122. Learning Variable Ordering Heuristics for Solving Constraint Satisfaction Problems. (arXiv:1912.10762v3 [cs.AI] UPDATED)
123. On Biased Compression for Distributed Learning. (arXiv:2002.12410v2 [cs.LG] UPDATED)
124. A Graph Convolutional Topic Model for Short and Noisy Text Streams. (arXiv:2003.06112v4 [cs.LG] UPDATED)
125. Dynamic transformation of prior knowledge into Bayesian models for data streams. (arXiv:2003.06123v4 [cs.LG] UPDATED)
126. Unsupervised Domain Adaptation Through Transferring both the Source-Knowledge and Target-Relatedness Simultaneously. (arXiv:2003.08051v3 [cs.LG] UPDATED)
127. Learning 1-Dimensional Submanifolds for Subsequent Inference on Random Dot Product Graphs. (arXiv:2004.07348v6 [stat.ML] UPDATED)
128. Unified Models of Human Behavioral Agents in Bandits, Contextual Bandits and RL. (arXiv:2005.04544v5 [cs.AI] UPDATED)
129. Greedy Algorithm almost Dominates in Smoothed Contextual Bandits. (arXiv:2005.10624v2 [cs.LG] UPDATED)
130. Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v4 [cs.LG] UPDATED)
131. Tensor Completion Made Practical. (arXiv:2006.03134v2 [cs.DS] UPDATED)
132. Learned Factor Graphs for Inference from Stationary Time Sequences. (arXiv:2006.03258v4 [cs.LG] UPDATED)
133. Disentangled Representation Learning and Generation with Manifold Optimization. (arXiv:2006.07046v3 [cs.LG] UPDATED)
134. Learning TSP Requires Rethinking Generalization. (arXiv:2006.07054v4 [cs.LG] UPDATED)
135. Understanding and Mitigating Exploding Inverses in Invertible Neural Networks. (arXiv:2006.09347v2 [cs.LG] UPDATED)
136. Architectural Implications of Graph Neural Networks. (arXiv:2009.00804v2 [cs.AR] UPDATED)
137. Hierarchical Multi-Grained Generative Model for Expressive Speech Synthesis. (arXiv:2009.08474v2 [eess.AS] UPDATED)
138. A Practical Tutorial on Graph Neural Networks. (arXiv:2010.05234v3 [cs.LG] UPDATED)
139. Distributionally Robust Learning for Uncertainty Calibration under Domain Shift. (arXiv:2010.05784v3 [cs.LG] UPDATED)
140. Efficient Learning in Non-Stationary Linear Markov Decision Processes. (arXiv:2010.12870v3 [cs.LG] UPDATED)
141. Non-Equilibrium Skewness, Market Crises, and Option Pricing: Non-Linear Langevin Model of Markets with Supersymmetry. (arXiv:2011.01417v3 [q-fin.CP] UPDATED)
142. Learning Energy-Based Model with Variational Auto-Encoder as Amortized Sampler. (arXiv:2012.14936v2 [stat.ML] UPDATED)
143. Through the Data Management Lens: Experimental Analysis and Evaluation of Fair Classification. (arXiv:2101.07361v3 [cs.LG] UPDATED)
144. Self-Adaptive Training: Bridging Supervised and Self-Supervised Learning. (arXiv:2101.08732v2 [cs.LG] UPDATED)
145. Appearance of Random Matrix Theory in Deep Learning. (arXiv:2102.06740v3 [cs.LG] UPDATED)
146. Confidence Calibration with Bounded Error Using Transformations. (arXiv:2102.12680v2 [cs.LG] UPDATED)
147. Meta-Learning an Inference Algorithm for Probabilistic Programs. (arXiv:2103.00737v4 [cs.LG] UPDATED)
148. Transient growth of accelerated optimization algorithms. (arXiv:2103.08017v2 [math.OC] UPDATED)
149. Online Learning with Radial Basis Function Networks. (arXiv:2103.08414v6 [cs.CE] UPDATED)
150. JFB: Jacobian-Free Backpropagation for Implicit Networks. (arXiv:2103.12803v4 [cs.LG] UPDATED)
151. Machine Learning Applications in the Routing in Computer Networks. (arXiv:2104.01946v2 [cs.NI] UPDATED)
152. Node Co-occurrence based Graph Neural Networks for Knowledge Graph Link Prediction. (arXiv:2104.07396v3 [cs.CL] UPDATED)
153. A Survey on Accuracy-oriented Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation. (arXiv:2104.13030v3 [cs.IR] UPDATED)
154. FairDrop: Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning. (arXiv:2104.14210v2 [cs.LG] UPDATED)
155. Towards Fair Classifiers Without Sensitive Attributes: Exploring Biases in Related Features. (arXiv:2104.14537v3 [cs.LG] UPDATED)
156. Time series forecasting of new cases and new deaths rate for COVID-19 using deep learning methods. (arXiv:2104.15007v3 [cs.LG] UPDATED)
157. GSPMD: General and Scalable Parallelization for ML Computation Graphs. (arXiv:2105.04663v2 [cs.DC] UPDATED)
158. Variational Quantum Classifiers Through the Lens of the Hessian. (arXiv:2105.10162v3 [quant-ph] UPDATED)
159. Novel Deep Learning Architecture for Heart Disease Prediction using Convolutional Neural Network. (arXiv:2105.10816v4 [cs.LG] UPDATED)
160. Killing One Bird with Two Stones: Model Extraction and Attribute Inference Attacks against BERT-based APIs. (arXiv:2105.10909v2 [cs.CR] UPDATED)
161. Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs with a Generative Model. (arXiv:2105.14016v2 [cs.LG] UPDATED)
162. Understanding Instance-based Interpretability of Variational Auto-Encoders. (arXiv:2105.14203v3 [cs.LG] UPDATED)
163. Compositional Reinforcement Learning from Logical Specifications. (arXiv:2106.13906v3 [cs.LG] UPDATED)
164. Understanding and Improving Early Stopping for Learning with Noisy Labels. (arXiv:2106.15853v2 [cs.LG] UPDATED)
165. Graph Signal Restoration Using Nested Deep Algorithm Unrolling. (arXiv:2106.15910v2 [eess.SP] UPDATED)
166. Action Transformer: A Self-Attention Model for Short-Time Pose-Based Human Action Recognition. (arXiv:2107.00606v5 [cs.CV] UPDATED)
167. Ascent Similarity Caching with Approximate Indexes. (arXiv:2107.00957v3 [cs.NI] UPDATED)
168. Clustering Structure of Microstructure Measures. (arXiv:2107.02283v3 [q-fin.ST] UPDATED)
169. CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v3 [cs.LG] UPDATED)
170. Deep Autoregressive Models with Spectral Attention. (arXiv:2107.05984v2 [stat.ML] UPDATED)
171. Going Beyond Linear RL: Sample Efficient Neural Function Approximation. (arXiv:2107.06466v2 [cs.LG] UPDATED)
172. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v2 [cs.LG] UPDATED)
173. Sparse Bayesian Learning with Diagonal Quasi-Newton Method for Large Scale Classification. (arXiv:2107.08195v2 [cs.LG] UPDATED)
174. ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A case study for skin lesion classification. (arXiv:2107.12734v2 [cs.CV] UPDATED)
175. AutoML Meets Time Series Regression Design and Analysis of the AutoSeries Challenge. (arXiv:2107.13186v2 [cs.LG] UPDATED)
176. The CirCor DigiScope Dataset: From Murmur Detection to Murmur Classification. (arXiv:2108.00813v2 [q-bio.QM] UPDATED)
177. Panoptic nuScenes: A Large-Scale Benchmark for LiDAR Panoptic Segmentation and Tracking. (arXiv:2109.03805v3 [cs.CV] UPDATED)
178. Unsolved Problems in ML Safety. (arXiv:2109.13916v3 [cs.LG] UPDATED)
179. Optimized U-Net for Brain Tumor Segmentation. (arXiv:2110.03352v2 [eess.IV] UPDATED)
180. Gated recurrent units and temporal convolutional network for multilabel classification. (arXiv:2110.04414v2 [cs.LG] UPDATED)
181. Reinforcement Learning for Systematic FX Trading. (arXiv:2110.04745v4 [q-fin.TR] UPDATED)
182. A Novel Clustering-Based Algorithm for Continuous and Non-invasive Cuff-Less Blood Pressure Estimation. (arXiv:2110.06996v2 [physics.med-ph] UPDATED)
183. User-Level Private Learning via Correlated Sampling. (arXiv:2110.11208v2 [cs.LG] UPDATED)
184. Multi-Agent Reinforcement Learning for Active Voltage Control on Power Distribution Networks. (arXiv:2110.14300v4 [cs.LG] UPDATED)
185. Self-Supervised Representation Learning on Neural Network Weights for Model Characteristic Prediction. (arXiv:2110.15288v3 [cs.LG] UPDATED)
186. Unsupervised Foreground Extraction via Deep Region Competition. (arXiv:2110.15497v3 [cs.CV] UPDATED)
187. On Joint Learning for Solving Placement and Routing in Chip Design. (arXiv:2111.00234v2 [cs.LG] UPDATED)
188. Deep Learning in Human Activity Recognition with Wearable Sensors: A Review on Advances. (arXiv:2111.00418v4 [cs.HC] UPDATED)
189. Influential Prototypical Networks for Few Shot Learning: A Dermatological Case Study. (arXiv:2111.00698v5 [eess.IV] UPDATED)
190. Code2Snapshot: Using Code Snapshots for Learning Representations of Source Code. (arXiv:2111.01097v2 [cs.SE] UPDATED)
191. Probabilistic Deep Learning for Real-Time Large Deformation Simulations. (arXiv:2111.01867v2 [cs.LG] UPDATED)
192. Linear, or Non-Linear, That is the Question!. (arXiv:2111.07265v2 [cs.IR] UPDATED)
193. Stochastic Extragradient: General Analysis and Improved Rates. (arXiv:2111.08611v2 [math.OC] UPDATED)
194. Machine Learning for Mechanical Ventilation Control (Extended Abstract). (arXiv:2111.10434v3 [cs.LG] UPDATED)
195. Generalized Normalizing Flows via Markov Chains. (arXiv:2111.12506v2 [cs.LG] UPDATED)
196. Computer Vision User Entity Behavior Analytics. (arXiv:2111.13176v2 [cs.CV] UPDATED)
197. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v3 [cs.CV] UPDATED)
198. An Investigation on Learning, Polluting, and Unlearning the Spam Emails for Lifelong Learning. (arXiv:2111.14609v2 [cs.LG] UPDATED)
199. Convergence of GANs Training: A Game and Stochastic Control Methodology. (arXiv:2112.00222v2 [stat.ML] UPDATED)
200. DANets: Deep Abstract Networks for Tabular Data Classification and Regression. (arXiv:2112.02962v2 [cs.LG] UPDATED)
201. Label-Efficient Semantic Segmentation with Diffusion Models. (arXiv:2112.03126v2 [cs.CV] UPDATED)
202. Top-Down Deep Clustering with Multi-generator GANs. (arXiv:2112.03398v2 [cs.LG] UPDATED)
203. A generalization gap estimation for overparameterized models via the Langevin functional variance. (arXiv:2112.03660v2 [stat.ML] UPDATED)
204. Ensemble CNN Networks for GBM Tumors Segmentation using Multi-parametric MRI. (arXiv:2112.06554v2 [cs.CV] UPDATED)
205. Non Asymptotic Bounds for Optimization via Online Multiplicative Stochastic Gradient Descent. (arXiv:2112.07110v3 [stat.ML] UPDATED)
206. Simple and Robust Loss Design for Multi-Label Learning with Missing Labels. (arXiv:2112.07368v2 [cs.LG] UPDATED)
207. Bootstrap Equilibrium and Probabilistic Speaker Representation Learning for Self-supervised Speaker Verification. (arXiv:2112.08929v2 [eess.AS] UPDATED)
208. Balancing Fairness and Robustness via Partial Invariance. (arXiv:2112.09346v2 [cs.LG] UPDATED)
209. NFTGAN: Non-Fungible Token Art Generation Using Generative Adversarial Networks. (arXiv:2112.10577v2 [cs.LG] UPDATED)
210. GCN-Geo: A Graph Convolution Network-based Fine-grained IP Geolocation System. (arXiv:2112.10767v3 [cs.LG] UPDATED)
211. Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v2 [cs.LG] UPDATED)
212. Decentralized Task Offloading in Edge Computing: A Multi-User Multi-Armed Bandit Approach. (arXiv:2112.11818v2 [cs.DC] UPDATED)
213. ProBF: Learning Probabilistic Safety Certificates with Barrier Functions. (arXiv:2112.12210v2 [cs.LG] UPDATED)
214. Revisiting and Advancing Fast Adversarial Training Through The Lens of Bi-Level Optimization. (arXiv:2112.12376v2 [cs.LG] UPDATED)
215. Newsvendor Model with Deep Reinforcement Learning. (arXiv:2112.12544v2 [cs.LG] UPDATED)
216. Optimal learning of high-dimensional classification problems using deep neural networks. (arXiv:2112.12555v2 [math.FA] UPDATED)
217. A deep reinforcement learning model for predictive maintenance planning of road assets: Integrating LCA and LCCA. (arXiv:2112.12589v2 [cs.LG] UPDATED)
218. Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review. (arXiv:2112.12705v2 [cs.AI] UPDATED)
219. Graph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids. (arXiv:2104.02012v2 [eess.SP] CROSS LISTED)
220. Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks. (arXiv:2104.11846v2 [cs.LG] CROSS LISTED)
221. DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual Network for the DiCOVA Challenge 2021. (arXiv:2107.06126v1 [cs.SD] CROSS LISTED)
## cs.AI
---
**96** new papers in cs.AI:-) 
1. A Multi-View Framework for BGP Anomaly Detection via Graph Attention Network. (arXiv:2112.12793v1 [cs.LG])
2. MISO hierarchical inference engine with fuzzy implication satisfying I(A(x, y), z) = I(x, I(y, z)). (arXiv:2112.12808v1 [cs.AI])
3. Learning to Walk with Dual Agents for Knowledge Graph Reasoning. (arXiv:2112.12876v1 [cs.AI])
4. Rediscovering Affordance: A Reinforcement Learning Perspective. (arXiv:2112.12886v1 [cs.HC])
5. Towards Understanding Human Functional Brain Development with Explainable Artificial Intelligence: Challenges and Perspectives. (arXiv:2112.12910v1 [q-bio.NC])
6. Visual Semantics Allow for Textual Reasoning Better in Scene Text Recognition. (arXiv:2112.12916v1 [cs.CV])
7. nvBench: A Large-Scale Synthesized Dataset for Cross-Domain Natural Language to Visualization Task. (arXiv:2112.12926v1 [cs.HC])
8. Counterfactual Memorization in Neural Language Models. (arXiv:2112.12938v1 [cs.CL])
9. Analyzing Scientific Publications using Domain-Specific Word Embedding and Topic Modelling. (arXiv:2112.12940v1 [cs.CL])
10. Deep ensembles in bioimage segmentation. (arXiv:2112.12955v1 [cs.CV])
11. DeepGANTT: A Scalable Deep Learning Scheduler for Backscatter Networks. (arXiv:2112.12985v1 [cs.LG])
12. Deep Neuroevolution Squeezes More out of Small Neural Networks and Small Training Sets: Sample Application to MRI Brain Sequence Classification. (arXiv:2112.12990v1 [cs.NE])
13. Stochastic Learning Equation using Monotone Increasing Resolution of Quantization. (arXiv:2112.13006v1 [cs.LG])
14. DARTS without a Validation Set: Optimizing the Marginal Likelihood. (arXiv:2112.13023v1 [cs.LG])
15. Channel-Wise Attention-Based Network for Self-Supervised Monocular Depth Estimation. (arXiv:2112.13047v1 [cs.CV])
16. NIP: Neuron-level Inverse Perturbation Against Adversarial Attacks. (arXiv:2112.13060v1 [cs.CV])
17. CatchBackdoor: Backdoor Testing by Critical Trojan Neural Path Identification via Differential Fuzzing. (arXiv:2112.13064v1 [cs.CR])
18. Virtuoso: Video-based Intelligence for real-time tuning on SOCs. (arXiv:2112.13076v1 [cs.CV])
19. Dual Hierarchical Attention Networks for Bi-typed Heterogeneous Graph Learning. (arXiv:2112.13078v1 [cs.LG])
20. Multi-Scale Feature Fusion: Learning Better Semantic Segmentation for Road Pothole Detection. (arXiv:2112.13082v1 [cs.CV])
21. A Survey on Interpretable Reinforcement Learning. (arXiv:2112.13112v1 [cs.LG])
22. The Curse of Zero Task Diversity: On the Failure of Transfer Learning to Outperform MAML and their Empirical Equivalence. (arXiv:2112.13121v1 [cs.LG])
23. Does MAML Only Work via Feature Re-use? A Data Centric Perspective. (arXiv:2112.13137v1 [cs.LG])
24. On the Unreasonable Efficiency of State Space Clustering in Personalization Tasks. (arXiv:2112.13141v1 [cs.LG])
25. SoK: A Study of the Security on Voice Processing Systems. (arXiv:2112.13144v1 [cs.CR])
26. Cyberattack Detection in Large-Scale Smart Grids using Chebyshev Graph Convolutional Networks. (arXiv:2112.13166v1 [cs.CR])
27. Practical Fixed-Parameter Algorithms for Defending Active Directory Style Attack Graphs. (arXiv:2112.13175v1 [cs.GT])
28. Explainable Artificial Intelligence for Pharmacovigilance: What Features Are Important When Predicting Adverse Outcomes?. (arXiv:2112.13210v1 [q-bio.QM])
29. NeuronFair: Interpretable White-Box Fairness Testing through Biased Neuron Identification. (arXiv:2112.13214v1 [cs.LG])
30. Edge Robotics: Edge-Computing-Accelerated Multi-Robot Simultaneous Localization and Mapping. (arXiv:2112.13222v1 [cs.RO])
31. An Ensemble of Pre-trained Transformer Models For Imbalanced Multiclass Malware Classification. (arXiv:2112.13236v1 [cs.CR])
32. CABACE: Injecting Character Sequence Information and Domain Knowledge for Enhanced Acronym and Long-Form Extraction. (arXiv:2112.13237v1 [cs.CL])
33. A Preliminary Study for Literary Rhyme Generation based on Neuronal Representation, Semantics and Shallow Parsing. (arXiv:2112.13241v1 [cs.CL])
34. Evolutionary Generation of Visual Motion Illusions. (arXiv:2112.13243v1 [cs.NE])
35. Reactive Message Passing for Scalable Bayesian Inference. (arXiv:2112.13251v1 [cs.LG])
36. Deeper Clinical Document Understanding Using Relation Extraction. (arXiv:2112.13259v1 [cs.CL])
37. Unsupervised Clustering Active Learning for Person Re-identification. (arXiv:2112.13308v1 [cs.CV])
38. Budget Sensitive Reannotation of Noisy Relation Classification Data Using Label Hierarchy. (arXiv:2112.13320v1 [cs.CL])
39. Delivery Issues Identification from Customer Feedback Data. (arXiv:2112.13372v1 [cs.CL])
40. Reducing Planning Complexity of General Reinforcement Learning with Non-Markovian Abstractions. (arXiv:2112.13386v1 [cs.AI])
41. The brain as a probabilistic transducer: an evolutionarily plausible network architecture for knowledge representation, computation, and behavior. (arXiv:2112.13388v1 [cs.AI])
42. Abstractions of General Reinforcement Learning. (arXiv:2112.13404v1 [cs.AI])
43. Perlin Noise Improve Adversarial Robustness. (arXiv:2112.13408v1 [cs.LG])
44. Generative Kernel Continual learning. (arXiv:2112.13410v1 [cs.LG])
45. Neuro-Symbolic Hierarchical Rule Induction. (arXiv:2112.13418v1 [cs.LG])
46. ArT: All-round Thinker for Unsupervised Commonsense Question-Answering. (arXiv:2112.13428v1 [cs.CL])
47. PreDisM: Pre-Disaster Modelling With CNN Ensembles for At-Risk Communities. (arXiv:2112.13465v1 [cs.CV])
48. A Brief History of Updates of Answer-Set Programs. (arXiv:2112.13477v1 [cs.AI])
49. Duck swarm algorithm: a novel swarm intelligence algorithm. (arXiv:2112.13508v1 [cs.NE])
50. Automatic Configuration for Optimal Communication Scheduling in DNN Training. (arXiv:2112.13509v1 [cs.DC])
51. Interpreting Dynamical Systems as Bayesian Reasoners. (arXiv:2112.13523v1 [cs.AI])
52. Adversarial Attack for Asynchronous Event-based Data. (arXiv:2112.13534v1 [cs.CV])
53. FitAct: Error Resilient Deep Neural Networks via Fine-Grained Post-Trainable Activation Functions. (arXiv:2112.13544v1 [cs.LG])
54. Semantic Characterizations of General Belief Base Revision. (arXiv:2112.13557v1 [cs.AI])
55. Learn Layer-wise Connections in Graph Neural Networks. (arXiv:2112.13585v1 [cs.LG])
56. HeteroQA: Learning towards Question-and-Answering through Multiple Information Sources via Heterogeneous Graph Modeling. (arXiv:2112.13597v1 [cs.CL])
57. Personalized Lane Change Decision Algorithm Using Deep Reinforcement Learning Approach. (arXiv:2112.13646v1 [cs.RO])
58. Move As You Like: Image Animation in E-Commerce Scenario. (arXiv:2112.13647v1 [cs.GR])
59. Knowledge, Justification, and Adequate Reasons. (arXiv:1412.1862v4 [cs.LO] UPDATED)
60. Generating and Exploring S-Box Multivariate Quadratic Equation Systems with SageMath. (arXiv:1506.04319v4 [cs.CR] UPDATED)
61. Generating Empathetic Responses by Looking Ahead the User's Sentiment. (arXiv:1906.08487v2 [cs.CL] UPDATED)
62. Learning Variable Ordering Heuristics for Solving Constraint Satisfaction Problems. (arXiv:1912.10762v3 [cs.AI] UPDATED)
63. Unified Models of Human Behavioral Agents in Bandits, Contextual Bandits and RL. (arXiv:2005.04544v5 [cs.AI] UPDATED)
64. A Practical Tutorial on Graph Neural Networks. (arXiv:2010.05234v3 [cs.LG] UPDATED)
65. Compositional Reinforcement Learning from Logical Specifications. (arXiv:2106.13906v3 [cs.LG] UPDATED)
66. Heterogeneous Global Graph Neural Networks for Personalized Session-based Recommendation. (arXiv:2107.03813v3 [cs.IR] UPDATED)
67. A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification. (arXiv:2107.07511v2 [cs.LG] UPDATED)
68. Panoptic nuScenes: A Large-Scale Benchmark for LiDAR Panoptic Segmentation and Tracking. (arXiv:2109.03805v3 [cs.CV] UPDATED)
69. Unsolved Problems in ML Safety. (arXiv:2109.13916v3 [cs.LG] UPDATED)
70. Learning, Computing, and Trustworthiness in Intelligent IoT Environments: Performance-Energy Tradeoffs. (arXiv:2110.01686v2 [cs.DC] UPDATED)
71. Gated recurrent units and temporal convolutional network for multilabel classification. (arXiv:2110.04414v2 [cs.LG] UPDATED)
72. A Novel Clustering-Based Algorithm for Continuous and Non-invasive Cuff-Less Blood Pressure Estimation. (arXiv:2110.06996v2 [physics.med-ph] UPDATED)
73. Neural ODE and DAE Modules for Power System Dynamic Component Modeling. (arXiv:2110.12981v3 [eess.SY] UPDATED)
74. On Joint Learning for Solving Placement and Routing in Chip Design. (arXiv:2111.00234v2 [cs.LG] UPDATED)
75. Artificial Association Neural Networks. (arXiv:2111.00424v7 [cs.AI] UPDATED)
76. Deductive Association Networks. (arXiv:2111.01431v3 [cs.AI] UPDATED)
77. Memory Association Networks. (arXiv:2111.02353v4 [cs.AI] UPDATED)
78. Imagine Networks. (arXiv:2111.03048v4 [cs.AI] UPDATED)
79. Profitable Trade-Off Between Memory and Performance In Multi-Domain Chatbot Architectures. (arXiv:2111.03963v2 [cs.CL] UPDATED)
80. Linear, or Non-Linear, That is the Question!. (arXiv:2111.07265v2 [cs.IR] UPDATED)
81. A distributed, plug-n-play algorithm for multi-robot applications with a priori non-computable objective functions. (arXiv:2111.07441v2 [cs.RO] UPDATED)
82. How Well Do Sparse Imagenet Models Transfer?. (arXiv:2111.13445v3 [cs.CV] UPDATED)
83. An Investigation on Learning, Polluting, and Unlearning the Spam Emails for Lifelong Learning. (arXiv:2111.14609v2 [cs.LG] UPDATED)
84. Open Vocabulary Electroencephalography-To-Text Decoding and Zero-shot Sentiment Classification. (arXiv:2112.02690v2 [cs.AI] UPDATED)
85. DANets: Deep Abstract Networks for Tabular Data Classification and Regression. (arXiv:2112.02962v2 [cs.LG] UPDATED)
86. Synapse Compression for Event-Based Convolutional-Neural-Network Accelerators. (arXiv:2112.07019v2 [cs.AR] UPDATED)
87. Simple and Robust Loss Design for Multi-Label Learning with Missing Labels. (arXiv:2112.07368v2 [cs.LG] UPDATED)
88. Bootstrap Equilibrium and Probabilistic Speaker Representation Learning for Self-supervised Speaker Verification. (arXiv:2112.08929v2 [eess.AS] UPDATED)
89. NFTGAN: Non-Fungible Token Art Generation Using Generative Adversarial Networks. (arXiv:2112.10577v2 [cs.LG] UPDATED)
90. There is an elephant in the room: Towards a critique on the use of fairness in biometrics. (arXiv:2112.11193v2 [cs.CY] UPDATED)
91. From Procedures, Objects, Actors, Components, Services, to Agents -- A Comparative Analysis of the History and Evolution of Programming Abstractions. (arXiv:2112.12508v2 [cs.SE] UPDATED)
92. A deep reinforcement learning model for predictive maintenance planning of road assets: Integrating LCA and LCCA. (arXiv:2112.12589v2 [cs.LG] UPDATED)
93. Explainable Artificial Intelligence Methods in Combating Pandemics: A Systematic Review. (arXiv:2112.12705v2 [cs.AI] UPDATED)
94. Graph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids. (arXiv:2104.02012v2 [eess.SP] CROSS LISTED)
95. Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids using Graph Neural Networks. (arXiv:2104.11846v2 [cs.LG] CROSS LISTED)
96. DiCOVA-Net: Diagnosing COVID-19 using Acoustics based on Deep Residual Network for the DiCOVA Challenge 2021. (arXiv:2107.06126v1 [cs.SD] CROSS LISTED)
