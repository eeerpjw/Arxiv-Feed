# Your interest papers
---
## cs.CV
---
### Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
- Authors : Marco Cardia, Massimiliano Luca, Luca Pappalardo
- Link : [http://arxiv.org/abs/2203.07372](http://arxiv.org/abs/2203.07372)
> ABSTRACT  :  Thanks to the diffusion of the Internet of Things, nowadays it is possible to sense human mobility almost in **real time** using unconventional methods (e.g., number of bikes in a bike station). Due to the diffusion of such technologies, the last years have witnessed a significant growth of human mobility studies, motivated by their importance in a wide range of applications, from traffic management to public security and computational epidemiology. A mobility task that is becoming prominent is crowd flow prediction, i.e., forecasting aggregated incoming and outgoing flows in the locations of a geographic region. Although several deep learning approaches have been proposed to solve this problem, their usage is limited to specific types of spatial tessellations and cannot provide sufficient explanations of their predictions. We propose CrowdNet, a solution to crowd flow prediction based on graph convolutional networks. Compared with state-of-the-art solutions, CrowdNet can be used with regions of irregular shapes and provide meaningful explanations of the predicted crowd flows. We conduct experiments on public data varying the spatio-temporal granularity of crowd flows to show the superiority of our model with respect to existing methods, and we investigate CrowdNet's reliability to missing or noisy input data. Our model is a step forward in the design of reliable deep learning models to predict and explain human displacements in urban environments.  
### Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v1 [eess.IV])
- Authors : Xiang Chen, Zhentao Fan, Zhuoran Zheng, Yufeng Li, Yufeng Huang, Longgang Dai, Caihua Kong, Pengpeng Li
- Link : [http://arxiv.org/abs/2203.07677](http://arxiv.org/abs/2203.07677)
> ABSTRACT  :  We present an effective unpaired learning based image dehazing network from an unpaired set of clear and hazy images. This paper provides a new perspective to treat image dehazing as a two-class separated factor disentanglement task, i.e, the task-relevant factor of clear image reconstruction and the task-irrelevant factor of haze-relevant distribution. To achieve the disentanglement of these two-class factors in deep feature space, contrastive learning is introduced into a CycleGAN framework to learn disentangled representations by guiding the generated images to be associated with latent factors. With such formulation, the proposed contrastive disentangled dehazing method (CDD-GAN) first develops negative generators to cooperate with the encoder network to update alternately, so as to produce a queue of challenging negative adversaries. Then these negative adversaries are trained end-to-end together with the backbone representation network to enhance the discriminative information and promote factor disentanglement performance by maximizing the adversarial contrastive loss. During the training, we further show that hard negative examples can suppress the task-irrelevant factors and unpaired clear exemples can enhance the task-relevant factors, in order to better facilitate haze removal and help image **restoration**. Extensive experiments on both synthetic and real-world datasets demonstrate that our method performs favorably against existing state-of-the-art unpaired dehazing approaches.  
### Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution. (arXiv:2203.07682v1 [cs.CV])
- Authors : Jinsu Yoo, Taehoon Kim, Sihaeng Lee, Seung Hwan, Honglak Lee, Tae Hyun
- Link : [http://arxiv.org/abs/2203.07682](http://arxiv.org/abs/2203.07682)
> ABSTRACT  :  Recent vision transformers along with self-attention have achieved promising results on various computer vision tasks. In particular, a pure transformer-based image **restoration** architecture surpasses the existing CNN-based methods using multi-task pre-training with a large number of trainable parameters. In this paper, we introduce an effective hybrid architecture for super-resolution (SR) tasks, which leverages local features from CNNs and long-range dependencies captured by transformers to further improve the SR results. Specifically, our architecture comprises of transformer and convolution branches, and we substantially elevate the performance by mutually fusing two branches to complement each representation. Furthermore, we propose a cross-scale token attention module, which allows the transformer to efficiently exploit the informative relationships among tokens across different scales. Our proposed method achieves state-of-the-art SR results on numerous benchmark datasets.  
### An Annotation-free **Restoration** Network for Cataractous Fundus Images. (arXiv:2203.07737v1 [cs.CV])
- Authors : Heng Li, Haofeng Liu, Yan Hu, Huazhu Fu, Yitian Zhao, Hanpei Miao, Jiang Liu
- Link : [http://arxiv.org/abs/2203.07737](http://arxiv.org/abs/2203.07737)
> ABSTRACT  :  Cataracts are the leading cause of vision loss worldwide. **Restoration** algorithms are developed to improve the readability of cataract fundus images in order to increase the certainty in diagnosis and treatment for cataract patients. Unfortunately, the requirement of annotation limits the application of these algorithms in clinics. This paper proposes a network to annotation-freely restore cataractous fundus images (ArcNet) so as to boost the clinical practicability of **restoration**. Annotations are unnecessary in ArcNet, where the high-frequency component is extracted from fundus images to replace segmentation in the preservation of retinal structures. The **restoration** model is learned from the synthesized images and adapted to real cataract images. Extensive experiments are implemented to verify the performance and effectiveness of ArcNet. Favorable performance is achieved using ArcNet against state-of-the-art algorithms, and the diagnosis of ocular fundus diseases in cataract patients is promoted by ArcNet. The capability of properly restoring cataractous images in the absence of annotated data promises the proposed algorithm outstanding clinical practicability.  
### Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization. (arXiv:2203.07740v1 [cs.CV])
- Authors : Yabin Zhang, Minghan Li, Ruihuang Li, Kui Jia, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.07740](http://arxiv.org/abs/2203.07740)
> ABSTRACT  :  Arbitrary style transfer (AST) and domain generalization (DG) are important yet challenging visual learning tasks, which can be cast as a feature distribution matching problem. With the assumption of Gaussian feature distribution, conventional feature distribution matching methods usually match the mean and standard deviation of features. However, the feature distributions of real-world data are usually much more complicated than Gaussian, which cannot be accurately matched by using only the first-order and second-order statistics, while it is computationally prohibitive to use high-order statistics for distribution matching. In this work, we, for the first time to our best knowledge, propose to perform Exact Feature Distribution Matching (EFDM) by exactly matching the empirical Cumulative Distribution Functions (eCDFs) of image features, which could be implemented by applying the Exact Histogram Matching (EHM) in the image feature space. Particularly, a fast EHM algorithm, named Sort-Matching, is employed to perform EFDM in a plug-and-play manner with minimal cost. The effectiveness of our proposed EFDM method is verified on a variety of AST and DG tasks, demonstrating new state-of-the-art results. Codes are available at https://github.com/YBZh/EFDM.  
### Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy. (arXiv:2203.07772v1 [eess.IV])
- Authors : phane Cuenat, Louis Andr, Patrick Sandoz, Maxime Jacquot
- Link : [http://arxiv.org/abs/2203.07772](http://arxiv.org/abs/2203.07772)
> ABSTRACT  :  The numerical wavefront backpropagation principle of digital holography confers unique extended focus capabilities, without mechanical displacements along z-axis. However, the determination of the correct focusing distance is a non-trivial and time consuming issue. A deep learning (DL) solution is proposed to cast the autofocusing as a regression problem and tested over both experimental and simulated holograms. Single wavelength digital holograms were recorded by a Digital Holographic Microscope (DHM) with a 10$\mathrm{x}$ microscope objective from a patterned target moving in 3D over an axial range of 92 $\mu$m. Tiny DL models are proposed and compared such as a tiny Vision Transformer (TViT), tiny VGG16 (TVGG) and a tiny **Swin**-Transfomer (T**Swin**T). The experiments show that the predicted focusing distance $Z_R^{\mathrm{Pred}}$ is accurately inferred with an accuracy of 1.2 $\mu$m in average in comparison with the DHM depth of field of 15 $\mu$m. Numerical simulations show that all tiny models give the $Z_R^{\mathrm{Pred}}$ with an error below 0.3 $\mu$m. Such a prospect would significantly improve the current capabilities of computer vision position sensing in applications such as 3D microscopy for life sciences or micro-robotics. Moreover, all models reach state of the art inference time on CPU, less than 25 ms per inference.  
### Image Quality Assessment for Magnetic Resonance Imaging. (arXiv:2203.07809v1 [eess.IV])
- Authors : Segrey Kastryulin, Jamil Zakirov, Nicola Pezzotti
- Link : [http://arxiv.org/abs/2203.07809](http://arxiv.org/abs/2203.07809)
> ABSTRACT  :  Image quality assessment (IQA) algorithms aim to reproduce the human's perception of the image quality. The growing popularity of image **enhancement**, generation, and recovery models instigated the development of many methods to assess their performance. However, most IQA solutions are designed to predict image quality in the general domain, with the applicability to specific areas, such as medical imaging, remaining questionable. Moreover, the selection of these IQA metrics for a specific task typically involves intentionally induced distortions, such as manually added noise or artificial blurring; yet, the chosen metrics are then used to judge the output of real-life computer vision models. In this work, we aspire to fill these gaps by carrying out the most extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date (14,700 subjective scores). We use outputs of neural network models trained to solve problems relevant to MRI, including image reconstruction in the scan acceleration, motion correction, and denoising. Seven trained radiologists assess these distorted images, with their verdicts then correlated with 35 different image quality metrics (full-reference, no-reference, and distribution-based metrics considered). Our emphasis is on reflecting the radiologist's perception of the reconstructed images, gauging the most diagnostically influential criteria for the quality of MRI scans: signal-to-noise ratio, contrast-to-noise ratio, and the presence of artifacts.  
### Panoptic SwiftNet: Pyramidal Fusion for **Real-time** Panoptic Segmentation. (arXiv:2203.07908v1 [cs.CV])
- Authors : Marin Or
- Link : [http://arxiv.org/abs/2203.07908](http://arxiv.org/abs/2203.07908)
> ABSTRACT  :  Dense panoptic prediction is a key ingredient in many existing applications such as autonomous driving, automated warehouses or agri-robotics. However, most of these applications leverage the recovered dense semantics as an input to visual closed-loop control. Hence, practical deployments require real-time inference over large input resolutions on embedded hardware. These requirements call for computationally efficient approaches which deliver high accuracy with limited computational resources. We propose to achieve this goal by trading-off backbone capacity for multi-scale feature extraction. In comparison with contemporaneous approaches to panoptic segmentation, the main novelties of our method are scale-equivariant feature extraction and cross-scale upsampling through pyramidal fusion. Our best model achieves 55.9% PQ on Cityscapes val at 60 FPS on full resolution 2MPx images and RTX3090 with FP16 Tensor RT optimization.  
### OcclusionFusion: Occlusion-aware Motion Estimation for **Real-time** Dynamic 3D Reconstruction. (arXiv:2203.07977v1 [cs.CV])
- Authors : Wenbin Lin, Chengwei Zheng, Hai Yong, Feng Xu
- Link : [http://arxiv.org/abs/2203.07977](http://arxiv.org/abs/2203.07977)
> ABSTRACT  :  RGBD-based real-time dynamic 3D reconstruction suffers from inaccurate inter-frame motion estimation as errors may accumulate with online tracking. This problem is even more severe for single-view-based systems due to strong occlusions. Based on these observations, we propose OcclusionFusion, a novel method to calculate occlusion-aware 3D motion to guide the reconstruction. In our technique, the motion of visible regions is first estimated and combined with temporal information to infer the motion of the occluded regions through an LSTM-involved graph neural network. Furthermore, our method computes the confidence of the estimated motion by modeling the network output with a probabilistic model, which alleviates untrustworthy motions and enables robust tracking. Experimental results on public datasets and our own recorded data show that our technique outperforms existing single-view-based real-time methods by a large margin. With the reduction of the motion errors, the proposed technique can handle long and challenging motion sequences. Please check out the project page for sequence results: https://wenbin-lin.github.io/OcclusionFusion.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
### On the Connection between Local Attention and Dynamic Depth-wise Convolution. (arXiv:2106.04263v3 [cs.CV] UPDATED)
- Authors : Qi Han, Zejia Fan, Qi Dai, Lei Sun, Ming Cheng, **Jiaying Liu**, Jingdong Wang
- Link : [http://arxiv.org/abs/2106.04263](http://arxiv.org/abs/2106.04263)
> ABSTRACT  :  Vision Transformer (ViT) attains state-of-the-art performance in visual recognition, and the variant, Local Vision Transformer, makes further improvements. The major component in Local Vision Transformer, local attention, performs the attention separately over small local windows. We rephrase local attention as a channel-wise locally-connected layer and analyze it from two network regularization manners, sparse connectivity and weight sharing, as well as weight computation. Sparse connectivity: there is no connection across channels, and each position is connected to the positions within a small local window. Weight sharing: the connection weights for one position are shared across channels or within each group of channels. Dynamic weight: the connection weights are dynamically predicted according to each image instance. We point out that local attention resembles depth-wise convolution and its dynamic version in sparse connectivity. The main difference lies in weight sharing - depth-wise convolution shares connection weights (kernel weights) across spatial positions. We empirically observe that the models based on depth-wise convolution and the dynamic variant with lower computation complexity perform on-par with or sometimes slightly better than **Swin** Transformer, an instance of Local Vision Transformer, for ImageNet classification, COCO object detection and ADE semantic segmentation. These observations suggest that Local Vision Transformer takes advantage of two regularization forms and dynamic weight to increase the network capacity. Code is available at https://github.com/Atten4Vis/DemystifyLocalViT.  
### Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v3 [cs.CV] UPDATED)
- Authors : Zhiyuan You, Yujun Shen, Kai Yang, Wenhan Luo, Xin Lu, Lei Cui, Xinyi Le
- Link : [http://arxiv.org/abs/2201.08959](http://arxiv.org/abs/2201.08959)
> ABSTRACT  :  This work studies the problem of few-shot object counting, which counts the number of exemplar objects (i.e., described by one or several support images) occurring in the query image. The major challenge lies in that the target objects can be densely packed in the query image, making it hard to recognize every single one. To tackle the obstacle, we propose a novel learning block, equipped with a similarity comparison module (SCM) and a feature **enhancement** module (FEM). Concretely, given a support image and a query image, we first derive a score map by comparing their projected features at every spatial position. The score maps regarding all support images are collected together and normalized across both the exemplar dimension and the spatial dimensions, producing a reliable similarity map. We then enhance the query feature with the support features by employing the developed point-wise similarities as the weighting coefficients. Such a design encourages the model to inspect the query image by focusing more on the regions akin to the support images, leading to much clearer boundaries between different objects. Extensive experiments on various benchmarks and training setups suggest that our method surpasses the state-of-the-art approaches by a sufficiently large margin. For instance, on the very recent large-scale FSC-147 dataset, we beat the second competitor by improving the mean absolute counting error from 22.08 to 14.32 (35% $\uparrow$).  
### Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
- Authors : Xiuwei Xu, Yifan Wang, Yu Zheng, Yongming Rao, Jie Zhou, Jiwen Lu
- Link : [http://arxiv.org/abs/2203.05238](http://arxiv.org/abs/2203.05238)
> ABSTRACT  :  In this paper, we propose a weakly-supervised approach for 3D object detection, which makes it possible to train strong 3D detector with position-level annotations (i.e. annotations of object centers). In order to remedy the information loss from box annotations to centers, our method, namely Back to Reality (BR), makes use of synthetic 3D shapes to convert the weak labels into fully-annotated virtual scenes as stronger supervision, and in turn utilizes the perfect virtual labels to complement and refine the real labels. Specifically, we first assemble 3D shapes into physically reasonable virtual scenes according to the coarse scene layout extracted from position-level annotations. Then we go back to reality by applying a virtual-to-real domain adaptation method, which refine the weak labels and additionally supervise the training of detector with the virtual scenes. Furthermore, we propose a more challenging benckmark for indoor 3D object detection with more diversity in object sizes to better show the potential of BR. With less than 5% of the labeling labor, we achieve comparable detection performance with some popular fully-supervised approaches on the widely used ScanNet dataset. Code is available at: https://github.com/wyf-ACCEPT/BackToReality  
### Bringing Rolling Shutter Images Alive with Dual Reversed Distortion. (arXiv:2203.06451v2 [cs.CV] UPDATED)
- Authors : Zhihang Zhong, Mingdeng Cao, Xiao Sun, Zhirong Wu, Zhongyi Zhou, Yinqiang Zheng, Stephen Lin, Imari Sato
- Link : [http://arxiv.org/abs/2203.06451](http://arxiv.org/abs/2203.06451)
> ABSTRACT  :  Rolling shutter (RS) distortion can be interpreted as the result of picking a row of pixels from instant global shutter (GS) frames over time during the **exposure** of the RS camera. This means that the information of each instant GS frame is partially, yet sequentially, embedded into the row-dependent distortion. Inspired by this fact, we address the challenging task of reversing this process, i.e., extracting undistorted GS frames from images suffering from RS distortion. However, since RS distortion is coupled with other factors such as readout settings and the relative velocity of scene elements to the camera, models that only exploit the geometric correlation between temporally adjacent images suffer from poor generality in processing data with different readout settings and dynamic scenes with both camera motion and object motion. In this paper, instead of two consecutive frames, we propose to exploit a pair of images captured by dual RS cameras with reversed RS directions for this highly challenging task. Grounded on the symmetric and complementary nature of dual reversed distortion, we develop a novel end-to-end model, IFED, to generate dual optical flow sequence through iterative learning of the velocity field during the RS time. Extensive experimental results demonstrate that IFED is superior to naive cascade schemes, as well as the state-of-the-art which utilizes adjacent RS images. Most importantly, although it is trained on a synthetic dataset, IFED is shown to be effective at retrieving GS frame sequences from real-world RS distorted images of dynamic scenes.  
## eess.IV
---
### Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v1 [eess.IV])
- Authors : Xiang Chen, Zhentao Fan, Zhuoran Zheng, Yufeng Li, Yufeng Huang, Longgang Dai, Caihua Kong, Pengpeng Li
- Link : [http://arxiv.org/abs/2203.07677](http://arxiv.org/abs/2203.07677)
> ABSTRACT  :  We present an effective unpaired learning based image dehazing network from an unpaired set of clear and hazy images. This paper provides a new perspective to treat image dehazing as a two-class separated factor disentanglement task, i.e, the task-relevant factor of clear image reconstruction and the task-irrelevant factor of haze-relevant distribution. To achieve the disentanglement of these two-class factors in deep feature space, contrastive learning is introduced into a CycleGAN framework to learn disentangled representations by guiding the generated images to be associated with latent factors. With such formulation, the proposed contrastive disentangled dehazing method (CDD-GAN) first develops negative generators to cooperate with the encoder network to update alternately, so as to produce a queue of challenging negative adversaries. Then these negative adversaries are trained end-to-end together with the backbone representation network to enhance the discriminative information and promote factor disentanglement performance by maximizing the adversarial contrastive loss. During the training, we further show that hard negative examples can suppress the task-irrelevant factors and unpaired clear exemples can enhance the task-relevant factors, in order to better facilitate haze removal and help image **restoration**. Extensive experiments on both synthetic and real-world datasets demonstrate that our method performs favorably against existing state-of-the-art unpaired dehazing approaches.  
### Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy. (arXiv:2203.07772v1 [eess.IV])
- Authors : phane Cuenat, Louis Andr, Patrick Sandoz, Maxime Jacquot
- Link : [http://arxiv.org/abs/2203.07772](http://arxiv.org/abs/2203.07772)
> ABSTRACT  :  The numerical wavefront backpropagation principle of digital holography confers unique extended focus capabilities, without mechanical displacements along z-axis. However, the determination of the correct focusing distance is a non-trivial and time consuming issue. A deep learning (DL) solution is proposed to cast the autofocusing as a regression problem and tested over both experimental and simulated holograms. Single wavelength digital holograms were recorded by a Digital Holographic Microscope (DHM) with a 10$\mathrm{x}$ microscope objective from a patterned target moving in 3D over an axial range of 92 $\mu$m. Tiny DL models are proposed and compared such as a tiny Vision Transformer (TViT), tiny VGG16 (TVGG) and a tiny **Swin**-Transfomer (T**Swin**T). The experiments show that the predicted focusing distance $Z_R^{\mathrm{Pred}}$ is accurately inferred with an accuracy of 1.2 $\mu$m in average in comparison with the DHM depth of field of 15 $\mu$m. Numerical simulations show that all tiny models give the $Z_R^{\mathrm{Pred}}$ with an error below 0.3 $\mu$m. Such a prospect would significantly improve the current capabilities of computer vision position sensing in applications such as 3D microscopy for life sciences or micro-robotics. Moreover, all models reach state of the art inference time on CPU, less than 25 ms per inference.  
### Image Quality Assessment for Magnetic Resonance Imaging. (arXiv:2203.07809v1 [eess.IV])
- Authors : Segrey Kastryulin, Jamil Zakirov, Nicola Pezzotti
- Link : [http://arxiv.org/abs/2203.07809](http://arxiv.org/abs/2203.07809)
> ABSTRACT  :  Image quality assessment (IQA) algorithms aim to reproduce the human's perception of the image quality. The growing popularity of image **enhancement**, generation, and recovery models instigated the development of many methods to assess their performance. However, most IQA solutions are designed to predict image quality in the general domain, with the applicability to specific areas, such as medical imaging, remaining questionable. Moreover, the selection of these IQA metrics for a specific task typically involves intentionally induced distortions, such as manually added noise or artificial blurring; yet, the chosen metrics are then used to judge the output of real-life computer vision models. In this work, we aspire to fill these gaps by carrying out the most extensive IQA evaluation study for Magnetic Resonance Imaging (MRI) to date (14,700 subjective scores). We use outputs of neural network models trained to solve problems relevant to MRI, including image reconstruction in the scan acceleration, motion correction, and denoising. Seven trained radiologists assess these distorted images, with their verdicts then correlated with 35 different image quality metrics (full-reference, no-reference, and distribution-based metrics considered). Our emphasis is on reflecting the radiologist's perception of the reconstructed images, gauging the most diagnostically influential criteria for the quality of MRI scans: signal-to-noise ratio, contrast-to-noise ratio, and the presence of artifacts.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
## cs.LG
---
### Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
- Authors : Marco Cardia, Massimiliano Luca, Luca Pappalardo
- Link : [http://arxiv.org/abs/2203.07372](http://arxiv.org/abs/2203.07372)
> ABSTRACT  :  Thanks to the diffusion of the Internet of Things, nowadays it is possible to sense human mobility almost in **real time** using unconventional methods (e.g., number of bikes in a bike station). Due to the diffusion of such technologies, the last years have witnessed a significant growth of human mobility studies, motivated by their importance in a wide range of applications, from traffic management to public security and computational epidemiology. A mobility task that is becoming prominent is crowd flow prediction, i.e., forecasting aggregated incoming and outgoing flows in the locations of a geographic region. Although several deep learning approaches have been proposed to solve this problem, their usage is limited to specific types of spatial tessellations and cannot provide sufficient explanations of their predictions. We propose CrowdNet, a solution to crowd flow prediction based on graph convolutional networks. Compared with state-of-the-art solutions, CrowdNet can be used with regions of irregular shapes and provide meaningful explanations of the predicted crowd flows. We conduct experiments on public data varying the spatio-temporal granularity of crowd flows to show the superiority of our model with respect to existing methods, and we investigate CrowdNet's reliability to missing or noisy input data. Our model is a step forward in the design of reliable deep learning models to predict and explain human displacements in urban environments.  
### Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning. (arXiv:2203.07413v1 [cs.LG])
- Authors : Qinjie Lin, Han Liu, Biswa Sengupta
- Link : [http://arxiv.org/abs/2203.07413](http://arxiv.org/abs/2203.07413)
> ABSTRACT  :  We propose SwitchTT, a multi-task extension to Trajectory Transformer but enhanced with two striking features: (i) exploiting a sparsely activated model to reduce computation cost in multi-task offline model learning and (ii) adopting a distributional trajectory value estimator that improves policy performance, especially in sparse reward settings. These two **enhancement**s make SwitchTT suitable for solving multi-task offline reinforcement learning problems, where model capacity is critical for absorbing the vast quantities of knowledge available in the multi-task dataset. More specifically, SwitchTT exploits switch transformer model architecture for multi-task policy learning, allowing us to improve model capacity without proportional computation cost. Also, SwitchTT approximates the distribution rather than the expectation of trajectory value, mitigating the effects of the Monte-Carlo Value estimator suffering from poor sample complexity, especially in the sparse-reward setting. We evaluate our method using the suite of ten sparse-reward tasks from the gym-mini-grid environment.We show an improvement of 10% over Trajectory Transformer across 10-task learning and obtain up to 90% increase in offline model training speed. Our results also demonstrate the advantage of the switch transformer model for absorbing expert knowledge and the importance of value distribution in evaluating the trajectory.  
### Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information. (arXiv:2203.07893v1 [cs.CL])
- Authors : Shun Shao, Yftah Ziser
- Link : [http://arxiv.org/abs/2203.07893](http://arxiv.org/abs/2203.07893)
> ABSTRACT  :  We describe a simple and effective method (Spectral Attribute removaL; SAL) to remove guarded information from neural representations. Our method uses singular value decomposition and eigenvalue decomposition to project the input representations into directions with reduced covariance with the guarded information rather than maximal covariance as normally these factorization methods are used. We begin with linear information removal and proceed to generalize our algorithm to the case of nonlinear information removal through the use of kernels. Our experiments demonstrate that our algorithm retains better main task performance after removing the guarded information compared to previous methods. In addition, our experiments demonstrate that we need a relatively small amount of guarded attribute data to remove information about these attributes, which lowers the **exposure** to such possibly sensitive data and fits better low-resource scenarios.  
### Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
- Authors : Innfarn Yoo, Huiwen Chang, Xiyang Luo, Ondrej Stava, Ce Liu, **Peyman Milanfar**, Feng Yang
- Link : [http://arxiv.org/abs/2104.13450](http://arxiv.org/abs/2104.13450)
> ABSTRACT  :  Digital watermarking is widely used for copyright protection. Traditional 3D watermarking approaches or commercial software are typically designed to embed messages into 3D meshes, and later retrieve the messages directly from distorted/undistorted watermarked 3D meshes. However, in many cases, users only have access to rendered 2D images instead of 3D meshes. Unfortunately, retrieving messages from 2D renderings of 3D meshes is still challenging and underexplored. We introduce a novel end-to-end learning framework to solve this problem through: 1) an encoder to covertly embed messages in both mesh geometry and textures; 2) a differentiable renderer to render watermarked 3D objects from different camera angles and under varied lighting conditions; 3) a decoder to recover the messages from 2D rendered images. From our experiments, we show that our model can learn to embed information visually imperceptible to humans, and to retrieve the embedded information from 2D renderings that undergo 3D distortions. In addition, we demonstrate that our method can also work with other renderers, such as ray tracers and real-time renderers with and without fine-tuning.  
### Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
- Authors : Xiuwei Xu, Yifan Wang, Yu Zheng, Yongming Rao, Jie Zhou, Jiwen Lu
- Link : [http://arxiv.org/abs/2203.05238](http://arxiv.org/abs/2203.05238)
> ABSTRACT  :  In this paper, we propose a weakly-supervised approach for 3D object detection, which makes it possible to train strong 3D detector with position-level annotations (i.e. annotations of object centers). In order to remedy the information loss from box annotations to centers, our method, namely Back to Reality (BR), makes use of synthetic 3D shapes to convert the weak labels into fully-annotated virtual scenes as stronger supervision, and in turn utilizes the perfect virtual labels to complement and refine the real labels. Specifically, we first assemble 3D shapes into physically reasonable virtual scenes according to the coarse scene layout extracted from position-level annotations. Then we go back to reality by applying a virtual-to-real domain adaptation method, which refine the weak labels and additionally supervise the training of detector with the virtual scenes. Furthermore, we propose a more challenging benckmark for indoor 3D object detection with more diversity in object sizes to better show the potential of BR. With less than 5% of the labeling labor, we achieve comparable detection performance with some popular fully-supervised approaches on the widely used ScanNet dataset. Code is available at: https://github.com/wyf-ACCEPT/BackToReality  
### Varying Coefficient Linear Discriminant Analysis for Dynamic Data. (arXiv:2203.06371v2 [stat.ME] UPDATED)
- Authors : Yajie Bao, Yuyang Liu
- Link : [http://arxiv.org/abs/2203.06371](http://arxiv.org/abs/2203.06371)
> ABSTRACT  :  Linear discriminant analysis (LDA) is a vital classification tool in statistics and machine learning. This paper investigates the varying coefficient LDA model for dynamic data, with Bayes' discriminant direction being a function of some **exposure** variable to address the heterogeneity. By deriving a new discriminant direction function parallel with Bayes' direction, we propose a least-square estimation procedure based on the B-spline approximation. For high-dimensional regime, the corresponding data-driven discriminant rule is more computationally efficient than the existed dynamic linear programming rule. We also establish the corresponding theoretical results, including estimation error bound and the uniform excess misclassification rate. Numerical experiments on synthetic data and real data both corroborate the superiority of our proposed classification method.  
## cs.AI
---
### Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
- Authors : Marco Cardia, Massimiliano Luca, Luca Pappalardo
- Link : [http://arxiv.org/abs/2203.07372](http://arxiv.org/abs/2203.07372)
> ABSTRACT  :  Thanks to the diffusion of the Internet of Things, nowadays it is possible to sense human mobility almost in **real time** using unconventional methods (e.g., number of bikes in a bike station). Due to the diffusion of such technologies, the last years have witnessed a significant growth of human mobility studies, motivated by their importance in a wide range of applications, from traffic management to public security and computational epidemiology. A mobility task that is becoming prominent is crowd flow prediction, i.e., forecasting aggregated incoming and outgoing flows in the locations of a geographic region. Although several deep learning approaches have been proposed to solve this problem, their usage is limited to specific types of spatial tessellations and cannot provide sufficient explanations of their predictions. We propose CrowdNet, a solution to crowd flow prediction based on graph convolutional networks. Compared with state-of-the-art solutions, CrowdNet can be used with regions of irregular shapes and provide meaningful explanations of the predicted crowd flows. We conduct experiments on public data varying the spatio-temporal granularity of crowd flows to show the superiority of our model with respect to existing methods, and we investigate CrowdNet's reliability to missing or noisy input data. Our model is a step forward in the design of reliable deep learning models to predict and explain human displacements in urban environments.  
### Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning. (arXiv:2203.07413v1 [cs.LG])
- Authors : Qinjie Lin, Han Liu, Biswa Sengupta
- Link : [http://arxiv.org/abs/2203.07413](http://arxiv.org/abs/2203.07413)
> ABSTRACT  :  We propose SwitchTT, a multi-task extension to Trajectory Transformer but enhanced with two striking features: (i) exploiting a sparsely activated model to reduce computation cost in multi-task offline model learning and (ii) adopting a distributional trajectory value estimator that improves policy performance, especially in sparse reward settings. These two **enhancement**s make SwitchTT suitable for solving multi-task offline reinforcement learning problems, where model capacity is critical for absorbing the vast quantities of knowledge available in the multi-task dataset. More specifically, SwitchTT exploits switch transformer model architecture for multi-task policy learning, allowing us to improve model capacity without proportional computation cost. Also, SwitchTT approximates the distribution rather than the expectation of trajectory value, mitigating the effects of the Monte-Carlo Value estimator suffering from poor sample complexity, especially in the sparse-reward setting. We evaluate our method using the suite of ten sparse-reward tasks from the gym-mini-grid environment.We show an improvement of 10% over Trajectory Transformer across 10-task learning and obtain up to 90% increase in offline model training speed. Our results also demonstrate the advantage of the switch transformer model for absorbing expert knowledge and the importance of value distribution in evaluating the trajectory.  
### Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
- Authors : Xiuwei Xu, Yifan Wang, Yu Zheng, Yongming Rao, Jie Zhou, Jiwen Lu
- Link : [http://arxiv.org/abs/2203.05238](http://arxiv.org/abs/2203.05238)
> ABSTRACT  :  In this paper, we propose a weakly-supervised approach for 3D object detection, which makes it possible to train strong 3D detector with position-level annotations (i.e. annotations of object centers). In order to remedy the information loss from box annotations to centers, our method, namely Back to Reality (BR), makes use of synthetic 3D shapes to convert the weak labels into fully-annotated virtual scenes as stronger supervision, and in turn utilizes the perfect virtual labels to complement and refine the real labels. Specifically, we first assemble 3D shapes into physically reasonable virtual scenes according to the coarse scene layout extracted from position-level annotations. Then we go back to reality by applying a virtual-to-real domain adaptation method, which refine the weak labels and additionally supervise the training of detector with the virtual scenes. Furthermore, we propose a more challenging benckmark for indoor 3D object detection with more diversity in object sizes to better show the potential of BR. With less than 5% of the labeling labor, we achieve comparable detection performance with some popular fully-supervised approaches on the widely used ScanNet dataset. Code is available at: https://github.com/wyf-ACCEPT/BackToReality  
# Paper List
---
## cs.CV
---
**162** new papers in cs.CV:-) 
1. Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
2. SATr: Slice Attention with Transformer for Universal Lesion Detection. (arXiv:2203.07373v1 [eess.IV])
3. There's no difference: Convolutional Neural Networks for transient detection without template subtraction. (arXiv:2203.07390v1 [cs.CV])
4. Panoptic animal pose estimators are zero-shot performers. (arXiv:2203.07436v1 [cs.CV])
5. Unsupervised Clustering of Roman Potsherds via Variational Autoencoders. (arXiv:2203.07437v1 [cs.CV])
6. A deep learning pipeline for breast cancer ki-67 proliferation index scoring. (arXiv:2203.07452v1 [eess.IV])
7. Skydiver: A Spiking Neural Network Accelerator Exploiting Spatio-Temporal Workload Balance. (arXiv:2203.07516v1 [cs.AR])
8. Fast Active Monocular Distance Estimation from Time-to-Contact. (arXiv:2203.07530v1 [cs.RO])
9. VPFusion: Joint 3D Volume and Pixel-Aligned Feature Fusion for Single and Multi-view 3D Reconstruction. (arXiv:2203.07553v1 [cs.CV])
10. Task-Agnostic Robust Representation Learning. (arXiv:2203.07596v1 [cs.LG])
11. CARETS: A Consistency And Robustness Evaluative Test Suite for VQA. (arXiv:2203.07613v1 [cs.CL])
12. Learning What Not to Segment: A New Perspective on Few-Shot Segmentation. (arXiv:2203.07615v1 [cs.CV])
13. P-STMO: Pre-Trained Spatial Temporal Many-to-One Model for 3D Human Pose Estimation. (arXiv:2203.07628v1 [cs.CV])
14. Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness. (arXiv:2203.07653v1 [cs.CL])
15. Wave-SAN: Wavelet based Style Augmentation Network for Cross-Domain Few-Shot Learning. (arXiv:2203.07656v1 [cs.CV])
16. Neural Radiance Projection. (arXiv:2203.07658v1 [cs.CV])
17. Breast Cancer Molecular Subtypes Prediction on Pathological Images with Discriminative Patch Selecting and Multi-Instance Learning. (arXiv:2203.07659v1 [eess.IV])
18. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v1 [cs.CV])
19. Can you even tell left from right? Presenting a new challenge for VQA. (arXiv:2203.07664v1 [cs.CV])
20. SATS: Self-Attention Transfer for Continual Semantic Segmentation. (arXiv:2203.07667v1 [cs.CV])
21. Progressive End-to-End Object Detection in Crowded Scenes. (arXiv:2203.07669v1 [cs.CV])
22. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v1 [eess.IV])
23. Rich CNN-Transformer Feature Aggregation Networks for Super-Resolution. (arXiv:2203.07682v1 [cs.CV])
24. InsCon:Instance Consistency Feature Representation via Self-Supervised Learning. (arXiv:2203.07688v1 [cs.CV])
25. Implicit field supervision for robust non-rigid shape matching. (arXiv:2203.07694v1 [cs.CV])
26. Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation. (arXiv:2203.07697v1 [cs.CV])
27. APRNet: Attention-based Pixel-wise Rendering Network for Photo-Realistic Text Image Generation. (arXiv:2203.07705v1 [cs.CV])
28. ActFormer: A GAN Transformer Framework towards General Action-Conditioned 3D Human Motion Generation. (arXiv:2203.07706v1 [cs.CV])
29. Magnification Prior: A Self-Supervised Method for Learning Representations on Breast Cancer Histopathological Images. (arXiv:2203.07707v1 [eess.IV])
30. Revitalize Region Feature for Democratizing Video-Language Pre-training. (arXiv:2203.07720v1 [cs.CV])
31. CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving. (arXiv:2203.07724v1 [cs.CV])
32. Meta Ordinal Regression Forest for Medical Image Classification with Ordinal Labels. (arXiv:2203.07725v1 [cs.CV])
33. Securing the Classification of COVID-19 in Chest X-ray Images: A Privacy-Preserving Deep Learning Approach. (arXiv:2203.07728v1 [eess.IV])
34. S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular Image. (arXiv:2203.07732v1 [cs.CV])
35. An Annotation-free **Restoration** Network for Cataractous Fundus Images. (arXiv:2203.07737v1 [cs.CV])
36. CSN: Component-Supervised Network for Few-Shot Classification. (arXiv:2203.07738v1 [cs.CV])
37. Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization. (arXiv:2203.07740v1 [cs.CV])
38. Multi-Curve Translator for Real-Time High-Resolution Image-to-Image Translation. (arXiv:2203.07756v1 [cs.CV])
39. Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy. (arXiv:2203.07772v1 [eess.IV])
40. Scalable Penalized Regression for Noise Detection in Learning with Noisy Labels. (arXiv:2203.07788v1 [cs.LG])
41. Parking Analytics Framework using Deep Learning. (arXiv:2203.07792v1 [cs.CV])
42. On the focusing of thermal images. (arXiv:2203.07805v1 [cs.CV])
43. Interspace Pruning: Using Adaptive Filter Representations to Improve Training of Sparse CNNs. (arXiv:2203.07808v1 [cs.CV])
44. Image Quality Assessment for Magnetic Resonance Imaging. (arXiv:2203.07809v1 [eess.IV])
45. Adversarial Counterfactual Augmentation: Application in Alzheimer's Disease Classification. (arXiv:2203.07815v1 [cs.CV])
46. SISL:Self-Supervised Image Signature Learning for Splicing Detection and Localization. (arXiv:2203.07824v1 [cs.CV])
47. SPA-VAE: Similar-Parts-Assignment for Unsupervised 3D Point Cloud Generation. (arXiv:2203.07825v1 [cs.CV])
48. Pose-MUM : Reinforcing Key Points Relationship for Semi-Supervised Human Pose Estimation. (arXiv:2203.07837v1 [cs.CV])
49. Bamboo: Building Mega-Scale Vision Dataset Continually with Human-Machine Synergy. (arXiv:2203.07845v1 [cs.CV])
50. Recursive 3D Segmentation of Shoulder Joint with Coarse-scanned MR Image. (arXiv:2203.07846v1 [eess.IV])
51. A Survey of Non-Rigid 3D Registration. (arXiv:2203.07858v1 [cs.CV])
52. Don't Get Me Wrong: How to apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v1 [cs.CV])
53. LiP-Flow: Learning Inference-time Priors for Codec Avatars via Normalizing Flows in Latent Space. (arXiv:2203.07881v1 [cs.CV])
54. K-VQG: Knowledge-aware Visual Question Generation for Common-sense Acquisition. (arXiv:2203.07890v1 [cs.CV])
55. Generalized Rectifier Wavelet Covariance Models For Texture Synthesis. (arXiv:2203.07902v1 [cs.CV])
56. Unsupervised Learning Based Focal Stack Camera Depth Estimation. (arXiv:2203.07904v1 [cs.CV])
57. Panoptic SwiftNet: Pyramidal Fusion for **Real-time** Panoptic Segmentation. (arXiv:2203.07908v1 [cs.CV])
58. Deep Transfer Learning with Graph Neural Network for Sensor-Based Human Activity Recognition. (arXiv:2203.07910v1 [cs.CV])
59. GPV-Pose: Category-level Object Pose Estimation via Geometry-guided Point-wise Voting. (arXiv:2203.07918v1 [cs.CV])
60. Relative Pose from SIFT Features. (arXiv:2203.07930v1 [cs.CV])
61. DialogueNeRF: Towards Realistic Avatar Face-to-face Conversation Video Generation. (arXiv:2203.07931v1 [cs.CV])
62. Style Transformer for Image Inversion and Editing. (arXiv:2203.07932v1 [cs.CV])
63. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v1 [cs.CV])
64. MOBDrone: a Drone Video Dataset for Man OverBoard Rescue. (arXiv:2203.07973v1 [cs.CV])
65. On the Pitfalls of Batch Normalization for End-to-End Video Learning: A Study on Surgical Workflow Analysis. (arXiv:2203.07976v1 [cs.CV])
66. OcclusionFusion: Occlusion-aware Motion Estimation for **Real-time** Dynamic 3D Reconstruction. (arXiv:2203.07977v1 [cs.CV])
67. Object Detection as Probabilistic Set Prediction. (arXiv:2203.07980v1 [cs.CV])
68. Smoothing Matters: Momentum Transformer for Domain Adaptive Semantic Segmentation. (arXiv:2203.07988v1 [cs.CV])
69. Leveraging Uni-Modal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition. (arXiv:2203.07996v1 [cs.SD])
70. Inverted Pyramid Multi-task Transformer for Dense Scene Understanding. (arXiv:2203.07997v1 [cs.CV])
71. End-to-End Modeling via Information Tree for One-Shot Natural Language Spatial Video Grounding. (arXiv:2203.08013v1 [cs.CV])
72. A Noise-level-aware Framework for PET Image Denoising. (arXiv:2203.08034v1 [eess.IV])
73. Deep learning for radar data exploitation of autonomous vehicle. (arXiv:2203.08038v1 [cs.CV])
74. Simultaneous Localisation and Mapping with Quadric Surfaces. (arXiv:2203.08040v1 [cs.RO])
75. A multi-organ point cloud registration algorithm for abdominal CT registration. (arXiv:2203.08041v1 [cs.CV])
76. On Hyperbolic Embeddings in 2D Object Detection. (arXiv:2203.08049v1 [cs.CV])
77. Seeking Commonness and Inconsistencies: A Jointly Smoothed Approach to Multi-view Subspace Clustering. (arXiv:2203.08060v1 [cs.CV])
78. MotionCLIP: Exposing Human Motion Generation to CLIP Space. (arXiv:2203.08063v1 [cs.CV])
79. Things not Written in Text: Exploring Spatial Commonsense from Visual Signals. (arXiv:2203.08075v1 [cs.CL])
80. Implicit Feature Decoupling with Depthwise Quantization. (arXiv:2203.08080v1 [cs.CV])
81. ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity. (arXiv:2203.08101v1 [cs.CV])
82. From 2D to 3D: Re-thinking Benchmarking of Monocular Depth Prediction. (arXiv:2203.08122v1 [cs.CV])
83. Can Neural Nets Learn the Same Model Twice? Investigating Reproducibility and Double Descent from the Decision Boundary Perspective. (arXiv:2203.08124v1 [cs.LG])
84. One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning. (arXiv:2203.08130v1 [cs.CV])
85. Animatable Neural Implicit Surfaces for Creating Avatars from Videos. (arXiv:2203.08133v1 [cs.CV])
86. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v1 [cs.CV])
87. Learning Spatio-Temporal Downsampling for Effective Video Upscaling. (arXiv:2203.08140v1 [cs.CV])
88. Object Manipulation via Visual Target Localization. (arXiv:2203.08141v1 [cs.CV])
89. Efficient Deep Neural Network for Photo-realistic Image Super-Resolution. (arXiv:1903.02240v5 [cs.CV] UPDATED)
90. MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks. (arXiv:2007.08386v2 [cs.CV] UPDATED)
91. Automatic Extrinsic Calibration Method for LiDAR and Camera Sensor Setups. (arXiv:2101.04431v2 [cs.RO] UPDATED)
92. Evaluating Large-Vocabulary Object Detectors: The Devil is in the Details. (arXiv:2102.01066v2 [cs.CV] UPDATED)
93. Towards Building A Group-based Unsupervised Representation Disentanglement Framework. (arXiv:2102.10303v2 [cs.LG] UPDATED)
94. Unveiling the Power of Mixup for Stronger Classifiers. (arXiv:2103.13027v4 [cs.CV] UPDATED)
95. Neural RGB-D Surface Reconstruction. (arXiv:2104.04532v3 [cs.CV] UPDATED)
96. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
97. On the Connection between Local Attention and Dynamic Depth-wise Convolution. (arXiv:2106.04263v3 [cs.CV] UPDATED)
98. AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v2 [cs.LG] UPDATED)
99. Generative Models as a Data Source for Multiview Representation Learning. (arXiv:2106.05258v2 [cs.CV] UPDATED)
100. Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic Manipulation via Discretisation. (arXiv:2106.12534v2 [cs.RO] UPDATED)
101. From General to Specific: Online Updating for Blind Super-Resolution. (arXiv:2107.02398v2 [cs.CV] UPDATED)
102. Exploring Set Similarity for Dense Self-supervised Representation Learning. (arXiv:2107.08712v2 [cs.CV] UPDATED)
103. Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v2 [cs.CV] UPDATED)
104. Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis DOmain Generalization Challenge. (arXiv:2108.11269v3 [eess.IV] UPDATED)
105. The Application of Convolutional Neural Networks for Tomographic Reconstruction of Hyperspectral Images. (arXiv:2108.13458v2 [eess.IV] UPDATED)
106. Joint Distribution Alignment via Adversarial Learning for Domain Adaptive Object Detection. (arXiv:2109.09033v2 [cs.CV] UPDATED)
107. StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation. (arXiv:2109.10115v3 [cs.CV] UPDATED)
108. DAMix: A Density-Aware Mixup Augmentation for Single Image Dehazing under Domain Shift. (arXiv:2109.12544v2 [cs.CV] UPDATED)
109. All-Around Real Label Supervision: Cyclic Prototype Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.13930v2 [eess.IV] UPDATED)
110. Trivial or impossible -- dichotomous data difficulty masks model differences (on ImageNet and beyond). (arXiv:2110.05922v2 [cs.CV] UPDATED)
111. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v4 [cs.LG] UPDATED)
112. Semantically Distributed Robust Optimization for Vision-and-Language Inference. (arXiv:2110.07165v2 [cs.CV] UPDATED)
113. Neural Dubber: Dubbing for Videos According to Scripts. (arXiv:2110.08243v3 [eess.AS] UPDATED)
114. A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models. (arXiv:2110.08484v2 [cs.CV] UPDATED)
115. A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification. (arXiv:2110.09759v2 [cs.LG] UPDATED)
116. Illiterate DALL-E Learns to Compose. (arXiv:2110.11405v3 [cs.CV] UPDATED)
117. SILT: Self-supervised Lighting Transfer Using Implicit Image Decomposition. (arXiv:2110.12914v2 [cs.CV] UPDATED)
118. Equivariant Contrastive Learning. (arXiv:2111.00899v2 [cs.CV] UPDATED)
119. Automatic Semantic Segmentation of the Lumbar Spine: Clinical Applicability in a Multi-parametric and Multi-centre Study on Magnetic Resonance Images. (arXiv:2111.08712v2 [eess.IV] UPDATED)
120. RAANet: Range-Aware Attention Network for LiDAR-based 3D Object Detection with Auxiliary Density Level Estimation. (arXiv:2111.09515v2 [cs.CV] UPDATED)
121. MUM : Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection. (arXiv:2111.10958v2 [cs.CV] UPDATED)
122. PointMixer: MLP-Mixer for Point Cloud Understanding. (arXiv:2111.11187v3 [cs.CV] UPDATED)
123. Deep Point Cloud Reconstruction. (arXiv:2111.11704v2 [cs.CV] UPDATED)
124. Conditional Object-Centric Learning from Video. (arXiv:2111.12594v2 [cs.CV] UPDATED)
125. Continual Active Learning Using Pseudo-Domains for Limited Labelling Resources and Changing Acquisition Characteristics. (arXiv:2111.13069v2 [cs.CV] UPDATED)
126. Confounder Identification-free Causal Visual Feature Learning. (arXiv:2111.13420v2 [cs.LG] UPDATED)
127. CDGNet: Class Distribution Guided Network for Human Parsing. (arXiv:2111.14173v2 [cs.CV] UPDATED)
128. MeshUDF: Fast and Differentiable Meshing of Unsigned Distance Field Networks. (arXiv:2111.14549v2 [cs.CV] UPDATED)
129. CRIS: CLIP-Driven Referring Image Segmentation. (arXiv:2111.15174v2 [cs.CV] UPDATED)
130. Auxiliary Learning for Self-Supervised Video Representation via Similarity-based Knowledge Distillation. (arXiv:2112.04011v2 [cs.CV] UPDATED)
131. Responsive Listening Head Generation: A Benchmark Dataset and Baseline. (arXiv:2112.13548v2 [cs.CV] UPDATED)
132. A Transformer-Based Siamese Network for Change Detection. (arXiv:2201.01293v6 [cs.CV] UPDATED)
133. Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation. (arXiv:2201.01427v2 [cs.CV] UPDATED)
134. Prototype Guided Network for Anomaly Segmentation. (arXiv:2201.05869v2 [cs.CV] UPDATED)
135. Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v3 [cs.CV] UPDATED)
136. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v3 [cs.CV] UPDATED)
137. Multi-modal unsupervised brain image registration using edge maps. (arXiv:2202.04647v3 [eess.IV] UPDATED)
138. Point Cloud Denoising via Momentum Ascent in Gradient Fields. (arXiv:2202.10094v2 [cs.CV] UPDATED)
139. Rethinking the Zigzag Flattening for Image Reading. (arXiv:2202.10240v2 [cs.CV] UPDATED)
140. Estimation of Looming from LiDAR. (arXiv:2202.10972v2 [cs.CV] UPDATED)
141. Learning Transferable Reward for Query Object Localization with Policy Adaptation. (arXiv:2202.12403v3 [cs.CV] UPDATED)
142. Semantic Supervision: Enabling Generalization over Output Spaces. (arXiv:2202.13100v2 [cs.LG] UPDATED)
143. GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction. (arXiv:2203.03079v2 [cs.CV] UPDATED)
144. RC-MVSNet: Unsupervised Multi-View Stereo with Neural Rendering. (arXiv:2203.03949v2 [cs.CV] UPDATED)
145. EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers. (arXiv:2203.03952v2 [cs.CV] UPDATED)
146. Dynamic Dual-Output Diffusion Models. (arXiv:2203.04304v2 [cs.CV] UPDATED)
147. Multiscale Convolutional Transformer with Center Mask Pretraining for Hyperspectral Image Classificationtion. (arXiv:2203.04771v2 [cs.CV] UPDATED)
148. Semi-supervision semantic segmentation with uncertainty-guided self cross supervision. (arXiv:2203.05118v2 [cs.CV] UPDATED)
149. Frequency-driven Imperceptible Adversarial Attack on Semantic Similarity. (arXiv:2203.05151v2 [cs.CV] UPDATED)
150. Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
151. Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing. (arXiv:2203.05340v3 [cs.CV] UPDATED)
152. Deep AutoAugment. (arXiv:2203.06172v2 [cs.CV] UPDATED)
153. PillarGrid: Deep Learning-based Cooperative Perception for 3D Object Detection from Onboard-Roadside LiDAR. (arXiv:2203.06319v2 [cs.CV] UPDATED)
154. Bringing Rolling Shutter Images Alive with Dual Reversed Distortion. (arXiv:2203.06451v2 [cs.CV] UPDATED)
155. Depth-Aware Generative Adversarial Network for Talking Head Video Generation. (arXiv:2203.06605v2 [cs.CV] UPDATED)
156. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v2 [cs.CV] UPDATED)
157. Similarity Equivariant Linear Transformation of Joint Orientation-Scale Space Representations. (arXiv:2203.06786v2 [cs.CV] UPDATED)
158. XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding. (arXiv:2203.06947v2 [cs.CV] UPDATED)
159. Computer Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey. (arXiv:2203.06951v2 [cs.CV] UPDATED)
160. Blind2Unblind: Self-Supervised Image Denoising with Visible Blind Spots. (arXiv:2203.06967v2 [cs.CV] UPDATED)
161. Adversarial amplitude swap towards robust image classifiers. (arXiv:2203.07138v2 [cs.CV] UPDATED)
162. Implicit Motion Handling for Video Camouflaged Object Detection. (arXiv:2203.07363v2 [cs.CV] UPDATED)
## eess.IV
---
**28** new papers in eess.IV:-) 
1. SATr: Slice Attention with Transformer for Universal Lesion Detection. (arXiv:2203.07373v1 [eess.IV])
2. ShapeNet: Shape Constraint for Galaxy Image Deconvolution. (arXiv:2203.07412v1 [astro-ph.IM])
3. A deep learning pipeline for breast cancer ki-67 proliferation index scoring. (arXiv:2203.07452v1 [eess.IV])
4. Time-series image denoising of pressure-sensitive paint data by projected multivariate singular spectrum analysis. (arXiv:2203.07574v1 [eess.IV])
5. Breast Cancer Molecular Subtypes Prediction on Pathological Images with Discriminative Patch Selecting and Multi-Instance Learning. (arXiv:2203.07659v1 [eess.IV])
6. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v1 [eess.IV])
7. Magnification Prior: A Self-Supervised Method for Learning Representations on Breast Cancer Histopathological Images. (arXiv:2203.07707v1 [eess.IV])
8. Bio-inspired Multi-robot Autonomy. (arXiv:2203.07718v1 [cs.RO])
9. Securing the Classification of COVID-19 in Chest X-ray Images: A Privacy-Preserving Deep Learning Approach. (arXiv:2203.07728v1 [eess.IV])
10. Fast Autofocusing using Tiny Networks for Digital Holographic Microscopy. (arXiv:2203.07772v1 [eess.IV])
11. Training Generative Adversarial Networks for Optical Property Mapping using Synthetic Image Data. (arXiv:2203.07793v1 [eess.IV])
12. Image Quality Assessment for Magnetic Resonance Imaging. (arXiv:2203.07809v1 [eess.IV])
13. Recursive 3D Segmentation of Shoulder Joint with Coarse-scanned MR Image. (arXiv:2203.07846v1 [eess.IV])
14. Generalized Rectifier Wavelet Covariance Models For Texture Synthesis. (arXiv:2203.07902v1 [cs.CV])
15. A Noise-level-aware Framework for PET Image Denoising. (arXiv:2203.08034v1 [eess.IV])
16. Key Point Agnostic Frequency-Selective Mesh-to-Grid Image Resampling using Spectral Weighting. (arXiv:2203.08086v1 [eess.IV])
17. MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks. (arXiv:2007.08386v2 [cs.CV] UPDATED)
18. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
19. Domain Adversarial RetinaNet as a Reference Algorithm for the MItosis DOmain Generalization Challenge. (arXiv:2108.11269v3 [eess.IV] UPDATED)
20. The Application of Convolutional Neural Networks for Tomographic Reconstruction of Hyperspectral Images. (arXiv:2108.13458v2 [eess.IV] UPDATED)
21. All-Around Real Label Supervision: Cyclic Prototype Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.13930v2 [eess.IV] UPDATED)
22. Ensemble Neural Representation Networks. (arXiv:2110.04124v2 [cs.LG] UPDATED)
23. Neural Dubber: Dubbing for Videos According to Scripts. (arXiv:2110.08243v3 [eess.AS] UPDATED)
24. Equivariant Contrastive Learning. (arXiv:2111.00899v2 [cs.CV] UPDATED)
25. Automatic Semantic Segmentation of the Lumbar Spine: Clinical Applicability in a Multi-parametric and Multi-centre Study on Magnetic Resonance Images. (arXiv:2111.08712v2 [eess.IV] UPDATED)
26. Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation. (arXiv:2201.01427v2 [cs.CV] UPDATED)
27. Multi-modal unsupervised brain image registration using edge maps. (arXiv:2202.04647v3 [eess.IV] UPDATED)
28. Dynamic Dual-Output Diffusion Models. (arXiv:2203.04304v2 [cs.CV] UPDATED)
## cs.LG
---
**219** new papers in cs.LG:-) 
1. Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
2. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v1 [cs.LG])
3. From Big to Small: Adaptive Learning to Partial-Set Domains. (arXiv:2203.07375v1 [cs.LG])
4. Dawn of the transformer era in speech emotion recognition: closing the valence gap. (arXiv:2203.07378v1 [eess.AS])
5. Quantitative Gaussian Approximation of Randomly Initialized Deep Neural Networks. (arXiv:2203.07379v1 [cs.LG])
6. Respecting causality is all you need for training physics-informed neural networks. (arXiv:2203.07404v1 [cs.LG])
7. On Connecting Deep Trigonometric Networks with Deep Gaussian Processes: Covariance, Expressivity, and Neural Tangent Kernel. (arXiv:2203.07411v1 [cs.LG])
8. Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning. (arXiv:2203.07413v1 [cs.LG])
9. Unsupervised Clustering of Roman Potsherds via Variational Autoencoders. (arXiv:2203.07437v1 [cs.CV])
10. A Neural Pairwise Ranking Model for Readability Assessment. (arXiv:2203.07450v1 [cs.CL])
11. L2Explorer: A Lifelong Reinforcement Learning Assessment Environment. (arXiv:2203.07454v1 [cs.LG])
12. Simultaneous Learning of the Inputs and Parameters in Neural Collaborative Filtering. (arXiv:2203.07463v1 [cs.IR])
13. Uncertainty Estimation for Language Reward Models. (arXiv:2203.07472v1 [cs.CL])
14. Distributed On-Sensor Compute System for AR/VR Devices: A Semi-Analytical Simulation Framework for Power Estimation. (arXiv:2203.07474v1 [cs.AR])
15. Invariance in Policy Optimisation and Partial Identifiability in Reward Learning. (arXiv:2203.07475v1 [cs.LG])
16. Simplicial Attention Networks. (arXiv:2203.07485v1 [cs.LG])
17. Achieving Downstream Fairness with Geometric Repair. (arXiv:2203.07490v1 [cs.LG])
18. VAST: The Valence-Assessing Semantics Test for Contextualizing Language Models. (arXiv:2203.07504v1 [cs.CL])
19. Closing the Loop: A Framework for Trustworthy Machine Learning in Power Systems. (arXiv:2203.07505v1 [eess.SY])
20. Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations. (arXiv:2203.07511v1 [cs.CL])
21. Don't fear the unlabelled: safe deep semi-supervised learning via simple debiaising. (arXiv:2203.07512v1 [stat.ML])
22. Multi Stage Screening: Enforcing Fairness and Maximizing Efficiency in a Pre-Existing Pipeline. (arXiv:2203.07513v1 [cs.LG])
23. Skydiver: A Spiking Neural Network Accelerator Exploiting Spatio-Temporal Workload Balance. (arXiv:2203.07516v1 [cs.AR])
24. Convolutional-Recurrent Neural Network Proxy for Robust Optimization and Closed-Loop Reservoir Management. (arXiv:2203.07524v1 [cs.LG])
25. Denoising and feature extraction in photoemission spectra with variational auto-encoder neural networks. (arXiv:2203.07537v1 [physics.ins-det])
26. Neural Network Solver for Coherent Synchrotron Radiation Wakefield Calculations in Accelerator-based Charged Particle Beams. (arXiv:2203.07542v1 [physics.acc-ph])
27. A Unified Framework for Rank-based Evaluation Metrics for Link Prediction in Knowledge Graphs. (arXiv:2203.07544v1 [cs.LG])
28. Permutation Invariant Representations with Applications to Graph Deep Learning. (arXiv:2203.07546v1 [math.FA])
29. On the Calibration of Pre-trained Language Models using Mixup Guided by Area Under the Margin and Saliency. (arXiv:2203.07559v1 [cs.CL])
30. Toward the Detection of Polyglot Files. (arXiv:2203.07561v1 [cs.CR])
31. Safe adaptation in multiagent competition. (arXiv:2203.07562v1 [cs.LG])
32. Time-series image denoising of pressure-sensitive paint data by projected multivariate singular spectrum analysis. (arXiv:2203.07574v1 [eess.IV])
33. Efficient and Optimal Fixed-Time Regret with Two Experts. (arXiv:2203.07577v1 [cs.LG])
34. TSM: Measuring the Enticement of Honeyfiles with Natural Language Processing. (arXiv:2203.07580v1 [cs.CL])
35. Accelerating Stochastic Probabilistic Inference. (arXiv:2203.07585v1 [cs.LG])
36. Distraction is All You Need for Fairness. (arXiv:2203.07593v1 [cs.LG])
37. Task-Agnostic Robust Representation Learning. (arXiv:2203.07596v1 [cs.LG])
38. Quantum Finite Automata and Quiver Algebras. (arXiv:2203.07597v1 [cs.FL])
39. Innovations in trigger and data acquisition systems for next-generation physics facilities. (arXiv:2203.07620v1 [hep-ex])
40. Graph Representation Learning for Popularity Prediction Problem: A Survey. (arXiv:2203.07632v1 [cs.SI])
41. Lifelong Matrix Completion with Sparsity-Number. (arXiv:2203.07637v1 [cs.LG])
42. Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness. (arXiv:2203.07653v1 [cs.CL])
43. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v1 [cs.CV])
44. Safe Neurosymbolic Learning with Differentiable Symbolic Execution. (arXiv:2203.07671v1 [cs.LG])
45. Incorporating Heterophily into Graph Neural Networks for Graph Classification. (arXiv:2203.07678v1 [cs.LG])
46. Energy-efficient Dense DNN Acceleration with Signed Bit-slice Architecture. (arXiv:2203.07679v1 [cs.AR])
47. DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting. (arXiv:2203.07681v1 [cs.LG])
48. Supervised Contrastive Learning with Structure Inference for Graph Classification. (arXiv:2203.07691v1 [cs.LG])
49. LDP: Learnable Dynamic Precision for Efficient Deep Neural Network Training and Inference. (arXiv:2203.07713v1 [cs.LG])
50. CODA: A Real-World Road Corner Case Dataset for Object Detection in Autonomous Driving. (arXiv:2203.07724v1 [cs.CV])
51. Evaluating BERT-based Pre-training Language Models for Detecting Misinformation. (arXiv:2203.07731v1 [cs.CL])
52. S2F2: Self-Supervised High Fidelity Face Reconstruction from Monocular Image. (arXiv:2203.07732v1 [cs.CV])
53. Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation. (arXiv:2203.07735v1 [cs.IR])
54. Neural-MPC: Deep Learning Model Predictive Control for Quadrotors and Agile Robotic Platforms. (arXiv:2203.07747v1 [cs.RO])
55. Generative models and Bayesian inversion using Laplace approximation. (arXiv:2203.07755v1 [stat.ML])
56. Reactive Motion Generation on Learned Riemannian Manifolds. (arXiv:2203.07761v1 [cs.RO])
57. Scalable Penalized Regression for Noise Detection in Learning with Noisy Labels. (arXiv:2203.07788v1 [cs.LG])
58. Igeood: An Information Geometry Approach to Out-of-Distribution Detection. (arXiv:2203.07798v1 [stat.ML])
59. A Framework for Verifiable and Auditable Federated Anomaly Detection. (arXiv:2203.07802v1 [cs.LG])
60. End-to-end P300 BCI using Bayesian accumulation of Riemannian probabilities. (arXiv:2203.07807v1 [cs.LG])
61. Interspace Pruning: Using Adaptive Filter Representations to Improve Training of Sparse CNNs. (arXiv:2203.07808v1 [cs.CV])
62. Competition-Level Code Generation with AlphaCode. (arXiv:2203.07814v1 [cs.PL])
63. Graph Neural Network Sensitivity Under Probabilistic Error Model. (arXiv:2203.07831v1 [stat.ML])
64. Learning to Infer Belief Embedded Communication. (arXiv:2203.07832v1 [cs.LG])
65. Trustworthy Deep Learning via Proper Calibration Errors: A Unifying Approach for Quantifying the Reliability of Predictive Uncertainty. (arXiv:2203.07835v1 [cs.LG])
66. What is the best RNN-cell structure for forecasting each time series behavior?. (arXiv:2203.07844v1 [cs.LG])
67. SCD: Self-Contrastive Decorrelation for Sentence Embeddings. (arXiv:2203.07847v1 [cs.CL])
68. Block-Recurrent Transformers. (arXiv:2203.07852v1 [cs.LG])
69. Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting. (arXiv:2203.07856v1 [cs.CL])
70. A Survey of Non-Rigid 3D Registration. (arXiv:2203.07858v1 [cs.CV])
71. Don't Get Me Wrong: How to apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v1 [cs.CV])
72. Regret Bounds for Expected Improvement Algorithms in Gaussian Process Bandit Optimization. (arXiv:2203.07875v1 [cs.LG])
73. Comparing two samples through stochastic dominance: a graphical approach. (arXiv:2203.07889v1 [stat.ML])
74. Gold Doesn't Always Glitter: Spectral Removal of Linear and Nonlinear Guarded Attribute Information. (arXiv:2203.07893v1 [cs.CL])
75. Simulating Liquids with Graph Networks. (arXiv:2203.07895v1 [cs.LG])
76. Magnetic Field Prediction Using Generative Adversarial Networks. (arXiv:2203.07897v1 [cs.LG])
77. Generalized Rectifier Wavelet Covariance Models For Texture Synthesis. (arXiv:2203.07902v1 [cs.CV])
78. Unsupervised Learning Based Focal Stack Camera Depth Estimation. (arXiv:2203.07904v1 [cs.CV])
79. Deep Transfer Learning with Graph Neural Network for Sensor-Based Human Activity Recognition. (arXiv:2203.07910v1 [cs.CV])
80. Signal in Noise: Exploring Meaning Encoded in Random Character Sequences with Character-Aware Language Models. (arXiv:2203.07911v1 [cs.CL])
81. Scalable Bigraphical Lasso: Two-way Sparse Network Inference for Count Data. (arXiv:2203.07912v1 [stat.ML])
82. Threat Detection for General Social Engineering Attack Using Machine Learning Techniques. (arXiv:2203.07933v1 [cs.CR])
83. Reachability In Simple Neural Networks. (arXiv:2203.07941v1 [cs.CC])
84. NINNs: Nudging Induced Neural Networks. (arXiv:2203.07947v1 [cs.LG])
85. Generating Privacy-Preserving Process Data with Deep Generative Models. (arXiv:2203.07949v1 [cs.LG])
86. Amortised inference of fractional Brownian motion with linear computational complexity. (arXiv:2203.07961v1 [cs.LG])
87. Learning Expanding Graphs for Signal Interpolation. (arXiv:2203.07966v1 [eess.SP])
88. Intrinsic Neural Fields: Learning Functions on Manifolds. (arXiv:2203.07967v1 [cs.CV])
89. PDNS-Net: A Large Heterogeneous Graph Benchmark Dataset of Network Resolutions for Graph Learning. (arXiv:2203.07969v1 [cs.LG])
90. Categorical Representation Learning and RG flow operators for algorithmic classifiers. (arXiv:2203.07975v1 [cs.LG])
91. Object Detection as Probabilistic Set Prediction. (arXiv:2203.07980v1 [cs.CV])
92. Adversarial Robustness of Neural-Statistical Features in Detection of Generative Transformers. (arXiv:2203.07983v1 [cs.CL])
93. Approximability and Generalisation. (arXiv:2203.07989v1 [cs.LG])
94. Reinforcement Learning Framework for Server Placement and Workload Allocation in Multi-Access Edge Computing. (arXiv:2203.07998v1 [cs.AI])
95. MSCET: A Multi-Scenario Offloading Schedule for Biomedical Data Processing and Analysis in Cloud-Edge-Terminal Collaborative Vehicular Networks. (arXiv:2203.07999v1 [cs.NI])
96. Data Smells in Public Datasets. (arXiv:2203.08007v1 [cs.SE])
97. Beyond Explaining: Opportunities and Challenges of XAI-Based Model Improvement. (arXiv:2203.08008v1 [cs.LG])
98. Approximate Decision Trees For Machine Learning Classification on Tiny Printed Circuits. (arXiv:2203.08011v1 [cs.AR])
99. On-the-fly Strategy Adaptation for ad-hoc Agent Coordination. (arXiv:2203.08015v1 [cs.LG])
100. Optimal Admission Control for Multiclass Queues with Time-Varying Arrival Rates via State Abstraction. (arXiv:2203.08019v1 [cs.LG])
101. Geometric reconstructions of density based clusterings. (arXiv:2203.08020v1 [cs.LG])
102. Interpretable machine learning in Physics. (arXiv:2203.08021v1 [hep-ph])
103. Natural Hierarchical Cluster Analysis by Nearest Neighbors with Near-Linear Time Complexity. (arXiv:2203.08027v1 [cs.DS])
104. Data-Efficient Graph Grammar Learning for Molecular Generation. (arXiv:2203.08031v1 [cs.LG])
105. A Noise-level-aware Framework for PET Image Denoising. (arXiv:2203.08034v1 [eess.IV])
106. A multi-organ point cloud registration algorithm for abdominal CT registration. (arXiv:2203.08041v1 [cs.CV])
107. Machine Learning and Cosmology. (arXiv:2203.08056v1 [hep-ph])
108. POETREE: Interpretable Policy Learning with Adaptive Decision Trees. (arXiv:2203.08057v1 [cs.LG])
109. Graph filtering over expanding graphs. (arXiv:2203.08058v1 [eess.SP])
110. Seeking Commonness and Inconsistencies: A Jointly Smoothed Approach to Multi-view Subspace Clustering. (arXiv:2203.08060v1 [cs.CV])
111. A novel sampler for Gauss-Hermite determinantal point processes with application to Monte Carlo integration. (arXiv:2203.08061v1 [cs.LG])
112. Surrogate Gap Minimization Improves Sharpness-Aware Training. (arXiv:2203.08065v1 [cs.LG])
113. Practical data monitoring in the internet-services domain. (arXiv:2203.08067v1 [cs.LG])
114. Neural Solvers for Fast and Accurate Numerical Optimal Control. (arXiv:2203.08072v1 [math.OC])
115. Can A Neural Network Hear the Shape of A Drum?. (arXiv:2203.08073v1 [cs.SD])
116. Combining AI/ML and PHY Layer Rule Based Inference -- Some First Results. (arXiv:2203.08074v1 [eess.SP])
117. Regenerative Particle Thompson Sampling. (arXiv:2203.08082v1 [cs.LG])
118. On Suspicious Coincidences and Pointwise Mutual Information. (arXiv:2203.08089v1 [cs.LG])
119. Does Corpus Quality Really Matter for Low-Resource Languages?. (arXiv:2203.08111v1 [cs.CL])
120. Deep Learning without Shortcuts: Shaping the Kernel with Tailored Rectifiers. (arXiv:2203.08120v1 [cs.LG])
121. Can Neural Nets Learn the Same Model Twice? Investigating Reproducibility and Double Descent from the Decision Boundary Perspective. (arXiv:2203.08124v1 [cs.LG])
122. One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning. (arXiv:2203.08130v1 [cs.CV])
123. Privacy-Aware Compression for Federated Data Analysis. (arXiv:2203.08134v1 [cs.LG])
124. CryoAI: Amortized Inference of Poses for Ab Initio Reconstruction of 3D Molecular Volumes from Real Cryo-EM Images. (arXiv:2203.08138v1 [cs.CV])
125. Object Manipulation via Visual Target Localization. (arXiv:2203.08141v1 [cs.CV])
126. On the Convergence of Overlapping Schwarz Decomposition for Nonlinear Optimal Control. (arXiv:2005.06674v5 [math.OC] UPDATED)
127. MTP: Multi-Task Pruning for Efficient Semantic Segmentation Networks. (arXiv:2007.08386v2 [cs.CV] UPDATED)
128. Learning Object-Based State Estimators for Household Robots. (arXiv:2011.03183v3 [cs.LG] UPDATED)
129. Deep Cox Mixtures for Survival Regression. (arXiv:2101.06536v5 [cs.LG] UPDATED)
130. WiSleep: Inferring Sleep Duration at Scale Using Passive WiFi Sensing. (arXiv:2102.03690v2 [eess.SP] UPDATED)
131. Towards Building A Group-based Unsupervised Representation Disentanglement Framework. (arXiv:2102.10303v2 [cs.LG] UPDATED)
132. Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning Approach. (arXiv:2103.00683v3 [cs.LG] UPDATED)
133. Inference for Generative Capsule Models. (arXiv:2103.06676v2 [cs.LG] UPDATED)
134. Machine Learning Emulation of 3D Cloud Radiative Effects. (arXiv:2103.11919v3 [cs.LG] UPDATED)
135. Improving Question Answering Model Robustness with Synthetic Adversarial Data Generation. (arXiv:2104.08678v3 [cs.CL] UPDATED)
136. Suppressing simulation bias using multi-modal data. (arXiv:2104.09684v2 [cs.LG] UPDATED)
137. Deep 3D-to-2D Watermarking: Embedding Messages in 3D Meshes and Extracting Them from 2D Renderings. (arXiv:2104.13450v3 [cs.CV] UPDATED)
138. Memorisation versus Generalisation in Pre-trained Language Models. (arXiv:2105.00828v2 [cs.CL] UPDATED)
139. DISSECT: Disentangled Simultaneous Explanations via Concept Traversals. (arXiv:2105.15164v4 [cs.LG] UPDATED)
140. Learning Curves for SGD on Structured Features. (arXiv:2106.02713v5 [stat.ML] UPDATED)
141. Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v2 [cs.LG] UPDATED)
142. Same State, Different Task: Continual Reinforcement Learning without Interference. (arXiv:2106.02940v2 [cs.LG] UPDATED)
143. AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v2 [cs.LG] UPDATED)
144. Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v3 [cs.LG] UPDATED)
145. Stein Latent Optimization for Generative Adversarial Networks. (arXiv:2106.05319v7 [cs.LG] UPDATED)
146. Knowledge Enhanced Machine Learning Pipeline against Diverse Adversarial Attacks. (arXiv:2106.06235v2 [cs.LG] UPDATED)
147. Simple GNN Regularisation for 3D Molecular Property Prediction & Beyond. (arXiv:2106.07971v2 [cs.LG] UPDATED)
148. Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic Manipulation via Discretisation. (arXiv:2106.12534v2 [cs.RO] UPDATED)
149. AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning. (arXiv:2107.02729v4 [cs.LG] UPDATED)
150. Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v2 [cs.CV] UPDATED)
151. Learning more skills through optimistic exploration. (arXiv:2107.14226v4 [cs.LG] UPDATED)
152. Towards Reliable and Efficient AI for 6G: Bayesian Active Meta-Learning for Few Pilot Demodulation and Equalization. (arXiv:2108.00785v2 [cs.LG] UPDATED)
153. PSA-GAN: Progressive Self Attention GANs for Synthetic Time Series. (arXiv:2108.00981v2 [cs.LG] UPDATED)
154. Imitation Learning by Reinforcement Learning. (arXiv:2108.04763v2 [stat.ML] UPDATED)
155. Gap-Dependent Unsupervised Exploration for Reinforcement Learning. (arXiv:2108.05439v2 [cs.LG] UPDATED)
156. MrSQM: Fast Time Series Classification with Symbolic Representations. (arXiv:2109.01036v2 [cs.LG] UPDATED)
157. A deep learning guided memetic framework for graph coloring problems. (arXiv:2109.05948v3 [cs.LG] UPDATED)
158. StereOBJ-1M: Large-scale Stereo Image Dataset for 6D Object Pose Estimation. (arXiv:2109.10115v3 [cs.CV] UPDATED)
159. FewNLU: Benchmarking State-of-the-Art Methods for Few-Shot Natural Language Understanding. (arXiv:2109.12742v2 [cs.CL] UPDATED)
160. Variational Marginal Particle Filters. (arXiv:2109.15134v3 [stat.ML] UPDATED)
161. Creating Training Sets via Weak Indirect Supervision. (arXiv:2110.03484v3 [cs.LG] UPDATED)
162. Ensemble Neural Representation Networks. (arXiv:2110.04124v2 [cs.LG] UPDATED)
163. Learning a subspace of policies for online adaptation in Reinforcement Learning. (arXiv:2110.05169v2 [cs.LG] UPDATED)
164. Trivial or impossible -- dichotomous data difficulty masks model differences (on ImageNet and beyond). (arXiv:2110.05922v2 [cs.CV] UPDATED)
165. Tracking the risk of a deployed model and detecting harmful distribution shifts. (arXiv:2110.06177v3 [stat.ML] UPDATED)
166. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v4 [cs.LG] UPDATED)
167. Towards Better Plasticity-Stability Trade-off in Incremental Learning: A Simple Linear Connector. (arXiv:2110.07905v3 [cs.LG] UPDATED)
168. Neural Dubber: Dubbing for Videos According to Scripts. (arXiv:2110.08243v3 [eess.AS] UPDATED)
169. Unsupervised Natural Language Inference Using PHL Triplet Generation. (arXiv:2110.08438v2 [cs.CL] UPDATED)
170. A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification. (arXiv:2110.09759v2 [cs.LG] UPDATED)
171. Illiterate DALL-E Learns to Compose. (arXiv:2110.11405v3 [cs.CV] UPDATED)
172. Deep learning via message passing algorithms based on belief propagation. (arXiv:2110.14583v3 [cs.LG] UPDATED)
173. Equivariant Contrastive Learning. (arXiv:2111.00899v2 [cs.CV] UPDATED)
174. MT3: Multi-Task Multitrack Music Transcription. (arXiv:2111.03017v4 [cs.SD] UPDATED)
175. Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking. (arXiv:2111.07786v2 [cs.AI] UPDATED)
176. Automatic Semantic Segmentation of the Lumbar Spine: Clinical Applicability in a Multi-parametric and Multi-centre Study on Magnetic Resonance Images. (arXiv:2111.08712v2 [eess.IV] UPDATED)
177. Max-Min Grouped Bandits. (arXiv:2111.08862v2 [stat.ML] UPDATED)
178. Transfer Learning with Gaussian Processes for Bayesian Optimization. (arXiv:2111.11223v2 [stat.ML] UPDATED)
179. Conditional Object-Centric Learning from Video. (arXiv:2111.12594v2 [cs.CV] UPDATED)
180. Continual Active Learning Using Pseudo-Domains for Limited Labelling Resources and Changing Acquisition Characteristics. (arXiv:2111.13069v2 [cs.CV] UPDATED)
181. Confounder Identification-free Causal Visual Feature Learning. (arXiv:2111.13420v2 [cs.LG] UPDATED)
182. Relating transformers to models and neural representations of the hippocampal formation. (arXiv:2112.04035v2 [cs.NE] UPDATED)
183. An Experimental Design Perspective on Model-Based Reinforcement Learning. (arXiv:2112.05244v2 [cs.LG] UPDATED)
184. Learning to Guide and to Be Guided in the Architect-Builder Problem. (arXiv:2112.07342v4 [cs.LG] UPDATED)
185. Incomplete Knowledge Graph Alignment. (arXiv:2112.09266v2 [cs.CL] UPDATED)
186. Machine Learning Emulation of Urban Land Surface Processes. (arXiv:2112.11429v3 [cs.LG] UPDATED)
187. Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates. (arXiv:2112.15025v3 [cs.LG] UPDATED)
188. Optimal Representations for Covariate Shift. (arXiv:2201.00057v2 [cs.LG] UPDATED)
189. Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal Federated Learning with Reputation and Contribution Measurement. (arXiv:2201.02410v2 [cs.AI] UPDATED)
190. Optimizing the Communication-Accuracy Trade-off in Federated Learning with Rate-Distortion Theory. (arXiv:2201.02664v2 [cs.LG] UPDATED)
191. Equivalent Distance Geometry Error for Molecular Conformation Comparison. (arXiv:2201.08714v2 [q-bio.BM] UPDATED)
192. GIU-GANs: Global Information Utilization for Generative Adversarial Networks. (arXiv:2201.10471v2 [cs.LG] UPDATED)
193. Model Agnostic Interpretability for Multiple Instance Learning. (arXiv:2201.11701v3 [cs.LG] UPDATED)
194. APPFL: Open-Source Software Framework for Privacy-Preserving Federated Learning. (arXiv:2202.03672v2 [cs.LG] UPDATED)
195. TinyM$^2$Net: A Flexible System Algorithm Co-designed Multimodal Learning Framework for Tiny Devices. (arXiv:2202.04303v2 [cs.LG] UPDATED)
196. Conditional Contrastive Learning with Kernel. (arXiv:2202.05458v3 [cs.LG] UPDATED)
197. SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography. (arXiv:2202.05735v3 [cs.LG] UPDATED)
198. StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement. (arXiv:2202.06205v2 [cs.HC] UPDATED)
199. Confidence Threshold Neural Diving. (arXiv:2202.07506v2 [math.OC] UPDATED)
200. Attentive Temporal Pooling for Conformer-based Streaming Language Identification in Long-form Speech. (arXiv:2202.12163v2 [eess.AS] UPDATED)
201. Learning Transferable Reward for Query Object Localization with Policy Adaptation. (arXiv:2202.12403v3 [cs.CV] UPDATED)
202. Semantic Supervision: Enabling Generalization over Output Spaces. (arXiv:2202.13100v2 [cs.LG] UPDATED)
203. Neural Ordinary Differential Equations for Nonlinear System Identification. (arXiv:2203.00120v2 [cs.LG] UPDATED)
204. Do Transformers use variable binding?. (arXiv:2203.00162v2 [cs.LG] UPDATED)
205. Representing Mixtures of Word Embeddings with Mixtures of Topic Embeddings. (arXiv:2203.01570v2 [cs.LG] UPDATED)
206. GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction. (arXiv:2203.03079v2 [cs.CV] UPDATED)
207. Singular Value Perturbation and Deep Network Optimization. (arXiv:2203.03099v3 [cs.LG] UPDATED)
208. Variational methods for simulation-based inference. (arXiv:2203.04176v2 [stat.ML] UPDATED)
209. Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
210. Sampling Bias Correction for Supervised Machine Learning: A Bayesian Inference Approach with Practical Applications. (arXiv:2203.06239v2 [stat.ML] UPDATED)
211. Bit-Metric Decoding Rate in Multi-User MIMO Systems: Theory. (arXiv:2203.06271v2 [cs.IT] UPDATED)
212. Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications. (arXiv:2203.06273v2 [cs.IT] UPDATED)
213. Varying Coefficient Linear Discriminant Analysis for Dynamic Data. (arXiv:2203.06371v2 [stat.ME] UPDATED)
214. Optimizer Amalgamation. (arXiv:2203.06474v2 [cs.LG] UPDATED)
215. Policy Learning for Robust Markov Decision Process with a Mismatched Generative Model. (arXiv:2203.06587v2 [cs.LG] UPDATED)
216. Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models. (arXiv:2203.06904v2 [cs.CL] UPDATED)
217. Computer Vision and Deep Learning for Fish Classification in Underwater Habitats: A Survey. (arXiv:2203.06951v2 [cs.CV] UPDATED)
218. Graph-Survival: A Survival Analysis Framework for Machine Learning on Temporal Networks. (arXiv:2203.07260v2 [cs.LG] UPDATED)
219. Predicting Porosity, Permeability, and Tortuosity of Porous Media from Images by Deep Learning. (arXiv:2007.02820v1 [physics.comp-ph] CROSS LISTED)
## cs.AI
---
**113** new papers in cs.AI:-) 
1. Enhancing crowd flow prediction in various spatial and temporal granularities. (arXiv:2203.07372v1 [cs.CV])
2. SATr: Slice Attention with Transformer for Universal Lesion Detection. (arXiv:2203.07373v1 [eess.IV])
3. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v1 [cs.LG])
4. HIE-SQL: History Information Enhanced Network for Context-Dependent Text-to-SQL Semantic Parsing. (arXiv:2203.07376v1 [cs.DB])
5. Switch Trajectory Transformer with Distributional Value Approximation for Multi-Task Reinforcement Learning. (arXiv:2203.07413v1 [cs.LG])
6. Sememe Prediction for BabelNet Synsets using Multilingual and Multimodal Information. (arXiv:2203.07426v1 [cs.CL])
7. Panoptic animal pose estimators are zero-shot performers. (arXiv:2203.07436v1 [cs.CV])
8. Unsupervised Clustering of Roman Potsherds via Variational Autoencoders. (arXiv:2203.07437v1 [cs.CV])
9. A Neural Pairwise Ranking Model for Readability Assessment. (arXiv:2203.07450v1 [cs.CL])
10. L2Explorer: A Lifelong Reinforcement Learning Assessment Environment. (arXiv:2203.07454v1 [cs.LG])
11. Uncertainty Estimation for Language Reward Models. (arXiv:2203.07472v1 [cs.CL])
12. Invariance in Policy Optimisation and Partial Identifiability in Reward Learning. (arXiv:2203.07475v1 [cs.LG])
13. Audiovisual Affect Assessment and Autonomous Automobiles: Applications. (arXiv:2203.07482v1 [cs.HC])
14. VAST: The Valence-Assessing Semantics Test for Contextualizing Language Models. (arXiv:2203.07504v1 [cs.CL])
15. Conformance Checking Over Stochastically Known Logs. (arXiv:2203.07507v1 [cs.AI])
16. Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations. (arXiv:2203.07511v1 [cs.CL])
17. Don't fear the unlabelled: safe deep semi-supervised learning via simple debiaising. (arXiv:2203.07512v1 [stat.ML])
18. Multi Stage Screening: Enforcing Fairness and Maximizing Efficiency in a Pre-Existing Pipeline. (arXiv:2203.07513v1 [cs.LG])
19. ScienceWorld: Is your Agent Smarter than a 5th Grader?. (arXiv:2203.07540v1 [cs.CL])
20. A Unified Framework for Rank-based Evaluation Metrics for Link Prediction in Knowledge Graphs. (arXiv:2203.07544v1 [cs.LG])
21. Physical Neural Cellular Automata for 2D Shape Classification. (arXiv:2203.07548v1 [cs.RO])
22. Agile Maneuvers in Legged Robots: a Predictive Control Approach. (arXiv:2203.07554v1 [cs.RO])
23. Accelerating Stochastic Probabilistic Inference. (arXiv:2203.07585v1 [cs.LG])
24. Distraction is All You Need for Fairness. (arXiv:2203.07593v1 [cs.LG])
25. Online Task Assignment Problems with Reusable Resources. (arXiv:2203.07605v1 [cs.DS])
26. Do Language Models Plagiarize?. (arXiv:2203.07618v1 [cs.CL])
27. Multilingual Mix: Example Interpolation Improves Multilingual Neural Machine Translation. (arXiv:2203.07627v1 [cs.CL])
28. InfoDCL: A Distantly Supervised Contrastive Learning Framework for Social Meaning. (arXiv:2203.07648v1 [cs.CL])
29. Generalized but not Robust? Comparing the Effects of Data Modification Methods on Out-of-Domain Generalization and Adversarial Robustness. (arXiv:2203.07653v1 [cs.CL])
30. Seamlessly Integrating Factual Information and Social Content with Persuasive Dialogue. (arXiv:2203.07657v1 [cs.CL])
31. What's in the Black Box? The False Negative Mechanisms Inside Object Detectors. (arXiv:2203.07662v1 [cs.CV])
32. Can you even tell left from right? Presenting a new challenge for VQA. (arXiv:2203.07664v1 [cs.CV])
33. One Agent To Rule Them All: Towards Multi-agent Conversational AI. (arXiv:2203.07665v1 [cs.CL])
34. An Introduction to Multi-Agent Reinforcement Learning and Review of its Application to Autonomous Mobility. (arXiv:2203.07676v1 [cs.AI])
35. DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting. (arXiv:2203.07681v1 [cs.LG])
36. ReACC: A Retrieval-Augmented Code Completion Framework. (arXiv:2203.07722v1 [cs.SE])
37. Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation. (arXiv:2203.07735v1 [cs.IR])
38. ViWOZ: A Multi-Domain Task-Oriented Dialogue Systems Dataset For Low-resource Language. (arXiv:2203.07742v1 [cs.CL])
39. Reactive Motion Generation on Learned Riemannian Manifolds. (arXiv:2203.07761v1 [cs.RO])
40. Social Choice Around the Block: On the Computational Social Choice of Blockchain. (arXiv:2203.07777v1 [cs.GT])
41. UniSAr: A Unified Structure-Aware Autoregressive Language Model for Text-to-SQL. (arXiv:2203.07781v1 [cs.CL])
42. Complex Evolutional Pattern Learning for Temporal Knowledge Graph Reasoning. (arXiv:2203.07782v1 [cs.AI])
43. The Ghost in the Machine has an American accent: value conflict in GPT-3. (arXiv:2203.07785v1 [cs.CL])
44. Multi-Unit Diffusion Auctions with Intermediaries. (arXiv:2203.07796v1 [cs.GT])
45. Competition-Level Code Generation with AlphaCode. (arXiv:2203.07814v1 [cs.PL])
46. Adversarial Counterfactual Augmentation: Application in Alzheimer's Disease Classification. (arXiv:2203.07815v1 [cs.CV])
47. Learning to Infer Belief Embedded Communication. (arXiv:2203.07832v1 [cs.LG])
48. What is the best RNN-cell structure for forecasting each time series behavior?. (arXiv:2203.07844v1 [cs.LG])
49. Block-Recurrent Transformers. (arXiv:2203.07852v1 [cs.LG])
50. Don't Get Me Wrong: How to apply Deep Visual Interpretations to Time Series. (arXiv:2203.07861v1 [cs.CV])
51. Style Transformer for Image Inversion and Editing. (arXiv:2203.07932v1 [cs.CV])
52. Generating Privacy-Preserving Process Data with Deep Generative Models. (arXiv:2203.07949v1 [cs.LG])
53. Categorical Representation Learning and RG flow operators for algorithmic classifiers. (arXiv:2203.07975v1 [cs.LG])
54. Linear-Time Verification of Data-Aware Dynamic Systems with Arithmetic. (arXiv:2203.07982v1 [cs.LO])
55. Adversarial Robustness of Neural-Statistical Features in Detection of Generative Transformers. (arXiv:2203.07983v1 [cs.CL])
56. UofA-Truth at Factify 2022 : Transformer And Transfer Learning Based Multi-Modal Fact-Checking. (arXiv:2203.07990v1 [cs.MM])
57. RotateQVS: Representing Temporal Information as Rotations in Quaternion Vector Space for Temporal Knowledge Graph Completion. (arXiv:2203.07993v1 [cs.AI])
58. Leveraging Uni-Modal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition. (arXiv:2203.07996v1 [cs.SD])
59. Reinforcement Learning Framework for Server Placement and Workload Allocation in Multi-Access Edge Computing. (arXiv:2203.07998v1 [cs.AI])
60. On-the-fly Strategy Adaptation for ad-hoc Agent Coordination. (arXiv:2203.08015v1 [cs.LG])
61. Optimal Admission Control for Multiclass Queues with Time-Varying Arrival Rates via State Abstraction. (arXiv:2203.08019v1 [cs.LG])
62. Surrogate Gap Minimization Improves Sharpness-Aware Training. (arXiv:2203.08065v1 [cs.LG])
63. Implicit Feature Decoupling with Depthwise Quantization. (arXiv:2203.08080v1 [cs.CV])
64. Does Corpus Quality Really Matter for Low-Resource Languages?. (arXiv:2203.08111v1 [cs.CL])
65. One Network Doesn't Rule Them All: Moving Beyond Handcrafted Architectures in Self-Supervised Learning. (arXiv:2203.08130v1 [cs.CV])
66. Learning Spatio-Temporal Downsampling for Effective Video Upscaling. (arXiv:2203.08140v1 [cs.CV])
67. Learning Object-Based State Estimators for Household Robots. (arXiv:2011.03183v3 [cs.LG] UPDATED)
68. Decision Making in Monopoly using a Hybrid Deep Reinforcement Learning Approach. (arXiv:2103.00683v3 [cs.LG] UPDATED)
69. Unveiling the Power of Mixup for Stronger Classifiers. (arXiv:2103.13027v4 [cs.CV] UPDATED)
70. Inference of Upcoming Human Grasp Using EMG During Reach-to-Grasp Movement. (arXiv:2104.09627v2 [cs.RO] UPDATED)
71. Dependency Parsing as MRC-based Span-Span Prediction. (arXiv:2105.07654v3 [cs.CL] UPDATED)
72. DISSECT: Disentangled Simultaneous Explanations via Concept Traversals. (arXiv:2105.15164v4 [cs.LG] UPDATED)
73. Same State, Different Task: Continual Reinforcement Learning without Interference. (arXiv:2106.02940v2 [cs.LG] UPDATED)
74. AdaMatch: A Unified Approach to Semi-Supervised Learning and Domain Adaptation. (arXiv:2106.04732v2 [cs.LG] UPDATED)
75. Efficient Active Search for Combinatorial Optimization Problems. (arXiv:2106.05126v3 [cs.LG] UPDATED)
76. Incorporating Word Sense Disambiguation in Neural Language Models. (arXiv:2106.07967v3 [cs.CL] UPDATED)
77. Coarse-to-Fine Q-attention: Efficient Learning for Visual Robotic Manipulation via Discretisation. (arXiv:2106.12534v2 [cs.RO] UPDATED)
78. FaVIQ: FAct Verification from Information-seeking Questions. (arXiv:2107.02153v2 [cs.CL] UPDATED)
79. AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning. (arXiv:2107.02729v4 [cs.LG] UPDATED)
80. Learning more skills through optimistic exploration. (arXiv:2107.14226v4 [cs.LG] UPDATED)
81. Noisy Channel Language Model Prompting for Few-Shot Text Classification. (arXiv:2108.04106v3 [cs.CL] UPDATED)
82. A deep learning guided memetic framework for graph coloring problems. (arXiv:2109.05948v3 [cs.LG] UPDATED)
83. Learning a subspace of policies for online adaptation in Reinforcement Learning. (arXiv:2110.05169v2 [cs.LG] UPDATED)
84. Trivial or impossible -- dichotomous data difficulty masks model differences (on ImageNet and beyond). (arXiv:2110.05922v2 [cs.CV] UPDATED)
85. Boosting the Certified Robustness of L-infinity Distance Nets. (arXiv:2110.06850v4 [cs.LG] UPDATED)
86. Towards Better Plasticity-Stability Trade-off in Incremental Learning: A Simple Linear Connector. (arXiv:2110.07905v3 [cs.LG] UPDATED)
87. Unsupervised Natural Language Inference Using PHL Triplet Generation. (arXiv:2110.08438v2 [cs.CL] UPDATED)
88. A Regularization Method to Improve Adversarial Robustness of Neural Networks for ECG Signal Classification. (arXiv:2110.09759v2 [cs.LG] UPDATED)
89. Task-Aware Meta Learning-based Siamese Neural Network for Classifying Obfuscated Malware. (arXiv:2110.13409v2 [cs.CR] UPDATED)
90. Independent SE(3)-Equivariant Models for End-to-End Rigid Protein Docking. (arXiv:2111.07786v2 [cs.AI] UPDATED)
91. Transfer Learning with Gaussian Processes for Bayesian Optimization. (arXiv:2111.11223v2 [stat.ML] UPDATED)
92. Continual Active Learning Using Pseudo-Domains for Limited Labelling Resources and Changing Acquisition Characteristics. (arXiv:2111.13069v2 [cs.CV] UPDATED)
93. Bridging Pre-trained Models and Downstream Tasks for Source Code Understanding. (arXiv:2112.02268v2 [cs.SE] UPDATED)
94. An Experimental Design Perspective on Model-Based Reinforcement Learning. (arXiv:2112.05244v2 [cs.LG] UPDATED)
95. Learning to Guide and to Be Guided in the Architect-Builder Problem. (arXiv:2112.07342v4 [cs.LG] UPDATED)
96. NewsClaims: A New Benchmark for Claim Detection from News with Background Knowledge. (arXiv:2112.08544v2 [cs.CL] UPDATED)
97. Incomplete Knowledge Graph Alignment. (arXiv:2112.09266v2 [cs.CL] UPDATED)
98. Optimal Representations for Covariate Shift. (arXiv:2201.00057v2 [cs.LG] UPDATED)
99. Auction-Based Ex-Post-Payment Incentive Mechanism Design for Horizontal Federated Learning with Reputation and Contribution Measurement. (arXiv:2201.02410v2 [cs.AI] UPDATED)
100. Online Auction-Based Incentive Mechanism Design for Horizontal Federated Learning with Budget Constraint. (arXiv:2201.09047v2 [cs.GT] UPDATED)
101. Model Agnostic Interpretability for Multiple Instance Learning. (arXiv:2201.11701v3 [cs.LG] UPDATED)
102. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v3 [cs.CV] UPDATED)
103. Multi-modal unsupervised brain image registration using edge maps. (arXiv:2202.04647v3 [eess.IV] UPDATED)
104. StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement. (arXiv:2202.06205v2 [cs.HC] UPDATED)
105. Confidence Threshold Neural Diving. (arXiv:2202.07506v2 [math.OC] UPDATED)
106. Do Transformers use variable binding?. (arXiv:2203.00162v2 [cs.LG] UPDATED)
107. Design of Detectors at the Electron Ion Collider with Artificial Intelligence. (arXiv:2203.04530v2 [physics.ins-det] UPDATED)
108. Back to Reality: Weakly-supervised 3D Object Detection with Shape-guided Label **Enhancement**. (arXiv:2203.05238v2 [cs.CV] UPDATED)
109. Deep AutoAugment. (arXiv:2203.06172v2 [cs.CV] UPDATED)
110. PillarGrid: Deep Learning-based Cooperative Perception for 3D Object Detection from Onboard-Roadside LiDAR. (arXiv:2203.06319v2 [cs.CV] UPDATED)
111. A ROS Architecture for Personalised HRI with a Bartender Social Robot. (arXiv:2203.06631v2 [cs.RO] UPDATED)
112. Towards Visual-Prompt Temporal Answering Grounding in Medical Instructional Video. (arXiv:2203.06667v2 [cs.CV] UPDATED)
113. Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models. (arXiv:2203.06904v2 [cs.CL] UPDATED)

