# Your interest papers
---
## cs.CV
---
### Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
- Authors : Zaineb Ajra, Binbin Xu, rard Dray, Jacky Montmain, Stephane Perrey
- Link : [http://arxiv.org/abs/2209.11767](http://arxiv.org/abs/2209.11767)
> ABSTRACT  :  In recent years, neuroscientists have been interested to the development of brain-computer interface (BCI) devices. Patients with motor disorders may benefit from BCIs as a means of communication and for the **restoration** of motor functions. Electroencephalography (EEG) is one of most used for evaluating the neuronal activity. In many computer vision applications, deep neural networks (DNN) show significant advantages. Towards to ultimate usage of DNN, we present here a shallow neural network that uses mainly two convolutional neural network (CNN) layers, with relatively few parameters and fast to learn spectral-temporal features from EEG. We compared this models to three other neural network models with different depths applied to a mental arithmetic task using eye-closed state adapted for patients suffering from motor disorders and a decline in visual functions. Experimental results showed that the shallow CNN model outperformed all the other models and achieved the highest classification accuracy of 90.68%. It's also more robust to deal with cross-subject classification issues: only 3% standard deviation of accuracy instead of 15.6% from conventional method.  
### A Neural Template Matching Method to Detect Knee Joint Areas. (arXiv:2209.11791v1 [cs.CV])
- Authors : Juha Tiirola
- Link : [http://arxiv.org/abs/2209.11791](http://arxiv.org/abs/2209.11791)
> ABSTRACT  :  In this paper, new methods are considered to detect knee joint areas in **bilateral** PA fixed flexion knee X-ray images. The methods are of template matching type where the distance criterion is based on the negative normalized cross-correlation. The manual annotations are made on only one side of a single **bilateral** image when the templates are selected. The best matching patch search is formulated as an unconstrained continuous domain minimization problem. For the minimization problem different optimization methods are considered. The main method of the paper is a trainable optimizer where the method is taught to take zoomed and possibly rotated patches from its input images which look like the template. In the experiments, we compare the minimum values found by different optimization methods. We also look at some test images to examine the correspondence between the minimum value and how well the knee area is localized. It seems that making annotations only to a single image enables to detect knee joint areas quite precisely.  
### JPEG Artifact Correction using Denoising Diffusion **Restoration** Models. (arXiv:2209.11888v1 [cs.CV])
- Authors : Bahjat Kawar, Jiaming Song, Stefano Ermon, Michael Elad
- Link : [http://arxiv.org/abs/2209.11888](http://arxiv.org/abs/2209.11888)
> ABSTRACT  :  Diffusion models can be used as learned priors for solving various inverse problems. However, most existing approaches are restricted to linear inverse problems, limiting their applicability to more general cases. In this paper, we build upon Denoising Diffusion **Restoration** Models (DDRM) and propose a method for solving some non-linear inverse problems. We leverage the pseudo-inverse operator used in DDRM and generalize this concept for other measurement operators, which allows us to use pre-trained unconditional diffusion models for applications such as JPEG artifact correction. We empirically demonstrate the effectiveness of our approach across various quality factors, attaining performance levels that are on par with state-of-the-art methods trained specifically for the JPEG **restoration** task.  
### S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction. (arXiv:2209.12075v1 [eess.IV])
- Authors : Jiamian Wang, Kunpeng Li, Yulun Zhang, Xin Yuan, Zhiqiang Tao
- Link : [http://arxiv.org/abs/2209.12075](http://arxiv.org/abs/2209.12075)
> ABSTRACT  :  The technology of hyperspectral imaging (HSI) records the visual information upon long-range-distributed spectral wavelengths. A representative hyperspectral image acquisition procedure conducts a 3D-to-2D encoding by the coded aperture snapshot spectral imager (CASSI), and requires a software decoder for the 3D signal reconstruction. Based on this encoding procedure, two major challenges stand in the way of a high-fidelity reconstruction: (i) To obtain 2D measurements, CASSI dislocates multiple channels by disperser-titling and squeezes them onto the same spatial region, yielding an entangled data loss. (ii) The physical coded aperture (mask) will lead to a masked data loss by selectively blocking the pixel-wise light **exposure**. To tackle these challenges, we propose a spatial-spectral (S2-) transformer architecture with a mask-aware learning strategy. Firstly, we simultaneously leverage spatial and spectral attention modelings to disentangle the blended information in the 2D measurement along both two dimensions. A series of Transformer structures across spatial &amp; spectral clues are systematically designed, which considers the information inter-dependency between the two-fold cues. Secondly, the masked pixels will induce higher prediction difficulty and should be treated differently from unmasked ones. Thereby, we adaptively prioritize the loss penalty attributing to the mask structure by inferring the difficulty-level upon the mask-aware prediction. Our proposed method not only sets a new state-of-the-art quantitatively, but also yields a better perceptual quality upon structured areas.  
### PL-EVIO: Robust Monocular Event-based Visual Inertial Odometry with Point and Line Features. (arXiv:2209.12160v1 [cs.CV])
- Authors : Weipeng Guan, Peiyu Chen, Yuhan Xie, Peng Lu
- Link : [http://arxiv.org/abs/2209.12160](http://arxiv.org/abs/2209.12160)
> ABSTRACT  :  Event cameras are motion-activated sensors that capture pixel-level illumination changes instead of the intensity image with a fixed frame rate. Compared with the standard cameras, it can provide reliable visual perception during high-speed motions and in **high dynamic range** scenarios. However, event cameras output only a little information or even noise when the relative motion between the camera and the scene is limited, such as in a still state. While standard cameras can provide rich perception information in most scenarios, especially in good lighting conditions. These two cameras are exactly complementary. In this paper, we proposed a robust, high-accurate, and real-time optimization-based monocular event-based visual-inertial odometry (VIO) method with event-corner features, line-based event features, and point-based image features. The proposed method offers to leverage the point-based features in the nature scene and line-based features in the human-made scene to provide more additional structure or constraints information through well-design feature management. Experiments in the public benchmark datasets show that our method can achieve superior performance compared with the state-of-the-art image-based or event-based VIO. Finally, we used our method to demonstrate an onboard closed-loop autonomous quadrotor flight and large-scale outdoor experiments. Videos of the evaluations are presented on our project website: https://b23.tv/OE3QM6j  
### From One to Many: Dynamic Cross Attention Networks for LiDAR and Camera Fusion. (arXiv:2209.12254v1 [cs.CV])
- Authors : Rui Wan, Shuangjie Xu, Wei Wu, Xiaoyi Zou, Tongyi Cao
- Link : [http://arxiv.org/abs/2209.12254](http://arxiv.org/abs/2209.12254)
> ABSTRACT  :  LiDAR and cameras are two complementary sensors for 3D perception in autonomous driving. LiDAR point clouds have accurate spatial and geometry information, while RGB images provide textural and color data for context reasoning. To exploit LiDAR and cameras jointly, existing fusion methods tend to align each 3D point to only one projected image pixel based on calibration, namely one-to-one mapping. However, the performance of these approaches highly relies on the calibration quality, which is sensitive to the temporal and spatial synchronization of sensors. Therefore, we propose a Dynamic Cross Attention (DCA) module with a novel one-to-many cross-modality mapping that learns multiple offsets from the initial projection towards the neighborhood and thus develops tolerance to calibration error. Moreover, a \textit{dynamic query **enhancement**} is proposed to perceive the model-independent calibration, which further strengthens DCA's tolerance to the initial misalignment. The whole fusion architecture named Dynamic Cross Attention Network (DCAN) exploits multi-level image features and adapts to multiple representations of point clouds, which allows DCA to serve as a plug-in fusion module. Extensive experiments on nuScenes and KITTI prove DCA's effectiveness. The proposed DCAN outperforms state-of-the-art methods on the nuScenes detection challenge.  
### Spatiotemporal Multi-scale **Bilateral** Motion Network for Gait Recognition. (arXiv:2209.12364v1 [cs.CV])
- Authors : Xinnan Ding, Shan Du, Yu Zhang, Kejun Wang
- Link : [http://arxiv.org/abs/2209.12364](http://arxiv.org/abs/2209.12364)
> ABSTRACT  :  The critical goal of gait recognition is to acquire the inter-frame walking habit representation from the gait sequences. The relations between frames, however, have not received adequate attention in comparison to the intra-frame features. In this paper, motivated by optical flow, the **bilateral** motion-oriented features are proposed, which can allow the classic convolutional structure to have the capability to directly portray gait movement patterns at the feature level. Based on such features, we develop a set of multi-scale temporal representations that force the motion context to be richly described at various levels of temporal resolution. Furthermore, a correction block is devised to eliminate the segmentation noise of silhouettes for getting more precise gait information. Subsequently, the temporal feature set and the spatial features are combined to comprehensively characterize gait processes. Extensive experiments are conducted on CASIA-B and OU-MVLP datasets, and the results achieve an outstanding identification performance, which has demonstrated the effectiveness of the proposed approach.  
### A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
- Authors : Haimiao Zhang, Bin Dong
- Link : [http://arxiv.org/abs/1906.10643](http://arxiv.org/abs/1906.10643)
> ABSTRACT  :  Medical imaging is crucial in modern clinics to guide the diagnosis and treatment of diseases. Medical image reconstruction is one of the most fundamental and important components of medical imaging, whose major objective is to acquire high-quality medical images for clinical usage at the minimal cost and risk to the patients. Mathematical models in medical image reconstruction or, more generally, image **restoration** in computer vision, have been playing a prominent role. Earlier mathematical models are mostly designed by human knowledge or hypothesis on the image to be reconstructed, and we shall call these models handcrafted models. Later, handcrafted plus data-driven modeling started to emerge which still mostly relies on human designs, while part of the model is learned from the observed data. More recently, as more data and computation resources are made available, deep learning based models (or deep models) pushed the data-driven modeling to the extreme where the models are mostly based on learning with minimal human designs. Both handcrafted and data-driven modeling have their own advantages and disadvantages. One of the major research trends in medical imaging is to combine handcrafted modeling with deep modeling so that we can enjoy benefits from both approaches. The major part of this article is to provide a conceptual review of some recent works on deep modeling from the unrolling dynamics viewpoint. This viewpoint stimulates new designs of neural network architectures with inspirations from optimization algorithms and numerical differential equations. Given the popularity of deep modeling, there are still vast remaining challenges in the field, as well as opportunities which we shall discuss at the end of this article.  
### DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
- Authors : Soumick Chatterjee, Kartik Prabhu, Mahantesh Pattadkal, Gerda Bortsova, Chompunuch Sarasaen, Florian Dubost, Hendrik Mattern, Marleen de, Oliver Speck
- Link : [http://arxiv.org/abs/2006.10802](http://arxiv.org/abs/2006.10802)
> ABSTRACT  :  Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer's disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi's vessel **enhancement** with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them time-consuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 $\pm$ 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.  
### Two Decades of Bengali Handwritten Digit Recognition: A Survey. (arXiv:2206.02234v3 [cs.CV] UPDATED)
- Authors : Ashikur Rahman, Bakhtiar Hasan, Sabbir Ahmed, Tasnim Ahmed, Hamjajul Ashmafee, Mohammad Ridwan, Hasanul Kabir
- Link : [http://arxiv.org/abs/2206.02234](http://arxiv.org/abs/2206.02234)
> ABSTRACT  :  Handwritten Digit Recognition (**HDR**) is one of the most challenging tasks in the domain of Optical Character Recognition (OCR). Irrespective of language, there are some inherent challenges of **HDR**, which mostly arise due to the variations in writing styles across individuals, writing medium and environment, inability to maintain the same strokes while writing any digit repeatedly, etc. In addition to that, the structural complexities of the digits of a particular language may lead to ambiguous scenarios of **HDR**. Over the years, researchers have developed numerous offline and online **HDR** pipelines, where different image processing techniques are combined with traditional Machine Learning (ML)-based and/or Deep Learning (DL)-based architectures. Although evidence of extensive review studies on **HDR** exists in the literature for languages, such as English, Arabic, Indian, Farsi, Chinese, etc., few surveys on Bengali **HDR** (B**HDR**) can be found, which lack a comprehensive analysis of the challenges, the underlying recognition process, and possible future directions. In this paper, the characteristics and inherent ambiguities of Bengali handwritten digits along with a comprehensive insight of two decades of state-of-the-art datasets and approaches towards offline B**HDR** have been analyzed. Furthermore, several real-life application-specific studies, which involve B**HDR**, have also been discussed in detail. This paper will also serve as a compendium for researchers interested in the science behind offline B**HDR**, instigating the exploration of newer avenues of relevant research that may further lead to better offline recognition of Bengali handwritten digits in different application areas.  
### L2E: Lasers to Events for 6-DoF Extrinsic Calibration of Lidars and Event Cameras. (arXiv:2207.01009v4 [cs.CV] UPDATED)
- Authors : Kevin Ta, David Bruggemann, Tim Br, Christos Sakaridis, Luc Van
- Link : [http://arxiv.org/abs/2207.01009](http://arxiv.org/abs/2207.01009)
> ABSTRACT  :  As neuromorphic technology is maturing, its application to robotics and autonomous vehicle systems has become an area of active research. In particular, event cameras have emerged as a compelling alternative to frame-based cameras in low-power and latency-demanding applications. To enable event cameras to operate alongside staple sensors like lidar in perception tasks, we propose a direct, temporally-decoupled extrinsic calibration method between event cameras and lidars. The **high dynamic range**, high temporal resolution, and low-latency operation of event cameras are exploited to directly register lidar laser returns, allowing information-based correlation methods to optimize for the 6-DoF extrinsic calibration between the two sensors. This paper presents the first direct calibration method between event cameras and lidars, removing dependencies on frame-based camera intermediaries and/or highly-accurate hand measurements.  
## eess.IV
---
### A Neural Template Matching Method to Detect Knee Joint Areas. (arXiv:2209.11791v1 [cs.CV])
- Authors : Juha Tiirola
- Link : [http://arxiv.org/abs/2209.11791](http://arxiv.org/abs/2209.11791)
> ABSTRACT  :  In this paper, new methods are considered to detect knee joint areas in **bilateral** PA fixed flexion knee X-ray images. The methods are of template matching type where the distance criterion is based on the negative normalized cross-correlation. The manual annotations are made on only one side of a single **bilateral** image when the templates are selected. The best matching patch search is formulated as an unconstrained continuous domain minimization problem. For the minimization problem different optimization methods are considered. The main method of the paper is a trainable optimizer where the method is taught to take zoomed and possibly rotated patches from its input images which look like the template. In the experiments, we compare the minimum values found by different optimization methods. We also look at some test images to examine the correspondence between the minimum value and how well the knee area is localized. It seems that making annotations only to a single image enables to detect knee joint areas quite precisely.  
### S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction. (arXiv:2209.12075v1 [eess.IV])
- Authors : Jiamian Wang, Kunpeng Li, Yulun Zhang, Xin Yuan, Zhiqiang Tao
- Link : [http://arxiv.org/abs/2209.12075](http://arxiv.org/abs/2209.12075)
> ABSTRACT  :  The technology of hyperspectral imaging (HSI) records the visual information upon long-range-distributed spectral wavelengths. A representative hyperspectral image acquisition procedure conducts a 3D-to-2D encoding by the coded aperture snapshot spectral imager (CASSI), and requires a software decoder for the 3D signal reconstruction. Based on this encoding procedure, two major challenges stand in the way of a high-fidelity reconstruction: (i) To obtain 2D measurements, CASSI dislocates multiple channels by disperser-titling and squeezes them onto the same spatial region, yielding an entangled data loss. (ii) The physical coded aperture (mask) will lead to a masked data loss by selectively blocking the pixel-wise light **exposure**. To tackle these challenges, we propose a spatial-spectral (S2-) transformer architecture with a mask-aware learning strategy. Firstly, we simultaneously leverage spatial and spectral attention modelings to disentangle the blended information in the 2D measurement along both two dimensions. A series of Transformer structures across spatial &amp; spectral clues are systematically designed, which considers the information inter-dependency between the two-fold cues. Secondly, the masked pixels will induce higher prediction difficulty and should be treated differently from unmasked ones. Thereby, we adaptively prioritize the loss penalty attributing to the mask structure by inferring the difficulty-level upon the mask-aware prediction. Our proposed method not only sets a new state-of-the-art quantitatively, but also yields a better perceptual quality upon structured areas.  
### Multi-stage image denoising with the wavelet transform. (arXiv:2209.12394v1 [eess.IV])
- Authors : Chunwei Tian, Menghua Zheng, Wangmeng Zuo, Bob Zhang, Yanning Zhang, David Zhang
- Link : [http://arxiv.org/abs/2209.12394](http://arxiv.org/abs/2209.12394)
> ABSTRACT  :  Deep convolutional neural networks (CNNs) are used for image denoising via automatically mining accurate structure information. However, most of existing CNNs depend on enlarging depth of designed networks to obtain better denoising performance, which may cause training difficulty. In this paper, we propose a multi-stage image denoising CNN with the wavelet transform (MWDCNN) via three stages, i.e., a dynamic convolutional block (DCB), two cascaded wavelet transform and **enhancement** blocks (WEBs) and residual block (RB). DCB uses a dynamic convolution to dynamically adjust parameters of several convolutions for making a tradeoff between denoising performance and computational costs. WEB uses a combination of signal processing technique (i.e., wavelet transformation) and discriminative learning to suppress noise for recovering more detailed information in image denoising. To further remove redundant features, RB is used to refine obtained features for improving denoising effects and reconstruct clean images via improved residual dense architectures. Experimental results show that the proposed MWDCNN outperforms some popular denoising methods in terms of quantitative and qualitative analysis. Codes are available at https://github.com/hellloxiaotian/MWDCNN.  
### A heterogeneous group CNN for image super-resolution. (arXiv:2209.12406v1 [eess.IV])
- Authors : Chunwei Tian, Yanning Zhang, Wangmeng Zuo, Wen Lin, David Zhang, Yixuan Yuan
- Link : [http://arxiv.org/abs/2209.12406](http://arxiv.org/abs/2209.12406)
> ABSTRACT  :  Convolutional neural networks (CNNs) have obtained remarkable performance via deep architectures. However, these CNNs often achieve poor robustness for image super-resolution (SR) under complex scenes. In this paper, we present a heterogeneous group SR CNN (HGSRCNN) via leveraging structure information of different types to obtain a high-quality image. Specifically, each heterogeneous group block (HGB) of HGSRCNN uses a heterogeneous architecture containing a symmetric group convolutional block and a complementary convolutional block in a parallel way to enhance internal and external relations of different channels for facilitating richer low-frequency structure information of different types. To prevent appearance of obtained redundant features, a refinement block with signal **enhancement**s in a serial way is designed to filter useless information. To prevent loss of original information, a multi-level **enhancement** mechanism guides a CNN to achieve a symmetric architecture for promoting expressive ability of HGSRCNN. Besides, a parallel up-sampling mechanism is developed to train a blind SR model. Extensive experiments illustrate that the proposed HGSRCNN has obtained excellent SR performance in terms of both quantitative and qualitative analysis. Codes can be accessed at https://github.com/hellloxiaotian/HGSRCNN.  
### Graph Neural Network and Superpixel Based Brain Tissue Segmentation (Corrected Version). (arXiv:2209.12764v1 [eess.IV])
- Authors : Chong Wu, Zhenan Feng, Houwang Zhang, Hong Yan
- Link : [http://arxiv.org/abs/2209.12764](http://arxiv.org/abs/2209.12764)
> ABSTRACT  :  Convolutional neural networks (CNNs) are usually used as a backbone to design methods in biomedical image segmentation. However, the limitation of receptive field and large number of parameters limit the performance of these methods. In this paper, we propose a graph neural network (GNN) based method named GNN-SEG for the segmentation of brain tissues. Different to conventional CNN based methods, GNN-SEG takes superpixels as basic processing units and uses GNNs to learn the structure of brain tissues. Besides, inspired by the interaction mechanism in biological vision systems, we propose two kinds of interaction modules for feature **enhancement** and integration. In the experiments, we compared GNN-SEG with state-of-the-art CNN based methods on four datasets of brain magnetic resonance images. The experimental results show the superiority of GNN-SEG.  
### A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
- Authors : Haimiao Zhang, Bin Dong
- Link : [http://arxiv.org/abs/1906.10643](http://arxiv.org/abs/1906.10643)
> ABSTRACT  :  Medical imaging is crucial in modern clinics to guide the diagnosis and treatment of diseases. Medical image reconstruction is one of the most fundamental and important components of medical imaging, whose major objective is to acquire high-quality medical images for clinical usage at the minimal cost and risk to the patients. Mathematical models in medical image reconstruction or, more generally, image **restoration** in computer vision, have been playing a prominent role. Earlier mathematical models are mostly designed by human knowledge or hypothesis on the image to be reconstructed, and we shall call these models handcrafted models. Later, handcrafted plus data-driven modeling started to emerge which still mostly relies on human designs, while part of the model is learned from the observed data. More recently, as more data and computation resources are made available, deep learning based models (or deep models) pushed the data-driven modeling to the extreme where the models are mostly based on learning with minimal human designs. Both handcrafted and data-driven modeling have their own advantages and disadvantages. One of the major research trends in medical imaging is to combine handcrafted modeling with deep modeling so that we can enjoy benefits from both approaches. The major part of this article is to provide a conceptual review of some recent works on deep modeling from the unrolling dynamics viewpoint. This viewpoint stimulates new designs of neural network architectures with inspirations from optimization algorithms and numerical differential equations. Given the popularity of deep modeling, there are still vast remaining challenges in the field, as well as opportunities which we shall discuss at the end of this article.  
### DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
- Authors : Soumick Chatterjee, Kartik Prabhu, Mahantesh Pattadkal, Gerda Bortsova, Chompunuch Sarasaen, Florian Dubost, Hendrik Mattern, Marleen de, Oliver Speck
- Link : [http://arxiv.org/abs/2006.10802](http://arxiv.org/abs/2006.10802)
> ABSTRACT  :  Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer's disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi's vessel **enhancement** with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them time-consuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 $\pm$ 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.  
## cs.LG
---
### Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
- Authors : Zaineb Ajra, Binbin Xu, rard Dray, Jacky Montmain, Stephane Perrey
- Link : [http://arxiv.org/abs/2209.11767](http://arxiv.org/abs/2209.11767)
> ABSTRACT  :  In recent years, neuroscientists have been interested to the development of brain-computer interface (BCI) devices. Patients with motor disorders may benefit from BCIs as a means of communication and for the **restoration** of motor functions. Electroencephalography (EEG) is one of most used for evaluating the neuronal activity. In many computer vision applications, deep neural networks (DNN) show significant advantages. Towards to ultimate usage of DNN, we present here a shallow neural network that uses mainly two convolutional neural network (CNN) layers, with relatively few parameters and fast to learn spectral-temporal features from EEG. We compared this models to three other neural network models with different depths applied to a mental arithmetic task using eye-closed state adapted for patients suffering from motor disorders and a decline in visual functions. Experimental results showed that the shallow CNN model outperformed all the other models and achieved the highest classification accuracy of 90.68%. It's also more robust to deal with cross-subject classification issues: only 3% standard deviation of accuracy instead of 15.6% from conventional method.  
### Speech **Enhancement** with Perceptually-motivated Optimization and Dual Transformations. (arXiv:2209.11905v1 [cs.SD])
- Authors : Xucheng Wan, Kai Liu, Ziqing Du, Huan Zhou
- Link : [http://arxiv.org/abs/2209.11905](http://arxiv.org/abs/2209.11905)
> ABSTRACT  :  To address the monaural speech **enhancement** problem, numerous research studies have been conducted to enhance speech via operations either in time-domain on the inner-domain learned from the speech mixture or in time--frequency domain on the fixed full-band short time Fourier transform (STFT) spectrograms. Very recently, a few studies on sub-band based speech **enhancement** have been proposed. By enhancing speech via operations on sub-band spectrograms, those studies demonstrated competitive performances on the benchmark dataset of DNS2020. Despite attractive, this new research direction has not been fully explored and there is still room for improvement. As such, in this study, we delve into the latest research direction and propose a sub-band based speech **enhancement** system with perceptually-motivated optimization and dual transformations, called PT-FSE. Specially, our proposed PT-FSE model improves its backbone, a full-band and sub-band fusion model, by three efforts. First, we design a frequency transformation module that aims to strengthen the global frequency correlation. Then a temporal transformation is introduced to capture long range temporal contexts. Lastly, a novel loss, with leverage of properties of human auditory perception, is proposed to facilitate the model to focus on low frequency **enhancement**. To validate the effectiveness of our proposed model, extensive experiments are conducted on the DNS2020 dataset. Experimental results show that our PT-FSE system achieves substantial improvements over its backbone, but also outperforms the current state-of-the-art while being 27\% smaller than the SOTA. With average NB-PESQ of 3.57 on the benchmark dataset, our system offers the best speech **enhancement** results reported till date.  
### Toward Intention Discovery for Early Malice Detection in Bitcoin. (arXiv:2209.12001v1 [cs.LG])
- Authors : Ling Cheng, Feida Zhu, Yong Wang, Huiwen Liu
- Link : [http://arxiv.org/abs/2209.12001](http://arxiv.org/abs/2209.12001)
> ABSTRACT  :  Bitcoin has been subject to illicit activities more often than probably any other financial assets, due to the pseudo-anonymous nature of its transacting entities. An ideal detection model is expected to achieve all the three properties of (I) early detection, (II) good interpretability, and (III) versatility for various illicit activities. However, existing solutions cannot meet all these requirements, as most of them heavily rely on deep learning without satisfying interpretability and are only available for retrospective analysis of a specific illicit type.    First, we present asset transfer paths, which aim to describe addresses' early characteristics. Next, with a decision tree based strategy for feature selection and segmentation, we split the entire observation period into different segments and encode each as a segment vector. After clustering all these segment vectors, we get the global status vectors, essentially the basic unit to describe the whole intention. Finally, a hierarchical self-attention predictor predicts the label for the given address in **real time**. A survival module tells the predictor when to stop and proposes the status sequence, namely intention. %    With the type-dependent selection strategy and global status vectors, our model can be applied to detect various illicit activities with strong interpretability. The well-designed predictor and particular loss functions strengthen the model's prediction speed and interpretability one step further. Extensive experiments on three real-world datasets show that our proposed algorithm outperforms state-of-the-art methods. Besides, additional case studies justify our model can not only explain existing illicit patterns but can also find new suspicious characters.  
### Weather2vec: Representation Learning for Causal Inference with Non-Local Confounding in Air Pollution and Climate Studies. (arXiv:2209.12316v1 [cs.LG])
- Authors : Mauricio Tec, James Scott, Corwin Zigler
- Link : [http://arxiv.org/abs/2209.12316](http://arxiv.org/abs/2209.12316)
> ABSTRACT  :  Estimating the causal effects of a spatially-varying intervention on a spatially-varying outcome may be subject to non-local confounding (NLC), a phenomenon that can bias estimates when the treatments and outcomes of a given unit are dictated in part by the covariates of other nearby units. In particular, NLC is a challenge for evaluating the effects of environmental policies and climate events on health-related outcomes such as air pollution **exposure**. This paper first formalizes NLC using the potential outcomes framework, providing a comparison with the related phenomenon of causal interference. Then, it proposes a broadly applicable framework, termed "weather2vec", that uses the theory of balancing scores to learn representations of non-local information into a scalar or vector defined for each observational unit, which is subsequently used to adjust for confounding in conjunction with causal inference methods. The framework is evaluated in a simulation study and two case studies on air pollution where the weather is an (inherently regional) known confounder.  
### A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
- Authors : Haimiao Zhang, Bin Dong
- Link : [http://arxiv.org/abs/1906.10643](http://arxiv.org/abs/1906.10643)
> ABSTRACT  :  Medical imaging is crucial in modern clinics to guide the diagnosis and treatment of diseases. Medical image reconstruction is one of the most fundamental and important components of medical imaging, whose major objective is to acquire high-quality medical images for clinical usage at the minimal cost and risk to the patients. Mathematical models in medical image reconstruction or, more generally, image **restoration** in computer vision, have been playing a prominent role. Earlier mathematical models are mostly designed by human knowledge or hypothesis on the image to be reconstructed, and we shall call these models handcrafted models. Later, handcrafted plus data-driven modeling started to emerge which still mostly relies on human designs, while part of the model is learned from the observed data. More recently, as more data and computation resources are made available, deep learning based models (or deep models) pushed the data-driven modeling to the extreme where the models are mostly based on learning with minimal human designs. Both handcrafted and data-driven modeling have their own advantages and disadvantages. One of the major research trends in medical imaging is to combine handcrafted modeling with deep modeling so that we can enjoy benefits from both approaches. The major part of this article is to provide a conceptual review of some recent works on deep modeling from the unrolling dynamics viewpoint. This viewpoint stimulates new designs of neural network architectures with inspirations from optimization algorithms and numerical differential equations. Given the popularity of deep modeling, there are still vast remaining challenges in the field, as well as opportunities which we shall discuss at the end of this article.  
### DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
- Authors : Soumick Chatterjee, Kartik Prabhu, Mahantesh Pattadkal, Gerda Bortsova, Chompunuch Sarasaen, Florian Dubost, Hendrik Mattern, Marleen de, Oliver Speck
- Link : [http://arxiv.org/abs/2006.10802](http://arxiv.org/abs/2006.10802)
> ABSTRACT  :  Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer's disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi's vessel **enhancement** with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them time-consuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 $\pm$ 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.  
### How Far Should We Look Back to Achieve Effective Real-Time Time-Series Anomaly Detection?. (arXiv:2102.06560v3 [cs.LG] UPDATED)
- Authors : Chang Lee, Chun Lin, Ernst Gunnar
- Link : [http://arxiv.org/abs/2102.06560](http://arxiv.org/abs/2102.06560)
> ABSTRACT  :  Anomaly detection is the process of identifying unexpected events or ab-normalities in data, and it has been applied in many different areas such as system monitoring, fraud detection, healthcare, intrusion detection, etc. Providing real-time, lightweight, and proactive anomaly detection for time series with neither human intervention nor domain knowledge could be highly valuable since it reduces human effort and enables appropriate countermeasures to be undertaken before a disastrous event occurs. To our knowledge, RePAD (**Real-time** Proactive Anomaly Detection algorithm) is a generic approach with all above-mentioned features. To achieve real-time and lightweight detection, RePAD utilizes Long Short-Term Memory (LSTM) to detect whether or not each upcoming data point is anomalous based on short-term historical data points. However, it is unclear that how different amounts of historical data points affect the performance of RePAD. Therefore, in this paper, we investigate the impact of different amounts of historical data on RePAD by introducing a set of performance metrics that cover novel detection accuracy measures, time efficiency, readiness, and resource consumption, etc. Empirical experiments based on real-world time series datasets are conducted to evaluate RePAD in different scenarios, and the experimental results are presented and discussed.  
### The network signature of constellation line figures. (arXiv:2110.12329v4 [cs.SI] UPDATED)
- Authors : Doina Bucur
- Link : [http://arxiv.org/abs/2110.12329](http://arxiv.org/abs/2110.12329)
> ABSTRACT  :  In traditional astronomies across the world, groups of stars in the **night** sky were linked into constellations -- symbolic representations rich in meaning and with practical roles. In some sky cultures, constellations are represented as line (or connect-the-dot) figures, which are spatial networks drawn over the fixed background of stars. We analyse 1802 line figures from 56 sky cultures spanning all continents, in terms of their network, spatial, and brightness features, and ask what associations exist between these visual features and culture type or sky region. First, an embedded map of constellations is learnt, to show clusters of line figures. We then form the network of constellations (as linked by their similarity), to study how similar cultures are by computing their assortativity (or homophily) over the network. Finally, we measure the diversity (or entropy) index for the set of constellations drawn per sky region. Our results show distinct types of line figures, and that many folk astronomies with oral traditions have widespread similarities in constellation design, which do not align with cultural ancestry. In a minority of sky regions, certain line designs appear universal, but this is not the norm: in the majority of sky regions, the line geometries are diverse.  
### How Does Data Freshness Affect **Real-time** Supervised Learning?. (arXiv:2208.06948v2 [cs.NI] UPDATED)
- Authors : Md Kamran, Chowdhury Shisher, Yin Sun
- Link : [http://arxiv.org/abs/2208.06948](http://arxiv.org/abs/2208.06948)
> ABSTRACT  :  In this paper, we analyze the impact of data freshness on real-time supervised learning, where a neural network is trained to infer a time-varying target (e.g., the position of the vehicle in front) based on features (e.g., video frames) observed at a sensing node (e.g., camera or lidar). One might expect that the performance of real-time supervised learning degrades monotonically as the feature becomes stale. Using an information-theoretic analysis, we show that this is true if the feature and target data sequence can be closely approximated as a Markov chain; it is not true if the data sequence is far from Markovian. Hence, the prediction error of real-time supervised learning is a function of the Age of Information (AoI), where the function could be non-monotonic. Several experiments are conducted to illustrate the monotonic and non-monotonic behaviors of the prediction error. To minimize the inference error in real-time, we propose a new "selection-from-buffer" model for sending the features, which is more general than the "generate-at-will" model used in earlier studies. By using Gittins and Whittle indices, low-complexity scheduling strategies are developed to minimize the inference error, where a new connection between the Gittins index theory and Age of Information (AoI) minimization is discovered. These scheduling results hold (i) for minimizing general AoI functions (monotonic or non-monotonic) and (ii) for general feature transmission time distributions. Data-driven evaluations are presented to illustrate the benefits of the proposed scheduling algorithms.  
## cs.AI
---
### Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
- Authors : Zaineb Ajra, Binbin Xu, rard Dray, Jacky Montmain, Stephane Perrey
- Link : [http://arxiv.org/abs/2209.11767](http://arxiv.org/abs/2209.11767)
> ABSTRACT  :  In recent years, neuroscientists have been interested to the development of brain-computer interface (BCI) devices. Patients with motor disorders may benefit from BCIs as a means of communication and for the **restoration** of motor functions. Electroencephalography (EEG) is one of most used for evaluating the neuronal activity. In many computer vision applications, deep neural networks (DNN) show significant advantages. Towards to ultimate usage of DNN, we present here a shallow neural network that uses mainly two convolutional neural network (CNN) layers, with relatively few parameters and fast to learn spectral-temporal features from EEG. We compared this models to three other neural network models with different depths applied to a mental arithmetic task using eye-closed state adapted for patients suffering from motor disorders and a decline in visual functions. Experimental results showed that the shallow CNN model outperformed all the other models and achieved the highest classification accuracy of 90.68%. It's also more robust to deal with cross-subject classification issues: only 3% standard deviation of accuracy instead of 15.6% from conventional method.  
### Speech **Enhancement** with Perceptually-motivated Optimization and Dual Transformations. (arXiv:2209.11905v1 [cs.SD])
- Authors : Xucheng Wan, Kai Liu, Ziqing Du, Huan Zhou
- Link : [http://arxiv.org/abs/2209.11905](http://arxiv.org/abs/2209.11905)
> ABSTRACT  :  To address the monaural speech **enhancement** problem, numerous research studies have been conducted to enhance speech via operations either in time-domain on the inner-domain learned from the speech mixture or in time--frequency domain on the fixed full-band short time Fourier transform (STFT) spectrograms. Very recently, a few studies on sub-band based speech **enhancement** have been proposed. By enhancing speech via operations on sub-band spectrograms, those studies demonstrated competitive performances on the benchmark dataset of DNS2020. Despite attractive, this new research direction has not been fully explored and there is still room for improvement. As such, in this study, we delve into the latest research direction and propose a sub-band based speech **enhancement** system with perceptually-motivated optimization and dual transformations, called PT-FSE. Specially, our proposed PT-FSE model improves its backbone, a full-band and sub-band fusion model, by three efforts. First, we design a frequency transformation module that aims to strengthen the global frequency correlation. Then a temporal transformation is introduced to capture long range temporal contexts. Lastly, a novel loss, with leverage of properties of human auditory perception, is proposed to facilitate the model to focus on low frequency **enhancement**. To validate the effectiveness of our proposed model, extensive experiments are conducted on the DNS2020 dataset. Experimental results show that our PT-FSE system achieves substantial improvements over its backbone, but also outperforms the current state-of-the-art while being 27\% smaller than the SOTA. With average NB-PESQ of 3.57 on the benchmark dataset, our system offers the best speech **enhancement** results reported till date.  
### Toward Intention Discovery for Early Malice Detection in Bitcoin. (arXiv:2209.12001v1 [cs.LG])
- Authors : Ling Cheng, Feida Zhu, Yong Wang, Huiwen Liu
- Link : [http://arxiv.org/abs/2209.12001](http://arxiv.org/abs/2209.12001)
> ABSTRACT  :  Bitcoin has been subject to illicit activities more often than probably any other financial assets, due to the pseudo-anonymous nature of its transacting entities. An ideal detection model is expected to achieve all the three properties of (I) early detection, (II) good interpretability, and (III) versatility for various illicit activities. However, existing solutions cannot meet all these requirements, as most of them heavily rely on deep learning without satisfying interpretability and are only available for retrospective analysis of a specific illicit type.    First, we present asset transfer paths, which aim to describe addresses' early characteristics. Next, with a decision tree based strategy for feature selection and segmentation, we split the entire observation period into different segments and encode each as a segment vector. After clustering all these segment vectors, we get the global status vectors, essentially the basic unit to describe the whole intention. Finally, a hierarchical self-attention predictor predicts the label for the given address in **real time**. A survival module tells the predictor when to stop and proposes the status sequence, namely intention. %    With the type-dependent selection strategy and global status vectors, our model can be applied to detect various illicit activities with strong interpretability. The well-designed predictor and particular loss functions strengthen the model's prediction speed and interpretability one step further. Extensive experiments on three real-world datasets show that our proposed algorithm outperforms state-of-the-art methods. Besides, additional case studies justify our model can not only explain existing illicit patterns but can also find new suspicious characters.  
# Paper List
---
## cs.CV
---
**129** new papers in cs.CV:-) 
1. Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
2. A direct time-of-flight image sensor with in-pixel surface detection and dynamic vision. (arXiv:2209.11772v1 [cs.CV])
3. A Neural Template Matching Method to Detect Knee Joint Areas. (arXiv:2209.11791v1 [cs.CV])
4. Descriptor Distillation: a Teacher-Student-Regularized Framework for Learning Local Descriptors. (arXiv:2209.11795v1 [cs.CV])
5. Composite Layers for Deep Anomaly Detection on 3D Point Clouds. (arXiv:2209.11796v1 [cs.CV])
6. Expanding the Deployment Envelope of Behavior Prediction via Adaptive Meta-Learning. (arXiv:2209.11820v1 [cs.LG])
7. Wide-Area Geolocalization with a Limited Field of View Camera. (arXiv:2209.11854v1 [cs.RO])
8. Transformer-Based Microbubble Localization. (arXiv:2209.11859v1 [eess.IV])
9. Leveraging Self-Supervised Training for Unintentional Action Recognition. (arXiv:2209.11870v1 [cs.CV])
10. Enhancing Data Diversity for Self-training Based Unsupervised Cross-modality Vestibular Schwannoma and Cochlea Segmentation. (arXiv:2209.11879v1 [cs.CV])
11. JPEG Artifact Correction using Denoising Diffusion **Restoration** Models. (arXiv:2209.11888v1 [cs.CV])
12. DomainATM: Domain Adaptation Toolbox for Medical Data Analysis. (arXiv:2209.11890v1 [cs.CV])
13. Closing the Loop: Graph Networks to Unify Semantic Objects and Visual Features for Multi-object Scenes. (arXiv:2209.11894v1 [cs.CV])
14. Unsupervised active speaker detection in media content using cross-modal information. (arXiv:2209.11896v1 [eess.IV])
15. A Simple Strategy to Provable Invariance via Orbit Mapping. (arXiv:2209.11916v1 [cs.CV])
16. Self-supervised Image Clustering from Multiple Incomplete Views via Constrastive Complementary Generation. (arXiv:2209.11927v1 [cs.CV])
17. Towards Bridging the Space Domain Gap for Satellite Pose Estimation using Event Sensing. (arXiv:2209.11945v1 [cs.CV])
18. Raising the Bar on the Evaluation of Out-of-Distribution Detection. (arXiv:2209.11960v1 [cs.CV])
19. Approximate better, Attack stronger: Adversarial Example Generation via Asymptotically Gaussian Mixture Distribution. (arXiv:2209.11964v1 [cs.LG])
20. Ground then Navigate: Language-guided Navigation in Dynamic Scenes. (arXiv:2209.11972v1 [cs.CV])
21. Robust Hyperspectral Image Fusion with Simultaneous Guide Image Denoising via Constrained Convex Optimization. (arXiv:2209.11979v1 [cs.CV])
22. Deep Neural Networks for Visual Reasoning. (arXiv:2209.11990v1 [cs.CV])
23. Contrastive learning for unsupervised medical image clustering and reconstruction. (arXiv:2209.12005v1 [cs.CV])
24. Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild. (arXiv:2209.12009v1 [cs.CV])
25. Spiking SiamFC++: Deep Spiking Neural Network for Object Tracking. (arXiv:2209.12010v1 [cs.CV])
26. Application of the nnU-Net for automatic segmentation of lung lesion on CT images, and implication on radiomic models. (arXiv:2209.12027v1 [eess.IV])
27. Towards Explainable 3D Grounded Visual Question Answering: A New Benchmark and Strong Baseline. (arXiv:2209.12028v1 [cs.CV])
28. Controllable Face Manipulation and UV Map Generation by Self-supervised Learning. (arXiv:2209.12050v1 [cs.CV])
29. Global Semantic Descriptors for Zero-Shot Action Recognition. (arXiv:2209.12061v1 [cs.CV])
30. Face Super-Resolution Using Stochastic Differential Equations. (arXiv:2209.12064v1 [cs.CV])
31. NeRF-Loc: Transformer-Based Object Localization Within Neural Radiance Fields. (arXiv:2209.12068v1 [cs.CV])
32. Self-supervised Learning for Unintentional Action Prediction. (arXiv:2209.12074v1 [cs.CV])
33. S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction. (arXiv:2209.12075v1 [eess.IV])
34. 3D Reconstruction using Structured Light from off-the-shelf components. (arXiv:2209.12101v1 [cs.CV])
35. Conversion Between CT and MRI Images Using Diffusion and Score-Matching Models. (arXiv:2209.12104v1 [eess.IV])
36. BURST: A Benchmark for Unifying Object Recognition, Segmentation and Tracking in Video. (arXiv:2209.12118v1 [cs.CV])
37. Vision-based Perimeter Defense via Multiview Pose Estimation. (arXiv:2209.12136v1 [cs.CV])
38. Towards Stable Co-saliency Detection and Object Co-segmentation. (arXiv:2209.12138v1 [cs.CV])
39. Lightweight Image Codec via Multi-Grid Multi-Block-Size Vector Quantization (MGBVQ). (arXiv:2209.12139v1 [cs.CV])
40. Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v1 [cs.CV])
41. All are Worth Words: a ViT Backbone for Score-based Diffusion Models. (arXiv:2209.12152v1 [cs.CV])
42. Discriminative feature encoding for intrinsic image decomposition. (arXiv:2209.12155v1 [cs.CV])
43. Dive into Self-Supervised Learning for Medical Image Analysis: Data, Models and Tasks. (arXiv:2209.12157v1 [cs.CV])
44. PL-EVIO: Robust Monocular Event-based Visual Inertial Odometry with Point and Line Features. (arXiv:2209.12160v1 [cs.CV])
45. Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward. (arXiv:2209.12164v1 [cs.CV])
46. Optimal Transport-based Identity Matching for Identity-invariant Facial Expression Recognition. (arXiv:2209.12172v1 [cs.CV])
47. Multimodal Exponentially Modified Gaussian Oscillators. (arXiv:2209.12202v1 [cs.SD])
48. A Uniform Representation Learning Method for OCT-based Fingerprint Presentation Attack Detection and Reconstruction. (arXiv:2209.12208v1 [cs.CV])
49. ECO-TR: Efficient Correspondences Finding Via Coarse-to-Fine Refinement. (arXiv:2209.12213v1 [cs.CV])
50. Partial annotations for the segmentation of large structures with low annotation cost. (arXiv:2209.12216v1 [eess.IV])
51. Hand Hygiene Assessment via Joint Step Segmentation and Key Action Scorer. (arXiv:2209.12221v1 [cs.CV])
52. Contour Dice loss for structures with Fuzzy and Complex Boundaries in Fetal MRI. (arXiv:2209.12232v1 [eess.IV])
53. High-Resolution Satellite Imagery for Modeling the Impact of Aridification on Crop Production. (arXiv:2209.12238v1 [cs.CV])
54. Safety-compliant Generative Adversarial Networks for Human Trajectory Forecasting. (arXiv:2209.12243v1 [cs.CV])
55. Multimodal Learning with Channel-Mixing and Masked Autoencoder on Facial Action Unit Detection. (arXiv:2209.12244v1 [cs.CV])
56. D$^{\bf{3}}$: Duplicate Detection Decontaminator for Multi-Athlete Tracking in Sports Videos. (arXiv:2209.12248v1 [cs.CV])
57. A Tightly Coupled LiDAR-IMU Odometry through Iterated Point-Level Undistortion. (arXiv:2209.12249v1 [cs.RO])
58. From One to Many: Dynamic Cross Attention Networks for LiDAR and Camera Fusion. (arXiv:2209.12254v1 [cs.CV])
59. Collaboration of Pre-trained Models Makes Better Few-shot Learner. (arXiv:2209.12255v1 [cs.CV])
60. VAESim: A probabilistic approach for self-supervised prototype discovery. (arXiv:2209.12279v1 [cs.CV])
61. Adnexal Mass Segmentation with Ultrasound Data Synthesis. (arXiv:2209.12305v1 [eess.IV])
62. Personalizing Text-to-Image Generation via Aesthetic Gradients. (arXiv:2209.12330v1 [cs.CV])
63. Paraphrasing Is All You Need for Novel Object Captioning. (arXiv:2209.12343v1 [cs.CV])
64. On the Opportunities and Challenges of using Animals Videos in Reinforcement Learning. (arXiv:2209.12347v1 [eess.SY])
65. InterCap: Joint Markerless 3D Tracking of Humans and Objects in Interaction. (arXiv:2209.12354v1 [cs.CV])
66. UDepth: Fast Monocular Depth Estimation for Visually-guided Underwater Robots. (arXiv:2209.12358v1 [cs.CV])
67. Multi-dataset Training of Transformers for Robust Action Recognition. (arXiv:2209.12362v1 [cs.CV])
68. Spatiotemporal Multi-scale **Bilateral** Motion Network for Gait Recognition. (arXiv:2209.12364v1 [cs.CV])
69. A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
70. Zero-Shot Imitating Collaborative Manipulation Plans from YouTube Cooking Videos. (arXiv:1911.10686v5 [cs.RO] UPDATED)
71. DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
72. MGIC: Multigrid-in-Channels Neural Network Architectures. (arXiv:2011.09128v4 [cs.CV] UPDATED)
73. Probabilistic combination of eigenlungs-based classifiers for COVID-19 diagnosis in chest CT images. (arXiv:2103.02961v2 [eess.IV] UPDATED)
74. Black-Box Dissector: Towards Erasing-based Hard-Label Model Stealing Attack. (arXiv:2105.00623v3 [cs.CV] UPDATED)
75. Clustering-Based Representation Learning through Output Translation and Its Application to Remote--Sensing Images. (arXiv:2107.05948v4 [cs.LG] UPDATED)
76. Domain and Content Adaptive Convolution based Multi-Source Domain Generalization for Medical Image Segmentation. (arXiv:2109.05676v2 [eess.IV] UPDATED)
77. Differentiable Stereopsis: Meshes from multiple views using differentiable rendering. (arXiv:2110.05472v2 [cs.CV] UPDATED)
78. ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable AI. (arXiv:2110.11597v2 [cs.LG] UPDATED)
79. MedMNIST v2 -- A large-scale lightweight benchmark for 2D and 3D biomedical image classification. (arXiv:2110.14795v2 [cs.CV] UPDATED)
80. Reconstructing Compact Building Models from Point Clouds Using Deep Implicit Fields. (arXiv:2112.13142v3 [cs.CV] UPDATED)
81. Modeling Mask Uncertainty in Hyperspectral Image Reconstruction. (arXiv:2112.15362v4 [eess.IV] UPDATED)
82. Semi-Supervised Adversarial Recognition of Refined Window Structures for Inverse Procedural Fa\c{c}ade Modeling. (arXiv:2201.08977v2 [cs.CV] UPDATED)
83. DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical Image Segmentation. (arXiv:2202.00972v2 [eess.IV] UPDATED)
84. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v4 [cs.CV] UPDATED)
85. VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning. (arXiv:2202.10324v2 [cs.CV] UPDATED)
86. TwistSLAM: Constrained SLAM in Dynamic Environment. (arXiv:2202.12384v4 [cs.RO] UPDATED)
87. Adversarial Dual-Student with Differentiable Spatial Warping for Semi-Supervised Semantic Segmentation. (arXiv:2203.02792v2 [cs.CV] UPDATED)
88. UWED: Unsigned Distance Field for Accurate 3D Scene Representation and Completion. (arXiv:2203.09167v2 [cs.CV] UPDATED)
89. MatchFormer: Interleaving Attention in Transformers for Feature Matching. (arXiv:2203.09645v3 [cs.CV] UPDATED)
90. FedVLN: Privacy-preserving Federated Vision-and-Language Navigation. (arXiv:2203.14936v3 [cs.AI] UPDATED)
91. Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer. (arXiv:2204.03638v4 [cs.CV] UPDATED)
92. Elastic shape analysis of surfaces with second-order Sobolev metrics: a comprehensive numerical framework. (arXiv:2204.04238v2 [cs.CV] UPDATED)
93. RAPQ: Rescuing Accuracy for Power-of-Two Low-bit Post-training Quantization. (arXiv:2204.12322v2 [cs.CV] UPDATED)
94. Free Lunch for Surgical Video Understanding by Distilling Self-Supervisions. (arXiv:2205.09292v2 [cs.CV] UPDATED)
95. AutoLink: Self-supervised Learning of Human Skeletons and Object Outlines by Linking Keypoints. (arXiv:2205.10636v4 [cs.CV] UPDATED)
96. Fast Dynamic Radiance Fields with Time-Aware Neural Voxels. (arXiv:2205.15285v2 [cs.CV] UPDATED)
97. D$^2$NeRF: Self-Supervised Decoupling of Dynamic and Static Objects from a Monocular Video. (arXiv:2205.15838v3 [cs.CV] UPDATED)
98. Two Decades of Bengali Handwritten Digit Recognition: A Survey. (arXiv:2206.02234v3 [cs.CV] UPDATED)
99. Tagged-MRI Sequence to Audio Synthesis via Self Residual Attention Guided Heterogeneous Translator. (arXiv:2206.02284v3 [cs.SD] UPDATED)
100. ACT: Semi-supervised Domain-adaptive Medical Image Segmentation with Asymmetric Co-training. (arXiv:2206.02288v3 [cs.CV] UPDATED)
101. Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. (arXiv:2206.07137v3 [cs.LG] UPDATED)
102. Multimodal Attention-based Deep Learning for Alzheimer's Disease Diagnosis. (arXiv:2206.08826v2 [cs.LG] UPDATED)
103. Contextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification. (arXiv:2206.09843v2 [cs.CV] UPDATED)
104. COVID-19 Detection Using Transfer Learning Approach from Computed Tomography Images. (arXiv:2207.00259v4 [eess.IV] UPDATED)
105. L2E: Lasers to Events for 6-DoF Extrinsic Calibration of Lidars and Event Cameras. (arXiv:2207.01009v4 [cs.CV] UPDATED)
106. CoBEVT: Cooperative Bird's Eye View Semantic Segmentation with Sparse Transformers. (arXiv:2207.02202v2 [cs.CV] UPDATED)
107. GFNet: Geometric Flow Network for 3D Point Cloud Semantic Segmentation. (arXiv:2207.02605v2 [cs.CV] UPDATED)
108. Towards Diverse and Faithful One-shot Adaption of Generative Adversarial Networks. (arXiv:2207.08736v2 [cs.CV] UPDATED)
109. Spatial-temporal Analysis for Automated Concrete Workability Estimation. (arXiv:2207.11635v3 [cs.CV] UPDATED)
110. Any Object is a Potential Weapon! Weaponized Violence Detection using Salient Image. (arXiv:2207.12850v3 [cs.CV] UPDATED)
111. BYOLMed3D: Self-Supervised Representation Learning of Medical Videos using Gradient Accumulation Assisted 3D BYOL Framework. (arXiv:2208.00444v2 [cs.CV] UPDATED)
112. HaloAE: An HaloNet based Local Transformer Auto-Encoder for Anomaly Detection and Localization. (arXiv:2208.03486v3 [cs.CV] UPDATED)
113. ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers for Interpretable Image Recognition. (arXiv:2208.10431v2 [cs.CV] UPDATED)
114. K-Order Graph-oriented Transformer with GraAttention for 3D Pose and Shape Estimation. (arXiv:2208.11328v2 [cs.CV] UPDATED)
115. Combating Noisy Labels in Long-Tailed Image Classification. (arXiv:2209.00273v2 [cs.CV] UPDATED)
116. ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets. (arXiv:2209.00613v2 [cs.LG] UPDATED)
117. Learning to Generate Realistic LiDAR Point Clouds. (arXiv:2209.03954v2 [cs.CV] UPDATED)
118. Situation Awareness for Automated Surgical Check-listing in AI-Assisted Operating Room. (arXiv:2209.05056v2 [cs.CV] UPDATED)
119. Data Lifecycle Management in Evolving Input Distributions for Learning-based Aerospace Applications. (arXiv:2209.06855v2 [cs.CV] UPDATED)
120. VINet: Visual and Inertial-based Terrain Classification and Adaptive Navigation over Unknown Terrain. (arXiv:2209.07725v2 [cs.RO] UPDATED)
121. DytanVO: Joint Refinement of Visual Odometry and Motion Segmentation in Dynamic Environments. (arXiv:2209.08430v2 [cs.CV] UPDATED)
122. NeRF-SOS: Any-View Self-supervised Object Segmentation on Complex Scenes. (arXiv:2209.08776v4 [cs.CV] UPDATED)
123. Rethinking Dimensionality Reduction in Grid-based 3D Object Detection. (arXiv:2209.09464v2 [cs.CV] UPDATED)
124. Revisiting Image Pyramid Structure for High Resolution Salient Object Detection. (arXiv:2209.09475v2 [cs.CV] UPDATED)
125. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v2 [cs.CV] UPDATED)
126. COVID-19 Detection and Analysis From Lung CT Images using Novel Channel Boosted CNNs. (arXiv:2209.10963v2 [eess.IV] UPDATED)
127. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v2 [eess.IV] UPDATED)
128. Structure Guided Manifolds for Discovery of Disease Characteristics. (arXiv:2209.11015v2 [eess.IV] UPDATED)
129. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v2 [cs.RO] UPDATED)
## eess.IV
---
**36** new papers in eess.IV:-) 
1. A direct time-of-flight image sensor with in-pixel surface detection and dynamic vision. (arXiv:2209.11772v1 [cs.CV])
2. A Neural Template Matching Method to Detect Knee Joint Areas. (arXiv:2209.11791v1 [cs.CV])
3. Transformer-Based Microbubble Localization. (arXiv:2209.11859v1 [eess.IV])
4. DomainATM: Domain Adaptation Toolbox for Medical Data Analysis. (arXiv:2209.11890v1 [cs.CV])
5. Unsupervised active speaker detection in media content using cross-modal information. (arXiv:2209.11896v1 [eess.IV])
6. Robust Hyperspectral Image Fusion with Simultaneous Guide Image Denoising via Constrained Convex Optimization. (arXiv:2209.11979v1 [cs.CV])
7. Application of the nnU-Net for automatic segmentation of lung lesion on CT images, and implication on radiomic models. (arXiv:2209.12027v1 [eess.IV])
8. S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction. (arXiv:2209.12075v1 [eess.IV])
9. Conversion Between CT and MRI Images Using Diffusion and Score-Matching Models. (arXiv:2209.12104v1 [eess.IV])
10. Partial annotations for the segmentation of large structures with low annotation cost. (arXiv:2209.12216v1 [eess.IV])
11. Contour Dice loss for structures with Fuzzy and Complex Boundaries in Fetal MRI. (arXiv:2209.12232v1 [eess.IV])
12. Analog Image Denoising with an Adaptive Memristive Crossbar Network. (arXiv:2209.12259v1 [eess.IV])
13. Personalized Saliency in Task-Oriented Semantic Communications: Image Transmission and Performance Analysis. (arXiv:2209.12274v1 [eess.IV])
14. Adnexal Mass Segmentation with Ultrasound Data Synthesis. (arXiv:2209.12305v1 [eess.IV])
15. UDepth: Fast Monocular Depth Estimation for Visually-guided Underwater Robots. (arXiv:2209.12358v1 [cs.CV])
16. Multi-stage image denoising with the wavelet transform. (arXiv:2209.12394v1 [eess.IV])
17. A heterogeneous group CNN for image super-resolution. (arXiv:2209.12406v1 [eess.IV])
18. RetiFluidNet: A Self-Adaptive and Multi-Attention Deep Convolutional Network for Retinal OCT Fluid Segmentation. (arXiv:2209.12468v1 [eess.IV])
19. STEMPO -- dynamic X-ray tomography phantom. (arXiv:2209.12471v1 [eess.IV])
20. Real-RawVSR: Real-World Raw Video Super-Resolution with a Benchmark Dataset. (arXiv:2209.12475v1 [cs.CV])
21. Multiscale Latent-Guided Entropy Model for LiDAR Point Cloud Compression. (arXiv:2209.12512v1 [cs.CV])
22. Recent trends and analysis of Generative Adversarial Networks in Cervical Cancer Imaging. (arXiv:2209.12680v1 [eess.IV])
23. Graph Neural Network and Superpixel Based Brain Tissue Segmentation (Corrected Version). (arXiv:2209.12764v1 [eess.IV])
24. A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
25. DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
26. Probabilistic combination of eigenlungs-based classifiers for COVID-19 diagnosis in chest CT images. (arXiv:2103.02961v2 [eess.IV] UPDATED)
27. Domain and Content Adaptive Convolution based Multi-Source Domain Generalization for Medical Image Segmentation. (arXiv:2109.05676v2 [eess.IV] UPDATED)
28. MedMNIST v2 -- A large-scale lightweight benchmark for 2D and 3D biomedical image classification. (arXiv:2110.14795v2 [cs.CV] UPDATED)
29. Modeling Mask Uncertainty in Hyperspectral Image Reconstruction. (arXiv:2112.15362v4 [eess.IV] UPDATED)
30. DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical Image Segmentation. (arXiv:2202.00972v2 [eess.IV] UPDATED)
31. MatchFormer: Interleaving Attention in Transformers for Feature Matching. (arXiv:2203.09645v3 [cs.CV] UPDATED)
32. Multimodal Attention-based Deep Learning for Alzheimer's Disease Diagnosis. (arXiv:2206.08826v2 [cs.LG] UPDATED)
33. COVID-19 Detection Using Transfer Learning Approach from Computed Tomography Images. (arXiv:2207.00259v4 [eess.IV] UPDATED)
34. COVID-19 Detection and Analysis From Lung CT Images using Novel Channel Boosted CNNs. (arXiv:2209.10963v2 [eess.IV] UPDATED)
35. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v2 [eess.IV] UPDATED)
36. Structure Guided Manifolds for Discovery of Disease Characteristics. (arXiv:2209.11015v2 [eess.IV] UPDATED)
## cs.LG
---
**215** new papers in cs.LG:-) 
1. Towards Auditing Unsupervised Learning Algorithms and Human Processes For Fairness. (arXiv:2209.11762v1 [cs.AI])
2. Enhancing Claim Classification with Feature Extraction from Anomaly-Detection-Derived Routine and Peculiarity Profiles. (arXiv:2209.11763v1 [cs.LG])
3. Multistage Large Segment Imputation Framework Based on Deep Learning and Statistic Metrics. (arXiv:2209.11766v1 [cs.LG])
4. Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
5. Toward Smart Doors: A Position Paper. (arXiv:2209.11770v1 [cs.HC])
6. Tiered Pruning for Efficient Differentialble Inference-Aware Neural Architecture Search. (arXiv:2209.11785v1 [cs.LG])
7. Composite Layers for Deep Anomaly Detection on 3D Point Clouds. (arXiv:2209.11796v1 [cs.CV])
8. Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained Language Models. (arXiv:2209.11799v1 [cs.AI])
9. Solutions to preference manipulation in recommender systems require knowledge of meta-preferences. (arXiv:2209.11801v1 [cs.IR])
10. Periodic Graph Transformers for Crystal Material Property Prediction. (arXiv:2209.11807v1 [cs.LG])
11. An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret. (arXiv:2209.11817v1 [cs.LG])
12. Expanding the Deployment Envelope of Behavior Prediction via Adaptive Meta-Learning. (arXiv:2209.11820v1 [cs.LG])
13. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. (arXiv:2209.11824v1 [cs.IR])
14. Creating Compact Regions of Social Determinants of Health. (arXiv:2209.11836v1 [cs.LG])
15. Doubly Fair Dynamic Pricing. (arXiv:2209.11837v1 [cs.LG])
16. Privacy-Preserving Online Content Moderation: A Federated Learning Use Case. (arXiv:2209.11843v1 [cs.LG])
17. Tighter Variational Bounds are Not Necessarily Better. A Research Report on Implementation, Ablation Study, and Extensions. (arXiv:2209.11875v1 [stat.ML])
18. Hebbian Deep Learning Without Feedback. (arXiv:2209.11883v1 [cs.NE])
19. Physics-Informed Graph Neural Network for Spatial-temporal Production Forecasting. (arXiv:2209.11885v1 [cs.LG])
20. Whodunit? Learning to Contrast for Authorship Attribution. (arXiv:2209.11887v1 [cs.CL])
21. Highly Scalable Task Grouping for Deep Multi-Task Learning in Prediction of Epigenetic Events. (arXiv:2209.11892v1 [cs.LG])
22. In-context Learning and Induction Heads. (arXiv:2209.11895v1 [cs.LG])
23. Two Bicomplex Least Mean Square (BLMS) algorithms. (arXiv:2209.11899v1 [cs.LG])
24. Learning Chess With Language Models and Transformers. (arXiv:2209.11902v1 [cs.AI])
25. CryptoGCN: Fast and Scalable Homomorphically Encrypted Graph Convolutional Network Inference. (arXiv:2209.11904v1 [cs.CR])
26. Speech **Enhancement** with Perceptually-motivated Optimization and Dual Transformations. (arXiv:2209.11905v1 [cs.SD])
27. Joint Speech Activity and Overlap Detection with Multi-Exit Architecture. (arXiv:2209.11906v1 [cs.SD])
28. Fast Lifelong Adaptive Inverse Reinforcement Learning from Demonstrations. (arXiv:2209.11908v1 [cs.LG])
29. Concordance based Survival Cobra with regression type weak learners. (arXiv:2209.11919v1 [stat.ML])
30. Tradeoffs between convergence rate and noise amplification for momentum-based accelerated optimization algorithms. (arXiv:2209.11920v1 [math.OC])
31. DeepChrome 2.0: Investigating and Improving Architectures, Visualizations, & Experiments. (arXiv:2209.11923v1 [cs.LG])
32. Interventional Causal Representation Learning. (arXiv:2209.11924v1 [stat.ML])
33. Communication-Efficient {Federated} Learning Using Censored Heavy Ball Descent. (arXiv:2209.11944v1 [cs.LG])
34. Are Machine Programming Systems using Right Source-Code Measures to Select Code Repositories?. (arXiv:2209.11946v1 [cs.SE])
35. Hybrid Multimodal Fusion for Humor Detection. (arXiv:2209.11949v1 [cs.LG])
36. TransPOS: Transformers for Consolidating Different POS Tagset Datasets. (arXiv:2209.11959v1 [cs.CL])
37. Raising the Bar on the Evaluation of Out-of-Distribution Detection. (arXiv:2209.11960v1 [cs.CV])
38. Approximate better, Attack stronger: Adversarial Example Generation via Asymptotically Gaussian Mixture Distribution. (arXiv:2209.11964v1 [cs.LG])
39. Removal of Ocular Artifacts in EEG Using Deep Learning. (arXiv:2209.11980v1 [eess.SP])
40. On Gender Bias in Fake News. (arXiv:2209.11984v1 [cs.CY])
41. Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems. (arXiv:2209.12000v1 [cs.AI])
42. Toward Intention Discovery for Early Malice Detection in Bitcoin. (arXiv:2209.12001v1 [cs.LG])
43. Contrastive learning for unsupervised medical image clustering and reconstruction. (arXiv:2209.12005v1 [cs.CV])
44. Explainable Reinforcement Learning via Model Transforms. (arXiv:2209.12006v1 [cs.AI])
45. Non-monotonic Resource Utilization in the Bandits with Knapsacks Problem. (arXiv:2209.12013v1 [cs.LG])
46. Asset Pricing and Deep Learning. (arXiv:2209.12014v1 [q-fin.ST])
47. Unsupervised Model-based Pre-training for Data-efficient Control from Pixels. (arXiv:2209.12016v1 [cs.AI])
48. Energy-Environment evaluation and Forecast of a Novel Regenerative turboshaft engine combine cycle with DNN application. (arXiv:2209.12020v1 [eess.SP])
49. Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation. (arXiv:2209.12029v1 [cs.LG])
50. Graph Representation Learning for Energy Demand Data: Application to Joint Energy System Planning under Emissions Constraints. (arXiv:2209.12035v1 [cs.LG])
51. Unsupervised domain adaptation for speech recognition with unsupervised error correction. (arXiv:2209.12043v1 [cs.SD])
52. Blinder: End-to-end Privacy Protection in Sensing Systems via Personalized Federated Learning. (arXiv:2209.12046v1 [cs.LG])
53. From Local to Global: Spectral-Inspired Graph Neural Networks. (arXiv:2209.12054v1 [stat.ML])
54. One-Shot Learning of Stochastic Differential Equations with Computational Graph Completion. (arXiv:2209.12086v1 [stat.ML])
55. Identifying latent activity behaviors and lifestyles using mobility data to describe urban dynamics. (arXiv:2209.12095v1 [physics.soc-ph])
56. Valuation of Public Bus Electrification with Open Data. (arXiv:2209.12107v1 [eess.SY])
57. An Asymptotically Optimal Batched Algorithm for the Dueling Bandit Problem. (arXiv:2209.12108v1 [cs.LG])
58. Online Allocation and Learning in the Presence of Strategic Agents. (arXiv:2209.12112v1 [cs.GT])
59. Bigger&Faster: Two-stage Neural Architecture Search for Quantized Transformer Models. (arXiv:2209.12127v1 [cs.LG])
60. A Deep Learning Approach to Analyzing Continuous-Time Systems. (arXiv:2209.12128v1 [cs.LG])
61. Machine Learning and Artificial Intelligence-Driven Multi-Scale Modeling for High Burnup Accident-Tolerant Fuels for Light Water-Based SMR Applications. (arXiv:2209.12146v1 [eess.SY])
62. Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v1 [cs.CV])
63. All are Worth Words: a ViT Backbone for Score-based Diffusion Models. (arXiv:2209.12152v1 [cs.CV])
64. Joint Triplet Loss Learning for Next New POI Recommendation. (arXiv:2209.12162v1 [cs.IR])
65. Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique. (arXiv:2209.12177v1 [cs.CL])
66. SPRITZ-1.5C: Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks. (arXiv:2209.12195v1 [cs.CR])
67. Capacity dependent analysis for functional online learning algorithms. (arXiv:2209.12198v1 [stat.ML])
68. Transfer learning for self-supervised, blind-spot seismic denoising. (arXiv:2209.12210v1 [physics.geo-ph])
69. Efficient Long Sequential User Data Modeling for Click-Through Rate Prediction. (arXiv:2209.12212v1 [cs.IR])
70. GPatch: Patching Graph Neural Networks for Cold-Start Recommendations. (arXiv:2209.12215v1 [cs.IR])
71. Partial annotations for the segmentation of large structures with low annotation cost. (arXiv:2209.12216v1 [eess.IV])
72. High-Resolution Satellite Imagery for Modeling the Impact of Aridification on Crop Production. (arXiv:2209.12238v1 [cs.CV])
73. Exploring Example Influence in Continual Learning. (arXiv:2209.12241v1 [cs.LG])
74. Algorithms that Approximate Data Removal: New Results and Limitations. (arXiv:2209.12269v1 [stat.ML])
75. VAESim: A probabilistic approach for self-supervised prototype discovery. (arXiv:2209.12279v1 [cs.CV])
76. Deep Feature Selection Using a Novel Complementary Feature Mask. (arXiv:2209.12282v1 [cs.LG])
77. On Representing Linear Programs by Graph Neural Networks. (arXiv:2209.12288v1 [cs.LG])
78. Gradient Optimization for Single-State RMDPs. (arXiv:2209.12295v1 [cs.LG])
79. Adnexal Mass Segmentation with Ultrasound Data Synthesis. (arXiv:2209.12305v1 [eess.IV])
80. On the Stability Analysis of Open Federated Learning Systems. (arXiv:2209.12307v1 [cs.LG])
81. Feature Encodings for Gradient Boosting with Automunge. (arXiv:2209.12309v1 [cs.LG])
82. Weather2vec: Representation Learning for Causal Inference with Non-Local Confounding in Air Pollution and Climate Studies. (arXiv:2209.12316v1 [cs.LG])
83. An Empirical Study on Cross-X Transfer for Legal Judgment Prediction. (arXiv:2209.12325v1 [cs.CL])
84. Personalizing Text-to-Image Generation via Aesthetic Gradients. (arXiv:2209.12330v1 [cs.CV])
85. Temporally Extended Successor Representations. (arXiv:2209.12331v1 [cs.LG])
86. Generating Formal Safety Assurances for High-Dimensional Reachability. (arXiv:2209.12336v1 [cs.RO])
87. Solving Seismic Wave Equations on Variable Velocity Models with Fourier Neural Operator. (arXiv:2209.12340v1 [cs.LG])
88. Paraphrasing Is All You Need for Novel Object Captioning. (arXiv:2209.12343v1 [cs.CV])
89. Stochastic Gradient Descent Captures How Children Learn About Physics. (arXiv:2209.12344v1 [cs.LG])
90. On the Opportunities and Challenges of using Animals Videos in Reinforcement Learning. (arXiv:2209.12347v1 [eess.SY])
91. Unsupervised Reward Shaping for a Robotic Sequential Picking Task from Visual Observations in a Logistics Scenario. (arXiv:2209.12350v1 [cs.RO])
92. Deep Reinforcement Learning for Adaptive Mesh Refinement. (arXiv:2209.12351v1 [cs.CE])
93. DDP-GCN: Multi-Graph Convolutional Network for Spatiotemporal Traffic Forecasting. (arXiv:1905.12256v3 [cs.LG] UPDATED)
94. A Review on Deep Learning in Medical Image Reconstruction. (arXiv:1906.10643v2 [eess.IV] UPDATED)
95. Composing Neural Learning and Symbolic Reasoning with an Application to Visual Discrimination. (arXiv:1907.05878v3 [cs.LG] UPDATED)
96. PPG2ABP: Translating Photoplethysmogram (PPG) Signals to Arterial Blood Pressure (ABP) Waveforms using Fully Convolutional Neural Networks. (arXiv:2005.01669v2 [eess.SP] UPDATED)
97. Variational Inference as Iterative Projection in a Bayesian Hilbert Space with Application to Robotic State Estimation. (arXiv:2005.07275v3 [cs.LG] UPDATED)
98. DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data. (arXiv:2006.10802v3 [eess.IV] UPDATED)
99. Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v4 [cs.LG] UPDATED)
100. MGIC: Multigrid-in-Channels Neural Network Architectures. (arXiv:2011.09128v4 [cs.CV] UPDATED)
101. Deep Empirical Risk Minimization in finance: looking into the future. (arXiv:2011.09349v3 [stat.ML] UPDATED)
102. GDA-HIN: A Generalized Domain Adaptive Model across Heterogeneous Information Networks. (arXiv:2012.05688v3 [cs.LG] UPDATED)
103. How Far Should We Look Back to Achieve Effective Real-Time Time-Series Anomaly Detection?. (arXiv:2102.06560v3 [cs.LG] UPDATED)
104. Bias-reduced Multi-step Hindsight Experience Replay for Efficient Multi-goal Reinforcement Learning. (arXiv:2102.12962v3 [cs.LG] UPDATED)
105. Consistency of Constrained Spectral Clustering under Graph Induced Fair Planted Partitions. (arXiv:2105.03714v2 [cs.LG] UPDATED)
106. Cooperative Online Learning with Feedback Graphs. (arXiv:2106.04982v4 [cs.LG] UPDATED)
107. ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense. (arXiv:2106.14300v4 [cs.LG] UPDATED)
108. Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction. (arXiv:2106.15013v4 [cs.LG] UPDATED)
109. Optimal Binary Classification Beyond Accuracy. (arXiv:2107.01777v3 [math.ST] UPDATED)
110. Deep Network Approximation: Achieving Arbitrary Accuracy with Fixed Number of Neurons. (arXiv:2107.02397v7 [cs.LG] UPDATED)
111. Clustering-Based Representation Learning through Output Translation and Its Application to Remote--Sensing Images. (arXiv:2107.05948v4 [cs.LG] UPDATED)
112. FLAT: An Optimized Dataflow for Mitigating Attention Bottlenecks. (arXiv:2107.06419v7 [cs.LG] UPDATED)
113. A Framework for Adversarial Streaming via Differential Privacy and Difference Estimators. (arXiv:2107.14527v2 [cs.DS] UPDATED)
114. Data Efficient Human Intention Prediction: Leveraging Neural Network Verification and Expert Guidance. (arXiv:2108.06871v3 [cs.LG] UPDATED)
115. A Stochastic Variance-Reduced Coordinate Descent Algorithm for Learning Sparse Bayesian Network from Discrete High-Dimensional Data. (arXiv:2108.09501v2 [cs.LG] UPDATED)
116. Learned Benchmarks for Subseasonal Forecasting. (arXiv:2109.10399v2 [physics.ao-ph] UPDATED)
117. Batch size-invariance for policy optimization. (arXiv:2110.00641v3 [cs.LG] UPDATED)
118. Towards Demystifying Representation Learning with Non-contrastive Self-supervision. (arXiv:2110.04947v2 [cs.LG] UPDATED)
119. Value Penalized Q-Learning for Recommender Systems. (arXiv:2110.07923v2 [cs.LG] UPDATED)
120. Neural Stochastic PDEs: Resolution-Invariant Learning of Continuous Spatiotemporal Dynamics. (arXiv:2110.10249v8 [cs.LG] UPDATED)
121. Finite-Time Complexity of Online Primal-Dual Natural Actor-Critic Algorithm for Constrained Markov Decision Processes. (arXiv:2110.11383v2 [math.OC] UPDATED)
122. ProtoShotXAI: Using Prototypical Few-Shot Architecture for Explainable AI. (arXiv:2110.11597v2 [cs.LG] UPDATED)
123. Error-correcting neural networks for semi-Lagrangian advection in the level-set method. (arXiv:2110.11611v3 [cs.LG] UPDATED)
124. The network signature of constellation line figures. (arXiv:2110.12329v4 [cs.SI] UPDATED)
125. MedMNIST v2 -- A large-scale lightweight benchmark for 2D and 3D biomedical image classification. (arXiv:2110.14795v2 [cs.CV] UPDATED)
126. Fair Incentives for Repeated Engagement. (arXiv:2111.00002v2 [cs.GT] UPDATED)
127. Realizable Learning is All You Need. (arXiv:2111.04746v2 [cs.LG] UPDATED)
128. Nonstochastic Bandits with Composite Anonymous Feedback. (arXiv:2112.02866v2 [cs.LG] UPDATED)
129. Local Advantage Networks for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2112.12458v2 [cs.LG] UPDATED)
130. The impacts of various parameters on learning process and machine learning based performance prediction in online coding competitions. (arXiv:2112.14407v3 [cs.HC] UPDATED)
131. Persformer: A Transformer Architecture for Topological Machine Learning. (arXiv:2112.15210v2 [cs.LG] UPDATED)
132. Modeling Mask Uncertainty in Hyperspectral Image Reconstruction. (arXiv:2112.15362v4 [eess.IV] UPDATED)
133. Overcoming Exploration: Deep Reinforcement Learning in Complex Environments from Temporal Logic Specifications. (arXiv:2201.12231v4 [cs.RO] UPDATED)
134. DCSAU-Net: A Deeper and More Compact Split-Attention U-Net for Medical Image Segmentation. (arXiv:2202.00972v2 [eess.IV] UPDATED)
135. Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary Time-Series. (arXiv:2202.02403v3 [cs.LG] UPDATED)
136. Deep Neural Networks to Correct Sub-Precision Errors in CFD. (arXiv:2202.04233v3 [physics.flu-dyn] UPDATED)
137. An Application of Online Learning to Spacecraft Memory Dump Optimization. (arXiv:2202.06617v2 [cs.LG] UPDATED)
138. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v4 [cs.CV] UPDATED)
139. Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v3 [cs.LG] UPDATED)
140. Task-Agnostic Graph Explanations. (arXiv:2202.08335v2 [cs.LG] UPDATED)
141. On Variance Estimation of Random Forests. (arXiv:2202.09008v3 [stat.ML] UPDATED)
142. Geometric Regularization from Overparameterization. (arXiv:2202.09276v2 [cs.LG] UPDATED)
143. Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training. (arXiv:2202.09514v2 [cs.LG] UPDATED)
144. VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning. (arXiv:2202.10324v2 [cs.CV] UPDATED)
145. Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data. (arXiv:2203.04218v2 [cs.RO] UPDATED)
146. Constitutive model characterization and discovery using physics-informed deep learning. (arXiv:2203.09789v2 [cs.LG] UPDATED)
147. GCF: Generalized Causal Forest for Heterogeneous Treatment Effect Estimation in Online Marketplace. (arXiv:2203.10975v2 [stat.ML] UPDATED)
148. Interpretable Machine Learning Models for Modal Split Prediction in Transportation Systems. (arXiv:2203.14191v2 [cs.LG] UPDATED)
149. FedVLN: Privacy-preserving Federated Vision-and-Language Navigation. (arXiv:2203.14936v3 [cs.AI] UPDATED)
150. When to Classify Events in Open Times Series?. (arXiv:2204.00392v2 [cs.LG] UPDATED)
151. Efficient Reconstruction of Stochastic Pedigrees: Some Steps From Theory to Practice. (arXiv:2204.04573v2 [q-bio.PE] UPDATED)
152. Uniform Complexity for Text Generation. (arXiv:2204.05185v2 [cs.CL] UPDATED)
153. AlphaZero-Inspired Game Learning: Faster Training by Using MCTS Only at Test Time. (arXiv:2204.13307v3 [cs.LG] UPDATED)
154. On the speed of uniform convergence in Mercer's theorem. (arXiv:2205.00487v2 [cs.LG] UPDATED)
155. EF-BV: A Unified Theory of Error Feedback and Variance Reduction Mechanisms for Biased and Unbiased Compression in Distributed Optimization. (arXiv:2205.04180v2 [cs.LG] UPDATED)
156. ALLSH: Active Learning Guided by Local Sensitivity and Hardness. (arXiv:2205.04980v2 [cs.CL] UPDATED)
157. FedHAP: Fast Federated Learning for LEO Constellations Using Collaborative HAPs. (arXiv:2205.07216v4 [cs.LG] UPDATED)
158. Exploiting the Relationship Between Kendall's Rank Correlation and Cosine Similarity for Attribution Protection. (arXiv:2205.07279v2 [cs.LG] UPDATED)
159. Latent Variable Method Demonstrator -- Software for Understanding Multivariate Data Analytics Algorithms. (arXiv:2205.08132v2 [stat.ML] UPDATED)
160. A unified framework for dataset shift diagnostics. (arXiv:2205.08340v2 [stat.ML] UPDATED)
161. How do Variational Autoencoders Learn? Insights from Representational Similarity. (arXiv:2205.08399v3 [cs.LG] UPDATED)
162. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v5 [cs.LG] UPDATED)
163. Self-Consistent Dynamical Field Theory of Kernel Evolution in Wide Neural Networks. (arXiv:2205.09653v2 [stat.ML] UPDATED)
164. Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?. (arXiv:2205.10652v2 [cs.AI] UPDATED)
165. Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret. (arXiv:2205.12418v2 [cs.LG] UPDATED)
166. Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification. (arXiv:2205.13094v3 [cs.LG] UPDATED)
167. ALMA: Hierarchical Learning for Composite Multi-Agent Tasks. (arXiv:2205.14205v2 [cs.LG] UPDATED)
168. Tuning Frequency Bias in Neural Network Training with Nonuniform Data. (arXiv:2205.14300v2 [cs.LG] UPDATED)
169. RORL: Robust Offline Reinforcement Learning via Conservative Smoothing. (arXiv:2206.02829v2 [cs.LG] UPDATED)
170. Graph Rationalization with Environment-based Augmentations. (arXiv:2206.02886v2 [cs.LG] UPDATED)
171. Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. (arXiv:2206.07137v3 [cs.LG] UPDATED)
172. Multimodal Attention-based Deep Learning for Alzheimer's Disease Diagnosis. (arXiv:2206.08826v2 [cs.LG] UPDATED)
173. Motley: Benchmarking Heterogeneity and Personalization in Federated Learning. (arXiv:2206.09262v6 [cs.LG] UPDATED)
174. Contextual Squeeze-and-Excitation for Efficient Few-Shot Image Classification. (arXiv:2206.09843v2 [cs.CV] UPDATED)
175. Generalized Permutants and Graph GENEOs. (arXiv:2206.14798v2 [math.CO] UPDATED)
176. An Additive Instance-Wise Approach to Multi-class Model Interpretation. (arXiv:2207.03113v3 [cs.LG] UPDATED)
177. RSD-GAN: Regularized Sobolev Defense GAN Against Speech-to-Text Adversarial Attacks. (arXiv:2207.06858v2 [cs.SD] UPDATED)
178. Automatic Sleep Scoring from Large-scale Multi-channel Pediatric EEG. (arXiv:2207.06921v2 [eess.SP] UPDATED)
179. A Concise Framework of Memory Efficient Training via Dual Activation Precision. (arXiv:2208.04187v2 [cs.LG] UPDATED)
180. FedOBD: Opportunistic Block Dropout for Efficiently Training Large-scale Neural Networks through Federated Learning. (arXiv:2208.05174v2 [cs.LG] UPDATED)
181. An Empirical Exploration of Cross-domain Alignment between Language and Electroencephalogram. (arXiv:2208.06348v3 [q-bio.NC] UPDATED)
182. A Near-Optimal Algorithm for Univariate Zeroth-Order Budget Convex Optimization. (arXiv:2208.06720v2 [math.OC] UPDATED)
183. How Does Data Freshness Affect **Real-time** Supervised Learning?. (arXiv:2208.06948v2 [cs.NI] UPDATED)
184. Dynamical softassign and adaptive parameter tuning for graph matching. (arXiv:2208.08233v2 [math.CO] UPDATED)
185. MLExchange: A web-based platform enabling exchangeable machine learning workflows for scientific studies. (arXiv:2208.09751v3 [cs.LG] UPDATED)
186. MolGraph: a Python package for the implementation of small molecular graphs and graph neural networks with TensorFlow and Keras. (arXiv:2208.09944v3 [cs.LG] UPDATED)
187. SCALE: Online Self-Supervised Lifelong Learning without Prior Knowledge. (arXiv:2208.11266v2 [cs.LG] UPDATED)
188. Federated Learning with Label Distribution Skew via Logits Calibration. (arXiv:2209.00189v2 [cs.LG] UPDATED)
189. ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets. (arXiv:2209.00613v2 [cs.LG] UPDATED)
190. Three Learning Stages and Accuracy-Efficiency Tradeoff of Restricted Boltzmann Machines. (arXiv:2209.00873v2 [cs.LG] UPDATED)
191. Regret Analysis of Dyadic Search. (arXiv:2209.00885v2 [cs.LG] UPDATED)
192. Applying Machine Learning to Life Insurance: some knowledge sharing to master it. (arXiv:2209.02057v2 [stat.ML] UPDATED)
193. Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics. (arXiv:2209.04049v2 [cs.AI] UPDATED)
194. Towards Sparsification of Graph Neural Networks. (arXiv:2209.04766v2 [cs.LG] UPDATED)
195. Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization. (arXiv:2209.05045v2 [math.OC] UPDATED)
196. Bounding the Rademacher Complexity of Fourier neural operators. (arXiv:2209.05150v3 [cs.LG] UPDATED)
197. Class-Level Logit Perturbation. (arXiv:2209.05668v3 [cs.LG] UPDATED)
198. Data Lifecycle Management in Evolving Input Distributions for Learning-based Aerospace Applications. (arXiv:2209.06855v2 [cs.CV] UPDATED)
199. Out-of-Distribution Representation Learning for Time Series Classification. (arXiv:2209.07027v2 [cs.LG] UPDATED)
200. ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech. (arXiv:2209.07556v2 [cs.GR] UPDATED)
201. Context-Aware Query Rewriting for Improving Users' Search Experience on E-commerce Websites. (arXiv:2209.07584v2 [cs.IR] UPDATED)
202. Self-Relation Attention and Temporal Awareness for Emotion Recognition via Vocal Burst. (arXiv:2209.07629v2 [cs.SD] UPDATED)
203. Rewarding Episodic Visitation Discrepancy for Exploration in Reinforcement Learning. (arXiv:2209.08842v2 [cs.LG] UPDATED)
204. Global Optimization for Cardinality-constrained Minimum Sum-of-Squares Clustering via Semidefinite Programming. (arXiv:2209.08901v2 [math.OC] UPDATED)
205. Relational Reasoning via Set Transformers: Provable Efficiency and Applications to MARL. (arXiv:2209.09845v2 [cs.LG] UPDATED)
206. Robust, High-Rate Trajectory Tracking on Insect-Scale Soft-Actuated Aerial Robots with Deep-Learned Tube MPC. (arXiv:2209.10007v2 [cs.RO] UPDATED)
207. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v3 [eess.AS] UPDATED)
208. Grape Cold Hardiness Prediction via Multi-Task Learning. (arXiv:2209.10585v2 [cs.LG] UPDATED)
209. Mega: Moving Average Equipped Gated Attention. (arXiv:2209.10655v2 [cs.LG] UPDATED)
210. Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation. (arXiv:2209.10780v2 [cs.RO] UPDATED)
211. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v2 [cs.CV] UPDATED)
212. Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing. (arXiv:2209.11002v2 [eess.IV] UPDATED)
213. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v2 [cs.RO] UPDATED)
214. U-Sleep: resilient to AASM guidelines. (arXiv:2209.11173v2 [eess.SP] UPDATED)
215. SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features. (arXiv:2209.11174v2 [eess.SP] UPDATED)
## cs.AI
---
**114** new papers in cs.AI:-) 
1. Assessment of cognitive characteristics in intelligent systems and predictive ability. (arXiv:2209.11761v1 [cs.AI])
2. Towards Auditing Unsupervised Learning Algorithms and Human Processes For Fairness. (arXiv:2209.11762v1 [cs.AI])
3. Taking the Intentional Stance Seriously: A Guide to Progress in Artificial Intelligence. (arXiv:2209.11764v1 [cs.AI])
4. Mental arithmetic task classification with convolutional neural network based on spectral-temporal features from EEG. (arXiv:2209.11767v1 [eess.SP])
5. Toward Smart Doors: A Position Paper. (arXiv:2209.11770v1 [cs.HC])
6. Safe Real-World Reinforcement Learning for Mobile Agent Obstacle Avoidance. (arXiv:2209.11789v1 [cs.RO])
7. Emb-GAM: an Interpretable and Efficient Predictor using Pre-trained Language Models. (arXiv:2209.11799v1 [cs.AI])
8. Solutions to preference manipulation in recommender systems require knowledge of meta-preferences. (arXiv:2209.11801v1 [cs.IR])
9. On Explanations, Fairness, and Appropriate Reliance in Human-AI Decision-Making. (arXiv:2209.11812v1 [cs.HC])
10. M2TRec: Metadata-aware Multi-task Transformer for Large-scale and Cold-start free Session-based Recommendations. (arXiv:2209.11824v1 [cs.IR])
11. Multiple-Choice Question Generation: Towards an Automated Assessment Framework. (arXiv:2209.11830v1 [cs.CL])
12. Whodunit? Learning to Contrast for Authorship Attribution. (arXiv:2209.11887v1 [cs.CL])
13. Learning Chess With Language Models and Transformers. (arXiv:2209.11902v1 [cs.AI])
14. CryptoGCN: Fast and Scalable Homomorphically Encrypted Graph Convolutional Network Inference. (arXiv:2209.11904v1 [cs.CR])
15. Speech **Enhancement** with Perceptually-motivated Optimization and Dual Transformations. (arXiv:2209.11905v1 [cs.SD])
16. Joint Speech Activity and Overlap Detection with Multi-Exit Architecture. (arXiv:2209.11906v1 [cs.SD])
17. Concordance based Survival Cobra with regression type weak learners. (arXiv:2209.11919v1 [stat.ML])
18. Communication-Efficient {Federated} Learning Using Censored Heavy Ball Descent. (arXiv:2209.11944v1 [cs.LG])
19. Are Machine Programming Systems using Right Source-Code Measures to Select Code Repositories?. (arXiv:2209.11946v1 [cs.SE])
20. Hybrid Multimodal Fusion for Humor Detection. (arXiv:2209.11949v1 [cs.LG])
21. Developing a Knowledge Graph Framework for Pharmacokinetic Natural Product-Drug Interactions. (arXiv:2209.11950v1 [cs.AI])
22. TransPOS: Transformers for Consolidating Different POS Tagset Datasets. (arXiv:2209.11959v1 [cs.CL])
23. A Deep Investigation of RNN and Self-attention for the Cyrillic-Traditional Mongolian Bidirectional Conversion. (arXiv:2209.11963v1 [cs.CL])
24. Removal of Ocular Artifacts in EEG Using Deep Learning. (arXiv:2209.11980v1 [eess.SP])
25. Deep Attentive Belief Propagation: Integrating Reasoning and Learning for Solving Constraint Optimization Problems. (arXiv:2209.12000v1 [cs.AI])
26. Toward Intention Discovery for Early Malice Detection in Bitcoin. (arXiv:2209.12001v1 [cs.LG])
27. Explainable Reinforcement Learning via Model Transforms. (arXiv:2209.12006v1 [cs.AI])
28. Spiking SiamFC++: Deep Spiking Neural Network for Object Tracking. (arXiv:2209.12010v1 [cs.CV])
29. Unsupervised Model-based Pre-training for Data-efficient Control from Pixels. (arXiv:2209.12016v1 [cs.AI])
30. Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation. (arXiv:2209.12029v1 [cs.LG])
31. Unsupervised domain adaptation for speech recognition with unsupervised error correction. (arXiv:2209.12043v1 [cs.SD])
32. Song Emotion Recognition: a Performance Comparison Between Audio Features and Artificial Neural Networks. (arXiv:2209.12045v1 [cs.SD])
33. Climate Impact Modelling Framework. (arXiv:2209.12080v1 [cs.DC])
34. Graph Neural Networks for Multi-Robot Active Information Acquisition. (arXiv:2209.12091v1 [cs.RO])
35. Learn what matters: cross-domain imitation learning with task-relevant embeddings. (arXiv:2209.12093v1 [cs.AI])
36. Controllable Text Generation for Open-Domain Creativity and Fairness. (arXiv:2209.12099v1 [cs.CL])
37. Answer-Set Programs for Repair Updates and Counterfactual Interventions. (arXiv:2209.12110v1 [cs.LO])
38. Self-Supervised Masked Convolutional Transformer Block for Anomaly Detection. (arXiv:2209.12148v1 [cs.CV])
39. All are Worth Words: a ViT Backbone for Score-based Diffusion Models. (arXiv:2209.12152v1 [cs.CV])
40. WinoDict: Probing language models for in-context word acquisition. (arXiv:2209.12153v1 [cs.CL])
41. Joint Triplet Loss Learning for Next New POI Recommendation. (arXiv:2209.12162v1 [cs.IR])
42. Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward. (arXiv:2209.12164v1 [cs.CV])
43. Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique. (arXiv:2209.12177v1 [cs.CL])
44. SPRITZ-1.5C: Employing Deep Ensemble Learning for Improving the Security of Computer Networks against Adversarial Attacks. (arXiv:2209.12195v1 [cs.CR])
45. High-Resolution Satellite Imagery for Modeling the Impact of Aridification on Crop Production. (arXiv:2209.12238v1 [cs.CV])
46. Probabilistic Planning with Partially Ordered Preferences over Temporal Goals. (arXiv:2209.12267v1 [cs.RO])
47. Social Assistive Robotics for Autistic Children. (arXiv:2209.12289v1 [cs.RO])
48. An Empirical Study on Cross-X Transfer for Legal Judgment Prediction. (arXiv:2209.12325v1 [cs.CL])
49. Temporally Extended Successor Representations. (arXiv:2209.12331v1 [cs.LG])
50. Generating Formal Safety Assurances for High-Dimensional Reachability. (arXiv:2209.12336v1 [cs.RO])
51. Stochastic Gradient Descent Captures How Children Learn About Physics. (arXiv:2209.12344v1 [cs.LG])
52. Political economy of superhuman AI. (arXiv:2209.12346v1 [econ.TH])
53. On the Opportunities and Challenges of using Animals Videos in Reinforcement Learning. (arXiv:2209.12347v1 [eess.SY])
54. Composing Neural Learning and Symbolic Reasoning with an Application to Visual Discrimination. (arXiv:1907.05878v3 [cs.LG] UPDATED)
55. Hurricane Forecasting: A Novel Multimodal Machine Learning Framework. (arXiv:2011.06125v4 [cs.LG] UPDATED)
56. Bias-reduced Multi-step Hindsight Experience Replay for Efficient Multi-goal Reinforcement Learning. (arXiv:2102.12962v3 [cs.LG] UPDATED)
57. Inference of Upcoming Human Grasp Using EMG During Reach-to-Grasp Movement. (arXiv:2104.09627v3 [cs.RO] UPDATED)
58. Attend and select: A segment selective transformer for microblog hashtag generation. (arXiv:2106.03151v2 [cs.CL] UPDATED)
59. ASK: Adversarial Soft k-Nearest Neighbor Attack and Defense. (arXiv:2106.14300v4 [cs.LG] UPDATED)
60. Clustering-Based Representation Learning through Output Translation and Its Application to Remote--Sensing Images. (arXiv:2107.05948v4 [cs.LG] UPDATED)
61. Value Penalized Q-Learning for Recommender Systems. (arXiv:2110.07923v2 [cs.LG] UPDATED)
62. MedMNIST v2 -- A large-scale lightweight benchmark for 2D and 3D biomedical image classification. (arXiv:2110.14795v2 [cs.CV] UPDATED)
63. Natural Language Processing for Smart Healthcare. (arXiv:2110.15803v3 [cs.CL] UPDATED)
64. Local Advantage Networks for Cooperative Multi-Agent Reinforcement Learning. (arXiv:2112.12458v2 [cs.LG] UPDATED)
65. Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary Time-Series. (arXiv:2202.02403v3 [cs.LG] UPDATED)
66. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v4 [cs.CV] UPDATED)
67. Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training. (arXiv:2202.09514v2 [cs.LG] UPDATED)
68. VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning. (arXiv:2202.10324v2 [cs.CV] UPDATED)
69. Find a Way Forward: a Language-Guided Semantic Map Navigator. (arXiv:2203.03183v2 [cs.AI] UPDATED)
70. Learning Bidirectional Translation between Descriptions and Actions with Small Paired Data. (arXiv:2203.04218v2 [cs.RO] UPDATED)
71. Adaptive Risk-Tendency: Nano Drone Navigation in Cluttered Environments with Distributional Reinforcement Learning. (arXiv:2203.14749v2 [cs.RO] UPDATED)
72. FedVLN: Privacy-preserving Federated Vision-and-Language Navigation. (arXiv:2203.14936v3 [cs.AI] UPDATED)
73. When to Classify Events in Open Times Series?. (arXiv:2204.00392v2 [cs.LG] UPDATED)
74. Long Video Generation with Time-Agnostic VQGAN and Time-Sensitive Transformer. (arXiv:2204.03638v4 [cs.CV] UPDATED)
75. Access to care: analysis of the geographical distribution of healthcare using Linked Open Data. (arXiv:2204.05206v2 [cs.AI] UPDATED)
76. Residue-Based Natural Language Adversarial Attack Detection. (arXiv:2204.10192v2 [cs.CL] UPDATED)
77. ATST: Audio Representation Learning with Teacher-Student Transformer. (arXiv:2204.12076v3 [eess.AS] UPDATED)
78. AlphaZero-Inspired Game Learning: Faster Training by Using MCTS Only at Test Time. (arXiv:2204.13307v3 [cs.LG] UPDATED)
79. ASP-Based Declarative Process Mining (Extended Abstract). (arXiv:2205.01979v2 [cs.AI] UPDATED)
80. ALLSH: Active Learning Guided by Local Sensitivity and Hardness. (arXiv:2205.04980v2 [cs.CL] UPDATED)
81. Exploiting the Relationship Between Kendall's Rank Correlation and Cosine Similarity for Attribution Protection. (arXiv:2205.07279v2 [cs.LG] UPDATED)
82. A unified framework for dataset shift diagnostics. (arXiv:2205.08340v2 [stat.ML] UPDATED)
83. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v5 [cs.LG] UPDATED)
84. Are Graph Neural Networks Really Helpful for Knowledge Graph Completion?. (arXiv:2205.10652v2 [cs.AI] UPDATED)
85. Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret. (arXiv:2205.12418v2 [cs.LG] UPDATED)
86. Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification. (arXiv:2205.13094v3 [cs.LG] UPDATED)
87. Human-AI Shared Control via Frequency-based Policy Dissection. (arXiv:2206.00152v2 [cs.RO] UPDATED)
88. RORL: Robust Offline Reinforcement Learning via Conservative Smoothing. (arXiv:2206.02829v2 [cs.LG] UPDATED)
89. TwiBot-22: Towards Graph-Based Twitter Bot Detection. (arXiv:2206.04564v4 [cs.SI] UPDATED)
90. A method for comparing multiple imputation techniques: a case study on the U.S. National COVID Cohort Collaborative. (arXiv:2206.06444v2 [cs.AI] UPDATED)
91. Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. (arXiv:2206.07137v3 [cs.LG] UPDATED)
92. PAC: Assisted Value Factorisation with Counterfactual Predictions in Multi-Agent Reinforcement Learning. (arXiv:2206.11420v2 [cs.MA] UPDATED)
93. An Additive Instance-Wise Approach to Multi-class Model Interpretation. (arXiv:2207.03113v3 [cs.LG] UPDATED)
94. Any Object is a Potential Weapon! Weaponized Violence Detection using Salient Image. (arXiv:2207.12850v3 [cs.CV] UPDATED)
95. HaloAE: An HaloNet based Local Transformer Auto-Encoder for Anomaly Detection and Localization. (arXiv:2208.03486v3 [cs.CV] UPDATED)
96. An Empirical Exploration of Cross-domain Alignment between Language and Electroencephalogram. (arXiv:2208.06348v3 [q-bio.NC] UPDATED)
97. MLExchange: A web-based platform enabling exchangeable machine learning workflows for scientific studies. (arXiv:2208.09751v3 [cs.LG] UPDATED)
98. ProtoPFormer: Concentrating on Prototypical Parts in Vision Transformers for Interpretable Image Recognition. (arXiv:2208.10431v2 [cs.CV] UPDATED)
99. AI and 6G into the Metaverse: Fundamentals, Challenges and Future Research Trends. (arXiv:2208.10921v2 [cs.AI] UPDATED)
100. SCALE: Online Self-Supervised Lifelong Learning without Prior Knowledge. (arXiv:2208.11266v2 [cs.LG] UPDATED)
101. Federated Learning with Label Distribution Skew via Logits Calibration. (arXiv:2209.00189v2 [cs.LG] UPDATED)
102. Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics. (arXiv:2209.04049v2 [cs.AI] UPDATED)
103. Class-Level Logit Perturbation. (arXiv:2209.05668v3 [cs.LG] UPDATED)
104. SkIn: Skimming-Intensive Long-Text Classification Using BERT for Medical Corpus. (arXiv:2209.05741v2 [cs.CL] UPDATED)
105. Out-of-Distribution Representation Learning for Time Series Classification. (arXiv:2209.07027v2 [cs.LG] UPDATED)
106. NL2INTERFACE: Interactive Visualization Interface Generation from Natural Language Queries. (arXiv:2209.08834v2 [cs.HC] UPDATED)
107. Rewarding Episodic Visitation Discrepancy for Exploration in Reinforcement Learning. (arXiv:2209.08842v2 [cs.LG] UPDATED)
108. Boosting Star-GANs for Voice Conversion with Contrastive Discriminator. (arXiv:2209.10088v3 [eess.AS] UPDATED)
109. Learning Model Predictive Controllers with Real-Time Attention for Real-World Navigation. (arXiv:2209.10780v2 [cs.RO] UPDATED)
110. DIG: Draping Implicit Garment over the Human Body. (arXiv:2209.10845v2 [cs.CV] UPDATED)
111. PACT: Perception-Action Causal Transformer for Autoregressive Robotics Pre-Training. (arXiv:2209.11133v2 [cs.RO] UPDATED)
112. SERF: Interpretable Sleep Staging using Embeddings, Rules, and Features. (arXiv:2209.11174v2 [eess.SP] UPDATED)
113. The "Beatrix'' Resurrections: Robust Backdoor Detection via Gram Matrices. (arXiv:2209.11715v2 [cs.CR] UPDATED)
114. Evaluating Agent Interactions Through Episodic Knowledge Graphs. (arXiv:2209.11746v2 [cs.AI] UPDATED)

