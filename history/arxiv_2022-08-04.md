# Your interest papers
---
## cs.CV
---
### Robust RGB-D Fusion for Saliency Detection. (arXiv:2208.01762v1 [cs.CV])
- Authors : Zongwei Wu, Shriarulmozhivarman Gobichettipalayam, Brahim Tamadazte, Guillaume Allibert, Danda Pani, dric Demonceaux
- Link : [http://arxiv.org/abs/2208.01762](http://arxiv.org/abs/2208.01762)
> ABSTRACT  :  Efficiently exploiting multi-modal inputs for accurate RGB-D saliency detection is a topic of high interest. Most existing works leverage cross-modal interactions to fuse the two streams of RGB-D for intermediate features' **enhancement**. In this process, a practical aspect of the low quality of the available depths has not been fully considered yet. In this work, we aim for RGB-D saliency detection that is robust to the low-quality depths which primarily appear in two forms: inaccuracy due to noise and the misalignment to RGB. To this end, we propose a robust RGB-D fusion method that benefits from (1) layer-wise, and (2) trident spatial, attention mechanisms. On the one hand, layer-wise attention (LWA) learns the trade-off between early and late fusion of RGB and depth features, depending upon the depth accuracy. On the other hand, trident spatial attention (TSA) aggregates the features from a wider spatial context to address the depth misalignment problem. The proposed LWA and TSA mechanisms allow us to efficiently exploit the multi-modal inputs for saliency detection while being robust against low-quality depths. Our experiments on five benchmark datasets demonstrate that the proposed fusion method performs consistently better than the state-of-the-art fusion alternatives.  
### Learning Prior Feature and Attention Enhanced Image Inpainting. (arXiv:2208.01837v1 [cs.CV])
- Authors : Chenjie Cao, Qiaole Dong, Yanwei Fu
- Link : [http://arxiv.org/abs/2208.01837](http://arxiv.org/abs/2208.01837)
> ABSTRACT  :  Many recent inpainting works have achieved impressive results by leveraging Deep Neural Networks (DNNs) to model various prior information for image **restoration**. Unfortunately, the performance of these methods is largely limited by the representation ability of vanilla Convolutional Neural Networks (CNNs) backbones.On the other hand, Vision Transformers (ViT) with self-supervised pre-training have shown great potential for many visual recognition and object detection tasks. A natural question is whether the inpainting task can be greatly benefited from the ViT backbone? However, it is nontrivial to directly replace the new backbones in inpainting networks, as the inpainting is an inverse problem fundamentally different from the recognition tasks. To this end, this paper incorporates the pre-training based Masked AutoEncoder (MAE) into the inpainting model, which enjoys richer informative priors to enhance the inpainting process. Moreover, we propose to use attention priors from MAE to make the inpainting model learn more long-distance dependencies between masked and unmasked regions. Sufficient ablations have been discussed about the inpainting and the self-supervised pre-training models in this paper. Besides, experiments on both Places2 and FFHQ demonstrate the effectiveness of our proposed model. Codes and pre-trained models are released in https://github.com/ewrfcas/MAE-FAR.  
### YOLO-FaceV2: A Scale and Occlusion Aware Face Detector. (arXiv:2208.02019v1 [cs.CV])
- Authors : Ziping Yu, Hongbo Huang, Weijun Chen, Yongxin Su, Yahui Liu, Xiuying Wang
- Link : [http://arxiv.org/abs/2208.02019](http://arxiv.org/abs/2208.02019)
> ABSTRACT  :  In recent years, face detection algorithms based on deep learning have made great progress. These algorithms can be generally divided into two categories, i.e. two-stage detector like Faster R-CNN and one-stage detector like YOLO. Because of the better balance between accuracy and speed, one-stage detectors have been widely used in many applications. In this paper, we propose a real-time face detector based on the one-stage detector YOLOv5, named YOLO-FaceV2. We design a Receptive Field **Enhancement** module called RFE to enhance receptive field of small face, and use NWD Loss to make up for the sensitivity of IoU to the location deviation of tiny objects. For face occlusion, we present an attention module named SEAM and introduce Repulsion Loss to solve it. Moreover, we use a weight function Slide to solve the imbalance between easy and hard samples and use the information of the effective receptive field to design the anchor. The experimental results on WiderFace dataset show that our face detector outperforms YOLO and its variants can be find in all easy, medium and hard subsets. Source code in https://github.com/Krasjet-Yu/YOLO-FaceV2  
### SSformer: A Lightweight Transformer for Semantic Segmentation. (arXiv:2208.02034v1 [cs.CV])
- Authors : Wentao Shi, Jing Xu, Pan Gao
- Link : [http://arxiv.org/abs/2208.02034](http://arxiv.org/abs/2208.02034)
> ABSTRACT  :  It is well believed that Transformer performs better in semantic segmentation compared to convolutional neural networks. Nevertheless, the original Vision Transformer may lack of inductive biases of local neighborhoods and possess a high time complexity. Recently, **Swin** Transformer sets a new record in various vision tasks by using hierarchical architecture and shifted windows while being more efficient. However, as **Swin** Transformer is specifically designed for image classification, it may achieve suboptimal performance on dense prediction-based segmentation task. Further, simply combing **Swin** Transformer with existing methods would lead to the boost of model size and parameters for the final segmentation model. In this paper, we rethink the **Swin** Transformer for semantic segmentation, and design a lightweight yet effective transformer model, called SSformer. In this model, considering the inherent hierarchical design of **Swin** Transformer, we propose a decoder to aggregate information from different layers, thus obtaining both local and global attentions. Experimental results show the proposed SSformer yields comparable mIoU performance with state-of-the-art models, while maintaining a smaller model size and lower compute.  
### Template matching with white balance adjustment under multiple illuminants. (arXiv:2208.02035v1 [cs.CV])
- Authors : Teruaki Akazawa, Yuma Kinoshita, Hitoshi Kiya
- Link : [http://arxiv.org/abs/2208.02035](http://arxiv.org/abs/2208.02035)
> ABSTRACT  :  In this paper, we propose a novel template matching method with a white balancing adjustment, called N-white balancing, which was proposed for multi-illuminant scenes. To reduce the influence of lighting effects, N-white balancing is applied to images for multi-illumination **color constancy**, and then a template matching method is carried out by using adjusted images. In experiments, the effectiveness of the proposed method is demonstrated to be effective in object detection tasks under various illumination conditions.  
### GPPF: A General Perception Pre-training Framework via Sparsely Activated Multi-Task Learning. (arXiv:2208.02148v1 [cs.CV])
- Authors : Benyuan Sun, Jin Dai, Zihao Liang, Congying Liu, Yi Yang, Bo Bai
- Link : [http://arxiv.org/abs/2208.02148](http://arxiv.org/abs/2208.02148)
> ABSTRACT  :  Pre-training over mixtured multi-task, multi-domain, and multi-modal data remains an open challenge in vision perception pre-training. In this paper, we propose GPPF, a General Perception Pre-training Framework, that pre-trains a task-level dynamic network, which is composed by knowledge "legos" in each layers, on labeled multi-task and multi-domain datasets. By inspecting humans' innate ability to learn in complex environment, we recognize and transfer three critical elements to deep networks: (1) simultaneous **exposure** to diverse cross-task and cross-domain information in each batch. (2) partitioned knowledge storage in separate lego units driven by knowledge sharing. (3) sparse activation of a subset of lego units for both pre-training and downstream tasks. Noteworthy, the joint training of disparate vision tasks is non-trivial due to their differences in input shapes, loss functions, output formats, data distributions, etc. Therefore, we innovatively develop a plug-and-play multi-task training algorithm, which supports Single Iteration Multiple Tasks (SIMT) concurrently training. SIMT lays the foundation of pre-training with large-scale multi-task multi-domain datasets and is proved essential for stable training in our GPPF experiments. Excitingly, the exhaustive experiments show that, our GPPF-R50 model achieves significant improvements of 2.5-5.8 over a strong baseline of the 8 pre-training tasks in GPPF-15M and harvests a range of SOTAs over the 22 downstream tasks with similar computation budgets. We also validate the generalization ability of GPPF to SOTA vision transformers with consistent improvements. These solid experimental results fully prove the effective knowledge learning, storing, sharing, and transfer provided by our novel GPPF framework.  
### CCTV-**Exposure**: An open-source system for measuring user's privacy **exposure** to mapped CCTV cameras based on geo-location (Extended Version). (arXiv:2208.02159v1 [cs.CR])
- Authors : Hannu Turtiainen, Andrei Costin, Timo Hamalainen
- Link : [http://arxiv.org/abs/2208.02159](http://arxiv.org/abs/2208.02159)
> ABSTRACT  :  In this work, we present CCTV-**Exposure** -- the first CCTV-aware solution to evaluate potential privacy **exposure** to closed-circuit television (CCTV) cameras. The objective was to develop a toolset for quantifying human **exposure** to CCTV cameras from a privacy perspective. Our novel approach is trajectory analysis of the individuals, coupled with a database of geo-location mapped CCTV cameras annotated with minimal yet sufficient meta-information. For this purpose, CCTV-**Exposure** model based on a Global Positioning System (GPS) tracking was applied to estimate individual privacy **exposure** in different scenarios. The current investigation provides an application example and validation of the modeling approach. The methodology and toolset developed and implemented in this work provide time-sequence and location-sequence of the **exposure** events, thus making possible association of the **exposure** with the individual activities and cameras, and delivers main statistics on individual's **exposure** to CCTV cameras with high spatio-temporal resolution.  
### Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v3 [eess.IV] UPDATED)
- Authors : Carlos Shimizu, Hae Yong
- Link : [http://arxiv.org/abs/2110.01606](http://arxiv.org/abs/2110.01606)
> ABSTRACT  :  Some recent studies have described deep convolutional neural networks to diagnose breast cancer in mammograms with similar or even superior performance to that of human experts. One of the best techniques does two transfer learnings: the first uses a model trained on natural images to create a "patch classifier" that categorizes small subimages; the second uses the patch classifier to scan the whole mammogram and create the "single-view whole-image classifier". We propose to make a third transfer learning to obtain a "two-view classifier" to use the two mammographic views: **bilateral** craniocaudal and mediolateral oblique. We use EfficientNet as the basis of our model. We "end-to-end" train the entire system using CBIS-DDSM dataset. To ensure statistical robustness, we test our system twice using: (a) 5-fold cross validation; and (b) the original training/test division of the dataset. Our technique reached an AUC of 0.9344 using 5-fold cross validation (accuracy, sensitivity and specificity are 85.13% at the equal error rate point of ROC). Using the original dataset division, our technique achieved an AUC of 0.8483, as far as we know the highest reported AUC for this problem, although the subtle differences in the testing conditions of each work do not allow for an accurate comparison. The inference code and model are available at https://github.com/dpetrini/two-views-classifier  
### RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v2 [eess.IV] UPDATED)
- Authors : Zhuo Deng, Yuanhao Cai, Lu Chen, Zheng Gong, Qiqi Bao, Xue Yao, Dong Fang, Shaochong Zhang, Lan Ma
- Link : [http://arxiv.org/abs/2201.00466](http://arxiv.org/abs/2201.00466)
> ABSTRACT  :  Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image **restoration** is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image **restoration** problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications. The dataset, code, and models are publicly available at https://github.com/dengzhuo-AI/Real-Fundus  
### You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image **Enhancement** and **Exposure** Correction. (arXiv:2205.14871v3 [cs.CV] UPDATED)
- Authors : Ziteng Cui, Kunchang Li, Lin Gu, Shenghan Su, Peng Gao, Zhengkai Jiang, Yu Qiao, Tatsuya Harada
- Link : [http://arxiv.org/abs/2205.14871](http://arxiv.org/abs/2205.14871)
> ABSTRACT  :  Challenging illumination conditions (**low-light**, under-**exposure** and over-**exposure**) in the real world not only cast an unpleasant visual appearance but also taint the computer vision tasks. After camera captures the raw-RGB data, it renders standard sRGB images with image signal processor (ISP). By decomposing ISP pipeline into local and global image components, we propose a lightweight fast Illumination Adaptive Transformer (IAT) to restore the normal lit sRGB image from either **low-light** or under/over-**exposure** conditions. Specifically, IAT uses attention queries to represent and adjust the ISP-related parameters such as colour correction, gamma correction. With only ~90k parameters and ~0.004s processing speed, our IAT consistently achieves superior performance over SOTA on the current benchmark **low-light** **enhancement** and **exposure** correction datasets. Competitive experimental performance also demonstrates that our IAT significantly enhances object detection and semantic segmentation tasks under various light conditions. Training code and pretrained model is available at https://github.com/cuiziteng/Illumination-Adaptive-Transformer.  
### BATMAN: **Bilateral** Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation. (arXiv:2208.01159v2 [cs.CV] UPDATED)
- Authors : Ye Yu, Jialin Yuan, Gaurav Mittal, Li Fuxin, Mei Chen
- Link : [http://arxiv.org/abs/2208.01159](http://arxiv.org/abs/2208.01159)
> ABSTRACT  :  Video Object Segmentation (VOS) is fundamental to video understanding. Transformer-based methods show significant performance improvement on semi-supervised VOS. However, existing work faces challenges segmenting visually similar objects in close proximity of each other. In this paper, we propose a novel **Bilateral** Attention Transformer in Motion-Appearance Neighboring space (BATMAN) for semi-supervised VOS. It captures object motion in the video via a novel optical flow calibration module that fuses the segmentation mask with optical flow estimation to improve within-object optical flow smoothness and reduce noise at object boundaries. This calibrated optical flow is then employed in our novel **bilateral** attention, which computes the correspondence between the query and reference frames in the neighboring **bilateral** space considering both motion and appearance. Extensive experiments validate the effectiveness of BATMAN architecture by outperforming all existing state-of-the-art on all four popular VOS benchmarks: Youtube-VOS 2019 (85.0%), Youtube-VOS 2018 (85.3%), DAVIS 2017Val/Testdev (86.2%/82.2%), and DAVIS 2016 (92.5%).  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
## eess.IV
---
### Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v3 [eess.IV] UPDATED)
- Authors : Carlos Shimizu, Hae Yong
- Link : [http://arxiv.org/abs/2110.01606](http://arxiv.org/abs/2110.01606)
> ABSTRACT  :  Some recent studies have described deep convolutional neural networks to diagnose breast cancer in mammograms with similar or even superior performance to that of human experts. One of the best techniques does two transfer learnings: the first uses a model trained on natural images to create a "patch classifier" that categorizes small subimages; the second uses the patch classifier to scan the whole mammogram and create the "single-view whole-image classifier". We propose to make a third transfer learning to obtain a "two-view classifier" to use the two mammographic views: **bilateral** craniocaudal and mediolateral oblique. We use EfficientNet as the basis of our model. We "end-to-end" train the entire system using CBIS-DDSM dataset. To ensure statistical robustness, we test our system twice using: (a) 5-fold cross validation; and (b) the original training/test division of the dataset. Our technique reached an AUC of 0.9344 using 5-fold cross validation (accuracy, sensitivity and specificity are 85.13% at the equal error rate point of ROC). Using the original dataset division, our technique achieved an AUC of 0.8483, as far as we know the highest reported AUC for this problem, although the subtle differences in the testing conditions of each work do not allow for an accurate comparison. The inference code and model are available at https://github.com/dpetrini/two-views-classifier  
### RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v2 [eess.IV] UPDATED)
- Authors : Zhuo Deng, Yuanhao Cai, Lu Chen, Zheng Gong, Qiqi Bao, Xue Yao, Dong Fang, Shaochong Zhang, Lan Ma
- Link : [http://arxiv.org/abs/2201.00466](http://arxiv.org/abs/2201.00466)
> ABSTRACT  :  Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image **restoration** is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image **restoration** problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications. The dataset, code, and models are publicly available at https://github.com/dengzhuo-AI/Real-Fundus  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
## cs.LG
---
### A New Implementation of Federated Learning for Privacy and Security **Enhancement**. (arXiv:2208.01826v1 [cs.CR])
- Authors : Xiang Ma, Haijian Sun, Rose Qingyang, Yi Qian
- Link : [http://arxiv.org/abs/2208.01826](http://arxiv.org/abs/2208.01826)
> ABSTRACT  :  Motivated by the ever-increasing concerns on personal data privacy and the rapidly growing data volume at local clients, federated learning (FL) has emerged as a new machine learning setting. An FL system is comprised of a central parameter server and multiple local clients. It keeps data at local clients and learns a centralized model by sharing the model parameters learned locally. No local data needs to be shared, and privacy can be well protected. Nevertheless, since it is the model instead of the raw data that is shared, the system can be exposed to the poisoning model attacks launched by malicious clients. Furthermore, it is challenging to identify malicious clients since no local client data is available on the server. Besides, membership inference attacks can still be performed by using the uploaded model to estimate the client's local data, leading to privacy disclosure. In this work, we first propose a model update based federated averaging algorithm to defend against Byzantine attacks such as additive noise attacks and sign-flipping attacks. The individual client model initialization method is presented to provide further privacy protections from the membership inference attacks by hiding the individual local machine learning model. When combining these two schemes, privacy and security can be both effectively enhanced. The proposed schemes are proved to converge experimentally under non-IID data distribution when there are no attacks. Under Byzantine attacks, the proposed schemes perform much better than the classical model based FedAvg algorithm.  
### RemixIT: Continual self-training of speech **enhancement** models via bootstrapped remixing. (arXiv:2202.08862v3 [cs.SD] UPDATED)
- Authors : Efthymios Tzinis, Yossi Adi, Vamsi Krishna, Buye Xu, Paris Smaragdis, Anurag Kumar
- Link : [http://arxiv.org/abs/2202.08862](http://arxiv.org/abs/2202.08862)
> ABSTRACT  :  We present RemixIT, a simple yet effective self-supervised method for training speech **enhancement** without the need of a single isolated in-domain speech nor a noise waveform. Our approach overcomes limitations of previous methods which make them dependent on clean in-domain target signals and thus, sensitive to any domain mismatch between train and test samples. RemixIT is based on a continuous self-training scheme in which a pre-trained teacher model on out-of-domain data infers estimated pseudo-target signals for in-domain mixtures. Then, by permuting the estimated clean and noise signals and remixing them together, we generate a new set of bootstrapped mixtures and corresponding pseudo-targets which are used to train the student network. Vice-versa, the teacher periodically refines its estimates using the updated parameters of the latest student models. Experimental results on multiple speech **enhancement** datasets and tasks not only show the superiority of our method over prior approaches but also showcase that RemixIT can be combined with any separation model as well as be applied towards any semi-supervised and unsupervised domain adaptation task. Our analysis, paired with empirical evidence, sheds light on the inside functioning of our self-training scheme wherein the student model keeps obtaining better performance while observing severely degraded pseudo-targets.  
### High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization. (arXiv:2206.08487v2 [cs.RO] UPDATED)
- Authors : Pranav Atreya, Haresh Karnan, Kavan Singh, Xuesu Xiao, Sadegh Rabiee, Joydeep Biswas
- Link : [http://arxiv.org/abs/2206.08487](http://arxiv.org/abs/2206.08487)
> ABSTRACT  :  Accurate control of robots at high speeds requires a control system that can take into account the kinodynamic interactions of the robot with the environment. Prior works on learning inverse kinodynamic (IKD) models of robots have shown success in capturing the complex kinodynamic effects. However, the types of control problems these approaches can be applied to are limited only to that of following pre-computed kinodynamically feasible trajectories. In this paper we present Optim-FKD, a new formulation for accurate, high-speed robot control that makes use of a learned forward kinodynamic (FKD) model and non-linear least squares optimization. Optim-FKD can be used for accurate, high speed control on any control task specifiable by a non-linear least squares objective. Optim-FKD can solve for control objectives such as path following and time-optimal control in **real time**, without needing access to pre-computed kinodynamically feasible trajectories. We empirically demonstrate these abilities of our approach through experiments on a scale one-tenth autonomous car. Our results show that Optim-FKD can follow desired trajectories more accurately and can find better solutions to optimal control problems than baseline approaches.  
### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
- Authors : Matteo Mancini, Marco Palombo
- Link : [http://arxiv.org/abs/2208.01602](http://arxiv.org/abs/2208.01602)
> ABSTRACT  :  In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for **implicit neural representation** of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.  
## cs.AI
---
### High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization. (arXiv:2206.08487v2 [cs.RO] UPDATED)
- Authors : Pranav Atreya, Haresh Karnan, Kavan Singh, Xuesu Xiao, Sadegh Rabiee, Joydeep Biswas
- Link : [http://arxiv.org/abs/2206.08487](http://arxiv.org/abs/2206.08487)
> ABSTRACT  :  Accurate control of robots at high speeds requires a control system that can take into account the kinodynamic interactions of the robot with the environment. Prior works on learning inverse kinodynamic (IKD) models of robots have shown success in capturing the complex kinodynamic effects. However, the types of control problems these approaches can be applied to are limited only to that of following pre-computed kinodynamically feasible trajectories. In this paper we present Optim-FKD, a new formulation for accurate, high-speed robot control that makes use of a learned forward kinodynamic (FKD) model and non-linear least squares optimization. Optim-FKD can be used for accurate, high speed control on any control task specifiable by a non-linear least squares objective. Optim-FKD can solve for control objectives such as path following and time-optimal control in **real time**, without needing access to pre-computed kinodynamically feasible trajectories. We empirically demonstrate these abilities of our approach through experiments on a scale one-tenth autonomous car. Our results show that Optim-FKD can follow desired trajectories more accurately and can find better solutions to optimal control problems than baseline approaches.  
# Paper List
---
## cs.CV
---
**107** new papers in cs.CV:-) 
1. A Roadmap for Greater Public Use of Privacy-Sensitive Government Data: Workshop Report. (arXiv:2208.01636v1 [cs.CR])
2. Comparative Analysis of State-of-the-Art Deep Learning Models for Detecting COVID-19 Lung Infection from Chest X-Ray Images. (arXiv:2208.01637v1 [eess.IV])
3. The Importance of the Instantaneous Phase in Detecting Faces with Convolutional Neural Networks. (arXiv:2208.01638v1 [cs.CV])
4. Streaming-capable High-performance Architecture of Learned Image Compression Codecs. (arXiv:2208.01641v1 [eess.IV])
5. CTooth+: A Large-scale Dental Cone Beam Computed Tomography Dataset and Benchmark for Tooth Volume Segmentation. (arXiv:2208.01643v1 [eess.IV])
6. Maximal Independent Vertex Set applied to Graph Pooling. (arXiv:2208.01648v1 [cs.LG])
7. Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning. (arXiv:2208.01674v1 [eess.IV])
8. Non-Line-of-Sight Tracking and Mapping with an Active Corner Camera. (arXiv:2208.01702v1 [eess.IV])
9. Autonomous Agriculture Robot for Smart Farming. (arXiv:2208.01708v1 [cs.RO])
10. Cross-Modal Alignment Learning of Vision-Language Conceptual Systems. (arXiv:2208.01744v1 [cs.CV])
11. A Fast Text-Driven Approach for Generating Artistic Content. (arXiv:2208.01748v1 [cs.CV])
12. Two-Stream Transformer Architecture for Long Video Understanding. (arXiv:2208.01753v1 [cs.CV])
13. Robust RGB-D Fusion for Saliency Detection. (arXiv:2208.01762v1 [cs.CV])
14. Mates2Motion: Learning How Mechanical CAD Assemblies Work. (arXiv:2208.01779v1 [cs.CV])
15. A comprehensive survey on computer-aided diagnostic systems in diabetic retinopathy screening. (arXiv:2208.01810v1 [eess.IV])
16. TAG: Boosting Text-VQA via Text-aware Visual Question-answer Generation. (arXiv:2208.01813v1 [cs.CV])
17. Neural Contourlet Network for Monocular 360 Depth Estimation. (arXiv:2208.01817v1 [cs.CV])
18. Statistical Attention Localization (SAL): Methodology and Application to Object Classification. (arXiv:2208.01823v1 [cs.CV])
19. Medical image registration using unsupervised deep neural network: A scoping literature review. (arXiv:2208.01825v1 [eess.IV])
20. Fast Hierarchical Deep Unfolding Network for Image Compressed Sensing. (arXiv:2208.01827v1 [cs.CV])
21. Integrating Object-aware and Interaction-aware Knowledge for Weakly Supervised Scene Graph Generation. (arXiv:2208.01834v1 [cs.CV])
22. EMC2A-Net: An Efficient Multibranch Cross-channel Attention Network for SAR Target Classification. (arXiv:2208.01836v1 [cs.CV])
23. Learning Prior Feature and Attention Enhanced Image Inpainting. (arXiv:2208.01837v1 [cs.CV])
24. Re-Attention Transformer for Weakly Supervised Object Localization. (arXiv:2208.01838v1 [cs.CV])
25. 'Labelling the Gaps': A Weakly Supervised Automatic Eye Gaze Estimation. (arXiv:2208.01840v1 [cs.CV])
26. Multi-Feature Vision Transformer via Self-Supervised Representation Learning for Improvement of COVID-19 Diagnosis. (arXiv:2208.01843v1 [eess.IV])
27. Multiclass ASMA vs Targeted PGD Attack in Image Segmentation. (arXiv:2208.01844v1 [cs.CV])
28. Pyramidal Denoising Diffusion Probabilistic Models. (arXiv:2208.01864v1 [cs.CV])
29. Leveraging Smartphone Sensors for Detecting Abnormal Gait for Smart Wearable Mobile Technologies. (arXiv:2208.01876v1 [cs.HC])
30. Graph Signal Processing for Heterogeneous Change Detection Part I: Vertex Domain Filtering. (arXiv:2208.01881v1 [cs.CV])
31. Combined CNN Transformer Encoder for Enhanced Fine-grained Human Action Recognition. (arXiv:2208.01897v1 [cs.CV])
32. XCon: Learning with Experts for Fine-grained Category Discovery. (arXiv:2208.01898v1 [cs.CV])
33. Graph Signal Processing for Heterogeneous Change Detection Part II: Spectral Domain Analysis. (arXiv:2208.01905v1 [cs.CV])
34. Rethinking the Evaluation of Unbiased Scene Graph Generation. (arXiv:2208.01909v1 [cs.CV])
35. Multimodal Generation of Novel Action Appearances for Synthetic-to-Real Recognition of Activities of Daily Living. (arXiv:2208.01910v1 [cs.CV])
36. N-RPN: Hard Example Learning for Region Proposal Networks. (arXiv:2208.01916v1 [cs.CV])
37. Per-Clip Video Object Segmentation. (arXiv:2208.01924v1 [cs.CV])
38. SuperLine3D: Self-supervised Line Segmentation and Description for LiDAR Point Cloud. (arXiv:2208.01925v1 [cs.CV])
39. PalQuant: Accelerating High-precision Networks on Low-precision Accelerators. (arXiv:2208.01944v1 [cs.CV])
40. Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoisin. (arXiv:2208.01948v1 [cs.CV])
41. Negative Frames Matter in Egocentric Visual Query 2D Localization. (arXiv:2208.01949v1 [cs.CV])
42. Dilated Context Integrated Network with Cross-Modal Consensus for Temporal Emotion Localization in Videos. (arXiv:2208.01954v1 [cs.CV])
43. Augmentation Learning for Semi-Supervised Classification. (arXiv:2208.01956v1 [cs.CV])
44. PolarMOT: How Far Can Geometric Relations Take Us in 3D Multi-Object Tracking?. (arXiv:2208.01957v1 [cs.CV])
45. Learning Object Manipulation Skills from Video via Approximate Differentiable Physics. (arXiv:2208.01960v1 [cs.RO])
46. Localization and Classification of Parasitic Eggs in Microscopic Images Using an EfficientDet Detector. (arXiv:2208.01963v1 [cs.CV])
47. Adaptive Domain Generalization via Online Disagreement Minimization. (arXiv:2208.01996v1 [cs.CV])
48. Convolutional Fine-Grained Classification with Self-Supervised Target Relation Regularization. (arXiv:2208.01997v1 [cs.CV])
49. Gradient-based Uncertainty for Monocular Depth Estimation. (arXiv:2208.02005v1 [cs.CV])
50. Maintaining Performance with Less Data. (arXiv:2208.02007v1 [cs.LG])
51. Vision-Based Safety System for Barrierless Human-Robot Collaboration. (arXiv:2208.02010v1 [cs.RO])
52. Character Generation through Self-Supervised Vectorization. (arXiv:2208.02012v1 [cs.CV])
53. YOLO-FaceV2: A Scale and Occlusion Aware Face Detector. (arXiv:2208.02019v1 [cs.CV])
54. SSformer: A Lightweight Transformer for Semantic Segmentation. (arXiv:2208.02034v1 [cs.CV])
55. Template matching with white balance adjustment under multiple illuminants. (arXiv:2208.02035v1 [cs.CV])
56. Texture features in medical image analysis: a survey. (arXiv:2208.02046v1 [eess.IV])
57. AutoLaparo: A New Dataset of Integrated Multi-tasks for Image-guided Surgical Automation in Laparoscopic Hysterectomy. (arXiv:2208.02049v1 [cs.CV])
58. AstroVision: Towards Autonomous Feature Detection and Description for Missions to Small Bodies Using Deep Learning. (arXiv:2208.02053v1 [astro-ph.IM])
59. Evaluation and comparison of eight popular Lidar and Visual SLAM algorithms. (arXiv:2208.02063v1 [cs.RO])
60. A Feature-space Multimodal Data Augmentation Technique for Text-video Retrieval. (arXiv:2208.02080v1 [cs.CV])
61. Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models. (arXiv:2208.02089v1 [cs.CV])
62. Edge-Based Self-Supervision for Semi-Supervised Few-Shot Microscopy Image Cell Segmentation. (arXiv:2208.02105v1 [cs.CV])
63. Pedestrian-Robot Interactions on Autonomous Crowd Navigation: Reactive Control Methods and Evaluation Metrics. (arXiv:2208.02121v1 [cs.RO])
64. LSSANet: A Long Short Slice-Aware Network for Pulmonary Nodule Detection. (arXiv:2208.02122v1 [eess.IV])
65. SC6D: Symmetry-agnostic and Correspondence-free 6D Object Pose Estimation. (arXiv:2208.02129v1 [cs.CV])
66. Masked Vision and Language Modeling for Multi-modal Representation Learning. (arXiv:2208.02131v1 [cs.CV])
67. Subject-Specific Lesion Generation and Pseudo-Healthy Synthesis for Multiple Sclerosis Brain Images. (arXiv:2208.02135v1 [eess.IV])
68. GPPF: A General Perception Pre-training Framework via Sparsely Activated Multi-Task Learning. (arXiv:2208.02148v1 [cs.CV])
69. CCTV-**Exposure**: An open-source system for measuring user's privacy **exposure** to mapped CCTV cameras based on geo-location (Extended Version). (arXiv:2208.02159v1 [cs.CR])
70. KD-SCFNet: Towards More Accurate and Efficient Salient Object Detection via Knowledge Distillation. (arXiv:2208.02178v1 [cs.CV])
71. RealPatch: A Statistical Matching Framework for Model Patching with Real Samples. (arXiv:2208.02192v1 [cs.CV])
72. DAHiTrA: Damage Assessment Using a Novel Hierarchical Transformer Architecture. (arXiv:2208.02205v1 [cs.CV])
73. Free-HeadGAN: Neural Talking Head Synthesis with Explicit Gaze Control. (arXiv:2208.02210v1 [cs.CV])
74. MinVIS: A Minimal Video Instance Segmentation Framework without Video-based Training. (arXiv:2208.02245v1 [cs.CV])
75. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v7 [cs.LG] UPDATED)
76. Stochastic Neighbor Embedding with Gaussian and Student-t Distributions: Tutorial and Survey. (arXiv:2009.10301v2 [stat.ML] UPDATED)
77. Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in Object Detection. (arXiv:2012.00257v3 [cs.CV] UPDATED)
78. Deep Decomposition Network for Image Processing: A Case Study for Visible and Infrared Image Fusion. (arXiv:2102.10526v2 [cs.CV] UPDATED)
79. PeCLR: Self-Supervised 3D Hand Pose Estimation from monocular RGB via Equivariant Contrastive Learning. (arXiv:2106.05953v5 [cs.CV] UPDATED)
80. Bridging the Gap Between Object Detection and User Intent via Query-Modulation. (arXiv:2106.10258v2 [cs.CV] UPDATED)
81. Unified Framework for Spectral Dimensionality Reduction, Maximum Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial and Survey. (arXiv:2106.15379v2 [stat.ML] UPDATED)
82. PPT Fusion: Pyramid Patch Transformerfor a Case Study in Image Fusion. (arXiv:2107.13967v3 [cs.CV] UPDATED)
83. Unsupervised Cross-Modality Domain Adaptation for Segmenting Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble. (arXiv:2109.12169v2 [eess.IV] UPDATED)
84. Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v3 [eess.IV] UPDATED)
85. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v3 [cs.RO] UPDATED)
86. Generalized Out-of-Distribution Detection: A Survey. (arXiv:2110.11334v2 [cs.CV] UPDATED)
87. Information Prebuilt Recurrent Reconstruction Network for Video Super-Resolution. (arXiv:2112.05755v2 [eess.IV] UPDATED)
88. RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v2 [eess.IV] UPDATED)
89. Robust Training under Label Noise by Over-parameterization. (arXiv:2202.14026v2 [cs.LG] UPDATED)
90. Patch Similarity Aware Data-Free Quantization for Vision Transformers. (arXiv:2203.02250v2 [cs.CV] UPDATED)
91. Temporal Context for Robust Maritime Obstacle Detection. (arXiv:2203.05352v2 [cs.CV] UPDATED)
92. Improving Transferability for Domain Adaptive Detection Transformers. (arXiv:2204.14195v3 [cs.CV] UPDATED)
93. Siamese Object Tracking for Unmanned Aerial Vehicle: A Review and Comprehensive Analysis. (arXiv:2205.04281v2 [cs.CV] UPDATED)
94. Naive Few-Shot Learning: Sequence Consistency Evaluation. (arXiv:2205.12013v2 [cs.AI] UPDATED)
95. You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image **Enhancement** and **Exposure** Correction. (arXiv:2205.14871v3 [cs.CV] UPDATED)
96. Action Spotting using Dense Detection Anchors Revisited: Submission to the SoccerNet Challenge 2022. (arXiv:2206.07846v2 [cs.CV] UPDATED)
97. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v4 [cs.LG] UPDATED)
98. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v2 [cs.LG] UPDATED)
99. MMFN: Multi-Modal-Fusion-Net for End-to-End Driving. (arXiv:2207.00186v2 [cs.CV] UPDATED)
100. Egocentric Video-Language Pretraining @ EPIC-KITCHENS-100 Multi-Instance Retrieval Challenge 2022. (arXiv:2207.01334v2 [cs.CV] UPDATED)
101. Egocentric Video-Language Pretraining @ Ego4D Challenge 2022. (arXiv:2207.01622v2 [cs.CV] UPDATED)
102. Dual Decision Improves Open-Set Panoptic Segmentation. (arXiv:2207.02504v3 [cs.CV] UPDATED)
103. Hierarchically Self-Supervised Transformer for Human Skeleton Representation Learning. (arXiv:2207.09644v2 [cs.CV] UPDATED)
104. Task-adaptive Spatial-Temporal Video Sampler for Few-shot Action Recognition. (arXiv:2207.09759v2 [cs.CV] UPDATED)
105. SYNTA: A novel approach for deep learning-based image analysis in muscle histopathology using photo-realistic synthetic data. (arXiv:2207.14650v2 [eess.IV] UPDATED)
106. BATMAN: **Bilateral** Attention Transformer in Motion-Appearance Neighboring Space for Video Object Segmentation. (arXiv:2208.01159v2 [cs.CV] UPDATED)
107. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
## eess.IV
---
**25** new papers in eess.IV:-) 
1. Comparative Analysis of State-of-the-Art Deep Learning Models for Detecting COVID-19 Lung Infection from Chest X-Ray Images. (arXiv:2208.01637v1 [eess.IV])
2. The Importance of the Instantaneous Phase in Detecting Faces with Convolutional Neural Networks. (arXiv:2208.01638v1 [cs.CV])
3. Streaming-capable High-performance Architecture of Learned Image Compression Codecs. (arXiv:2208.01641v1 [eess.IV])
4. CTooth+: A Large-scale Dental Cone Beam Computed Tomography Dataset and Benchmark for Tooth Volume Segmentation. (arXiv:2208.01643v1 [eess.IV])
5. Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning. (arXiv:2208.01674v1 [eess.IV])
6. Non-Line-of-Sight Tracking and Mapping with an Active Corner Camera. (arXiv:2208.01702v1 [eess.IV])
7. A comprehensive survey on computer-aided diagnostic systems in diabetic retinopathy screening. (arXiv:2208.01810v1 [eess.IV])
8. Medical image registration using unsupervised deep neural network: A scoping literature review. (arXiv:2208.01825v1 [eess.IV])
9. Fast Hierarchical Deep Unfolding Network for Image Compressed Sensing. (arXiv:2208.01827v1 [cs.CV])
10. Multi-Feature Vision Transformer via Self-Supervised Representation Learning for Improvement of COVID-19 Diagnosis. (arXiv:2208.01843v1 [eess.IV])
11. Graph Signal Processing for Heterogeneous Change Detection Part I: Vertex Domain Filtering. (arXiv:2208.01881v1 [cs.CV])
12. Decay2Distill: Leveraging spatial perturbation and regularization for self-supervised image denoisin. (arXiv:2208.01948v1 [cs.CV])
13. Texture features in medical image analysis: a survey. (arXiv:2208.02046v1 [eess.IV])
14. Audio-visual scene classification via contrastive event-object alignment and semantic-based fusion. (arXiv:2208.02086v1 [cs.SD])
15. Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models. (arXiv:2208.02089v1 [cs.CV])
16. LSSANet: A Long Short Slice-Aware Network for Pulmonary Nodule Detection. (arXiv:2208.02122v1 [eess.IV])
17. Subject-Specific Lesion Generation and Pseudo-Healthy Synthesis for Multiple Sclerosis Brain Images. (arXiv:2208.02135v1 [eess.IV])
18. Deep Decomposition Network for Image Processing: A Case Study for Visible and Infrared Image Fusion. (arXiv:2102.10526v2 [cs.CV] UPDATED)
19. Unsupervised Cross-Modality Domain Adaptation for Segmenting Vestibular Schwannoma and Cochlea with Data Augmentation and Model Ensemble. (arXiv:2109.12169v2 [eess.IV] UPDATED)
20. Breast Cancer Diagnosis in Two-View Mammography Using End-to-End Trained EfficientNet-Based Convolutional Network. (arXiv:2110.01606v3 [eess.IV] UPDATED)
21. Information Prebuilt Recurrent Reconstruction Network for Video Super-Resolution. (arXiv:2112.05755v2 [eess.IV] UPDATED)
22. RFormer: Transformer-based Generative Adversarial Network for Real Fundus Image **Restoration** on A New Clinical Benchmark. (arXiv:2201.00466v2 [eess.IV] UPDATED)
23. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v3 [eess.IV] UPDATED)
24. SYNTA: A novel approach for deep learning-based image analysis in muscle histopathology using photo-realistic synthetic data. (arXiv:2207.14650v2 [eess.IV] UPDATED)
25. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
## cs.LG
---
**150** new papers in cs.LG:-) 
1. A Roadmap for Greater Public Use of Privacy-Sensitive Government Data: Workshop Report. (arXiv:2208.01636v1 [cs.CR])
2. AI-driven Hypernetwork of Organic Chemistry: Network Statistics and Applications in Reaction Classification. (arXiv:2208.01647v1 [q-bio.MN])
3. Maximal Independent Vertex Set applied to Graph Pooling. (arXiv:2208.01648v1 [cs.LG])
4. Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning. (arXiv:2208.01674v1 [eess.IV])
5. Curvature-informed multi-task learning for graph networks. (arXiv:2208.01684v1 [cs.LG])
6. Neural Basis Functions for Accelerating Solutions to High Mach Euler Equations. (arXiv:2208.01687v1 [cs.LG])
7. A cloud platform for automating and sharing analysis of raw simulation data from high throughput polymer molecular dynamics simulations. (arXiv:2208.01692v1 [cond-mat.mtrl-sci])
8. Differentially Private Vertical Federated Clustering. (arXiv:2208.01700v1 [cs.CR])
9. Binary Classification with Positive Labeling Sources. (arXiv:2208.01704v1 [cs.LG])
10. Success of Uncertainty-Aware Deep Models Depends on Data Manifold Geometry. (arXiv:2208.01705v1 [cs.LG])
11. Adapting Triplet Importance of Implicit Feedback for Personalized Recommendation. (arXiv:2208.01709v1 [cs.IR])
12. Optimal Rates for Regularized Conditional Mean Embedding Learning. (arXiv:2208.01711v1 [stat.ML])
13. No Pattern, No Recognition: a Survey about Reproducibility and Distortion Issues of Text Clustering and Topic Modeling. (arXiv:2208.01712v1 [cs.LG])
14. A Tighter Analysis of Spectral Clustering, and Beyond. (arXiv:2208.01724v1 [cs.DS])
15. V-Coder: Adaptive AutoEncoder for Semantic Disclosure in Knowledge Graphs. (arXiv:2208.01735v1 [cs.AI])
16. Reconstructing Sparse Illicit Supply Networks: A Case Study of Multiplex Drug Trafficking Networks. (arXiv:2208.01739v1 [cs.SI])
17. Cross-Modal Alignment Learning of Vision-Language Conceptual Systems. (arXiv:2208.01744v1 [cs.CV])
18. Analysis of the Spatio-temporal Dynamics of COVID-19 in Massachusetts via Spectral Graph Wavelet Theory. (arXiv:2208.01749v1 [cs.SI])
19. Two-Stream Transformer Architecture for Long Video Understanding. (arXiv:2208.01753v1 [cs.CV])
20. Deep Reinforcement Learning for Multi-Agent Interaction. (arXiv:2208.01769v1 [cs.MA])
21. Digital Twin-Assisted Efficient Reinforcement Learning for Edge Task Scheduling. (arXiv:2208.01781v1 [cs.LG])
22. Post-hoc Interpretability based Parameter Selection for Data Oriented Nuclear Reactor Accident Diagnosis System. (arXiv:2208.01805v1 [eess.SY])
23. Adversarial Camouflage for Node Injection Attack on Graphs. (arXiv:2208.01819v1 [cs.LG])
24. Link Prediction on Heterophilic Graphs via Disentangled Representation Learning. (arXiv:2208.01820v1 [cs.LG])
25. A Lightweight Transmission Parameter Selection Scheme Using Reinforcement Learning for LoRaWAN. (arXiv:2208.01824v1 [cs.LG])
26. A New Implementation of Federated Learning for Privacy and Security **Enhancement**. (arXiv:2208.01826v1 [cs.CR])
27. Robust Learning of Deep Time Series Anomaly Detection Models with Contaminated Training Data. (arXiv:2208.01841v1 [cs.LG])
28. Multi-Feature Vision Transformer via Self-Supervised Representation Learning for Improvement of COVID-19 Diagnosis. (arXiv:2208.01843v1 [eess.IV])
29. Robust Graph Neural Networks using Weighted Graph Laplacian. (arXiv:2208.01853v1 [cs.LG])
30. The Power and Limitation of Pretraining-Finetuning for Linear Regression under Covariate Shift. (arXiv:2208.01857v1 [cs.LG])
31. Pyramidal Denoising Diffusion Probabilistic Models. (arXiv:2208.01864v1 [cs.CV])
32. A Deep Learning Approach to Detect Lean Blowout in Combustion Systems. (arXiv:2208.01871v1 [cs.LG])
33. Exploring Generative Neural Temporal Point Process. (arXiv:2208.01874v1 [cs.LG])
34. Leveraging Smartphone Sensors for Detecting Abnormal Gait for Smart Wearable Mobile Technologies. (arXiv:2208.01876v1 [cs.HC])
35. Flow Annealed Importance Sampling Bootstrap. (arXiv:2208.01893v1 [cs.LG])
36. Understanding Adversarial Imitation Learning in Small Sample Regime: A Stage-coupled Analysis. (arXiv:2208.01899v1 [cs.LG])
37. Asynchronous Federated Learning for Edge-assisted Vehicular Networks. (arXiv:2208.01901v1 [cs.LG])
38. EgPDE-Net: Building Continuous Neural Networks for Time Series Prediction with Exogenous Variables. (arXiv:2208.01913v1 [cs.LG])
39. Zero-Shot Style Transfer for Gesture Animation driven by Text and Speech using Adversarial Disentanglement of Multimodal Style Encoding. (arXiv:2208.01917v1 [cs.SD])
40. DeepProphet2 -- A Deep Learning Gene Recommendation Engine. (arXiv:2208.01918v1 [q-bio.QM])
41. Graph Regularized Nonnegative Latent Factor Analysis Model for Temporal Link Prediction in Cryptocurrency Transaction Networks. (arXiv:2208.01923v1 [cs.LG])
42. Exploration with Model Uncertainty at Extreme Scale in Real-Time Bidding. (arXiv:2208.01951v1 [cs.LG])
43. PolarMOT: How Far Can Geometric Relations Take Us in 3D Multi-Object Tracking?. (arXiv:2208.01957v1 [cs.CV])
44. Learning Object Manipulation Skills from Video via Approximate Differentiable Physics. (arXiv:2208.01960v1 [cs.RO])
45. Localization and Classification of Parasitic Eggs in Microscopic Images Using an EfficientDet Detector. (arXiv:2208.01963v1 [cs.CV])
46. Adaptive Domain Generalization via Online Disagreement Minimization. (arXiv:2208.01996v1 [cs.CV])
47. Robust PCA for Anomaly Detection and Data Imputation in Seasonal Time Series. (arXiv:2208.01998v1 [stat.ML])
48. Maintaining Performance with Less Data. (arXiv:2208.02007v1 [cs.LG])
49. Vision-Based Safety System for Barrierless Human-Robot Collaboration. (arXiv:2208.02010v1 [cs.RO])
50. Equivariant Disentangled Transformation for Domain Generalization under Combination Shift. (arXiv:2208.02011v1 [cs.LG])
51. Character Generation through Self-Supervised Vectorization. (arXiv:2208.02012v1 [cs.CV])
52. Neural Nets with a Newton Conjugate Gradient Method on Multiple GPUs. (arXiv:2208.02017v1 [cs.LG])
53. OLLIE: Derivation-based Tensor Program Optimizer. (arXiv:2208.02025v1 [cs.LG])
54. BPMN4sML: A BPMN Extension for Serverless Machine Learning. Technology Independent and Interoperable Modeling of Machine Learning Workflows and their Serverless Deployment Orchestration. (arXiv:2208.02030v1 [cs.SE])
55. Cross-lingual Approaches for the Detection of Adverse Drug Reactions in German from a Patient's Perspective. (arXiv:2208.02031v1 [cs.CL])
56. Centroids Matching: an efficient Continual Learning approach operating in the embedding space. (arXiv:2208.02048v1 [cs.LG])
57. Robots with Different Embodiments Can Express and Influence Carefulness in Object Manipulation. (arXiv:2208.02058v1 [cs.RO])
58. HybridGNN: Learning Hybrid Representation in Multiplex Heterogeneous Networks. (arXiv:2208.02068v1 [cs.LG])
59. Efficient Fine-Tuning of Compressed Language Models with Learners. (arXiv:2208.02070v1 [cs.CL])
60. Gradient descent provably escapes saddle points in the training of shallow ReLU networks. (arXiv:2208.02083v1 [cs.LG])
61. Unsupervised Discovery of Semantic Concepts in Satellite Imagery with Style-based Wavelet-driven Generative Models. (arXiv:2208.02089v1 [cs.CV])
62. A Novel Approach To Network Intrusion Detection System Using Deep Learning For Sdn: Futuristic Approach. (arXiv:2208.02094v1 [cs.CR])
63. Edge-Based Self-Supervision for Semi-Supervised Few-Shot Microscopy Image Cell Segmentation. (arXiv:2208.02105v1 [cs.CV])
64. A Convolutional Persistence Transform. (arXiv:2208.02107v1 [math.AT])
65. MTGFlow: Unsupervised Multivariate Time Series Anomaly Detection via Dynamic Graph and Entity-aware Normalizing Flow. (arXiv:2208.02108v1 [cs.LG])
66. Noise tolerance of learning to rank under class-conditional label noise. (arXiv:2208.02126v1 [cs.IR])
67. Masked Vision and Language Modeling for Multi-modal Representation Learning. (arXiv:2208.02131v1 [cs.CV])
68. Subject-Specific Lesion Generation and Pseudo-Healthy Synthesis for Multiple Sclerosis Brain Images. (arXiv:2208.02135v1 [eess.IV])
69. KPI-BERT: A Joint Named Entity Recognition and Relation Extraction Model for Financial Reports. (arXiv:2208.02140v1 [cs.CL])
70. Empirical Study of Overfitting in Deep FNN Prediction Models for Breast Cancer Metastasis. (arXiv:2208.02150v1 [cs.LG])
71. A Screening Strategy for Structured Optimization Involving Nonconvex $\ell_{q,p}$ Regularization. (arXiv:2208.02161v1 [cs.LG])
72. One Node at a Time: Node-Level Network Classification. (arXiv:2208.02162v1 [cs.SI])
73. SpanDrop: Simple and Effective Counterfactual Learning for Long Sequences. (arXiv:2208.02169v1 [cs.LG])
74. Conv-NILM-Net, a causal and multi-appliance model for energy source separation. (arXiv:2208.02173v1 [eess.SP])
75. Machine learning optimization of Majorana hybrid nanowires. (arXiv:2208.02182v1 [cond-mat.mes-hall])
76. Multimodal sensor fusion in the latent representation space. (arXiv:2208.02183v1 [cs.AI])
77. A Study of Modeling Rising Intonation in Cantonese Neural Speech Synthesis. (arXiv:2208.02189v1 [eess.AS])
78. Interpretable bilinear attention network with domain adaptation improves drug-target prediction. (arXiv:2208.02194v1 [cs.LG])
79. Efficiently Computing Nash Equilibria in Adversarial Team Markov Games. (arXiv:2208.02204v1 [cs.GT])
80. SGEM: stochastic gradient with energy and momentum. (arXiv:2208.02208v1 [cs.LG])
81. Blockchain associated machine learning and IoT based hypoglycemia detection system with auto-injection feature. (arXiv:2208.02222v1 [cs.LG])
82. Sequence Model Imitation Learning with Unobserved Contexts. (arXiv:2208.02225v1 [cs.LG])
83. Internet of Things (IoT) based ECG System for Rural Health Care. (arXiv:2208.02226v1 [eess.SP])
84. Quantum-Inspired Tensor Neural Networks for Partial Differential Equations. (arXiv:2208.02235v1 [cs.LG])
85. AdaCat: Adaptive Categorical Discretization for Autoregressive Models. (arXiv:2208.02246v1 [cs.LG])
86. Adversarial Bandits with Knapsacks. (arXiv:1811.11881v9 [cs.DS] UPDATED)
87. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v7 [cs.LG] UPDATED)
88. Hierarchical Multiple-Instance Data Classification with Costly Features. (arXiv:1911.08756v5 [cs.LG] UPDATED)
89. Multimodal Controller for Generative Models. (arXiv:2002.02572v7 [cs.LG] UPDATED)
90. Can you hear me $\textit{now}$? Sensitive comparisons of human and machine perception. (arXiv:2003.12362v2 [eess.AS] UPDATED)
91. Stochastic Neighbor Embedding with Gaussian and Student-t Distributions: Tutorial and Survey. (arXiv:2009.10301v2 [stat.ML] UPDATED)
92. Optimised one-class classification performance. (arXiv:2102.02618v3 [cs.LG] UPDATED)
93. Provable Model-based Nonlinear Bandit and Reinforcement Learning: Shelve Optimism, Embrace Virtual Curvature. (arXiv:2102.04168v5 [cs.LG] UPDATED)
94. A Glimpse of Physical Layer Decision Mechanisms: Facts, Challenges, and Remedies. (arXiv:2102.07258v3 [cs.LG] UPDATED)
95. A first look into the carbon footprint of federated learning. (arXiv:2102.07627v4 [cs.LG] UPDATED)
96. RBNN: Memory-Efficient Reconfigurable Deep Binary Neural Network with IP Protection for Internet of Things. (arXiv:2105.03822v3 [cs.CR] UPDATED)
97. Stable and Interpretable Unrolled Dictionary Learning. (arXiv:2106.00058v5 [cs.LG] UPDATED)
98. Bridging the Gap Between Object Detection and User Intent via Query-Modulation. (arXiv:2106.10258v2 [cs.CV] UPDATED)
99. Unified Framework for Spectral Dimensionality Reduction, Maximum Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial and Survey. (arXiv:2106.15379v2 [stat.ML] UPDATED)
100. Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v4 [math.OC] UPDATED)
101. Quantized Convolutional Neural Networks Through the Lens of Partial Differential Equations. (arXiv:2109.00095v2 [cs.LG] UPDATED)
102. Mapping Research Topics in Software Testing: A Bibliometric Analysis. (arXiv:2109.04086v3 [cs.DL] UPDATED)
103. ProcK: Machine Learning for Knowledge-Intensive Processes. (arXiv:2109.04881v2 [cs.LG] UPDATED)
104. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v3 [cs.RO] UPDATED)
105. Convex-Concave Min-Max Stackelberg Games. (arXiv:2110.05192v7 [cs.GT] UPDATED)
106. Generalized Out-of-Distribution Detection: A Survey. (arXiv:2110.11334v2 [cs.CV] UPDATED)
107. Stochastic Gradient Line Bayesian Optimization for Efficient Noise-Robust Optimization of Parameterized Quantum Circuits. (arXiv:2111.07952v2 [quant-ph] UPDATED)
108. Revisiting local branching with a machine learning lens. (arXiv:2112.02195v2 [math.OC] UPDATED)
109. A data-centric weak supervised learning for highway traffic incident detection. (arXiv:2112.09792v2 [cs.LG] UPDATED)
110. List Autoencoder: Towards Deep Learning Based Reliable Transmission Over Noisy Channels. (arXiv:2112.11920v2 [cs.IT] UPDATED)
111. Physics Constrained Flow Neural Network for Short-Timescale Predictions in Data Communications Networks. (arXiv:2112.12321v2 [cs.LG] UPDATED)
112. Automatic Meta-Path Discovery for Effective Graph-Based Recommendation. (arXiv:2112.12845v3 [cs.IR] UPDATED)
113. Matrix Decomposition and Applications. (arXiv:2201.00145v2 [math.NA] UPDATED)
114. Spectral Propagation Graph Network for Few-shot Time Series Classification. (arXiv:2202.04769v2 [cs.LG] UPDATED)
115. Laplacian Features for Learning with Hyperbolic Space. (arXiv:2202.06854v2 [cs.LG] UPDATED)
116. RemixIT: Continual self-training of speech **enhancement** models via bootstrapped remixing. (arXiv:2202.08862v3 [cs.SD] UPDATED)
117. Off-Policy Confidence Interval Estimation with Confounded Markov Decision Process. (arXiv:2202.10589v4 [stat.ML] UPDATED)
118. Policy Evaluation for Temporal and/or Spatial Dependent Experiments in Ride-sourcing Platforms. (arXiv:2202.10887v2 [stat.ME] UPDATED)
119. Robust Training under Label Noise by Over-parameterization. (arXiv:2202.14026v2 [cs.LG] UPDATED)
120. A Transformational Characterization of Unconditionally Equivalent Bayesian Networks. (arXiv:2203.00521v2 [stat.ML] UPDATED)
121. STEADY: Simultaneous State Estimation and Dynamics Learning from Indirect Observations. (arXiv:2203.01299v2 [cs.RO] UPDATED)
122. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v3 [cs.LG] UPDATED)
123. AUC Maximization in the Era of Big Data and AI: A Survey. (arXiv:2203.15046v3 [cs.LG] UPDATED)
124. Explainable Artificial Intelligence in Process Mining: Assessing the Explainability-Performance Trade-Off in Outcome-Oriented Predictive Process Monitoring. (arXiv:2203.16073v2 [cs.LG] UPDATED)
125. An Empirical Study of Language Model Integration for Transducer based Speech Recognition. (arXiv:2203.16776v4 [eess.AS] UPDATED)
126. Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v2 [stat.ML] UPDATED)
127. auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event Data. (arXiv:2204.07276v4 [cs.LG] UPDATED)
128. Deep Learning-Enabled Semantic Communication Systems with Task-Unaware Transmitter and Dynamic Data. (arXiv:2205.00271v2 [cs.IT] UPDATED)
129. Spatial Autoregressive Coding for Graph Neural Recommendation. (arXiv:2205.09489v2 [cs.IR] UPDATED)
130. Naive Few-Shot Learning: Sequence Consistency Evaluation. (arXiv:2205.12013v2 [cs.AI] UPDATED)
131. TSEM: Temporally Weighted Spatiotemporal Explainable Neural Network for Multivariate Time Series. (arXiv:2205.13012v2 [cs.LG] UPDATED)
132. FlowNet-PET: Unsupervised Learning to Perform Respiratory Motion Correction in PET Imaging. (arXiv:2205.14147v3 [eess.IV] UPDATED)
133. Combinatorial Causal Bandits. (arXiv:2206.01995v2 [cs.LG] UPDATED)
134. Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2206.06022v2 [cs.AR] UPDATED)
135. High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization. (arXiv:2206.08487v2 [cs.RO] UPDATED)
136. GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks. (arXiv:2206.09677v3 [cs.LG] UPDATED)
137. WrapperFL: A Model Agnostic Plug-in for Industrial Federated Learning. (arXiv:2206.10407v2 [cs.LG] UPDATED)
138. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v4 [cs.LG] UPDATED)
139. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v2 [cs.LG] UPDATED)
140. Few-Shot Cross-Lingual TTS Using Transferable Phoneme Embedding. (arXiv:2206.15427v2 [eess.AS] UPDATED)
141. Integral Probability Metrics PAC-Bayes Bounds. (arXiv:2207.00614v3 [stat.ML] UPDATED)
142. Eliciting and Learning with Soft Labels from Every Annotator. (arXiv:2207.00810v2 [cs.LG] UPDATED)
143. Emergence of Novelty in Evolutionary Algorithms. (arXiv:2207.04857v3 [cs.NE] UPDATED)
144. Towards Global Optimality in Cooperative MARL with Sequential Transformation. (arXiv:2207.11143v2 [cs.MA] UPDATED)
145. SYNTA: A novel approach for deep learning-based image analysis in muscle histopathology using photo-realistic synthetic data. (arXiv:2207.14650v2 [eess.IV] UPDATED)
146. Tangential Wasserstein Projections. (arXiv:2207.14727v2 [stat.ML] UPDATED)
147. On the Evaluation of User Privacy in Deep Neural Networks using Timing Side Channel. (arXiv:2208.01113v2 [cs.CR] UPDATED)
148. AlexaTM 20B: Few-Shot Learning Using a Large-Scale Multilingual Seq2Seq Model. (arXiv:2208.01448v2 [cs.CL] UPDATED)
149. An Online Sparse Streaming Feature Selection Algorithm. (arXiv:2208.01562v2 [cs.LG] UPDATED)
150. Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study. (arXiv:2208.01602v2 [eess.IV] UPDATED)
## cs.AI
---
**59** new papers in cs.AI:-) 
1. CTooth+: A Large-scale Dental Cone Beam Computed Tomography Dataset and Benchmark for Tooth Volume Segmentation. (arXiv:2208.01643v1 [eess.IV])
2. AI-driven Hypernetwork of Organic Chemistry: Network Statistics and Applications in Reaction Classification. (arXiv:2208.01647v1 [q-bio.MN])
3. Maximal Independent Vertex Set applied to Graph Pooling. (arXiv:2208.01648v1 [cs.LG])
4. Heterogeneous-Agent Mirror Learning: A Continuum of Solutions to Cooperative MARL. (arXiv:2208.01682v1 [cs.MA])
5. Curvature-informed multi-task learning for graph networks. (arXiv:2208.01684v1 [cs.LG])
6. A cloud platform for automating and sharing analysis of raw simulation data from high throughput polymer molecular dynamics simulations. (arXiv:2208.01692v1 [cond-mat.mtrl-sci])
7. Recognizing and Extracting Cybersecurtity-relevant Entities from Text. (arXiv:2208.01693v1 [cs.CL])
8. CAPD: A Context-Aware, Policy-Driven Framework for Secure and Resilient IoBT Operations. (arXiv:2208.01703v1 [cs.CR])
9. Autonomous Agriculture Robot for Smart Farming. (arXiv:2208.01708v1 [cs.RO])
10. V-Coder: Adaptive AutoEncoder for Semantic Disclosure in Knowledge Graphs. (arXiv:2208.01735v1 [cs.AI])
11. From Single Aircraft to Communities: A Neutral Interpretation of Air Traffic Complexity Dynamics. (arXiv:2208.01740v1 [cs.AI])
12. Cross-Modal Alignment Learning of Vision-Language Conceptual Systems. (arXiv:2208.01744v1 [cs.CV])
13. Deep Reinforcement Learning for Multi-Agent Interaction. (arXiv:2208.01769v1 [cs.MA])
14. Digital Twin-Assisted Efficient Reinforcement Learning for Edge Task Scheduling. (arXiv:2208.01781v1 [cs.LG])
15. Post-hoc Interpretability based Parameter Selection for Data Oriented Nuclear Reactor Accident Diagnosis System. (arXiv:2208.01805v1 [eess.SY])
16. Coarse-to-Fine Knowledge-Enhanced Multi-Interest Learning Framework for Multi-Behavior Recommendation. (arXiv:2208.01849v1 [cs.IR])
17. Neural Dynamic Movement Primitives -- a survey. (arXiv:2208.01903v1 [cs.RO])
18. Supervised and Reinforcement Learning from Observations in Reconnaissance Blind Chess. (arXiv:2208.02029v1 [cs.AI])
19. A Novel Approach To Network Intrusion Detection System Using Deep Learning For Sdn: Futuristic Approach. (arXiv:2208.02094v1 [cs.CR])
20. Active Learning on a Programmable Photonic Quantum Processor. (arXiv:2208.02104v1 [quant-ph])
21. MTGFlow: Unsupervised Multivariate Time Series Anomaly Detection via Dynamic Graph and Entity-aware Normalizing Flow. (arXiv:2208.02108v1 [cs.LG])
22. KPI-BERT: A Joint Named Entity Recognition and Relation Extraction Model for Financial Reports. (arXiv:2208.02140v1 [cs.CL])
23. Empirical Study of Overfitting in Deep FNN Prediction Models for Breast Cancer Metastasis. (arXiv:2208.02150v1 [cs.LG])
24. Multimodal sensor fusion in the latent representation space. (arXiv:2208.02183v1 [cs.AI])
25. On the independence between phenomenal consciousness and computational intelligence. (arXiv:2208.02187v1 [cs.AI])
26. Blockchain associated machine learning and IoT based hypoglycemia detection system with auto-injection feature. (arXiv:2208.02222v1 [cs.LG])
27. Internet of Things (IoT) based ECG System for Rural Health Care. (arXiv:2208.02226v1 [eess.SP])
28. Quantum-Inspired Tensor Neural Networks for Partial Differential Equations. (arXiv:2208.02235v1 [cs.LG])
29. MinVIS: A Minimal Video Instance Segmentation Framework without Video-based Training. (arXiv:2208.02245v1 [cs.CV])
30. AdaCat: Adaptive Categorical Discretization for Autoregressive Models. (arXiv:2208.02246v1 [cs.LG])
31. Recovery of Future Data via Convolution Nuclear Norm Minimization. (arXiv:1909.03889v7 [cs.LG] UPDATED)
32. Hierarchical Multiple-Instance Data Classification with Costly Features. (arXiv:1911.08756v5 [cs.LG] UPDATED)
33. To Be Announced. (arXiv:2004.05802v3 [cs.LO] UPDATED)
34. Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in Object Detection. (arXiv:2012.00257v3 [cs.CV] UPDATED)
35. Bridging the Gap Between Object Detection and User Intent via Query-Modulation. (arXiv:2106.10258v2 [cs.CV] UPDATED)
36. Scene Editing as Teleoperation: A Case Study in 6DoF Kit Assembly. (arXiv:2110.04450v3 [cs.RO] UPDATED)
37. Generalized Out-of-Distribution Detection: A Survey. (arXiv:2110.11334v2 [cs.CV] UPDATED)
38. Revisiting local branching with a machine learning lens. (arXiv:2112.02195v2 [math.OC] UPDATED)
39. Spectral Propagation Graph Network for Few-shot Time Series Classification. (arXiv:2202.04769v2 [cs.LG] UPDATED)
40. Robust Training under Label Noise by Over-parameterization. (arXiv:2202.14026v2 [cs.LG] UPDATED)
41. Automated fault tree learning from continuous-valued sensor data: a case study on domestic heaters. (arXiv:2203.07374v3 [cs.LG] UPDATED)
42. TCM-SD: A Benchmark for Probing Syndrome Differentiation via Natural Language Processing. (arXiv:2203.10839v2 [cs.CL] UPDATED)
43. AUC Maximization in the Era of Big Data and AI: A Survey. (arXiv:2203.15046v3 [cs.LG] UPDATED)
44. Explainable Artificial Intelligence in Process Mining: Assessing the Explainability-Performance Trade-Off in Outcome-Oriented Predictive Process Monitoring. (arXiv:2203.16073v2 [cs.LG] UPDATED)
45. Spatial Autoregressive Coding for Graph Neural Recommendation. (arXiv:2205.09489v2 [cs.IR] UPDATED)
46. Naive Few-Shot Learning: Sequence Consistency Evaluation. (arXiv:2205.12013v2 [cs.AI] UPDATED)
47. TSEM: Temporally Weighted Spatiotemporal Explainable Neural Network for Multivariate Time Series. (arXiv:2205.13012v2 [cs.LG] UPDATED)
48. High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization. (arXiv:2206.08487v2 [cs.RO] UPDATED)
49. GraphFramEx: Towards Systematic Evaluation of Explainability Methods for Graph Neural Networks. (arXiv:2206.09677v3 [cs.LG] UPDATED)
50. WrapperFL: A Model Agnostic Plug-in for Industrial Federated Learning. (arXiv:2206.10407v2 [cs.LG] UPDATED)
51. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v4 [cs.LG] UPDATED)
52. Beyond neural scaling laws: beating power law scaling via data pruning. (arXiv:2206.14486v2 [cs.LG] UPDATED)
53. Few-Shot Cross-Lingual TTS Using Transferable Phoneme Embedding. (arXiv:2206.15427v2 [eess.AS] UPDATED)
54. Eliciting and Learning with Soft Labels from Every Annotator. (arXiv:2207.00810v2 [cs.LG] UPDATED)
55. Refutation of Spectral Graph Theory Conjectures with Monte Carlo Search. (arXiv:2207.03343v3 [cs.AI] UPDATED)
56. Emergence of Novelty in Evolutionary Algorithms. (arXiv:2207.04857v3 [cs.NE] UPDATED)
57. Task-adaptive Spatial-Temporal Video Sampler for Few-shot Action Recognition. (arXiv:2207.09759v2 [cs.CV] UPDATED)
58. Towards Global Optimality in Cooperative MARL with Sequential Transformation. (arXiv:2207.11143v2 [cs.MA] UPDATED)
59. A Particle-Based Algorithm for Distributional Optimization on \textit{Constrained Domains} via Variational Transport and Mirror Descent. (arXiv:2208.00587v3 [math.OC] UPDATED)

