# Your interest papers
---
## cs.CV
---
### Semi-supervised segmentation of tooth from 3D Scanned Dental Arches. (arXiv:2208.05539v1 [cs.CV])
- Authors : Ammar Alsheghri, Farnoosh Ghadiri, Ying Zhang, Olivier Lessard, Julia Keren, Farida Cheriet, Francois Guibault
- Link : [http://arxiv.org/abs/2208.05539](http://arxiv.org/abs/2208.05539)
> ABSTRACT  :  Teeth segmentation is an important topic in dental **restoration**s that is essential for crown generation, diagnosis, and treatment planning. In the dental field, the variability of input data is high and there are no publicly available 3D dental arch datasets. Although there has been improvement in the field provided by recent deep learning architectures on 3D data, there still exists some problems such as properly identifying missing teeth in an arch. We propose to use spectral clustering as a self-supervisory signal to joint-train neural networks for segmentation of 3D arches. Our approach is motivated by the observation that K-means clustering provides cues to capture margin lines related to human perception. The main idea is to automatically generate training data by decomposing unlabeled 3D arches into segments relying solely on geometric information. The network is then trained using a joint loss that combines a supervised loss of annotated input and a self-supervised loss of non-labeled input. Our collected data has a variety of arches including arches with missing teeth. Our experimental results show improvement over the fully supervised state-of-the-art MeshSegNet when using semi-supervised learning. Finally, we contribute code and a dataset.  
### FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques. (arXiv:2208.05615v1 [cs.CV])
- Authors : Ibrahim Yilmaz
- Link : [http://arxiv.org/abs/2208.05615](http://arxiv.org/abs/2208.05615)
> ABSTRACT  :  Fingerprint evidence plays an important role in a criminal investigation for the identification of individuals. Although various techniques have been proposed for fingerprint classification and feature extraction, automated fingerprint identification of fingerprints is still in its earliest stage. The performance of traditional \textit{Automatic Fingerprint Identification System} (AFIS) depends on the presence of valid minutiae points and still requires human expert assistance in feature extraction and identification stages. Based on this motivation, we propose a Fingerprint Identification approach based on Generative adversarial network and One-shot learning techniques (FIGO). Our solution contains two components: fingerprint **enhancement** tier and fingerprint identification tier. First, we propose a Pix2Pix model to transform low-quality fingerprint images to a higher level of fingerprint images pixel by pixel directly in the fingerprint **enhancement** tier. With the proposed **enhancement** algorithm, the fingerprint identification model's performance is significantly improved. Furthermore, we develop another existing solution based on Gabor filters as a benchmark to compare with the proposed model by observing the fingerprint device's recognition accuracy. Experimental results show that our proposed Pix2pix model has better support than the baseline approach for fingerprint identification. Second, we construct a fully automated fingerprint feature extraction model using a one-shot learning approach to differentiate each fingerprint from the others in the fingerprint identification process. Two twin convolutional neural networks (CNNs) with shared weights and parameters are used to obtain the feature vectors in this process. Using the proposed method, we demonstrate that it is possible to learn necessary information from only one training sample with high accuracy.  
### FD**NeRF**: Few-shot Dynamic Neural Radiance Fields for Face Reconstruction and Expression Editing. (arXiv:2208.05751v1 [cs.CV])
- Authors : Jingbo Zhang, Xiaoyu Li, Ziyu Wan, Can Wang, Jing Liao
- Link : [http://arxiv.org/abs/2208.05751](http://arxiv.org/abs/2208.05751)
> ABSTRACT  :  We propose a Few-shot Dynamic Neural Radiance Field (FD**NeRF**), the first **NeRF**-based method capable of reconstruction and expression editing of 3D faces based on a small number of dynamic images. Unlike existing dynamic **NeRF**s that require dense images as input and can only be modeled for a single identity, our method enables face reconstruction across different persons with few-shot inputs. Compared to state-of-the-art few-shot **NeRF**s designed for modeling static scenes, the proposed FD**NeRF** accepts view-inconsistent dynamic inputs and supports arbitrary facial expression editing, i.e., producing faces with novel expressions beyond the input ones. To handle the inconsistencies between dynamic inputs, we introduce a well-designed conditional feature warping (CFW) module to perform expression conditioned warping in 2D feature space, which is also identity adaptive and 3D constrained. As a result, features of different expressions are transformed into the target ones. We then construct a radiance field based on these view-consistent features and use volumetric rendering to synthesize novel views of the modeled faces. Extensive experiments with quantitative and qualitative evaluation demonstrate that our method outperforms existing dynamic and few-shot **NeRF**s on both 3D face reconstruction and expression editing tasks. Our code and model will be available upon acceptance.  
### RelPose: Predicting Probabilistic Relative Rotation for Single Objects in the Wild. (arXiv:2208.05963v1 [cs.CV])
- Authors : Deva Ramanan, Shubham Tulsiani
- Link : [http://arxiv.org/abs/2208.05963](http://arxiv.org/abs/2208.05963)
> ABSTRACT  :  We describe a data-driven method for inferring the camera viewpoints given multiple images of an arbitrary object. This task is a core component of classic geometric pipelines such as SfM and SLAM, and also serves as a vital pre-processing requirement for contemporary neural approaches (e.g. **NeRF**) to object reconstruction and view synthesis. In contrast to existing correspondence-driven methods that do not perform well given sparse views, we propose a top-down prediction based approach for estimating camera viewpoints. Our key technical insight is the use of an energy-based formulation for representing distributions over relative camera rotations, thus allowing us to explicitly represent multiple camera modes arising from object symmetries or views. Leveraging these relative predictions, we jointly estimate a consistent set of camera rotations from multiple images. We show that our approach outperforms state-of-the-art SfM and SLAM methods given sparse images on both seen and unseen categories. Further, our probabilistic approach significantly outperforms directly regressing relative poses, suggesting that modeling multimodality is important for coherent joint reconstruction. We demonstrate that our system can be a stepping stone toward in-the-wild reconstruction from multi-view datasets. The project page with code and videos can be found at https://jasonyzhang.com/relpose.  
### Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
- Authors : Olivier Rukundo
- Link : [http://arxiv.org/abs/2101.11508](http://arxiv.org/abs/2101.11508)
> ABSTRACT  :  In this paper the main objective is to determine the best size of late gadolinium **enhancement** (LGE)-magnetic resonance imaging (MRI) images for the training dataset to achieve optimal deep learning training outcomes. To determine the new size of LGE-MRI images from the reference training dataset, non-extra pixel and extra pixel interpolation algorithms are used. A novel strategy based on thresholding, median filtering, and subtraction operations is introduced and applied to remove extra class labels in interpolated ground truth (GT) segmentation masks. Fully automated quantification is achieved using the expectation maximization, weighted intensity, a priori information (EWA) algorithm, and the outcome of automatic semantic segmentation of LGE-MRI images with the convolutional neural network (CNN). In the experiments, common class metrics are used to evaluate the quality of semantic segmentation with a CNN architecture of interest (U-net) against the GT segmentation. Arbitrary threshold, comparison of the sums, and sums of differences are criteria or options used to estimate the relationship between semi-automatic and fully automated quantification of MI results. A close relationship between semi-automatic or manual and fully automated quantification of MI results was more identified in the case involving the dataset of bigger LGE MRI images than in that of the dataset of smaller LGE-MRI images where the best quantification results based on the dataset of bigger LGE MRI images were 55.5% closer the manual or semiautomatic results while the best quantification results based on the dataset of smaller LGE MRI images were 22.2% closer the manual results.  
### Multi-scale Feature Aggregation for Crowd Counting. (arXiv:2208.05256v2 [cs.CV] UPDATED)
- Authors : Xiaoheng Jiang, Xinyi Wu, Hisham Cholakkal, Rao Muhammad, Jiale Cao, Mingliang Xu, Bing Zhou, Yanwei Pang, Fahad Shahbaz
- Link : [http://arxiv.org/abs/2208.05256](http://arxiv.org/abs/2208.05256)
> ABSTRACT  :  Convolutional Neural Network (CNN) based crowd counting methods have achieved promising results in the past few years. However, the scale variation problem is still a huge challenge for accurate count estimation. In this paper, we propose a multi-scale feature aggregation network (MSFANet) that can alleviate this problem to some extent. Specifically, our approach consists of two feature aggregation modules: the short aggregation (ShortAgg) and the skip aggregation (SkipAgg). The ShortAgg module aggregates the features of the adjacent convolution blocks. Its purpose is to make features with different receptive fields fused gradually from the bottom to the top of the network. The SkipAgg module directly propagates features with small receptive fields to features with much larger receptive fields. Its purpose is to promote the fusion of features with small and large receptive fields. Especially, the SkipAgg module introduces the local self-attention features from the **Swin** Transformer blocks to incorporate rich spatial information. Furthermore, we present a local-and-global based counting loss by considering the non-uniform crowd distribution. Extensive experiments on four challenging datasets (ShanghaiTech dataset, UCF_CC_50 dataset, UCF-QNRF Dataset, WorldExpo'10 dataset) demonstrate the proposed easy-to-implement MSFANet can achieve promising results when compared with the previous state-of-the-art approaches.  
## eess.IV
---
### Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
- Authors : Olivier Rukundo
- Link : [http://arxiv.org/abs/2101.11508](http://arxiv.org/abs/2101.11508)
> ABSTRACT  :  In this paper the main objective is to determine the best size of late gadolinium **enhancement** (LGE)-magnetic resonance imaging (MRI) images for the training dataset to achieve optimal deep learning training outcomes. To determine the new size of LGE-MRI images from the reference training dataset, non-extra pixel and extra pixel interpolation algorithms are used. A novel strategy based on thresholding, median filtering, and subtraction operations is introduced and applied to remove extra class labels in interpolated ground truth (GT) segmentation masks. Fully automated quantification is achieved using the expectation maximization, weighted intensity, a priori information (EWA) algorithm, and the outcome of automatic semantic segmentation of LGE-MRI images with the convolutional neural network (CNN). In the experiments, common class metrics are used to evaluate the quality of semantic segmentation with a CNN architecture of interest (U-net) against the GT segmentation. Arbitrary threshold, comparison of the sums, and sums of differences are criteria or options used to estimate the relationship between semi-automatic and fully automated quantification of MI results. A close relationship between semi-automatic or manual and fully automated quantification of MI results was more identified in the case involving the dataset of bigger LGE MRI images than in that of the dataset of smaller LGE-MRI images where the best quantification results based on the dataset of bigger LGE MRI images were 55.5% closer the manual or semiautomatic results while the best quantification results based on the dataset of smaller LGE MRI images were 22.2% closer the manual results.  
## cs.LG
---
### Semi-supervised segmentation of tooth from 3D Scanned Dental Arches. (arXiv:2208.05539v1 [cs.CV])
- Authors : Ammar Alsheghri, Farnoosh Ghadiri, Ying Zhang, Olivier Lessard, Julia Keren, Farida Cheriet, Francois Guibault
- Link : [http://arxiv.org/abs/2208.05539](http://arxiv.org/abs/2208.05539)
> ABSTRACT  :  Teeth segmentation is an important topic in dental **restoration**s that is essential for crown generation, diagnosis, and treatment planning. In the dental field, the variability of input data is high and there are no publicly available 3D dental arch datasets. Although there has been improvement in the field provided by recent deep learning architectures on 3D data, there still exists some problems such as properly identifying missing teeth in an arch. We propose to use spectral clustering as a self-supervisory signal to joint-train neural networks for segmentation of 3D arches. Our approach is motivated by the observation that K-means clustering provides cues to capture margin lines related to human perception. The main idea is to automatically generate training data by decomposing unlabeled 3D arches into segments relying solely on geometric information. The network is then trained using a joint loss that combines a supervised loss of annotated input and a self-supervised loss of non-labeled input. Our collected data has a variety of arches including arches with missing teeth. Our experimental results show improvement over the fully supervised state-of-the-art MeshSegNet when using semi-supervised learning. Finally, we contribute code and a dataset.  
### Speech **Enhancement** and Dereverberation with Diffusion-based Generative Models. (arXiv:2208.05830v1 [eess.AS])
- Authors : Julius Richter, Simon Welker, Marie Lemercier, Bunlong Lay, Timo Gerkmann
- Link : [http://arxiv.org/abs/2208.05830](http://arxiv.org/abs/2208.05830)
> ABSTRACT  :  Recently, diffusion-based generative models have been introduced to the task of speech **enhancement**. The corruption of clean speech is modeled as a fixed forward process in which increasing amounts of noise are gradually added. By learning to reverse this process in an iterative fashion conditioned on the noisy input, clean speech is generated. We build upon our previous work and derive the training task within the formalism of stochastic differential equations. We present a detailed theoretical review of the underlying score matching objective and explore different sampler configurations for solving the reverse process at test time. By using a sophisticated network architecture from natural image generation literature, we significantly improve performance compared to our previous publication. We also show that we can compete with recent discriminative models and achieve better generalization when evaluating on a different corpus than used for training. We complement the evaluation results with a subjective listening test, in which our proposed method is rated best. Furthermore, we show that the proposed method achieves remarkable state-of-the-art performance in single-channel speech dereverberation. Our code and audio examples are available online, see https://uhh.de/inf-sp-sgmse  
### RelPose: Predicting Probabilistic Relative Rotation for Single Objects in the Wild. (arXiv:2208.05963v1 [cs.CV])
- Authors : Deva Ramanan, Shubham Tulsiani
- Link : [http://arxiv.org/abs/2208.05963](http://arxiv.org/abs/2208.05963)
> ABSTRACT  :  We describe a data-driven method for inferring the camera viewpoints given multiple images of an arbitrary object. This task is a core component of classic geometric pipelines such as SfM and SLAM, and also serves as a vital pre-processing requirement for contemporary neural approaches (e.g. **NeRF**) to object reconstruction and view synthesis. In contrast to existing correspondence-driven methods that do not perform well given sparse views, we propose a top-down prediction based approach for estimating camera viewpoints. Our key technical insight is the use of an energy-based formulation for representing distributions over relative camera rotations, thus allowing us to explicitly represent multiple camera modes arising from object symmetries or views. Leveraging these relative predictions, we jointly estimate a consistent set of camera rotations from multiple images. We show that our approach outperforms state-of-the-art SfM and SLAM methods given sparse images on both seen and unseen categories. Further, our probabilistic approach significantly outperforms directly regressing relative poses, suggesting that modeling multimodality is important for coherent joint reconstruction. We demonstrate that our system can be a stepping stone toward in-the-wild reconstruction from multi-view datasets. The project page with code and videos can be found at https://jasonyzhang.com/relpose.  
### Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
- Authors : Olivier Rukundo
- Link : [http://arxiv.org/abs/2101.11508](http://arxiv.org/abs/2101.11508)
> ABSTRACT  :  In this paper the main objective is to determine the best size of late gadolinium **enhancement** (LGE)-magnetic resonance imaging (MRI) images for the training dataset to achieve optimal deep learning training outcomes. To determine the new size of LGE-MRI images from the reference training dataset, non-extra pixel and extra pixel interpolation algorithms are used. A novel strategy based on thresholding, median filtering, and subtraction operations is introduced and applied to remove extra class labels in interpolated ground truth (GT) segmentation masks. Fully automated quantification is achieved using the expectation maximization, weighted intensity, a priori information (EWA) algorithm, and the outcome of automatic semantic segmentation of LGE-MRI images with the convolutional neural network (CNN). In the experiments, common class metrics are used to evaluate the quality of semantic segmentation with a CNN architecture of interest (U-net) against the GT segmentation. Arbitrary threshold, comparison of the sums, and sums of differences are criteria or options used to estimate the relationship between semi-automatic and fully automated quantification of MI results. A close relationship between semi-automatic or manual and fully automated quantification of MI results was more identified in the case involving the dataset of bigger LGE MRI images than in that of the dataset of smaller LGE-MRI images where the best quantification results based on the dataset of bigger LGE MRI images were 55.5% closer the manual or semiautomatic results while the best quantification results based on the dataset of smaller LGE MRI images were 22.2% closer the manual results.  
### Low-complexity Near-optimum Symbol Detection Based on Neural **Enhancement** of Factor Graphs. (arXiv:2203.16417v2 [cs.IT] UPDATED)
- Authors : Luca Schmid, Laurent Schmalen
- Link : [http://arxiv.org/abs/2203.16417](http://arxiv.org/abs/2203.16417)
> ABSTRACT  :  We consider the application of the factor graph framework for symbol detection on linear inter-symbol interference channels. Based on the Ungerboeck observation model, a detection algorithm with appealing complexity properties can be derived. However, since the underlying factor graph contains cycles, the sum-product algorithm (SPA) yields a suboptimal algorithm. In this paper, we develop and evaluate efficient strategies to improve the performance of the factor graph-based symbol detection by means of neural **enhancement**. In particular, we consider neural belief propagation and generalizations of the factor nodes as an effective way to mitigate the effect of cycles within the factor graph. By applying a generic preprocessor to the channel output, we propose a simple technique to vary the underlying factor graph in every SPA iteration. Using this dynamic factor graph transition, we intend to preserve the extrinsic nature of the SPA messages which is otherwise impaired due to cycles. Simulation results show that the proposed methods can massively improve the detection performance, even approaching the maximum a posteriori performance for various transmission scenarios, while preserving a complexity which is linear in both the block length and the channel memory.  
## cs.AI
---
### FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques. (arXiv:2208.05615v1 [cs.CV])
- Authors : Ibrahim Yilmaz
- Link : [http://arxiv.org/abs/2208.05615](http://arxiv.org/abs/2208.05615)
> ABSTRACT  :  Fingerprint evidence plays an important role in a criminal investigation for the identification of individuals. Although various techniques have been proposed for fingerprint classification and feature extraction, automated fingerprint identification of fingerprints is still in its earliest stage. The performance of traditional \textit{Automatic Fingerprint Identification System} (AFIS) depends on the presence of valid minutiae points and still requires human expert assistance in feature extraction and identification stages. Based on this motivation, we propose a Fingerprint Identification approach based on Generative adversarial network and One-shot learning techniques (FIGO). Our solution contains two components: fingerprint **enhancement** tier and fingerprint identification tier. First, we propose a Pix2Pix model to transform low-quality fingerprint images to a higher level of fingerprint images pixel by pixel directly in the fingerprint **enhancement** tier. With the proposed **enhancement** algorithm, the fingerprint identification model's performance is significantly improved. Furthermore, we develop another existing solution based on Gabor filters as a benchmark to compare with the proposed model by observing the fingerprint device's recognition accuracy. Experimental results show that our proposed Pix2pix model has better support than the baseline approach for fingerprint identification. Second, we construct a fully automated fingerprint feature extraction model using a one-shot learning approach to differentiate each fingerprint from the others in the fingerprint identification process. Two twin convolutional neural networks (CNNs) with shared weights and parameters are used to obtain the feature vectors in this process. Using the proposed method, we demonstrate that it is possible to learn necessary information from only one training sample with high accuracy.  
### Shielding Federated Learning Systems against Inference Attacks with ARM TrustZone. (arXiv:2208.05895v1 [cs.CR])
- Authors : Aghiles Ait, Sonia Ben, Vlad Nitu, Valerio Shiavoni
- Link : [http://arxiv.org/abs/2208.05895](http://arxiv.org/abs/2208.05895)
> ABSTRACT  :  Federated Learning (FL) opens new perspectives for training machine learning models while keeping personal data on the users premises. Specifically, in FL, models are trained on the users devices and only model updates (i.e., gradients) are sent to a central server for aggregation purposes. However, the long list of inference attacks that leak private data from gradients, published in the recent years, have emphasized the need of devising effective protection mechanisms to incentivize the adoption of FL at scale. While there exist solutions to mitigate these attacks on the server side, little has been done to protect users from attacks performed on the client side. In this context, the use of Trusted Execution Environments (TEEs) on the client side are among the most proposing solutions. However, existing frameworks (e.g., **Dark**neTZ) require statically putting a large portion of the machine learning model into the TEE to effectively protect against complex attacks or a combination of attacks. We present GradSec, a solution that allows protecting in a TEE only sensitive layers of a machine learning model, either statically or dynamically, hence reducing both the TCB size and the overall training time by up to 30% and 56%, respectively compared to state-of-the-art competitors.  
# Paper List
---
## cs.CV
---
**72** new papers in cs.CV:-) 
1. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v1 [eess.IV])
2. Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP. (arXiv:2208.05516v1 [cs.LG])
3. Semi-supervised segmentation of tooth from 3D Scanned Dental Arches. (arXiv:2208.05539v1 [cs.CV])
4. Towards Automating Retinoscopy for Refractive Error Diagnosis. (arXiv:2208.05552v1 [cs.HC])
5. Patching open-vocabulary models by interpolating weights. (arXiv:2208.05592v1 [cs.CV])
6. Evaluating Generatively Synthesized Diabetic Retinopathy Imagery. (arXiv:2208.05593v1 [eess.IV])
7. Memorizing Complementation Network for Few-Shot Class-Incremental Learning. (arXiv:2208.05610v1 [cs.CV])
8. FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques. (arXiv:2208.05615v1 [cs.CV])
9. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v1 [eess.IV])
10. Language-Guided Face Animation by Recurrent StyleGAN-based Generator. (arXiv:2208.05617v1 [cs.CV])
11. ARMANI: Part-level Garment-Text Alignment for Unified Cross-Modal Fashion Design. (arXiv:2208.05621v1 [cs.CV])
12. Locality-aware Attention Network with Discriminative Dynamics Learning for Weakly Supervised Anomaly Detection. (arXiv:2208.05636v1 [cs.CV])
13. Adaptive and Implicit Regularization for Matrix Completion. (arXiv:2208.05640v1 [cs.CV])
14. Towards Automated Key-Point Detection in Images with Partial Pool View. (arXiv:2208.05641v1 [cs.CV])
15. Self-Knowledge Distillation via Dropout. (arXiv:2208.05642v1 [cs.CV])
16. PPMN: Pixel-Phrase Matching Network for One-Stage Panoptic Narrative Grounding. (arXiv:2208.05647v1 [cs.CV])
17. Diverse Generative Adversarial Perturbations on Attention Space for Transferable Adversarial Attacks. (arXiv:2208.05650v1 [cs.CV])
18. PA-Seg: Learning from Point Annotations for 3D Medical Image Segmentation using Contextual Regularization and Cross Knowledge Distillation. (arXiv:2208.05669v1 [cs.CV])
19. Semi-supervised Vision Transformers at Scale. (arXiv:2208.05688v1 [cs.CV])
20. General Cutting Planes for Bound-Propagation-Based Neural Network Verification. (arXiv:2208.05740v1 [cs.LG])
21. On the Pros and Cons of Momentum Encoder in Self-Supervised Visual Representation Learning. (arXiv:2208.05744v1 [cs.CV])
22. FD**NeRF**: Few-shot Dynamic Neural Radiance Fields for Face Reconstruction and Expression Editing. (arXiv:2208.05751v1 [cs.CV])
23. MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition. (arXiv:2208.05768v1 [cs.CV])
24. KiPA22 Report: U-Net with Contour Regularization for Renal Structures Segmentation. (arXiv:2208.05772v1 [eess.IV])
25. PSUMNet: Unified Modality Part Streams are All You Need for Efficient Pose-based Action Recognition. (arXiv:2208.05775v1 [cs.CV])
26. Neural Mesh-Based Graphics. (arXiv:2208.05785v1 [cs.CV])
27. Unsupervised Face Morphing Attack Detection via Self-paced Anomaly Detection. (arXiv:2208.05787v1 [cs.CV])
28. Semantic Self-adaptation: Enhancing Generalization with a Single Sample. (arXiv:2208.05788v1 [cs.CV])
29. Aesthetic Visual Question Answering of Photographs. (arXiv:2208.05798v1 [cs.CV])
30. Towards Sequence-Level Training for Visual Tracking. (arXiv:2208.05810v1 [cs.CV])
31. Seeing your sleep stage: cross-modal distillation from EEG to infrared video. (arXiv:2208.05814v1 [cs.CV])
32. Hybrid Transformer Network for Deepfake Detection. (arXiv:2208.05820v1 [cs.CV])
33. K-UNN: k-Space Interpolation With Untrained Neural Network. (arXiv:2208.05827v1 [cs.CV])
34. Joint reconstruction-segmentation on graphs. (arXiv:2208.05834v1 [cs.CV])
35. Differencing based Self-supervised pretraining for Scene Change Detection. (arXiv:2208.05838v1 [cs.CV])
36. A Comprehensive Analysis of AI Biases in DeepFake Detection With Massively Annotated Databases. (arXiv:2208.05845v1 [cs.CV])
37. MultiMatch: Multi-task Learning for Semi-supervised Domain Generalization. (arXiv:2208.05853v1 [cs.CV])
38. Face Morphing Attacks and Face Image Quality: The Effect of Morphing and the Unsupervised Attack Detection by Quality. (arXiv:2208.05864v1 [cs.CV])
39. TotalSegmentator: robust segmentation of 104 anatomical structures in CT images. (arXiv:2208.05868v1 [eess.IV])
40. Uncertainty-Aware Blob Detection with an Application to Integrated-Light Stellar Population Recoveries. (arXiv:2208.05881v1 [astro-ph.GA])
41. Optimal Transport Features for Morphometric Population Analysis. (arXiv:2208.05891v1 [cs.CV])
42. Heatmap Regression for Lesion Detection using Pointwise Annotations. (arXiv:2208.05939v1 [eess.IV])
43. PointTree: Transformation-Robust Point Cloud Encoder with Relaxed K-D Trees. (arXiv:2208.05962v1 [cs.CV])
44. RelPose: Predicting Probabilistic Relative Rotation for Single Objects in the Wild. (arXiv:2208.05963v1 [cs.CV])
45. Pancreas segmentation with probabilistic map guided bi-directional recurrent UNet. (arXiv:1903.00923v6 [cs.CV] UPDATED)
46. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v5 [cs.CV] UPDATED)
47. Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
48. The Work of Art in an Age of Mechanical Generation. (arXiv:2101.11587v2 [cs.CY] UPDATED)
49. Augmenting Deep Classifiers with Polynomial Neural Networks. (arXiv:2104.07916v2 [cs.CV] UPDATED)
50. End-to-end Temporal Action Detection with Transformer. (arXiv:2106.10271v4 [cs.CV] UPDATED)
51. Change is Everywhere: Single-Temporal Supervised Object Change Detection in Remote Sensing Imagery. (arXiv:2108.07002v2 [cs.CV] UPDATED)
52. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v6 [cs.CV] UPDATED)
53. Hierarchical Memory Learning for Fine-Grained Scene Graph Generation. (arXiv:2203.06907v4 [cs.CV] UPDATED)
54. Inferring topological transitions in pattern-forming processes with self-supervised learning. (arXiv:2203.10204v2 [cond-mat.mtrl-sci] UPDATED)
55. EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation. (arXiv:2203.13254v4 [cs.CV] UPDATED)
56. StretchBEV: Stretching Future Instance Prediction Spatially and Temporally. (arXiv:2203.13641v2 [cs.CV] UPDATED)
57. Recognition of polar lows in Sentinel-1 SAR images with deep learning. (arXiv:2203.16401v3 [cs.CV] UPDATED)
58. ProCST: Boosting Semantic Segmentation Using Progressive Cyclic Style-Transfer. (arXiv:2204.11891v2 [cs.CV] UPDATED)
59. Binarizing by Classification: Is soft function really necessary?. (arXiv:2205.07433v2 [cs.CV] UPDATED)
60. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v2 [cs.CV] UPDATED)
61. Prototypical Contrastive Language Image Pretraining. (arXiv:2206.10996v2 [cs.CV] UPDATED)
62. ExpansionNet: exploring the sequence length bottleneck in the Transformer for Image Captioning. (arXiv:2207.03327v2 [cs.CV] UPDATED)
63. A Study on Self-Supervised Object Detection Pretraining. (arXiv:2207.04186v2 [cs.CV] UPDATED)
64. Towards Grand Unification of Object Tracking. (arXiv:2207.07078v4 [cs.CV] UPDATED)
65. CACTUSS: Common Anatomical CT-US Space for US examinations. (arXiv:2207.08619v2 [eess.IV] UPDATED)
66. LR-Net: A Block-based Convolutional Neural Network for Low-Resolution Image Classification. (arXiv:2207.09531v3 [cs.CV] UPDATED)
67. Class-Aware Universum Inspired Re-Balance Learning for Long-Tailed Recognition. (arXiv:2207.12808v3 [cs.CV] UPDATED)
68. See What You See: Self-supervised Cross-modal Retrieval of Visual Stimuli from Brain Activity. (arXiv:2208.03666v3 [cs.MM] UPDATED)
69. Distinctive Image Captioning via CLIP Guided Group Optimization. (arXiv:2208.04254v3 [cs.CV] UPDATED)
70. RWSeg: Cross-graph Competing Random Walks for Weakly Supervised 3D Instance Segmentation. (arXiv:2208.05110v2 [cs.CV] UPDATED)
71. A Detection Method of Temporally Operated Videos Using Robust Hashing. (arXiv:2208.05198v2 [cs.CV] UPDATED)
72. Multi-scale Feature Aggregation for Crowd Counting. (arXiv:2208.05256v2 [cs.CV] UPDATED)
## eess.IV
---
**13** new papers in eess.IV:-) 
1. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v1 [eess.IV])
2. 4D Real-Time GRASP MRI at Sub-Second Temporal Resolution. (arXiv:2208.05508v1 [physics.med-ph])
3. Evaluating Generatively Synthesized Diabetic Retinopathy Imagery. (arXiv:2208.05593v1 [eess.IV])
4. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v1 [eess.IV])
5. KiPA22 Report: U-Net with Contour Regularization for Renal Structures Segmentation. (arXiv:2208.05772v1 [eess.IV])
6. TotalSegmentator: robust segmentation of 104 anatomical structures in CT images. (arXiv:2208.05868v1 [eess.IV])
7. Optimal Transport Features for Morphometric Population Analysis. (arXiv:2208.05891v1 [cs.CV])
8. Heatmap Regression for Lesion Detection using Pointwise Annotations. (arXiv:2208.05939v1 [eess.IV])
9. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v5 [cs.CV] UPDATED)
10. Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
11. Inverse Problem of Ultrasound Beamforming with Denoising-Based Regularized Solutions. (arXiv:2206.07926v2 [eess.IV] UPDATED)
12. Fast Low Rank column-wise Compressive Sensing for Accelerated Dynamic MRI. (arXiv:2206.13618v2 [eess.IV] UPDATED)
13. CACTUSS: Common Anatomical CT-US Space for US examinations. (arXiv:2207.08619v2 [eess.IV] UPDATED)
## cs.LG
---
**99** new papers in cs.LG:-) 
1. Customized Watermarking for Deep Neural Networks via Label Distribution Perturbation. (arXiv:2208.05477v1 [cs.CR])
2. High-Frequency Space Diffusion Models for Accelerated MRI. (arXiv:2208.05481v1 [eess.IV])
3. Modeling Diverse Chemical Reactions for Single-step Retrosynthesis via Discrete Latent Variables. (arXiv:2208.05482v1 [q-bio.QM])
4. Neural Embedding: Learning the Embedding of Manifold of Physics Data. (arXiv:2208.05484v1 [hep-ph])
5. Imbalance Trouble: Revisiting Neural-Collapse Geometry. (arXiv:2208.05512v1 [cs.LG])
6. Are Gradients on Graph Structure Reliable in Gray-box Attacks?. (arXiv:2208.05514v1 [cs.CR])
7. Quality Not Quantity: On the Interaction between Dataset Design and Robustness of CLIP. (arXiv:2208.05516v1 [cs.LG])
8. Semi-supervised segmentation of tooth from 3D Scanned Dental Arches. (arXiv:2208.05539v1 [cs.CV])
9. The Moral Foundations Reddit Corpus. (arXiv:2208.05545v1 [cs.CL])
10. SSDBCODI: Semi-Supervised Density-Based Clustering with Outliers Detection Integrated. (arXiv:2208.05561v1 [cs.LG])
11. Patching open-vocabulary models by interpolating weights. (arXiv:2208.05592v1 [cs.CV])
12. Finding Reusable Machine Learning Components to Build Programming Language Processing Pipelines. (arXiv:2208.05596v1 [cs.LG])
13. Multi-fidelity wavelet neural operator with application to uncertainty quantification. (arXiv:2208.05606v1 [cs.LG])
14. Polynomial Optimization: Enhancing RLT relaxations with Conic Constraints. (arXiv:2208.05608v1 [math.OC])
15. OpenMedIA: Open-Source Medical Image Analysis Toolbox and Benchmark under Heterogeneous AI Computing Platforms. (arXiv:2208.05616v1 [eess.IV])
16. Regret Analysis for Hierarchical Experts Bandit Problem. (arXiv:2208.05622v1 [cs.LG])
17. Quantized Adaptive Subgradient Algorithms and Their Applications. (arXiv:2208.05631v1 [cs.LG])
18. Best Policy Identification in Linear MDPs. (arXiv:2208.05633v1 [cs.LG])
19. Scalable neural quantum states architecture for quantum chemistry. (arXiv:2208.05637v1 [physics.chem-ph])
20. Solving MathWord Problems Automatically with Heterogeneous Line Graph Transformer for Online Learning. (arXiv:2208.05645v1 [cs.LG])
21. Embedding Compression with Hashing for Efficient Representation Learning in Large-Scale Graph. (arXiv:2208.05648v1 [cs.LG])
22. Goodness of Fit Metrics for Multi-class Predictor. (arXiv:2208.05651v1 [cs.LG])
23. A Principled Method for the Creation of Synthetic Multi-fidelity Data Sets. (arXiv:2208.05667v1 [stat.ML])
24. Semi-supervised Vision Transformers at Scale. (arXiv:2208.05688v1 [cs.CV])
25. Learning Based Joint Coding-Modulation for Digital Semantic Communication Systems. (arXiv:2208.05704v1 [cs.IT])
26. A Model of Anaphoric Ambiguities using Sheaf Theoretic Quantum-like Contextuality and BERT. (arXiv:2208.05720v1 [cs.CL])
27. Word-Embeddings Distinguish Denominal and Root-Derived Verbs in Semitic. (arXiv:2208.05721v1 [cs.CL])
28. Learning Point Processes using Recurrent Graph Network. (arXiv:2208.05736v1 [cs.LG])
29. A Modified UDP for Federated Learning Packet Transmissions. (arXiv:2208.05737v1 [cs.NI])
30. General Cutting Planes for Bound-Propagation-Based Neural Network Verification. (arXiv:2208.05740v1 [cs.LG])
31. Interpretable cytometry cell-type annotation with flow-based deep generative models. (arXiv:2208.05745v1 [q-bio.QM])
32. Distributionally Robust Model-Based Offline Reinforcement Learning with Near-Optimal Sample Complexity. (arXiv:2208.05767v1 [cs.LG])
33. KiPA22 Report: U-Net with Contour Regularization for Renal Structures Segmentation. (arXiv:2208.05772v1 [eess.IV])
34. Neural Networks for Scalar Input and Functional Output. (arXiv:2208.05776v1 [stat.ML])
35. Path-aware Siamese Graph Neural Network for Link Prediction. (arXiv:2208.05781v1 [cs.LG])
36. Comparison and Analysis of New Curriculum Criteria for End-to-End ASR. (arXiv:2208.05782v1 [eess.AS])
37. Empirical investigations on WVA structural issues. (arXiv:2208.05791v1 [cs.LG])
38. Regressing Relative Fine-Grained Change for Sub-Groups in Unreliable Heterogeneous Data Through Deep Multi-Task Metric Learning. (arXiv:2208.05800v1 [cs.LG])
39. Towards Sequence-Level Training for Visual Tracking. (arXiv:2208.05810v1 [cs.CV])
40. Speech **Enhancement** and Dereverberation with Diffusion-based Generative Models. (arXiv:2208.05830v1 [eess.AS])
41. HyperTime: Implicit Neural Representation for Time Series. (arXiv:2208.05836v1 [cs.LG])
42. Adaptively Identifying Patient Populations With Treatment Benefit in Clinical Trials. (arXiv:2208.05844v1 [stat.ML])
43. A Comprehensive Analysis of AI Biases in DeepFake Detection With Massively Annotated Databases. (arXiv:2208.05845v1 [cs.CV])
44. Language Tokens: A Frustratingly Simple Approach Improves Zero-Shot Performance of Multilingual Translation. (arXiv:2208.05852v1 [cs.CL])
45. Predicting Tornadoes days ahead with Machine Learning. (arXiv:2208.05855v1 [cs.LG])
46. GEM-2: Next Generation Molecular Property Prediction Network with Many-body and Full-range Interaction Modeling. (arXiv:2208.05863v1 [cs.LG])
47. Uncertainty Quantification for Traffic Forecasting: A Unified Approach. (arXiv:2208.05875v1 [cs.LG])
48. Super-Universal Regularized Newton Method. (arXiv:2208.05888v1 [math.OC])
49. Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks. (arXiv:2208.05908v1 [cs.LG])
50. Machine learning in front of statistical methods for prediction spread SARS-CoV-2 in Colombia. (arXiv:2208.05910v1 [physics.soc-ph])
51. Regularizing Deep Neural Networks with Stochastic Estimators of Hessian Trace. (arXiv:2208.05924v1 [cs.LG])
52. Near-Optimal Algorithms for Making the Gradient Small in Stochastic Minimax Optimization. (arXiv:2208.05925v1 [cs.LG])
53. Heatmap Regression for Lesion Detection using Pointwise Annotations. (arXiv:2208.05939v1 [eess.IV])
54. Valid Inference after Causal Discovery. (arXiv:2208.05949v1 [stat.ME])
55. Interactive Code Generation via Test-Driven User-Intent Formalization. (arXiv:2208.05950v1 [cs.SE])
56. Partition Pooling for Convolutional Graph Network Applications in Particle Physics. (arXiv:2208.05952v1 [hep-ex])
57. PointTree: Transformation-Robust Point Cloud Encoder with Relaxed K-D Trees. (arXiv:2208.05962v1 [cs.CV])
58. RelPose: Predicting Probabilistic Relative Rotation for Single Objects in the Wild. (arXiv:2208.05963v1 [cs.CV])
59. Explaining Machine Learning Models using Entropic Variable Projection. (arXiv:1810.07924v6 [stat.ML] UPDATED)
60. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v5 [cs.CV] UPDATED)
61. Achieving Fairness via Post-Processing in Web-Scale Recommender Systems. (arXiv:2006.11350v3 [stat.ML] UPDATED)
62. Distributionally Robust Losses for Latent Covariate Mixtures. (arXiv:2007.13982v2 [cs.LG] UPDATED)
63. Simple and optimal methods for stochastic variational inequalities, I: operator extrapolation. (arXiv:2011.02987v4 [math.OC] UPDATED)
64. Effects of Image Size on Deep Learning. (arXiv:2101.11508v5 [cs.CV] UPDATED)
65. Social Norm Bias: Residual Harms of Fairness-Aware Algorithms. (arXiv:2108.11056v3 [cs.LG] UPDATED)
66. Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data. (arXiv:2109.07117v5 [cs.LG] UPDATED)
67. Connecting Low-Loss Subspace for Personalized Federated Learning. (arXiv:2109.07628v3 [cs.LG] UPDATED)
68. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v6 [cs.CV] UPDATED)
69. Learning Topic Models: Identifiability and Finite-Sample Analysis. (arXiv:2110.04232v2 [stat.ML] UPDATED)
70. Off-Policy Actor-Critic with Emphatic Weightings. (arXiv:2111.08172v2 [cs.LG] UPDATED)
71. The Geometry of Robust Value Functions. (arXiv:2201.12929v2 [cs.LG] UPDATED)
72. CoCoFL: Communication- and Computation-Aware Federated Learning via Partial NN Freezing and Quantization. (arXiv:2203.05468v2 [cs.LG] UPDATED)
73. Inferring topological transitions in pattern-forming processes with self-supervised learning. (arXiv:2203.10204v2 [cond-mat.mtrl-sci] UPDATED)
74. StretchBEV: Stretching Future Instance Prediction Spatially and Temporally. (arXiv:2203.13641v2 [cs.CV] UPDATED)
75. Low-complexity Near-optimum Symbol Detection Based on Neural **Enhancement** of Factor Graphs. (arXiv:2203.16417v2 [cs.IT] UPDATED)
76. Learning List-wise Representation in Reinforcement Learning for Ads Allocation with Multiple Auxiliary Tasks. (arXiv:2204.00888v3 [cs.LG] UPDATED)
77. On Convergence Lemma and Convergence Stability for Piecewise Analytic Functions. (arXiv:2204.01643v3 [cs.GT] UPDATED)
78. Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v3 [stat.ML] UPDATED)
79. Hybrid Transfer in Deep Reinforcement Learning for Ads Allocation. (arXiv:2204.11589v3 [cs.IR] UPDATED)
80. ProCST: Boosting Semantic Segmentation Using Progressive Cyclic Style-Transfer. (arXiv:2204.11891v2 [cs.CV] UPDATED)
81. DECONET: an Unfolding Network for Analysis-based Compressed Sensing with Generalization Error Estimates. (arXiv:2205.07050v4 [cs.IT] UPDATED)
82. Fast variable selection makes Karhunen-Lo\`eve decomposed Gaussian process BSS-ANOVA a speedy and accurate choice for dynamic systems identification. (arXiv:2205.13676v2 [cs.LG] UPDATED)
83. Neural Decoding with Optimization of Node Activations. (arXiv:2206.00786v2 [cs.IT] UPDATED)
84. Three-dimensional microstructure generation using generative adversarial neural networks in the context of continuum micromechanics. (arXiv:2206.01693v3 [cond-mat.mtrl-sci] UPDATED)
85. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v2 [cs.CV] UPDATED)
86. Learning to Order for Inventory Systems with Lost Sales and Uncertain Supplies. (arXiv:2207.04550v2 [math.OC] UPDATED)
87. Latent Variable Models for Bayesian Causal Discovery. (arXiv:2207.05723v2 [cs.LG] UPDATED)
88. Multi-Objective Provisioning of Network Slices using Deep Reinforcement Learning. (arXiv:2207.13821v3 [cs.NI] UPDATED)
89. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v3 [cs.CL] UPDATED)
90. GeoECG: Data Augmentation via Wasserstein Geodesic Perturbation for Robust Electrocardiogram Prediction. (arXiv:2208.01220v2 [stat.ML] UPDATED)
91. Modeling Price Elasticity for Occupancy Prediction in Hotel Dynamic Pricing. (arXiv:2208.03135v2 [econ.GN] UPDATED)
92. A Visual Analytics System for Improving Attention-based Traffic Forecasting Models. (arXiv:2208.04350v2 [cs.HC] UPDATED)
93. Optimal scheduling of entropy regulariser for continuous-time linear-quadratic reinforcement learning. (arXiv:2208.04466v2 [cs.LG] UPDATED)
94. Applying data technologies to combat AMR: current status, challenges, and opportunities on the way forward. (arXiv:2208.04683v2 [cs.CY] UPDATED)
95. Clustering Optimisation Method for Highly Connected Biological Data. (arXiv:2208.04720v2 [q-bio.QM] UPDATED)
96. On the Activation Function Dependence of the Spectral Bias of Neural Networks. (arXiv:2208.04924v2 [cs.LG] UPDATED)
97. Controlling Perceived Emotion in Symbolic Music Generation with Monte Carlo Tree Search. (arXiv:2208.05162v2 [cs.SD] UPDATED)
98. Fast Offline Policy Optimization for Large Scale Recommendation. (arXiv:2208.05327v2 [cs.IR] UPDATED)
99. EFI: A Toolbox for Feature Importance Fusion and Interpretation in Python. (arXiv:2208.04343v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**43** new papers in cs.AI:-) 
1. Sequence Feature Extraction for Malware Family Analysis via Graph Neural Network. (arXiv:2208.05476v1 [cs.CR])
2. Augmented Driver Behavior Models for High-Fidelity Simulation Study of Crash Detection Algorithms. (arXiv:2208.05540v1 [cs.MA])
3. SSDBCODI: Semi-Supervised Density-Based Clustering with Outliers Detection Integrated. (arXiv:2208.05561v1 [cs.LG])
4. What's on your mind? A Mental and Perceptual Load Estimation Framework towards Adaptive In-vehicle Interaction while Driving. (arXiv:2208.05564v1 [cs.HC])
5. The emergence of division of labor through decentralized social sanctioning. (arXiv:2208.05568v1 [cs.MA])
6. Memorizing Complementation Network for Few-Shot Class-Incremental Learning. (arXiv:2208.05610v1 [cs.CV])
7. FIGO: Enhanced Fingerprint Identification Approach Using GAN and One Shot Learning Techniques. (arXiv:2208.05615v1 [cs.CV])
8. SignalKG: Towards reasoning about the underlying causes of sensor observations. (arXiv:2208.05627v1 [cs.AI])
9. Quantized Adaptive Subgradient Algorithms and Their Applications. (arXiv:2208.05631v1 [cs.LG])
10. Visual Haptic Reasoning: Estimating Contact Forces by Observing Deformable Object Interactions. (arXiv:2208.05632v1 [cs.RO])
11. Adaptive and Implicit Regularization for Matrix Completion. (arXiv:2208.05640v1 [cs.CV])
12. Solving MathWord Problems Automatically with Heterogeneous Line Graph Transformer for Online Learning. (arXiv:2208.05645v1 [cs.LG])
13. Embedding Compression with Hashing for Efficient Representation Learning in Large-Scale Graph. (arXiv:2208.05648v1 [cs.LG])
14. Semi-supervised Vision Transformers at Scale. (arXiv:2208.05688v1 [cs.CV])
15. ROC: A New Paradigm for Lyric-to-Melody Generation. (arXiv:2208.05697v1 [cs.SD])
16. Cine-AI: Generating Video Game Cutscenes in the Style of Human Directors. (arXiv:2208.05701v1 [cs.HC])
17. A Model of Anaphoric Ambiguities using Sheaf Theoretic Quantum-like Contextuality and BERT. (arXiv:2208.05720v1 [cs.CL])
18. Word-Embeddings Distinguish Denominal and Root-Derived Verbs in Semitic. (arXiv:2208.05721v1 [cs.CL])
19. Learning Point Processes using Recurrent Graph Network. (arXiv:2208.05736v1 [cs.LG])
20. A Modified UDP for Federated Learning Packet Transmissions. (arXiv:2208.05737v1 [cs.NI])
21. The dynamics of belief: continuously monitoring and visualising complex systems. (arXiv:2208.05764v1 [cs.AI])
22. Path-aware Siamese Graph Neural Network for Link Prediction. (arXiv:2208.05781v1 [cs.LG])
23. Regressing Relative Fine-Grained Change for Sub-Groups in Unreliable Heterogeneous Data Through Deep Multi-Task Metric Learning. (arXiv:2208.05800v1 [cs.LG])
24. Seeing your sleep stage: cross-modal distillation from EEG to infrared video. (arXiv:2208.05814v1 [cs.CV])
25. Speech Synthesis with Mixed Emotions. (arXiv:2208.05890v1 [cs.CL])
26. Shielding Federated Learning Systems against Inference Attacks with ARM TrustZone. (arXiv:2208.05895v1 [cs.CR])
27. Simple and optimal methods for stochastic variational inequalities, I: operator extrapolation. (arXiv:2011.02987v4 [math.OC] UPDATED)
28. The Work of Art in an Age of Mechanical Generation. (arXiv:2101.11587v2 [cs.CY] UPDATED)
29. Social Norm Bias: Residual Harms of Fairness-Aware Algorithms. (arXiv:2108.11056v3 [cs.LG] UPDATED)
30. Connecting Low-Loss Subspace for Personalized Federated Learning. (arXiv:2109.07628v3 [cs.LG] UPDATED)
31. Deep Reinforcement Learning for Wireless Scheduling in Distributed Networked Control. (arXiv:2109.12562v2 [eess.SY] UPDATED)
32. DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation. (arXiv:2110.02711v6 [cs.CV] UPDATED)
33. On Convergence Lemma and Convergence Stability for Piecewise Analytic Functions. (arXiv:2204.01643v3 [cs.GT] UPDATED)
34. Diagnosing and Fixing Manifold Overfitting in Deep Generative Models. (arXiv:2204.07172v3 [stat.ML] UPDATED)
35. ProCST: Boosting Semantic Segmentation Using Progressive Cyclic Style-Transfer. (arXiv:2204.11891v2 [cs.CV] UPDATED)
36. Binarizing by Classification: Is soft function really necessary?. (arXiv:2205.07433v2 [cs.CV] UPDATED)
37. Neural Decoding with Optimization of Node Activations. (arXiv:2206.00786v2 [cs.IT] UPDATED)
38. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v2 [cs.CV] UPDATED)
39. Latent Variable Models for Bayesian Causal Discovery. (arXiv:2207.05723v2 [cs.LG] UPDATED)
40. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v3 [cs.CL] UPDATED)
41. Applying data technologies to combat AMR: current status, challenges, and opportunities on the way forward. (arXiv:2208.04683v2 [cs.CY] UPDATED)
42. Fast Offline Policy Optimization for Large Scale Recommendation. (arXiv:2208.05327v2 [cs.IR] UPDATED)
43. Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services. (arXiv:2208.05438v2 [cs.AI] UPDATED)

