# Your interest papers
---
## cs.CV
---
### Ghost-free **High Dynamic Range** Imaging with Context-aware Transformer. (arXiv:2208.05114v1 [cs.CV])
- Authors : Zhen Liu, Yinglong Wang, Bing Zeng, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2208.05114](http://arxiv.org/abs/2208.05114)
> ABSTRACT  :  **High dynamic range** (**HDR**) **deghosting** algorithms aim to generate ghost-free **HDR** images with realistic details. Restricted by the locality of the receptive field, existing CNN-based methods are typically prone to producing ghosting artifacts and intensity distortions in the presence of large motion and severe saturation. In this paper, we propose a novel Context-Aware Vision Transformer (CA-ViT) for ghost-free **high dynamic range** imaging. The CA-ViT is designed as a dual-branch architecture, which can jointly capture both global and local dependencies. Specifically, the global branch employs a window-based Transformer encoder to model long-range object movements and intensity variations to solve ghosting. For the local branch, we design a local context extractor (LCE) to capture short-range image features and use the channel attention mechanism to select informative local details across the extracted features to complement the global branch. By incorporating the CA-ViT as basic components, we further build the **HDR**-Transformer, a hierarchical network to reconstruct high-quality ghost-free **HDR** images. Extensive experiments on three benchmark datasets show that our approach outperforms state-of-the-art methods qualitatively and quantitatively with considerably reduced computational budgets. Codes are available at https://github.com/megvii-research/**HDR**-Transformer  
### Learning Degradation Representations for Image Deblurring. (arXiv:2208.05244v1 [cs.CV])
- Authors : Dasong Li, Yi Zhang, Ka Chun, Xiaogang Wang, Hongwei Qin, Hongsheng Li
- Link : [http://arxiv.org/abs/2208.05244](http://arxiv.org/abs/2208.05244)
> ABSTRACT  :  In various learning-based image **restoration** tasks, such as image denoising and image super-resolution, the degradation representations were widely used to model the degradation process and handle complicated degradation patterns. However, they are less explored in learning-based image deblurring as blur kernel estimation cannot perform well in real-world challenging cases. We argue that it is particularly necessary for image deblurring to model degradation representations since blurry patterns typically show much larger variations than noisy patterns or high-frequency textures.In this paper, we propose a framework to learn spatially adaptive degradation representations of blurry images. A novel joint image reblurring and deblurring learning process is presented to improve the expressiveness of degradation representations. To make learned degradation representations effective in reblurring and deblurring, we propose a Multi-Scale Degradation Injection Network (MSDI-Net) to integrate them into the neural networks. With the integration, MSDI-Net can handle various and complicated blurry patterns adaptively. Experiments on the GoPro and RealBlur datasets demonstrate that our proposed deblurring framework with the learned degradation representations outperforms state-of-the-art methods with appealing improvements. The code is released at https://github.com/dasongli1/Learning_degradation.  
### Multi-scale Feature Aggregation for Crowd Counting. (arXiv:2208.05256v1 [cs.CV])
- Authors : Xiaoheng Jiang, Xinyi Wu, Hisham Cholakkal, Rao Muhammad, Jiale Cao, Mingliang Xu, Bing Zhou, Yanwei Pang, Fahad Shahbaz
- Link : [http://arxiv.org/abs/2208.05256](http://arxiv.org/abs/2208.05256)
> ABSTRACT  :  Convolutional Neural Network (CNN) based crowd counting methods have achieved promising results in the past few years. However, the scale variation problem is still a huge challenge for accurate count estimation. In this paper, we propose a multi-scale feature aggregation network (MSFANet) that can alleviate this problem to some extent. Specifically, our approach consists of two feature aggregation modules: the short aggregation (ShortAgg) and the skip aggregation (SkipAgg). The ShortAgg module aggregates the features of the adjacent convolution blocks. Its purpose is to make features with different receptive fields fused gradually from the bottom to the top of the network. The SkipAgg module directly propagates features with small receptive fields to features with much larger receptive fields. Its purpose is to promote the fusion of features with small and large receptive fields. Especially, the SkipAgg module introduces the local self-attention features from the **Swin** Transformer blocks to incorporate rich spatial information. Furthermore, we present a local-and-global based counting loss by considering the non-uniform crowd distribution. Extensive experiments on four challenging datasets (ShanghaiTech dataset, UCF_CC_50 dataset, UCF-QNRF Dataset, WorldExpo'10 dataset) demonstrate the proposed easy-to-implement MSFANet can achieve promising results when compared with the previous state-of-the-art approaches.  
### Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
- Authors : Wangmeng Xiang, Chao Li, Yuxuan Zhou, Biao Wang, **Lei Zhang**
- Link : [http://arxiv.org/abs/2208.05318](http://arxiv.org/abs/2208.05318)
> ABSTRACT  :  Skeleton-based action recognition has drawn a lot of attention for its computation efficiency and robustness to lighting conditions. Existing skeleton-based action recognition methods are typically formulated as a one-hot classification task without fully utilizing the semantic relations between actions. For example, "make victory sign" and "thumb up" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled in the language description of actions. Therefore, utilizing action language descriptions in training could potentially benefit representation learning. In this work, we propose a Language Supervised Training (LST) approach for skeleton-based action recognition. More specifically, we employ a large-scale language model as the knowledge engine to provide text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder to generate feature vectors for different body parts and supervise the skeleton encoder for action representation learning. Experiments show that our proposed LST method achieves noticeable improvements over various baseline models without extra computation cost at inference. LST achieves new state-of-the-arts on popular skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and NW-UCLA. The code can be found at https://github.com/MartinXM/LST.  
### Benchmarking Joint Face Spoofing and Forgery Detection with Visual and Physiological Cues. (arXiv:2208.05401v1 [cs.CV])
- Authors : Zitong Yu, Rizhao Cai, Zhi Li, **Wenhan Yang**, Jingang Shi
- Link : [http://arxiv.org/abs/2208.05401](http://arxiv.org/abs/2208.05401)
> ABSTRACT  :  Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite promising performance upon large-scale data and powerful deep models, the generalization problem of existing approaches is still an open issue. Most of recent approaches focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized face attack detection. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.  
### Continuous **Exposure** for Extreme **Low-Light** Imaging. (arXiv:2012.04112v2 [eess.IV] UPDATED)
- Authors : Evgeny Hershkovitch, Michael Klyuchka, Gil Ben
- Link : [http://arxiv.org/abs/2012.04112](http://arxiv.org/abs/2012.04112)
> ABSTRACT  :  We consider the problem of enhancing an underexposed **dark** image captured in a very **low-light** environment where details cannot be detected. Existing methods learn to adjust the input image's **exposure** to a predetermined value. In practice, however, the optimal enhanced **exposure** varies from one input image to another, and as a result, the enhanced images may contain visual artifacts such as low-contrast or **dark** areas. We address this limitation by introducing a deep learning model that allows the user to continuously adjust the enhanced **exposure** level during runtime in order to optimize the output based on his preferences. We present a dataset of 1500 raw images captured in both outdoor and indoor scenes in extreme **low-light** conditions, with five different **exposure** levels and various camera parameters, as a key contribution. We demonstrate that, when compared to previous methods, our method can significantly improve the **enhancement** quality of images captured in extreme **low-light** conditions under a variety of conditions.  
### **NeRF**ocus: Neural Radiance Field for 3D Synthetic Defocus. (arXiv:2203.05189v2 [cs.CV] UPDATED)
- Authors : Yinhuai Wang, Shuzhou Yang, Yujie Hu, Jian Zhang
- Link : [http://arxiv.org/abs/2203.05189](http://arxiv.org/abs/2203.05189)
> ABSTRACT  :  Neural radiance fields (**NeRF**) bring a new wave for 3D interactive experiences. However, as an important part of the immersive experiences, the defocus effects have not been fully explored within **NeRF**. Some recent **NeRF**-based methods generate 3D defocus effects in a post-process fashion by utilizing multiplane technology. Still, they are either time-consuming or memory-consuming. This paper proposes a novel thin-lens-imaging-based **NeRF** framework that can directly render various 3D defocus effects, dubbed **NeRF**ocus. Unlike the pinhole, the thin lens refracts rays of a scene point, so its imaging on the sensor plane is scattered as a circle of confusion (CoC). A direct solution sampling enough rays to approximate this process is computationally expensive. Instead, we propose to inverse the thin lens imaging to explicitly model the beam path for each point on the sensor plane and generalize this paradigm to the beam path of each pixel, then use the frustum-based volume rendering to render each pixel's beam path. We further design an efficient probabilistic training (p-training) strategy to simplify the training process vastly. Extensive experiments demonstrate that our **NeRF**ocus can achieve various 3D defocus effects with adjustable camera pose, focus distance, and aperture size. Existing **NeRF** can be regarded as our special case by setting aperture size as zero to render large depth-of-field images. Despite such merits, **NeRF**ocus does not sacrifice **NeRF**'s original performance (e.g., training and inference time, parameter consumption, rendering quality), which implies its great potential for broader application and further improvement. Code and video are available at https://github.com/wyhuai/**NeRF**ocus.  
## eess.IV
---
### Quantum artificial vision for defect detection in manufacturing. (arXiv:2208.04988v1 [quant-ph])
- Authors : Daniel Guijo, Victor Onofre, Gianni Del, Samuel Mugel, Daniel Estepa, Xabier De, Ana Adell, Aizea Lojo, Josu Bilbao, Roman Orus
- Link : [http://arxiv.org/abs/2208.04988](http://arxiv.org/abs/2208.04988)
> ABSTRACT  :  In this paper we consider several algorithms for quantum computer vision using Noisy Intermediate-Scale Quantum (NISQ) devices, and benchmark them for a real problem against their classical counterparts. Specifically, we consider two approaches: a quantum Support Vector Machine (QSVM) on a universal gate-based quantum computer, and QBoost on a quantum annealer. The quantum vision systems are benchmarked for an unbalanced dataset of images where the aim is to detect defects in manufactured car pieces. We see that the quantum algorithms outperform their classical counterparts in several ways, with QBoost allowing for larger problems to be analyzed with present-day quantum annealers. Data preprocessing, including dimensionality reduction and contrast **enhancement**, is also discussed, as well as hyperparameter tuning in QBoost. To the best of our knowledge, this is the first implementation of quantum computer vision systems for a problem of industrial relevance in a manufacturing production line.  
### Continuous **Exposure** for Extreme **Low-Light** Imaging. (arXiv:2012.04112v2 [eess.IV] UPDATED)
- Authors : Evgeny Hershkovitch, Michael Klyuchka, Gil Ben
- Link : [http://arxiv.org/abs/2012.04112](http://arxiv.org/abs/2012.04112)
> ABSTRACT  :  We consider the problem of enhancing an underexposed **dark** image captured in a very **low-light** environment where details cannot be detected. Existing methods learn to adjust the input image's **exposure** to a predetermined value. In practice, however, the optimal enhanced **exposure** varies from one input image to another, and as a result, the enhanced images may contain visual artifacts such as low-contrast or **dark** areas. We address this limitation by introducing a deep learning model that allows the user to continuously adjust the enhanced **exposure** level during runtime in order to optimize the output based on his preferences. We present a dataset of 1500 raw images captured in both outdoor and indoor scenes in extreme **low-light** conditions, with five different **exposure** levels and various camera parameters, as a key contribution. We demonstrate that, when compared to previous methods, our method can significantly improve the **enhancement** quality of images captured in extreme **low-light** conditions under a variety of conditions.  
## cs.LG
---
### Quantum artificial vision for defect detection in manufacturing. (arXiv:2208.04988v1 [quant-ph])
- Authors : Daniel Guijo, Victor Onofre, Gianni Del, Samuel Mugel, Daniel Estepa, Xabier De, Ana Adell, Aizea Lojo, Josu Bilbao, Roman Orus
- Link : [http://arxiv.org/abs/2208.04988](http://arxiv.org/abs/2208.04988)
> ABSTRACT  :  In this paper we consider several algorithms for quantum computer vision using Noisy Intermediate-Scale Quantum (NISQ) devices, and benchmark them for a real problem against their classical counterparts. Specifically, we consider two approaches: a quantum Support Vector Machine (QSVM) on a universal gate-based quantum computer, and QBoost on a quantum annealer. The quantum vision systems are benchmarked for an unbalanced dataset of images where the aim is to detect defects in manufactured car pieces. We see that the quantum algorithms outperform their classical counterparts in several ways, with QBoost allowing for larger problems to be analyzed with present-day quantum annealers. Data preprocessing, including dimensionality reduction and contrast **enhancement**, is also discussed, as well as hyperparameter tuning in QBoost. To the best of our knowledge, this is the first implementation of quantum computer vision systems for a problem of industrial relevance in a manufacturing production line.  
### CoViT: **Real-time** phylogenetics for the SARS-CoV-2 pandemic using Vision Transformers. (arXiv:2208.05004v1 [cs.LG])
- Authors : Zuher Jahshan, Leonid Yavits
- Link : [http://arxiv.org/abs/2208.05004](http://arxiv.org/abs/2208.05004)
> ABSTRACT  :  **Real-time** viral genome detection, taxonomic classification and phylogenetic analysis are critical for efficient tracking and control of viral pandemics such as Covid-19. However, the unprecedented and still growing amounts of viral genome data create a computational bottleneck, which effectively prevents the real-time pandemic tracking. We are attempting to alleviate this bottleneck by modifying and applying Vision Transformer, a recently developed neural network model for image recognition, to taxonomic classification and placement of viral genomes, such as SARS-CoV-2. Our solution, CoViT, places newly acquired samples onto the tree of SARS-CoV-2 lineages. One of the two potential placements returned by CoVit is the true one with the probability of 99.0%. The probability of the correct placement to be found among five potential placements generated by CoViT is 99.8%. The placement time is 1.45ms per individual genome running on NVIDIAs GeForce RTX 2080 Ti GPU. We make CoViT available to research community through GitHub: https://github.com/zuherJahshan/covit.  
### Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
- Authors : Wangmeng Xiang, Chao Li, Yuxuan Zhou, Biao Wang, **Lei Zhang**
- Link : [http://arxiv.org/abs/2208.05318](http://arxiv.org/abs/2208.05318)
> ABSTRACT  :  Skeleton-based action recognition has drawn a lot of attention for its computation efficiency and robustness to lighting conditions. Existing skeleton-based action recognition methods are typically formulated as a one-hot classification task without fully utilizing the semantic relations between actions. For example, "make victory sign" and "thumb up" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled in the language description of actions. Therefore, utilizing action language descriptions in training could potentially benefit representation learning. In this work, we propose a Language Supervised Training (LST) approach for skeleton-based action recognition. More specifically, we employ a large-scale language model as the knowledge engine to provide text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder to generate feature vectors for different body parts and supervise the skeleton encoder for action representation learning. Experiments show that our proposed LST method achieves noticeable improvements over various baseline models without extra computation cost at inference. LST achieves new state-of-the-arts on popular skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and NW-UCLA. The code can be found at https://github.com/MartinXM/LST.  
### Self-Supervised Learning from Contrastive Mixtures for Personalized Speech **Enhancement**. (arXiv:2011.03426v2 [eess.AS] UPDATED)
- Authors : Aswin Sivaraman, Minje Kim
- Link : [http://arxiv.org/abs/2011.03426](http://arxiv.org/abs/2011.03426)
> ABSTRACT  :  This work explores how self-supervised learning can be universally used to discover speaker-specific features towards enabling personalized speech **enhancement** models. We specifically address the few-shot learning scenario where access to cleaning recordings of a test-time speaker is limited to a few seconds, but noisy recordings of the speaker are abundant. We develop a simple contrastive learning procedure which treats the abundant noisy data as makeshift training targets through pairwise noise injection: the model is pretrained to maximize agreement between pairs of differently deformed identical utterances and to minimize agreement between pairs of similarly deformed nonidentical utterances. Our experiments compare the proposed pretraining approach with two baseline alternatives: speaker-agnostic fully-supervised pretraining, and speaker-specific self-supervised pretraining without contrastive loss terms. Of all three approaches, the proposed method using contrastive mixtures is found to be most robust to model compression (using 85% fewer parameters) and reduced clean speech (requiring only 3 seconds).  
### Online Learning in Fisher Markets: Static Pricing Limits and Adaptive **Enhancement**s. (arXiv:2205.00825v2 [cs.GT] UPDATED)
- Authors : Devansh Jalota, Yinyu Ye
- Link : [http://arxiv.org/abs/2205.00825](http://arxiv.org/abs/2205.00825)
> ABSTRACT  :  In a Fisher market, agents (users) spend a budget of (artificial) currency to buy goods that maximize their utilities while a central planner sets prices on capacity-constrained goods such that the market clears. However, the efficacy of pricing schemes in achieving an equilibrium outcome in Fisher markets typically relies on complete knowledge of users' budgets and utilities and requires that transactions happen in a static market wherein all users are present simultaneously.    As a result, we study an online variant of Fisher markets, wherein budget-constrained users with privately known utility and budget parameters, drawn i.i.d. from a distribution $\mathcal{D}$, enter the market sequentially. In this setting, we develop an algorithm that adjusts prices solely based on observations of user consumption, i.e., revealed preference feedback, and achieves a regret and capacity violation of $O(\sqrt{n})$, where $n$ is the number of users and the good capacities scale as $O(n)$. Here, our regret measure is the optimality gap in the objective of the Eisenberg-Gale program between an online algorithm and an offline oracle with complete information on users' budgets and utilities. To establish the efficacy of our approach, we show that any uniform (static) pricing algorithm, including one that sets expected equilibrium prices with complete knowledge of the distribution $\mathcal{D}$, cannot achieve both a regret and constraint violation of less than $\Omega(\sqrt{n})$. While our revealed preference algorithm requires no knowledge of the distribution $\mathcal{D}$, we show that if $\mathcal{D}$ is known, then an adaptive variant of expected equilibrium pricing achieves $O(\log(n))$ regret and constant capacity violation for discrete distributions. Finally, we present numerical experiments to demonstrate the performance of our revealed preference algorithm relative to several benchmarks.  
## cs.AI
---
### Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
- Authors : Wangmeng Xiang, Chao Li, Yuxuan Zhou, Biao Wang, **Lei Zhang**
- Link : [http://arxiv.org/abs/2208.05318](http://arxiv.org/abs/2208.05318)
> ABSTRACT  :  Skeleton-based action recognition has drawn a lot of attention for its computation efficiency and robustness to lighting conditions. Existing skeleton-based action recognition methods are typically formulated as a one-hot classification task without fully utilizing the semantic relations between actions. For example, "make victory sign" and "thumb up" are two actions of hand gestures, whose major difference lies in the movement of hands. This information is agnostic from the categorical one-hot encoding of action classes but could be unveiled in the language description of actions. Therefore, utilizing action language descriptions in training could potentially benefit representation learning. In this work, we propose a Language Supervised Training (LST) approach for skeleton-based action recognition. More specifically, we employ a large-scale language model as the knowledge engine to provide text descriptions for body parts movements of actions, and propose a multi-modal training scheme by utilizing the text encoder to generate feature vectors for different body parts and supervise the skeleton encoder for action representation learning. Experiments show that our proposed LST method achieves noticeable improvements over various baseline models without extra computation cost at inference. LST achieves new state-of-the-arts on popular skeleton-based action recognition benchmarks, including NTU RGB+D, NTU RGB+D 120 and NW-UCLA. The code can be found at https://github.com/MartinXM/LST.  
# Paper List
---
## cs.CV
---
**66** new papers in cs.CV:-) 
1. U-Net vs Transformer: Is U-Net Outdated in Medical Image Registration?. (arXiv:2208.04939v1 [eess.IV])
2. Multi-Depth Boundary-Aware Left Atrial Scar Segmentation Network. (arXiv:2208.04940v1 [eess.IV])
3. Learning from imperfect training data using a robust loss function: application to brain image segmentation. (arXiv:2208.04941v1 [eess.IV])
4. Visual Heart Rate Estimation from RGB Facial Video using Spectral Reflectance. (arXiv:2208.04947v1 [cs.CV])
5. BabyNet: A Lightweight Network for Infant Reaching Action Recognition in Unconstrained Environments to Support Future Pediatric Rehabilitation Applications. (arXiv:2208.04950v1 [cs.CV])
6. Continual Prune-and-Select: Class-incremental learning with specialized subnetworks. (arXiv:2208.04952v1 [cs.LG])
7. Wavelet Score-Based Generative Modeling. (arXiv:2208.05003v1 [cs.LG])
8. Human Activity Recognition Using Cascaded Dual Attention CNN and Bi-Directional GRU Framework. (arXiv:2208.05034v1 [cs.CV])
9. Automatic Ultrasound Image Segmentation of Supraclavicular Nerve Using Dilated U-Net Deep Learning Architecture. (arXiv:2208.05050v1 [eess.IV])
10. Learning to Complete Object Shapes for Object-level Mapping in Dynamic Scenes. (arXiv:2208.05067v1 [cs.CV])
11. RWSeg: Cross-graph Competing Random Walks for Weakly Supervised 3D Instance Segmentation. (arXiv:2208.05110v1 [cs.CV])
12. Ghost-free **High Dynamic Range** Imaging with Context-aware Transformer. (arXiv:2208.05114v1 [cs.CV])
13. Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation. (arXiv:2208.05140v1 [eess.IV])
14. Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization. (arXiv:2208.05163v1 [cs.CV])
15. EXTERN: Leveraging Endo-Temporal Regularization for Black-box Video Domain Adaptation. (arXiv:2208.05187v1 [cs.CV])
16. Real-Time Oil Leakage Detection on Aftermarket Motorcycle Damping System with Convolutional Neural Networks. (arXiv:2208.05192v1 [cs.CV])
17. A Detection Method of Temporally Operated Videos Using Robust Hashing. (arXiv:2208.05198v1 [cs.CV])
18. Automatic Camera Control and Directing with an Ultra-High-Definition Collaborative Recording System. (arXiv:2208.05213v1 [cs.CV])
19. Exploring Point-BEV Fusion for 3D Point Cloud Object Tracking with Transformer. (arXiv:2208.05216v1 [cs.CV])
20. Dual Domain-Adversarial Learning for Audio-Visual Saliency Prediction. (arXiv:2208.05220v1 [cs.CV])
21. Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for Patients with Cerebral Palsy. (arXiv:2208.05232v1 [cs.HC])
22. Multi-structure segmentation for renal cancer treatment with modified nn-UNet. (arXiv:2208.05241v1 [eess.IV])
23. Learning Degradation Representations for Image Deblurring. (arXiv:2208.05244v1 [cs.CV])
24. Consistency-based Self-supervised Learning for Temporal Anomaly Localization. (arXiv:2208.05251v1 [cs.CV])
25. Multi-scale Feature Aggregation for Crowd Counting. (arXiv:2208.05256v1 [cs.CV])
26. Efficient Joint-Dimensional Search with Solution Space Regularization for Real-Time Semantic Segmentation. (arXiv:2208.05271v1 [cs.CV])
27. Arbitrary Point Cloud Upsampling with Spherical Mixture of Gaussians. (arXiv:2208.05274v1 [cs.CV])
28. Generative Transfer Learning: Covid-19 Classification with a few Chest X-ray Images. (arXiv:2208.05305v1 [eess.IV])
29. Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
30. MD-Net: Multi-Detector for Local Feature Extraction. (arXiv:2208.05350v1 [cs.CV])
31. CLEVR-Math: A Dataset for Compositional Language, Visual and Mathematical Reasoning. (arXiv:2208.05358v1 [cs.LG])
32. E Pluribus Unum Interpretable Convolutional Neural Networks. (arXiv:2208.05369v1 [cs.CV])
33. Exploring Anchor-based Detection for Ego4D Natural Language Query. (arXiv:2208.05375v1 [cs.CV])
34. Benchmarking Joint Face Spoofing and Forgery Detection with Visual and Physiological Cues. (arXiv:2208.05401v1 [cs.CV])
35. FourCastNet: Accelerating Global High-Resolution Weather Forecasting using Adaptive Fourier Neural Operators. (arXiv:2208.05419v1 [physics.ao-ph])
36. Detecting COVID-19 from digitized ECG printouts using 1D convolutional neural networks. (arXiv:2208.05433v1 [eess.IV])
37. EvolveHypergraph: Group-Aware Dynamic Relational Reasoning for Trajectory Prediction. (arXiv:2208.05470v1 [cs.CV])
38. A Deep Learning Approach for Real-Time 3D Human Action Recognition from Skeletal Data. (arXiv:1907.03520v2 [cs.CV] UPDATED)
39. Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization without Accessing Target Domain Data. (arXiv:1909.00889v2 [cs.CV] UPDATED)
40. Deep Learning Based Single Sample Per Person Face Recognition: A Survey. (arXiv:2006.11395v2 [cs.CV] UPDATED)
41. Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches. (arXiv:2007.02200v3 [cs.CV] UPDATED)
42. Continuous **Exposure** for Extreme **Low-Light** Imaging. (arXiv:2012.04112v2 [eess.IV] UPDATED)
43. Model Pruning Based on Quantified Similarity of Feature Maps. (arXiv:2105.06052v2 [cs.CV] UPDATED)
44. Face Identification Proficiency Test Designed Using Item Response Theory. (arXiv:2106.15323v3 [cs.CV] UPDATED)
45. Benchmarking the Robustness of Instance Segmentation Models. (arXiv:2109.01123v2 [cs.CV] UPDATED)
46. A Light-weight Interpretable Compositional Model for Nuclei Detection and Weakly-Supervised Segmentation. (arXiv:2110.13846v2 [cs.CV] UPDATED)
47. Tracking Blobs in the Turbulent Edge Plasma of a Tokamak Fusion Device. (arXiv:2111.08570v3 [physics.plasm-ph] UPDATED)
48. Image classifiers can not be made robust to small perturbations. (arXiv:2112.04033v2 [cs.CV] UPDATED)
49. **NeRF**ocus: Neural Radiance Field for 3D Synthetic Defocus. (arXiv:2203.05189v2 [cs.CV] UPDATED)
50. Dense Siamese Network for Dense Unsupervised Learning. (arXiv:2203.11075v2 [cs.CV] UPDATED)
51. GEB+: A Benchmark for Generic Event Boundary Captioning, Grounding and Retrieval. (arXiv:2204.00486v4 [cs.CV] UPDATED)
52. PS-Net: Learned Partially Separable Model for Dynamic MR Imaging. (arXiv:2205.04073v2 [eess.IV] UPDATED)
53. AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation. (arXiv:2205.05277v2 [cs.CV] UPDATED)
54. PREF: Phasorial Embedding Fields for Compact Neural Representations. (arXiv:2205.13524v2 [cs.CV] UPDATED)
55. Knowledge Distillation with Representative Teacher Keys Based on Attention Mechanism for Image Classification Model Compression. (arXiv:2206.12788v3 [cs.CV] UPDATED)
56. A Simple Approach for Visual Rearrangement: 3D Mapping and Semantic Search. (arXiv:2206.13396v2 [cs.CV] UPDATED)
57. Delving into Sequential Patches for Deepfake Detection. (arXiv:2207.02803v2 [cs.CV] UPDATED)
58. ALBench: A Framework for Evaluating Active Learning in Object Detection. (arXiv:2207.13339v2 [cs.CV] UPDATED)
59. First Glance Diagnosis: Brain Disease Classification with Single fMRI Volume. (arXiv:2208.03028v2 [eess.IV] UPDATED)
60. Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model. (arXiv:2208.03987v2 [cs.CV] UPDATED)
61. SKDCGN: Source-free Knowledge Distillation of Counterfactual Generative Networks using cGANs. (arXiv:2208.04226v2 [cs.CV] UPDATED)
62. Distincive Image Captioning via CLIP Guided Group Optimization. (arXiv:2208.04254v2 [cs.CV] UPDATED)
63. In the Eye of Transformer: Global-Local Correlation for Egocentric Gaze Estimation. (arXiv:2208.04464v2 [cs.CV] UPDATED)
64. Using Large Context for Kidney Multi-Structure Segmentation from CTA Images. (arXiv:2208.04525v2 [eess.IV] UPDATED)
65. Efficient Out-of-Distribution Detection of Melanoma with Wavelet-based Normalizing Flows. (arXiv:2208.04639v2 [cs.CV] UPDATED)
66. Improved Multiple-Image-Based Reflection Removal Algorithm Using Deep Neural Networks. (arXiv:2208.04679v2 [eess.IV] UPDATED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. U-Net vs Transformer: Is U-Net Outdated in Medical Image Registration?. (arXiv:2208.04939v1 [eess.IV])
2. Multi-Depth Boundary-Aware Left Atrial Scar Segmentation Network. (arXiv:2208.04940v1 [eess.IV])
3. Learning from imperfect training data using a robust loss function: application to brain image segmentation. (arXiv:2208.04941v1 [eess.IV])
4. Multiscale Autoencoder with Structural-Functional Attention Network for Alzheimer's Disease Prediction. (arXiv:2208.04945v1 [eess.IV])
5. Visual Heart Rate Estimation from RGB Facial Video using Spectral Reflectance. (arXiv:2208.04947v1 [cs.CV])
6. BabyNet: A Lightweight Network for Infant Reaching Action Recognition in Unconstrained Environments to Support Future Pediatric Rehabilitation Applications. (arXiv:2208.04950v1 [cs.CV])
7. Quantum artificial vision for defect detection in manufacturing. (arXiv:2208.04988v1 [quant-ph])
8. Towards Enabling Next Generation Societal Virtual Reality Applications for Virtual Human Teleportation. (arXiv:2208.04998v1 [cs.NI])
9. G-PCC Post-Processing Using Fractional Super-Resolution. (arXiv:2208.05010v1 [eess.IV])
10. Automatic Ultrasound Image Segmentation of Supraclavicular Nerve Using Dilated U-Net Deep Learning Architecture. (arXiv:2208.05050v1 [eess.IV])
11. Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation. (arXiv:2208.05140v1 [eess.IV])
12. Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization. (arXiv:2208.05163v1 [cs.CV])
13. Multi-structure segmentation for renal cancer treatment with modified nn-UNet. (arXiv:2208.05241v1 [eess.IV])
14. Generative Transfer Learning: Covid-19 Classification with a few Chest X-ray Images. (arXiv:2208.05305v1 [eess.IV])
15. Detecting COVID-19 from digitized ECG printouts using 1D convolutional neural networks. (arXiv:2208.05433v1 [eess.IV])
16. Deep Learning Based Single Sample Per Person Face Recognition: A Survey. (arXiv:2006.11395v2 [cs.CV] UPDATED)
17. Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches. (arXiv:2007.02200v3 [cs.CV] UPDATED)
18. Continuous **Exposure** for Extreme **Low-Light** Imaging. (arXiv:2012.04112v2 [eess.IV] UPDATED)
19. Ultrasound Matrix Imaging. I. The focused reflection matrix, the F-factor and the role of multiple scattering. (arXiv:2103.02029v2 [physics.app-ph] UPDATED)
20. Ultrasound Matrix Imaging. II. The distortion matrix for aberration correction over multiple isoplanatic patches. (arXiv:2103.02036v2 [eess.IV] UPDATED)
21. PS-Net: Learned Partially Separable Model for Dynamic MR Imaging. (arXiv:2205.04073v2 [eess.IV] UPDATED)
22. First Glance Diagnosis: Brain Disease Classification with Single fMRI Volume. (arXiv:2208.03028v2 [eess.IV] UPDATED)
23. Using Large Context for Kidney Multi-Structure Segmentation from CTA Images. (arXiv:2208.04525v2 [eess.IV] UPDATED)
24. Improved Multiple-Image-Based Reflection Removal Algorithm Using Deep Neural Networks. (arXiv:2208.04679v2 [eess.IV] UPDATED)
## cs.LG
---
**111** new papers in cs.LG:-) 
1. A physically-informed Deep-Learning approach for locating sources in a waveguide. (arXiv:2208.04938v1 [cs.LG])
2. Multi-Depth Boundary-Aware Left Atrial Scar Segmentation Network. (arXiv:2208.04940v1 [eess.IV])
3. Learning from imperfect training data using a robust loss function: application to brain image segmentation. (arXiv:2208.04941v1 [eess.IV])
4. PerD: Perturbation Sensitivity-based Neural Trojan Detection Framework on NLP Applications. (arXiv:2208.04943v1 [cs.LG])
5. Bridging the gap between target-based and cell-based drug discovery with a graph generative multi-task model. (arXiv:2208.04944v1 [q-bio.QM])
6. Attention Hijacking in Trojan Transformers. (arXiv:2208.04946v1 [cs.LG])
7. BabyNet: A Lightweight Network for Infant Reaching Action Recognition in Unconstrained Environments to Support Future Pediatric Rehabilitation Applications. (arXiv:2208.04950v1 [cs.CV])
8. Continual Prune-and-Select: Class-incremental learning with specialized subnetworks. (arXiv:2208.04952v1 [cs.LG])
9. Explainable prediction of Qcodes for NOTAMs using column generation. (arXiv:2208.04955v1 [cs.LG])
10. Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v1 [cs.NE])
11. Machine Learning 1- and 2-electron reduced density matrices of polymeric molecules. (arXiv:2208.04976v1 [physics.chem-ph])
12. An NLP-Assisted Bayesian Time Series Analysis for Prevalence of Twitter Cyberbullying During the COVID-19 Pandemic. (arXiv:2208.04980v1 [cs.SI])
13. Quantum artificial vision for defect detection in manufacturing. (arXiv:2208.04988v1 [quant-ph])
14. A Model-Constrained Tangent Manifold Learning Approach for Dynamical Systems. (arXiv:2208.04995v1 [cs.LG])
15. Wavelet Score-Based Generative Modeling. (arXiv:2208.05003v1 [cs.LG])
16. CoViT: **Real-time** phylogenetics for the SARS-CoV-2 pandemic using Vision Transformers. (arXiv:2208.05004v1 [cs.LG])
17. Privacy-Aware Adversarial Network in Human Mobility Prediction. (arXiv:2208.05009v1 [cs.LG])
18. A Unified Comparison of User Modeling Techniques for Predicting Data Interaction and Detecting Exploration Bias. (arXiv:2208.05021v1 [cs.HC])
19. Adaptive Target-Condition Neural Network: DNN-Aided Load Balancing for Hybrid LiFi and WiFi Networks. (arXiv:2208.05035v1 [eess.SP])
20. Adaptive Resources Allocation CUSUM for Binomial Count Data Monitoring with Application to COVID-19 Hotspot Detection. (arXiv:2208.05045v1 [cs.LG])
21. Automatic Ultrasound Image Segmentation of Supraclavicular Nerve Using Dilated U-Net Deep Learning Architecture. (arXiv:2208.05050v1 [eess.IV])
22. Model-Free Generative Replay for Lifelong Reinforcement Learning: Application to Starcraft-2. (arXiv:2208.05056v1 [cs.LG])
23. Interpretable Polynomial Neural Ordinary Differential Equations. (arXiv:2208.05072v1 [cs.LG])
24. Reducing Exploitability with Population Based Training. (arXiv:2208.05083v1 [cs.LG])
25. Increasing Students' Engagement to Reminder Emails Through Multi-Armed Bandits. (arXiv:2208.05090v1 [cs.LG])
26. Using Adaptive Experiments to Rapidly Help Students. (arXiv:2208.05092v1 [cs.LG])
27. KL-divergence Based Deep Learning for Discrete Time Model. (arXiv:2208.05100v1 [stat.ML])
28. Machine Learning with DBOS. (arXiv:2208.05101v1 [cs.CR])
29. Classifier Transfer with Data Selection Strategies for Online Support Vector Machine Classification with Class Imbalance. (arXiv:2208.05112v1 [cs.LG])
30. Robust Continual Test-time Adaptation: Instance-aware BN and Prediction-balanced Memory. (arXiv:2208.05117v1 [cs.LG])
31. Semi-Supervised Junction Tree Variational Autoencoder for Molecular Property Prediction. (arXiv:2208.05119v1 [cs.LG])
32. D-BIAS: A Causality-Based Human-in-the-Loop System for Tackling Algorithmic Bias. (arXiv:2208.05126v1 [cs.LG])
33. Robust Reinforcement Learning using Offline Data. (arXiv:2208.05129v1 [cs.LG])
34. Fast Heterogeneous Federated Learning with Hybrid Client Selection. (arXiv:2208.05135v1 [cs.LG])
35. Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation. (arXiv:2208.05140v1 [eess.IV])
36. Machine Learning-based EEG Applications and Markets. (arXiv:2208.05144v1 [cs.LG])
37. Controlling Perceived Emotion in Symbolic Music Generation with Monte Carlo Tree Search. (arXiv:2208.05162v1 [cs.SD])
38. Auto-ViT-Acc: An FPGA-Aware Automatic Acceleration Framework for Vision Transformer with Mixed-Scheme Quantization. (arXiv:2208.05163v1 [cs.CV])
39. FedOBD: Opportunistic Block Dropout for Efficiently Training Large-scale Neural Networks through Federated Learning. (arXiv:2208.05174v1 [cs.LG])
40. Learning Quantization in LDPC Decoders. (arXiv:2208.05186v1 [cs.IT])
41. A data-driven modular architecture with denoising autoencoders for health indicator construction in a manufacturing process. (arXiv:2208.05208v1 [cs.LG])
42. Capturing Dependencies within Machine Learning via a Formal Process Model. (arXiv:2208.05219v1 [cs.SE])
43. Trustworthy Visual Analytics in Clinical Gait Analysis: A Case Study for Patients with Cerebral Palsy. (arXiv:2208.05232v1 [cs.HC])
44. Spatial-Temporal Identity: A Simple yet Effective Baseline for Multivariate Time Series Forecasting. (arXiv:2208.05233v1 [cs.LG])
45. Fairness Based Energy-Efficient 3D Path Planning of a Portable Access Point: A Deep Reinforcement Learning Approach. (arXiv:2208.05265v1 [eess.SP])
46. A Novel Resource Allocation for Anti-jamming in Cognitive-UAVs: an Active Inference Approach. (arXiv:2208.05269v1 [cs.LG])
47. TSInterpret: A unified framework for time series interpretability. (arXiv:2208.05280v1 [cs.LG])
48. Explaining Machine Learning DGA Detectors from DNS Traffic Data. (arXiv:2208.05285v1 [cs.CR])
49. Adaptive Learning Rates for Faster Stochastic Gradient Methods. (arXiv:2208.05287v1 [cs.LG])
50. Learning to Improve Code Efficiency. (arXiv:2208.05297v1 [cs.SE])
51. Generative Transfer Learning: Covid-19 Classification with a few Chest X-ray Images. (arXiv:2208.05305v1 [eess.IV])
52. Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation. (arXiv:2208.05309v1 [cs.CL])
53. Convergence of denoising diffusion models under the manifold hypothesis. (arXiv:2208.05314v1 [stat.ML])
54. Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
55. PEPPER: Empowering User-Centric Recommender Systems over Gossip Learning. (arXiv:2208.05320v1 [cs.IR])
56. A Frequency-aware Software Cache for Large Recommendation System Embeddings. (arXiv:2208.05321v1 [cs.IR])
57. Fast Offline Policy Optimization for Large Scale Recommendation. (arXiv:2208.05327v1 [cs.IR])
58. Mappings for Marginal Probabilities with Applications to Models in Statistical Physics. (arXiv:2208.05333v1 [stat.ML])
59. Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee: Geospatial Machine Learning Approach. (arXiv:2208.05335v1 [cs.LG])
60. Diversifying Design of Nucleic Acid Aptamers Using Unsupervised Machine Learning. (arXiv:2208.05341v1 [physics.bio-ph])
61. CLEVR-Math: A Dataset for Compositional Language, Visual and Mathematical Reasoning. (arXiv:2208.05358v1 [cs.LG])
62. Learning Two-Player Mixture Markov Games: Kernel Function Approximation and Correlated Equilibrium. (arXiv:2208.05363v1 [cs.LG])
63. Multi-task Active Learning for Pre-trained Transformer-based Models. (arXiv:2208.05379v1 [cs.CL])
64. ATLAS: Universal Function Approximator for Memory Retention. (arXiv:2208.05388v1 [cs.LG])
65. A Sublinear Adversarial Training Algorithm. (arXiv:2208.05395v1 [cs.LG])
66. Active Sampling of Multiple Sources for Sequential Estimation. (arXiv:2208.05406v1 [cs.LG])
67. Non-Contrastive Self-Supervised Learning of Utterance-Level Speech Representations. (arXiv:2208.05413v1 [eess.AS])
68. FourCastNet: Accelerating Global High-Resolution Weather Forecasting using Adaptive Fourier Neural Operators. (arXiv:2208.05419v1 [physics.ao-ph])
69. Generating physically-consistent high-resolution climate data with hard-constrained neural networks. (arXiv:2208.05424v1 [physics.ao-ph])
70. Differentiable Inference of Temporal Logic Formulas. (arXiv:2208.05440v1 [cs.LG])
71. Flexible Unsupervised Learning for Massive MIMO Subarray Hybrid Beamforming. (arXiv:2208.05443v1 [cs.IT])
72. Rapid Exploration of a 32.5M Compound Chemical Space with Active Learning to Discover Density Functional Approximation Insensitive and Synthetically Accessible Transitional Metal Chromophores. (arXiv:2208.05444v1 [physics.chem-ph])
73. Non-Contrastive Self-supervised Learning for Utterance-Level Information Extraction from Speech. (arXiv:2208.05445v1 [eess.AS])
74. CoditT5: Pretraining for Source Code and Natural Language Editing. (arXiv:2208.05446v1 [cs.SE])
75. Robust methods for high-dimensional linear learning. (arXiv:2208.05447v1 [stat.ML])
76. EvolveHypergraph: Group-Aware Dynamic Relational Reasoning for Trajectory Prediction. (arXiv:2208.05470v1 [cs.CV])
77. Deep Learning Based Single Sample Per Person Face Recognition: A Survey. (arXiv:2006.11395v2 [cs.CV] UPDATED)
78. Offline versus Online Triplet Mining based on Extreme Distances of Histopathology Patches. (arXiv:2007.02200v3 [cs.CV] UPDATED)
79. How Does the Task Landscape Affect MAML Performance?. (arXiv:2010.14672v5 [cs.LG] UPDATED)
80. Self-Supervised Learning from Contrastive Mixtures for Personalized Speech **Enhancement**. (arXiv:2011.03426v2 [eess.AS] UPDATED)
81. Model Pruning Based on Quantified Similarity of Feature Maps. (arXiv:2105.06052v2 [cs.CV] UPDATED)
82. Tianshou: a Highly Modularized Deep Reinforcement Learning Library. (arXiv:2107.14171v3 [cs.LG] UPDATED)
83. Benchmarking the Robustness of Instance Segmentation Models. (arXiv:2109.01123v2 [cs.CV] UPDATED)
84. System Norm Regularization Methods for Koopman Operator Approximation. (arXiv:2110.09658v3 [eess.SY] UPDATED)
85. Oblique and rotation double random forest. (arXiv:2111.02010v3 [cs.LG] UPDATED)
86. Subgraph Permutation Equivariant Networks. (arXiv:2111.11840v3 [cs.LG] UPDATED)
87. Image classifiers can not be made robust to small perturbations. (arXiv:2112.04033v2 [cs.CV] UPDATED)
88. Edge-Compatible Reinforcement Learning for Recommendations. (arXiv:2112.05812v2 [cs.LG] UPDATED)
89. Importance Weighting Approach in Kernel Bayes' Rule. (arXiv:2202.02474v3 [stat.ML] UPDATED)
90. StratDef: a strategic defense against adversarial attacks in malware detection. (arXiv:2202.07568v2 [cs.LG] UPDATED)
91. An alternative approach to train neural networks using monotone variational inequality. (arXiv:2202.08876v3 [stat.ML] UPDATED)
92. Counterfactual Phenotyping with Censored Time-to-Events. (arXiv:2202.11089v3 [cs.LG] UPDATED)
93. Flat Latent Manifolds for Human-machine Co-creation of Music. (arXiv:2202.12243v3 [cs.SD] UPDATED)
94. A Transformational Characterization of Unconditionally Equivalent Bayesian Networks. (arXiv:2203.00521v3 [stat.ML] UPDATED)
95. Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization. (arXiv:2203.02214v4 [cs.LG] UPDATED)
96. Flow-matching -- efficient coarse-graining molecular dynamics without forces. (arXiv:2203.11167v2 [physics.comp-ph] UPDATED)
97. Theoretical Connection between Locally Linear Embedding, Factor Analysis, and Probabilistic PCA. (arXiv:2203.13911v2 [stat.ML] UPDATED)
98. SurvLatent ODE : A Neural ODE based time-to-event model with competing risks for longitudinal data improves cancer-associated Venous Thromboembolism (VTE) prediction. (arXiv:2204.09633v2 [cs.LG] UPDATED)
99. Online Learning in Fisher Markets: Static Pricing Limits and Adaptive **Enhancement**s. (arXiv:2205.00825v2 [cs.GT] UPDATED)
100. PS-Net: Learned Partially Separable Model for Dynamic MR Imaging. (arXiv:2205.04073v2 [eess.IV] UPDATED)
101. Training neural networks using Metropolis Monte Carlo and an adaptive variant. (arXiv:2205.07408v2 [cs.LG] UPDATED)
102. Deep Learning Methods for Proximal Inference via Maximum Moment Restriction. (arXiv:2205.09824v2 [stat.ML] UPDATED)
103. Approximation of Functionals by Neural Network without Curse of Dimensionality. (arXiv:2205.14421v3 [math.NA] UPDATED)
104. A Transistor Operations Model for Deep Learning Energy Consumption Scaling Law. (arXiv:2205.15062v2 [cs.LG] UPDATED)
105. Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance. (arXiv:2206.03787v2 [cs.LG] UPDATED)
106. Accelerated Algorithms for Monotone Inclusion and Constrained Nonconvex-Nonconcave Min-Max Optimization. (arXiv:2206.05248v2 [math.OC] UPDATED)
107. A Simple Approach for Visual Rearrangement: 3D Mapping and Semantic Search. (arXiv:2206.13396v2 [cs.CV] UPDATED)
108. Model selection with Gini indices under auto-calibration. (arXiv:2207.14372v3 [cs.LG] UPDATED)
109. Quantum-Inspired Tensor Neural Networks for Partial Differential Equations. (arXiv:2208.02235v2 [cs.LG] UPDATED)
110. Deep Learning Closure Models for Large-Eddy Simulation of Flows around Bluff Bodies. (arXiv:2208.03498v2 [physics.flu-dyn] UPDATED)
111. SKDCGN: Source-free Knowledge Distillation of Counterfactual Generative Networks using cGANs. (arXiv:2208.04226v2 [cs.CV] UPDATED)
## cs.AI
---
**51** new papers in cs.AI:-) 
1. Attention Hijacking in Trojan Transformers. (arXiv:2208.04946v1 [cs.LG])
2. Continual Prune-and-Select: Class-incremental learning with specialized subnetworks. (arXiv:2208.04952v1 [cs.LG])
3. Explainable prediction of Qcodes for NOTAMs using column generation. (arXiv:2208.04955v1 [cs.LG])
4. Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v1 [cs.NE])
5. Vehicle Type Specific Waypoint Generation. (arXiv:2208.04987v1 [cs.AI])
6. Aesthetic Bot: Interactively Evolving Game Maps on Twitter. (arXiv:2208.05017v1 [cs.AI])
7. Human Activity Recognition Using Cascaded Dual Attention CNN and Bi-Directional GRU Framework. (arXiv:2208.05034v1 [cs.CV])
8. Economics of Semantic Communication System: An Auction Approach. (arXiv:2208.05040v1 [cs.NI])
9. Model-Free Generative Replay for Lifelong Reinforcement Learning: Application to Starcraft-2. (arXiv:2208.05056v1 [cs.LG])
10. Ad Hoc Teamwork in the Presence of Adversaries. (arXiv:2208.05071v1 [cs.MA])
11. Interpretable Polynomial Neural Ordinary Differential Equations. (arXiv:2208.05072v1 [cs.LG])
12. Adversarial Machine Learning-Based Anticipation of Threats Against Vehicle-to-Microgrid Services. (arXiv:2208.05073v1 [cs.CR])
13. Reducing Exploitability with Population Based Training. (arXiv:2208.05083v1 [cs.LG])
14. Research on restaurant recommendation using machine learning. (arXiv:2208.05113v1 [cs.IR])
15. Robust Reinforcement Learning using Offline Data. (arXiv:2208.05129v1 [cs.LG])
16. Fast Heterogeneous Federated Learning with Hybrid Client Selection. (arXiv:2208.05135v1 [cs.LG])
17. Multi-View Pre-Trained Model for Code Vulnerability Identification. (arXiv:2208.05227v1 [cs.SE])
18. Consistency-based Self-supervised Learning for Temporal Anomaly Localization. (arXiv:2208.05251v1 [cs.CV])
19. Fairness Based Energy-Efficient 3D Path Planning of a Portable Access Point: A Deep Reinforcement Learning Approach. (arXiv:2208.05265v1 [eess.SP])
20. A Novel Resource Allocation for Anti-jamming in Cognitive-UAVs: an Active Inference Approach. (arXiv:2208.05269v1 [cs.LG])
21. Efficient Joint-Dimensional Search with Solution Space Regularization for Real-Time Semantic Segmentation. (arXiv:2208.05271v1 [cs.CV])
22. Language Supervised Training for Skeleton-based Action Recognition. (arXiv:2208.05318v1 [cs.CV])
23. A Frequency-aware Software Cache for Large Recommendation System Embeddings. (arXiv:2208.05321v1 [cs.IR])
24. Fast Offline Policy Optimization for Large Scale Recommendation. (arXiv:2208.05327v1 [cs.IR])
25. Learning Two-Player Mixture Markov Games: Kernel Function Approximation and Correlated Equilibrium. (arXiv:2208.05363v1 [cs.LG])
26. A Monitoring and Discovery Approach for Declarative Processes Based on Streams. (arXiv:2208.05364v1 [cs.AI])
27. E Pluribus Unum Interpretable Convolutional Neural Networks. (arXiv:2208.05369v1 [cs.CV])
28. Exploring Anchor-based Detection for Ego4D Natural Language Query. (arXiv:2208.05375v1 [cs.CV])
29. Towards Autonomous Atlas-based Ultrasound Acquisitions in Presence of Articulated Motion. (arXiv:2208.05399v1 [cs.RO])
30. FourCastNet: Accelerating Global High-Resolution Weather Forecasting using Adaptive Fourier Neural Operators. (arXiv:2208.05419v1 [physics.ao-ph])
31. Attention-aware Resource Allocation and QoE Analysis for Metaverse xURLLC Services. (arXiv:2208.05438v1 [cs.AI])
32. Differentiable Inference of Temporal Logic Formulas. (arXiv:2208.05440v1 [cs.LG])
33. Non-Contrastive Self-supervised Learning for Utterance-Level Information Extraction from Speech. (arXiv:2208.05445v1 [eess.AS])
34. EvolveHypergraph: Group-Aware Dynamic Relational Reasoning for Trajectory Prediction. (arXiv:2208.05470v1 [cs.CV])
35. Benchmarking the Robustness of Instance Segmentation Models. (arXiv:2109.01123v2 [cs.CV] UPDATED)
36. Oblique and rotation double random forest. (arXiv:2111.02010v3 [cs.LG] UPDATED)
37. On the Relationship between Shy and Warded Datalog+/-. (arXiv:2202.06285v3 [cs.LO] UPDATED)
38. IBIA: Bayesian Inference via Incremental Build-Infer-Approximate operations on Clique Trees. (arXiv:2202.12003v2 [cs.AI] UPDATED)
39. Plan Your Target and Learn Your Skills: Transferable State-Only Imitation Learning via Decoupled Policy Optimization. (arXiv:2203.02214v4 [cs.LG] UPDATED)
40. Dense Siamese Network for Dense Unsupervised Learning. (arXiv:2203.11075v2 [cs.CV] UPDATED)
41. STC-IDS: Spatial-Temporal Correlation Feature Analyzing based Intrusion Detection System for Intelligent Connected Vehicles. (arXiv:2204.10990v2 [cs.CR] UPDATED)
42. AggPose: Deep Aggregation Vision Transformer for Infant Pose Estimation. (arXiv:2205.05277v2 [cs.CV] UPDATED)
43. Inductive Learning of Complex Knowledge from Raw Data. (arXiv:2205.12735v2 [cs.AI] UPDATED)
44. A Transistor Operations Model for Deep Learning Energy Consumption Scaling Law. (arXiv:2205.15062v2 [cs.LG] UPDATED)
45. Action Noise in Off-Policy Deep Reinforcement Learning: Impact on Exploration and Performance. (arXiv:2206.03787v2 [cs.LG] UPDATED)
46. Knowledge Distillation with Representative Teacher Keys Based on Attention Mechanism for Image Classification Model Compression. (arXiv:2206.12788v3 [cs.CV] UPDATED)
47. A Simple Approach for Visual Rearrangement: 3D Mapping and Semantic Search. (arXiv:2206.13396v2 [cs.CV] UPDATED)
48. Quantum-Inspired Tensor Neural Networks for Partial Differential Equations. (arXiv:2208.02235v2 [cs.LG] UPDATED)
49. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. (arXiv:2208.03188v3 [cs.CL] UPDATED)
50. Debiased Large Language Models Still Associate Muslims with Uniquely Violent Acts. (arXiv:2208.04417v2 [cs.CL] UPDATED)
51. Multi-Task Fusion via Reinforcement Learning for Long-Term User Satisfaction in Recommender Systems. (arXiv:2208.04560v2 [cs.IR] UPDATED)

