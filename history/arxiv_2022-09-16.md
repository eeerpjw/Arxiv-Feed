# Your interest papers
---
## cs.CV
---
### DEANet: Decomposition **Enhancement** and Adjustment Network for **Low-Light** Image **Enhancement**. (arXiv:2209.06823v1 [cs.CV])
- Authors : Yonglong Jiang, Liangliang Li, Yuan Xue, Hongbing Ma
- Link : [http://arxiv.org/abs/2209.06823](http://arxiv.org/abs/2209.06823)
> ABSTRACT  :  Images obtained under **low-light** conditions will seriously affect the quality of the images. Solving the problem of poor **low-light** image quality can effectively improve the visual quality of images and better improve the usability of computer vision. In addition, it has very important applications in many fields. This paper proposes a DEANet based on Retinex for **low-light** image **enhancement**. It combines the frequency information and content information of the image into three sub-networks: decomposition network, **enhancement** network and adjustment network. These three sub-networks are respectively used for decomposition, denoising, contrast **enhancement** and detail preservation, adjustment, and image generation. Our model has good robust results for all **low-light** images. The model is trained on the public data set LOL, and the experimental results show that our method is better than the existing state-of-the-art methods in terms of vision and quality.  
### NanoFlowNet: **Real-time** Dense Optical Flow on a Nano Quadcopter. (arXiv:2209.06918v1 [cs.RO])
- Authors : Federico Paredes, de Croon
- Link : [http://arxiv.org/abs/2209.06918](http://arxiv.org/abs/2209.06918)
> ABSTRACT  :  Nano quadcopters are small, agile, and cheap platforms that are well suited for deployment in narrow, cluttered environments. Due to their limited payload, these vehicles are highly constrained in processing power, rendering conventional vision-based methods for safe and autonomous navigation incompatible. Recent machine learning developments promise high-performance perception at low latency, while dedicated edge computing hardware has the potential to augment the processing capabilities of these limited devices. In this work, we present NanoFlowNet, a lightweight convolutional neural network for real-time dense optical flow estimation on edge computing hardware. We draw inspiration from recent advances in semantic segmentation for the design of this network. Additionally, we guide the learning of optical flow using motion boundary ground truth data, which improves performance with no impact on latency. Validation results on the MPI-Sintel dataset show the high performance of the proposed network given its constrained architecture. Additionally, we successfully demonstrate the capabilities of NanoFlowNet by deploying it on the ultra-low power GAP8 microprocessor and by applying it to vision-based obstacle avoidance on board a Bitcraze Crazyflie, a 34 g nano quadcopter.  
### Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models. (arXiv:2209.06970v1 [cs.CV])
- Authors : Chen Henry, Saman Motamed, Shaunak Srivastava, Fernando De, la Torre
- Link : [http://arxiv.org/abs/2209.06970](http://arxiv.org/abs/2209.06970)
> ABSTRACT  :  Generative models (e.g., GANs and diffusion models) learn the underlying data distribution in an unsupervised manner. However, many applications of interest require sampling from a specific region of the generative model's output space or evenly over a range of characteristics. To allow efficient sampling in these scenarios, we propose Generative Visual Prompt (PromptGen), a framework for distributional control over pre-trained generative models by incorporating knowledge of arbitrary off-the-shelf models. PromptGen defines control as an energy-based model (EBM) and samples images in a feed-forward manner by approximating the EBM with invertible neural networks, avoiding optimization at inference. We demonstrate how PromptGen can control several generative models (e.g., StyleGAN2, Style**NeRF**, diffusion autoencoder, and NVAE) using various off-the-shelf models: (1) with the CLIP model, PromptGen can sample images guided by text, (2) with image classifiers, PromptGen can de-bias generative models across a set of attributes, and (3) with inverse graphics models, PromptGen can sample images of the same identity in different poses. (4) Finally, PromptGen reveals that the CLIP model shows "reporting bias" when used as control, and PromptGen can further de-bias this controlled distribution in an iterative manner. Our code is available at https://github.com/ChenWu98/Generative-Visual-Prompt.  
### A Temporal Densely Connected Recurrent Network for Event-based Human Pose Estimation. (arXiv:2209.07034v1 [cs.CV])
- Authors : Zhanpeng Shao, Wen Zhou, Wuzhen Wang, Jianyu Yang, Youfu Li
- Link : [http://arxiv.org/abs/2209.07034](http://arxiv.org/abs/2209.07034)
> ABSTRACT  :  Event camera is an emerging bio-inspired vision sensors that report per-pixel brightness changes asynchronously. It holds noticeable advantage of **high dynamic range**, high speed response, and low power budget that enable it to best capture local motions in uncontrolled environments. This motivates us to unlock the potential of event cameras for human pose estimation, as the human pose estimation with event cameras is rarely explored. Due to the novel paradigm shift from conventional frame-based cameras, however, event signals in a time interval contain very limited information, as event cameras can only capture the moving body parts and ignores those static body parts, resulting in some parts to be incomplete or even disappeared in the time interval. This paper proposes a novel densely connected recurrent architecture to address the problem of incomplete information. By this recurrent architecture, we can explicitly model not only the sequential but also non-sequential geometric consistency across time steps to accumulate information from previous frames to recover the entire human bodies, achieving a stable and accurate human pose estimation from event data. Moreover, to better evaluate our model, we collect a large scale multimodal event-based dataset that comes with human pose annotations, which is by far the most challenging one to the best of our knowledge. The experimental results on two public datasets and our own dataset demonstrate the effectiveness and strength of our approach. Code can be available online for facilitating the future research.  
### Towards self-attention based navigation in the real world. (arXiv:2209.07043v1 [cs.RO])
- Authors : Jaime Ruiz, Jack White, Stephen Petrie, Tatiana Kameneva, Chris McCarthy
- Link : [http://arxiv.org/abs/2209.07043](http://arxiv.org/abs/2209.07043)
> ABSTRACT  :  Vision-based navigation requires processing complex information to make task-orientated decisions. Applications include autonomous robots, self-driving cars, and assistive vision for humans. One of the key elements in the process is the extraction and selection of relevant features in pixel space upon which to base action choices, for which Machine Learning techniques are well suited. However, Deep Reinforcement Learning agents trained in simulation often exhibit unsatisfactory results when deployed in the real-world due to perceptual differences known as the $\textit{reality gap}$. An approach that is yet to be explored to bridge this gap is self-attention. In this paper we (1) perform a systematic exploration of the hyperparameter space for self-attention based navigation of 3D environments and qualitatively appraise behaviour observed from different hyperparameter sets, including their ability to generalise; (2) present strategies to improve the agents' generalisation abilities and navigation behaviour; and (3) show how models trained in simulation are capable of processing real world images meaningfully in **real time**. To our knowledge, this is the first demonstration of a self-attention based agent successfully trained in navigating a 3D action space, using less than 4000 parameters.  
### MIPI 2022 Challenge on Under-Display Camera Image **Restoration**: Methods and Results. (arXiv:2209.07052v1 [eess.IV])
- Authors : Ruicheng Feng, **Chongyi Li**, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Jun Jiang, Qingyu Yang, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07052](http://arxiv.org/abs/2209.07052)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge including five tracks focusing on novel image sensors and imaging algorithms. In this paper, we summarize and review the Under-Display Camera (UDC) Image **Restoration** track on MIPI 2022. In total, 167 participants were successfully registered, and 19 teams submitted results in the final testing phase. The developed solutions in this challenge achieved state-of-the-art performance on Under-Display Camera Image **Restoration**. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### MIPI 2022 Challenge on RGB+ToF Depth Completion: Dataset and Report. (arXiv:2209.07057v1 [cs.CV])
- Authors : Wenxiu Sun, Qingpeng Zhu, **Chongyi Li**, Ruicheng Feng, Shangchen Zhou, Jun Jiang, Qingyu Yang, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07057](http://arxiv.org/abs/2209.07057)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems is prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge including five tracks focusing on novel image sensors and imaging algorithms. In this paper, RGB+ToF Depth Completion, one of the five tracks, working on the fusion of RGB sensor and ToF sensor (with spot illumination) is introduced. The participants were provided with a new dataset called TetrasRGBD, which contains 18k pairs of high-quality synthetic RGB+Depth training data and 2.3k pairs of testing data from mixed sources. All the data are collected in an indoor scenario. We require that the running time of all methods should be real-time on desktop GPUs. The final results are evaluated using objective metrics and Mean Opinion Score (MOS) subjectively. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### MIPI 2022 Challenge on Quad-Bayer Re-mosaic: Dataset and Report. (arXiv:2209.07060v1 [eess.IV])
- Authors : Qingyu Yang, Guang Yang, Jun Jiang, **Chongyi Li**, Ruicheng Feng, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07060](http://arxiv.org/abs/2209.07060)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge, including five tracks focusing on novel image sensors and imaging algorithms. In this paper, Quad Joint Remosaic and Denoise, one of the five tracks, working on the interpolation of Quad CFA to Bayer at full resolution, is introduced. The participants were provided a new dataset, including 70 (training) and 15 (validation) scenes of high-quality Quad and Bayer pairs. In addition, for each scene, Quad of different noise levels was provided at 0dB, 24dB, and 42dB. All the data were captured using a Quad sensor in both outdoor and indoor conditions. The final results are evaluated using objective metrics, including PSNR, SSIM, LPIPS, and KLD. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### PROB-SLAM: **Real-time** Visual SLAM Based on Probabilistic Graph Optimization. (arXiv:2209.07061v1 [cs.CV])
- Authors : Xianwei Meng, Bonian Li
- Link : [http://arxiv.org/abs/2209.07061](http://arxiv.org/abs/2209.07061)
> ABSTRACT  :  Traditional SLAM algorithms are typically based on artificial features, which lack high-level information. By introducing semantic information, SLAM can own higher stability and robustness rather than purely hand-crafted features. However, the high uncertainty of semantic detection networks prohibits the practical functionality of high-level information. To solve the uncertainty property introduced by semantics, this paper proposed a novel probability map based on the Gaussian distribution assumption. This map transforms the semantic binary object detection into probability results, which help establish a probabilistic data association between artificial features and semantic info. Through our algorithm, the higher confidence will be given higher weights in each update step while the edge of the detection area will be endowed with lower confidence. Then the uncertainty is undermined and has less effect on nonlinear optimization. The experiments are carried out in the TUM RGBD dataset, results show that our system improves ORB-SLAM2 by about 15% in indoor environments' errors. We have demonstrated that the method can be successfully applied to environments containing dynamic objects.  
### Robust Implementation of Foreground Extraction and Vessel Segmentation for X-ray Coronary Angiography Image Sequence. (arXiv:2209.07237v1 [cs.CV])
- Authors : Zeyu Fu, Zhuang Fu, Chenzhuo Lv, Jun Yan
- Link : [http://arxiv.org/abs/2209.07237](http://arxiv.org/abs/2209.07237)
> ABSTRACT  :  The extraction of contrast-filled vessels from X-ray coronary angiography(XCA) image sequence has important clinical significance for intuitively diagnosis and therapy. In this study, XCA image sequence O is regarded as a three-dimensional tensor input, vessel layer H is a sparse tensor, and background layer B is a low-rank tensor. Using tensor nuclear norm(TNN) minimization, a novel method for vessel layer extraction based on tensor robust principal component analysis(TRPCA) is proposed. Furthermore, considering the irregular movement of vessels and the dynamic interference of surrounding irrelevant tissues, the total variation(TV) regularized spatial-temporal constraint is introduced to separate the dynamic background E. Subsequently, for the vessel images with uneven contrast distribution, a two-stage region growth(TSRG) method is utilized for vessel **enhancement** and segmentation. A global threshold segmentation is used as the pre-processing to obtain the main branch, and the Radon-Like features(RLF) filter is used to enhance and connect broken minor segments, the final vessel mask is constructed by combining the two intermediate results. We evaluated the visibility of TV-TRPCA algorithm for foreground extraction and the accuracy of TSRG algorithm for vessel segmentation on real clinical XCA image sequences and third-party database. Both qualitative and quantitative results verify the superiority of the proposed methods over the existing state-of-the-art approaches.  
### Visual Recognition with Deep Nearest Centroids. (arXiv:2209.07383v1 [cs.CV])
- Authors : Wenguan Wang, Cheng Han, Tianfei Zhou, Dongfang Liu
- Link : [http://arxiv.org/abs/2209.07383](http://arxiv.org/abs/2209.07383)
> ABSTRACT  :  We devise deep nearest centroids (DNC), a conceptually elegant yet surprisingly effective network for large-scale visual recognition, by revisiting Nearest Centroids, one of the most classic and simple classifiers. Current deep models learn the classifier in a fully parametric manner, ignoring the latent data structure and lacking simplicity and explainability. DNC instead conducts nonparametric, case-based reasoning; it utilizes sub-centroids of training samples to describe class distributions and clearly explains the classification as the proximity of test data and the class sub-centroids in the feature space. Due to the distance-based nature, the network output dimensionality is flexible, and all the learnable parameters are only for data embedding. That means all the knowledge learnt for ImageNet classification can be completely transferred for pixel recognition learning, under the "pre-training and fine-tuning" paradigm. Apart from its nested simplicity and intuitive decision-making mechanism, DNC can even possess ad-hoc explainability when the sub-centroids are selected as actual training images that humans can view and inspect. Compared with parametric counterparts, DNC performs better on image classification (CIFAR-10, ImageNet) and greatly boots pixel recognition (ADE20K, Cityscapes), with improved transparency and fewer learnable parameters, using various network architectures (ResNet, **Swin**) and segmentation models (FCN, DeepLabV3, **Swin**). We feel this work brings fundamental insights into related fields.  
### Motion Projection Consistency Based 3D Human Pose Estimation with Virtual Bones from Monocular Videos. (arXiv:2106.14706v2 [cs.CV] UPDATED)
- Authors : Guangming Wang, Honghao Zeng, Ziliang Wang, Zhe Liu, Hesheng Wang
- Link : [http://arxiv.org/abs/2106.14706](http://arxiv.org/abs/2106.14706)
> ABSTRACT  :  **Real-time** 3D human pose estimation is crucial for human-computer interaction. It is cheap and practical to estimate 3D human pose only from monocular video. However, recent bone splicing based 3D human pose estimation method brings about the problem of cumulative error. In this paper, the concept of virtual bones is proposed to solve such a challenge. The virtual bones are imaginary bones between non-adjacent joints. They do not exist in reality, but they bring new loop constraints for the estimation of 3D human joints. The proposed network in this paper predicts real bones and virtual bones, simultaneously. The final length of real bones is constrained and learned by the loop constructed by the predicted real bones and virtual bones. Besides, the motion constraints of joints in consecutive frames are considered. The consistency between the 2D projected position displacement predicted by the network and the captured real 2D displacement by the camera is proposed as a new projection consistency loss for the learning of 3D human pose. The experiments on the Human3.6M dataset demonstrate the good performance of the proposed method. Ablation studies demonstrate the effectiveness of the proposed inter-frame projection consistency constraints and intra-frame loop constraints.  
### End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v3 [cs.CV] UPDATED)
- Authors : Zelin Zhao, Jiaya Jia
- Link : [http://arxiv.org/abs/2207.14741](http://arxiv.org/abs/2207.14741)
> ABSTRACT  :  In this paper, we present a simple seq2seq formulation for view synthesis where we take a set of ray points as input and output colors corresponding to the rays. Directly applying a standard transformer on this seq2seq formulation has two limitations. First, the standard attention cannot successfully fit the volumetric rendering procedure, and therefore high-frequency components are missing in the synthesized views. Second, applying global attention to all rays and pixels is extremely inefficient. Inspired by the neural radiance field (**NeRF**), we propose the **NeRF** attention (**NeRF**A) to address the above problems. On the one hand, **NeRF**A considers the volumetric rendering equation as a soft feature modulation procedure. In this way, the feature modulation enhances the transformers with the **NeRF**-like inductive bias. On the other hand, **NeRF**A performs multi-stage attention to reduce the computational overhead. Furthermore, the **NeRF**A model adopts the ray and pixel transformers to learn the interactions between rays and pixels. **NeRF**A demonstrates superior performance over **NeRF** and NerFormer on four datasets: DeepVoxels, Blender, LLFF, and CO3D. Besides, **NeRF**A establishes a new state-of-the-art under two settings: the single-scene view synthesis and the category-centric novel view synthesis.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Hsuan Yang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation. Despite demonstrated success than state-of-the-art approaches, diffusion models often entail costly sampling procedures and sub-optimal likelihood estimation. Significant efforts have been made to improve the performance of diffusion models in various aspects. In this article, we present a comprehensive review of existing variants of diffusion models. Specifically, we provide the taxonomy of diffusion models and categorize them into three types: sampling-acceleration **enhancement**, likelihood-maximization **enhancement**, and data-generalization **enhancement**. We also introduce the other generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models) and discuss the connections between diffusion models and these generative models. Then we review the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of generative models. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.  
### Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
- Authors : Antoine Monod, Julie Delon, Matias Tassano
- Link : [http://arxiv.org/abs/2209.02854](http://arxiv.org/abs/2209.02854)
> ABSTRACT  :  This paper presents a novel method for restoring digital videos via a Deep Plug-and-Play (PnP) approach. Under a Bayesian formalism, the method consists in using a deep convolutional denoising network in place of the proximal operator of the prior in an alternating optimization scheme. We distinguish ourselves from prior PnP work by directly applying that method to restore a digital video from a degraded video observation. This way, a network trained once for denoising can be repurposed for other video **restoration** tasks. Our experiments in video deblurring, super-resolution, and interpolation of random missing pixels all show a clear benefit to using a network specifically designed for video denoising, as it yields better **restoration** performance and better temporal stability than a single image network with similar denoising performance using the same PnP formulation. Moreover, our method compares favorably to applying a different state-of-the-art PnP scheme separately on each frame of the sequence. This opens new perspectives in the field of video **restoration**.  
## eess.IV
---
### MIPI 2022 Challenge on Under-Display Camera Image **Restoration**: Methods and Results. (arXiv:2209.07052v1 [eess.IV])
- Authors : Ruicheng Feng, **Chongyi Li**, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Jun Jiang, Qingyu Yang, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07052](http://arxiv.org/abs/2209.07052)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge including five tracks focusing on novel image sensors and imaging algorithms. In this paper, we summarize and review the Under-Display Camera (UDC) Image **Restoration** track on MIPI 2022. In total, 167 participants were successfully registered, and 19 teams submitted results in the final testing phase. The developed solutions in this challenge achieved state-of-the-art performance on Under-Display Camera Image **Restoration**. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### MIPI 2022 Challenge on Quad-Bayer Re-mosaic: Dataset and Report. (arXiv:2209.07060v1 [eess.IV])
- Authors : Qingyu Yang, Guang Yang, Jun Jiang, **Chongyi Li**, Ruicheng Feng, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07060](http://arxiv.org/abs/2209.07060)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge, including five tracks focusing on novel image sensors and imaging algorithms. In this paper, Quad Joint Remosaic and Denoise, one of the five tracks, working on the interpolation of Quad CFA to Bayer at full resolution, is introduced. The participants were provided a new dataset, including 70 (training) and 15 (validation) scenes of high-quality Quad and Bayer pairs. In addition, for each scene, Quad of different noise levels was provided at 0dB, 24dB, and 42dB. All the data were captured using a Quad sensor in both outdoor and indoor conditions. The final results are evaluated using objective metrics, including PSNR, SSIM, LPIPS, and KLD. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
- Authors : Antoine Monod, Julie Delon, Matias Tassano
- Link : [http://arxiv.org/abs/2209.02854](http://arxiv.org/abs/2209.02854)
> ABSTRACT  :  This paper presents a novel method for restoring digital videos via a Deep Plug-and-Play (PnP) approach. Under a Bayesian formalism, the method consists in using a deep convolutional denoising network in place of the proximal operator of the prior in an alternating optimization scheme. We distinguish ourselves from prior PnP work by directly applying that method to restore a digital video from a degraded video observation. This way, a network trained once for denoising can be repurposed for other video **restoration** tasks. Our experiments in video deblurring, super-resolution, and interpolation of random missing pixels all show a clear benefit to using a network specifically designed for video denoising, as it yields better **restoration** performance and better temporal stability than a single image network with similar denoising performance using the same PnP formulation. Moreover, our method compares favorably to applying a different state-of-the-art PnP scheme separately on each frame of the sequence. This opens new perspectives in the field of video **restoration**.  
## cs.LG
---
### Robust field-level inference with **dark** matter halos. (arXiv:2209.06843v1 [astro-ph.CO])
- Authors : Helen Shao, Francisco Villaescusa, Pablo Villanueva, Romain Teyssier, Marco Gatti, Derek Inman, Yueying Ni, Mihir Kulkarni, Eli Visbal, Daniel Angles, Tiago Castro, Elena Hernandez, Klaus Dolag
- Link : [http://arxiv.org/abs/2209.06843](http://arxiv.org/abs/2209.06843)
> ABSTRACT  :  We train graph neural networks on halo catalogues from Gadget N-body simulations to perform field-level likelihood-free inference of cosmological parameters. The catalogues contain $\lesssim$5,000 halos with masses $\gtrsim 10^{10}~h^{-1}M_\odot$ in a periodic volume of $(25~h^{-1}{\rm Mpc})^3$; every halo in the catalogue is characterized by several properties such as position, mass, velocity, concentration, and maximum circular velocity. Our models, built to be permutationally, translationally, and rotationally invariant, do not impose a minimum scale on which to extract information and are able to infer the values of $\Omega_{\rm m}$ and $\sigma_8$ with a mean relative error of $\sim6\%$, when using positions plus velocities and positions plus masses, respectively. More importantly, we find that our models are very robust: they can infer the value of $\Omega_{\rm m}$ and $\sigma_8$ when tested using halo catalogues from thousands of N-body simulations run with five different N-body codes: Abacus, CUBEP$^3$M, Enzo, PKDGrav3, and Ramses. Surprisingly, the model trained to infer $\Omega_{\rm m}$ also works when tested on thousands of state-of-the-art CAMELS hydrodynamic simulations run with four different codes and subgrid physics implementations. Using halo properties such as concentration and maximum circular velocity allow our models to extract more information, at the expense of breaking the robustness of the models. This may happen because the different N-body codes are not converged on the relevant scales corresponding to these parameters.  
### Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v1 [q-bio.NC])
- Authors : Chandramouli Rajagopalan, David Rawlinson, Elkhonon Goldberg, Gideon Kowadlo
- Link : [http://arxiv.org/abs/2209.06862](http://arxiv.org/abs/2209.06862)
> ABSTRACT  :  The brains of all **bilateral**ly symmetric animals on Earth are are divided into left and right hemispheres. The anatomy and functionality of the hemispheres have a large degree of overlap, but they specialize to possess different attributes. The left hemisphere is believed to specialize in specificity and routine, the right in generalities and novelty. In this study, we propose an artificial neural network that imitates that **bilateral** architecture using two convolutional neural networks with different training objectives and test it on an image classification task. The **bilateral** architecture outperforms architectures of similar representational capacity that don't exploit differential specialization. It demonstrates the efficacy of **bilateral**ism and constitutes a new principle that could be incorporated into other computational neuroscientific models and used as an inductive bias when designing new ML systems. An analysis of the model can help us to understand the human brain.  
### Graph Neural Network Based Node Deployment for Throughput **Enhancement**. (arXiv:2209.06905v1 [cs.NI])
- Authors : Yifei Yang, Dongmian Zou, Xiaofan He
- Link : [http://arxiv.org/abs/2209.06905](http://arxiv.org/abs/2209.06905)
> ABSTRACT  :  The recent rapid growth in mobile data traffic entails a pressing demand for improving the throughput of the underlying wireless communication networks. Network node deployment has been considered as an effective approach for throughput **enhancement** which, however, often leads to highly non-trivial non-convex optimizations. Although convex approximation based solutions are considered in the literature, their approximation to the actual throughput may be loose and sometimes lead to unsatisfactory performance. With this consideration, in this paper, we propose a novel graph neural network (GNN) method for the network node deployment problem. Specifically, we fit a GNN to the network throughput and use the gradients of this GNN to iteratively update the locations of the network nodes. Besides, we show that an expressive GNN has the capacity to approximate both the function value and the gradients of a multivariate permutation-invariant function, as a theoretic support to the proposed method. To further improve the throughput, we also study a hybrid node deployment method based on this approach. To train the desired GNN, we adopt a policy gradient algorithm to create datasets containing good training samples. Numerical experiments show that the proposed methods produce competitive results compared to the baselines.  
### Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models. (arXiv:2209.06970v1 [cs.CV])
- Authors : Chen Henry, Saman Motamed, Shaunak Srivastava, Fernando De, la Torre
- Link : [http://arxiv.org/abs/2209.06970](http://arxiv.org/abs/2209.06970)
> ABSTRACT  :  Generative models (e.g., GANs and diffusion models) learn the underlying data distribution in an unsupervised manner. However, many applications of interest require sampling from a specific region of the generative model's output space or evenly over a range of characteristics. To allow efficient sampling in these scenarios, we propose Generative Visual Prompt (PromptGen), a framework for distributional control over pre-trained generative models by incorporating knowledge of arbitrary off-the-shelf models. PromptGen defines control as an energy-based model (EBM) and samples images in a feed-forward manner by approximating the EBM with invertible neural networks, avoiding optimization at inference. We demonstrate how PromptGen can control several generative models (e.g., StyleGAN2, Style**NeRF**, diffusion autoencoder, and NVAE) using various off-the-shelf models: (1) with the CLIP model, PromptGen can sample images guided by text, (2) with image classifiers, PromptGen can de-bias generative models across a set of attributes, and (3) with inverse graphics models, PromptGen can sample images of the same identity in different poses. (4) Finally, PromptGen reveals that the CLIP model shows "reporting bias" when used as control, and PromptGen can further de-bias this controlled distribution in an iterative manner. Our code is available at https://github.com/ChenWu98/Generative-Visual-Prompt.  
### Towards self-attention based navigation in the real world. (arXiv:2209.07043v1 [cs.RO])
- Authors : Jaime Ruiz, Jack White, Stephen Petrie, Tatiana Kameneva, Chris McCarthy
- Link : [http://arxiv.org/abs/2209.07043](http://arxiv.org/abs/2209.07043)
> ABSTRACT  :  Vision-based navigation requires processing complex information to make task-orientated decisions. Applications include autonomous robots, self-driving cars, and assistive vision for humans. One of the key elements in the process is the extraction and selection of relevant features in pixel space upon which to base action choices, for which Machine Learning techniques are well suited. However, Deep Reinforcement Learning agents trained in simulation often exhibit unsatisfactory results when deployed in the real-world due to perceptual differences known as the $\textit{reality gap}$. An approach that is yet to be explored to bridge this gap is self-attention. In this paper we (1) perform a systematic exploration of the hyperparameter space for self-attention based navigation of 3D environments and qualitatively appraise behaviour observed from different hyperparameter sets, including their ability to generalise; (2) present strategies to improve the agents' generalisation abilities and navigation behaviour; and (3) show how models trained in simulation are capable of processing real world images meaningfully in **real time**. To our knowledge, this is the first demonstration of a self-attention based agent successfully trained in navigating a 3D action space, using less than 4000 parameters.  
### Statistical monitoring of models based on artificial intelligence. (arXiv:2209.07436v1 [stat.ME])
- Authors : Anna Malinovskaya, Pavlo Mozharovskyi, Philipp Otto
- Link : [http://arxiv.org/abs/2209.07436](http://arxiv.org/abs/2209.07436)
> ABSTRACT  :  The rapid advancement of models based on artificial intelligence demands innovative monitoring techniques which can operate in **real time** with low computational costs. In machine learning, especially if we consider neural network (NN) learning algorithms, and in particular deep-learning architectures, the models are often trained in a supervised manner. Consequently, the learned relationship between the input and the output must remain valid during the model's deployment. If this stationarity assumption holds, we can conclude that the NN generates accurate predictions. Otherwise, the retraining or rebuilding of the model is required. We propose to consider the latent feature representation of the data (called "embedding") generated by the NN for determining the time point when the data stream starts being nonstationary. To be precise, we monitor embeddings by applying multivariate control charts based on the calculation of the data depth and normalized ranks. The performance of the introduced method is evaluated using various NNs with different underlying data formats.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Hsuan Yang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation. Despite demonstrated success than state-of-the-art approaches, diffusion models often entail costly sampling procedures and sub-optimal likelihood estimation. Significant efforts have been made to improve the performance of diffusion models in various aspects. In this article, we present a comprehensive review of existing variants of diffusion models. Specifically, we provide the taxonomy of diffusion models and categorize them into three types: sampling-acceleration **enhancement**, likelihood-maximization **enhancement**, and data-generalization **enhancement**. We also introduce the other generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models) and discuss the connections between diffusion models and these generative models. Then we review the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of generative models. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.  
### Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
- Authors : Antoine Monod, Julie Delon, Matias Tassano
- Link : [http://arxiv.org/abs/2209.02854](http://arxiv.org/abs/2209.02854)
> ABSTRACT  :  This paper presents a novel method for restoring digital videos via a Deep Plug-and-Play (PnP) approach. Under a Bayesian formalism, the method consists in using a deep convolutional denoising network in place of the proximal operator of the prior in an alternating optimization scheme. We distinguish ourselves from prior PnP work by directly applying that method to restore a digital video from a degraded video observation. This way, a network trained once for denoising can be repurposed for other video **restoration** tasks. Our experiments in video deblurring, super-resolution, and interpolation of random missing pixels all show a clear benefit to using a network specifically designed for video denoising, as it yields better **restoration** performance and better temporal stability than a single image network with similar denoising performance using the same PnP formulation. Moreover, our method compares favorably to applying a different state-of-the-art PnP scheme separately on each frame of the sequence. This opens new perspectives in the field of video **restoration**.  
## cs.AI
---
### Robust field-level inference with **dark** matter halos. (arXiv:2209.06843v1 [astro-ph.CO])
- Authors : Helen Shao, Francisco Villaescusa, Pablo Villanueva, Romain Teyssier, Marco Gatti, Derek Inman, Yueying Ni, Mihir Kulkarni, Eli Visbal, Daniel Angles, Tiago Castro, Elena Hernandez, Klaus Dolag
- Link : [http://arxiv.org/abs/2209.06843](http://arxiv.org/abs/2209.06843)
> ABSTRACT  :  We train graph neural networks on halo catalogues from Gadget N-body simulations to perform field-level likelihood-free inference of cosmological parameters. The catalogues contain $\lesssim$5,000 halos with masses $\gtrsim 10^{10}~h^{-1}M_\odot$ in a periodic volume of $(25~h^{-1}{\rm Mpc})^3$; every halo in the catalogue is characterized by several properties such as position, mass, velocity, concentration, and maximum circular velocity. Our models, built to be permutationally, translationally, and rotationally invariant, do not impose a minimum scale on which to extract information and are able to infer the values of $\Omega_{\rm m}$ and $\sigma_8$ with a mean relative error of $\sim6\%$, when using positions plus velocities and positions plus masses, respectively. More importantly, we find that our models are very robust: they can infer the value of $\Omega_{\rm m}$ and $\sigma_8$ when tested using halo catalogues from thousands of N-body simulations run with five different N-body codes: Abacus, CUBEP$^3$M, Enzo, PKDGrav3, and Ramses. Surprisingly, the model trained to infer $\Omega_{\rm m}$ also works when tested on thousands of state-of-the-art CAMELS hydrodynamic simulations run with four different codes and subgrid physics implementations. Using halo properties such as concentration and maximum circular velocity allow our models to extract more information, at the expense of breaking the robustness of the models. This may happen because the different N-body codes are not converged on the relevant scales corresponding to these parameters.  
### Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v1 [q-bio.NC])
- Authors : Chandramouli Rajagopalan, David Rawlinson, Elkhonon Goldberg, Gideon Kowadlo
- Link : [http://arxiv.org/abs/2209.06862](http://arxiv.org/abs/2209.06862)
> ABSTRACT  :  The brains of all **bilateral**ly symmetric animals on Earth are are divided into left and right hemispheres. The anatomy and functionality of the hemispheres have a large degree of overlap, but they specialize to possess different attributes. The left hemisphere is believed to specialize in specificity and routine, the right in generalities and novelty. In this study, we propose an artificial neural network that imitates that **bilateral** architecture using two convolutional neural networks with different training objectives and test it on an image classification task. The **bilateral** architecture outperforms architectures of similar representational capacity that don't exploit differential specialization. It demonstrates the efficacy of **bilateral**ism and constitutes a new principle that could be incorporated into other computational neuroscientific models and used as an inductive bias when designing new ML systems. An analysis of the model can help us to understand the human brain.  
### NanoFlowNet: **Real-time** Dense Optical Flow on a Nano Quadcopter. (arXiv:2209.06918v1 [cs.RO])
- Authors : Federico Paredes, de Croon
- Link : [http://arxiv.org/abs/2209.06918](http://arxiv.org/abs/2209.06918)
> ABSTRACT  :  Nano quadcopters are small, agile, and cheap platforms that are well suited for deployment in narrow, cluttered environments. Due to their limited payload, these vehicles are highly constrained in processing power, rendering conventional vision-based methods for safe and autonomous navigation incompatible. Recent machine learning developments promise high-performance perception at low latency, while dedicated edge computing hardware has the potential to augment the processing capabilities of these limited devices. In this work, we present NanoFlowNet, a lightweight convolutional neural network for real-time dense optical flow estimation on edge computing hardware. We draw inspiration from recent advances in semantic segmentation for the design of this network. Additionally, we guide the learning of optical flow using motion boundary ground truth data, which improves performance with no impact on latency. Validation results on the MPI-Sintel dataset show the high performance of the proposed network given its constrained architecture. Additionally, we successfully demonstrate the capabilities of NanoFlowNet by deploying it on the ultra-low power GAP8 microprocessor and by applying it to vision-based obstacle avoidance on board a Bitcraze Crazyflie, a 34 g nano quadcopter.  
### End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v3 [cs.CV] UPDATED)
- Authors : Zelin Zhao, Jiaya Jia
- Link : [http://arxiv.org/abs/2207.14741](http://arxiv.org/abs/2207.14741)
> ABSTRACT  :  In this paper, we present a simple seq2seq formulation for view synthesis where we take a set of ray points as input and output colors corresponding to the rays. Directly applying a standard transformer on this seq2seq formulation has two limitations. First, the standard attention cannot successfully fit the volumetric rendering procedure, and therefore high-frequency components are missing in the synthesized views. Second, applying global attention to all rays and pixels is extremely inefficient. Inspired by the neural radiance field (**NeRF**), we propose the **NeRF** attention (**NeRF**A) to address the above problems. On the one hand, **NeRF**A considers the volumetric rendering equation as a soft feature modulation procedure. In this way, the feature modulation enhances the transformers with the **NeRF**-like inductive bias. On the other hand, **NeRF**A performs multi-stage attention to reduce the computational overhead. Furthermore, the **NeRF**A model adopts the ray and pixel transformers to learn the interactions between rays and pixels. **NeRF**A demonstrates superior performance over **NeRF** and NerFormer on four datasets: DeepVoxels, Blender, LLFF, and CO3D. Besides, **NeRF**A establishes a new state-of-the-art under two settings: the single-scene view synthesis and the category-centric novel view synthesis.  
### Summarizing Patients Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models. (arXiv:2208.08408v2 [cs.CL] UPDATED)
- Authors : Yanjun Gao, Dmitriy Dligach, Timothy Miller, Dongfang Xu, Majid Afshar
- Link : [http://arxiv.org/abs/2208.08408](http://arxiv.org/abs/2208.08408)
> ABSTRACT  :  Automatically summarizing patients' main problems from daily progress notes using natural language processing methods helps to battle against information and cognitive overload in hospital settings and potentially assists providers with computerized diagnostic decision support. Problem list summarization requires a model to understand, abstract, and generate clinical documentation. In this work, we propose a new NLP task that aims to generate a list of problems in a patient's daily care plan using input from the provider's progress notes during hospitalization. We investigate the performance of T5 and BART, two state-of-the-art seq2seq transformer architectures, in solving this problem. We provide a corpus built on top of progress notes from publicly available electronic health record progress notes in the Medical Information Mart for Intensive Care (MIMIC)-III. T5 and BART are trained on general domain text, and we experiment with a data augmentation method and a domain adaptation pre-training method to increase **exposure** to medical vocabulary and knowledge. Evaluation methods include ROUGE, BERTScore, cosine similarity on sentence embedding, and F-score on medical concepts. Results show that T5 with domain adaptive pre-training achieves significant performance gains compared to a rule-based system and general domain pre-trained language models, indicating a promising direction for tackling the problem summarization task.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Hsuan Yang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with a solid theoretical foundation. Despite demonstrated success than state-of-the-art approaches, diffusion models often entail costly sampling procedures and sub-optimal likelihood estimation. Significant efforts have been made to improve the performance of diffusion models in various aspects. In this article, we present a comprehensive review of existing variants of diffusion models. Specifically, we provide the taxonomy of diffusion models and categorize them into three types: sampling-acceleration **enhancement**, likelihood-maximization **enhancement**, and data-generalization **enhancement**. We also introduce the other generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models) and discuss the connections between diffusion models and these generative models. Then we review the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of generative models. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.  
# Paper List
---
## cs.CV
---
**118** new papers in cs.CV:-) 
1. DEANet: Decomposition **Enhancement** and Adjustment Network for **Low-Light** Image **Enhancement**. (arXiv:2209.06823v1 [cs.CV])
2. Urban precipitation downscaling using deep learning: a smart city application over Austin, Texas, USA. (arXiv:2209.06848v1 [physics.ao-ph])
3. CAT: Controllable Attribute Translation for Fair Facial Attribute Classification. (arXiv:2209.06850v1 [cs.CV])
4. Data Lifecycle Management in Evolving Input Distributions for Learning-based Aerospace Applications. (arXiv:2209.06855v1 [cs.CV])
5. Reconstruction of Three-dimensional Scroll Wave Chaos in Opaque and Transparent Excitable Media using Deep Neural Networks. (arXiv:2209.06860v1 [q-bio.TO])
6. Landmark-free Statistical Shape Modeling via Neural Flow Deformations. (arXiv:2209.06861v1 [cs.CV])
7. NanoFlowNet: **Real-time** Dense Optical Flow on a Nano Quadcopter. (arXiv:2209.06918v1 [cs.RO])
8. End-to-End Multi-View Structure-from-Motion with Hypercorrelation Volumes. (arXiv:2209.06926v1 [cs.CV])
9. Joint Debiased Representation and Image Clustering Learning with Self-Supervision. (arXiv:2209.06941v1 [cs.CV])
10. Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v1 [eess.IV])
11. Landmark Tracking in Liver US images Using Cascade Convolutional Neural Networks with Long Short-Term Memory. (arXiv:2209.06952v1 [cs.CV])
12. On the interplay of adversarial robustness and architecture components: patches, convolution and attention. (arXiv:2209.06953v1 [cs.CV])
13. Finetuning Pretrained Vision-Language Models with Correlation Information Bottleneck for Robust Visual Question Answering. (arXiv:2209.06954v1 [cs.CV])
14. A novel illumination condition varied image dataset-Food Vision Dataset (FVD) for fair and reliable consumer acceptability predictions from food. (arXiv:2209.06967v1 [cs.CV])
15. Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models. (arXiv:2209.06970v1 [cs.CV])
16. PointACL:Adversarial Contrastive Learning for Robust Point Clouds Representation under Adversarial Attack. (arXiv:2209.06971v1 [cs.CV])
17. Learning from Future: A Novel Self-Training Framework for Semantic Segmentation. (arXiv:2209.06993v1 [cs.CV])
18. PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on Transformer. (arXiv:2209.06994v1 [cs.CV])
19. Pose Attention-Guided Profile-to-Frontal Face Recognition. (arXiv:2209.07001v1 [cs.CV])
20. Self-Supervised Texture Image Anomaly Detection By Fusing Normalizing Flow and Dictionary Learning. (arXiv:2209.07005v1 [cs.CV])
21. Gromov-Wasserstein Autoencoders. (arXiv:2209.07007v1 [cs.LG])
22. Can We Solve 3D Vision Tasks Starting from A 2D Vision Transformer?. (arXiv:2209.07026v1 [cs.CV])
23. Model-Guided Multi-Contrast Deep Unfolding Network for MRI Super-resolution Reconstruction. (arXiv:2209.07030v1 [eess.IV])
24. A Temporal Densely Connected Recurrent Network for Event-based Human Pose Estimation. (arXiv:2209.07034v1 [cs.CV])
25. Efficient Perception, Planning, and Control Algorithms for Vision-Based Automated Vehicles. (arXiv:2209.07042v1 [cs.RO])
26. Towards self-attention based navigation in the real world. (arXiv:2209.07043v1 [cs.RO])
27. Exploring Visual Interpretability for Contrastive Language-Image Pre-training. (arXiv:2209.07046v1 [cs.CV])
28. MIPI 2022 Challenge on Under-Display Camera Image **Restoration**: Methods and Results. (arXiv:2209.07052v1 [eess.IV])
29. MIPI 2022 Challenge on RGB+ToF Depth Completion: Dataset and Report. (arXiv:2209.07057v1 [cs.CV])
30. MIPI 2022 Challenge on Quad-Bayer Re-mosaic: Dataset and Report. (arXiv:2209.07060v1 [eess.IV])
31. PROB-SLAM: **Real-time** Visual SLAM Based on Probabilistic Graph Optimization. (arXiv:2209.07061v1 [cs.CV])
32. Active Self-Training for Weakly Supervised 3D Scene Semantic Segmentation. (arXiv:2209.07069v1 [cs.CV])
33. Self-distilled Feature Aggregation for Self-supervised Monocular Depth Estimation. (arXiv:2209.07088v1 [cs.CV])
34. Multi-Modal Masked Autoencoders for Medical Vision-and-Language Pre-Training. (arXiv:2209.07098v1 [cs.CV])
35. Bridging Implicit and Explicit Geometric Transformations for Single-Image View Synthesis. (arXiv:2209.07105v1 [cs.CV])
36. LAVOLUTION: Measurement of Non-target Structural Displacement Calibrated by Structured Light. (arXiv:2209.07115v1 [cs.CV])
37. Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge. (arXiv:2209.07118v1 [cs.CL])
38. 4DenoiseNet: Adverse Weather Denoising from Adjacent Point Clouds. (arXiv:2209.07121v1 [cs.CV])
39. Forgetting to Remember: A Scalable Incremental Learning Framework for Cross-Task Blind Image Quality Assessment. (arXiv:2209.07126v1 [cs.CV])
40. HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator. (arXiv:2209.07143v1 [cs.CV])
41. One-Shot Transfer of Affordance Regions? AffCorrs!. (arXiv:2209.07147v1 [cs.CV])
42. Brain Imaging Generation with Latent Diffusion Models. (arXiv:2209.07162v1 [eess.IV])
43. Morphology-Aware Interactive Keypoint Estimation. (arXiv:2209.07163v1 [cs.CV])
44. NU-net: An Unpretentious Nested U-net for Breast Tumor Segmentation. (arXiv:2209.07193v1 [eess.IV])
45. Face Shape-Guided Deep Feature Alignment for Face Recognition Robust to Face Misalignment. (arXiv:2209.07220v1 [cs.CV])
46. Number of Attention Heads vs Number of Transformer-Encoders in Computer Vision. (arXiv:2209.07221v1 [cs.CV])
47. A Spatiotemporal Model for Precise and Efficient Fully-automatic 3D Motion Correction in OCT. (arXiv:2209.07232v1 [eess.IV])
48. Robust Implementation of Foreground Extraction and Vessel Segmentation for X-ray Coronary Angiography Image Sequence. (arXiv:2209.07237v1 [cs.CV])
49. Revisiting Crowd Counting: State-of-the-art, Trends, and Future Perspectives. (arXiv:2209.07271v1 [cs.CV])
50. HarDNet-DFUS: An Enhanced Harmonically-Connected Network for Diabetic Foot Ulcer Image Segmentation and Colonoscopy Polyp Segmentation. (arXiv:2209.07313v1 [eess.IV])
51. A Continual Development Methodology for Large-scale Multitask Dynamic ML Systems. (arXiv:2209.07326v1 [cs.LG])
52. CLIPping Privacy: Identity Inference Attacks on Multi-Modal Machine Learning Models. (arXiv:2209.07341v1 [cs.LG])
53. 3DMM-RF: Convolutional Radiance Fields for 3D Face Modeling. (arXiv:2209.07366v1 [cs.CV])
54. Visual Recognition with Deep Nearest Centroids. (arXiv:2209.07383v1 [cs.CV])
55. Online Marker-free Extrinsic Camera Calibration using Person Keypoint Detections. (arXiv:2209.07393v1 [cs.CV])
56. A Light Recipe to Train Robust Vision Transformers. (arXiv:2209.07399v1 [cs.CV])
57. Evolving Zero Cost Proxies For Neural Architecture Scoring. (arXiv:2209.07413v1 [cs.LG])
58. Trustworthy modelling of atmospheric formaldehyde powered by deep learning. (arXiv:2209.07414v1 [physics.ao-ph])
59. FFPA-Net: Efficient Feature Fusion with Projection Awareness for 3D Object Detection. (arXiv:2209.07419v1 [cs.CV])
60. A Robotic Visual Grasping Design: Rethinking Convolution Neural Network with High-Resolutions. (arXiv:2209.07459v1 [cs.RO])
61. On the Surprising Effectiveness of Transformers in Low-Labeled Video Recognition. (arXiv:2209.07474v1 [cs.CV])
62. Hydra Attention: Efficient Attention with Many Heads. (arXiv:2209.07484v1 [cs.CV])
63. Test-Time Prompt Tuning for Zero-Shot Generalization in Vision-Language Models. (arXiv:2209.07511v1 [cs.CV])
64. Distribution Aware Metrics for Conditional Natural Language Generation. (arXiv:2209.07518v1 [cs.CL])
65. On-Device Domain Generalization. (arXiv:2209.07521v1 [cs.CV])
66. Test-Time Training with Masked Autoencoders. (arXiv:2209.07522v1 [cs.CV])
67. OmniVL:One Foundation Model for Image-Language and Video-Language Tasks. (arXiv:2209.07526v1 [cs.CV])
68. Dynamic Graph Message Passing Networks. (arXiv:1908.06955v5 [cs.CV] UPDATED)
69. Delving into Inter-Image Invariance for Unsupervised Visual Representations. (arXiv:2008.11702v3 [cs.CV] UPDATED)
70. Normalized Weighting Schemes for Image Interpolation Algorithms. (arXiv:2011.08559v4 [cs.GR] UPDATED)
71. ISP Distillation. (arXiv:2101.10203v2 [cs.CV] UPDATED)
72. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v6 [cs.CV] UPDATED)
73. Motion Projection Consistency Based 3D Human Pose Estimation with Virtual Bones from Monocular Videos. (arXiv:2106.14706v2 [cs.CV] UPDATED)
74. LibFewShot: A Comprehensive Library for Few-shot Learning. (arXiv:2109.04898v3 [cs.CV] UPDATED)
75. Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends. (arXiv:2109.09824v5 [cs.CV] UPDATED)
76. Rapid detection and recognition of whole brain activity in a freely behaving Caenorhabditis elegans. (arXiv:2109.10474v4 [q-bio.QM] UPDATED)
77. A Closer Look at Prototype Classifier for Few-shot Image Classification. (arXiv:2110.05076v5 [cs.CV] UPDATED)
78. Efficient 3D Deep LiDAR Odometry. (arXiv:2111.02135v2 [cs.CV] UPDATED)
79. DoodleFormer: Creative Sketch Drawing with Transformers. (arXiv:2112.03258v3 [cs.CV] UPDATED)
80. Decision-based Black-box Attack Against Vision Transformers via Patch-wise Adversarial Removal. (arXiv:2112.03492v2 [cs.CV] UPDATED)
81. Few-Shot Object Detection: A Comprehensive Survey. (arXiv:2112.11699v2 [cs.CV] UPDATED)
82. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v3 [cs.HC] UPDATED)
83. Sign Language Video Retrieval with Free-Form Textual Queries. (arXiv:2201.02495v2 [cs.CV] UPDATED)
84. ImageSubject: A Large-scale Dataset for Subject Detection. (arXiv:2201.03101v2 [cs.CV] UPDATED)
85. Meta-RangeSeg: LiDAR Sequence Semantic Segmentation Using Multiple Feature Aggregation. (arXiv:2202.13377v3 [cs.CV] UPDATED)
86. Descriptellation: Deep Learned Constellation Descriptors. (arXiv:2203.00567v2 [cs.RO] UPDATED)
87. Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis. (arXiv:2203.02202v2 [eess.IV] UPDATED)
88. Self-Supervised Domain Calibration and Uncertainty Estimation for Place Recognition. (arXiv:2203.04446v2 [cs.CV] UPDATED)
89. Defending From Physically-Realizable Adversarial Attacks Through Internal Over-Activation Analysis. (arXiv:2203.07341v2 [cs.CV] UPDATED)
90. Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared Control on the Hannes Prosthesis. (arXiv:2203.09812v2 [cs.RO] UPDATED)
91. Learning Occlusion-Aware Coarse-to-Fine Depth Map for Self-supervised Monocular Depth Estimation. (arXiv:2203.10925v2 [cs.CV] UPDATED)
92. ACR Loss: Adaptive Coordinate-based Regression Loss for Face Alignment. (arXiv:2203.15835v2 [cs.CV] UPDATED)
93. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v4 [cs.LG] UPDATED)
94. Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware Adversarial Training. (arXiv:2204.02844v2 [cs.CV] UPDATED)
95. Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling. (arXiv:2205.05826v2 [cs.AR] UPDATED)
96. Economical Precise Manipulation and Auto Eye-Hand Coordination with Binocular Visual Reinforcement Learning. (arXiv:2205.05963v2 [cs.RO] UPDATED)
97. Flexible Diffusion Modeling of Long Videos. (arXiv:2205.11495v2 [cs.CV] UPDATED)
98. Falconn++: A Locality-sensitive Filtering Approach for Approximate Nearest Neighbor Search. (arXiv:2206.01382v2 [cs.DS] UPDATED)
99. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v7 [cs.LG] UPDATED)
100. Metrics reloaded: Pitfalls and recommendations for image analysis validation. (arXiv:2206.01653v3 [cs.CV] UPDATED)
101. Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning. (arXiv:2206.01843v2 [cs.CV] UPDATED)
102. Understanding Robust Learning through the Lens of Representation Similarities. (arXiv:2206.09868v2 [cs.LG] UPDATED)
103. Learning Debiased Classifier with Biased Committee. (arXiv:2206.10843v2 [cs.LG] UPDATED)
104. SuperTickets: Drawing Task-Agnostic Lottery Tickets from Supernets via Jointly Architecture Searching and Parameter Pruning. (arXiv:2207.03677v3 [cs.CV] UPDATED)
105. Rethinking Data Augmentation for Robust Visual Question Answering. (arXiv:2207.08739v2 [cs.CV] UPDATED)
106. End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v3 [cs.CV] UPDATED)
107. STrajNet: Multi-modal Hierarchical Transformer for Occupancy Flow Field Prediction in Autonomous Driving. (arXiv:2208.00394v2 [cs.CV] UPDATED)
108. Improved post-hoc probability calibration for out-of-domain MRI segmentation. (arXiv:2208.02870v2 [cs.CV] UPDATED)
109. CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal Relationships between Chest X-Rays. (arXiv:2208.03873v2 [cs.CV] UPDATED)
110. Task Oriented Video Coding: A Survey. (arXiv:2208.07313v2 [eess.IV] UPDATED)
111. SC-Explorer: Incremental 3D Scene Completion for Safe and Efficient Exploration Mapping and Planning. (arXiv:2208.08307v2 [cs.RO] UPDATED)
112. Adaptive Perception Transformer for Temporal Action Localization. (arXiv:2208.11908v2 [cs.CV] UPDATED)
113. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
114. Studying Bias in GANs through the Lens of Race. (arXiv:2209.02836v2 [cs.CV] UPDATED)
115. Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
116. DevNet: Self-supervised Monocular Depth Learning via Density Volume Construction. (arXiv:2209.06351v2 [cs.CV] UPDATED)
117. Learning to Evaluate Performance of Multi-modal Semantic Localization. (arXiv:2209.06515v2 [cs.CV] UPDATED)
118. NAAP-440 Dataset and Baseline for Neural Architecture Accuracy Prediction. (arXiv:2209.06626v2 [cs.CV] UPDATED)
## eess.IV
---
**16** new papers in eess.IV:-) 
1. Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v1 [eess.IV])
2. Model-Guided Multi-Contrast Deep Unfolding Network for MRI Super-resolution Reconstruction. (arXiv:2209.07030v1 [eess.IV])
3. MIPI 2022 Challenge on Under-Display Camera Image **Restoration**: Methods and Results. (arXiv:2209.07052v1 [eess.IV])
4. MIPI 2022 Challenge on Quad-Bayer Re-mosaic: Dataset and Report. (arXiv:2209.07060v1 [eess.IV])
5. Brain Imaging Generation with Latent Diffusion Models. (arXiv:2209.07162v1 [eess.IV])
6. NU-net: An Unpretentious Nested U-net for Breast Tumor Segmentation. (arXiv:2209.07193v1 [eess.IV])
7. Motion-Adapted Three-Dimensional Frequency Selective Extrapolation. (arXiv:2209.07231v1 [eess.IV])
8. A Spatiotemporal Model for Precise and Efficient Fully-automatic 3D Motion Correction in OCT. (arXiv:2209.07232v1 [eess.IV])
9. HarDNet-DFUS: An Enhanced Harmonically-Connected Network for Diabetic Foot Ulcer Image Segmentation and Colonoscopy Polyp Segmentation. (arXiv:2209.07313v1 [eess.IV])
10. MRI-MECH: Mechanics-informed MRI to estimate esophageal health. (arXiv:2209.07492v1 [physics.med-ph])
11. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v3 [cs.HC] UPDATED)
12. Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis. (arXiv:2203.02202v2 [eess.IV] UPDATED)
13. Learning to Generate Realistic Noisy Images via Pixel-level Noise-aware Adversarial Training. (arXiv:2204.02844v2 [cs.CV] UPDATED)
14. Learning Series-Parallel Lookup Tables for Efficient Image Super-Resolution. (arXiv:2207.12987v2 [eess.IV] UPDATED)
15. Task Oriented Video Coding: A Survey. (arXiv:2208.07313v2 [eess.IV] UPDATED)
16. Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
## cs.LG
---
**189** new papers in cs.LG:-) 
1. An ensemble Multi-Agent System for non-linear classification. (arXiv:2209.06824v1 [cs.LG])
2. Modifying Squint for Prediction with Expert Advice in a Changing Environment. (arXiv:2209.06826v1 [cs.LG])
3. Weakly Supervised Invariant Representation Learning Via Disentangling Known and Unknown Nuisance Factors. (arXiv:2209.06827v1 [cs.LG])
4. A Temporal Anomaly Detection System for Vehicles utilizing Functional Working Groups and Sensor Channels. (arXiv:2209.06828v1 [cs.LG])
5. Robust field-level inference with **dark** matter halos. (arXiv:2209.06843v1 [astro-ph.CO])
6. Urban precipitation downscaling using deep learning: a smart city application over Austin, Texas, USA. (arXiv:2209.06848v1 [physics.ao-ph])
7. A Model Drift Detection and Adaptation Framework for 5G Core Networks. (arXiv:2209.06852v1 [cs.NI])
8. Asymptotic Statistical Analysis of $f$-divergence GAN. (arXiv:2209.06853v1 [math.ST])
9. Data Lifecycle Management in Evolving Input Distributions for Learning-based Aerospace Applications. (arXiv:2209.06855v1 [cs.CV])
10. Landmark-free Statistical Shape Modeling via Neural Flow Deformations. (arXiv:2209.06861v1 [cs.CV])
11. Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v1 [q-bio.NC])
12. Robust Constrained Reinforcement Learning. (arXiv:2209.06866v1 [cs.LG])
13. On the State of the Art in Authorship Attribution and Authorship Verification. (arXiv:2209.06869v1 [cs.CL])
14. Vectorized Adjoint Sensitivity Method for Graph Convolutional Neural Ordinary Differential Equations. (arXiv:2209.06886v1 [cs.LG])
15. Time Series Prediction for Food sustainability. (arXiv:2209.06889v1 [cs.LG])
16. Out of One, Many: Using Language Models to Simulate Human Samples. (arXiv:2209.06899v1 [cs.LG])
17. Simulation of Atlantic Hurricane Tracks and Features: A Deep Learning Approach. (arXiv:2209.06901v1 [physics.ao-ph])
18. Forecasting Evolution of Clusters in StarCraft II with Hebbian Learning. (arXiv:2209.06904v1 [cs.NE])
19. Graph Neural Network Based Node Deployment for Throughput **Enhancement**. (arXiv:2209.06905v1 [cs.NI])
20. Modelling of physical systems with a Hopf bifurcation using mechanistic models and machine learning. (arXiv:2209.06910v1 [math.DS])
21. Limit Cycles of AdaBoost. (arXiv:2209.06928v1 [cs.LG])
22. Robust Transferable Feature Extractors: Learning to Defend Pre-Trained Networks Against White Box Adversaries. (arXiv:2209.06931v1 [cs.LG])
23. Optimal Connectivity through Network Gradients for the Restricted Boltzmann Machine. (arXiv:2209.06932v1 [cs.LG])
24. Joint Debiased Representation and Image Clustering Learning with Self-Supervision. (arXiv:2209.06941v1 [cs.CV])
25. Use case-focused metrics to evaluate machine learning for diseases involving parasite loads. (arXiv:2209.06947v1 [cs.LG])
26. Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v1 [eess.IV])
27. On the interplay of adversarial robustness and architecture components: patches, convolution and attention. (arXiv:2209.06953v1 [cs.CV])
28. Generative Visual Prompt: Unifying Distributional Control of Pre-Trained Generative Models. (arXiv:2209.06970v1 [cs.CV])
29. Wasserstein $K$-means for clustering probability distributions. (arXiv:2209.06975v1 [stat.ML])
30. Efficient Quantized Sparse Matrix Operations on Tensor Cores. (arXiv:2209.06979v1 [cs.DC])
31. Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits. (arXiv:2209.06983v1 [stat.ML])
32. Non-Parallel Voice Conversion for ASR Augmentation. (arXiv:2209.06987v1 [cs.SD])
33. Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach. (arXiv:2209.06995v1 [cs.CL])
34. M^4I: Multi-modal Models Membership Inference. (arXiv:2209.06997v1 [cs.LG])
35. Stochastic Tree Ensembles for Estimating Heterogeneous Effects. (arXiv:2209.06998v1 [stat.ML])
36. Data Science Approach to predict the winning Fantasy Cricket Team Dream 11 Fantasy Sports. (arXiv:2209.06999v1 [cs.LG])
37. Gromov-Wasserstein Autoencoders. (arXiv:2209.07007v1 [cs.LG])
38. Feature Selection integrated Deep Learning for Ultrahigh Dimensional and Highly Correlated Feature Space. (arXiv:2209.07011v1 [stat.ML])
39. Upper bounds on the Natarajan dimensions of some function classes. (arXiv:2209.07015v1 [stat.ML])
40. FRANS: Automatic Feature Extraction for Time Series Forecasting. (arXiv:2209.07018v1 [cs.LG])
41. Generalized Representations Learning for Time Series Classification. (arXiv:2209.07027v1 [cs.LG])
42. Estimating large causal polytree skeletons from small samples. (arXiv:2209.07028v1 [stat.ME])
43. Langevin Autoencoders for Learning Deep Latent Variable Models. (arXiv:2209.07036v1 [cs.LG])
44. Learning-Based Adaptive Control for Stochastic Linear Systems with Input Constraints. (arXiv:2209.07040v1 [eess.SY])
45. Towards self-attention based navigation in the real world. (arXiv:2209.07043v1 [cs.RO])
46. Fair Inference for Discrete Latent Variable Models. (arXiv:2209.07044v1 [cs.LG])
47. iFlipper: Label Flipping for Individual Fairness. (arXiv:2209.07047v1 [cs.LG])
48. GAGA: Deciphering Age-path of Generalized Self-paced Regularizer. (arXiv:2209.07063v1 [cs.LG])
49. Efficient learning of nonlinear prediction models with time-series privileged information. (arXiv:2209.07067v1 [cs.LG])
50. On the Reuse Bias in Off-Policy Reinforcement Learning. (arXiv:2209.07074v1 [cs.LG])
51. Bi-level Physics-Informed Neural Networks for PDE Constrained Optimization using Broyden's Hypergradients. (arXiv:2209.07075v1 [cs.LG])
52. Layerwise Bregman Representation Learning with Applications to Knowledge Distillation. (arXiv:2209.07080v1 [cs.LG])
53. DEQGAN: Learning the Loss Function for PINNs with Generative Adversarial Networks. (arXiv:2209.07081v1 [cs.LG])
54. Earthquake Phase Association with Graph Neural Networks. (arXiv:2209.07086v1 [physics.geo-ph])
55. Constrained Update Projection Approach to Safe Policy Optimization. (arXiv:2209.07089v1 [cs.LG])
56. Decentralized Learning with Separable Data: Generalization and Fast Algorithms. (arXiv:2209.07116v1 [cs.LG])
57. How Much Does It Cost to Train a Machine Learning Model over Distributed Data Sources?. (arXiv:2209.07124v1 [cs.LG])
58. COOL-MC: A Comprehensive Tool for Reinforcement Learning and Model Checking. (arXiv:2209.07133v1 [cs.LG])
59. Semi-Counterfactual Risk Minimization Via Neural Networks. (arXiv:2209.07148v1 [cs.LG])
60. Risk-aware linear bandits with convex loss. (arXiv:2209.07154v1 [stat.ML])
61. On the detrimental effect of invariances in the likelihood for variational inference. (arXiv:2209.07157v1 [cs.LG])
62. Learning to Exploit Elastic Actuators for Quadruped Locomotion. (arXiv:2209.07171v1 [cs.RO])
63. Adaptive Fairness Improvement Based on Causality Analysis. (arXiv:2209.07190v1 [cs.LG])
64. NU-net: An Unpretentious Nested U-net for Breast Tumor Segmentation. (arXiv:2209.07193v1 [eess.IV])
65. ProAPT: Projection of APT Threats with Deep Reinforcement Learning. (arXiv:2209.07215v1 [cs.CR])
66. Training Neural Networks in Single vs Double Precision. (arXiv:2209.07219v1 [cs.LG])
67. Number of Attention Heads vs Number of Transformer-Encoders in Computer Vision. (arXiv:2209.07221v1 [cs.CV])
68. MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees. (arXiv:2209.07225v1 [cs.LG])
69. Distributed Sparse Linear Regression with Sublinear Communication. (arXiv:2209.07230v1 [stat.ML])
70. Sound and Complete Verification of Polynomial Networks. (arXiv:2209.07235v1 [cs.LG])
71. Generalization Properties of NAS under Activation and Skip Connection Search. (arXiv:2209.07238v1 [cs.LG])
72. Efficient first-order predictor-corrector multiple objective optimization for fair misinformation detection. (arXiv:2209.07245v1 [cs.LG])
73. Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization). (arXiv:2209.07263v1 [cs.LG])
74. Compressed Particle-Based Federated Bayesian Learning and Unlearning. (arXiv:2209.07267v1 [cs.LG])
75. Socially Enhanced Situation Awareness from Microblogs using Artificial Intelligence: A Survey. (arXiv:2209.07272v1 [cs.LG])
76. Blind and Channel-agnostic Equalization Using Adversarial Networks. (arXiv:2209.07277v1 [eess.SP])
77. MDE for Machine Learning-Enabled Software Systems: A Case Study and Comparison of MontiAnna & ML-Quadrat. (arXiv:2209.07282v1 [cs.SE])
78. Exploiting Reward Shifting in Value-Based Deep RL. (arXiv:2209.07288v1 [cs.LG])
79. Multi-Task Mixture Density Graph Neural Networks for Predicting Cu-based Single-Atom Alloy Catalysts for CO2 Reduction Reaction. (arXiv:2209.07300v1 [cond-mat.mtrl-sci])
80. Differentially Private Estimation of Hawkes Process. (arXiv:2209.07303v1 [cs.LG])
81. Multicalibrated Regression for Downstream Fairness. (arXiv:2209.07312v1 [cs.LG])
82. A Continual Development Methodology for Large-scale Multitask Dynamic ML Systems. (arXiv:2209.07326v1 [cs.LG])
83. Semiparametric Best Arm Identification with Contextual Information. (arXiv:2209.07330v1 [cs.LG])
84. A Temporal Graphlet Kernel for Classifying Dissemination in Evolving Networks. (arXiv:2209.07332v1 [cs.SI])
85. Public Reaction to Scientific Research via Twitter Sentiment Prediction. (arXiv:2209.07333v1 [cs.IR])
86. CLIPping Privacy: Identity Inference Attacks on Multi-Modal Machine Learning Models. (arXiv:2209.07341v1 [cs.LG])
87. Sampling for network function learning. (arXiv:2209.07342v1 [cs.SI])
88. Overhead-Free Blockage Detection and Precoding Through Physics-Based Graph Neural Networks: LIDAR Data Meets Ray Tracing. (arXiv:2209.07350v1 [cs.IT])
89. Continuous MDP Homomorphisms and Homomorphic Policy Gradient. (arXiv:2209.07364v1 [cs.LG])
90. Adversarially Robust Learning: A Generic Minimax Optimal Learner and Characterization. (arXiv:2209.07369v1 [cs.LG])
91. A Geometric Perspective on Variational Autoencoders. (arXiv:2209.07370v1 [stat.ML])
92. Understanding Deep Neural Function Approximation in Reinforcement Learning via $\epsilon$-Greedy Exploration. (arXiv:2209.07376v1 [cs.LG])
93. Towards Healing the Blindness of Score Matching. (arXiv:2209.07396v1 [stat.ML])
94. Decision making in cancer: Causal questions require causal answers. (arXiv:2209.07397v1 [cs.LG])
95. A Light Recipe to Train Robust Vision Transformers. (arXiv:2209.07399v1 [cs.CV])
96. Private Synthetic Data for Multitask Learning and Marginal Queries. (arXiv:2209.07400v1 [cs.LG])
97. Private Stochastic Optimization in the Presence of Outliers: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v1 [cs.LG])
98. Self-Organizing Map Neural Network Algorithm for the Determination of Fracture Location in Solid-State Process joined Dissimilar Alloys. (arXiv:2209.07404v1 [cs.NE])
99. Widely Used and Fast De Novo Drug Design by a Protein Sequence-Based Reinforcement Learning Model. (arXiv:2209.07405v1 [q-bio.BM])
100. Towards Coupling Full-disk and Active Region-based Flare Prediction for Operational Space Weather Forecasting. (arXiv:2209.07406v1 [physics.space-ph])
101. Chemotaxis of sea urchin sperm cells through deep reinforcement learning. (arXiv:2209.07407v1 [cs.NE])
102. Evolving Zero Cost Proxies For Neural Architecture Scoring. (arXiv:2209.07413v1 [cs.LG])
103. Trustworthy modelling of atmospheric formaldehyde powered by deep learning. (arXiv:2209.07414v1 [physics.ao-ph])
104. Scalable Task-Driven Robotic Swarm Control via Collision Avoidance and Learning Mean-Field Control. (arXiv:2209.07420v1 [cs.RO])
105. Can Pre-trained Models Really Learn Better Molecular Representations for AI-aided Drug Discovery?. (arXiv:2209.07423v1 [q-bio.BM])
106. CMSBERT-CLR: Context-driven Modality Shifting BERT with Contrastive Learning for linguistic, visual, acoustic Representations. (arXiv:2209.07424v1 [cs.CL])
107. Statistical monitoring of models based on artificial intelligence. (arXiv:2209.07436v1 [stat.ME])
108. Mean-Field Approximation of Cooperative Constrained Multi-Agent Reinforcement Learning (CMARL). (arXiv:2209.07437v1 [cs.LG])
109. Efficiency Ordering of Stochastic Gradient Descent. (arXiv:2209.07446v1 [cs.LG])
110. A Unifying Framework for Online Optimization with Long-Term Constraints. (arXiv:2209.07454v1 [cs.LG])
111. A Robotic Visual Grasping Design: Rethinking Convolution Neural Network with High-Resolutions. (arXiv:2209.07459v1 [cs.RO])
112. Omnipredictors for Constrained Optimization. (arXiv:2209.07463v1 [cs.LG])
113. On the Surprising Effectiveness of Transformers in Low-Labeled Video Recognition. (arXiv:2209.07474v1 [cs.CV])
114. Neural Networks Reduction via Lumping. (arXiv:2209.07475v1 [cs.LG])
115. Rho-Tau Bregman Information and the Geometry of Annealing Paths. (arXiv:2209.07481v1 [cs.LG])
116. MRI-MECH: Mechanics-informed MRI to estimate esophageal health. (arXiv:2209.07492v1 [physics.med-ph])
117. DiP-GNN: Discriminative Pre-Training of Graph Neural Networks. (arXiv:2209.07499v1 [cs.LG])
118. Random initialisations performing above chance and how to find them. (arXiv:2209.07509v1 [cs.LG])
119. Distribution Aware Metrics for Conditional Natural Language Generation. (arXiv:2209.07518v1 [cs.CL])
120. On-Device Domain Generalization. (arXiv:2209.07521v1 [cs.CV])
121. Test-Time Training with Masked Autoencoders. (arXiv:2209.07522v1 [cs.CV])
122. Nearest Neighbor and Kernel Survival Analysis: Nonasymptotic Error Bounds and Strong Consistency Rates. (arXiv:1905.05285v2 [stat.ML] UPDATED)
123. Dynamic Graph Message Passing Networks. (arXiv:1908.06955v5 [cs.CV] UPDATED)
124. Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v5 [cs.LG] UPDATED)
125. Delving into Inter-Image Invariance for Unsupervised Visual Representations. (arXiv:2008.11702v3 [cs.CV] UPDATED)
126. Particle gradient descent model for point process generation. (arXiv:2010.14928v3 [stat.ML] UPDATED)
127. Neural-iLQR: A Learning-Aided Shooting Method for Trajectory Optimization. (arXiv:2011.10737v3 [cs.LG] UPDATED)
128. A Stochastic Optimization Framework for Fair Risk Minimization. (arXiv:2102.12586v3 [cs.LG] UPDATED)
129. A Random Persistence Diagram Generator. (arXiv:2104.07737v4 [stat.ML] UPDATED)
130. BR-NPA: A Non-Parametric High-Resolution Attention Model to improve the Interpretability of Attention. (arXiv:2106.02566v6 [cs.CV] UPDATED)
131. Time Series Prediction using Deep Learning Methods in Healthcare. (arXiv:2108.13461v3 [cs.LG] UPDATED)
132. Well Googled is Half Done: Multimodal Forecasting of New Fashion Product Sales with Image-based Google Trends. (arXiv:2109.09824v5 [cs.CV] UPDATED)
133. The Fragility of Optimized Bandit Algorithms. (arXiv:2109.13595v3 [cs.LG] UPDATED)
134. Personalized Rehabilitation Robotics based on Online Learning Control. (arXiv:2110.00481v2 [cs.LG] UPDATED)
135. A Closer Look at Prototype Classifier for Few-shot Image Classification. (arXiv:2110.05076v5 [cs.CV] UPDATED)
136. Study of Drug Assimilation in Human System using Physics Informed Neural Networks. (arXiv:2110.05531v2 [q-bio.OT] UPDATED)
137. Tangent Space and Dimension Estimation with the Wasserstein Distance. (arXiv:2110.06357v3 [math.ST] UPDATED)
138. Few-Shot Object Detection: A Comprehensive Survey. (arXiv:2112.11699v2 [cs.CV] UPDATED)
139. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v3 [cs.HC] UPDATED)
140. Learning Multi-agent Options for Tabular Reinforcement Learning using Factor Graphs. (arXiv:2201.08227v2 [cs.MA] UPDATED)
141. Fast Server Learning Rate Tuning for Coded Federated Dropout. (arXiv:2201.11036v4 [cs.LG] UPDATED)
142. Deep invariant networks with differentiable augmentation layers. (arXiv:2202.02142v5 [cs.LG] UPDATED)
143. Experimental Investigation of Variational Mode Decomposition and Deep Learning for Short-Term Multi-horizon Residential Electric Load Forecasting. (arXiv:2202.03264v2 [eess.SP] UPDATED)
144. Unsupervised Learning of Group Invariant and Equivariant Representations. (arXiv:2202.07559v2 [cs.LG] UPDATED)
145. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v4 [cs.LG] UPDATED)
146. Parameter-Efficient Mixture-of-Experts Architecture for Pre-trained Language Models. (arXiv:2203.01104v3 [cs.CL] UPDATED)
147. Carbon Footprint of Selecting and Training Deep Learning Models for Medical Image Analysis. (arXiv:2203.02202v2 [eess.IV] UPDATED)
148. Benchmarking Counterfactual Algorithms for XAI: From White Box to Black Box. (arXiv:2203.02399v2 [cs.LG] UPDATED)
149. Learning to Reason Deductively: Math Word Problem Solving as Complex Relation Extraction. (arXiv:2203.10316v4 [cs.CL] UPDATED)
150. Collaborative Learning for Cyberattack Detection in Blockchain Networks. (arXiv:2203.11076v2 [cs.CR] UPDATED)
151. Learning the conditional law: signatures and conditional GANs in filtering and prediction of diffusion processes. (arXiv:2204.00611v2 [stat.ML] UPDATED)
152. Fitting an immersed submanifold to data via Sussmann's orbit theorem. (arXiv:2204.01119v3 [cs.LG] UPDATED)
153. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v4 [cs.LG] UPDATED)
154. PALBERT: Teaching ALBERT to Ponder. (arXiv:2204.03276v2 [cs.LG] UPDATED)
155. Hybrid Neural Network Augmented Physics-based Models for Nonlinear Filtering. (arXiv:2204.06471v2 [cs.LG] UPDATED)
156. Ergo, SMIRK is Safe: A Safety Case for a Machine Learning Component in a Pedestrian Automatic Emergency Brake System. (arXiv:2204.07874v2 [cs.SE] UPDATED)
157. Blind Equalization and Channel Estimation in Coherent Optical Communications Using Variational Autoencoders. (arXiv:2204.11776v2 [eess.SP] UPDATED)
158. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v3 [cs.LG] UPDATED)
159. Stochastic first-order methods for average-reward Markov decision processes. (arXiv:2205.05800v5 [cs.LG] UPDATED)
160. Content-Context Factorized Representations for Automated Speech Recognition. (arXiv:2205.09872v2 [eess.AS] UPDATED)
161. Flexible Diffusion Modeling of Long Videos. (arXiv:2205.11495v2 [cs.CV] UPDATED)
162. Low-rank Optimal Transport: Approximation, Statistics and Debiasing. (arXiv:2205.12365v2 [stat.ML] UPDATED)
163. First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization. (arXiv:2205.12381v2 [cs.LG] UPDATED)
164. Do Residual Neural Networks discretize Neural Ordinary Differential Equations?. (arXiv:2205.14612v2 [cs.LG] UPDATED)
165. OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs. (arXiv:2205.15117v4 [cs.LG] UPDATED)
166. Robust Anytime Learning of Markov Decision Processes. (arXiv:2205.15827v2 [cs.AI] UPDATED)
167. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v7 [cs.LG] UPDATED)
168. Markov Chain Score Ascent: A Unifying Framework of Variational Inference with Markovian Gradients. (arXiv:2206.06295v3 [cs.LG] UPDATED)
169. Understanding Robust Learning through the Lens of Representation Similarities. (arXiv:2206.09868v2 [cs.LG] UPDATED)
170. Learning Debiased Classifier with Biased Committee. (arXiv:2206.10843v2 [cs.LG] UPDATED)
171. Shifts 2.0: Extending The Dataset of Real Distributional Shifts. (arXiv:2206.15407v2 [cs.LG] UPDATED)
172. Distributed Online System Identification for LTI Systems Using Reverse Experience Replay. (arXiv:2207.01062v2 [cs.LG] UPDATED)
173. SuperTickets: Drawing Task-Agnostic Lottery Tickets from Supernets via Jointly Architecture Searching and Parameter Pruning. (arXiv:2207.03677v3 [cs.CV] UPDATED)
174. Estimating Classification Confidence Using Kernel Densities. (arXiv:2207.06529v3 [stat.ML] UPDATED)
175. Pick your Neighbor: Local Gauss-Southwell Rule for Fast Asynchronous Decentralized Optimization. (arXiv:2207.07543v2 [math.OC] UPDATED)
176. To update or not to update? Neurons at equilibrium in deep models. (arXiv:2207.09455v2 [cs.LG] UPDATED)
177. Laplacian-based Cluster-Contractive t-SNE for High Dimensional Data Visualization. (arXiv:2207.12214v2 [cs.LG] UPDATED)
178. CheXRelNet: An Anatomy-Aware Model for Tracking Longitudinal Relationships between Chest X-Rays. (arXiv:2208.03873v2 [cs.CV] UPDATED)
179. Active Learning Exploration of Transition Metal Complexes to Discover Method-Insensitive and Synthetically Accessible Chromophores. (arXiv:2208.05444v2 [physics.chem-ph] UPDATED)
180. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
181. Studying Bias in GANs through the Lens of Race. (arXiv:2209.02836v2 [cs.CV] UPDATED)
182. Video **Restoration** with a Deep Plug-and-Play Prior. (arXiv:2209.02854v2 [eess.IV] UPDATED)
183. RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk. (arXiv:2209.04067v2 [cs.LG] UPDATED)
184. Deterministic Sequencing of Exploration and Exploitation for Reinforcement Learning. (arXiv:2209.05408v2 [cs.LG] UPDATED)
185. Leveraging Language Foundation Models for Human Mobility Forecasting. (arXiv:2209.05479v2 [cs.LG] UPDATED)
186. R\'{e}nyi Divergence Deep Mutual Learning. (arXiv:2209.05732v3 [cs.LG] UPDATED)
187. BERT-based Ensemble Approaches for Hate Speech Detection. (arXiv:2209.06505v2 [cs.CL] UPDATED)
188. Graph Contrastive Learning with Personalized Augmentation. (arXiv:2209.06560v2 [cs.LG] UPDATED)
189. NAAP-440 Dataset and Baseline for Neural Architecture Accuracy Prediction. (arXiv:2209.06626v2 [cs.CV] UPDATED)
## cs.AI
---
**92** new papers in cs.AI:-) 
1. Using Genetic Algorithms to Simulate Evolution. (arXiv:2209.06822v1 [cs.NE])
2. An ensemble Multi-Agent System for non-linear classification. (arXiv:2209.06824v1 [cs.LG])
3. Weakly Supervised Invariant Representation Learning Via Disentangling Known and Unknown Nuisance Factors. (arXiv:2209.06827v1 [cs.LG])
4. A Temporal Anomaly Detection System for Vehicles utilizing Functional Working Groups and Sensor Channels. (arXiv:2209.06828v1 [cs.LG])
5. Robust field-level inference with **dark** matter halos. (arXiv:2209.06843v1 [astro-ph.CO])
6. Urban precipitation downscaling using deep learning: a smart city application over Austin, Texas, USA. (arXiv:2209.06848v1 [physics.ao-ph])
7. Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v1 [q-bio.NC])
8. Sketch of a novel approach to a neural model. (arXiv:2209.06865v1 [q-bio.NC])
9. On the State of the Art in Authorship Attribution and Authorship Verification. (arXiv:2209.06869v1 [cs.CL])
10. Forecasting Evolution of Clusters in StarCraft II with Hebbian Learning. (arXiv:2209.06904v1 [cs.NE])
11. NanoFlowNet: **Real-time** Dense Optical Flow on a Nano Quadcopter. (arXiv:2209.06918v1 [cs.RO])
12. Robust Transferable Feature Extractors: Learning to Defend Pre-Trained Networks Against White Box Adversaries. (arXiv:2209.06931v1 [cs.LG])
13. PointACL:Adversarial Contrastive Learning for Robust Point Clouds Representation under Adversarial Attack. (arXiv:2209.06971v1 [cs.CV])
14. SQL and NoSQL Databases Software architectures performance analysis and assessments -- A Systematic Literature review. (arXiv:2209.06977v1 [cs.DB])
15. Vision-aided UAV Navigation and Dynamic Obstacle Avoidance using Gradient-based B-spline Trajectory Optimization. (arXiv:2209.07003v1 [cs.RO])
16. MR4MR: Mixed Reality for Melody Reincarnation. (arXiv:2209.07023v1 [cs.HC])
17. Can We Solve 3D Vision Tasks Starting from A 2D Vision Transformer?. (arXiv:2209.07026v1 [cs.CV])
18. Generalized Representations Learning for Time Series Classification. (arXiv:2209.07027v1 [cs.LG])
19. Efficient Perception, Planning, and Control Algorithms for Vision-Based Automated Vehicles. (arXiv:2209.07042v1 [cs.RO])
20. CommunityLM: Probing Partisan Worldviews from Language Models. (arXiv:2209.07065v1 [cs.SI])
21. Responsible AI Implementation: A Human-centered Framework for Accelerating the Innovation Process. (arXiv:2209.07076v1 [cs.AI])
22. Knowledge Graph Completion with Pre-trained Multimodal Transformer and Twins Negative Sampling. (arXiv:2209.07084v1 [cs.AI])
23. Constrained Update Projection Approach to Safe Policy Optimization. (arXiv:2209.07089v1 [cs.LG])
24. Multi-Objective Policy Gradients with Topological Constraints. (arXiv:2209.07096v1 [cs.AI])
25. Bridging Implicit and Explicit Geometric Transformations for Single-Image View Synthesis. (arXiv:2209.07105v1 [cs.CV])
26. $\rho$-GNF : A Novel Sensitivity Analysis Approach Under Unobserved Confounders. (arXiv:2209.07111v1 [stat.ME])
27. Semi-Counterfactual Risk Minimization Via Neural Networks. (arXiv:2209.07148v1 [cs.LG])
28. Morphology-Aware Interactive Keypoint Estimation. (arXiv:2209.07163v1 [cs.CV])
29. Literature Review of various Fuzzy Rule based Systems. (arXiv:2209.07175v1 [cs.AI])
30. Sound and Complete Verification of Polynomial Networks. (arXiv:2209.07235v1 [cs.LG])
31. Generalization Properties of NAS under Activation and Skip Connection Search. (arXiv:2209.07238v1 [cs.LG])
32. Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization). (arXiv:2209.07263v1 [cs.LG])
33. AssembleRL: Learning to Assemble Furniture from Their Point Clouds. (arXiv:2209.07268v1 [cs.RO])
34. Revisiting Crowd Counting: State-of-the-art, Trends, and Future Perspectives. (arXiv:2209.07271v1 [cs.CV])
35. Exploiting Reward Shifting in Value-Based Deep RL. (arXiv:2209.07288v1 [cs.LG])
36. A Continual Development Methodology for Large-scale Multitask Dynamic ML Systems. (arXiv:2209.07326v1 [cs.LG])
37. Public Reaction to Scientific Research via Twitter Sentiment Prediction. (arXiv:2209.07333v1 [cs.IR])
38. Deep Reinforcement Learning for Task Offloading in UAV-Aided Smart Farm Networks. (arXiv:2209.07367v1 [cs.NI])
39. Causal Coupled Mechanisms: A Control Method with Cooperation and Competition for Complex System. (arXiv:2209.07368v1 [cs.AI])
40. IoT-Aerial Base Station Task Offloading with Risk-Sensitive Reinforcement Learning for Smart Agriculture. (arXiv:2209.07382v1 [cs.NI])
41. Self-Supervised Attention Networks and Uncertainty Loss Weighting for Multi-Task Emotion Recognition on Vocal Bursts. (arXiv:2209.07384v1 [cs.SD])
42. Self-Organizing Map Neural Network Algorithm for the Determination of Fracture Location in Solid-State Process joined Dissimilar Alloys. (arXiv:2209.07404v1 [cs.NE])
43. Towards Coupling Full-disk and Active Region-based Flare Prediction for Operational Space Weather Forecasting. (arXiv:2209.07406v1 [physics.space-ph])
44. Chemotaxis of sea urchin sperm cells through deep reinforcement learning. (arXiv:2209.07407v1 [cs.NE])
45. Examining Large Pre-Trained Language Models for Machine Translation: What You Don't Know About It. (arXiv:2209.07417v1 [cs.CL])
46. Scalable Task-Driven Robotic Swarm Control via Collision Avoidance and Learning Mean-Field Control. (arXiv:2209.07420v1 [cs.RO])
47. Extended Intelligence. (arXiv:2209.07449v1 [cs.AI])
48. Gollum: A Gold Standard for Large Scale Multi Source Knowledge Graph Matching. (arXiv:2209.07479v1 [cs.AI])
49. Distribution Aware Metrics for Conditional Natural Language Generation. (arXiv:2209.07518v1 [cs.CL])
50. On-Device Domain Generalization. (arXiv:2209.07521v1 [cs.CV])
51. Neural-iLQR: A Learning-Aided Shooting Method for Trajectory Optimization. (arXiv:2011.10737v3 [cs.LG] UPDATED)
52. ISP Distillation. (arXiv:2101.10203v2 [cs.CV] UPDATED)
53. A Discrete-Time Switching System Analysis of Q-learning. (arXiv:2102.08583v9 [math.OC] UPDATED)
54. Towards Multi-Sense Cross-Lingual Alignment of Contextual Embeddings. (arXiv:2103.06459v4 [cs.CL] UPDATED)
55. Effect of Post-processing on Contextualized Word Representations. (arXiv:2104.07456v2 [cs.CL] UPDATED)
56. Sign Language Video Retrieval with Free-Form Textual Queries. (arXiv:2201.02495v2 [cs.CV] UPDATED)
57. Learning Multi-agent Options for Tabular Reinforcement Learning using Factor Graphs. (arXiv:2201.08227v2 [cs.MA] UPDATED)
58. Deep invariant networks with differentiable augmentation layers. (arXiv:2202.02142v5 [cs.LG] UPDATED)
59. Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence. (arXiv:2202.12183v4 [cs.LG] UPDATED)
60. Human Detection of Political Deepfakes across Transcripts, Audio, and Video. (arXiv:2202.12883v2 [cs.HC] UPDATED)
61. Parameter-Efficient Mixture-of-Experts Architecture for Pre-trained Language Models. (arXiv:2203.01104v3 [cs.CL] UPDATED)
62. Benchmarking Counterfactual Algorithms for XAI: From White Box to Black Box. (arXiv:2203.02399v2 [cs.LG] UPDATED)
63. DialMed: A Dataset for Dialogue-based Medication Recommendation. (arXiv:2203.07094v2 [cs.CL] UPDATED)
64. Defending From Physically-Realizable Adversarial Attacks Through Internal Over-Activation Analysis. (arXiv:2203.07341v2 [cs.CV] UPDATED)
65. Learning of Structurally Unambiguous Probabilistic Grammars. (arXiv:2203.09441v2 [cs.LO] UPDATED)
66. Emergence of hierarchical reference systems in multi-agent communication. (arXiv:2203.13176v2 [cs.AI] UPDATED)
67. Complex-Valued Autoencoders for Object Discovery. (arXiv:2204.02075v4 [cs.LG] UPDATED)
68. Adversarial Training for High-Stakes Reliability. (arXiv:2205.01663v3 [cs.LG] UPDATED)
69. Economical Precise Manipulation and Auto Eye-Hand Coordination with Binocular Visual Reinforcement Learning. (arXiv:2205.05963v2 [cs.RO] UPDATED)
70. OOD Link Prediction Generalization Capabilities of Message-Passing GNNs in Larger Test Graphs. (arXiv:2205.15117v4 [cs.LG] UPDATED)
71. Refining Low-Resource Unsupervised Translation by Language Disentanglement of Multilingual Model. (arXiv:2205.15544v2 [cs.CL] UPDATED)
72. Robust Anytime Learning of Markov Decision Processes. (arXiv:2205.15827v2 [cs.AI] UPDATED)
73. OmniXAI: A Library for Explainable AI. (arXiv:2206.01612v7 [cs.LG] UPDATED)
74. Visual Clues: Bridging Vision and Language Foundations for Image Paragraph Captioning. (arXiv:2206.01843v2 [cs.CV] UPDATED)
75. Markov Chain Score Ascent: A Unifying Framework of Variational Inference with Markovian Gradients. (arXiv:2206.06295v3 [cs.LG] UPDATED)
76. Shifts 2.0: Extending The Dataset of Real Distributional Shifts. (arXiv:2206.15407v2 [cs.LG] UPDATED)
77. Knowledge Graph Induction enabling Recommending and Trend Analysis: A Corporate Research Community Use Case. (arXiv:2207.05188v3 [cs.AI] UPDATED)
78. Rethinking Data Augmentation for Robust Visual Question Answering. (arXiv:2207.08739v2 [cs.CV] UPDATED)
79. To update or not to update? Neurons at equilibrium in deep models. (arXiv:2207.09455v2 [cs.LG] UPDATED)
80. End-to-end View Synthesis via **NeRF** Attention. (arXiv:2207.14741v3 [cs.CV] UPDATED)
81. STrajNet: Multi-modal Hierarchical Transformer for Occupancy Flow Field Prediction in Autonomous Driving. (arXiv:2208.00394v2 [cs.CV] UPDATED)
82. Composable Text Controls in Latent Space with ODEs. (arXiv:2208.00638v2 [cs.CL] UPDATED)
83. Summarizing Patients Problems from Hospital Progress Notes Using Pre-trained Sequence-to-Sequence Models. (arXiv:2208.08408v2 [cs.CL] UPDATED)
84. I Know What You Do Not Know: Knowledge Graph Embedding via Co-distillation Learning. (arXiv:2208.09828v3 [cs.CL] UPDATED)
85. From Easy to Hard: A Dual Curriculum Learning Framework for Context-Aware Document Ranking. (arXiv:2208.10226v2 [cs.IR] UPDATED)
86. CLOWER: A Pre-trained Language Model with Contrastive Learning over Word and Character Representations. (arXiv:2208.10844v2 [cs.CL] UPDATED)
87. Adapting the LodView RDF Browser for Navigation over the Multilingual Linguistic Linked Open Data Cloud. (arXiv:2208.13295v3 [cs.CL] UPDATED)
88. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v6 [cs.LG] UPDATED)
89. RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk. (arXiv:2209.04067v2 [cs.LG] UPDATED)
90. Responsible AI Pattern Catalogue: A Multivocal Literature Review. (arXiv:2209.04963v3 [cs.AI] UPDATED)
91. Leveraging Language Foundation Models for Human Mobility Forecasting. (arXiv:2209.05479v2 [cs.LG] UPDATED)
92. R\'{e}nyi Divergence Deep Mutual Learning. (arXiv:2209.05732v3 [cs.LG] UPDATED)

