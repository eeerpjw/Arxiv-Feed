# Your interest papers
---
## cs.CV
---
### A Dual Weighting Label Assignment Scheme for Object Detection. (arXiv:2203.09730v1 [cs.CV])
- Authors : Shuai Li, Chenhang He, Ruihuang Li, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09730](http://arxiv.org/abs/2203.09730)
> ABSTRACT  :  Label assignment (LA), which aims to assign each training sample a positive (pos) and a negative (neg) loss weight, plays an important role in object detection. Existing LA methods mostly focus on the design of pos weighting function, while the neg weight is directly derived from the pos weight. Such a mechanism limits the learning capacity of detectors. In this paper, we explore a new weighting paradigm, termed dual weighting (DW), to specify pos and neg weights separately. We first identify the key influential factors of pos/neg weights by analyzing the evaluation metrics in object detection, and then design the pos and neg weighting functions based on them. Specifically, the pos weight of a sample is determined by the consistency degree between its classification and localization scores, while the neg weight is decomposed into two terms: the probability that it is a neg sample and its importance conditioned on being a neg sample. Such a weighting strategy offers greater flexibility to distinguish between important and less important samples, resulting in a more effective object detector. Equipped with the proposed DW method, a single FCOS-ResNet-50 detector can reach 41.5% mAP on COCO under 1x schedule, outperforming other existing LA methods. It consistently improves the baselines on COCO by a large margin under various backbones without bells and whistles. Code is available at https://github.com/strongwolf/DW.  
### Class-Balanced Pixel-Level Self-Labeling for Domain Adaptive Semantic Segmentation. (arXiv:2203.09744v1 [cs.CV])
- Authors : Ruihuang Li, Shuai Li, Chenhang He, Yabin Zhang, Xu Jia, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09744](http://arxiv.org/abs/2203.09744)
> ABSTRACT  :  Domain adaptive semantic segmentation aims to learn a model with the supervision of source domain data, and produce satisfactory dense predictions on unlabeled target domain. One popular solution to this challenging task is self-training, which selects high-scoring predictions on target samples as pseudo labels for training. However, the produced pseudo labels often contain much noise because the model is biased to source domain as well as majority categories. To address the above issues, we propose to directly explore the intrinsic pixel distributions of target domain data, instead of heavily relying on the source domain. Specifically, we simultaneously cluster pixels and rectify pseudo labels with the obtained cluster assignments. This process is done in an online fashion so that pseudo labels could co-evolve with the segmentation model without extra training rounds. To overcome the class imbalance problem on long-tailed categories, we employ a distribution alignment technique to enforce the marginal class distribution of cluster assignments to be close to that of pseudo labels. The proposed method, namely Class-balanced Pixel-level Self-Labeling (CPSL), improves the segmentation performance on target domain over state-of-the-arts by a large margin, especially on long-tailed categories.  
### Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition. (arXiv:2203.09771v1 [cs.CV])
- Authors : Tao Yang, Peiran Ren, Xuansong Xie, Xiansheng Hua, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09771](http://arxiv.org/abs/2203.09771)
> ABSTRACT  :  Video frame interpolation (VFI) aims to improve the temporal resolution of a video sequence. Most of the existing deep learning based VFI methods adopt off-the-shelf optical flow algorithms to estimate the bidirectional flows and interpolate the missing frames accordingly. Though having achieved a great success, these methods require much human experience to tune the bidirectional flows and often generate unpleasant results when the estimated flows are not accurate. In this work, we rethink the VFI problem and formulate it as a continuous image transition (CIT) task, whose key issue is to transition an image from one space to another space continuously. More specifically, we learn to implicitly decouple the images into a translatable flow space and a non-translatable feature space. The former depicts the translatable states between the given images, while the later aims to reconstruct the intermediate features that cannot be directly translated. In this way, we can easily perform image interpolation in the flow space and intermediate image synthesis in the feature space, obtaining a CIT model. The proposed space decoupled learning (SDL) approach is simple to implement, while it provides an effective framework to a variety of CIT problems beyond VFI, such as style transfer and image morphing. Our extensive experiments on a variety of CIT tasks demonstrate the superiority of SDL to existing methods. The source code and models can be found at \url{https://github.com/yangxy/SDL}.  
### Transferable Class-Modelling for Decentralized Source Attribution of GAN-Generated Images. (arXiv:2203.09777v1 [cs.CV])
- Authors : Chern Hong
- Link : [http://arxiv.org/abs/2203.09777](http://arxiv.org/abs/2203.09777)
> ABSTRACT  :  GAN-generated deepfakes as a genre of digital images are gaining ground as both catalysts of artistic expression and malicious forms of deception, therefore demanding systems to enforce and accredit their ethical use. Existing techniques for the source attribution of synthetic images identify subtle intrinsic fingerprints using multiclass classification neural nets limited in functionality and scalability. Hence, we redefine the deepfake detection and source attribution problems as a series of related binary classification tasks. We leverage transfer learning to rapidly adapt forgery detection networks for multiple independent attribution problems, by proposing a semi-decentralized modular design to solve them simultaneously and efficiently. Class activation mapping is also demonstrated as an effective means of feature localization for model interpretation. Our models are determined via experimentation to be competitive with current benchmarks, and capable of decent performance on human portraits in ideal conditions. Decentralized fingerprint-based attribution is found to retain validity in the presence of novel sources, but is more susceptible to type II errors that intensify with image perturbations and attributive uncertainty. We describe both our conceptual framework and model prototypes for further **enhancement** when investigating the technical limits of reactive deepfake attribution.  
### Towards Robust 2D Convolution for Reliable Visual Recognition. (arXiv:2203.09790v1 [cs.CV])
- Authors : Lida Li, Shuai Li, Kun Wang, Xiangchu Feng, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09790](http://arxiv.org/abs/2203.09790)
> ABSTRACT  :  2D convolution (Conv2d), which is responsible for extracting features from the input image, is one of the key modules of a convolutional neural network (CNN). However, Conv2d is vulnerable to image corruptions and adversarial samples. It is an important yet rarely investigated problem that whether we can design a more robust alternative of Conv2d for more reliable feature extraction. In this paper, inspired by the recently developed learnable sparse transform that learns to convert the CNN features into a compact and sparse latent space, we design a novel building block, denoted by RConv-MK, to strengthen the robustness of extracted convolutional features. Our method leverages a set of learnable kernels of different sizes to extract features at different frequencies and employs a normalized soft thresholding operator to adaptively remove noises and trivial features at different corruption levels. Extensive experiments on clean images, corrupted images as well as adversarial samples validate the effectiveness of the proposed robust module for reliable visual recognition. The source codes are enclosed in the submission.  
### Fourier Document **Restoration** for Robust Document Dewarping and Recognition. (arXiv:2203.09910v1 [cs.CV])
- Authors : Chuhui Xue, Zichen Tian, Fangneng Zhan, Shijian Lu, Song Bai
- Link : [http://arxiv.org/abs/2203.09910](http://arxiv.org/abs/2203.09910)
> ABSTRACT  :  State-of-the-art document dewarping techniques learn to predict 3-dimensional information of documents which are prone to errors while dealing with documents with irregular distortions or large variations in depth. This paper presents FDRNet, a Fourier Document **Restoration** Network that can restore documents with different distortions and improve document recognition in a reliable and simpler manner. FDRNet focuses on high-frequency components in the Fourier space that capture most structural information but are largely free of degradation in appearance. It dewarps documents by a flexible Thin-Plate Spline transformation which can handle various deformations effectively without requiring deformation annotations in training. These features allow FDRNet to learn from a small amount of simply labeled training images, and the learned model can dewarp documents with complex geometric distortion and recognize the restored texts accurately. To facilitate document **restoration** research, we create a benchmark dataset consisting of over one thousand camera documents with different types of geometric and photometric distortion. Extensive experiments show that FDRNet outperforms the state-of-the-art by large margins on both dewarping and text recognition tasks. In addition, FDRNet requires a small amount of simply labeled training data and is easy to deploy.  
### **Enhancement** of Novel View Synthesis Using Omnidirectional Image Completion. (arXiv:2203.09957v1 [cs.CV])
- Authors : Takayuki Hara, Tatsuya Harada
- Link : [http://arxiv.org/abs/2203.09957](http://arxiv.org/abs/2203.09957)
> ABSTRACT  :  We present a method for synthesizing novel views from a single 360-degree image based on the neural radiance field (NeRF) . Prior studies rely on the neighborhood interpolation capability of multi-layer perceptrons to complete missing regions caused by occlusion and zooming, and this leads to artifacts. In the proposed method, the input image is reprojected to 360-degree images at other camera positions, the missing regions of the reprojected images are completed by a self-supervised trained generative model, and the completed images are utilized to train the NeRF. Because multiple completed images contain inconsistencies in 3D, we introduce a method to train NeRF while dynamically selecting a sparse set of completed images, to reduce the discrimination error of the synthesized views with real images. Experiments indicate that the proposed method can synthesize plausible novel views while preserving the features of the scene for both artificial and real-world data.  
### Parametric Scaling of Preprocessing assisted U-net Architecture for Improvised Retinal Vessel Segmentation. (arXiv:2203.10014v1 [eess.IV])
- Authors : Kundan Kumar, Sumanshu Agarwal
- Link : [http://arxiv.org/abs/2203.10014](http://arxiv.org/abs/2203.10014)
> ABSTRACT  :  Extracting blood vessels from retinal fundus images plays a decisive role in diagnosing the progression in pertinent diseases. In medical image analysis, vessel extraction is a semantic binary segmentation problem, where blood vasculature needs to be extracted from the background. Here, we present an image **enhancement** technique based on the morphological preprocessing coupled with a scaled U-net architecture. Despite a relatively less number of trainable network parameters, the scaled version of U-net architecture provides better performance compare to other methods in the domain. We validated the proposed method on retinal fundus images from the DRIVE database. A significant improvement as compared to the other algorithms in the domain, in terms of the area under ROC curve (&gt;0.9762) and classification accuracy (&gt;95.47%) are evident from the results. Furthermore, the proposed method is resistant to the central vessel reflex while sensitive to detect blood vessels in the presence of background items viz. exudates, optic disc, and fovea.  
### ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV])
- Authors : Zhaoning Sun, Nico Messikommer, Daniel Gehrig, Davide Scaramuzza
- Link : [http://arxiv.org/abs/2203.10016](http://arxiv.org/abs/2203.10016)
> ABSTRACT  :  Retrieving accurate semantic information in challenging **high dynamic range** (**HDR**) and high-speed conditions remains an open challenge for image-based algorithms due to severe image degradations. Event cameras promise to address these challenges since they feature a much higher dynamic range and are resilient to motion blur. Nonetheless, semantic segmentation with event cameras is still in its infancy which is chiefly due to the novelty of the sensor, and the lack of high-quality, labeled datasets. In this work, we introduce ESS, which tackles this problem by directly transferring the semantic segmentation task from existing labeled image datasets to unlabeled events via unsupervised domain adaptation (UDA). Compared to existing UDA methods, our approach aligns recurrent, motion-invariant event embeddings with image embeddings. For this reason, our method neither requires video data nor per-pixel alignment between images and events and, crucially, does not need to hallucinate motion from still images. Additionally, to spur further research in event-based semantic segmentation, we introduce DSEC-Semantic, the first large-scale event-based dataset with fine-grained labels. We show that using image labels alone, ESS outperforms existing UDA approaches, and when combined with event labels, it even outperforms state-of-the-art supervised approaches on both DDD17 and DSEC-Semantic. Finally, ESS is general-purpose, which unlocks the vast amount of existing labeled image datasets and paves the way for new and exciting research directions in new fields previously inaccessible for event cameras.  
### Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v7 [cs.CR] UPDATED)
- Authors : Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz
- Link : [http://arxiv.org/abs/2007.08457](http://arxiv.org/abs/2007.08457)
> ABSTRACT  :  Photorealistic image generation has reached a new level of quality due to the breakthroughs of generative adversarial networks (GANs). Yet, the **dark** side of such deepfakes, the malicious use of generated media, raises concerns about visual misinformation. While existing research work on deepfake detection demonstrates high accuracy, it is subject to advances in generation techniques and adversarial iterations on detection countermeasure techniques. Thus, we seek a proactive and sustainable solution on deepfake detection, that is agnostic to the evolution of generative models, by introducing artificial fingerprints into the models.    Our approach is simple and effective. We first embed artificial fingerprints into training data, then validate a surprising discovery on the transferability of such fingerprints from training data to generative models, which in turn appears in the generated deepfakes. Experiments show that our fingerprinting solution (1) holds for a variety of cutting-edge generative models, (2) leads to a negligible side effect on generation quality, (3) stays robust against image-level and model-level perturbations, (4) stays hard to be detected by adversaries, and (5) converts deepfake detection and attribution into trivial tasks and outperforms the recent state-of-the-art baselines. Our solution closes the responsibility loop between publishing pre-trained generative model inventions and their possible misuses, which makes it independent of the current arms race. Code and models are available at https://github.com/ningyu1991/ArtificialGANFingerprints .  
### CycleMLP: A MLP-like Architecture for Dense Prediction. (arXiv:2107.10224v4 [cs.CV] UPDATED)
- Authors : Shoufa Chen, Enze Xie, Chongjian Ge, Runjian Chen, Ding Liang, Ping Luo
- Link : [http://arxiv.org/abs/2107.10224](http://arxiv.org/abs/2107.10224)
> ABSTRACT  :  This paper presents a simple MLP-like architecture, CycleMLP, which is a versatile backbone for visual recognition and dense predictions. As compared to modern MLP architectures, e.g., MLP-Mixer, ResMLP, and gMLP, whose architectures are correlated to image size and thus are infeasible in object detection and segmentation, CycleMLP has two advantages compared to modern approaches. (1) It can cope with various image sizes. (2) It achieves linear computational complexity to image size by using local windows. In contrast, previous MLPs have $O(N^2)$ computations due to fully spatial connections. We build a family of models which surpass existing MLPs and even state-of-the-art Transformer-based models, e.g., **Swin** Transformer, while using fewer parameters and FLOPs. We expand the MLP-like models' applicability, making them a versatile backbone for dense prediction tasks. CycleMLP achieves competitive results on object detection, instance segmentation, and semantic segmentation. In particular, CycleMLP-Tiny outperforms **Swin**-Tiny by 1.3% mIoU on ADE20K dataset with fewer FLOPs. Moreover, CycleMLP also shows excellent zero-shot robustness on ImageNet-C dataset. Code is available at https://github.com/ShoufaChen/CycleMLP.  
### An Empirical Study of Training End-to-End Vision-and-Language Transformers. (arXiv:2111.02387v3 [cs.CV] UPDATED)
- Authors : Yi Dou, Yichong Xu, Zhe Gan, Jianfeng Wang, Shuohang Wang, Lijuan Wang, Chenguang Zhu, Pengchuan Zhang, Lu Yuan, Nanyun Peng, Zicheng Liu, Michael Zeng
- Link : [http://arxiv.org/abs/2111.02387](http://arxiv.org/abs/2111.02387)
> ABSTRACT  :  Vision-and-language (VL) pre-training has proven to be highly effective on various VL downstream tasks. While recent work has shown that fully transformer-based VL models can be more efficient than previous region-feature-based methods, their performance on downstream tasks often degrades significantly. In this paper, we present METER, a Multimodal End-to-end TransformER framework, through which we investigate how to design and pre-train a fully transformer-based VL model in an end-to-end manner. Specifically, we dissect the model designs along multiple dimensions: vision encoders (e.g., CLIP-ViT, **Swin** transformer), text encoders (e.g., RoBERTa, DeBERTa), multimodal fusion module (e.g., merged attention vs. co-attention), architectural design (e.g., encoder-only vs. encoder-decoder), and pre-training objectives (e.g., masked image modeling). We conduct comprehensive experiments and provide insights on how to train a performant VL transformer. METER achieves an accuracy of 77.64% on the VQAv2 test-std set using only 4M images for pre-training, surpassing the state-of-the-art region-feature-based model by 1.04%, and outperforming the previous best fully transformer-based model by 1.6%. Notably, when further scaled up, our best VQA model achieves an accuracy of 80.54%. Code and pre-trained models are released at https://github.com/zdou0830/METER.  
### iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images. (arXiv:2112.11325v5 [cs.CV] UPDATED)
- Authors : Qin Liu, Zhenlin Xu, Yining Jiao, Marc Niethammer
- Link : [http://arxiv.org/abs/2112.11325](http://arxiv.org/abs/2112.11325)
> ABSTRACT  :  We propose iSegFormer, a memory-efficient transformer that combines a **Swin** transformer with a lightweight multilayer perceptron (MLP) decoder. With the efficient **Swin** transformer blocks for hierarchical self-attention and the simple MLP decoder for aggregating both local and global attention, iSegFormer learns powerful representations while achieving high computational efficiencies. Specifically, we apply iSegFormer to interactive 3D medical image segmentation.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joseph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Clinical Artificial lntelligence (AI) applications are rapidly expanding worldwide, and have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow to track data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection that includes the use of VAE and domain specific statistical methods, (2) a multi-modal methodology to measure and unify drift metrics, (3) new insights into the challenges and solutions to observe deployed medical imaging AI, and (4) creation of open-source tools that enable others to easily run their own workflows and scenarios. This work has important implications. It addresses the concerning translation gap found in continuous medical imaging AI model monitoring common in dynamic healthcare environments.  
### Deep Dirichlet uncertainty for unsupervised out-of-distribution detection of eye fundus photographs in glaucoma screening. (arXiv:2202.12634v2 [cs.CV] UPDATED)
- Authors : Teresa Ara, Guilherme Aresta, Hrvoje Bogunovic
- Link : [http://arxiv.org/abs/2202.12634](http://arxiv.org/abs/2202.12634)
> ABSTRACT  :  The development of automatic tools for early glaucoma diagnosis with color fundus photographs can significantly reduce the impact of this disease. However, current state-of-the-art solutions are not robust to real-world scenarios, providing over-confident predictions for out-of-distribution cases. With this in mind, we propose a model based on the Dirichlet distribution that allows to obtain class-wise probabilities together with an uncertainty estimation without **exposure** to out-of-distribution cases. We demonstrate our approach on the AIROGS challenge. At the start of the final test phase (8 Feb. 2022), our method had the highest average score among all submissions.  
### Neural Compression-Based Feature Learning for Video **Restoration**. (arXiv:2203.09208v2 [cs.CV] UPDATED)
- Authors : Cong Huang, Jiahao Li, Bin Li, Dong Liu, Yan Lu
- Link : [http://arxiv.org/abs/2203.09208](http://arxiv.org/abs/2203.09208)
> ABSTRACT  :  How to efficiently utilize the temporal features is crucial, yet challenging, for video **restoration**. The temporal features usually contain various noisy and uncorrelated information, and they may interfere with the **restoration** of the current frame. This paper proposes learning noise-robust feature representations to help video **restoration**. We are inspired by that the neural codec is a natural denoiser. In neural codec, the noisy and uncorrelated contents which are hard to predict but cost lots of bits are more inclined to be discarded for bitrate saving. Therefore, we design a neural compression module to filter the noise and keep the most useful information in features for video **restoration**. To achieve robustness to noise, our compression module adopts a spatial channel-wise quantization mechanism to adaptively determine the quantization step size for each position in the latent. Experiments show that our method can significantly boost the performance on video denoising, where we obtain 0.13 dB improvement over BasicVSR++ with only 0.23x FLOPs. Meanwhile, our method also obtains SOTA results on video deraining and dehazing.  
### A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-resolution. (arXiv:2203.09388v2 [cs.CV] UPDATED)
- Authors : Jianqi Ma, Zhetong Liang, **Lei Zhang**
- Link : [http://arxiv.org/abs/2203.09388](http://arxiv.org/abs/2203.09388)
> ABSTRACT  :  Scene text image super-resolution aims to increase the resolution and readability of the text in low-resolution images. Though significant improvement has been achieved by deep convolutional neural networks (CNNs), it remains difficult to reconstruct high-resolution images for spatially deformed texts, especially rotated and curve-shaped ones. This is because the current CNN-based methods adopt locality-based operations, which are not effective to deal with the variation caused by deformations. In this paper, we propose a CNN based Text ATTention network (TATT) to address this problem. The semantics of the text are firstly extracted by a text recognition module as text prior information. Then we design a novel transformer-based module, which leverages global attention mechanism, to exert the semantic guidance of text prior to the text reconstruction process. In addition, we propose a text structure consistency loss to refine the visual appearance by imposing structural consistency on the reconstructions of regular and deformed texts. Experiments on the benchmark TextZoom dataset show that the proposed TATT not only achieves state-of-the-art performance in terms of PSNR/SSIM metrics, but also significantly improves the recognition accuracy in the downstream text recognition task, particularly for text instances with multi-orientation and curved shapes. Code is available at https://github.com/mjq11302010044/TATT.  
## eess.IV
---
### Secondary complementary balancing compressive imaging with a free-space balanced amplified photodetector. (arXiv:2203.09802v1 [physics.optics])
- Authors : Kai Yu, Ying Yang, Rui Liu, Ning Wei, Fei Wang
- Link : [http://arxiv.org/abs/2203.09802](http://arxiv.org/abs/2203.09802)
> ABSTRACT  :  Single-pixel imaging (SPI) has attracted widespread attention because it generally uses a non-pixelated photodetector and a digital micromirror device (DMD) to acquire the object image. Since the modulated patterns seen from two reflection directions of the DMD are naturally complementary, one can apply complementary balanced measurements to greatly improve the measurement signal-to-noise ratio and reconstruction quality. However, the balance between two reflection arms significantly determines the quality of differential measurements. In this work, we propose and demonstrate a simple secondary complementary balancing mechanism to minimize the impact of the imbalance on the imaging system. In our SPI setup, we used a silicon free-space balanced amplified photodetector with 5 mm active diameter which could directly output the difference between two optical input signals in two reflection arms. Both simulation and experimental results have demonstrated that the use of secondary complementary balancing can result in a better cancellation of direct current components of measurements and a better image **restoration** quality.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joseph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Clinical Artificial lntelligence (AI) applications are rapidly expanding worldwide, and have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow to track data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection that includes the use of VAE and domain specific statistical methods, (2) a multi-modal methodology to measure and unify drift metrics, (3) new insights into the challenges and solutions to observe deployed medical imaging AI, and (4) creation of open-source tools that enable others to easily run their own workflows and scenarios. This work has important implications. It addresses the concerning translation gap found in continuous medical imaging AI model monitoring common in dynamic healthcare environments.  
## cs.LG
---
### Transferable Class-Modelling for Decentralized Source Attribution of GAN-Generated Images. (arXiv:2203.09777v1 [cs.CV])
- Authors : Chern Hong
- Link : [http://arxiv.org/abs/2203.09777](http://arxiv.org/abs/2203.09777)
> ABSTRACT  :  GAN-generated deepfakes as a genre of digital images are gaining ground as both catalysts of artistic expression and malicious forms of deception, therefore demanding systems to enforce and accredit their ethical use. Existing techniques for the source attribution of synthetic images identify subtle intrinsic fingerprints using multiclass classification neural nets limited in functionality and scalability. Hence, we redefine the deepfake detection and source attribution problems as a series of related binary classification tasks. We leverage transfer learning to rapidly adapt forgery detection networks for multiple independent attribution problems, by proposing a semi-decentralized modular design to solve them simultaneously and efficiently. Class activation mapping is also demonstrated as an effective means of feature localization for model interpretation. Our models are determined via experimentation to be competitive with current benchmarks, and capable of decent performance on human portraits in ideal conditions. Decentralized fingerprint-based attribution is found to retain validity in the presence of novel sources, but is more susceptible to type II errors that intensify with image perturbations and attributive uncertainty. We describe both our conceptual framework and model prototypes for further **enhancement** when investigating the technical limits of reactive deepfake attribution.  
### Parametric Scaling of Preprocessing assisted U-net Architecture for Improvised Retinal Vessel Segmentation. (arXiv:2203.10014v1 [eess.IV])
- Authors : Kundan Kumar, Sumanshu Agarwal
- Link : [http://arxiv.org/abs/2203.10014](http://arxiv.org/abs/2203.10014)
> ABSTRACT  :  Extracting blood vessels from retinal fundus images plays a decisive role in diagnosing the progression in pertinent diseases. In medical image analysis, vessel extraction is a semantic binary segmentation problem, where blood vasculature needs to be extracted from the background. Here, we present an image **enhancement** technique based on the morphological preprocessing coupled with a scaled U-net architecture. Despite a relatively less number of trainable network parameters, the scaled version of U-net architecture provides better performance compare to other methods in the domain. We validated the proposed method on retinal fundus images from the DRIVE database. A significant improvement as compared to the other algorithms in the domain, in terms of the area under ROC curve (&gt;0.9762) and classification accuracy (&gt;95.47%) are evident from the results. Furthermore, the proposed method is resistant to the central vessel reflex while sensitive to detect blood vessels in the presence of background items viz. exudates, optic disc, and fovea.  
### Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v7 [cs.CR] UPDATED)
- Authors : Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz
- Link : [http://arxiv.org/abs/2007.08457](http://arxiv.org/abs/2007.08457)
> ABSTRACT  :  Photorealistic image generation has reached a new level of quality due to the breakthroughs of generative adversarial networks (GANs). Yet, the **dark** side of such deepfakes, the malicious use of generated media, raises concerns about visual misinformation. While existing research work on deepfake detection demonstrates high accuracy, it is subject to advances in generation techniques and adversarial iterations on detection countermeasure techniques. Thus, we seek a proactive and sustainable solution on deepfake detection, that is agnostic to the evolution of generative models, by introducing artificial fingerprints into the models.    Our approach is simple and effective. We first embed artificial fingerprints into training data, then validate a surprising discovery on the transferability of such fingerprints from training data to generative models, which in turn appears in the generated deepfakes. Experiments show that our fingerprinting solution (1) holds for a variety of cutting-edge generative models, (2) leads to a negligible side effect on generation quality, (3) stays robust against image-level and model-level perturbations, (4) stays hard to be detected by adversaries, and (5) converts deepfake detection and attribution into trivial tasks and outperforms the recent state-of-the-art baselines. Our solution closes the responsibility loop between publishing pre-trained generative model inventions and their possible misuses, which makes it independent of the current arms race. Code and models are available at https://github.com/ningyu1991/ArtificialGANFingerprints .  
### Comprehensive Review On Twin Support Vector Machines. (arXiv:2105.00336v3 [cs.LG] UPDATED)
- Authors : 
- Link : [http://arxiv.org/abs/2105.00336](http://arxiv.org/abs/2105.00336)
> ABSTRACT  :  Twin support vector machine (TWSVM) and twin support vector regression (TSVR) are newly emerging efficient machine learning techniques which offer promising solutions for classification and regression challenges respectively. TWSVM is based upon the idea to identify two nonparallel hyperplanes which classify the data points to their respective classes. It requires to solve two small sized quadratic programming problems (QPPs) in lieu of solving single large size QPP in support vector machine (SVM) while TSVR is formulated on the lines of TWSVM and requires to solve two SVM kind problems. Although there has been good research progress on these techniques; there is limited literature on the comparison of different variants of TSVR. Thus, this review presents a rigorous analysis of recent research in TWSVM and TSVR simultaneously mentioning their limitations and advantages. To begin with we first introduce the basic theory of support vector machine, TWSVM and then focus on the various improvements and applications of TWSVM, and then we introduce TSVR and its various **enhancement**s. Finally, we suggest future research and development prospects.  
### An Empirical Study of Training End-to-End Vision-and-Language Transformers. (arXiv:2111.02387v3 [cs.CV] UPDATED)
- Authors : Yi Dou, Yichong Xu, Zhe Gan, Jianfeng Wang, Shuohang Wang, Lijuan Wang, Chenguang Zhu, Pengchuan Zhang, Lu Yuan, Nanyun Peng, Zicheng Liu, Michael Zeng
- Link : [http://arxiv.org/abs/2111.02387](http://arxiv.org/abs/2111.02387)
> ABSTRACT  :  Vision-and-language (VL) pre-training has proven to be highly effective on various VL downstream tasks. While recent work has shown that fully transformer-based VL models can be more efficient than previous region-feature-based methods, their performance on downstream tasks often degrades significantly. In this paper, we present METER, a Multimodal End-to-end TransformER framework, through which we investigate how to design and pre-train a fully transformer-based VL model in an end-to-end manner. Specifically, we dissect the model designs along multiple dimensions: vision encoders (e.g., CLIP-ViT, **Swin** transformer), text encoders (e.g., RoBERTa, DeBERTa), multimodal fusion module (e.g., merged attention vs. co-attention), architectural design (e.g., encoder-only vs. encoder-decoder), and pre-training objectives (e.g., masked image modeling). We conduct comprehensive experiments and provide insights on how to train a performant VL transformer. METER achieves an accuracy of 77.64% on the VQAv2 test-std set using only 4M images for pre-training, surpassing the state-of-the-art region-feature-based model by 1.04%, and outperforming the previous best fully transformer-based model by 1.6%. Notably, when further scaled up, our best VQA model achieves an accuracy of 80.54%. Code and pre-trained models are released at https://github.com/zdou0830/METER.  
### Correcting diacritics and typos with a ByT5 transformer model. (arXiv:2201.13242v2 [cs.CL] UPDATED)
- Authors : Lukas Stankevi, Mantas Luko, Jurgita Kapo, Monika Briedien, Tomas Krilavi
- Link : [http://arxiv.org/abs/2201.13242](http://arxiv.org/abs/2201.13242)
> ABSTRACT  :  Due to the fast pace of life and online communications and the prevalence of English and the QWERTY keyboard, people tend to forgo using diacritics, make typographical errors (typos) when typing in other languages. Restoring diacritics and correcting spelling is important for proper language use and the disambiguation of texts for both humans and downstream algorithms. However, both of these problems are typically addressed separately: the state-of-the-art diacritics **restoration** methods do not tolerate other typos, but classical spellcheckers also cannot deal adequately with all the diacritics missing. In this work, we tackle both problems at once by employing the newly-developed universal ByT5 byte-level seq2seq transformer model that requires no language-specific model structures. For a comparison, we perform diacritics **restoration** on benchmark datasets of 12 languages, with the addition of Lithuanian. The experimental investigation proves that our approach is able to achieve results (&gt; 98%) comparable to the previous state-of-the-art, despite being trained less and on fewer data. Our approach is also able to restore diacritics in words not seen during training with &gt; 76% accuracy. Our simultaneous diacritics **restoration** and typos correction approach reaches &gt; 94% alpha-word accuracy on the 13 languages. It has no direct competitors and strongly outperforms classical spell-checking or dictionary-based approaches. We also demonstrate all the accuracies to further improve with more training. Taken together, this shows the great real-world application potential of our suggested methods to more data, languages, and error classes.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joseph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Clinical Artificial lntelligence (AI) applications are rapidly expanding worldwide, and have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow to track data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection that includes the use of VAE and domain specific statistical methods, (2) a multi-modal methodology to measure and unify drift metrics, (3) new insights into the challenges and solutions to observe deployed medical imaging AI, and (4) creation of open-source tools that enable others to easily run their own workflows and scenarios. This work has important implications. It addresses the concerning translation gap found in continuous medical imaging AI model monitoring common in dynamic healthcare environments.  
### Deep Dirichlet uncertainty for unsupervised out-of-distribution detection of eye fundus photographs in glaucoma screening. (arXiv:2202.12634v2 [cs.CV] UPDATED)
- Authors : Teresa Ara, Guilherme Aresta, Hrvoje Bogunovic
- Link : [http://arxiv.org/abs/2202.12634](http://arxiv.org/abs/2202.12634)
> ABSTRACT  :  The development of automatic tools for early glaucoma diagnosis with color fundus photographs can significantly reduce the impact of this disease. However, current state-of-the-art solutions are not robust to real-world scenarios, providing over-confident predictions for out-of-distribution cases. With this in mind, we propose a model based on the Dirichlet distribution that allows to obtain class-wise probabilities together with an uncertainty estimation without **exposure** to out-of-distribution cases. We demonstrate our approach on the AIROGS challenge. At the start of the final test phase (8 Feb. 2022), our method had the highest average score among all submissions.  
## cs.AI
---
### Developing a Successful Bomberman Agent. (arXiv:2203.09608v1 [cs.AI])
- Authors : Dominik Kowalczyk, Jakub Kowalski, Hubert Obrzut, Szymon Kosakowski, aw Miernik
- Link : [http://arxiv.org/abs/2203.09608](http://arxiv.org/abs/2203.09608)
> ABSTRACT  :  In this paper, we study AI approaches to successfully play a 2-4 players, full information, Bomberman variant published on the CodinGame platform. We compare the behavior of three search algorithms: Monte Carlo Tree Search, Rolling Horizon Evolution, and Beam Search. We present various **enhancement**s leading to improve the agents' strength that concern search, opponent prediction, game state evaluation, and game engine encoding. Our top agent variant is based on a Beam Search with low-level bit-based state representation and evaluation function heavy relying on pruning unpromising states based on simulation-based estimation of survival. It reached the top one position among the 2,300 AI agents submitted on the CodinGame arena.  
### Comprehensive Review On Twin Support Vector Machines. (arXiv:2105.00336v3 [cs.LG] UPDATED)
- Authors : 
- Link : [http://arxiv.org/abs/2105.00336](http://arxiv.org/abs/2105.00336)
> ABSTRACT  :  Twin support vector machine (TWSVM) and twin support vector regression (TSVR) are newly emerging efficient machine learning techniques which offer promising solutions for classification and regression challenges respectively. TWSVM is based upon the idea to identify two nonparallel hyperplanes which classify the data points to their respective classes. It requires to solve two small sized quadratic programming problems (QPPs) in lieu of solving single large size QPP in support vector machine (SVM) while TSVR is formulated on the lines of TWSVM and requires to solve two SVM kind problems. Although there has been good research progress on these techniques; there is limited literature on the comparison of different variants of TSVR. Thus, this review presents a rigorous analysis of recent research in TWSVM and TSVR simultaneously mentioning their limitations and advantages. To begin with we first introduce the basic theory of support vector machine, TWSVM and then focus on the various improvements and applications of TWSVM, and then we introduce TSVR and its various **enhancement**s. Finally, we suggest future research and development prospects.  
# Paper List
---
## cs.CV
---
**121** new papers in cs.CV:-) 
1. Human Gait Analysis using Gait Energy Image. (arXiv:2203.09549v1 [cs.CV])
2. Multi-similarity based Hyperrelation Network for few-shot segmentation. (arXiv:2203.09550v1 [cs.CV])
3. CoGS: Controllable Generation and Search from Sketch and Style. (arXiv:2203.09554v1 [cs.CV])
4. Surface Defect Detection and Evaluation for Marine Vessels using Multi-Stage Deep Learning. (arXiv:2203.09580v1 [cs.CV])
5. SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v1 [cs.CV])
6. Video-based Formative and Summative Assessment of Surgical Tasks using Deep Learning. (arXiv:2203.09589v1 [cs.CV])
7. Delta Distillation for Efficient Video Processing. (arXiv:2203.09594v1 [cs.CV])
8. Unified Line and Paragraph Detection by Graph Convolutional Networks. (arXiv:2203.09638v1 [cs.CV])
9. Cascade Transformers for End-to-End Person Search. (arXiv:2203.09642v1 [cs.CV])
10. MatchFormer: Interleaving Attention in Transformers for Feature Matching. (arXiv:2203.09645v1 [cs.CV])
11. Regional Semantic Contrast and Aggregation for Weakly Supervised Semantic Segmentation. (arXiv:2203.09653v1 [cs.CV])
12. A workflow for segmenting soil and plant X-ray CT images with deep learning in Googles Colaboratory. (arXiv:2203.09674v1 [eess.IV])
13. Modeling Intensification for Sign Language Generation: A Computational Approach. (arXiv:2203.09679v1 [cs.CL])
14. Facial Geometric Detail Recovery via Implicit Representation. (arXiv:2203.09692v1 [cs.CV])
15. Group Contextualization for Video Recognition. (arXiv:2203.09694v1 [cs.CV])
16. VISTA: Boosting 3D Object Detection via Dual Cross-VIew SpaTial Attention. (arXiv:2203.09704v1 [cs.CV])
17. Deterministic Bridge Regression for Compressive Classification. (arXiv:2203.09721v1 [cs.LG])
18. Rethinking the optimization process for self-supervised model-driven MRI reconstruction. (arXiv:2203.09724v1 [eess.IV])
19. REALY: Rethinking the Evaluation of 3D Face Reconstruction. (arXiv:2203.09729v1 [cs.CV])
20. A Dual Weighting Label Assignment Scheme for Object Detection. (arXiv:2203.09730v1 [cs.CV])
21. Distortion-Tolerant Monocular Depth Estimation On Omnidirectional Images Using Dual-cubemap. (arXiv:2203.09733v1 [cs.CV])
22. Series Photo Selection via Multi-view Graph Learning. (arXiv:2203.09736v1 [cs.CV])
23. Semi-Supervised Learning with Mutual Distillation for Monocular Depth Estimation. (arXiv:2203.09737v1 [cs.CV])
24. Do Deep Networks Transfer Invariances Across Classes?. (arXiv:2203.09739v1 [cs.CV])
25. Class-Balanced Pixel-Level Self-Labeling for Domain Adaptive Semantic Segmentation. (arXiv:2203.09744v1 [cs.CV])
26. Robot peels banana with goal-conditioned dual-action deep imitation learning. (arXiv:2203.09749v1 [cs.RO])
27. AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack. (arXiv:2203.09756v1 [cs.CV])
28. Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition. (arXiv:2203.09771v1 [cs.CV])
29. Completing Partial Point Clouds with Outliers by Collaborative Completion and Segmentation. (arXiv:2203.09772v1 [cs.CV])
30. Local-Global Context Aware Transformer for Language-Guided Video Segmentation. (arXiv:2203.09773v1 [cs.CV])
31. ContrastMask: Contrastive Learning to Segment Every Thing. (arXiv:2203.09775v1 [cs.CV])
32. Transferable Class-Modelling for Decentralized Source Attribution of GAN-Generated Images. (arXiv:2203.09777v1 [cs.CV])
33. Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion. (arXiv:2203.09780v1 [cs.CV])
34. Towards Robust 2D Convolution for Reliable Visual Recognition. (arXiv:2203.09790v1 [cs.CV])
35. Three things everyone should know about Vision Transformers. (arXiv:2203.09795v1 [cs.CV])
36. Learning Consistency from High-quality Pseudo-labels for Weakly Supervised Object Localization. (arXiv:2203.09803v1 [cs.CV])
37. Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation. (arXiv:2203.09811v1 [cs.CV])
38. Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared Control on the Hannes Prosthesis. (arXiv:2203.09812v1 [cs.RO])
39. Cross-Modal Perceptionist: Can Face Geometry be Gleaned from Voices?. (arXiv:2203.09824v1 [cs.CV])
40. Laneformer: Object-aware Row-Column Transformers for Lane Detection. (arXiv:2203.09830v1 [cs.CV])
41. DTA: Physical Camouflage Attacks using Differentiable Transformation Network. (arXiv:2203.09831v1 [cs.CV])
42. Perspective Flow Aggregation for Data-Limited 6D Object Pose Estimation. (arXiv:2203.09836v1 [cs.CV])
43. Location-Free Camouflage Generation Network. (arXiv:2203.09845v1 [cs.CV])
44. Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion. (arXiv:2203.09855v1 [cs.CV])
45. Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification. (arXiv:2203.09860v1 [eess.IV])
46. CodedVTR: Codebook-based Sparse Voxel Transformer with Geometric Guidance. (arXiv:2203.09887v1 [cs.CV])
47. Learning Affordance Grounding from Exocentric Images. (arXiv:2203.09905v1 [cs.CV])
48. Fourier Document **Restoration** for Robust Document Dewarping and Recognition. (arXiv:2203.09910v1 [cs.CV])
49. Convolutional Simultaneous Sparse Approximation with Applications to RGB-NIR Image Fusion. (arXiv:2203.09913v1 [cs.CV])
50. Revealing Reliable Signatures by Learning Top-Rank Pairs. (arXiv:2203.09927v1 [cs.CV])
51. Deepfake Style Transfer Mixture: a First Forensic Ballistics Study on Synthetic Images. (arXiv:2203.09928v1 [cs.CV])
52. 3DAC: Learning Attribute Compression for Point Clouds. (arXiv:2203.09931v1 [cs.CV])
53. On the sensitivity of pose estimation neural networks: rotation parameterizations, Lipschitz constants, and provable bounds. (arXiv:2203.09937v1 [cs.CV])
54. Neural Enhanced Belief Propagation for Data Assocation in Multiobject Tracking. (arXiv:2203.09948v1 [cs.CV])
55. **Enhancement** of Novel View Synthesis Using Omnidirectional Image Completion. (arXiv:2203.09957v1 [cs.CV])
56. SynthStrip: Skull-Stripping for Any Brain Image. (arXiv:2203.09974v1 [eess.IV])
57. GiNGR: Generalized Iterative Non-Rigid Point Cloud and Surface Registration Using Gaussian Process Regression. (arXiv:2203.09986v1 [cs.CV])
58. Diffusion and Volume Maximization-Based Clustering of Highly Mixed Hyperspectral Images. (arXiv:2203.09992v1 [cs.CV])
59. Elastica Models for Color Image Regularization. (arXiv:2203.09995v1 [cs.CV])
60. Application of Top-hat Transformation for Enhanced Blood Vessel Extraction. (arXiv:2203.10005v1 [cs.CV])
61. Ultra-low Latency Spiking Neural Networks with Spatio-Temporal Compression and Synaptic Convolutional Block. (arXiv:2203.10006v1 [cs.NE])
62. Analyzing EEG Data with Machine and Deep Learning: A Benchmark. (arXiv:2203.10009v1 [cs.LG])
63. Parametric Scaling of Preprocessing assisted U-net Architecture for Improvised Retinal Vessel Segmentation. (arXiv:2203.10014v1 [eess.IV])
64. ESS: Learning Event-based Semantic Segmentation from Still Images. (arXiv:2203.10016v1 [cs.CV])
65. Unbiased Subclass Regularization for Semi-Supervised Semantic Segmentation. (arXiv:2203.10026v1 [cs.CV])
66. Nonnegative-Constrained Joint Collaborative Representation with Union Dictionary for Hyperspectral Anomaly Detection. (arXiv:2203.10030v1 [cs.CV])
67. SHREC 2021: Classification in cryo-electron tomograms. (arXiv:2203.10035v1 [cs.CV])
68. Multi-input segmentation of damaged brain in acute ischemic stroke patients using slow fusion with skip connection. (arXiv:2203.10039v1 [cs.CV])
69. Imaging-based histological features are predictive of MET alterations in Non-Small Cell Lung Cancer. (arXiv:2203.10062v1 [cs.CV])
70. Lunar Rover Localization Using Craters as Landmarks. (arXiv:2203.10073v1 [cs.RO])
71. Bayesian Inversion for Nonlinear Imaging Models using Deep Generative Priors. (arXiv:2203.10078v1 [cs.CV])
72. Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v7 [cs.CR] UPDATED)
73. MODNet: Real-Time Trimap-Free Portrait Matting via Objective Decomposition. (arXiv:2011.11961v4 [cs.CV] UPDATED)
74. Globetrotter: Connecting Languages by Connecting Images. (arXiv:2012.04631v2 [cs.CL] UPDATED)
75. Responsible Disclosure of Generative Models Using Scalable Fingerprinting. (arXiv:2012.08726v5 [cs.CR] UPDATED)
76. A Simple Mutual Information based Registration Method for Thermal-Optical Image Pairs applied on a Novel Dataset. (arXiv:2101.06910v3 [eess.IV] UPDATED)
77. Domain Adversarial Neural Networks for Domain Generalization: When It Works and How to Improve. (arXiv:2102.03924v2 [cs.LG] UPDATED)
78. ImageNet as a Representative Basis for Deriving Generally Effective CNN Architectures. (arXiv:2103.09108v3 [cs.CV] UPDATED)
79. Collapsible Linear Blocks for Super-Efficient Super Resolution. (arXiv:2103.09404v4 [eess.IV] UPDATED)
80. ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation. (arXiv:2103.10702v3 [cs.CV] UPDATED)
81. Dual Contrastive Loss and Attention for GANs. (arXiv:2103.16748v3 [cs.CV] UPDATED)
82. Generative Adversarial Registration for Improved Conditional Deformable Templates. (arXiv:2105.04349v2 [cs.CV] UPDATED)
83. Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v4 [cs.LG] UPDATED)
84. Learning to Affiliate: Mutual Centralized Learning for Few-shot Classification. (arXiv:2106.05517v4 [cs.CV] UPDATED)
85. Gradient-Based Quantification of Epistemic Uncertainty for Deep Object Detectors. (arXiv:2107.04517v2 [cs.CV] UPDATED)
86. HDMapNet: An Online HD Map Construction and Evaluation Framework. (arXiv:2107.06307v4 [cs.CV] UPDATED)
87. CycleMLP: A MLP-like Architecture for Dense Prediction. (arXiv:2107.10224v4 [cs.CV] UPDATED)
88. Cervical Optical Coherence Tomography Image Classification Based on Contrastive Self-Supervised Texture Learning. (arXiv:2108.05081v3 [eess.IV] UPDATED)
89. PGTRNet: Two-phase Weakly Supervised Object Detection with Pseudo Ground Truth Refinement. (arXiv:2108.11439v2 [cs.CV] UPDATED)
90. Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with Transformers. (arXiv:2109.03814v4 [cs.CV] UPDATED)
91. M5Product: Self-harmonized Contrastive Learning for E-commercial Multi-modal Pretraining. (arXiv:2109.04275v4 [cs.CV] UPDATED)
92. METEOR:A Dense, Heterogeneous, and Unstructured Traffic Dataset With Rare Behaviors. (arXiv:2109.07648v3 [cs.CV] UPDATED)
93. Image-Based CLIP-Guided Essence Transfer. (arXiv:2110.12427v3 [cs.CV] UPDATED)
94. An Empirical Study of Training End-to-End Vision-and-Language Transformers. (arXiv:2111.02387v3 [cs.CV] UPDATED)
95. TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation. (arXiv:2111.02682v2 [cs.CV] UPDATED)
96. Deep Depth from Focus with Differential Focus Volume. (arXiv:2112.01712v2 [cs.CV] UPDATED)
97. A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion. (arXiv:2112.03530v3 [cs.CV] UPDATED)
98. All You Need is RAW: Defending Against Adversarial Attacks with Camera Image Pipelines. (arXiv:2112.09219v2 [cs.CV] UPDATED)
99. iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images. (arXiv:2112.11325v5 [cs.CV] UPDATED)
100. SAMCNet for Spatial-configuration-based Classification: A Summary of Results. (arXiv:2112.12219v2 [cs.CV] UPDATED)
101. Towards Disturbance-Free Visual Mobile Manipulation. (arXiv:2112.12612v2 [cs.RO] UPDATED)
102. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
103. A multiscale spatiotemporal approach for smallholder irrigation detection. (arXiv:2202.04239v2 [cs.CV] UPDATED)
104. Deep Dirichlet uncertainty for unsupervised out-of-distribution detection of eye fundus photographs in glaucoma screening. (arXiv:2202.12634v2 [cs.CV] UPDATED)
105. X-Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning. (arXiv:2203.00843v2 [cs.CV] UPDATED)
106. Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation. (arXiv:2203.01452v2 [cs.CV] UPDATED)
107. Towards Universal Backward-Compatible Representation Learning. (arXiv:2203.01583v2 [cs.CV] UPDATED)
108. Adversarial Texture for Fooling Person Detectors in the Physical World. (arXiv:2203.03373v3 [cs.CV] UPDATED)
109. Region-Aware Face Swapping. (arXiv:2203.04564v2 [cs.CV] UPDATED)
110. BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis. (arXiv:2203.05297v3 [cs.CV] UPDATED)
111. Domain Generalization via Shuffled Style Assembly for Face Anti-Spoofing. (arXiv:2203.05340v4 [cs.CV] UPDATED)
112. NeILF: Neural Incident Light Field for Physically-based Material Estimation. (arXiv:2203.07182v2 [cs.CV] UPDATED)
113. Distribution-Aware Single-Stage Models for Multi-Person 3D Pose Estimation. (arXiv:2203.07697v3 [cs.CV] UPDATED)
114. On Hyperbolic Embeddings in 2D Object Detection. (arXiv:2203.08049v3 [cs.CV] UPDATED)
115. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v2 [cs.CV] UPDATED)
116. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v2 [cs.CL] UPDATED)
117. Neural Compression-Based Feature Learning for Video **Restoration**. (arXiv:2203.09208v2 [cs.CV] UPDATED)
118. Interacting Attention Graph for Single Image Two-Hand Reconstruction. (arXiv:2203.09364v2 [cs.CV] UPDATED)
119. A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-resolution. (arXiv:2203.09388v2 [cs.CV] UPDATED)
120. Vox2Cortex: Fast Explicit Reconstruction of Cortical Surfaces from 3D MRI Scans with Geometric Deep Neural Networks. (arXiv:2203.09446v2 [cs.CV] UPDATED)
121. Transframer: Arbitrary Frame Prediction with Generative Models. (arXiv:2203.09494v2 [cs.CV] UPDATED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. MatchFormer: Interleaving Attention in Transformers for Feature Matching. (arXiv:2203.09645v1 [cs.CV])
2. Learning Nonlocal Sparse and Low-Rank Models for Image Compressive Sensing. (arXiv:2203.09656v1 [eess.IV])
3. A workflow for segmenting soil and plant X-ray CT images with deep learning in Googles Colaboratory. (arXiv:2203.09674v1 [eess.IV])
4. Rethinking the optimization process for self-supervised model-driven MRI reconstruction. (arXiv:2203.09724v1 [eess.IV])
5. Sensor fusion in ptychography. (arXiv:2203.09794v1 [eess.IV])
6. Secondary complementary balancing compressive imaging with a free-space balanced amplified photodetector. (arXiv:2203.09802v1 [physics.optics])
7. Pseudo Bias-Balanced Learning for Debiased Chest X-ray Classification. (arXiv:2203.09860v1 [eess.IV])
8. SynthStrip: Skull-Stripping for Any Brain Image. (arXiv:2203.09974v1 [eess.IV])
9. Image Storage on Synthetic DNA Using Autoencoders. (arXiv:2203.09981v1 [cs.LG])
10. A constrained Shannon-Fano entropy coder for image storage in synthetic DNA. (arXiv:2203.09988v1 [eess.IV])
11. Picosecond Hyperspectral Fringe Pattern Projection for 3D Surface Measurement. (arXiv:2203.10008v1 [physics.optics])
12. A Simple Mutual Information based Registration Method for Thermal-Optical Image Pairs applied on a Novel Dataset. (arXiv:2101.06910v3 [eess.IV] UPDATED)
13. Collapsible Linear Blocks for Super-Efficient Super Resolution. (arXiv:2103.09404v4 [eess.IV] UPDATED)
14. Generative Adversarial Registration for Improved Conditional Deformable Templates. (arXiv:2105.04349v2 [cs.CV] UPDATED)
15. Cervical Optical Coherence Tomography Image Classification Based on Contrastive Self-Supervised Texture Learning. (arXiv:2108.05081v3 [eess.IV] UPDATED)
16. All You Need is RAW: Defending Against Adversarial Attacks with Camera Image Pipelines. (arXiv:2112.09219v2 [cs.CV] UPDATED)
17. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
18. Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation. (arXiv:2203.01452v2 [cs.CV] UPDATED)
19. Neural network processing of holographic images. (arXiv:2203.08898v2 [eess.IV] UPDATED)
20. Lossless Image and Intra-frame Compression with Integer-to-Integer DST. (arXiv:1708.07154v1 [cs.MM] CROSS LISTED)
21. Deep Semi-supervised Metric Learning with Dual Alignment for Cervical Cancer Cell Detection. (arXiv:2104.03265v2 [eess.IV] CROSS LISTED)
## cs.LG
---
**173** new papers in cs.LG:-) 
1. Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation. (arXiv:2203.09553v1 [cs.AI])
2. On the expressive power of message-passing neural networks as global feature map transformers. (arXiv:2203.09555v1 [cs.AI])
3. Outcome Assumptions and Duality Theory for Balancing Weights. (arXiv:2203.09557v1 [stat.ME])
4. Leveraging Adversarial Examples to Quantify Membership Information Leakage. (arXiv:2203.09566v1 [cs.LG])
5. Triangle and Four Cycle Counting with Predictions in Graph Streams. (arXiv:2203.09572v1 [cs.DS])
6. SepTr: Separable Transformer for Audio Spectrogram Processing. (arXiv:2203.09581v1 [cs.CV])
7. Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations. (arXiv:2203.09590v1 [cs.CL])
8. Delta Distillation for Efficient Video Processing. (arXiv:2203.09594v1 [cs.CV])
9. DP-KB: Data Programming with Knowledge Bases Improves Transformer Fine Tuning for Answer Sentence Selection. (arXiv:2203.09598v1 [cs.CL])
10. Learning Distributionally Robust Models at Scale via Composite Optimization. (arXiv:2203.09607v1 [cs.LG])
11. STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v1 [cs.LG])
12. DeepLSS: breaking parameter degeneracies in large scale structure with deep learning analysis of combined probes. (arXiv:2203.09616v1 [astro-ph.CO])
13. The Analysis of Online Event Streams: Predicting the Next Activity for Anomaly Detection. (arXiv:2203.09619v1 [cs.LG])
14. On the Importance of Data Size in Probing Fine-tuned Models. (arXiv:2203.09627v1 [cs.CL])
15. Monotonic Differentiable Sorting Networks. (arXiv:2203.09630v1 [cs.LG])
16. A Learning Framework for Bandwidth-Efficient Distributed Inference in Wireless IoT. (arXiv:2203.09631v1 [eess.SP])
17. Inventing Relational State and Action Abstractions for Effective and Efficient Bilevel Planning. (arXiv:2203.09634v1 [cs.AI])
18. Design of Compressed Sensing Systems via Density-Evolution Framework for Structure Recovery in Graphical Models. (arXiv:2203.09636v1 [cs.IT])
19. Investigating Compounding Prediction Errors in Learned Dynamics Models. (arXiv:2203.09637v1 [cs.LG])
20. Unified Line and Paragraph Detection by Graph Convolutional Networks. (arXiv:2203.09638v1 [cs.CV])
21. Generating unrepresented proportions of geological facies using Generative Adversarial Networks. (arXiv:2203.09639v1 [cs.LG])
22. Low-degree learning and the metric entropy of polynomials. (arXiv:2203.09659v1 [cs.LG])
23. Meta Reinforcement Learning for Adaptive Control: An Offline Approach. (arXiv:2203.09661v1 [eess.SY])
24. An Improved Subject-Independent Stress Detection Model Applied to Consumer-grade Wearable Devices. (arXiv:2203.09663v1 [cs.LG])
25. Emerging Artificial Intelligence Applications in Spatial Transcriptomics Analysis. (arXiv:2203.09664v1 [cs.LG])
26. Analysing the Performance of Stress Detection Models on Consumer-Grade Wearable Devices. (arXiv:2203.09669v1 [cs.LG])
27. Latency Optimization for Blockchain-Empowered Federated Learning in Multi-Server Edge Computing. (arXiv:2203.09670v1 [cs.LG])
28. Multi-Modal Causal Inference with Deep Structural Equation Models. (arXiv:2203.09672v1 [cs.LG])
29. Fast Bayesian Coresets via Subsampling and Quasi-Newton Refinement. (arXiv:2203.09675v1 [stat.ML])
30. Self-Ensemble Adversarial Training for Improved Robustness. (arXiv:2203.09678v1 [cs.LG])
31. LeHDC: Learning-Based Hyperdimensional Computing Classifier. (arXiv:2203.09680v1 [cs.LG])
32. Generative Principal Component Analysis. (arXiv:2203.09693v1 [stat.ML])
33. Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations. (arXiv:2203.09697v1 [cs.LG])
34. Federated Learning for Privacy Preservation in Smart Healthcare Systems: A Comprehensive Survey. (arXiv:2203.09702v1 [eess.SY])
35. Learning Stabilizable Deep Dynamics Models. (arXiv:2203.09710v1 [cs.LG])
36. Towards an AI-Driven Universal Anti-Jamming Solution with Convolutional Interference Cancellation Network. (arXiv:2203.09717v1 [cs.NI])
37. Deterministic Bridge Regression for Compressive Classification. (arXiv:2203.09721v1 [cs.LG])
38. DEFORM: A Practical, Universal Deep Beamforming System. (arXiv:2203.09727v1 [cs.NI])
39. PRBoost: Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning. (arXiv:2203.09735v1 [cs.CL])
40. Do Deep Networks Transfer Invariances Across Classes?. (arXiv:2203.09739v1 [cs.CV])
41. Soft Smoothness for Audio Inpainting Using a Latent Matrix Model in Delay-embedded Space. (arXiv:2203.09746v1 [eess.AS])
42. Efficient Split-Mix Federated Learning for On-Demand and In-Situ Customization. (arXiv:2203.09747v1 [cs.LG])
43. Look-Ahead Acquisition Functions for Bernoulli Level Set Estimation. (arXiv:2203.09751v1 [stat.ML])
44. Distributed Sketching for Randomized Optimization: Exact Characterization, Concentration and Lower Bounds. (arXiv:2203.09755v1 [math.OC])
45. AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack. (arXiv:2203.09756v1 [cs.CV])
46. Speaker Embedding-aware Neural Diarization: a Novel Framework for Overlapped Speech Diarization in the Meeting Scenario. (arXiv:2203.09767v1 [cs.SD])
47. Prototypical Verbalizer for Prompt-based Few-shot Tuning. (arXiv:2203.09770v1 [cs.CL])
48. Transferable Class-Modelling for Decentralized Source Attribution of GAN-Generated Images. (arXiv:2203.09777v1 [cs.CV])
49. ISDE : Independence Structure Density Estimation. (arXiv:2203.09783v1 [cs.LG])
50. Constitutive model characterization and discovery using physics-informed deep learning. (arXiv:2203.09789v1 [cs.LG])
51. AdIoTack: Quantifying and Refining Resilience of Decision Tree Ensemble Inference Models against Adversarial Volumetric Attacks on IoT Networks. (arXiv:2203.09792v1 [cs.LG])
52. Proximal Policy Optimization with Adaptive Threshold for Symmetric Relative Density Ratio. (arXiv:2203.09809v1 [cs.LG])
53. Dencentralized learning in the presence of low-rank noise. (arXiv:2203.09810v1 [cs.LG])
54. Are You Robert or RoBERTa? Deceiving Online Authorship Attribution Models Using Neural Text Generators. (arXiv:2203.09813v1 [cs.CL])
55. Cross-Modal Perceptionist: Can Face Geometry be Gleaned from Voices?. (arXiv:2203.09824v1 [cs.CV])
56. Towards Representative Subset Selection for Self-Supervised Speech Recognition. (arXiv:2203.09829v1 [cs.LG])
57. Gender classification by means of online uppercase handwriting: A text-dependent allographic approach. (arXiv:2203.09848v1 [cs.LG])
58. Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition. (arXiv:2203.09849v1 [cs.SD])
59. Decision-Making under Miscalibration. (arXiv:2203.09852v1 [cs.LG])
60. Finite-sample analysis of identification of switched linear systems with arbitrary or restricted switching. (arXiv:2203.09862v1 [eess.SY])
61. Class-wise Classifier Design Capable of Continual Learning using Adaptive Resonance Theory-based Topological Clustering. (arXiv:2203.09879v1 [cs.LG])
62. Identification of Hypokinetic Dysarthria Using Acoustic Analysis of Poem Recitation. (arXiv:2203.09880v1 [cs.SD])
63. Hypergraph Modeling via Spectral Embedding Connection: Hypergraph Cut, Weighted Kernel $k$-means, and Heat Kernel. (arXiv:2203.09888v1 [cs.LG])
64. A Lightweight Instrument-Agnostic Model for Polyphonic Note Transcription and Multipitch Estimation. (arXiv:2203.09893v1 [cs.SD])
65. Learning to Reduce False Positives in Analytic Bug Detectors. (arXiv:2203.09907v1 [cs.SE])
66. Why we need biased AI -- How including cognitive and ethical machine biases can enhance AI systems. (arXiv:2203.09911v1 [cs.LG])
67. Convolutional Simultaneous Sparse Approximation with Applications to RGB-NIR Image Fusion. (arXiv:2203.09913v1 [cs.CV])
68. Comparing SONN Types for Efficient Robot Motion Planning in the Configuration Space. (arXiv:2203.09914v1 [cs.RO])
69. Revealing Reliable Signatures by Learning Top-Rank Pairs. (arXiv:2203.09927v1 [cs.CV])
70. On the sensitivity of pose estimation neural networks: rotation parameterizations, Lipschitz constants, and provable bounds. (arXiv:2203.09937v1 [cs.CV])
71. A Comparison of Static, Dynamic, and Hybrid Analysis for Malware Detection. (arXiv:2203.09938v1 [cs.CR])
72. Defending Variational Autoencoders from Adversarial Attacks with MCMC. (arXiv:2203.09940v1 [cs.LG])
73. Training a Tokenizer for Free with Private Federated Learning. (arXiv:2203.09943v1 [cs.CR])
74. Neural Enhanced Belief Propagation for Data Assocation in Multiobject Tracking. (arXiv:2203.09948v1 [cs.CV])
75. Learning to Optimize Resource Assignment for Task Offloading in Mobile Edge Computing. (arXiv:2203.09954v1 [eess.SP])
76. SS-SAM : Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks. (arXiv:2203.09962v1 [cs.LG])
77. Towards Lithuanian grammatical error correction. (arXiv:2203.09963v1 [cs.CL])
78. BIOS: An Algorithmically Generated Biomedical Knowledge Graph. (arXiv:2203.09975v1 [cs.CL])
79. WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series Tasks. (arXiv:2203.09978v1 [cs.LG])
80. Image Storage on Synthetic DNA Using Autoencoders. (arXiv:2203.09981v1 [cs.LG])
81. Diffusion and Volume Maximization-Based Clustering of Highly Mixed Hyperspectral Images. (arXiv:2203.09992v1 [cs.CV])
82. Graph-Text Multi-Modal Pre-training for Medical Representation Learning. (arXiv:2203.09994v1 [cs.CL])
83. FORCE: A Framework of Rule-Based Conversational Recommender System. (arXiv:2203.10001v1 [cs.IR])
84. Application of Top-hat Transformation for Enhanced Blood Vessel Extraction. (arXiv:2203.10005v1 [cs.CV])
85. Ultra-low Latency Spiking Neural Networks with Spatio-Temporal Compression and Synaptic Convolutional Block. (arXiv:2203.10006v1 [cs.NE])
86. Analyzing EEG Data with Machine and Deep Learning: A Benchmark. (arXiv:2203.10009v1 [cs.LG])
87. Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges. (arXiv:2203.10012v1 [cs.CL])
88. Parametric Scaling of Preprocessing assisted U-net Architecture for Improvised Retinal Vessel Segmentation. (arXiv:2203.10014v1 [eess.IV])
89. Skill-based Multi-objective Reinforcement Learning of Industrial Robot Tasks with Planning and Knowledge Integration. (arXiv:2203.10033v1 [cs.RO])
90. On the Generalization Mystery in Deep Learning. (arXiv:2203.10036v1 [cs.LG])
91. Bayesian Low-rank Matrix Completion with Dual-graph Embedding: Prior Analysis and Tuning-free Inference. (arXiv:2203.10044v1 [cs.LG])
92. Risk-Sensitive Bayesian Games for Multi-Agent Reinforcement Learning under Policy Uncertainty. (arXiv:2203.10045v1 [cs.LG])
93. SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning. (arXiv:2203.10050v1 [cs.LG])
94. Lunar Rover Localization Using Craters as Landmarks. (arXiv:2203.10073v1 [cs.RO])
95. I Know Therefore I Score: Label-Free Crafting of Scoring Functions using Constraints Based on Domain Expertise. (arXiv:2203.10085v1 [cs.LG])
96. But that's not why: Inference adjustment by interactive prototype deselection. (arXiv:2203.10087v1 [cs.LG])
97. A Generalized Minimax Q-learning Algorithm for Two-Player Zero-Sum Stochastic Games. (arXiv:1906.06659v7 [cs.LG] UPDATED)
98. Dualize, Split, Randomize: Fast Nonsmooth Optimization Algorithms. (arXiv:2004.02635v3 [math.OC] UPDATED)
99. Dimensions of Diversity in Human Perceptions of Algorithmic Fairness. (arXiv:2005.00808v2 [cs.CY] UPDATED)
100. Artificial Fingerprinting for Generative Models: Rooting Deepfake Attribution in Training Data. (arXiv:2007.08457v7 [cs.CR] UPDATED)
101. Provably Robust Adversarial Examples. (arXiv:2007.12133v3 [cs.LG] UPDATED)
102. Accuracy and Fairness Trade-offs in Machine Learning: A Stochastic Multi-Objective Approach. (arXiv:2008.01132v3 [cs.LG] UPDATED)
103. Hierarchical Message-Passing Graph Neural Networks. (arXiv:2009.03717v2 [cs.LG] UPDATED)
104. Learning to Personalize Treatments When Agents Are Strategic. (arXiv:2011.06528v4 [econ.EM] UPDATED)
105. Globetrotter: Connecting Languages by Connecting Images. (arXiv:2012.04631v2 [cs.CL] UPDATED)
106. Responsible Disclosure of Generative Models Using Scalable Fingerprinting. (arXiv:2012.08726v5 [cs.CR] UPDATED)
107. Domain Adversarial Neural Networks for Domain Generalization: When It Works and How to Improve. (arXiv:2102.03924v2 [cs.LG] UPDATED)
108. UCB Momentum Q-learning: Correcting the bias without forgetting. (arXiv:2103.01312v2 [stat.ML] UPDATED)
109. ImageNet as a Representative Basis for Deriving Generally Effective CNN Architectures. (arXiv:2103.09108v3 [cs.CV] UPDATED)
110. Collapsible Linear Blocks for Super-Efficient Super Resolution. (arXiv:2103.09404v4 [eess.IV] UPDATED)
111. Sample-based and Feature-based Federated Learning for Unconstrained and Constrained Nonconvex Optimization via Mini-batch SSCA. (arXiv:2104.06011v2 [cs.LG] UPDATED)
112. Comprehensive Review On Twin Support Vector Machines. (arXiv:2105.00336v3 [cs.LG] UPDATED)
113. Generative Adversarial Registration for Improved Conditional Deformable Templates. (arXiv:2105.04349v2 [cs.CV] UPDATED)
114. Priors in Bayesian Deep Learning: A Review. (arXiv:2105.06868v3 [stat.ML] UPDATED)
115. Adaptive Filters in Graph Convolutional Neural Networks. (arXiv:2105.10377v3 [cs.LG] UPDATED)
116. Retweet communities reveal the main sources of hate speech. (arXiv:2105.14898v2 [cs.SI] UPDATED)
117. Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v4 [cs.LG] UPDATED)
118. Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions. (arXiv:2106.01098v3 [cs.LG] UPDATED)
119. Probabilistic task modelling for meta-learning. (arXiv:2106.04802v2 [cs.LG] UPDATED)
120. Fair Normalizing Flows. (arXiv:2106.05937v2 [cs.LG] UPDATED)
121. Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v2 [cs.CL] UPDATED)
122. The Bayesian Learning Rule. (arXiv:2107.04562v2 [stat.ML] UPDATED)
123. Zeroth and First Order Stochastic Frank-Wolfe Algorithms for Constrained Optimization. (arXiv:2107.06534v2 [math.OC] UPDATED)
124. Unifying Heterogeneous Electronic Health Records Systems via Text-Based Code Embedding. (arXiv:2108.03625v3 [cs.LG] UPDATED)
125. Cervical Optical Coherence Tomography Image Classification Based on Contrastive Self-Supervised Texture Learning. (arXiv:2108.05081v3 [eess.IV] UPDATED)
126. Designing Rotationally Invariant Neural Networks from PDEs and Variational Methods. (arXiv:2108.13993v2 [cs.LG] UPDATED)
127. Gradual (In)Compatibility of Fairness Criteria. (arXiv:2109.04399v2 [cs.LG] UPDATED)
128. Non-Asymptotic Analysis of Stochastic Approximation Algorithms for Streaming Data. (arXiv:2109.07117v4 [cs.LG] UPDATED)
129. Generalized Kernel Thinning. (arXiv:2110.01593v4 [stat.ML] UPDATED)
130. Foolish Crowds Support Benign Overfitting. (arXiv:2110.02914v5 [stat.ML] UPDATED)
131. Data-driven Tissue Mechanics with Polyconvex Neural Ordinary Differential Equations. (arXiv:2110.03774v2 [cs.CE] UPDATED)
132. PAMA-TTS: Progression-Aware Monotonic Attention for Stable Seq2Seq TTS With Accurate Phoneme Duration Control. (arXiv:2110.04486v2 [cs.SD] UPDATED)
133. Planning from Pixels in Environments with Combinatorially Hard Search Spaces. (arXiv:2110.06149v2 [cs.LG] UPDATED)
134. The Rich Get Richer: Disparate Impact of Semi-Supervised Learning. (arXiv:2110.06282v2 [cs.LG] UPDATED)
135. Graph-Fraudster: Adversarial Attacks on Graph Neural Network Based Vertical Federated Learning. (arXiv:2110.06468v2 [cs.LG] UPDATED)
136. Map Induction: Compositional spatial submap learning for efficient exploration in novel environments. (arXiv:2110.12301v2 [cs.LG] UPDATED)
137. Robbing the Fed: Directly Obtaining Private Data in Federated Learning with Modified Models. (arXiv:2110.13057v2 [cs.LG] UPDATED)
138. Counterfactual Shapley Additive Explanations. (arXiv:2110.14270v3 [cs.LG] UPDATED)
139. An Empirical Study of Training End-to-End Vision-and-Language Transformers. (arXiv:2111.02387v3 [cs.CV] UPDATED)
140. TimeMatch: Unsupervised Cross-Region Adaptation by Temporal Shift Estimation. (arXiv:2111.02682v2 [cs.CV] UPDATED)
141. Dynamic Regret Minimization for Control of Non-stationary Linear Dynamical Systems. (arXiv:2111.03772v2 [cs.LG] UPDATED)
142. On Predicting Generalization using GANs. (arXiv:2111.14212v2 [cs.LG] UPDATED)
143. Beyond Periodicity: Towards a Unifying Framework for Activations in Coordinate-MLPs. (arXiv:2111.15135v2 [cs.LG] UPDATED)
144. Learning Curves for Continual Learning in Neural Networks: Self-Knowledge Transfer and Forgetting. (arXiv:2112.01653v2 [stat.ML] UPDATED)
145. Training Structured Neural Networks Through Manifold Identification and Variance Reduction. (arXiv:2112.02612v3 [cs.LG] UPDATED)
146. Universalizing Weak Supervision. (arXiv:2112.03865v2 [cs.LG] UPDATED)
147. Implications of Topological Imbalance for Representation Learning on Biomedical Knowledge Graphs. (arXiv:2112.06567v2 [cs.LG] UPDATED)
148. Unsupervised machine learning approaches to the $q$-state Potts model. (arXiv:2112.06735v2 [cond-mat.stat-mech] UPDATED)
149. BoGraph: Structured Bayesian Optimization From Logs for Expensive Systems with Many Parameters. (arXiv:2112.08774v2 [cs.LG] UPDATED)
150. MIDI-DDSP: Detailed Control of Musical Performance via Hierarchical Modeling. (arXiv:2112.09312v2 [cs.SD] UPDATED)
151. SAMCNet for Spatial-configuration-based Classification: A Summary of Results. (arXiv:2112.12219v2 [cs.CV] UPDATED)
152. Unicorn: Reasoning about Configurable System Performance through the lens of Causality. (arXiv:2201.08413v2 [cs.LG] UPDATED)
153. A Priori Denoising Strategies for Sparse Identification of Nonlinear Dynamical Systems: A Comparative Study. (arXiv:2201.12683v2 [stat.ML] UPDATED)
154. Correcting diacritics and typos with a ByT5 transformer model. (arXiv:2201.13242v2 [cs.CL] UPDATED)
155. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v2 [eess.IV] UPDATED)
156. A multiscale spatiotemporal approach for smallholder irrigation detection. (arXiv:2202.04239v2 [cs.CV] UPDATED)
157. Bias and unfairness in machine learning models: a systematic literature review. (arXiv:2202.08176v2 [cs.LG] UPDATED)
158. tinyMAN: Lightweight Energy Manager using Reinforcement Learning for Energy Harvesting Wearable IoT Devices. (arXiv:2202.09297v2 [eess.SP] UPDATED)
159. Deep Dirichlet uncertainty for unsupervised out-of-distribution detection of eye fundus photographs in glaucoma screening. (arXiv:2202.12634v2 [cs.CV] UPDATED)
160. PLSSVM: A (multi-)GPGPU-accelerated Least Squares Support Vector Machine. (arXiv:2202.12674v2 [cs.LG] UPDATED)
161. Machine Learning for CUDA+MPI Design Rules. (arXiv:2203.02530v2 [cs.PF] UPDATED)
162. Estimating the average causal effect of intervention in continuous variables using machine learning. (arXiv:2203.03916v4 [stat.ML] UPDATED)
163. Learning to control from expert demonstrations. (arXiv:2203.05012v2 [eess.SY] UPDATED)
164. BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis. (arXiv:2203.05297v3 [cs.CV] UPDATED)
165. Lead-agnostic Self-supervised Learning for Local and Global Representations of Electrocardiogram. (arXiv:2203.06889v2 [cs.LG] UPDATED)
166. Innovations in trigger and data acquisition systems for next-generation physics facilities. (arXiv:2203.07620v2 [hep-ex] UPDATED)
167. Domain Adaptive Hand Keypoint and Pixel Localization in the Wild. (arXiv:2203.08344v2 [cs.CV] UPDATED)
168. Neural network processing of holographic images. (arXiv:2203.08898v2 [eess.IV] UPDATED)
169. Backpropagation through Time and Space: Learning Numerical Methods with Multi-Agent Reinforcement Learning. (arXiv:2203.08937v2 [cs.LG] UPDATED)
170. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v2 [cs.CL] UPDATED)
171. Nearest Neighbor Classifier with Margin Penalty for Active Learning. (arXiv:2203.09174v2 [cs.IR] UPDATED)
172. Transframer: Arbitrary Frame Prediction with Generative Models. (arXiv:2203.09494v2 [cs.CV] UPDATED)
173. Mapping conditional distributions for domain adaptation under generalized target shift. (arXiv:2110.15057v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**61** new papers in cs.AI:-) 
1. Privacy-Preserving Speech Representation Learning using Vector Quantization. (arXiv:2203.09518v1 [eess.AS])
2. SemTUI: a Framework for the Interactive Semantic Enrichment of Tabular Data. (arXiv:2203.09521v1 [cs.DB])
3. Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation. (arXiv:2203.09553v1 [cs.AI])
4. On the expressive power of message-passing neural networks as global feature map transformers. (arXiv:2203.09555v1 [cs.AI])
5. Strategic Maneuver and Disruption with Reinforcement Learning Approaches for Multi-Agent Coordination. (arXiv:2203.09565v1 [cs.MA])
6. GAC: A Deep Reinforcement Learning Model Toward User Incentivization in Unknown Social Networks. (arXiv:2203.09578v1 [cs.SI])
7. Surface Defect Detection and Evaluation for Marine Vessels using Multi-Stage Deep Learning. (arXiv:2203.09580v1 [cs.CV])
8. Video-based Formative and Summative Assessment of Surgical Tasks using Deep Learning. (arXiv:2203.09589v1 [cs.CV])
9. Prioritized Variable-length Test Cases Generation for Finite State Machines. (arXiv:2203.09596v1 [cs.SE])
10. Overview of Test Coverage Criteria for Test Case Generation from Finite State Machines Modelled as Directed Graphs. (arXiv:2203.09604v1 [cs.SE])
11. Developing a Successful Bomberman Agent. (arXiv:2203.09608v1 [cs.AI])
12. STICC: A multivariate spatial clustering method for repeated geographic pattern discovery with consideration of spatial contiguity. (arXiv:2203.09611v1 [cs.LG])
13. Monotonic Differentiable Sorting Networks. (arXiv:2203.09630v1 [cs.LG])
14. A Learning Framework for Bandwidth-Efficient Distributed Inference in Wireless IoT. (arXiv:2203.09631v1 [eess.SP])
15. Inventing Relational State and Action Abstractions for Effective and Efficient Bilevel Planning. (arXiv:2203.09634v1 [cs.AI])
16. Modeling Intensification for Sign Language Generation: A Computational Approach. (arXiv:2203.09679v1 [cs.CL])
17. Towards Training Billion Parameter Graph Neural Networks for Atomic Simulations. (arXiv:2203.09697v1 [cs.LG])
18. M2TS: Multi-Scale Multi-Modal Approach Based on Transformer for Source Code Summarization. (arXiv:2203.09707v1 [cs.SE])
19. AutoAdversary: A Pixel Pruning Method for Sparse Adversarial Attack. (arXiv:2203.09756v1 [cs.CV])
20. Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation. (arXiv:2203.09811v1 [cs.CV])
21. Are You Robert or RoBERTa? Deceiving Online Authorship Attribution Models Using Neural Text Generators. (arXiv:2203.09813v1 [cs.CL])
22. Neural Predictor for Black-Box Adversarial Attacks on Speech Recognition. (arXiv:2203.09849v1 [cs.SD])
23. Battle royale optimizer with a new movement strategy. (arXiv:2203.09889v1 [cs.NE])
24. Why we need biased AI -- How including cognitive and ethical machine biases can enhance AI systems. (arXiv:2203.09911v1 [cs.LG])
25. CITS: Coherent Ising Tree Search Algorithm Towards Solving Combinatorial Optimization Problems. (arXiv:2203.09926v1 [cs.AI])
26. Deepfake Style Transfer Mixture: a First Forensic Ballistics Study on Synthetic Images. (arXiv:2203.09928v1 [cs.CV])
27. Conquering Ghosts: Relation Learning for Information Reliability Representation and End-to-End Robust Navigation. (arXiv:2203.09952v1 [cs.AI])
28. SS-SAM : Stochastic Scheduled Sharpness-Aware Minimization for Efficiently Training Deep Neural Networks. (arXiv:2203.09962v1 [cs.LG])
29. Image Storage on Synthetic DNA Using Autoencoders. (arXiv:2203.09981v1 [cs.LG])
30. FORCE: A Framework of Rule-Based Conversational Recommender System. (arXiv:2203.10001v1 [cs.IR])
31. Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges. (arXiv:2203.10012v1 [cs.CL])
32. Multi-input segmentation of damaged brain in acute ischemic stroke patients using slow fusion with skip connection. (arXiv:2203.10039v1 [cs.CV])
33. SURF: Semi-supervised Reward Learning with Data Augmentation for Feedback-efficient Preference-based Reinforcement Learning. (arXiv:2203.10050v1 [cs.LG])
34. Lunar Rover Localization Using Craters as Landmarks. (arXiv:2203.10073v1 [cs.RO])
35. I Know Therefore I Score: Label-Free Crafting of Scoring Functions using Constraints Based on Domain Expertise. (arXiv:2203.10085v1 [cs.LG])
36. Distributed Attack-Robust Submodular Maximization for Multi-Robot Planning. (arXiv:1910.01208v5 [cs.RO] UPDATED)
37. Multi-Resolution POMDP Planning for Multi-Object Search in 3D. (arXiv:2005.02878v5 [cs.RO] UPDATED)
38. Multi-grained Semantics-aware Graph Neural Networks. (arXiv:2010.00238v3 [cs.AI] UPDATED)
39. Uniform Object Rearrangement: From Complete Monotone Primitives to Efficient Non-Monotone Informed Search. (arXiv:2101.12241v2 [cs.RO] UPDATED)
40. Articulated Object Interaction in Unknown Scenes with Whole-Body Mobile Manipulation. (arXiv:2103.10534v2 [cs.RO] UPDATED)
41. Comprehensive Review On Twin Support Vector Machines. (arXiv:2105.00336v3 [cs.LG] UPDATED)
42. Adaptive Filters in Graph Convolutional Neural Networks. (arXiv:2105.10377v3 [cs.LG] UPDATED)
43. Fair Normalizing Flows. (arXiv:2106.05937v2 [cs.LG] UPDATED)
44. Assessing Multilingual Fairness in Pre-trained Multimodal Representations. (arXiv:2106.06683v2 [cs.CL] UPDATED)
45. HDMapNet: An Online HD Map Construction and Evaluation Framework. (arXiv:2107.06307v4 [cs.CV] UPDATED)
46. METEOR:A Dense, Heterogeneous, and Unstructured Traffic Dataset With Rare Behaviors. (arXiv:2109.07648v3 [cs.CV] UPDATED)
47. Efficient and High-quality Prehensile Rearrangement in Cluttered and Confined Spaces. (arXiv:2110.02814v2 [cs.RO] UPDATED)
48. PAMA-TTS: Progression-Aware Monotonic Attention for Stable Seq2Seq TTS With Accurate Phoneme Duration Control. (arXiv:2110.04486v2 [cs.SD] UPDATED)
49. Planning from Pixels in Environments with Combinatorially Hard Search Spaces. (arXiv:2110.06149v2 [cs.LG] UPDATED)
50. Map Induction: Compositional spatial submap learning for efficient exploration in novel environments. (arXiv:2110.12301v2 [cs.LG] UPDATED)
51. Counterfactual Shapley Additive Explanations. (arXiv:2110.14270v3 [cs.LG] UPDATED)
52. A Conditional Point Diffusion-Refinement Paradigm for 3D Point Cloud Completion. (arXiv:2112.03530v3 [cs.CV] UPDATED)
53. Universalizing Weak Supervision. (arXiv:2112.03865v2 [cs.LG] UPDATED)
54. Implications of Topological Imbalance for Representation Learning on Biomedical Knowledge Graphs. (arXiv:2112.06567v2 [cs.LG] UPDATED)
55. Unicorn: Reasoning about Configurable System Performance through the lens of Causality. (arXiv:2201.08413v2 [cs.LG] UPDATED)
56. Bias and unfairness in machine learning models: a systematic literature review. (arXiv:2202.08176v2 [cs.LG] UPDATED)
57. Inference of Affordances and Active Motor Control in Simulated Agents. (arXiv:2202.11532v2 [cs.AI] UPDATED)
58. Overcoming Catastrophic Forgetting beyond Continual Learning: Balanced Training for Neural Machine Translation. (arXiv:2203.03910v2 [cs.CL] UPDATED)
59. Towards Afrocentric NLP for African Languages: Where We Are and Where We Can Go. (arXiv:2203.08351v2 [cs.CL] UPDATED)
60. How Many Data Samples is an Additional Instruction Worth?. (arXiv:2203.09161v2 [cs.CL] UPDATED)
61. Mapping conditional distributions for domain adaptation under generalized target shift. (arXiv:2110.15057v2 [cs.LG] CROSS LISTED)

