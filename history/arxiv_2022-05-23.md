# Your interest papers
---
## cs.CV
---
### Real Time Multi-Object Detection for Helmet Safety. (arXiv:2205.09878v1 [cs.CV])
- Authors : Mrinal Mathur, Archana Benkkallpalli, Venkata Krishna, Chaithanya Nuthalapati
- Link : [http://arxiv.org/abs/2205.09878](http://arxiv.org/abs/2205.09878)
> ABSTRACT  :  The National Football League and Amazon Web Services teamed up to develop the best sports injury surveillance and mitigation program via the Kaggle competition. Through which the NFL wants to assign specific players to each helmet, which would help accurately identify each player's "**exposure**s" throughout a football play. We are trying to implement a computer vision based ML algorithms capable of assigning detected helmet impacts to correct players via tracking information. Our paper will explain the approach to automatically track player helmets and their collisions. This will also allow them to review previous plays and explore the trends in **exposure** over time.  
### Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality. (arXiv:2205.10063v1 [cs.CV])
- Authors : Xiang Li, Wenhai Wang, Lingfeng Yang, Jian Yang
- Link : [http://arxiv.org/abs/2205.10063](http://arxiv.org/abs/2205.10063)
> ABSTRACT  :  Masked AutoEncoder (MAE) has recently led the trends of visual self-supervision area by an elegant asymmetric encoder-decoder design, which significantly optimizes both the pre-training efficiency and fine-tuning accuracy. Notably, the success of the asymmetric structure relies on the "global" property of Vanilla Vision Transformer (ViT), whose self-attention mechanism reasons over arbitrary subset of discrete image patches. However, it is still unclear how the advanced Pyramid-based ViTs (e.g., PVT, **Swin**) can be adopted in MAE pre-training as they commonly introduce operators within "local" windows, making it difficult to handle the random sequence of partial vision tokens. In this paper, we propose Uniform Masking (UM), successfully enabling MAE pre-training for Pyramid-based ViTs with locality (termed "UM-MAE" for short). Specifically, UM includes a Uniform Sampling (US) that strictly samples $1$ random patch from each $2 \times 2$ grid, and a Secondary Masking (SM) which randomly masks a portion of (usually $25\%$) the already sampled regions as learnable tokens. US preserves equivalent elements across multiple non-overlapped local windows, resulting in the smooth support for popular Pyramid-based ViTs; whilst SM is designed for better transferable visual representations since US reduces the difficulty of pixel recovery pre-task that hinders the semantic learning. We demonstrate that UM-MAE significantly improves the pre-training efficiency (e.g., it speeds up and reduces the GPU memory by $\sim 2\times$) of Pyramid-based ViTs, but maintains the competitive fine-tuning performance across downstream tasks. For example using HTC++ detector, the pre-trained **Swin**-Large backbone self-supervised under UM-MAE only in ImageNet-1K can even outperform the one supervised in ImageNet-22K. The codes are available at https://github.com/implus/UM-MAE.  
### MSTRIQ: No Reference Image Quality Assessment Based on **Swin** Transformer with Multi-Stage Fusion. (arXiv:2205.10101v1 [cs.CV])
- Authors : Jing Wang, Haotian Fa, Xiaoxia Hou, Yitian Xu, Tao Li, Xuechao Lu, Lean Fu
- Link : [http://arxiv.org/abs/2205.10101](http://arxiv.org/abs/2205.10101)
> ABSTRACT  :  Measuring the perceptual quality of images automatically is an essential task in the area of computer vision, as degradations on image quality can exist in many processes from image acquisition, transmission to enhancing. Many Image Quality Assessment(IQA) algorithms have been designed to tackle this problem. However, it still remains un settled due to the various types of image distortions and the lack of large-scale human-rated datasets. In this paper, we propose a novel algorithm based on the **Swin** Transformer [31] with fused features from multiple stages, which aggregates information from both local and global features to better predict the quality. To address the issues of small-scale datasets, relative rankings of images have been taken into account together with regression loss to simultaneously optimize the model. Furthermore, effective data augmentation strategies are also used to improve the performance. In comparisons with previous works, experiments are carried out on two standard IQA datasets and a challenge dataset. The results demonstrate the effectiveness of our work. The proposed method outperforms other methods on standard datasets and ranks 2nd in the no-reference track of NTIRE 2022 Perceptual Image Quality Assessment Challenge [53]. It verifies that our method is promising in solving diverse IQA problems and thus can be used to real-word applications.  
### Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video **Restoration**. (arXiv:2205.10195v1 [cs.CV])
- Authors : Jing Lin, Xiaowan Hu, Yuanhao Cai, Haoqian Wang, Youliang Yan, Xueyi Zou, Yulun Zhang, Luc Van
- Link : [http://arxiv.org/abs/2205.10195](http://arxiv.org/abs/2205.10195)
> ABSTRACT  :  How to properly model the inter-frame relation within the video sequence is an important but unsolved challenge for video **restoration** (VR). In this work, we propose an unsupervised flow-aligned sequence-to-sequence model (S2SVR) to address this problem. On the one hand, the sequence-to-sequence model, which has proven capable of sequence modeling in the field of natural language processing, is explored for the first time in VR. Optimized serialization modeling shows potential in capturing long-range dependencies among frames. On the other hand, we equip the sequence-to-sequence model with an unsupervised optical flow estimator to maximize its potential. The flow estimator is trained with our proposed unsupervised distillation loss, which can alleviate the data discrepancy and inaccurate degraded optical flow issues of previous flow-based methods. With reliable optical flow, we can establish accurate correspondence among multiple frames, narrowing the domain difference between 1D language and 2D misaligned frames and improving the potential of the sequence-to-sequence model. S2SVR shows superior performance in multiple VR tasks, including video deblurring, video super-resolution, and compressed video quality **enhancement**. Code and models are publicly available at https://github.com/linjing7/VR-Baseline  
### A Novel Underwater Image **Enhancement** and Improved Underwater Biological Detection Pipeline. (arXiv:2205.10199v1 [cs.CV])
- Authors : Zheng Liu, Yaoming Zhuang, Pengrun Jia, Chengdong Wu, Hongli Xu, ang Zhanlin
- Link : [http://arxiv.org/abs/2205.10199](http://arxiv.org/abs/2205.10199)
> ABSTRACT  :  For aquaculture resource evaluation and ecological environment monitoring, automatic detection and identification of marine organisms is critical. However, due to the low quality of underwater images and the characteristics of underwater biological, a lack of abundant features may impede traditional hand-designed feature extraction approaches or CNN-based object detection algorithms, particularly in complex underwater environment. Therefore, the goal of this paper is to perform object detection in the underwater environment. This paper proposed a novel method for capturing feature information, which adds the convolutional block attention module (CBAM) to the YOLOv5 backbone. The interference of underwater creature characteristics on object characteristics is decreased, and the output of the backbone network to object information is enhanced. In addition, the self-adaptive global histogram stretching algorithm (SAGHS) is designed to eliminate the degradation problems such as low contrast and color loss caused by underwater environmental information to better restore image quality. Extensive experiments and comprehensive evaluation on the URPC2021 benchmark dataset demonstrate the effectiveness and adaptivity of our methods. Beyond that, this paper conducts an exhaustive analysis of the role of training data on performance.  
### Fast Autofocusing using Tiny Transformer Networks for Digital Holographic Microscopy. (arXiv:2203.07772v4 [eess.IV] UPDATED)
- Authors : phane Cuenat, Louis Andr, Patrick Sandoz, Maxime Jacquot
- Link : [http://arxiv.org/abs/2203.07772](http://arxiv.org/abs/2203.07772)
> ABSTRACT  :  The numerical wavefront backpropagation principle of digital holography confers unique extended focus capabilities, without mechanical displacements along z-axis. However, the determination of the correct focusing distance is a non-trivial and time consuming issue. A deep learning (DL) solution is proposed to cast the autofocusing as a regression problem and tested over both experimental and simulated holograms. Single wavelength digital holograms were recorded by a Digital Holographic Microscope (DHM) with a 10$\mathrm{x}$ microscope objective from a patterned target moving in 3D over an axial range of 92 $\mu$m. Tiny DL models are proposed and compared such as a tiny Vision Transformer (TViT), tiny VGG16 (TVGG) and a tiny **Swin**-Transfomer (T**Swin**T). The proposed tiny networks are compared with their original versions (ViT/B16, VGG16 and **Swin**-Transformer Tiny) and the main neural networks used in digital holography such as LeNet and AlexNet. The experiments show that the predicted focusing distance $Z_R^{\mathrm{Pred}}$ is accurately inferred with an accuracy of 1.2 $\mu$m in average in comparison with the DHM depth of field of 15 $\mu$m. Numerical simulations show that all tiny models give the $Z_R^{\mathrm{Pred}}$ with an error below 0.3 $\mu$m. Such a prospect would significantly improve the current capabilities of computer vision position sensing in applications such as 3D microscopy for life sciences or micro-robotics. Moreover, all models reach an inference time on CPU, inferior to 25 ms per inference. In terms of occlusions, TViT based on its Transformer architecture is the most robust.  
### Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning. (arXiv:2205.09542v2 [cs.CV] UPDATED)
- Authors : Yuxin Zhang, Fan Tang, Weiming Dong, Haibin Huang, Chongyang Ma, Yee Lee, Changsheng Xu
- Link : [http://arxiv.org/abs/2205.09542](http://arxiv.org/abs/2205.09542)
> ABSTRACT  :  In this work, we tackle the challenging problem of arbitrary image style transfer using a novel style feature representation learning method. A suitable style representation, as a key component in image stylization tasks, is essential to achieve satisfactory results. Existing deep neural network based approaches achieve reasonable results with the guidance from second-order statistics such as Gram matrix of content features. However, they do not leverage sufficient style information, which results in artifacts such as local distortions and style inconsistency. To address these issues, we propose to learn style representation directly from image features instead of their second-order statistics, by analyzing the similarities and differences between multiple styles and considering the style distribution. Specifically, we present Contrastive Arbitrary Style Transfer (CAST), which is a new style representation learning and style transfer method via contrastive learning. Our framework consists of three key components, i.e., a multi-layer style projector for style code encoding, a domain **enhancement** module for effective learning of style distribution, and a generative network for image style transfer. We conduct qualitative and quantitative evaluations comprehensively to demonstrate that our approach achieves significantly better results compared to those obtained via state-of-the-art methods. Code and models are available at https://github.com/zyxElsa/CAST_pytorch  
## eess.IV
---
### Fast Autofocusing using Tiny Transformer Networks for Digital Holographic Microscopy. (arXiv:2203.07772v4 [eess.IV] UPDATED)
- Authors : phane Cuenat, Louis Andr, Patrick Sandoz, Maxime Jacquot
- Link : [http://arxiv.org/abs/2203.07772](http://arxiv.org/abs/2203.07772)
> ABSTRACT  :  The numerical wavefront backpropagation principle of digital holography confers unique extended focus capabilities, without mechanical displacements along z-axis. However, the determination of the correct focusing distance is a non-trivial and time consuming issue. A deep learning (DL) solution is proposed to cast the autofocusing as a regression problem and tested over both experimental and simulated holograms. Single wavelength digital holograms were recorded by a Digital Holographic Microscope (DHM) with a 10$\mathrm{x}$ microscope objective from a patterned target moving in 3D over an axial range of 92 $\mu$m. Tiny DL models are proposed and compared such as a tiny Vision Transformer (TViT), tiny VGG16 (TVGG) and a tiny **Swin**-Transfomer (T**Swin**T). The proposed tiny networks are compared with their original versions (ViT/B16, VGG16 and **Swin**-Transformer Tiny) and the main neural networks used in digital holography such as LeNet and AlexNet. The experiments show that the predicted focusing distance $Z_R^{\mathrm{Pred}}$ is accurately inferred with an accuracy of 1.2 $\mu$m in average in comparison with the DHM depth of field of 15 $\mu$m. Numerical simulations show that all tiny models give the $Z_R^{\mathrm{Pred}}$ with an error below 0.3 $\mu$m. Such a prospect would significantly improve the current capabilities of computer vision position sensing in applications such as 3D microscopy for life sciences or micro-robotics. Moreover, all models reach an inference time on CPU, inferior to 25 ms per inference. In terms of occlusions, TViT based on its Transformer architecture is the most robust.  
## cs.LG
---
### Real Time Multi-Object Detection for Helmet Safety. (arXiv:2205.09878v1 [cs.CV])
- Authors : Mrinal Mathur, Archana Benkkallpalli, Venkata Krishna, Chaithanya Nuthalapati
- Link : [http://arxiv.org/abs/2205.09878](http://arxiv.org/abs/2205.09878)
> ABSTRACT  :  The National Football League and Amazon Web Services teamed up to develop the best sports injury surveillance and mitigation program via the Kaggle competition. Through which the NFL wants to assign specific players to each helmet, which would help accurately identify each player's "**exposure**s" throughout a football play. We are trying to implement a computer vision based ML algorithms capable of assigning detected helmet impacts to correct players via tracking information. Our paper will explain the approach to automatically track player helmets and their collisions. This will also allow them to review previous plays and explore the trends in **exposure** over time.  
### Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks. (arXiv:2205.10282v1 [cs.CL])
- Authors : Bowen Jin, Yu Zhang, Qi Zhu, Jiawei Han
- Link : [http://arxiv.org/abs/2205.10282](http://arxiv.org/abs/2205.10282)
> ABSTRACT  :  We study node representation learning on heterogeneous text-rich networks, where nodes and edges are multi-typed and some types of nodes are associated with text information. Although recent studies on graph neural networks (GNNs) and pretrained language models (PLMs) have demonstrated their power in encoding network and text signals, respectively, less focus has been given to delicately coupling these two types of models on heterogeneous text-rich networks. Specifically, existing GNNs rarely model text in each node in a contextualized way; existing PLMs can hardly be applied to characterize graph structures due to their sequence architecture. In this paper, we propose Heterformer, a Heterogeneous GNN-nested transformer that blends GNNs and PLMs into a unified model. Different from previous "cascaded architectures" that directly add GNN layers upon a PLM, our Heterformer alternately stacks two modules - a graph-attention-based neighbor aggregation module and a transformer-based text and neighbor joint encoding module - to facilitate thorough mutual **enhancement** between network and text signals. Meanwhile, Heterformer is capable of characterizing network heterogeneity and nodes without text information. Comprehensive experiments on three large-scale datasets from different domains demonstrate the superiority of Heterformer over state-of-the-art baselines in link prediction, transductive/inductive node classification, node clustering, and semantics-based retrieval.  
## cs.AI
---
### A Novel Underwater Image **Enhancement** and Improved Underwater Biological Detection Pipeline. (arXiv:2205.10199v1 [cs.CV])
- Authors : Zheng Liu, Yaoming Zhuang, Pengrun Jia, Chengdong Wu, Hongli Xu, ang Zhanlin
- Link : [http://arxiv.org/abs/2205.10199](http://arxiv.org/abs/2205.10199)
> ABSTRACT  :  For aquaculture resource evaluation and ecological environment monitoring, automatic detection and identification of marine organisms is critical. However, due to the low quality of underwater images and the characteristics of underwater biological, a lack of abundant features may impede traditional hand-designed feature extraction approaches or CNN-based object detection algorithms, particularly in complex underwater environment. Therefore, the goal of this paper is to perform object detection in the underwater environment. This paper proposed a novel method for capturing feature information, which adds the convolutional block attention module (CBAM) to the YOLOv5 backbone. The interference of underwater creature characteristics on object characteristics is decreased, and the output of the backbone network to object information is enhanced. In addition, the self-adaptive global histogram stretching algorithm (SAGHS) is designed to eliminate the degradation problems such as low contrast and color loss caused by underwater environmental information to better restore image quality. Extensive experiments and comprehensive evaluation on the URPC2021 benchmark dataset demonstrate the effectiveness and adaptivity of our methods. Beyond that, this paper conducts an exhaustive analysis of the role of training data on performance.  
# Paper List
---
## cs.CV
---
**87** new papers in cs.CV:-) 
1. HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v1 [cs.AI])
2. Identifying outliers in astronomical images with unsupervised machine learning. (arXiv:2205.09760v1 [cs.CV])
3. A Peek at Peak Emotion Recognition. (arXiv:2205.09791v1 [cs.CV])
4. Label-invariant Augmentation for Semi-Supervised Graph Classification. (arXiv:2205.09802v1 [cs.CV])
5. Unsupervised Learning of Depth, Camera Pose and Optical Flow from Monocular Video. (arXiv:2205.09821v1 [cs.CV])
6. Subcellular Protein Localisation in the Human Protein Atlas using Ensembles of Diverse Deep Architectures. (arXiv:2205.09841v1 [cs.CV])
7. Generation of Artificial CT Images using Patch-based Conditional Generative Adversarial Networks. (arXiv:2205.09842v1 [eess.IV])
8. Human Gender Prediction Based on Deep Transfer Learning from Panoramic Radiograph Images. (arXiv:2205.09850v1 [eess.IV])
9. Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v1 [cs.CV])
10. Real Time Multi-Object Detection for Helmet Safety. (arXiv:2205.09878v1 [cs.CV])
11. Beyond Labels: Visual Representations for Bone Marrow Cell Morphology Recognition. (arXiv:2205.09880v1 [cs.CV])
12. Deep transfer learning for image classification: a survey. (arXiv:2205.09904v1 [cs.CV])
13. Hyperspectral Unmixing Based on Nonnegative Matrix Factorization: A Comprehensive Review. (arXiv:2205.09933v1 [cs.CV])
14. PGDP5K: A Diagram Parsing Dataset for Plane Geometry Problems. (arXiv:2205.09947v1 [cs.CV])
15. Clustering as Attention: Unified Image Segmentation with Hierarchical Clustering. (arXiv:2205.09949v1 [cs.CV])
16. Structured Attention Composition for Temporal Action Localization. (arXiv:2205.09956v1 [cs.CV])
17. Advanced Feature Learning on Point Clouds using Multi-resolution Features and Learnable Pooling. (arXiv:2205.09962v1 [cs.CV])
18. Few-Shot Font Generation by Learning Fine-Grained Local Styles. (arXiv:2205.09965v1 [cs.CV])
19. Mask-guided Vision Transformer (MG-ViT) for Few-Shot Learning. (arXiv:2205.09995v1 [cs.CV])
20. InDistill: Transferring Knowledge From Pruned Intermediate Layers. (arXiv:2205.10003v1 [cs.CV])
21. Self-Supervised Depth Estimation with Isometric-Self-Sample-Based Learning. (arXiv:2205.10006v1 [cs.CV])
22. Action parsing using context features. (arXiv:2205.10008v1 [cs.CV])
23. Constructive Interpretability with CoLabel: Corroborative Integration, Complementary Features, and Collaborative Learning. (arXiv:2205.10011v1 [cs.CV])
24. Assessing Demographic Bias Transfer from Dataset to Model: A Case Study in Facial Expression Recognition. (arXiv:2205.10049v1 [cs.CV])
25. Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality. (arXiv:2205.10063v1 [cs.CV])
26. Contrastive Learning with Cross-Modal Knowledge Mining for Multimodal Human Activity Recognition. (arXiv:2205.10071v1 [cs.CV])
27. Unintended memorisation of unique features in neural networks. (arXiv:2205.10079v1 [cs.LG])
28. Emergence of Double-slit Interference by Representing Visual Space in Artificial Neural Networks. (arXiv:2205.10081v1 [cs.CV])
29. People Tracking and Re-Identifying in Distributed Contexts: Extension of PoseTReID. (arXiv:2205.10086v1 [cs.CV])
30. Kernel Normalized Convolutional Networks. (arXiv:2205.10089v1 [cs.LG])
31. Visual Concepts Tokenization. (arXiv:2205.10093v1 [cs.CV])
32. MSTRIQ: No Reference Image Quality Assessment Based on **Swin** Transformer with Multi-Stage Fusion. (arXiv:2205.10101v1 [cs.CV])
33. Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging. (arXiv:2205.10102v1 [cs.CV])
34. Privacy Preserving Image Registration. (arXiv:2205.10120v1 [cs.CV])
35. Reliability-based Mesh-to-Grid Image Reconstruction. (arXiv:2205.10138v1 [cs.CV])
36. The developmental trajectory of object recognition robustness: children are like small adults but unlike big deep neural networks. (arXiv:2205.10144v1 [cs.CV])
37. Swapping Semantic Contents for Mixing Images. (arXiv:2205.10158v1 [cs.CV])
38. Towards the Generation of Synthetic Images of Palm Vein Patterns: A Review. (arXiv:2205.10179v1 [cs.CV])
39. E-Scooter Rider Detection and Classification in Dense Urban Environments. (arXiv:2205.10184v1 [cs.CV])
40. Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video **Restoration**. (arXiv:2205.10195v1 [cs.CV])
41. A Novel Underwater Image **Enhancement** and Improved Underwater Biological Detection Pipeline. (arXiv:2205.10199v1 [cs.CV])
42. How to Guide Adaptive Depth Sampling?. (arXiv:2205.10202v1 [cs.CV])
43. Learning to Count Anything: Reference-less Class-agnostic Counting with Weak Supervision. (arXiv:2205.10203v1 [cs.CV])
44. Test-time Batch Normalization. (arXiv:2205.10210v1 [cs.LG])
45. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v1 [cs.LG])
46. Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization in Harsh Urban Environments. (arXiv:2205.10223v1 [cs.AI])
47. A Demographic Attribute Guided Approach to Age Estimation. (arXiv:2205.10254v1 [cs.CV])
48. Analysis of Co-Laughter Gesture Relationship on RGB videos in Dyadic Conversation Contex. (arXiv:2205.10266v1 [cs.CV])
49. B-cos Networks: Alignment is All We Need for Interpretability. (arXiv:2205.10268v1 [cs.CV])
50. Compression ensembles quantify aesthetic complexity and the evolution of visual art. (arXiv:2205.10271v1 [cs.CV])
51. Salient Skin Lesion Segmentation via Dilated Scale-Wise Feature Fusion Network. (arXiv:2205.10272v1 [cs.CV])
52. Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors. (arXiv:2205.10279v1 [cs.LG])
53. User Localization using RF Sensing: A Performance comparison between LIS and mmWave Radars. (arXiv:2205.10321v1 [eess.SP])
54. UCC: Uncertainty guided Cross-head Co-training for Semi-Supervised Semantic Segmentation. (arXiv:2205.10334v1 [cs.CV])
55. UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes. (arXiv:2205.10337v1 [cs.CV])
56. Efficient visual object representation using a biologically plausible spike-latency code and winner-take-all inhibition. (arXiv:2205.10338v1 [cs.CV])
57. Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT). (arXiv:2205.10342v1 [eess.IV])
58. Diverse super-resolution with pretrained deep hiererarchical VAEs. (arXiv:2205.10347v1 [cs.CV])
59. Enriching StyleGAN with Illumination Physics. (arXiv:2205.10351v1 [cs.CV])
60. Recognizing License Plates in Real-Time. (arXiv:1906.04376v4 [cs.CV] UPDATED)
61. Layer-Wise Data-Free CNN Compression. (arXiv:2011.09058v3 [cs.CV] UPDATED)
62. Flow-based Spatio-Temporal Structured Prediction of Dynamics. (arXiv:2104.04391v2 [cs.CV] UPDATED)
63. MeshTalk: 3D Face Animation from Speech using Cross-Modality Disentanglement. (arXiv:2104.08223v2 [cs.CV] UPDATED)
64. On Algorithmic Stability in Unsupervised Representation Learning. (arXiv:2106.05238v3 [cs.LG] UPDATED)
65. Synthesis in Style: Semantic Segmentation of Historical Documents using Synthetic Data. (arXiv:2107.06777v3 [cs.CV] UPDATED)
66. Statistical Dependency Guided Contrastive Learning for Multiple Labeling in Prenatal Ultrasound. (arXiv:2108.05055v3 [cs.CV] UPDATED)
67. CPT: Colorful Prompt Tuning for Pre-trained Vision-Language Models. (arXiv:2109.11797v3 [cs.CV] UPDATED)
68. Track Boosting and Synthetic Data Aided Drone Detection. (arXiv:2111.12389v5 [cs.CV] UPDATED)
69. Personalized Federated Learning with Adaptive Batchnorm for Healthcare. (arXiv:2112.00734v3 [cs.LG] UPDATED)
70. Generalisation effects of predictive uncertainty estimation in deep learning for digital pathology. (arXiv:2112.09693v2 [cs.LG] UPDATED)
71. Flow-Guided Sparse Transformer for Video Deblurring. (arXiv:2201.01893v2 [eess.IV] UPDATED)
72. Task Specific Attention is one more thing you need for object detection. (arXiv:2202.09048v3 [cs.CV] UPDATED)
73. HMD-EgoPose: Head-Mounted Display-Based Egocentric Marker-Less Tool and Hand Pose Estimation for Augmented Surgical Guidance. (arXiv:2202.11891v2 [cs.CV] UPDATED)
74. TwistSLAM: Constrained SLAM in Dynamic Environment. (arXiv:2202.12384v2 [cs.RO] UPDATED)
75. Robust Multi-Task Learning and Online Refinement for Spacecraft Pose Estimation across Domain Gap. (arXiv:2203.04275v3 [cs.CV] UPDATED)
76. Fast Autofocusing using Tiny Transformer Networks for Digital Holographic Microscopy. (arXiv:2203.07772v4 [eess.IV] UPDATED)
77. Uncertainty-aware Contrastive Distillation for Incremental Semantic Segmentation. (arXiv:2203.14098v2 [cs.CV] UPDATED)
78. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v8 [cs.CV] UPDATED)
79. COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval. (arXiv:2204.07441v2 [cs.CV] UPDATED)
80. Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation. (arXiv:2205.01271v2 [cs.CV] UPDATED)
81. DeepPortraitDrawing: Generating Human Body Images from Freehand Sketches. (arXiv:2205.02070v2 [cs.CV] UPDATED)
82. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v4 [eess.IV] UPDATED)
83. Noise-Tolerant Learning for Audio-Visual Action Recognition. (arXiv:2205.07611v2 [cs.CV] UPDATED)
84. Continual learning on 3D point clouds with random compressed rehearsal. (arXiv:2205.08013v2 [cs.LG] UPDATED)
85. Unraveling Attention via Convex Duality: Analysis and Interpretations of Vision Transformers. (arXiv:2205.08078v2 [cs.LG] UPDATED)
86. Domain Enhanced Arbitrary Image Style Transfer via Contrastive Learning. (arXiv:2205.09542v2 [cs.CV] UPDATED)
87. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v2 [cs.LG] UPDATED)
## eess.IV
---
**17** new papers in eess.IV:-) 
1. Generation of Artificial CT Images using Patch-based Conditional Generative Adversarial Networks. (arXiv:2205.09842v1 [eess.IV])
2. Human Gender Prediction Based on Deep Transfer Learning from Panoramic Radiograph Images. (arXiv:2205.09850v1 [eess.IV])
3. Hyperspectral Unmixing Based on Nonnegative Matrix Factorization: A Comprehensive Review. (arXiv:2205.09933v1 [cs.CV])
4. Action parsing using context features. (arXiv:2205.10008v1 [cs.CV])
5. Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging. (arXiv:2205.10102v1 [cs.CV])
6. Privacy Preserving Image Registration. (arXiv:2205.10120v1 [cs.CV])
7. Reliability-based Mesh-to-Grid Image Reconstruction. (arXiv:2205.10138v1 [cs.CV])
8. Revisiting GANs by Best-Response Constraint: Perspective, Methodology, and Application. (arXiv:2205.10146v1 [cs.LG])
9. How to Guide Adaptive Depth Sampling?. (arXiv:2205.10202v1 [cs.CV])
10. Self-supervised deep learning MRI reconstruction with Noisier2Noise. (arXiv:2205.10278v1 [eess.IV])
11. Self-supervised 3D anatomy segmentation using self-distilled masked image transformer (SMIT). (arXiv:2205.10342v1 [eess.IV])
12. Diverse super-resolution with pretrained deep hiererarchical VAEs. (arXiv:2205.10347v1 [cs.CV])
13. Generalisation effects of predictive uncertainty estimation in deep learning for digital pathology. (arXiv:2112.09693v2 [cs.LG] UPDATED)
14. Flow-Guided Sparse Transformer for Video Deblurring. (arXiv:2201.01893v2 [eess.IV] UPDATED)
15. Fast Autofocusing using Tiny Transformer Networks for Digital Holographic Microscopy. (arXiv:2203.07772v4 [eess.IV] UPDATED)
16. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v4 [eess.IV] UPDATED)
17. A Framework to Map VMAF with the Probability of Just Noticeable Difference between Video Encoding Recipes. (arXiv:2205.07565v2 [eess.IV] UPDATED)
## cs.LG
---
**228** new papers in cs.LG:-) 
1. HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v1 [cs.AI])
2. Residual Dynamic Mode Decomposition: Robust and verified Koopmanism. (arXiv:2205.09779v1 [physics.flu-dyn])
3. Causal Discovery and Injection for Feed-Forward Neural Networks. (arXiv:2205.09787v1 [cs.LG])
4. Improving Multi-Task Generalization via Regularizing Spurious Correlation. (arXiv:2205.09797v1 [cs.LG])
5. Graph Neural Networks Are More Powerful Than we Think. (arXiv:2205.09801v1 [cs.LG])
6. Label-invariant Augmentation for Semi-Supervised Graph Classification. (arXiv:2205.09802v1 [cs.CV])
7. Towards a Holistic View on Argument Quality Prediction. (arXiv:2205.09803v1 [cs.CL])
8. Estimation of Entropy in Constant Space with Improved Sample Complexity. (arXiv:2205.09804v1 [cs.DS])
9. Calibration Matters: Tackling Maximization Bias in Large-scale Advertising Recommendation Systems. (arXiv:2205.09809v1 [cs.LG])
10. A Novel Weighted Ensemble Learning Based Agent for the Werewolf Game. (arXiv:2205.09813v1 [cs.LG])
11. MiDAS: Multi-integrated Domain Adaptive Supervision for Fake News Detection. (arXiv:2205.09817v1 [cs.LG])
12. A Learning-Based Approach to Approximate Coded Computation. (arXiv:2205.09818v1 [cs.IT])
13. Deep Learning Methods for Proximal Inference via Maximum Moment Restriction. (arXiv:2205.09824v1 [stat.ML])
14. Algorithms for Weak Optimal Transport with an Application to Economics. (arXiv:2205.09825v1 [stat.ML])
15. Capturing cross-session neural population variability through self-supervised identification of consistent neuron ensembles. (arXiv:2205.09829v1 [q-bio.NC])
16. Learning Interface Conditions in Domain Decomposition Solvers. (arXiv:2205.09833v1 [cs.LG])
17. Classification of Intra-Pulse Modulation of Radar Signals by Feature Fusion Based Convolutional Neural Networks. (arXiv:2205.09834v1 [cs.LG])
18. Concurrent Policy Blending and System Identification for Generalized Assistive Control. (arXiv:2205.09836v1 [cs.RO])
19. Summarization as Indirect Supervision for Relation Extraction. (arXiv:2205.09837v1 [cs.CL])
20. Why GANs are overkill for NLP. (arXiv:2205.09838v1 [cs.LG])
21. HyBNN and FedHyBNN: (Federated) Hybrid Binary Neural Networks. (arXiv:2205.09839v1 [cs.LG])
22. A toolbox for idea generation and evaluation: Machine learning, data-driven, and contest-driven approaches to support idea generation. (arXiv:2205.09840v1 [cs.LG])
23. Confident Clustering via PCA Compression Ratio and Its Application to Single-cell RNA-seq Analysis. (arXiv:2205.09849v1 [cs.LG])
24. Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic Treatment Regimes. (arXiv:2205.09852v1 [cs.LG])
25. Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v1 [cs.CV])
26. Mean-Field Analysis of Two-Layer Neural Networks: Global Optimality with Linear Convergence Rates. (arXiv:2205.09860v1 [cs.LG])
27. Recurrent segmentation meets block models in temporal networks. (arXiv:2205.09862v1 [cs.SI])
28. Automated Scoring for Reading Comprehension via In-context BERT Tuning. (arXiv:2205.09864v1 [cs.LG])
29. Service Delay Minimization for Federated Learning over Mobile Devices. (arXiv:2205.09868v1 [cs.LG])
30. Transformer with Memory Replay. (arXiv:2205.09869v1 [cs.LG])
31. Content-Context Factorized Representations for Automated Speech Recognition. (arXiv:2205.09872v1 [eess.AS])
32. Incremental Learning with Differentiable Architecture and Forgetting Search. (arXiv:2205.09875v1 [cs.LG])
33. Real Time Multi-Object Detection for Helmet Safety. (arXiv:2205.09878v1 [cs.CV])
34. Beyond Labels: Visual Representations for Bone Marrow Cell Morphology Recognition. (arXiv:2205.09880v1 [cs.CV])
35. A Rule Search Framework for the Early Identification of Chronic Emergency Homeless Shelter Clients. (arXiv:2205.09883v1 [cs.CY])
36. Time Series Anomaly Detection via Reinforcement Learning-Based Model Selection. (arXiv:2205.09884v1 [cs.LG])
37. Interpolating Compressed Parameter Subspaces. (arXiv:2205.09891v1 [cs.LG])
38. Let the Model Decide its Curriculum for Multitask Learning. (arXiv:2205.09898v1 [cs.LG])
39. Breaking the $\sqrt{T}$ Barrier: Instance-Independent Logarithmic Regret in Stochastic Contextual Linear Bandits. (arXiv:2205.09899v1 [stat.ML])
40. Estimating the frame potential of large-scale quantum circuit sampling using tensor networks up to 50 qubits. (arXiv:2205.09900v1 [quant-ph])
41. Minimal Explanations for Neural Network Predictions. (arXiv:2205.09901v1 [cs.LG])
42. Data Augmentation for Compositional Data: Advancing Predictive Models of the Microbiome. (arXiv:2205.09906v1 [stat.ML])
43. Sparse Infinite Random Feature Latent Variable Modeling. (arXiv:2205.09909v1 [stat.ML])
44. Can Foundation Models Wrangle Your Data?. (arXiv:2205.09911v1 [cs.LG])
45. Robust Expected Information Gain for Optimal Bayesian Experimental Design Using Ambiguity Sets. (arXiv:2205.09914v1 [stat.ML])
46. KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation. (arXiv:2205.09921v1 [cs.CL])
47. Anomaly Detection for Multivariate Time Series on Large-scale Fluid Handling Plant Using Two-stage Autoencoder. (arXiv:2205.09924v1 [cs.LG])
48. On Jointly Optimizing Partial Offloading and SFC Mapping: A Cooperative Dual-agent Deep Reinforcement Learning Approach. (arXiv:2205.09925v1 [cs.AI])
49. CertiFair: A Framework for Certified Global Fairness of Neural Networks. (arXiv:2205.09927v1 [cs.LG])
50. Cross Reconstruction Transformer for Self-Supervised Time Series Representation Learning. (arXiv:2205.09928v1 [cs.LG])
51. BayesPCN: A Continually Learnable Predictive Coding Associative Memory. (arXiv:2205.09930v1 [cs.LG])
52. Towards Explanation for Unsupervised Graph-Level Representation Learning. (arXiv:2205.09934v1 [cs.LG])
53. Conformal Prediction with Temporal Quantile Adjustments. (arXiv:2205.09940v1 [stat.ML])
54. Explainable Supervised Domain Adaptation. (arXiv:2205.09943v1 [cs.LG])
55. Discrete-Convex-Analysis-Based Framework for Warm-Starting Algorithms with Predictions. (arXiv:2205.09961v1 [cs.LG])
56. Sample Complexity of Learning Heuristic Functions for Greedy-Best-First and A* Search. (arXiv:2205.09963v1 [cs.LG])
57. A Fully Controllable Agent in the Path Planning using Goal-Conditioned Reinforcement Learning. (arXiv:2205.09967v1 [cs.AI])
58. A General Framework for quantifying Aleatoric and Epistemic uncertainty in Graph Neural Networks. (arXiv:2205.09968v1 [cs.LG])
59. On Tackling Explanation Redundancy in Decision Trees. (arXiv:2205.09971v1 [cs.AI])
60. A New Feature Selection Method for LogNNet and its Application for Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values. (arXiv:2205.09974v1 [cs.LG])
61. FairNorm: Fair and Fast Graph Neural Network Training. (arXiv:2205.09977v1 [cs.LG])
62. HeadText: Exploring Hands-free Text Entry using Head Gestures by Motion Sensing on a Smart Earpiece. (arXiv:2205.09978v1 [cs.HC])
63. SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning. (arXiv:2205.09986v1 [cs.CR])
64. Set-based Meta-Interpolation for Few-Task Meta-Learning. (arXiv:2205.09990v1 [cs.LG])
65. Planning with Diffusion for Flexible Behavior Synthesis. (arXiv:2205.09991v1 [cs.LG])
66. RiskLoc: Localization of Multi-dimensional Root Causes by Weighted Risk. (arXiv:2205.10004v1 [cs.LG])
67. Self-Supervised Depth Estimation with Isometric-Self-Sample-Based Learning. (arXiv:2205.10006v1 [cs.CV])
68. The price of ignorance: how much does it cost to forget noise structure in low-rank matrix estimation?. (arXiv:2205.10009v1 [cs.IT])
69. Constructive Interpretability with CoLabel: Corroborative Integration, Complementary Features, and Collaborative Learning. (arXiv:2205.10011v1 [cs.CV])
70. A Survey of Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection. (arXiv:2205.10014v1 [cs.LG])
71. Self-Paced Multi-Agent Reinforcement Learning. (arXiv:2205.10016v1 [cs.AI])
72. Translating Hanja historical documents to understandable Korean and English. (arXiv:2205.10019v1 [cs.CL])
73. Neural Additive Models for Nowcasting. (arXiv:2205.10020v1 [cs.LG])
74. Predicting electrode array impedance after one month from cochlear implantation surgery. (arXiv:2205.10021v1 [cs.LG])
75. Towards Consistency in Adversarial Classification. (arXiv:2205.10022v1 [cs.LG])
76. Trend analysis and forecasting air pollution in Rwanda. (arXiv:2205.10024v1 [stat.ML])
77. Survey on Fair Reinforcement Learning: Theory and Practice. (arXiv:2205.10032v1 [cs.LG])
78. Exploring Extreme Parameter Compression for Pre-trained Language Models. (arXiv:2205.10036v1 [cs.CL])
79. Posterior Refinement Improves Sample Efficiency in Bayesian Neural Networks. (arXiv:2205.10041v1 [cs.LG])
80. Towards biologically plausible Dreaming and Planning. (arXiv:2205.10044v1 [cs.LG])
81. ExMo: Explainable AI Model using Inverse Frequency Decision Rules. (arXiv:2205.10045v1 [cs.AI])
82. Sigmoidally Preconditioned Off-policy Learning:a new exploration method for reinforcement learning. (arXiv:2205.10047v1 [cs.LG])
83. MaskGAE: Masked Graph Modeling Meets Graph Autoencoders. (arXiv:2205.10053v1 [cs.LG])
84. Towards Extremely Fast Bilevel Optimization with Self-governed Convergence Guarantees. (arXiv:2205.10054v1 [math.OC])
85. A Case of Exponential Convergence Rates for SVM. (arXiv:2205.10055v1 [stat.ML])
86. Leveraging Relational Information for Learning Weakly Disentangled Representations. (arXiv:2205.10056v1 [cs.LG])
87. The Unreasonable Effectiveness of Deep Evidential Regression. (arXiv:2205.10060v1 [cs.LG])
88. Understanding and Mitigating the Uncertainty in Zero-Shot Translation. (arXiv:2205.10068v1 [cs.CL])
89. On the Prediction Instability of Graph Neural Networks. (arXiv:2205.10070v1 [cs.LG])
90. Unintended memorisation of unique features in neural networks. (arXiv:2205.10079v1 [cs.LG])
91. On Calibration of Ensemble-Based Credal Predictors. (arXiv:2205.10082v1 [stat.ML])
92. A Unified Experiment Design Approach for Cyclic and Acyclic Causal Models. (arXiv:2205.10083v1 [cs.LG])
93. Semi-self-supervised Automated ICD Coding. (arXiv:2205.10088v1 [cs.CL])
94. Kernel Normalized Convolutional Networks. (arXiv:2205.10089v1 [cs.LG])
95. Visual Concepts Tokenization. (arXiv:2205.10093v1 [cs.CV])
96. LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation. (arXiv:2205.10106v1 [cs.LG])
97. FedNoiL: A Simple Two-Level Sampling Method for Federated Learning with Noisy Labels. (arXiv:2205.10110v1 [cs.LG])
98. Evolutionary Multi-Armed Bandits with Genetic Thompson Sampling. (arXiv:2205.10113v1 [cs.NE])
99. Evolving SimGANs to Improve Abnormal Electrocardiogram Classification. (arXiv:2205.10116v1 [cs.NE])
100. DDDM: a Brain-Inspired Framework for Robust Classification. (arXiv:2205.10117v1 [cs.NE])
101. An Artificial Neural Network Functionalized by Evolution. (arXiv:2205.10118v1 [cs.NE])
102. Is explainable AI a race against model complexity?. (arXiv:2205.10119v1 [cs.AI])
103. Converting Artificial Neural Networks to Spiking Neural Networks via Parameter Calibration. (arXiv:2205.10121v1 [cs.NE])
104. Stochastic resonance neurons in artificial neural networks. (arXiv:2205.10122v1 [cs.NE])
105. Lifelong Personal Context Recognition. (arXiv:2205.10123v1 [cs.AI])
106. The Fellowship of the Dyson Ring: ACT\&Friends' Results and Methods for GTOC 11. (arXiv:2205.10124v1 [cs.AI])
107. Neural-Symbolic Models for Logical Queries on Knowledge Graphs. (arXiv:2205.10128v1 [cs.AI])
108. Topology-aware Graph Neural Networks for Learning Feasible and Adaptive ac-OPF Solutions. (arXiv:2205.10129v1 [eess.SY])
109. Function Regression using Spiking DeepONet. (arXiv:2205.10130v1 [cs.NE])
110. Towards efficient feature sharing in MIMO architectures. (arXiv:2205.10139v1 [cs.LG])
111. The developmental trajectory of object recognition robustness: children are like small adults but unlike big deep neural networks. (arXiv:2205.10144v1 [cs.CV])
112. Revisiting GANs by Best-Response Constraint: Perspective, Methodology, and Application. (arXiv:2205.10146v1 [cs.LG])
113. Machine Learning for Combinatorial Optimisation of Partially-Specified Problems: Regret Minimisation as a Unifying Lens. (arXiv:2205.10157v1 [cs.LG])
114. Swapping Semantic Contents for Mixing Images. (arXiv:2205.10158v1 [cs.CV])
115. AutoFedNLP: An efficient FedNLP framework. (arXiv:2205.10162v1 [cs.LG])
116. Task Relabelling for Multi-task Transfer using Successor Features. (arXiv:2205.10175v1 [cs.AI])
117. Towards the Generation of Synthetic Images of Palm Vein Patterns: A Review. (arXiv:2205.10179v1 [cs.CV])
118. Bayesian Active Learning with Fully Bayesian Gaussian Processes. (arXiv:2205.10186v1 [cs.LG])
119. A Proximal Algorithm for Sampling from Non-convex Potentials. (arXiv:2205.10188v1 [cs.LG])
120. The Fairness of Credit Scoring Models. (arXiv:2205.10200v1 [stat.ML])
121. How to Guide Adaptive Depth Sampling?. (arXiv:2205.10202v1 [cs.CV])
122. Test-time Batch Normalization. (arXiv:2205.10210v1 [cs.LG])
123. Memorization and Optimization in Deep Neural Networks with Minimum Over-parameterization. (arXiv:2205.10217v1 [stat.ML])
124. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v1 [cs.LG])
125. Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization in Harsh Urban Environments. (arXiv:2205.10223v1 [cs.AI])
126. Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?. (arXiv:2205.10226v1 [cs.CL])
127. You Don't Know My Favorite Color: Preventing Dialogue Representations from Revealing Speakers' Private Personas. (arXiv:2205.10228v1 [cs.CL])
128. Exploring the Trade-off between Plausibility, Change Intensity and Adversarial Power in Counterfactual Explanations using Multi-objective Optimization. (arXiv:2205.10232v1 [cs.LG])
129. Federated learning for violence incident prediction in a simulated cross-institutional psychiatric setting. (arXiv:2205.10234v1 [cs.CL])
130. Visualizing and Explaining Language Models. (arXiv:2205.10238v1 [cs.CL])
131. EXODUS: Stable and Efficient Training of Spiking Neural Networks. (arXiv:2205.10242v1 [cs.NE])
132. SADAM: Stochastic Adam, A Stochastic Operator for First-Order Gradient-based Optimizer. (arXiv:2205.10247v1 [cs.LG])
133. Explanatory machine learning for sequential human teaching. (arXiv:2205.10250v1 [cs.AI])
134. DEMAND: Deep Matrix Approximately NonlinearDecomposition to Identify Meta, Canonical, and Sub-Spatial Pattern of functional Magnetic Resonance Imaging in the Human Brain. (arXiv:2205.10264v1 [cs.LG])
135. Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors. (arXiv:2205.10279v1 [cs.LG])
136. Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks. (arXiv:2205.10282v1 [cs.CL])
137. On the SDEs and Scaling Rules for Adaptive Gradient Algorithms. (arXiv:2205.10287v1 [cs.LG])
138. Delator: Automatic Detection of Money Laundering Evidence on Transaction Graphs via Neural Networks. (arXiv:2205.10293v1 [cs.LG])
139. ClusterEA: Scalable Entity Alignment with Stochastic Training and Normalized Mini-batch Similarities. (arXiv:2205.10312v1 [cs.DB])
140. Seeking entropy: complex behavior from intrinsic motivation to occupy action-state path space. (arXiv:2205.10316v1 [cs.AI])
141. Nothing makes sense in deep learning, except in the light of evolution. (arXiv:2205.10320v1 [cs.LG])
142. User Localization using RF Sensing: A Performance comparison between LIS and mmWave Radars. (arXiv:2205.10321v1 [eess.SP])
143. Classifying Human Activities using Machine Learning and Deep Learning Techniques. (arXiv:2205.10325v1 [cs.LG])
144. What's the Harm? Sharp Bounds on the Fraction Negatively Affected by Treatment. (arXiv:2205.10327v1 [stat.ME])
145. A Review of Safe Reinforcement Learning: Methods, Theory and Applications. (arXiv:2205.10330v1 [cs.AI])
146. Towards Understanding Grokking: An Effective Theory of Representation Learning. (arXiv:2205.10343v1 [cs.LG])
147. Diverse super-resolution with pretrained deep hiererarchical VAEs. (arXiv:2205.10347v1 [cs.CV])
148. Lossless Acceleration for Seq2seq Generation with Aggressive Decoding. (arXiv:2205.10350v1 [cs.CL])
149. Lifelong Neural Predictive Coding: Learning Cumulatively Online without Forgetting. (arXiv:1905.10696v3 [cs.LG] UPDATED)
150. Instagram Fake and Automated Account Detection. (arXiv:1910.03090v3 [cs.IR] UPDATED)
151. Generating Semantic Adversarial Examples via Feature Manipulation. (arXiv:2001.02297v2 [cs.LG] UPDATED)
152. Interpretable Personalization via Policy Learning with Linear Decision Boundaries. (arXiv:2003.07545v3 [cs.LG] UPDATED)
153. Almost exact recovery in noisy semi-supervised learning. (arXiv:2007.14717v3 [cs.LG] UPDATED)
154. A Unified Approach to Synchronization Problems over Subgroups of the Orthogonal Group. (arXiv:2009.07514v2 [math.OC] UPDATED)
155. An alternative proof of the vulnerability of retrieval in high intrinsic dimensionality neighborhood. (arXiv:2010.00990v2 [cs.LG] UPDATED)
156. Global and Individualized Community Detection in Inhomogeneous Multilayer Networks. (arXiv:2012.00933v3 [math.ST] UPDATED)
157. Policies for the Dynamic Traveling Maintainer Problem with Alerts. (arXiv:2105.15119v2 [math.OC] UPDATED)
158. Unsupervised Out-of-Domain Detection via Pre-trained Transformers. (arXiv:2106.00948v2 [cs.CL] UPDATED)
159. On Algorithmic Stability in Unsupervised Representation Learning. (arXiv:2106.05238v3 [cs.LG] UPDATED)
160. Adversarial Sample Detection for Speaker Verification by Neural Vocoders. (arXiv:2107.00309v4 [cs.SD] UPDATED)
161. Greedy structure learning from data that contain systematic missing values. (arXiv:2107.04184v3 [cs.LG] UPDATED)
162. Learning a Large Neighborhood Search Algorithm for Mixed Integer Programs. (arXiv:2107.10201v3 [math.OC] UPDATED)
163. Multi-Graph Convolutional-Recurrent Neural Network (MGC-RNN) for Short-Term Forecasting of Transit Passenger Flow. (arXiv:2107.13226v2 [cs.LG] UPDATED)
164. Mitigating Statistical Bias within Differentially Private Synthetic Data. (arXiv:2108.10934v3 [stat.ML] UPDATED)
165. WALNUT: A Benchmark on Weakly Supervised Learning for Natural Language Understanding. (arXiv:2108.12603v2 [cs.CL] UPDATED)
166. Speeding up PCA with priming. (arXiv:2109.03709v3 [cs.LG] UPDATED)
167. Cross DQN: Cross Deep Q Network for Ads Allocation in Feed. (arXiv:2109.04353v4 [cs.LG] UPDATED)
168. Long-Range Transformers for Dynamic Spatiotemporal Forecasting. (arXiv:2109.12218v2 [cs.LG] UPDATED)
169. Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining. (arXiv:2110.08412v2 [cs.CL] UPDATED)
170. Edge Rewiring Goes Neural: Boosting Network Resilience without Rich Features. (arXiv:2110.09035v2 [cs.LG] UPDATED)
171. On pseudo-absence generation and machine learning for locust breeding ground prediction in Africa. (arXiv:2111.03904v2 [cs.LG] UPDATED)
172. Counterfactual Temporal Point Processes. (arXiv:2111.07603v2 [cs.LG] UPDATED)
173. Track Boosting and Synthetic Data Aided Drone Detection. (arXiv:2111.12389v5 [cs.CV] UPDATED)
174. Characteristic Neural Ordinary Differential Equations. (arXiv:2111.13207v3 [cs.LG] UPDATED)
175. Personalized Federated Learning with Adaptive Batchnorm for Healthcare. (arXiv:2112.00734v3 [cs.LG] UPDATED)
176. Millimeter Wave Localization with Imperfect Training Data using Shallow Neural Networks. (arXiv:2112.05008v2 [cs.NI] UPDATED)
177. Triangulation candidates for Bayesian optimization. (arXiv:2112.07457v2 [stat.CO] UPDATED)
178. Proposition-Level Clustering for Multi-Document Summarization. (arXiv:2112.08770v2 [cs.CL] UPDATED)
179. Privacy preserving n-party scalar product protocol. (arXiv:2112.09436v3 [cs.CR] UPDATED)
180. Generalisation effects of predictive uncertainty estimation in deep learning for digital pathology. (arXiv:2112.09693v2 [cs.LG] UPDATED)
181. GNN-Geo: A Graph Neural Network-based Fine-grained IP geolocation Framework. (arXiv:2112.10767v6 [cs.LG] UPDATED)
182. Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v7 [cs.LG] UPDATED)
183. Optimizing the Communication-Accuracy Trade-off in Federated Learning with Rate-Distortion Theory. (arXiv:2201.02664v3 [cs.LG] UPDATED)
184. Graph Representation Learning for Multi-Task Settings: a Meta-Learning Approach. (arXiv:2201.03326v2 [cs.LG] UPDATED)
185. Deep reinforcement learning under signal temporal logic constraints using Lagrangian relaxation. (arXiv:2201.08504v3 [stat.ML] UPDATED)
186. Understanding Why Generalized Reweighting Does Not Improve Over ERM. (arXiv:2201.12293v3 [cs.LG] UPDATED)
187. Nonlinear Initialization Methods for Low-Rank Neural Networks. (arXiv:2202.00834v3 [cs.LG] UPDATED)
188. Sequentially learning the topological ordering of causal directed acyclic graphs with likelihood ratio scores. (arXiv:2202.01748v2 [stat.ME] UPDATED)
189. Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo. (arXiv:2202.04599v2 [cs.LG] UPDATED)
190. EquiBind: Geometric Deep Learning for Drug Binding Structure Prediction. (arXiv:2202.05146v3 [q-bio.BM] UPDATED)
191. When, where, and how to add new neurons to ANNs. (arXiv:2202.08539v2 [cs.LG] UPDATED)
192. HCMD-zero: Learning Value Aligned Mechanisms from Data. (arXiv:2202.10122v2 [cs.MA] UPDATED)
193. MCMARL: Parameterizing Value Function via Mixture of Categorical Distributions for Multi-Agent Reinforcement Learning. (arXiv:2202.10134v2 [cs.LG] UPDATED)
194. Permutation Predictions for Non-Clairvoyant Scheduling. (arXiv:2202.10199v2 [cs.DS] UPDATED)
195. Adaptor: Objective-Centric Adaptation Framework for Language Models. (arXiv:2203.03989v2 [cs.CL] UPDATED)
196. Robot Learning of Mobile Manipulation with Reachability Behavior Priors. (arXiv:2203.04051v2 [cs.RO] UPDATED)
197. Robust Multi-Task Learning and Online Refinement for Spacecraft Pose Estimation across Domain Gap. (arXiv:2203.04275v3 [cs.CV] UPDATED)
198. Enhanced Temporal Knowledge Embeddings with Contextualized Language Representations. (arXiv:2203.09590v3 [cs.CL] UPDATED)
199. Linearizing Transformer with Key-Value Memory. (arXiv:2203.12644v3 [cs.CL] UPDATED)
200. Remember and Forget Experience Replay for Multi-Agent Reinforcement Learning. (arXiv:2203.13319v2 [cs.LG] UPDATED)
201. STaR: Bootstrapping Reasoning With Reasoning. (arXiv:2203.14465v2 [cs.LG] UPDATED)
202. Lossless Speedup of Autoregressive Translation with Generalized Aggressive Decoding. (arXiv:2203.16487v4 [cs.CL] UPDATED)
203. Learning List-wise Representation in Reinforcement Learning for Ads Allocation with Multiple Auxiliary Tasks. (arXiv:2204.00888v2 [cs.LG] UPDATED)
204. Can language models learn from explanations in context?. (arXiv:2204.02329v3 [cs.CL] UPDATED)
205. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v8 [cs.CV] UPDATED)
206. On the Representation Collapse of Sparse Mixture of Experts. (arXiv:2204.09179v2 [cs.CL] UPDATED)
207. Bounding the Effects of Continuous Treatments for Hidden Confounders. (arXiv:2204.11206v2 [stat.ME] UPDATED)
208. Hybrid Transfer in Deep Reinforcement Learning for Ads Allocation. (arXiv:2204.11589v2 [cs.IR] UPDATED)
209. Adaptable Text Matching via Meta-Weight Regulator. (arXiv:2204.12668v2 [cs.IR] UPDATED)
210. Open challenges for Machine Learning based Early Decision-Making research. (arXiv:2204.13111v2 [cs.LG] UPDATED)
211. Training Language Models with Language Feedback. (arXiv:2204.14146v3 [cs.CL] UPDATED)
212. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v4 [eess.IV] UPDATED)
213. LDSA: Learning Dynamic Subtask Assignment in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2205.02561v2 [cs.LG] UPDATED)
214. Meta-learning Adaptive Deep Kernel Gaussian Processes for Molecular Property Prediction. (arXiv:2205.02708v2 [cs.LG] UPDATED)
215. How to Minimize the Weighted Sum AoI in Multi-Source Status Update Systems: OMA or NOMA?. (arXiv:2205.03143v2 [cs.IT] UPDATED)
216. Optimal Parameter-free Online Learning with Switching Cost. (arXiv:2205.06846v2 [cs.LG] UPDATED)
217. A Computational Framework of Cortical Microcircuits Approximates Sign-concordant Random Backpropagation. (arXiv:2205.07292v2 [cs.NE] UPDATED)
218. Continual learning on 3D point clouds with random compressed rehearsal. (arXiv:2205.08013v2 [cs.LG] UPDATED)
219. Unraveling Attention via Convex Duality: Analysis and Interpretations of Vision Transformers. (arXiv:2205.08078v2 [cs.LG] UPDATED)
220. Position Aided Beam Prediction in the Real World: How Useful GPS Locations Actually Are?. (arXiv:2205.09054v2 [eess.SP] UPDATED)
221. AI-assisted Optimization of the ECCE Tracking System at the Electron Ion Collider. (arXiv:2205.09185v2 [physics.ins-det] UPDATED)
222. An Introduction to Quantum Machine Learning for Engineers. (arXiv:2205.09510v2 [quant-ph] UPDATED)
223. ODBO: Bayesian Optimization with Search Space Prescreening for Directed Protein Evolution. (arXiv:2205.09548v2 [q-bio.BM] UPDATED)
224. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v2 [cs.LG] UPDATED)
225. Semi-WTC: A Practical Semi-supervised Framework for Attack Categorization through Weight-Task Consistency. (arXiv:2205.09669v2 [cs.CR] UPDATED)
226. Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis. (arXiv:2205.09702v2 [cs.LG] UPDATED)
227. Deep electric field predictions by drift-reduced Braginskii theory with plasma-neutral interactions based upon experimental images of boundary turbulence. (arXiv:2204.11689v1 [physics.plasm-ph] CROSS LISTED)
228. Deep Learning in Business Analytics: A Clash of Expectations and Reality. (arXiv:2205.09337v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**105** new papers in cs.AI:-) 
1. Taylor Genetic Programming for Symbolic Regression. (arXiv:2205.09751v1 [cs.NE])
2. Local dynamic mode of Cognitive Behavioral Therapy. (arXiv:2205.09752v1 [cs.AI])
3. HDGT: Heterogeneous Driving Graph Transformer for Multi-Agent Trajectory Prediction via Scene Encoding. (arXiv:2205.09753v1 [cs.AI])
4. Causal Discovery and Injection for Feed-Forward Neural Networks. (arXiv:2205.09787v1 [cs.LG])
5. Improving Multi-Task Generalization via Regularizing Spurious Correlation. (arXiv:2205.09797v1 [cs.LG])
6. Graph Neural Networks Are More Powerful Than we Think. (arXiv:2205.09801v1 [cs.LG])
7. Label-invariant Augmentation for Semi-Supervised Graph Classification. (arXiv:2205.09802v1 [cs.CV])
8. Towards a Holistic View on Argument Quality Prediction. (arXiv:2205.09803v1 [cs.CL])
9. Unsupervised Learning of Depth, Camera Pose and Optical Flow from Monocular Video. (arXiv:2205.09821v1 [cs.CV])
10. DPER: Dynamic Programming for Exist-Random Stochastic SAT. (arXiv:2205.09826v1 [cs.LO])
11. Concurrent Policy Blending and System Identification for Generalized Assistive Control. (arXiv:2205.09836v1 [cs.RO])
12. HyBNN and FedHyBNN: (Federated) Hybrid Binary Neural Networks. (arXiv:2205.09839v1 [cs.LG])
13. A toolbox for idea generation and evaluation: Machine learning, data-driven, and contest-driven approaches to support idea generation. (arXiv:2205.09840v1 [cs.LG])
14. Deconfounding Actor-Critic Network with Policy Adaptation for Dynamic Treatment Regimes. (arXiv:2205.09852v1 [cs.LG])
15. Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v1 [cs.CV])
16. Automated Scoring for Reading Comprehension via In-context BERT Tuning. (arXiv:2205.09864v1 [cs.LG])
17. Explainable Graph Theory-Based Identification of Meter-Transformer Mapping. (arXiv:2205.09874v1 [math.OC])
18. Incremental Learning with Differentiable Architecture and Forgetting Search. (arXiv:2205.09875v1 [cs.LG])
19. Breaking the $\sqrt{T}$ Barrier: Instance-Independent Logarithmic Regret in Stochastic Contextual Linear Bandits. (arXiv:2205.09899v1 [stat.ML])
20. Deep transfer learning for image classification: a survey. (arXiv:2205.09904v1 [cs.CV])
21. Sparse Infinite Random Feature Latent Variable Modeling. (arXiv:2205.09909v1 [stat.ML])
22. Can Foundation Models Wrangle Your Data?. (arXiv:2205.09911v1 [cs.LG])
23. Robust Expected Information Gain for Optimal Bayesian Experimental Design Using Ambiguity Sets. (arXiv:2205.09914v1 [stat.ML])
24. On Jointly Optimizing Partial Offloading and SFC Mapping: A Cooperative Dual-agent Deep Reinforcement Learning Approach. (arXiv:2205.09925v1 [cs.AI])
25. BayesPCN: A Continually Learnable Predictive Coding Associative Memory. (arXiv:2205.09930v1 [cs.LG])
26. Towards Explanation for Unsupervised Graph-Level Representation Learning. (arXiv:2205.09934v1 [cs.LG])
27. Explainable Supervised Domain Adaptation. (arXiv:2205.09943v1 [cs.LG])
28. A Fully Controllable Agent in the Path Planning using Goal-Conditioned Reinforcement Learning. (arXiv:2205.09967v1 [cs.AI])
29. On Tackling Explanation Redundancy in Decision Trees. (arXiv:2205.09971v1 [cs.AI])
30. A New Feature Selection Method for LogNNet and its Application for Diagnosis and Prognosis of COVID-19 Disease Using Routine Blood Values. (arXiv:2205.09974v1 [cs.LG])
31. SALTED: A Framework for SAlient Long-Tail Translation Error Detection. (arXiv:2205.09988v1 [cs.CL])
32. Set-based Meta-Interpolation for Few-Task Meta-Learning. (arXiv:2205.09990v1 [cs.LG])
33. Planning with Diffusion for Flexible Behavior Synthesis. (arXiv:2205.09991v1 [cs.LG])
34. Self-Supervised Depth Estimation with Isometric-Self-Sample-Based Learning. (arXiv:2205.10006v1 [cs.CV])
35. A Survey of Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection. (arXiv:2205.10014v1 [cs.LG])
36. Self-Paced Multi-Agent Reinforcement Learning. (arXiv:2205.10016v1 [cs.AI])
37. NMA: Neural Multi-slot Auctions with Externalities for Online Advertising. (arXiv:2205.10018v1 [cs.AI])
38. Translating Hanja historical documents to understandable Korean and English. (arXiv:2205.10019v1 [cs.CL])
39. Neural Additive Models for Nowcasting. (arXiv:2205.10020v1 [cs.LG])
40. Predicting electrode array impedance after one month from cochlear implantation surgery. (arXiv:2205.10021v1 [cs.LG])
41. SE-MoE: A Scalable and Efficient Mixture-of-Experts Distributed Training and Inference System. (arXiv:2205.10034v1 [cs.DC])
42. ExMo: Explainable AI Model using Inverse Frequency Decision Rules. (arXiv:2205.10045v1 [cs.AI])
43. MaskGAE: Masked Graph Modeling Meets Graph Autoencoders. (arXiv:2205.10053v1 [cs.LG])
44. A Case of Exponential Convergence Rates for SVM. (arXiv:2205.10055v1 [stat.ML])
45. Understanding and Mitigating the Uncertainty in Zero-Shot Translation. (arXiv:2205.10068v1 [cs.CL])
46. Contrastive Learning with Cross-Modal Knowledge Mining for Multimodal Human Activity Recognition. (arXiv:2205.10071v1 [cs.CV])
47. A Unified Experiment Design Approach for Cyclic and Acyclic Causal Models. (arXiv:2205.10083v1 [cs.LG])
48. Adversarial joint attacks on legged robots. (arXiv:2205.10098v1 [cs.RO])
49. LeNSE: Learning To Navigate Subgraph Embeddings for Large-Scale Combinatorial Optimisation. (arXiv:2205.10106v1 [cs.LG])
50. Evolutionary Multi-Armed Bandits with Genetic Thompson Sampling. (arXiv:2205.10113v1 [cs.NE])
51. Testing predictive automated driving systems: lessons learned and future recommendations. (arXiv:2205.10115v1 [cs.AI])
52. Evolving SimGANs to Improve Abnormal Electrocardiogram Classification. (arXiv:2205.10116v1 [cs.NE])
53. An Artificial Neural Network Functionalized by Evolution. (arXiv:2205.10118v1 [cs.NE])
54. Is explainable AI a race against model complexity?. (arXiv:2205.10119v1 [cs.AI])
55. Privacy Preserving Image Registration. (arXiv:2205.10120v1 [cs.CV])
56. Lifelong Personal Context Recognition. (arXiv:2205.10123v1 [cs.AI])
57. The Fellowship of the Dyson Ring: ACT\&Friends' Results and Methods for GTOC 11. (arXiv:2205.10124v1 [cs.AI])
58. Some neighborhood-related fuzzy covering-based rough set models and their applications for decision making. (arXiv:2205.10125v1 [math.GM])
59. On Evaluating Power Loss with HATSGA Algorithm for Power Network Reconfiguration in the Smart Grid. (arXiv:2205.10126v1 [cs.AI])
60. Construction of Rough graph to handle uncertain pattern from an Information System. (arXiv:2205.10127v1 [cs.AI])
61. Neural-Symbolic Models for Logical Queries on Knowledge Graphs. (arXiv:2205.10128v1 [cs.AI])
62. Agent-Based modeling in Medical Research. Example in Health Economics. (arXiv:2205.10131v1 [cs.AI])
63. The developmental trajectory of object recognition robustness: children are like small adults but unlike big deep neural networks. (arXiv:2205.10144v1 [cs.CV])
64. Task Relabelling for Multi-task Transfer using Successor Features. (arXiv:2205.10175v1 [cs.AI])
65. Adversarial Body Shape Search for Legged Robots. (arXiv:2205.10187v1 [cs.RO])
66. Progressive Class Semantic Matching for Semi-supervised Text Classification. (arXiv:2205.10189v1 [cs.CL])
67. A Novel Underwater Image **Enhancement** and Improved Underwater Biological Detection Pipeline. (arXiv:2205.10199v1 [cs.CV])
68. On the Decentralization of Blockchain-enabled Asynchronous Federated Learning. (arXiv:2205.10201v1 [cs.CR])
69. Measuring algorithmic interpretability: A human-learning-based framework and the corresponding cognitive complexity score. (arXiv:2205.10207v1 [cs.AI])
70. Learning Task-relevant Representations for Generalization via Characteristic Functions of Reward Sequence Distributions. (arXiv:2205.10218v1 [cs.LG])
71. Mosaic Zonotope Shadow Matching for Risk-Aware Autonomous Localization in Harsh Urban Environments. (arXiv:2205.10223v1 [cs.AI])
72. Exploring the Trade-off between Plausibility, Change Intensity and Adversarial Power in Counterfactual Explanations using Multi-objective Optimization. (arXiv:2205.10232v1 [cs.LG])
73. M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database. (arXiv:2205.10237v1 [cs.CL])
74. Sampling Is All You Need on Modeling Long-Term User Behaviors for CTR Prediction. (arXiv:2205.10249v1 [cs.IR])
75. Explanatory machine learning for sequential human teaching. (arXiv:2205.10250v1 [cs.AI])
76. Self-supervised deep learning MRI reconstruction with Noisier2Noise. (arXiv:2205.10278v1 [eess.IV])
77. Low-cost Relevance Generation and Evaluation Metrics for Entity Resolution in AI. (arXiv:2205.10298v1 [cs.IT])
78. ClusterEA: Scalable Entity Alignment with Stochastic Training and Normalized Mini-batch Similarities. (arXiv:2205.10312v1 [cs.DB])
79. Seeking entropy: complex behavior from intrinsic motivation to occupy action-state path space. (arXiv:2205.10316v1 [cs.AI])
80. Nothing makes sense in deep learning, except in the light of evolution. (arXiv:2205.10320v1 [cs.LG])
81. A Review of Safe Reinforcement Learning: Methods, Theory and Applications. (arXiv:2205.10330v1 [cs.AI])
82. Towards Understanding Grokking: An Effective Theory of Representation Learning. (arXiv:2205.10343v1 [cs.LG])
83. Open Benchmarking for Click-Through Rate Prediction. (arXiv:2009.05794v3 [cs.IR] UPDATED)
84. Synthesis in Style: Semantic Segmentation of Historical Documents using Synthetic Data. (arXiv:2107.06777v3 [cs.CV] UPDATED)
85. Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining. (arXiv:2110.08412v2 [cs.CL] UPDATED)
86. Edge Rewiring Goes Neural: Boosting Network Resilience without Rich Features. (arXiv:2110.09035v2 [cs.LG] UPDATED)
87. Counterfactual Temporal Point Processes. (arXiv:2111.07603v2 [cs.LG] UPDATED)
88. Monolith to Microservices: Representing Application Software through Heterogeneous Graph Neural Network. (arXiv:2112.01317v3 [cs.SE] UPDATED)
89. Generalisation effects of predictive uncertainty estimation in deep learning for digital pathology. (arXiv:2112.09693v2 [cs.LG] UPDATED)
90. Regionalized Optimization. (arXiv:2201.11876v2 [cs.AI] UPDATED)
91. Nonlinear Initialization Methods for Low-Rank Neural Networks. (arXiv:2202.00834v3 [cs.LG] UPDATED)
92. HCMD-zero: Learning Value Aligned Mechanisms from Data. (arXiv:2202.10122v2 [cs.MA] UPDATED)
93. First do not fall: learning to exploit a wall with a damaged humanoid robot. (arXiv:2203.00316v2 [cs.RO] UPDATED)
94. Adaptor: Objective-Centric Adaptation Framework for Language Models. (arXiv:2203.03989v2 [cs.CL] UPDATED)
95. Robot Learning of Mobile Manipulation with Reachability Behavior Priors. (arXiv:2203.04051v2 [cs.RO] UPDATED)
96. Remember and Forget Experience Replay for Multi-Agent Reinforcement Learning. (arXiv:2203.13319v2 [cs.LG] UPDATED)
97. STaR: Bootstrapping Reasoning With Reasoning. (arXiv:2203.14465v2 [cs.LG] UPDATED)
98. Can language models learn from explanations in context?. (arXiv:2204.02329v3 [cs.CL] UPDATED)
99. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v8 [cs.CV] UPDATED)
100. Exploiting Session Information in BERT-based Session-aware Sequential Recommendation. (arXiv:2204.10851v3 [cs.IR] UPDATED)
101. Training Language Models with Language Feedback. (arXiv:2204.14146v3 [cs.CL] UPDATED)
102. A Computational Framework of Cortical Microcircuits Approximates Sign-concordant Random Backpropagation. (arXiv:2205.07292v2 [cs.NE] UPDATED)
103. Connection-minimal Abduction in EL via Translation to FOL -- Technical Report. (arXiv:2205.08449v2 [cs.AI] UPDATED)
104. Confidential Machine Learning within Graphcore IPUs. (arXiv:2205.09005v2 [cs.CR] UPDATED)
105. Deep Learning in Business Analytics: A Clash of Expectations and Reality. (arXiv:2205.09337v1 [cs.LG] CROSS LISTED)

