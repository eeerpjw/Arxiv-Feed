# Your interest papers
---
## cs.CV
---
### Synthetic Latent Fingerprint Generator. (arXiv:2208.13811v1 [cs.CV])
- Authors : Andre Brasil, Vieira Wyzykowski
- Link : [http://arxiv.org/abs/2208.13811](http://arxiv.org/abs/2208.13811)
> ABSTRACT  :  Given a full fingerprint image (rolled or slap), we present CycleGAN models to generate multiple latent impressions of the same identity as the full print. Our models can control the degree of distortion, noise, blurriness and occlusion in the generated latent print images to obtain Good, Bad and Ugly latent image categories as introduced in the NIST SD27 latent database. The contributions of our work are twofold: (i) demonstrate the similarity of synthetically generated latent fingerprint images to crime scene latents in NIST SD27 and MSP databases as evaluated by the NIST NFIQ 2 quality measure and ROC curves obtained by a SOTA fingerprint matcher, and (ii) use of synthetic latents to augment small-size latent training databases in the public domain to improve the performance of DeepPrint, a SOTA fingerprint matcher designed for rolled to rolled fingerprint matching on three latent databases (NIST SD27, NIST SD302, and IIITD-SLF). As an example, with synthetic latent data augmentation, the Rank-1 retrieval performance of DeepPrint is improved from 15.50% to 29.07% on challenging NIST SD27 latent database. Our approach for generating synthetic latent fingerprints can be used to improve the recognition performance of any latent matcher and its individual components (e.g., **enhancement**, segmentation and feature extraction).  
### Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising. (arXiv:2208.14022v1 [eess.IV])
- Authors : Ruizhou Liu, Qiang Ma, Zhiwei Cheng, Yuanyuan Lyu, Jianji Wang, Kevin Zhou
- Link : [http://arxiv.org/abs/2208.14022](http://arxiv.org/abs/2208.14022)
> ABSTRACT  :  Fluoroscopy is an imaging technique that uses X-ray to obtain a real-time 2D video of the interior of a 3D object, helping surgeons to observe pathological structures and tissue functions especially during intervention. However, it suffers from heavy noise that mainly arises from the clinical use of a low dose X-ray, thereby necessitating the technology of fluoroscopy denoising. Such denoising is challenged by the relative motion between the object being imaged and the X-ray imaging system. We tackle this challenge by proposing a self-supervised, three-stage framework that exploits the domain knowledge of fluoroscopy imaging. (i) Stabilize: we first construct a dynamic panorama based on optical flow calculation to stabilize the non-stationary background induced by the motion of the X-ray detector. (ii) Decompose: we then propose a novel mask-based Robust Principle Component Analysis (RPCA) decomposition method to separate a video with detector motion into a low-rank background and a sparse foreground. Such a decomposition accommodates the reading habit of experts. (iii) Denoise: we finally denoise the background and foreground separately by a self-supervised learning strategy and fuse the denoised parts into the final output via a **bilateral**, spatiotemporal filter. To assess the effectiveness of our work, we curate a dedicated fluoroscopy dataset of 27 videos (1,568 frames) and corresponding ground truth. Our experiments demonstrate that it achieves significant improvements in terms of denoising and **enhancement** effects when compared with standard approaches. Finally, expert rating confirms this efficacy.  
### CAIR: Fast and Lightweight Multi-Scale Color Attention Network for Instagram Filter Removal. (arXiv:2208.14039v1 [cs.CV])
- Authors : Ha Yeo, Taek Oh, Su Kang, Il Kim, Cheol Ryu
- Link : [http://arxiv.org/abs/2208.14039](http://arxiv.org/abs/2208.14039)
> ABSTRACT  :  Image **restoration** is an important and challenging task in computer vision. Reverting a filtered image to its original image is helpful in various computer vision tasks. We employ a nonlinear activation function free network (NAFNet) for a fast and lightweight model and add a color attention module that extracts useful color information for better accuracy. We propose an accurate, fast, lightweight network with multi-scale and color attention for Instagram filter removal (CAIR). Experiment results show that the proposed CAIR outperforms existing Instagram filter removal networks in fast and lightweight ways, about 11$\times$ faster and 2.4$\times$ lighter while exceeding 3.69 dB PSNR on IFFI dataset. CAIR can successfully remove the Instagram filter with high quality and restore color information in qualitative results. The source code and pretrained weights are available at \url{https://github.com/HnV-Lab/CAIR}.  
### Synthehicle: Multi-Vehicle Multi-Camera Tracking in Virtual Cities. (arXiv:2208.14167v1 [cs.CV])
- Authors : Fabian Herzog, Junpeng Chen, Torben Teepe, Johannes Gilg, Gerhard Rigoll
- Link : [http://arxiv.org/abs/2208.14167](http://arxiv.org/abs/2208.14167)
> ABSTRACT  :  Smart City applications such as intelligent traffic routing or accident prevention rely on computer vision methods for exact vehicle localization and tracking. Due to the scarcity of accurately labeled data, detecting and tracking vehicles in 3D from multiple cameras proves challenging to explore. We present a massive synthetic dataset for multiple vehicle tracking and segmentation in multiple overlapping and non-overlapping camera views. Unlike existing datasets, which only provide tracking ground truth for 2D bounding boxes, our dataset additionally contains perfect labels for 3D bounding boxes in camera- and world coordinates, depth estimation, and instance, semantic and panoptic segmentation. The dataset consists of 17 hours of labeled video material, recorded from 340 cameras in 64 diverse day, rain, dawn, and **night** scenes, making it the most extensive dataset for multi-target multi-camera tracking so far. We provide baselines for detection, vehicle re-identification, and single- and multi-camera tracking. Code and data are publicly available.  
### Boosting **Night**-time Scene Parsing with Learnable Frequency. (arXiv:2208.14241v1 [cs.CV])
- Authors : Zhifeng Xie, Sen Wang, Ke Xu, Zhizhong Zhang, Xin Tan, Yuan Xie, Lizhuang Ma
- Link : [http://arxiv.org/abs/2208.14241](http://arxiv.org/abs/2208.14241)
> ABSTRACT  :  **Night**-Time Scene Parsing (NTSP) is essential to many vision applications, especially for autonomous driving. Most of the existing methods are proposed for day-time scene parsing. They rely on modeling pixel intensity-based spatial contextual cues under even illumination. Hence, these methods do not perform well in **night**-time scenes as such spatial contextual cues are buried in the over-/under-exposed regions in **night**-time scenes. In this paper, we first conduct an image frequency-based statistical experiment to interpret the day-time and **night**-time scene discrepancies. We find that image frequency distributions differ significantly between day-time and **night**-time scenes, and understanding such frequency distributions is critical to NTSP problem. Based on this, we propose to exploit the image frequency distributions for **night**-time scene parsing. First, we propose a Learnable Frequency Encoder (LFE) to model the relationship between different frequency coefficients to measure all frequency components dynamically. Second, we propose a Spatial Frequency Fusion module (SFF) that fuses both spatial and frequency information to guide the extraction of spatial context features. Extensive experiments show that our method performs favorably against the state-of-the-art methods on the **Night**City, **Night**City+ and BDD100K-**night** datasets. In addition, we demonstrate that our method can be applied to existing day-time scene parsing methods and boost their performance on **night**-time scenes.  
### A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes. (arXiv:2208.14433v1 [cs.CV])
- Authors : Tianjia Zhang, Fui Lau, Qifeng Chen
- Link : [http://arxiv.org/abs/2208.14433](http://arxiv.org/abs/2208.14433)
> ABSTRACT  :  We present a portable multiscopic camera system with a dedicated model for novel view and time synthesis in dynamic scenes. Our goal is to render high-quality images for a dynamic scene from any viewpoint at any time using our portable multiscopic camera. To achieve such novel view and time synthesis, we develop a physical multiscopic camera equipped with five cameras to train a neural radiance field (**NeRF**) in both time and spatial domains for dynamic scenes. Our model maps a 6D coordinate (3D spatial position, 1D temporal coordinate, and 2D viewing direction) to view-dependent and time-varying emitted radiance and volume density. Volume rendering is applied to render a photo-realistic image at a specified camera pose and time. To improve the robustness of our physical camera, we propose a camera parameter optimization module and a temporal frame interpolation module to promote information propagation across time. We conduct experiments on both real-world and synthetic datasets to evaluate our system, and the results show that our approach outperforms alternative solutions qualitatively and quantitatively. Our code and dataset are available at https://yuenfuilau.github.io.  
### Contrast **Enhancement** of Brightness-Distorted Images by Improved Adaptive Gamma Correction. (arXiv:1709.04427v2 [cs.MM] UPDATED)
- Authors : Gang Cao, Lihui Huang, Huawei Tian, Xianglin Huang, Yongbin Wang, Ruicong Zhi
- Link : [http://arxiv.org/abs/1709.04427](http://arxiv.org/abs/1709.04427)
> ABSTRACT  :  As an efficient image contrast **enhancement** (CE) tool, adaptive gamma correction (AGC) was previously proposed by relating gamma parameter with cumulative distribution function (CDF) of the pixel gray levels within an image. ACG deals well with most dimmed images, but fails for globally bright images and the dimmed images with local bright regions. Such two categories of brightness-distorted images are universal in real scenarios, such as improper **exposure** and white object regions. In order to attenuate such deficiencies, here we propose an improved AGC algorithm. The novel strategy of negative images is used to realize CE of the bright images, and the gamma correction modulated by truncated CDF is employed to enhance the dimmed ones. As such, local over-**enhancement** and structure distortion can be alleviated. Both qualitative and quantitative experimental results show that our proposed method yields consistently good CE results.  
### Acceleration of Histogram-Based Contrast **Enhancement** via Selective Downsampling. (arXiv:1709.04583v3 [cs.MM] UPDATED)
- Authors : Gang Cao, Huawei Tian, Lifang Yu, Xianglin Huang, Yongbin Wang
- Link : [http://arxiv.org/abs/1709.04583](http://arxiv.org/abs/1709.04583)
> ABSTRACT  :  In this paper, we propose a general framework to accelerate the universal histogram-based image contrast **enhancement** (CE) algorithms. Both spatial and gray-level selective down-sampling of digital images are adopted to decrease computational cost, while the visual quality of enhanced images is still preserved and without apparent degradation. Mapping function calibration is novelly proposed to reconstruct the pixel mapping on the gray levels missed by downsampling. As two case studies, accelerations of histogram equalization (HE) and the state-of-the-art global CE algorithm, i.e., spatial mutual information and PageRank (SMIRANK), are presented detailedly. Both quantitative and qualitative assessment results have verified the effectiveness of our proposed CE acceleration framework. In typical tests, computational efficiencies of HE and SMIRANK have been speeded up by about 3.9 and 13.5 times, respectively.  
### Accurate and **Real-time** 3D Pedestrian Detection Using an Efficient Attentive Pillar Network. (arXiv:2112.15458v2 [cs.CV] UPDATED)
- Authors : Tho Le, Hengcan Shi, Hamid Rezatofighi, Jianfei Cai
- Link : [http://arxiv.org/abs/2112.15458](http://arxiv.org/abs/2112.15458)
> ABSTRACT  :  Efficiently and accurately detecting people from 3D point cloud data is of great importance in many robotic and autonomous driving applications. This fundamental perception task is still very challenging due to (i) significant deformations of human body pose and gesture over time and (ii) point cloud sparsity and scarcity for pedestrian class objects. Recent efficient 3D object detection approaches rely on pillar features to detect objects from point cloud data. However, these pillar features do not carry sufficient expressive representations to deal with all the aforementioned challenges in detecting people. To address this shortcoming, we first introduce a stackable Pillar Aware Attention (PAA) module for enhanced pillar features extraction while suppressing noises in the point clouds. By integrating multi-point-channel-pooling, point-wise, channel-wise, and task-aware attention into a simple module, the representation capabilities are boosted while requiring little additional computing resources. We also present Mini-BiFPN, a small yet effective feature network that creates bidirectional information flow and multi-level cross-scale feature fusion to better integrate multi-resolution features. Our proposed framework, namely PiFeNet, has been evaluated on three popular large-scale datasets for 3D pedestrian Detection, i.e. KITTI, JRDB, and nuScenes achieving state-of-the-art (SOTA) performance on KITTI Bird-eye-view (BEV) and JRDB and very competitive performance on nuScenes. Our approach has inference speed of 26 frame-per-second (FPS), making it a real-time detector. The code for our PiFeNet is available at https://github.com/ldtho/PiFeNet.  
### LEDNet: Joint **Low-light** **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v2 [eess.IV] UPDATED)
- Authors : Shangchen Zhou, **Chongyi Li**, Chen Change
- Link : [http://arxiv.org/abs/2202.03373](http://arxiv.org/abs/2202.03373)
> ABSTRACT  :  **Night** photography typically suffers from both **low light** and blurring issues due to the dim environment and the common use of long **exposure**. While existing light **enhancement** and deblurring methods could deal with each problem individually, a cascade of such methods cannot work harmoniously to cope well with joint degradation of visibility and textures. Training an end-to-end network is also infeasible as no paired data is available to characterize the coexistence of **low light** and blurs. We address the problem by introducing a novel data synthesis pipeline that models realistic **low-light** blurring degradations. With the pipeline, we present the first large-scale dataset for joint **low-light** **enhancement** and deblurring. The dataset, LOL-Blur, contains 12,000 low-blur/normal-sharp pairs with diverse **dark**ness and motion blurs in different scenarios. We further present an effective network, named LEDNet, to perform joint **low-light** **enhancement** and deblurring. Our network is unique as it is specially designed to consider the synergy between the two inter-connected tasks. Both the proposed dataset and network provide a foundation for this challenging joint task. Extensive experiments demonstrate the effectiveness of our method on both synthetic and real-world datasets.  
### Robust RGB-D Fusion for Saliency Detection. (arXiv:2208.01762v2 [cs.CV] UPDATED)
- Authors : Zongwei Wu, Shriarulmozhivarman Gobichettipalayam, Brahim Tamadazte, Guillaume Allibert, Danda Pani, dric Demonceaux
- Link : [http://arxiv.org/abs/2208.01762](http://arxiv.org/abs/2208.01762)
> ABSTRACT  :  Efficiently exploiting multi-modal inputs for accurate RGB-D saliency detection is a topic of high interest. Most existing works leverage cross-modal interactions to fuse the two streams of RGB-D for intermediate features' **enhancement**. In this process, a practical aspect of the low quality of the available depths has not been fully considered yet. In this work, we aim for RGB-D saliency detection that is robust to the low-quality depths which primarily appear in two forms: inaccuracy due to noise and the misalignment to RGB. To this end, we propose a robust RGB-D fusion method that benefits from (1) layer-wise, and (2) trident spatial, attention mechanisms. On the one hand, layer-wise attention (LWA) learns the trade-off between early and late fusion of RGB and depth features, depending upon the depth accuracy. On the other hand, trident spatial attention (TSA) aggregates the features from a wider spatial context to address the depth misalignment problem. The proposed LWA and TSA mechanisms allow us to efficiently exploit the multi-modal inputs for saliency detection while being robust against low-quality depths. Our experiments on five benchmark datasets demonstrate that the proposed fusion method performs consistently better than the state-of-the-art fusion alternatives.  
## eess.IV
---
### Virtual impactor-based label-free bio-aerosol detection using holography and deep learning. (arXiv:2208.13979v1 [physics.app-ph])
- Authors : Yi Luo, Yijie Zhang, Tairan Liu, Alan Yu, Yichen Wu, Aydogan Ozcan
- Link : [http://arxiv.org/abs/2208.13979](http://arxiv.org/abs/2208.13979)
> ABSTRACT  :  **Exposure** to bio-aerosols such as mold spores and pollen can lead to adverse health effects. There is a need for a portable and cost-effective device for long-term monitoring and quantification of various bio-aerosols. To address this need, we present a mobile and cost-effective label-free bio-aerosol sensor that takes holographic images of flowing particulate matter concentrated by a virtual impactor, which selectively slows down and guides particles larger than ~6 microns to fly through an imaging window. The flowing particles are illuminated by a pulsed laser diode, casting their inline holograms on a CMOS image sensor in a lens-free mobile imaging device. The illumination contains three short pulses with a negligible shift of the flowing particle within one pulse, and triplicate holograms of the same particle are recorded at a single frame before it exits the imaging field-of-view, revealing different perspectives of each particle. The particles within the virtual impactor are localized through a differential detection scheme, and a deep neural network classifies the aerosol type in a label-free manner, based on the acquired holographic images. We demonstrated the success of this mobile bio-aerosol detector with a virtual impactor using different types of pollen (i.e., bermuda, elm, oak, pine, sycamore, and wheat) and achieved a blind classification accuracy of 92.91%. This mobile and cost-effective device weighs ~700 g and can be used for label-free sensing and quantification of various bio-aerosols over extended periods since it is based on a cartridge-free virtual impactor that does not capture or immobilize particulate matter.  
### Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising. (arXiv:2208.14022v1 [eess.IV])
- Authors : Ruizhou Liu, Qiang Ma, Zhiwei Cheng, Yuanyuan Lyu, Jianji Wang, Kevin Zhou
- Link : [http://arxiv.org/abs/2208.14022](http://arxiv.org/abs/2208.14022)
> ABSTRACT  :  Fluoroscopy is an imaging technique that uses X-ray to obtain a real-time 2D video of the interior of a 3D object, helping surgeons to observe pathological structures and tissue functions especially during intervention. However, it suffers from heavy noise that mainly arises from the clinical use of a low dose X-ray, thereby necessitating the technology of fluoroscopy denoising. Such denoising is challenged by the relative motion between the object being imaged and the X-ray imaging system. We tackle this challenge by proposing a self-supervised, three-stage framework that exploits the domain knowledge of fluoroscopy imaging. (i) Stabilize: we first construct a dynamic panorama based on optical flow calculation to stabilize the non-stationary background induced by the motion of the X-ray detector. (ii) Decompose: we then propose a novel mask-based Robust Principle Component Analysis (RPCA) decomposition method to separate a video with detector motion into a low-rank background and a sparse foreground. Such a decomposition accommodates the reading habit of experts. (iii) Denoise: we finally denoise the background and foreground separately by a self-supervised learning strategy and fuse the denoised parts into the final output via a **bilateral**, spatiotemporal filter. To assess the effectiveness of our work, we curate a dedicated fluoroscopy dataset of 27 videos (1,568 frames) and corresponding ground truth. Our experiments demonstrate that it achieves significant improvements in terms of denoising and **enhancement** effects when compared with standard approaches. Finally, expert rating confirms this efficacy.  
### G-SemTMO: Tone Mapping with a Trainable Semantic Graph. (arXiv:2208.14113v1 [eess.IV])
- Authors : Abhishek Goswami, Erwan Bernard, Wolf Hauser, Frederic Dufaux, **Rafal Mantiuk**
- Link : [http://arxiv.org/abs/2208.14113](http://arxiv.org/abs/2208.14113)
> ABSTRACT  :  A Tone Mapping Operator (TMO) is required to render images with a **High Dynamic Range** (**HDR**) on media with limited dynamic capabilities. TMOs compress the dynamic range with the aim of preserving the visually perceptual cues of the scene. Previous literature has established the benefits of TMOs being semantic aware, understanding the content in the scene to preserve the cues better. Expert photographers analyze the semantic and the contextual information of a scene and decide tonal transformations or local luminance adjustments. This process can be considered a manual analogy to tone mapping. In this work, we draw inspiration from an expert photographer's approach and present a Graph-based Semantic-aware Tone Mapping Operator, G-SemTMO. We leverage semantic information as well as the contextual information of the scene in the form of a graph capturing the spatial arrangements of its semantic segments. Using Graph Convolutional Network (GCN), we predict intermediate parameters called Semantic Hints and use these parameters to apply tonal adjustments locally to different semantic segments in the image. In addition, we also introduce Loc**HDR**, a dataset of 781 **HDR** images tone mapped manually by an expert photo-retoucher with local tonal **enhancement**s. We conduct ablation studies to show that our approach, G-SemTMO\footnote{Code and dataset to be published with the final version of the manuscript}, can learn both global and local tonal transformations from a pair of input linear and manually retouched images by leveraging the semantic graphs and produce better results than both classical and learning based TMOs. We also conduct ablation experiments to validate the advantage of using GCN.  
### LEDNet: Joint **Low-light** **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v2 [eess.IV] UPDATED)
- Authors : Shangchen Zhou, **Chongyi Li**, Chen Change
- Link : [http://arxiv.org/abs/2202.03373](http://arxiv.org/abs/2202.03373)
> ABSTRACT  :  **Night** photography typically suffers from both **low light** and blurring issues due to the dim environment and the common use of long **exposure**. While existing light **enhancement** and deblurring methods could deal with each problem individually, a cascade of such methods cannot work harmoniously to cope well with joint degradation of visibility and textures. Training an end-to-end network is also infeasible as no paired data is available to characterize the coexistence of **low light** and blurs. We address the problem by introducing a novel data synthesis pipeline that models realistic **low-light** blurring degradations. With the pipeline, we present the first large-scale dataset for joint **low-light** **enhancement** and deblurring. The dataset, LOL-Blur, contains 12,000 low-blur/normal-sharp pairs with diverse **dark**ness and motion blurs in different scenarios. We further present an effective network, named LEDNet, to perform joint **low-light** **enhancement** and deblurring. Our network is unique as it is specially designed to consider the synergy between the two inter-connected tasks. Both the proposed dataset and network provide a foundation for this challenging joint task. Extensive experiments demonstrate the effectiveness of our method on both synthetic and real-world datasets.  
## cs.LG
---
### Inferring subhalo effective density slopes from strong lensing observations with neural likelihood-ratio estimation. (arXiv:2208.13796v1 [astro-ph.CO])
- Authors : Gemma Zhang, Siddharth Mishra, Cora Dvorkin
- Link : [http://arxiv.org/abs/2208.13796](http://arxiv.org/abs/2208.13796)
> ABSTRACT  :  Strong gravitational lensing has emerged as a promising approach for probing **dark** matter models on sub-galactic scales. Recent work has proposed the subhalo effective density slope as a more reliable observable than the commonly used subhalo mass function. The subhalo effective density slope is a measurement independent of assumptions about the underlying density profile and can be inferred for individual subhalos through traditional sampling methods. To go beyond individual subhalo measurements, we leverage recent advances in machine learning and introduce a neural likelihood-ratio estimator to infer an effective density slope for populations of subhalos. We demonstrate that our method is capable of harnessing the statistical power of multiple subhalos (within and across multiple images) to distinguish between characteristics of different subhalo populations. The computational efficiency warranted by the neural likelihood-ratio estimator over traditional sampling enables statistical studies of **dark** matter perturbers and is particularly useful as we expect an influx of strong lensing systems from upcoming surveys.  
### Virtual impactor-based label-free bio-aerosol detection using holography and deep learning. (arXiv:2208.13979v1 [physics.app-ph])
- Authors : Yi Luo, Yijie Zhang, Tairan Liu, Alan Yu, Yichen Wu, Aydogan Ozcan
- Link : [http://arxiv.org/abs/2208.13979](http://arxiv.org/abs/2208.13979)
> ABSTRACT  :  **Exposure** to bio-aerosols such as mold spores and pollen can lead to adverse health effects. There is a need for a portable and cost-effective device for long-term monitoring and quantification of various bio-aerosols. To address this need, we present a mobile and cost-effective label-free bio-aerosol sensor that takes holographic images of flowing particulate matter concentrated by a virtual impactor, which selectively slows down and guides particles larger than ~6 microns to fly through an imaging window. The flowing particles are illuminated by a pulsed laser diode, casting their inline holograms on a CMOS image sensor in a lens-free mobile imaging device. The illumination contains three short pulses with a negligible shift of the flowing particle within one pulse, and triplicate holograms of the same particle are recorded at a single frame before it exits the imaging field-of-view, revealing different perspectives of each particle. The particles within the virtual impactor are localized through a differential detection scheme, and a deep neural network classifies the aerosol type in a label-free manner, based on the acquired holographic images. We demonstrated the success of this mobile bio-aerosol detector with a virtual impactor using different types of pollen (i.e., bermuda, elm, oak, pine, sycamore, and wheat) and achieved a blind classification accuracy of 92.91%. This mobile and cost-effective device weighs ~700 g and can be used for label-free sensing and quantification of various bio-aerosols over extended periods since it is based on a cartridge-free virtual impactor that does not capture or immobilize particulate matter.  
### Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning. (arXiv:2201.12356v2 [cs.LG] UPDATED)
- Authors : Jie Zhang, **Lei Zhang**, Gang Li, Chao Wu
- Link : [http://arxiv.org/abs/2201.12356](http://arxiv.org/abs/2201.12356)
> ABSTRACT  :  Adversarial examples are inputs for machine learning models that have been designed by attackers to cause the model to make mistakes. In this paper, we demonstrate that adversarial examples can also be utilized for good to improve the performance of imbalanced learning. We provide a new perspective on how to deal with imbalanced data: adjust the biased decision boundary by training with Guiding Adversarial Examples (GAEs). Our method can effectively increase the accuracy of minority classes while sacrificing little accuracy on majority classes. We empirically show, on several benchmark datasets, our proposed method is comparable to the state-of-the-art method. To our best knowledge, we are the first to deal with imbalanced learning with adversarial examples.  
### Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v2 [cs.IR] UPDATED)
- Authors : Yuta Saito, Thorsten Joachims
- Link : [http://arxiv.org/abs/2206.07247](http://arxiv.org/abs/2206.07247)
> ABSTRACT  :  Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates **exposure** -- and thus economic opportunity -- to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item **exposure** to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond **exposure**. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional **exposure**-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.  
### Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v2 [cs.LG] UPDATED)
- Authors : Hsiang Chiu, Manfred Huber
- Link : [http://arxiv.org/abs/2208.04822](http://arxiv.org/abs/2208.04822)
> ABSTRACT  :  Learning a control policy capable of adapting to time-varying and potentially evolving system dynamics has been a great challenge to the mainstream reinforcement learning (RL). Mainly, the ever-changing system properties would continuously affect how the RL agent interacts with the state space through its actions, which effectively (re-)introduces concept drifts to the underlying policy learning process. We postulated that higher adaptability for the control policy can be achieved by characterizing and representing actions with extra "degrees of freedom" and thereby, with greater flexibility, adjusts to variations from the action's "behavioral" outcomes, including how these actions get carried out in **real time** and the shift in the action set itself. This paper proposes a Bayesian-flavored generalized RL framework by first establishing the notion of parametric action model to better cope with uncertainty and fluid action behaviors, followed by introducing the notion of reinforcement field as a physics-inspired construct established through "polarized experience particles" maintained in the RL agent's working memory. These particles effectively encode the agent's dynamic learning experience that evolves over time in a self-organizing way. Using the reinforcement field as a substrate, we will further generalize the policy search to incorporate high-level decision concepts by viewing the past memory as an implicit graph structure, in which the memory instances, or particles, are interconnected with their degrees of associability/similarity defined and quantified such that the "associative memory" principle can be consistently applied to establish and augment the learning agent's evolving world model.  
## cs.AI
---
### Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning. (arXiv:2201.12356v2 [cs.LG] UPDATED)
- Authors : Jie Zhang, **Lei Zhang**, Gang Li, Chao Wu
- Link : [http://arxiv.org/abs/2201.12356](http://arxiv.org/abs/2201.12356)
> ABSTRACT  :  Adversarial examples are inputs for machine learning models that have been designed by attackers to cause the model to make mistakes. In this paper, we demonstrate that adversarial examples can also be utilized for good to improve the performance of imbalanced learning. We provide a new perspective on how to deal with imbalanced data: adjust the biased decision boundary by training with Guiding Adversarial Examples (GAEs). Our method can effectively increase the accuracy of minority classes while sacrificing little accuracy on majority classes. We empirically show, on several benchmark datasets, our proposed method is comparable to the state-of-the-art method. To our best knowledge, we are the first to deal with imbalanced learning with adversarial examples.  
### Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v2 [cs.IR] UPDATED)
- Authors : Yuta Saito, Thorsten Joachims
- Link : [http://arxiv.org/abs/2206.07247](http://arxiv.org/abs/2206.07247)
> ABSTRACT  :  Rankings have become the primary interface in two-sided online markets. Many have noted that the rankings not only affect the satisfaction of the users (e.g., customers, listeners, employers, travelers), but that the position in the ranking allocates **exposure** -- and thus economic opportunity -- to the ranked items (e.g., articles, products, songs, job seekers, restaurants, hotels). This has raised questions of fairness to the items, and most existing works have addressed fairness by explicitly linking item **exposure** to item relevance. However, we argue that any particular choice of such a link function may be difficult to defend, and we show that the resulting rankings can still be unfair. To avoid these shortcomings, we develop a new axiomatic approach that is rooted in principles of fair division. This not only avoids the need to choose a link function, but also more meaningfully quantifies the impact on the items beyond **exposure**. Our axioms of envy-freeness and dominance over uniform ranking postulate that for a fair ranking policy every item should prefer their own rank allocation over that of any other item, and that no item should be actively disadvantaged by the rankings. To compute ranking policies that are fair according to these axioms, we propose a new ranking objective related to the Nash Social Welfare. We show that the solution has guarantees regarding its envy-freeness, its dominance over uniform rankings for every item, and its Pareto optimality. In contrast, we show that conventional **exposure**-based fairness can produce large amounts of envy and have a highly disparate impact on the items. Beyond these theoretical results, we illustrate empirically how our framework controls the trade-off between impact-based individual item fairness and user utility.  
### Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v2 [cs.LG] UPDATED)
- Authors : Hsiang Chiu, Manfred Huber
- Link : [http://arxiv.org/abs/2208.04822](http://arxiv.org/abs/2208.04822)
> ABSTRACT  :  Learning a control policy capable of adapting to time-varying and potentially evolving system dynamics has been a great challenge to the mainstream reinforcement learning (RL). Mainly, the ever-changing system properties would continuously affect how the RL agent interacts with the state space through its actions, which effectively (re-)introduces concept drifts to the underlying policy learning process. We postulated that higher adaptability for the control policy can be achieved by characterizing and representing actions with extra "degrees of freedom" and thereby, with greater flexibility, adjusts to variations from the action's "behavioral" outcomes, including how these actions get carried out in **real time** and the shift in the action set itself. This paper proposes a Bayesian-flavored generalized RL framework by first establishing the notion of parametric action model to better cope with uncertainty and fluid action behaviors, followed by introducing the notion of reinforcement field as a physics-inspired construct established through "polarized experience particles" maintained in the RL agent's working memory. These particles effectively encode the agent's dynamic learning experience that evolves over time in a self-organizing way. Using the reinforcement field as a substrate, we will further generalize the policy search to incorporate high-level decision concepts by viewing the past memory as an implicit graph structure, in which the memory instances, or particles, are interconnected with their degrees of associability/similarity defined and quantified such that the "associative memory" principle can be consistently applied to establish and augment the learning agent's evolving world model.  
# Paper List
---
## cs.CV
---
**88** new papers in cs.CV:-) 
1. Boundary-Aware Network for Abdominal Multi-Organ Segmentation. (arXiv:2208.13774v1 [cs.CV])
2. Synthetic Latent Fingerprint Generator. (arXiv:2208.13811v1 [cs.CV])
3. Perfusion assessment via local remote photoplethysmography (rPPG). (arXiv:2208.13840v1 [cs.CV])
4. Radial Prediction Domain Adaption Classifier for the MIDOG 2022 challenge. (arXiv:2208.13902v1 [cs.CV])
5. SB-SSL: Slice-Based Self-Supervised Transformers for Knee Abnormality Classification from MRI. (arXiv:2208.13923v1 [eess.IV])
6. Noisy Inliers Make Great Outliers: Out-of-Distribution Object Detection with Noisy Synthetic Outliers. (arXiv:2208.13930v1 [cs.CV])
7. CUAHN-VIO: Content-and-Uncertainty-Aware Homography Network for Visual-Inertial Odometry. (arXiv:2208.13935v1 [cs.RO])
8. Prior-Aware Synthetic Data to the Rescue: Animal Pose Estimation with Very Limited Real Data. (arXiv:2208.13944v1 [cs.CV])
9. PercentMatch: Percentile-based Dynamic Thresholding for Multi-Label Semi-Supervised Classification. (arXiv:2208.13946v1 [cs.CV])
10. Video-based Cross-modal Auxiliary Network for Multimodal Sentiment Analysis. (arXiv:2208.13954v1 [cs.CV])
11. Learned Lossless Image Compression With Combined Autoregressive Models And Attention Modules. (arXiv:2208.13974v1 [eess.IV])
12. MRL: Learning to Mix with Attention and Convolutions. (arXiv:2208.13975v1 [cs.CV])
13. Uncertainty-Induced Transferability Representation for Source-Free Unsupervised Domain Adaptation. (arXiv:2208.13986v1 [cs.CV])
14. Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising. (arXiv:2208.14022v1 [eess.IV])
15. SoMoFormer: Multi-Person Pose Forecasting with Transformers. (arXiv:2208.14023v1 [cs.CV])
16. Spacecraft depth completion based on the gray image and the sparse depth map. (arXiv:2208.14030v1 [cs.CV])
17. CAIR: Fast and Lightweight Multi-Scale Color Attention Network for Instagram Filter Removal. (arXiv:2208.14039v1 [cs.CV])
18. Deep Autoencoders for Anomaly Detection in Textured Images using CW-SSIM. (arXiv:2208.14045v1 [cs.CV])
19. Weakly Supervised Faster-RCNN+FPN to classify animals in camera trap images. (arXiv:2208.14060v1 [cs.CV])
20. Deep Open-Set Recognition for Silicon Wafer Production Monitoring. (arXiv:2208.14071v1 [cs.CV])
21. Treating Point Cloud as Moving Camera Videos: A No-Reference Quality Assessment Metric. (arXiv:2208.14085v1 [cs.CV])
22. SSORN: Self-Supervised Outlier Removal Network for Robust Homography Estimation. (arXiv:2208.14093v1 [cs.CV])
23. Robust Sound-Guided Image Manipulation. (arXiv:2208.14114v1 [cs.CV])
24. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v1 [cs.CV])
25. Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models. (arXiv:2208.14133v1 [cs.LG])
26. Airway measurement by refinement of synthetic images improves mortality prediction in idiopathic pulmonary fibrosis. (arXiv:2208.14141v1 [eess.IV])
27. FAKD: Feature Augmented Knowledge Distillation for Semantic Segmentation. (arXiv:2208.14143v1 [cs.CV])
28. MODNet: Multi-offset Point Cloud Denoising Network Customized for Multi-scale Patches. (arXiv:2208.14160v1 [cs.CV])
29. Synthehicle: Multi-Vehicle Multi-Camera Tracking in Virtual Cities. (arXiv:2208.14167v1 [cs.CV])
30. Probing Contextual Diversity for Dense Out-of-Distribution Detection. (arXiv:2208.14195v1 [cs.CV])
31. ASpanFormer: Detector-Free Image Matching with Adaptive Span Transformer. (arXiv:2208.14201v1 [cs.CV])
32. FUSION: Fully Unsupervised Test-Time Stain Adaptation via Fused Normalization Statistics. (arXiv:2208.14206v1 [eess.IV])
33. A Circular Window-based Cascade Transformer for Online Action Detection. (arXiv:2208.14209v1 [cs.CV])
34. CLUDA : Contrastive Learning in Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2208.14227v1 [cs.CV])
35. Boosting **Night**-time Scene Parsing with Learnable Frequency. (arXiv:2208.14241v1 [cs.CV])
36. Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance. (arXiv:2208.14263v1 [cs.CV])
37. Learning 6D Pose Estimation from Synthetic RGBD Images for Robotic Applications. (arXiv:2208.14288v1 [cs.CV])
38. Coarse Retinal Lesion Annotations Refinement via Prototypical Learning. (arXiv:2208.14294v1 [cs.CV])
39. PanorAMS: Automatic Annotation for Detecting Objects in Urban Context. (arXiv:2208.14295v1 [cs.CV])
40. A Black-Box Attack on Optical Character Recognition Systems. (arXiv:2208.14302v1 [cs.CV])
41. GaitFi: Robust Device-Free Human Identification via WiFi and Vision Multimodal Learning. (arXiv:2208.14326v1 [cs.CV])
42. On the Automated Segmentation of Epicardial and Mediastinal Cardiac Adipose Tissues Using Classification Algorithms. (arXiv:2208.14352v1 [eess.IV])
43. Compound Figure Separation of Biomedical Images: Mining Large Datasets for Self-supervised Learning. (arXiv:2208.14357v1 [cs.CV])
44. FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain. (arXiv:2208.14360v1 [eess.IV])
45. AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels. (arXiv:2208.14362v1 [cs.LG])
46. Image-Specific Information Suppression and Implicit Local Alignment for Text-based Person Search. (arXiv:2208.14365v1 [cs.CV])
47. SIGNet: Intrinsic Image Decomposition by a Semantic and Invariant Gradient Driven Network for Indoor Scenes. (arXiv:2208.14369v1 [cs.CV])
48. Machine learning in the prediction of cardiac epicardial and mediastinal fat volumes. (arXiv:2208.14374v1 [cs.CV])
49. Automated recognition of the pericardium contour on processed CT images using genetic algorithms. (arXiv:2208.14375v1 [eess.IV])
50. Verifiable Obstacle Detection. (arXiv:2208.14403v1 [cs.RO])
51. Comparing Results of Thermographic Images Based Diagnosis for Breast Diseases. (arXiv:2208.14410v1 [eess.IV])
52. A Portable Multiscopic Camera for Novel View and Time Synthesis in Dynamic Scenes. (arXiv:2208.14433v1 [cs.CV])
53. MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction. (arXiv:2208.14437v1 [cs.CV])
54. Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond. (arXiv:2208.14439v1 [cs.CV])
55. Contrast **Enhancement** of Brightness-Distorted Images by Improved Adaptive Gamma Correction. (arXiv:1709.04427v2 [cs.MM] UPDATED)
56. Acceleration of Histogram-Based Contrast **Enhancement** via Selective Downsampling. (arXiv:1709.04583v3 [cs.MM] UPDATED)
57. Implicit Regularization and Convergence for Weight Normalization. (arXiv:1911.07956v5 [cs.LG] UPDATED)
58. Deep Reinforced Attention Learning for Quality-Aware Visual Recognition. (arXiv:2007.06156v2 [cs.CV] UPDATED)
59. Ranking Neural Checkpoints. (arXiv:2011.11200v4 [cs.LG] UPDATED)
60. MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis. (arXiv:2107.06149v4 [cs.CV] UPDATED)
61. Hyperdimensional Feature Fusion for Out-Of-Distribution Detection. (arXiv:2112.05341v3 [cs.CV] UPDATED)
62. MetaGraspNet_v0: A Large-Scale Benchmark Dataset for Vision-driven Robotic Grasping via Physics-based Metaverse Synthesis. (arXiv:2112.14663v3 [cs.CV] UPDATED)
63. Accurate and **Real-time** 3D Pedestrian Detection Using an Efficient Attentive Pillar Network. (arXiv:2112.15458v2 [cs.CV] UPDATED)
64. LEDNet: Joint **Low-light** **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v2 [eess.IV] UPDATED)
65. Universal Representations: A Unified Look at Multiple Task and Domain Learning. (arXiv:2204.02744v2 [cs.CV] UPDATED)
66. What Matters in Language Conditioned Robotic Imitation Learning over Unstructured Data. (arXiv:2204.06252v2 [cs.RO] UPDATED)
67. Sound-Guided Semantic Video Generation. (arXiv:2204.09273v3 [cs.CV] UPDATED)
68. Adversarial Scratches: Deployable Attacks to CNN Classifiers. (arXiv:2204.09397v2 [cs.LG] UPDATED)
69. Shadow-Aware Dynamic Convolution for Shadow Removal. (arXiv:2205.04908v3 [cs.CV] UPDATED)
70. Arbitrary Shape Text Detection via Boundary Transformer. (arXiv:2205.05320v2 [cs.CV] UPDATED)
71. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v3 [cs.CV] UPDATED)
72. Clustering as Attention: Unified Image Segmentation with Hierarchical Clustering. (arXiv:2205.09949v2 [cs.CV] UPDATED)
73. Texture Extraction Methods Based Ensembling Framework for Improved Classification. (arXiv:2206.04158v2 [cs.CV] UPDATED)
74. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v2 [cs.LG] UPDATED)
75. SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving. (arXiv:2206.14116v2 [cs.CV] UPDATED)
76. Detecting and Recovering Adversarial Examples from Extracting Non-robust and Highly Predictive Adversarial Perturbations. (arXiv:2206.15128v2 [cs.CV] UPDATED)
77. DeepPS2: Revisiting Photometric Stereo Using Two Differently Illuminated Images. (arXiv:2207.02025v2 [cs.CV] UPDATED)
78. Multi-Task Learning Framework for Emotion Recognition in-the-wild. (arXiv:2207.09373v3 [cs.CV] UPDATED)
79. Robust RGB-D Fusion for Saliency Detection. (arXiv:2208.01762v2 [cs.CV] UPDATED)
80. Conviformers: Convolutionally guided Vision Transformer. (arXiv:2208.08900v2 [cs.CV] UPDATED)
81. Semi-supervised Semantic Segmentation with Mutual Knowledge Distillation. (arXiv:2208.11499v2 [cs.CV] UPDATED)
82. Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task. (arXiv:2208.12037v2 [cs.CV] UPDATED)
83. CMD: Self-supervised 3D Action Representation Learning with Cross-modal Mutual Distillation. (arXiv:2208.12448v2 [cs.CV] UPDATED)
84. MORI-RAN: Multi-view Robust Representation Learning via Hybrid Contrastive Fusion. (arXiv:2208.12545v2 [cs.CV] UPDATED)
85. JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents. (arXiv:2208.13266v2 [cs.AI] UPDATED)
86. SphereDepth: Panorama Depth Estimation from Spherical Domain. (arXiv:2208.13714v2 [cs.CV] UPDATED)
87. Effective Image Tampering Localization via Semantic Segmentation Network. (arXiv:2208.13739v2 [cs.CV] UPDATED)
88. StableFace: Analyzing and Improving Motion Stability for Talking Face Generation. (arXiv:2208.13717v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**17** new papers in eess.IV:-) 
1. SB-SSL: Slice-Based Self-Supervised Transformers for Knee Abnormality Classification from MRI. (arXiv:2208.13923v1 [eess.IV])
2. Airway Tree Modeling Using Dual-channel 3D UNet 3+ with Vesselness Prior. (arXiv:2208.13969v1 [eess.IV])
3. Learned Lossless Image Compression With Combined Autoregressive Models And Attention Modules. (arXiv:2208.13974v1 [eess.IV])
4. Virtual impactor-based label-free bio-aerosol detection using holography and deep learning. (arXiv:2208.13979v1 [physics.app-ph])
5. EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks. (arXiv:2208.14003v1 [eess.IV])
6. Stabilize, Decompose, and Denoise: Self-Supervised Fluoroscopy Denoising. (arXiv:2208.14022v1 [eess.IV])
7. Treating Point Cloud as Moving Camera Videos: A No-Reference Quality Assessment Metric. (arXiv:2208.14085v1 [cs.CV])
8. G-SemTMO: Tone Mapping with a Trainable Semantic Graph. (arXiv:2208.14113v1 [eess.IV])
9. Airway measurement by refinement of synthetic images improves mortality prediction in idiopathic pulmonary fibrosis. (arXiv:2208.14141v1 [eess.IV])
10. FUSION: Fully Unsupervised Test-Time Stain Adaptation via Fused Normalization Statistics. (arXiv:2208.14206v1 [eess.IV])
11. On the Automated Segmentation of Epicardial and Mediastinal Cardiac Adipose Tissues Using Classification Algorithms. (arXiv:2208.14352v1 [eess.IV])
12. FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain. (arXiv:2208.14360v1 [eess.IV])
13. Deep Spatial and Tonal Optimisation for Diffusion Inpainting. (arXiv:2208.14371v1 [eess.IV])
14. Automated recognition of the pericardium contour on processed CT images using genetic algorithms. (arXiv:2208.14375v1 [eess.IV])
15. Expert Opinion Elicitation for Assisting Deep Learning based Lyme Disease Classifier with Patient Data. (arXiv:2208.14384v1 [cs.AI])
16. Comparing Results of Thermographic Images Based Diagnosis for Breast Diseases. (arXiv:2208.14410v1 [eess.IV])
17. LEDNet: Joint **Low-light** **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v2 [eess.IV] UPDATED)
## cs.LG
---
**138** new papers in cs.LG:-) 
1. Fast Bayesian Optimization of Needle-in-a-Haystack Problems using Zooming Memory-Based Initialization. (arXiv:2208.13771v1 [cs.LG])
2. Modeling Spatial Trajectories using Coarse-Grained Smartphone Logs. (arXiv:2208.13775v1 [cs.LG])
3. Attention-based Interpretable Regression of Gene Expression in Histology. (arXiv:2208.13776v1 [q-bio.QM])
4. Rosenblatt's first theorem and frugality of deep learning. (arXiv:2208.13778v1 [cs.LG])
5. Autoinverse: Uncertainty Aware Inversion of Neural Networks. (arXiv:2208.13780v1 [cs.LG])
6. Dimension Independent Data Sets Approximation and Applications to Classification. (arXiv:2208.13781v1 [cs.LG])
7. Inferring subhalo effective density slopes from strong lensing observations with neural likelihood-ratio estimation. (arXiv:2208.13796v1 [astro-ph.CO])
8. DR-DSGD: A Distributionally Robust Decentralized Learning Algorithm over Graphs. (arXiv:2208.13810v1 [cs.LG])
9. Differentiable Programming for Earth System Modeling. (arXiv:2208.13825v1 [cs.LG])
10. PGNAA Spectral Classification of Metal with Density Estimations. (arXiv:2208.13836v1 [cs.LG])
11. Towards Adversarial Purification using Denoising AutoEncoders. (arXiv:2208.13838v1 [cs.LG])
12. Perfusion assessment via local remote photoplethysmography (rPPG). (arXiv:2208.13840v1 [cs.CV])
13. Inference and Optimization for Engineering and Physical Systems. (arXiv:2208.13880v1 [cs.LG])
14. Reinforcement Learning for Hardware Security: Opportunities, Developments, and Challenges. (arXiv:2208.13885v1 [cs.CR])
15. Data Isotopes for Data Provenance in DNNs. (arXiv:2208.13893v1 [cs.CR])
16. Conjugate Natural Selection. (arXiv:2208.13898v1 [cs.LG])
17. Reducing Certified Regression to Certified Classification. (arXiv:2208.13904v1 [cs.LG])
18. "Prompt-Gamma Neutron Activation Analysis (PGNAA)" Metal Spectral Classification using Deep Learning Method. (arXiv:2208.13909v1 [cs.LG])
19. Finite Sample Identification of Bilinear Dynamical Systems. (arXiv:2208.13915v1 [cs.LG])
20. SB-SSL: Slice-Based Self-Supervised Transformers for Knee Abnormality Classification from MRI. (arXiv:2208.13923v1 [eess.IV])
21. Exploring and Evaluating Personalized Models for Code Generation. (arXiv:2208.13928v1 [cs.SE])
22. Using Taylor-Approximated Gradients to Improve the Frank-Wolfe Method for Empirical Risk Minimization. (arXiv:2208.13933v1 [cs.LG])
23. CUAHN-VIO: Content-and-Uncertainty-Aware Homography Network for Visual-Inertial Odometry. (arXiv:2208.13935v1 [cs.RO])
24. The case for fully Bayesian optimisation in small-sample trials. (arXiv:2208.13960v1 [cs.LG])
25. Neural Architecture Search for Improving Latency-Accuracy Trade-off in Split Computing. (arXiv:2208.13968v1 [cs.LG])
26. Airway Tree Modeling Using Dual-channel 3D UNet 3+ with Vesselness Prior. (arXiv:2208.13969v1 [eess.IV])
27. MRL: Learning to Mix with Attention and Convolutions. (arXiv:2208.13975v1 [cs.CV])
28. Virtual impactor-based label-free bio-aerosol detection using holography and deep learning. (arXiv:2208.13979v1 [physics.app-ph])
29. HiGNN: Hierarchical Informative Graph Neural Networks for Molecular Property Prediction Equipped with Feature-Wise Attention. (arXiv:2208.13994v1 [cs.LG])
30. EchoGNN: Explainable Ejection Fraction Estimation with Graph Neural Networks. (arXiv:2208.14003v1 [eess.IV])
31. Finding neural signatures for obesity using source-localized EEG features. (arXiv:2208.14007v1 [cs.LG])
32. Prediction of Red Wine Quality Using One-dimensional Convolutional Neural Networks. (arXiv:2208.14008v1 [cs.LG])
33. Anomaly Detection using Contrastive Normalizing Flows. (arXiv:2208.14024v1 [cs.LG])
34. Deep Autoencoders for Anomaly Detection in Textured Images using CW-SSIM. (arXiv:2208.14045v1 [cs.CV])
35. A Deep Neural Networks ensemble workflow from hyperparameter search to inference leveraging GPU clusters. (arXiv:2208.14046v1 [cs.LG])
36. An efficient and flexible inference system for serving heterogeneous ensembles of deep neural networks. (arXiv:2208.14049v1 [cs.DC])
37. Symmetric Pruning in Quantum Neural Networks. (arXiv:2208.14057v1 [quant-ph])
38. Weakly Supervised Faster-RCNN+FPN to classify animals in camera trap images. (arXiv:2208.14060v1 [cs.CV])
39. A Self-supervised Riemannian GNN with Time Varying Curvature for Temporal Graph Learning. (arXiv:2208.14073v1 [cs.LG])
40. Effective Multi-User Delay-Constrained Scheduling with Deep Recurrent Reinforcement Learning. (arXiv:2208.14074v1 [cs.LG])
41. Super-model ecosystem: A domain-adaptation perspective. (arXiv:2208.14092v1 [cs.LG])
42. Towards making the most of NLP-based device mapping optimization for OpenCL kernels. (arXiv:2208.14124v1 [cs.LG])
43. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v1 [cs.CV])
44. Deep Generative Modeling on Limited Data with Regularization by Nontransferable Pre-trained Models. (arXiv:2208.14133v1 [cs.LG])
45. On the Trade-Off between Actionable Explanations and the Right to be Forgotten. (arXiv:2208.14137v1 [cs.LG])
46. Leap-frog neural network for learning the symplectic evolution from partitioned data. (arXiv:2208.14148v1 [astro-ph.EP])
47. Weight-variant Latent Causal Models. (arXiv:2208.14153v1 [cs.LG])
48. Identifying Latent Causal Content for Multi-Source Domain Adaptation. (arXiv:2208.14161v1 [cs.LG])
49. RAGUEL: Recourse-Aware Group Unfairness Elimination. (arXiv:2208.14175v1 [cs.LG])
50. FuncFooler: A Practical Black-box Attack Against Learning-based Binary Code Similarity Detection Methods. (arXiv:2208.14191v1 [cs.CR])
51. A Comprehensive Review of Digital Twin -- Part 1: Modeling and Twinning Enabling Technologies. (arXiv:2208.14197v1 [cs.CE])
52. FUSION: Fully Unsupervised Test-Time Stain Adaptation via Fused Normalization Statistics. (arXiv:2208.14206v1 [eess.IV])
53. Learned k-NN Distance Estimation. (arXiv:2208.14210v1 [cs.DB])
54. Tackling Multimodal Device Distributions in Inverse Photonic Design using Invertible Neural Networks. (arXiv:2208.14212v1 [cs.LG])
55. Unsupervised Representation Learning in Deep Reinforcement Learning: A Review. (arXiv:2208.14226v1 [cs.LG])
56. Prediction-based One-shot Dynamic Parking Pricing. (arXiv:2208.14231v1 [cs.LG])
57. Persistence Initialization: A novel adaptation of the Transformer architecture for Time Series Forecasting. (arXiv:2208.14236v1 [cs.LG])
58. Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents. (arXiv:2208.14244v1 [cs.CL])
59. ANT: Exploiting Adaptive Numerical Data Type for Low-bit Deep Neural Network Quantization. (arXiv:2208.14286v1 [cs.LG])
60. A Black-Box Attack on Optical Character Recognition Systems. (arXiv:2208.14302v1 [cs.CV])
61. Beyond Supervised Continual Learning: a Review. (arXiv:2208.14307v1 [cs.LG])
62. Modeling Volatility and Dependence of European Carbon and Energy Prices. (arXiv:2208.14311v1 [q-fin.ST])
63. Convergence Rates of Training Deep Neural Networks via Alternating Minimization Methods. (arXiv:2208.14318v1 [cs.LG])
64. Learning Representations for Hyper-Relational Knowledge Graphs. (arXiv:2208.14322v1 [cs.LG])
65. Denoising Architecture for Unsupervised Anomaly Detection in Time-Series. (arXiv:2208.14337v1 [cs.LG])
66. Distributed Ensembles of Reinforcement Learning Agents for Electricity Control. (arXiv:2208.14338v1 [cs.LG])
67. Analysis of Distributed Deep Learning in the Cloud. (arXiv:2208.14344v1 [cs.LG])
68. MeloForm: Generating Melody with Musical Form based on Expert Systems and Neural Networks. (arXiv:2208.14345v1 [cs.SD])
69. On the Automated Segmentation of Epicardial and Mediastinal Cardiac Adipose Tissues Using Classification Algorithms. (arXiv:2208.14352v1 [eess.IV])
70. FAST-AID Brain: Fast and Accurate Segmentation Tool using Artificial Intelligence Developed for Brain. (arXiv:2208.14360v1 [eess.IV])
71. AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels. (arXiv:2208.14362v1 [cs.LG])
72. Machine learning in the prediction of cardiac epicardial and mediastinal fat volumes. (arXiv:2208.14374v1 [cs.CV])
73. Automated recognition of the pericardium contour on processed CT images using genetic algorithms. (arXiv:2208.14375v1 [eess.IV])
74. Associative Learning for Network Embedding. (arXiv:2208.14376v1 [cs.LG])
75. Application of Convolutional Neural Networks with Quasi-Reversibility Method Results for Option Forecasting. (arXiv:2208.14385v1 [q-fin.ST])
76. k-MS: A novel clustering algorithm based on morphological reconstruction. (arXiv:2208.14390v1 [cs.LG])
77. Evolutionary Deep Reinforcement Learning for Dynamic Slice Management in O-RAN. (arXiv:2208.14394v1 [eess.SY])
78. An Analysis of Abstracted Model-Based Reinforcement Learning. (arXiv:2208.14407v1 [cs.LG])
79. FDB: Fraud Dataset Benchmark. (arXiv:2208.14417v1 [cs.LG])
80. Competition, Alignment, and Equilibria in Digital Marketplaces. (arXiv:2208.14423v1 [cs.GT])
81. Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond. (arXiv:2208.14439v1 [cs.CV])
82. Block Mean Approximation for Efficient Second Order Optimization. (arXiv:1804.05484v4 [cs.LG] UPDATED)
83. Discriminative Learning of Similarity and Group Equivariant Representations. (arXiv:1808.10078v2 [stat.ML] UPDATED)
84. A deep learning-based remaining useful life prediction approach for bearings. (arXiv:1812.03315v2 [cs.LG] UPDATED)
85. A General End-to-end Diagnosis Framework for Manufacturing Systems. (arXiv:1901.02057v2 [cs.LG] UPDATED)
86. Optimal Rates for Distributed Learning with Random Features. (arXiv:1906.03155v4 [cs.LG] UPDATED)
87. Implicit Regularization and Convergence for Weight Normalization. (arXiv:1911.07956v5 [cs.LG] UPDATED)
88. Community recovery in non-binary and temporal stochastic block models. (arXiv:2008.04790v5 [math.ST] UPDATED)
89. Automatic Feasibility Study via Data Quality Analysis for ML: A Case-Study on Label Noise. (arXiv:2010.08410v4 [cs.LG] UPDATED)
90. Ranking Neural Checkpoints. (arXiv:2011.11200v4 [cs.LG] UPDATED)
91. Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization. (arXiv:2103.17182v5 [cs.LG] UPDATED)
92. TAG: Task-based Accumulated Gradients for Lifelong learning. (arXiv:2105.05155v3 [cs.LG] UPDATED)
93. Achieving Fairness with a Simple Ridge Penalty. (arXiv:2105.13817v3 [cs.LG] UPDATED)
94. A Discontinuity Capturing Shallow Neural Network for Elliptic Interface Problems. (arXiv:2106.05587v3 [math.NA] UPDATED)
95. Graph Contrastive Learning for Anomaly Detection. (arXiv:2108.07516v3 [cs.LG] UPDATED)
96. A Data-Centric Optimization Framework for Machine Learning. (arXiv:2110.10802v3 [cs.LG] UPDATED)
97. Offline Reinforcement Learning: Fundamental Barriers for Value Function Approximation. (arXiv:2111.10919v2 [cs.LG] UPDATED)
98. AtteSTNet -- An attention and subword tokenization based approach for code-switched text hate speech detection. (arXiv:2112.11479v2 [cs.CL] UPDATED)
99. A Non-Classical Parameterization for Density Estimation Using Sample Moments. (arXiv:2201.04786v3 [stat.ML] UPDATED)
100. Solving a directed percolation inverse problem. (arXiv:2201.12222v4 [cond-mat.dis-nn] UPDATED)
101. Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning. (arXiv:2201.12356v2 [cs.LG] UPDATED)
102. A Survey on Deep Graph Generation: Methods and Applications. (arXiv:2203.06714v2 [cs.LG] UPDATED)
103. Solving parametric partial differential equations with deep rectified quadratic unit neural networks. (arXiv:2203.06973v2 [math.NA] UPDATED)
104. Modelling variability in vibration-based PBSHM via a generalised population form. (arXiv:2203.07115v2 [cs.LG] UPDATED)
105. Comparing Two Samples Through Stochastic Dominance: A Graphical Approach. (arXiv:2203.07889v4 [stat.ML] UPDATED)
106. Learning Spatiotemporal Chaos Using Next-Generation Reservoir Computing. (arXiv:2203.13294v3 [cs.LG] UPDATED)
107. SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks. (arXiv:2203.13913v3 [cs.LG] UPDATED)
108. Independent Natural Policy Gradient Methods for Potential Games: Finite-time Global Convergence with Entropy Regularization. (arXiv:2204.05466v2 [math.OC] UPDATED)
109. Adversarial Scratches: Deployable Attacks to CNN Classifiers. (arXiv:2204.09397v2 [cs.LG] UPDATED)
110. Learning Coulomb Diamonds in Large Quantum Dot Arrays. (arXiv:2205.01443v3 [cond-mat.mes-hall] UPDATED)
111. Addressing Census data problems in race imputation via fully Bayesian Improved Surname Geocoding and name supplements. (arXiv:2205.06129v2 [stat.ML] UPDATED)
112. Fault Detection for Non-Condensing Boilers using Simulated Building Automation System Sensor Data. (arXiv:2205.08418v2 [eess.SP] UPDATED)
113. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v3 [cs.CV] UPDATED)
114. SFP: State-free Priors for Exploration in Off-Policy Reinforcement Learning. (arXiv:2205.13528v2 [cs.LG] UPDATED)
115. Principal Component Analysis based frameworks for efficient missing data imputation algorithms. (arXiv:2205.15150v2 [cs.LG] UPDATED)
116. Transfer learning to decode brain states reflecting the relationship between cognitive tasks. (arXiv:2206.03950v3 [q-bio.NC] UPDATED)
117. Texture Extraction Methods Based Ensembling Framework for Improved Classification. (arXiv:2206.04158v2 [cs.CV] UPDATED)
118. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v2 [cs.LG] UPDATED)
119. A Dataset and Benchmark for Automatically Answering and Generating Machine Learning Final Exams. (arXiv:2206.05442v2 [cs.LG] UPDATED)
120. Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v2 [cs.IR] UPDATED)
121. DASH: Distributed Adaptive Sequencing Heuristic for Submodular Maximization. (arXiv:2206.09563v2 [cs.DS] UPDATED)
122. On the effectiveness of persistent homology. (arXiv:2206.10551v2 [math.AT] UPDATED)
123. Eliciting and Learning with Soft Labels from Every Annotator. (arXiv:2207.00810v3 [cs.LG] UPDATED)
124. Online Active Regression. (arXiv:2207.05945v2 [cs.LG] UPDATED)
125. MCTensor: A High-Precision Deep Learning Library with Multi-Component Floating-Point. (arXiv:2207.08867v2 [cs.LG] UPDATED)
126. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v5 [cs.CL] UPDATED)
127. Learning to Navigate using Visual Sensor Networks. (arXiv:2208.00759v3 [cs.RO] UPDATED)
128. Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v2 [cs.LG] UPDATED)
129. An Efficient and Reliable Asynchronous Federated Learning Scheme for Smart Public Transportation. (arXiv:2208.07194v2 [cs.LG] UPDATED)
130. Understanding the Effect of Data Augmentation in Self-supervised Anomaly Detection. (arXiv:2208.07734v3 [cs.LG] UPDATED)
131. Conviformers: Convolutionally guided Vision Transformer. (arXiv:2208.08900v2 [cs.CV] UPDATED)
132. IAN: Iterated Adaptive Neighborhoods for manifold learning and dimensionality estimation. (arXiv:2208.09123v2 [cs.LG] UPDATED)
133. Convolutional Neural Networks with A Topographic Representation Module for EEG-Based Brain-Computer Interfaces. (arXiv:2208.10708v2 [eess.SP] UPDATED)
134. A Comparison of Reinforcement Learning Frameworks for Software Testing Tasks. (arXiv:2208.12136v2 [cs.SE] UPDATED)
135. Supervised Dimensionality Reduction and Classification with Convolutional Autoencoders. (arXiv:2208.12152v3 [cs.LG] UPDATED)
136. Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers. (arXiv:2208.12886v2 [cs.CL] UPDATED)
137. Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo. (arXiv:2208.12991v2 [cs.NE] UPDATED)
138. StableFace: Analyzing and Improving Motion Stability for Talking Face Generation. (arXiv:2208.13717v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**60** new papers in cs.AI:-) 
1. Rosenblatt's first theorem and frugality of deep learning. (arXiv:2208.13778v1 [cs.LG])
2. Autoinverse: Uncertainty Aware Inversion of Neural Networks. (arXiv:2208.13780v1 [cs.LG])
3. Dimension Independent Data Sets Approximation and Applications to Classification. (arXiv:2208.13781v1 [cs.LG])
4. Visual-Imagery-Based Analogical Construction in Geometric Matrix Reasoning Task. (arXiv:2208.13841v1 [cs.AI])
5. ProspectNet: Weighted Conditional Attention for Future Interaction Modeling in Behavior Prediction. (arXiv:2208.13848v1 [cs.AI])
6. Reinforcement Learning for Hardware Security: Opportunities, Developments, and Challenges. (arXiv:2208.13885v1 [cs.CR])
7. Debiasing Word Embeddings with Nonlinear Geometry. (arXiv:2208.13899v1 [cs.CL])
8. Spacecraft depth completion based on the gray image and the sparse depth map. (arXiv:2208.14030v1 [cs.CV])
9. Towards Artificial Virtuous Agents: Games, Dilemmas and Machine Learning. (arXiv:2208.14037v1 [cs.AI])
10. Intelligent Perception System for Vehicle-Road Cooperation. (arXiv:2208.14052v1 [cs.RO])
11. Symmetric Pruning in Quantum Neural Networks. (arXiv:2208.14057v1 [quant-ph])
12. Super-model ecosystem: A domain-adaptation perspective. (arXiv:2208.14092v1 [cs.LG])
13. A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v1 [cs.CV])
14. On the Trade-Off between Actionable Explanations and the Right to be Forgotten. (arXiv:2208.14137v1 [cs.LG])
15. Leap-frog neural network for learning the symplectic evolution from partitioned data. (arXiv:2208.14148v1 [astro-ph.EP])
16. MODNet: Multi-offset Point Cloud Denoising Network Customized for Multi-scale Patches. (arXiv:2208.14160v1 [cs.CV])
17. FuncFooler: A Practical Black-box Attack Against Learning-based Binary Code Similarity Detection Methods. (arXiv:2208.14191v1 [cs.CR])
18. A Comprehensive Review of Digital Twin -- Part 1: Modeling and Twinning Enabling Technologies. (arXiv:2208.14197v1 [cs.CE])
19. Learned k-NN Distance Estimation. (arXiv:2208.14210v1 [cs.DB])
20. A Generic Algorithm for Top-K On-Shelf Utility Mining. (arXiv:2208.14230v1 [cs.DB])
21. Prediction-based One-shot Dynamic Parking Pricing. (arXiv:2208.14231v1 [cs.LG])
22. Persistence Initialization: A novel adaptation of the Transformer architecture for Time Series Forecasting. (arXiv:2208.14236v1 [cs.LG])
23. Expressions Causing Differences in Emotion Recognition in Social Networking Service Documents. (arXiv:2208.14244v1 [cs.CL])
24. Faithful Reasoning Using Large Language Models. (arXiv:2208.14271v1 [cs.AI])
25. DLDNN: Deterministic Lateral Displacement Design Automation by Neural Networks. (arXiv:2208.14303v1 [cs.NE])
26. Representation Learning based and Interpretable Reactor System Diagnosis Using Denoising Padded Autoencoder. (arXiv:2208.14319v1 [eess.SP])
27. Learning Representations for Hyper-Relational Knowledge Graphs. (arXiv:2208.14322v1 [cs.LG])
28. GaitFi: Robust Device-Free Human Identification via WiFi and Vision Multimodal Learning. (arXiv:2208.14326v1 [cs.CV])
29. Denoising Architecture for Unsupervised Anomaly Detection in Time-Series. (arXiv:2208.14337v1 [cs.LG])
30. AutoWS-Bench-101: Benchmarking Automated Weak Supervision with 100 Labels. (arXiv:2208.14362v1 [cs.LG])
31. Expert Opinion Elicitation for Assisting Deep Learning based Lyme Disease Classifier with Patient Data. (arXiv:2208.14384v1 [cs.AI])
32. k-MS: A novel clustering algorithm based on morphological reconstruction. (arXiv:2208.14390v1 [cs.LG])
33. Evolutionary Deep Reinforcement Learning for Dynamic Slice Management in O-RAN. (arXiv:2208.14394v1 [eess.SY])
34. Correct-by-Construction Runtime Enforcement in AI - A Survey. (arXiv:2208.14426v1 [cs.AI])
35. Generating and Adapting to Diverse Ad-Hoc Cooperation Agents in Hanabi. (arXiv:2004.13710v3 [cs.AI] UPDATED)
36. BarsCTR: Open Benchmarking for Click-Through Rate Prediction. (arXiv:2009.05794v4 [cs.IR] UPDATED)
37. Hyperdimensional Feature Fusion for Out-Of-Distribution Detection. (arXiv:2112.05341v3 [cs.CV] UPDATED)
38. Adversarial Examples for Good: Adversarial Examples Guided Imbalanced Learning. (arXiv:2201.12356v2 [cs.LG] UPDATED)
39. A Survey on Cross-Lingual Summarization. (arXiv:2203.12515v2 [cs.CL] UPDATED)
40. SpeqNets: Sparsity-aware Permutation-equivariant Graph Networks. (arXiv:2203.13913v3 [cs.LG] UPDATED)
41. What Matters in Language Conditioned Robotic Imitation Learning over Unstructured Data. (arXiv:2204.06252v2 [cs.RO] UPDATED)
42. Sound-Guided Semantic Video Generation. (arXiv:2204.09273v3 [cs.CV] UPDATED)
43. Beyond Greedy Search: Tracking by Multi-Agent Reinforcement Learning-based Beam Search. (arXiv:2205.09676v3 [cs.CV] UPDATED)
44. Effective Integration of Weighted Cost-to-go and Conflict Heuristic within Suboptimal CBS. (arXiv:2205.11624v4 [cs.AI] UPDATED)
45. Transfer learning to decode brain states reflecting the relationship between cognitive tasks. (arXiv:2206.03950v3 [q-bio.NC] UPDATED)
46. Texture Extraction Methods Based Ensembling Framework for Improved Classification. (arXiv:2206.04158v2 [cs.CV] UPDATED)
47. Memory Classifiers: Two-stage Classification for Robustness in Machine Learning. (arXiv:2206.05323v2 [cs.LG] UPDATED)
48. Fair Ranking as Fair Division: Impact-Based Individual Fairness in Ranking. (arXiv:2206.07247v2 [cs.IR] UPDATED)
49. SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving. (arXiv:2206.14116v2 [cs.CV] UPDATED)
50. Eliciting and Learning with Soft Labels from Every Annotator. (arXiv:2207.00810v3 [cs.LG] UPDATED)
51. Large Language Models and the Reverse Turing Test. (arXiv:2207.14382v5 [cs.CL] UPDATED)
52. Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v2 [cs.LG] UPDATED)
53. Understanding the Effect of Data Augmentation in Self-supervised Anomaly Detection. (arXiv:2208.07734v3 [cs.LG] UPDATED)
54. Conviformers: Convolutionally guided Vision Transformer. (arXiv:2208.08900v2 [cs.CV] UPDATED)
55. IAN: Iterated Adaptive Neighborhoods for manifold learning and dimensionality estimation. (arXiv:2208.09123v2 [cs.LG] UPDATED)
56. Building the Intent Landscape of Real-World Conversational Corpora with Extractive Question-Answering Transformers. (arXiv:2208.12886v2 [cs.CL] UPDATED)
57. Sub-mW Neuromorphic SNN audio processing applications with Rockpool and Xylo. (arXiv:2208.12991v2 [cs.NE] UPDATED)
58. JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents. (arXiv:2208.13266v2 [cs.AI] UPDATED)
59. Adapting the LodView RDF Browser for Navigation over the Multilingual Linguistic Linked Open Data Cloud. (arXiv:2208.13295v2 [cs.CL] UPDATED)
60. StableFace: Analyzing and Improving Motion Stability for Talking Face Generation. (arXiv:2208.13717v1 [cs.CV] CROSS LISTED)

