# Your interest papers
---
## cs.CV
---
### FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
- Authors : Zhengang Li, Sheng Lin, Shan Liu, Songnan Li, Xue Lin, Wei Wang, Wei Jiang
- Link : [http://arxiv.org/abs/2207.04090](http://arxiv.org/abs/2207.04090)
> ABSTRACT  :  Recently, high-quality video conferencing with fewer transmission bits has become a very hot and challenging problem. We propose FAIVConf, a specially designed video compression framework for video conferencing, based on the effective neural human face generation techniques. FAIVConf brings together several designs to improve the system robustness in real video conference scenarios: face-swapping to avoid artifacts in background animation; facial blurring to decrease transmission bit-rate and maintain the quality of extracted facial landmarks; and dynamic source update for face view interpolation to accommodate a large range of head poses. Our method achieves a significant bit-rate reduction in the video conference and gives much better visual quality under the same bit-rate compared with H.264 and H.265 coding schemes.  
### Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
- Authors : Rushil Anirudh
- Link : [http://arxiv.org/abs/2207.04125](http://arxiv.org/abs/2207.04125)
> ABSTRACT  :  Our goal in this paper is to exploit heteroscedastic temperature scaling as a calibration strategy for out of distribution (OOD) detection. Heteroscedasticity here refers to the fact that the optimal temperature parameter for each sample can be different, as opposed to conventional approaches that use the same value for the entire distribution. To enable this, we propose a new training strategy called anchoring that can estimate appropriate temperature values for each sample, leading to state-of-the-art OOD detection performance across several benchmarks. Using NTK theory, we show that this temperature function estimate is closely linked to the epistemic uncertainty of the classifier, which explains its behavior. In contrast to some of the best-performing OOD detection approaches, our method does not require **exposure** to additional outlier datasets, custom calibration objectives, or model ensembling. Through empirical studies with different OOD detection settings -- far OOD, near OOD, and semantically coherent OOD - we establish a highly effective OOD detection approach. Code and models can be accessed here -- https://github.com/rushilanirudh/AMP  
### Variational Approach for Intensity Domain Multi-**exposure** Image Fusion. (arXiv:2207.04204v1 [cs.CV])
- Authors : Harbinder Singh, Dinesh Arora, Vinay Kumar
- Link : [http://arxiv.org/abs/2207.04204](http://arxiv.org/abs/2207.04204)
> ABSTRACT  :  Recent innovations shows that blending of details captured by single Low Dynamic Range (LDR) sensor overcomes the limitations of standard digital cameras to capture details from **high dynamic range** scene. We present a method to produce well-exposed fused image that can be displayed directly on conventional display devices. The ambition is to preserve details in poorly illuminated and brightly illuminated regions. Proposed approach does not require true radiance reconstruction and tone manipulation steps. The aforesaid objective is achieved by taking into account local information measure that select well-exposed regions across input **exposure**s. In addition, Contrast Limited Adaptive Histogram equalization (CLAHE) is introduced to improve uniformity of input multi-**exposure** image prior to fusion.  
### Self-attention on Multi-Shifted Windows for Scene Segmentation. (arXiv:2207.04403v1 [cs.CV])
- Authors : Litao Yu, Zhibin Li, Jian Zhang, Qiang Wu
- Link : [http://arxiv.org/abs/2207.04403](http://arxiv.org/abs/2207.04403)
> ABSTRACT  :  Scene segmentation in images is a fundamental yet challenging problem in visual content understanding, which is to learn a model to assign every image pixel to a categorical label. One of the challenges for this learning task is to consider the spatial and semantic relationships to obtain descriptive feature representations, so learning the feature maps from multiple scales is a common practice in scene segmentation. In this paper, we explore the effective use of self-attention within multi-scale image windows to learn descriptive visual features, then propose three different strategies to aggregate these feature maps to decode the feature representation for dense prediction. Our design is based on the recently proposed **Swin** Transformer models, which totally discards convolution operations. With the simple yet effective multi-scale feature learning and aggregation, our models achieve very promising performance on four public scene segmentation datasets, PASCAL VOC2012, COCO-Stuff 10K, ADE20K and Cityscapes.  
### Hiding Your Signals: A Security Analysis of PPG-based Biometric Authentication. (arXiv:2207.04434v1 [cs.CR])
- Authors : Lin Li, Chao Chen, Lei Pan, Yonghang Tai, Jun Zhang, Yang Xiang
- Link : [http://arxiv.org/abs/2207.04434](http://arxiv.org/abs/2207.04434)
> ABSTRACT  :  Recently, physiological signal-based biometric systems have received wide attention. Unlike traditional biometric features, physiological signals can not be easily compromised (usually unobservable to human eyes). Photoplethysmography (PPG) signal is easy to measure, making it more attractive than many other physiological signals for biometric authentication. However, with the advent of remote PPG (rPPG), unobservability has been challenged when the attacker can remotely steal the rPPG signals by monitoring the victim's face, subsequently posing a threat to PPG-based biometrics. In PPG-based biometric authentication, current attack approaches mandate the victim's PPG signal, making rPPG-based attacks neglected. In this paper, we firstly analyze the security of PPG-based biometrics, including user authentication and communication protocols. We evaluate the signal waveforms, heart rate and inter-pulse-interval information extracted by five rPPG methods, including four traditional optical computing methods (CHROM, POS, LGI, PCA) and one deep learning method (CL_rPPG). We conducted experiments on five datasets (PURE, UBFC_rPPG, UBFC_Phys, LGI_PPGI, and COHFACE) to collect a comprehensive set of results. Our empirical studies show that rPPG poses a serious threat to the authentication system. The success rate of the rPPG signal spoofing attack in the user authentication system reached 0.35. The bit hit rate is 0.6 in inter-pulse-interval-based security protocols. Further, we propose an active defence strategy to hide the physiological signals of the face to resist the attack. It reduces the success rate of rPPG spoofing attacks in user authentication to 0.05. The bit hit rate was reduced to 0.5, which is at the level of a random guess. Our strategy effectively prevents the **exposure** of PPG signals to protect users' sensitive physiological data.  
### Progressively-connected Light Field Network for Efficient View Synthesis. (arXiv:2207.04465v1 [cs.CV])
- Authors : Peng Wang, Yuan Liu, Guying Lin, Jiatao Gu, Lingjie Liu, Taku Komura, Wenping Wang
- Link : [http://arxiv.org/abs/2207.04465](http://arxiv.org/abs/2207.04465)
> ABSTRACT  :  This paper presents a Progressively-connected Light Field network (ProLiF), for the novel view synthesis of complex forward-facing scenes. ProLiF encodes a 4D light field, which allows rendering a large batch of rays in one training step for image- or patch-level losses. Directly learning a neural light field from images has difficulty in rendering multi-view consistent images due to its unawareness of the underlying 3D geometry. To address this problem, we propose a progressive training scheme and regularization losses to infer the underlying geometry during training, both of which enforce the multi-view consistency and thus greatly improves the rendering quality. Experiments demonstrate that our method is able to achieve significantly better rendering quality than the vanilla neural light fields and comparable results to **NeRF**-like rendering methods on the challenging LLFF dataset and Shiny Object dataset. Moreover, we demonstrate better compatibility with LPIPS loss to achieve robustness to varying light conditions and CLIP loss to control the rendering style of the scene. Project page: https://totoro97.github.io/projects/prolif.  
### Efficient Multi-Task RGB-D Scene Analysis for Indoor Environments. (arXiv:2207.04526v1 [cs.CV])
- Authors : Daniel Seichter, hnke Benedikt, Michael Gro
- Link : [http://arxiv.org/abs/2207.04526](http://arxiv.org/abs/2207.04526)
> ABSTRACT  :  Semantic scene understanding is essential for mobile agents acting in various environments. Although semantic segmentation already provides a lot of information, details about individual objects as well as the general scene are missing but required for many real-world applications. However, solving multiple tasks separately is expensive and cannot be accomplished in **real time** given limited computing and battery capabilities on a mobile platform. In this paper, we propose an efficient multi-task approach for RGB-D scene analysis~(EMSANet) that simultaneously performs semantic and instance segmentation~(panoptic segmentation), instance orientation estimation, and scene classification. We show that all tasks can be accomplished using a single neural network in **real time** on a mobile platform without diminishing performance - by contrast, the individual tasks are able to benefit from each other. In order to evaluate our multi-task approach, we extend the annotations of the common RGB-D indoor datasets NYUv2 and SUNRGB-D for instance segmentation and orientation estimation. To the best of our knowledge, we are the first to provide results in such a comprehensive multi-task setting for indoor scene analysis on NYUv2 and SUNRGB-D.  
### GAN-based Virtual Re-Staining: A Promising Solution for Whole Slide Image Analysis. (arXiv:1901.04059v2 [cs.CV] UPDATED)
- Authors : Zhaoyang Xu, Xingru Huang, Carlos Fern, ndez Moro, la Boz, Qianni Zhang
- Link : [http://arxiv.org/abs/1901.04059](http://arxiv.org/abs/1901.04059)
> ABSTRACT  :  Histopathological cancer diagnosis is based on visual examination of stained tissue slides. Hematoxylin and eosin (H\&amp;E) is a standard stain routinely employed worldwide. It is easy to acquire and cost effective, but cells and tissue components show low-contrast with varying tones of **dark** blue and pink, which makes difficult visual assessments, digital image analysis, and quantifications. These limitations can be overcome by IHC staining of target proteins of the tissue slide. IHC provides a selective, high-contrast imaging of cells and tissue components, but their use is largely limited by a significantly more complex laboratory processing and high cost. We proposed a conditional CycleGAN (cCGAN) network to transform the H\&amp;E stained images into IHC stained images, facilitating virtual IHC staining on the same slide. This data-driven method requires only a limited amount of labelled data but will generate pixel level segmentation results. The proposed cCGAN model improves the original network \cite{zhu_unpaired_2017} by adding category conditions and introducing two structural loss functions, which realize a multi-subdomain translation and improve the translation accuracy as well. % need to give reasons here. Experiments demonstrate that the proposed model outperforms the original method in unpaired image translation with multi-subdomains. We also explore the potential of unpaired images to image translation method applied on other histology images related tasks with different staining techniques.  
### Learned Camera Gain and **Exposure** Control for Improved Visual Feature Detection and Matching. (arXiv:2102.04341v3 [cs.RO] UPDATED)
- Authors : Justin Tomasi, Brandon Wagstaff, Jonathan Kelly
- Link : [http://arxiv.org/abs/2102.04341](http://arxiv.org/abs/2102.04341)
> ABSTRACT  :  Successful visual navigation depends upon capturing images that contain sufficient useful information. In this letter, we explore a data-driven approach to account for environmental lighting changes, improving the quality of images for use in visual odometry (VO) or visual simultaneous localization and mapping (SLAM). We train a deep convolutional neural network model to predictively adjust camera gain and **exposure** time parameters such that consecutive images contain a maximal number of matchable features. The training process is fully self-supervised: our training signal is derived from an underlying VO or SLAM pipeline and, as a result, the model is optimized to perform well with that specific pipeline. We demonstrate through extensive real-world experiments that our network can anticipate and compensate for dramatic lighting changes (e.g., transitions into and out of road tunnels), maintaining a substantially higher number of inlier feature matches than competing camera parameter control algorithms.  
### Pedestrian Detection by Exemplar-Guided Contrastive Learning. (arXiv:2111.08974v3 [cs.CV] UPDATED)
- Authors : Zebin Lin, Wenjie Pei, Fanglin Chen, David Zhang, Guangming Lu
- Link : [http://arxiv.org/abs/2111.08974](http://arxiv.org/abs/2111.08974)
> ABSTRACT  :  Typical methods for pedestrian detection focus on either tackling mutual occlusions between crowded pedestrians, or dealing with the various scales of pedestrians. Detecting pedestrians with substantial appearance diversities such as different pedestrian silhouettes, different viewpoints or different dressing, remains a crucial challenge. Instead of learning each of these diverse pedestrian appearance features individually as most existing methods do, we propose to perform contrastive learning to guide the feature learning in such a way that the semantic distance between pedestrians with different appearances in the learned feature space is minimized to eliminate the appearance diversities, whilst the distance between pedestrians and background is maximized. To facilitate the efficiency and effectiveness of contrastive learning, we construct an exemplar dictionary with representative pedestrian appearances as prior knowledge to construct effective contrastive training pairs and thus guide contrastive learning. Besides, the constructed exemplar dictionary is further leveraged to evaluate the quality of pedestrian proposals during inference by measuring the semantic distance between the proposal and the exemplar dictionary. Extensive experiments on both daytime and **night**time pedestrian detection validate the effectiveness of the proposed method.  
### **NeRF**-SR: High-Quality Neural Radiance Fields using Super-Sampling. (arXiv:2112.01759v2 [cs.CV] UPDATED)
- Authors : Chen Wang, Xian Wu, Chen Guo, Hai Zhang, Wing Tai, Min Hu
- Link : [http://arxiv.org/abs/2112.01759](http://arxiv.org/abs/2112.01759)
> ABSTRACT  :  We present **NeRF**-SR, a solution for high-resolution (HR) novel view synthesis with mostly low-resolution (LR) inputs. Our method is built upon Neural Radiance Fields (**NeRF**) that predicts per-point density and color with a multi-layer perceptron. While producing images at arbitrary scales, **NeRF** struggles with resolutions that go beyond observed images. Our key insight is that **NeRF** benefits from 3D consistency, which means an observed pixel absorbs information from nearby views. We first exploit it by a super-sampling strategy that shoots multiple rays at each image pixel, which further enforces multi-view constraint at a sub-pixel level. Then, we show that **NeRF**-SR can further boost the performance of super-sampling by a refinement network that leverages the estimated depth at hand to hallucinate details from related patches on only one HR reference image. Experiment results demonstrate that **NeRF**-SR generates high-quality results for novel view synthesis at HR on both synthetic and real-world datasets without any external information.  
### Visual Attention Network. (arXiv:2202.09741v5 [cs.CV] UPDATED)
- Authors : Hao Guo, Ze Lu, Ning Liu, Ming Cheng, Min Hu
- Link : [http://arxiv.org/abs/2202.09741](http://arxiv.org/abs/2202.09741)
> ABSTRACT  :  While originally designed for natural language processing tasks, the self-attention mechanism has recently taken various computer vision areas by storm. However, the 2D nature of images brings three challenges for applying self-attention in computer vision. (1) Treating images as 1D sequences neglects their 2D structures. (2) The quadratic complexity is too expensive for high-resolution images. (3) It only captures spatial adaptability but ignores channel adaptability. In this paper, we propose a novel linear attention named large kernel attention (LKA) to enable self-adaptive and long-range correlations in self-attention while avoiding its shortcomings. Furthermore, we present a neural network based on LKA, namely Visual Attention Network (VAN). While extremely simple, VAN surpasses similar size vision transformers(ViTs) and convolutional neural networks(CNNs) in various tasks, including image classification, object detection, semantic segmentation, panoptic segmentation, pose estimation, etc. For example, VAN-B6 achieves 87.8% accuracy on ImageNet benchmark and set new state-of-the-art performance (58.2 PQ) for panoptic segmentation. Besides, VAN-B2 surpasses **Swin**-T 4% mIoU (50.1 vs. 46.1) for semantic segmentation on ADE20K benchmark, 2.6% AP (48.8 vs. 46.2) for object detection on COCO dataset. It provides a novel method and a simple yet strong baseline for the community. Code is available at https://github.com/Visual-Attention-Network.  
### Semantic-Aware Latent Space Exploration for Face Image **Restoration**. (arXiv:2203.03005v2 [cs.CV] UPDATED)
- Authors : Yanhui Guo, Fangzhou Luo
- Link : [http://arxiv.org/abs/2203.03005](http://arxiv.org/abs/2203.03005)
> ABSTRACT  :  For image **restoration**, the majority of existing deep learning-based algorithms have a tendency to overfit the training data, resulting in poor performance when confronted with unseen degradations. To achieve more robust **restoration**, generative adversarial network (GAN) prior based methods have been proposed, demonstrating a promising capacity to restore photo-realistic and high-quality results. However, these methods are susceptible to semantic ambiguity, particularly with semantically relevant images such as facial images. In this paper, we propose a semantic-aware latent space exploration method for image **restoration** (SAIR). By explicitly modeling referenced semantics information, SAIR is able to reliably restore severely degraded images not only to high-resolution highly-realistic looks but also to correct semantics. Quantitative and qualitative experiments collectively demonstrate the effectiveness of the proposed SAIR. Our code can be found in https://github.com/Liamkuo/SAIR.  
### DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection. (arXiv:2203.03605v4 [cs.CV] UPDATED)
- Authors : Hao Zhang, Feng Li, Shilong Liu, **Lei Zhang**, Hang Su, Jun Zhu, Yeung Shum
- Link : [http://arxiv.org/abs/2203.03605](http://arxiv.org/abs/2203.03605)
> ABSTRACT  :  We present DINO (\textbf{D}ETR with \textbf{I}mproved de\textbf{N}oising anch\textbf{O}r boxes), a state-of-the-art end-to-end object detector. % in this paper. DINO improves over previous DETR-like models in performance and efficiency by using a contrastive way for denoising training, a mixed query selection method for anchor initialization, and a look forward twice scheme for box prediction. DINO achieves $49.4$AP in $12$ epochs and $51.3$AP in $24$ epochs on COCO with a ResNet-50 backbone and multi-scale features, yielding a significant improvement of $\textbf{+6.0}$\textbf{AP} and $\textbf{+2.7}$\textbf{AP}, respectively, compared to DN-DETR, the previous best DETR-like model. DINO scales well in both model size and data size. Without bells and whistles, after pre-training on the Objects365 dataset with a **Swin**L backbone, DINO obtains the best results on both COCO \texttt{val2017} ($\textbf{63.2}$\textbf{AP}) and \texttt{test-dev} (\textbf{$\textbf{63.3}$AP}). Compared to other models on the leaderboard, DINO significantly reduces its model size and pre-training data size while achieving better results. Our code will be available at \url{https://github.com/IDEACVR/DINO}.  
### Panoptic-PartFormer: Learning a Unified Model for Panoptic Part Segmentation. (arXiv:2204.04655v2 [cs.CV] UPDATED)
- Authors : Xiangtai Li, Shilin Xu, Yibo Yang, Guangliang Cheng, Yunhai Tong, Dacheng Tao
- Link : [http://arxiv.org/abs/2204.04655](http://arxiv.org/abs/2204.04655)
> ABSTRACT  :  Panoptic Part Segmentation (PPS) aims to unify panoptic segmentation and part segmentation into one task. Previous work mainly utilizes separated approaches to handle thing, stuff, and part predictions individually without performing any shared computation and task association. In this work, we aim to unify these tasks at the architectural level, designing the first end-to-end unified method named Panoptic-PartFormer. In particular, motivated by the recent progress in Vision Transformer, we model things, stuff, and part as object queries and directly learn to optimize the all three predictions as unified mask prediction and classification problem. We design a decoupled decoder to generate part feature and thing/stuff feature respectively. Then we propose to utilize all the queries and corresponding features to perform reasoning jointly and iteratively. The final mask can be obtained via inner product between queries and the corresponding features. The extensive ablation studies and analysis prove the effectiveness of our framework. Our Panoptic-PartFormer achieves the new state-of-the-art results on both Cityscapes PPS and Pascal Context PPS datasets with at least 70% GFlops and 50% parameters decrease. In particular, we get 3.4% relative improvements with ResNet50 backbone and 10% improvements after adopting **Swin** Transformer on Pascal Context PPS dataset. To the best of our knowledge, we are the first to solve the PPS problem via \textit{a unified and end-to-end transformer model. Given its effectiveness and conceptual simplicity, we hope our Panoptic-PartFormer can serve as a good baseline and aid future unified research for PPS. Our code and models are available at https://github.com/lxtGH/Panoptic-PartFormer.  
### Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted-window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We open-sourced our checkpoints, code and CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer.  
### Memory Efficient Patch-based Training for INR-based GANs. (arXiv:2207.01395v2 [cs.CV] UPDATED)
- Authors : Namwoo Lee, Hyunsu Kim, Gayoung Lee, Sungjoo Yoo, Yunjey Choi
- Link : [http://arxiv.org/abs/2207.01395](http://arxiv.org/abs/2207.01395)
> ABSTRACT  :  Recent studies have shown remarkable progress in GANs based on **implicit neural representation** (INR) - an MLP that produces an RGB value given its (x, y) coordinate. They represent an image as a continuous version of the underlying 2D signal instead of a 2D array of pixels, which opens new horizons for GAN applications (e.g., zero-shot super-resolution, image outpainting). However, training existing approaches require a heavy computational cost proportional to the image resolution, since they compute an MLP operation for every (x, y) coordinate. To alleviate this issue, we propose a multi-stage patch-based training, a novel and scalable approach that can train INR-based GANs with a flexible computational cost regardless of the image resolution. Specifically, our method allows to generate and discriminate by patch to learn the local details of the image and learn global structural information by a novel reconstruction loss to enable efficient GAN training. We conduct experiments on several benchmark datasets to demonstrate that our approach enhances baseline models in GPU memory while maintaining FIDs at a reasonable level.  
## eess.IV
---
### FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
- Authors : Zhengang Li, Sheng Lin, Shan Liu, Songnan Li, Xue Lin, Wei Wang, Wei Jiang
- Link : [http://arxiv.org/abs/2207.04090](http://arxiv.org/abs/2207.04090)
> ABSTRACT  :  Recently, high-quality video conferencing with fewer transmission bits has become a very hot and challenging problem. We propose FAIVConf, a specially designed video compression framework for video conferencing, based on the effective neural human face generation techniques. FAIVConf brings together several designs to improve the system robustness in real video conference scenarios: face-swapping to avoid artifacts in background animation; facial blurring to decrease transmission bit-rate and maintain the quality of extracted facial landmarks; and dynamic source update for face view interpolation to accommodate a large range of head poses. Our method achieves a significant bit-rate reduction in the video conference and gives much better visual quality under the same bit-rate compared with H.264 and H.265 coding schemes.  
### Learned Video Compression via Heterogeneous Deformable Compensation Network. (arXiv:2207.04589v1 [eess.IV])
- Authors : Huairui Wang, Zhenzhong Chen, Chang Wen
- Link : [http://arxiv.org/abs/2207.04589](http://arxiv.org/abs/2207.04589)
> ABSTRACT  :  Learned video compression has recently emerged as an essential research topic in developing advanced video compression technologies, where motion compensation is considered one of the most challenging issues. In this paper, we propose a learned video compression framework via heterogeneous deformable compensation strategy (HDCVC) to tackle the problems of unstable compression performance caused by single-size deformable kernels in downsampled feature domain. More specifically, instead of utilizing optical flow warping or single-size-kernel deformable alignment, the proposed algorithm extracts features from the two adjacent frames to estimate content-adaptive heterogeneous deformable (HetDeform) kernel offsets. Then we transform the reference features with the HetDeform convolution to accomplish motion compensation. Moreover, we design a Spatial-Neighborhood-Conditioned Divisive Normalization (SNCDN) to achieve more effective data Gaussianization combined with the Generalized Divisive Normalization. Furthermore, we propose a multi-frame enhanced reconstruction module for exploiting context and temporal information for final quality **enhancement**. Experimental results indicate that HDCVC achieves superior performance than the recent state-of-the-art learned video compression approaches.  
### An Ultra-low Power TinyML System for **Real-time** Visual Processing at Edge. (arXiv:2207.04663v1 [eess.IV])
- Authors : Kunran Xu, Huawei Zhang, Yishi Li, Yuhao Zhang, Rui Lai, Yi Liu
- Link : [http://arxiv.org/abs/2207.04663](http://arxiv.org/abs/2207.04663)
> ABSTRACT  :  Tiny machine learning (TinyML), executing AI workloads on resource and power strictly restricted systems, is an important and challenging topic. This brief firstly presents an extremely tiny backbone to construct high efficiency CNN models for various visual tasks. Then, a specially designed neural co-processor (NCP) is interconnected with MCU to build an ultra-low power TinyML system, which stores all features and weights on chip and completely removes both of latency and power consumption in off-chip memory access. Furthermore, an application specific instruction-set is further presented for realizing agile development and rapid deployment. Extensive experiments demonstrate that the proposed TinyML system based on our model, NCP and instruction set yields considerable accuracy and achieves a record ultra-low power of 160mW while implementing object detection and recognition at 30FPS. The demo video is available on \url{https://www.youtube.com/watch?v=mIZPxtJ-9EY}.  
## cs.LG
---
### Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
- Authors : Rushil Anirudh
- Link : [http://arxiv.org/abs/2207.04125](http://arxiv.org/abs/2207.04125)
> ABSTRACT  :  Our goal in this paper is to exploit heteroscedastic temperature scaling as a calibration strategy for out of distribution (OOD) detection. Heteroscedasticity here refers to the fact that the optimal temperature parameter for each sample can be different, as opposed to conventional approaches that use the same value for the entire distribution. To enable this, we propose a new training strategy called anchoring that can estimate appropriate temperature values for each sample, leading to state-of-the-art OOD detection performance across several benchmarks. Using NTK theory, we show that this temperature function estimate is closely linked to the epistemic uncertainty of the classifier, which explains its behavior. In contrast to some of the best-performing OOD detection approaches, our method does not require **exposure** to additional outlier datasets, custom calibration objectives, or model ensembling. Through empirical studies with different OOD detection settings -- far OOD, near OOD, and semantically coherent OOD - we establish a highly effective OOD detection approach. Code and models can be accessed here -- https://github.com/rushilanirudh/AMP  
### Variational Mixtures of ODEs for Inferring Cellular Gene Expression Dynamics. (arXiv:2207.04166v1 [cs.LG])
- Authors : Yichen Gu, David Blaauw, Joshua Welch
- Link : [http://arxiv.org/abs/2207.04166](http://arxiv.org/abs/2207.04166)
> ABSTRACT  :  A key problem in computational biology is discovering the gene expression changes that regulate cell fate transitions, in which one cell type turns into another. However, each individual cell cannot be tracked longitudinally, and cells at the same point in **real time** may be at different stages of the transition process. This can be viewed as a problem of learning the behavior of a dynamical system from observations whose times are unknown. Additionally, a single progenitor cell type often bifurcates into multiple child cell types, further complicating the problem of modeling the dynamics. To address this problem, we developed an approach called variational mixtures of ordinary differential equations. By using a simple family of ODEs informed by the biochemistry of gene expression to constrain the likelihood of a deep generative model, we can simultaneously infer the latent time and latent state of each cell and predict its future gene expression state. The model can be interpreted as a mixture of ODEs whose parameters vary continuously across a latent space of cell states. Our approach dramatically improves data fit, latent time inference, and future cell state estimation of single-cell gene expression data compared to previous approaches.  
### Multi-label Classification with High-rank and High-order Label Correlations. (arXiv:2207.04197v1 [cs.LG])
- Authors : Chongjie Si, Yuheng Jia, Ran Wang, Ling Zhang, Yanghe Feng, Qu Chongxiao
- Link : [http://arxiv.org/abs/2207.04197](http://arxiv.org/abs/2207.04197)
> ABSTRACT  :  Exploiting label correlations is important to multi-label classification. Previous methods capture the high-order label correlations mainly by transforming the label matrix to a latent label space with low-rank matrix factorization. However, the label matrix is generally a full-rank or approximate full-rank matrix, making the low-rank factorization inappropriate. Besides, in the latent space, the label correlations will become implicit. To this end, we propose a simple yet effective method to depict the high-order label correlations explicitly, and at the same time maintain the high-rank of the label matrix. Moreover, we estimate the label correlations and infer model parameters simultaneously via the local geometric structure of the input to achieve mutual **enhancement**. Comparative studies over ten benchmark data sets validate the effectiveness of the proposed algorithm in multi-label classification. The exploited high-order label correlations are consistent with common sense empirically. Our code is publicly available at https://github.<a href="http://export.arxiv.org/abs/com/6011759">com/6011759</a>36/HOMI.  
### Efficient Multi-Task RGB-D Scene Analysis for Indoor Environments. (arXiv:2207.04526v1 [cs.CV])
- Authors : Daniel Seichter, hnke Benedikt, Michael Gro
- Link : [http://arxiv.org/abs/2207.04526](http://arxiv.org/abs/2207.04526)
> ABSTRACT  :  Semantic scene understanding is essential for mobile agents acting in various environments. Although semantic segmentation already provides a lot of information, details about individual objects as well as the general scene are missing but required for many real-world applications. However, solving multiple tasks separately is expensive and cannot be accomplished in **real time** given limited computing and battery capabilities on a mobile platform. In this paper, we propose an efficient multi-task approach for RGB-D scene analysis~(EMSANet) that simultaneously performs semantic and instance segmentation~(panoptic segmentation), instance orientation estimation, and scene classification. We show that all tasks can be accomplished using a single neural network in **real time** on a mobile platform without diminishing performance - by contrast, the individual tasks are able to benefit from each other. In order to evaluate our multi-task approach, we extend the annotations of the common RGB-D indoor datasets NYUv2 and SUNRGB-D for instance segmentation and orientation estimation. To the best of our knowledge, we are the first to provide results in such a comprehensive multi-task setting for indoor scene analysis on NYUv2 and SUNRGB-D.  
### Online Continual Learning for Embedded Devices. (arXiv:2203.10681v2 [cs.LG] UPDATED)
- Authors : Christopher Kanan
- Link : [http://arxiv.org/abs/2203.10681](http://arxiv.org/abs/2203.10681)
> ABSTRACT  :  **Real-time** on-device continual learning is needed for new applications such as home robots, user personalization on smartphones, and augmented/virtual reality headsets. However, this setting poses unique challenges: embedded devices have limited memory and compute capacity and conventional machine learning models suffer from catastrophic forgetting when updated on non-stationary data streams. While several online continual learning models have been developed, their effectiveness for embedded applications has not been rigorously studied. In this paper, we first identify criteria that online continual learners must meet to effectively perform real-time, on-device learning. We then study the efficacy of several online continual learning methods when used with mobile neural networks. We measure their performance, memory usage, compute requirements, and ability to generalize to out-of-domain inputs.  
### Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted-window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We open-sourced our checkpoints, code and CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer.  
### Improving Speech **Enhancement** through Fine-Grained Speech Characteristics. (arXiv:2207.00237v2 [cs.SD] UPDATED)
- Authors : Muqiao Yang, Joseph Konan, David Bick, Anurag Kumar, Shinji Watanabe, Bhiksha Raj
- Link : [http://arxiv.org/abs/2207.00237](http://arxiv.org/abs/2207.00237)
> ABSTRACT  :  While deep learning based speech **enhancement** systems have made rapid progress in improving the quality of speech signals, they can still produce outputs that contain artifacts and can sound unnatural. We propose a novel approach to speech **enhancement** aimed at improving perceptual quality and naturalness of enhanced signals by optimizing for key characteristics of speech. We first identify key acoustic parameters that have been found to correlate well with voice quality (e.g. jitter, shimmer, and spectral flux) and then propose objective functions which are aimed at reducing the difference between clean speech and enhanced speech with respect to these features. The full set of acoustic features is the extended Geneva Acoustic Parameter Set (eGeMAPS), which includes 25 different attributes associated with perception of speech. Given the non-differentiable nature of these feature computation, we first build differentiable estimators of the eGeMAPS and then use them to fine-tune existing speech **enhancement** systems. Our approach is generic and can be applied to any existing deep learning based **enhancement** systems to further improve the enhanced speech signals. Experimental results conducted on the Deep Noise Suppression (DNS) Challenge dataset shows that our approach can improve the state-of-the-art deep learning based **enhancement** systems.  
## cs.AI
---
### FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
- Authors : Zhengang Li, Sheng Lin, Shan Liu, Songnan Li, Xue Lin, Wei Wang, Wei Jiang
- Link : [http://arxiv.org/abs/2207.04090](http://arxiv.org/abs/2207.04090)
> ABSTRACT  :  Recently, high-quality video conferencing with fewer transmission bits has become a very hot and challenging problem. We propose FAIVConf, a specially designed video compression framework for video conferencing, based on the effective neural human face generation techniques. FAIVConf brings together several designs to improve the system robustness in real video conference scenarios: face-swapping to avoid artifacts in background animation; facial blurring to decrease transmission bit-rate and maintain the quality of extracted facial landmarks; and dynamic source update for face view interpolation to accommodate a large range of head poses. Our method achieves a significant bit-rate reduction in the video conference and gives much better visual quality under the same bit-rate compared with H.264 and H.265 coding schemes.  
### Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
- Authors : Rushil Anirudh
- Link : [http://arxiv.org/abs/2207.04125](http://arxiv.org/abs/2207.04125)
> ABSTRACT  :  Our goal in this paper is to exploit heteroscedastic temperature scaling as a calibration strategy for out of distribution (OOD) detection. Heteroscedasticity here refers to the fact that the optimal temperature parameter for each sample can be different, as opposed to conventional approaches that use the same value for the entire distribution. To enable this, we propose a new training strategy called anchoring that can estimate appropriate temperature values for each sample, leading to state-of-the-art OOD detection performance across several benchmarks. Using NTK theory, we show that this temperature function estimate is closely linked to the epistemic uncertainty of the classifier, which explains its behavior. In contrast to some of the best-performing OOD detection approaches, our method does not require **exposure** to additional outlier datasets, custom calibration objectives, or model ensembling. Through empirical studies with different OOD detection settings -- far OOD, near OOD, and semantically coherent OOD - we establish a highly effective OOD detection approach. Code and models can be accessed here -- https://github.com/rushilanirudh/AMP  
### ADVERT: An Adaptive and Data-Driven Attention **Enhancement** Mechanism for Phishing Prevention. (arXiv:2106.06907v3 [cs.HC] UPDATED)
- Authors : Linan Huang, Shumeng Jia, Emily Balcetis, Quanyan Zhu
- Link : [http://arxiv.org/abs/2106.06907](http://arxiv.org/abs/2106.06907)
> ABSTRACT  :  Attacks exploiting the innate and the acquired vulnerabilities of human users have posed severe threats to cybersecurity. This work proposes ADVERT, a human-technical solution that generates adaptive visual aids in real-time to prevent users from inadvertence and reduce their susceptibility to phishing attacks. Based on the eye-tracking data, we extract visual states and attention states as system-level sufficient statistics to characterize the user's visual behaviors and attention status. By adopting a data-driven approach and two learning feedback of different time scales, this work lays out a theoretical foundation to analyze, evaluate, and particularly modify humans' attention processes while they vet and recognize phishing emails. We corroborate the effectiveness, efficiency, and robustness of ADVERT through a case study based on the data set collected from human subject experiments conducted at New York University. The results show that the visual aids can statistically increase the attention level and improve the accuracy of phishing recognition from 74.6% to a minimum of 86%. The meta-adaptation can further improve the accuracy to 91.5% (resp. 93.7%) in less than 3 (resp. 50) tuning stages.  
### **NeRF**-SR: High-Quality Neural Radiance Fields using Super-Sampling. (arXiv:2112.01759v2 [cs.CV] UPDATED)
- Authors : Chen Wang, Xian Wu, Chen Guo, Hai Zhang, Wing Tai, Min Hu
- Link : [http://arxiv.org/abs/2112.01759](http://arxiv.org/abs/2112.01759)
> ABSTRACT  :  We present **NeRF**-SR, a solution for high-resolution (HR) novel view synthesis with mostly low-resolution (LR) inputs. Our method is built upon Neural Radiance Fields (**NeRF**) that predicts per-point density and color with a multi-layer perceptron. While producing images at arbitrary scales, **NeRF** struggles with resolutions that go beyond observed images. Our key insight is that **NeRF** benefits from 3D consistency, which means an observed pixel absorbs information from nearby views. We first exploit it by a super-sampling strategy that shoots multiple rays at each image pixel, which further enforces multi-view constraint at a sub-pixel level. Then, we show that **NeRF**-SR can further boost the performance of super-sampling by a refinement network that leverages the estimated depth at hand to hallucinate details from related patches on only one HR reference image. Experiment results demonstrate that **NeRF**-SR generates high-quality results for novel view synthesis at HR on both synthetic and real-world datasets without any external information.  
### Online Continual Learning for Embedded Devices. (arXiv:2203.10681v2 [cs.LG] UPDATED)
- Authors : Christopher Kanan
- Link : [http://arxiv.org/abs/2203.10681](http://arxiv.org/abs/2203.10681)
> ABSTRACT  :  **Real-time** on-device continual learning is needed for new applications such as home robots, user personalization on smartphones, and augmented/virtual reality headsets. However, this setting poses unique challenges: embedded devices have limited memory and compute capacity and conventional machine learning models suffer from catastrophic forgetting when updated on non-stationary data streams. While several online continual learning models have been developed, their effectiveness for embedded applications has not been rigorously studied. In this paper, we first identify criteria that online continual learners must meet to effectively perform real-time, on-device learning. We then study the efficacy of several online continual learning methods when used with mobile neural networks. We measure their performance, memory usage, compute requirements, and ability to generalize to out-of-domain inputs.  
### Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
- Authors : Ali Hassani, Steven Walton, Jiachen Li, Shen Li, Humphrey Shi
- Link : [http://arxiv.org/abs/2204.07143](http://arxiv.org/abs/2204.07143)
> ABSTRACT  :  We present Neighborhood Attention Transformer (NAT), an efficient, accurate and scalable hierarchical transformer that works well on both image classification and downstream vision tasks. It is built upon Neighborhood Attention (NA), a simple and flexible attention mechanism that localizes the receptive field for each query to its nearest neighboring pixels. NA is a localization of self-attention, and approaches it as the receptive field size increases. It is also equivalent in FLOPs and memory usage to **Swin** Transformer's shifted-window attention given the same receptive field size, while being less constrained. Furthermore, NA includes local inductive biases, which eliminate the need for extra operations such as pixel shifts. Experimental results on NAT are competitive; NAT-Tiny reaches 83.2% top-1 accuracy on ImageNet with only 4.3 GFLOPs and 28M parameters, 51.4% mAP on MS-COCO and 48.4% mIoU on ADE20k. We open-sourced our checkpoints, code and CUDA kernel at: https://github.com/SHI-Labs/Neighborhood-Attention-Transformer.  
# Paper List
---
## cs.CV
---
**156** new papers in cs.CV:-) 
1. SInGE: Sparsity via Integrated Gradients Estimation of Neuron Relevance. (arXiv:2207.04089v1 [cs.CV])
2. FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
3. StatMix: Data augmentation method that relies on image statistics in federated learning. (arXiv:2207.04103v1 [cs.LG])
4. Evaluating Systemic Error Detection Methods using Synthetic Images. (arXiv:2207.04104v1 [cs.LG])
5. Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
6. Multi-view Attention for gestational age at birth prediction. (arXiv:2207.04130v1 [eess.IV])
7. Cross-Attention Transformer for Video Interpolation. (arXiv:2207.04132v1 [cs.CV])
8. L$_0$onie: Compressing COINs with L$_0$-constraints. (arXiv:2207.04144v1 [cs.LG])
9. A Survey of Task-Based Machine Learning Content Extraction Services for VIDINT. (arXiv:2207.04158v1 [cs.ET])
10. Few 'Zero Level Set'-Shot Learning of Shape Signed Distance Functions in Feature Space. (arXiv:2207.04161v1 [cs.CV])
11. Towards Multimodal Vision-Language Models Generating Non-Generic Text. (arXiv:2207.04174v1 [cs.CV])
12. Direct Handheld Burst Imaging to Simulated Defocus. (arXiv:2207.04175v1 [cs.CV])
13. Learning Robust Representation for Joint Grading of Ophthalmic Diseases via Adaptive Curriculum and Feature Disentanglement. (arXiv:2207.04183v1 [cs.CV])
14. Domain Alignment Meets Fully Test-Time Adaptation. (arXiv:2207.04185v1 [cs.CV])
15. A Study on Self-Supervised Object Detection Pretraining. (arXiv:2207.04186v1 [cs.CV])
16. Learning Structured Representations of Visual Scenes. (arXiv:2207.04200v1 [cs.CV])
17. Smart Multi-tenant Federated Learning. (arXiv:2207.04202v1 [cs.LG])
18. Variational Approach for Intensity Domain Multi-**exposure** Image Fusion. (arXiv:2207.04204v1 [cs.CV])
19. BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid Counterfactual Training for Robust Content-based Image Retrieval. (arXiv:2207.04211v1 [cs.AI])
20. COVID-19 Disease Identification on Chest-CT images using CNN and VGG16. (arXiv:2207.04212v1 [eess.IV])
21. Dual-path Attention is All You Need for Audio-Visual Speech Extraction. (arXiv:2207.04213v1 [cs.MM])
22. Rethinking Persistent Homology for Visual Recognition. (arXiv:2207.04220v1 [cs.CV])
23. Learning to Register Unbalanced Point Pairs. (arXiv:2207.04221v1 [cs.CV])
24. SiaTrans: Siamese Transformer Network for RGB-D Salient Object Detection with Depth Image Classification. (arXiv:2207.04224v1 [cs.CV])
25. Batch-efficient EigenDecomposition for Small and Medium Matrices. (arXiv:2207.04228v1 [cs.CV])
26. Sparse Ellipsometry: Portable Acquisition of Polarimetric SVBRDF and Shape with Unstructured Flash Photography. (arXiv:2207.04236v1 [cs.GR])
27. PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for Cross-View Image Translation. (arXiv:2207.04242v1 [cs.CV])
28. Improving saliency models' predictions of the next fixation with humans' intrinsic cost of gaze shifts. (arXiv:2207.04250v1 [cs.CV])
29. Rank-Enhanced Low-Dimensional Convolution Set for Hyperspectral Image Denoising. (arXiv:2207.04266v1 [eess.IV])
30. Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises and Challenges. (arXiv:2207.04295v1 [cs.LG])
31. SHDM-NET: Heat Map Detail Guidance with Image Matting for Industrial Weld Semantic Segmentation Network. (arXiv:2207.04297v1 [cs.CV])
32. QKVA grid: Attention in Image Perspective and Stacked DETR. (arXiv:2207.04313v1 [cs.CV])
33. Improving Diffusion Model Efficiency Through Patching. (arXiv:2207.04316v1 [cs.LG])
34. Snipper: A Spatiotemporal Transformer for Simultaneous Multi-Person 3D Pose Estimation Tracking and Forecasting on a Video Snippet. (arXiv:2207.04320v1 [cs.CV])
35. Video Coding Using Learned Latent GAN Compression. (arXiv:2207.04324v1 [eess.IV])
36. Unsupervised Joint Image Transfer and Uncertainty Quantification using Patch Invariant Networks. (arXiv:2207.04325v1 [cs.CV])
37. Explaining Chest X-ray Pathologies in Natural Language. (arXiv:2207.04343v1 [cs.CV])
38. Segmentation of Blood Vessels, Optic Disc Localization, Detection of Exudates and Diabetic Retinopathy Diagnosis from Digital Fundus Images. (arXiv:2207.04345v1 [eess.IV])
39. Radiomics-Guided Global-Local Transformer for Weakly Supervised Pathology Localization in Chest X-Rays. (arXiv:2207.04394v1 [cs.CV])
40. 2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds. (arXiv:2207.04397v1 [cs.CV])
41. Self-supervised Learning with Local Contrastive Loss for Detection and Semantic Segmentation. (arXiv:2207.04398v1 [cs.CV])
42. Horizontal and Vertical Attention in Transformers. (arXiv:2207.04399v1 [cs.CV])
43. Self-attention on Multi-Shifted Windows for Scene Segmentation. (arXiv:2207.04403v1 [cs.CV])
44. CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical Expression Recognition. (arXiv:2207.04410v1 [cs.CV])
45. SFNet: Faster, Accurate, and Domain Agnostic Semantic Segmentation via Semantic Flow. (arXiv:2207.04415v1 [cs.CV])
46. Dual-Correction Adaptation Network for Noisy Knowledge Transfer. (arXiv:2207.04423v1 [cs.CV])
47. Hiding Your Signals: A Security Analysis of PPG-based Biometric Authentication. (arXiv:2207.04434v1 [cs.CR])
48. SRRT: Search Region Regulation Tracking. (arXiv:2207.04438v1 [cs.CV])
49. Mix-Teaching: A Simple, Unified and Effective Semi-Supervised Learning Framework for Monocular 3D Object Detection. (arXiv:2207.04448v1 [cs.CV])
50. Progressively-connected Light Field Network for Efficient View Synthesis. (arXiv:2207.04465v1 [cs.CV])
51. DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer. (arXiv:2207.04491v1 [cs.CV])
52. Towards Adaptive Unknown Authentication for Universal Domain Adaptation by Classifier Paradox. (arXiv:2207.04494v1 [cs.CV])
53. Learning-based Monocular 3D Reconstruction of Birds: A Contemporary Survey. (arXiv:2207.04512v1 [cs.CV])
54. Facilitated machine learning for image-based fruit quality assessment in developing countries. (arXiv:2207.04523v1 [cs.CV])
55. Efficient Multi-Task RGB-D Scene Analysis for Indoor Environments. (arXiv:2207.04526v1 [cs.CV])
56. An Open-Source Tool for Longitudinal Whole-Brain and White Matter Lesion Segmentation. (arXiv:2207.04534v1 [cs.CV])
57. Depthformer : Multiscale Vision Transformer For Monocular Depth Estimation With Local Global Information Fusion. (arXiv:2207.04535v1 [cs.CV])
58. Depth Perspective-aware Multiple Object Tracking. (arXiv:2207.04551v1 [cs.CV])
59. GAN-based Virtual Re-Staining: A Promising Solution for Whole Slide Image Analysis. (arXiv:1901.04059v2 [cs.CV] UPDATED)
60. Identifying and Compensating for Feature Deviation in Imbalanced Deep Learning. (arXiv:2001.01385v4 [cs.LG] UPDATED)
61. From Symmetry to Geometry: Tractable Nonconvex Problems. (arXiv:2007.06753v4 [cs.LG] UPDATED)
62. Towards End-to-end Car License Plate Location and Recognition in Unconstrained Scenarios. (arXiv:2008.10916v2 [cs.CV] UPDATED)
63. Amodal Segmentation through Out-of-Task and Out-of-Distribution Generalization with a Bayesian Model. (arXiv:2010.13175v4 [cs.CV] UPDATED)
64. A Survey on Deep Learning-based Single Image Crowd Counting: Network Design, Loss Function and Supervisory Signal. (arXiv:2012.15685v2 [cs.CV] UPDATED)
65. Rethinking Interactive Image Segmentation: Feature Space Annotation. (arXiv:2101.04378v3 [cs.CV] UPDATED)
66. Visual explanation of black-box model: Similarity Difference and Uniqueness (SIDU) method. (arXiv:2101.10710v2 [cs.CV] UPDATED)
67. Learned Camera Gain and **Exposure** Control for Improved Visual Feature Detection and Matching. (arXiv:2102.04341v3 [cs.RO] UPDATED)
68. Learning Purified Feature Representations from Task-irrelevant Labels. (arXiv:2102.10955v3 [cs.LG] UPDATED)
69. Exploiting Playbacks in Unsupervised Domain Adaptation for 3D Object Detection. (arXiv:2103.14198v2 [cs.CV] UPDATED)
70. Self-supervised object detection from audio-visual correspondence. (arXiv:2104.06401v2 [cs.CV] UPDATED)
71. An Exact Hypergraph Matching Algorithm for Nuclear Identification in Embryonic Caenorhabditis elegans. (arXiv:2104.10003v3 [cs.CV] UPDATED)
72. FourierNets enable the design of highly non-local optical encoders for computational imaging. (arXiv:2104.10611v5 [eess.IV] UPDATED)
73. Stochastic Neural Networks for Automatic Cell Tracking in Microscopy Image Sequences of Bacterial Colonies. (arXiv:2104.13482v2 [cs.CV] UPDATED)
74. GAN Cocktail: mixing GANs without dataset access. (arXiv:2106.03847v2 [cs.LG] UPDATED)
75. On the Coupling of Depth and Egomotion Networks for Self-Supervised Structure from Motion. (arXiv:2106.04007v3 [cs.CV] UPDATED)
76. Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v4 [cs.CV] UPDATED)
77. Making Images Real Again: A Comprehensive Survey on Deep Image Composition. (arXiv:2106.14490v2 [cs.CV] UPDATED)
78. How to Train Your MAML to Excel in Few-Shot Classification. (arXiv:2106.16245v3 [cs.LG] UPDATED)
79. Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v2 [cs.CV] UPDATED)
80. FINT: Field-aware INTeraction Neural Network For CTR Prediction. (arXiv:2107.01999v3 [cs.IR] UPDATED)
81. TransAttUnet: Multi-level Attention-guided U-Net with Transformer for Medical Image Segmentation. (arXiv:2107.05274v2 [eess.IV] UPDATED)
82. Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm. (arXiv:2108.03002v4 [math.NA] UPDATED)
83. Tensor Full Feature Measure and Its Nonconvex Relaxation Applications to Tensor Recovery. (arXiv:2109.12257v2 [cs.CV] UPDATED)
84. CTRN: Class-Temporal Relational Network for Action Detection. (arXiv:2110.13473v2 [cs.CV] UPDATED)
85. Robust deep learning-based semantic organ segmentation in hyperspectral images. (arXiv:2111.05408v2 [eess.IV] UPDATED)
86. Multiple Hypothesis Hypergraph Tracking for Posture Identification in Embryonic Caenorhabditis elegans. (arXiv:2111.06425v2 [eess.IV] UPDATED)
87. Pedestrian Detection by Exemplar-Guided Contrastive Learning. (arXiv:2111.08974v3 [cs.CV] UPDATED)
88. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v5 [eess.IV] UPDATED)
89. Classification-Regression for Chart Comprehension. (arXiv:2111.14792v2 [cs.CV] UPDATED)
90. **NeRF**-SR: High-Quality Neural Radiance Fields using Super-Sampling. (arXiv:2112.01759v2 [cs.CV] UPDATED)
91. Classification of COVID-19 on chest X-Ray images using Deep Learning model with Histogram Equalization and Lungs Segmentation. (arXiv:2112.02478v3 [eess.IV] UPDATED)
92. DoodleFormer: Creative Sketch Drawing with Transformers. (arXiv:2112.03258v2 [cs.CV] UPDATED)
93. Fully Attentional Network for Semantic Segmentation. (arXiv:2112.04108v4 [cs.CV] UPDATED)
94. Looking Beyond Corners: Contrastive Learning of Visual Representations for Keypoint Detection and Description Extraction. (arXiv:2112.12002v2 [cs.CV] UPDATED)
95. Free-Viewpoint RGB-D Human Performance Capture and Rendering. (arXiv:2112.13889v3 [cs.CV] UPDATED)
96. Tensor Recovery Based on Tensor Equivalent Minimax-Concave Penalty. (arXiv:2201.12709v2 [cs.CV] UPDATED)
97. Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding. (arXiv:2202.03323v2 [eess.IV] UPDATED)
98. Motion Puzzle: Arbitrary Motion Style Transfer by Body Part. (arXiv:2202.05274v2 [cs.GR] UPDATED)
99. Depth-Cooperated Trimodal Network for Video Salient Object Detection. (arXiv:2202.06060v2 [cs.CV] UPDATED)
100. Universal Adversarial Examples in Remote Sensing: Methodology and Benchmark. (arXiv:2202.07054v2 [cs.CV] UPDATED)
101. MANet: Improving Video Denoising with a Multi-Alignment Network. (arXiv:2202.09704v2 [cs.CV] UPDATED)
102. Visual Attention Network. (arXiv:2202.09741v5 [cs.CV] UPDATED)
103. Deep learning classification of large-scale point clouds: A case study on cuneiform tablets. (arXiv:2202.10851v2 [cs.CV] UPDATED)
104. RelMobNet: End-to-end relative camera pose estimation using a robust two-stage training. (arXiv:2202.12838v2 [cs.CV] UPDATED)
105. Point Label Aware Superpixels for Multi-species Segmentation of Underwater Imagery. (arXiv:2202.13487v2 [cs.CV] UPDATED)
106. Continual BatchNorm Adaptation (CBNA) for Semantic Segmentation. (arXiv:2203.01074v2 [cs.CV] UPDATED)
107. Recent, rapid advancement in visual question answering architecture: a review. (arXiv:2203.01322v4 [cs.CV] UPDATED)
108. Spatio-Temporal Gating-Adjacency GCN for Human Motion Prediction. (arXiv:2203.01474v3 [cs.CV] UPDATED)
109. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v3 [cs.LG] UPDATED)
110. Semantic-Aware Latent Space Exploration for Face Image **Restoration**. (arXiv:2203.03005v2 [cs.CV] UPDATED)
111. DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection. (arXiv:2203.03605v4 [cs.CV] UPDATED)
112. EdgeFormer: Improving Light-weight ConvNets by Learning from Vision Transformers. (arXiv:2203.03952v3 [cs.CV] UPDATED)
113. Source-free Video Domain Adaptation by Learning Temporal Consistency for Action Recognition. (arXiv:2203.04559v4 [cs.CV] UPDATED)
114. Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction. (arXiv:2203.04845v3 [cs.CV] UPDATED)
115. Multi-Curve Translator for High-Resolution Photorealistic Image Translation. (arXiv:2203.07756v2 [cs.CV] UPDATED)
116. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v2 [cs.LG] UPDATED)
117. Unitail: Detecting, Reading, and Matching in Retail Scene. (arXiv:2204.00298v3 [cs.CV] UPDATED)
118. A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v2 [eess.IV] UPDATED)
119. Fashionformer: A simple, Effective and Unified Baseline for Human Fashion Segmentation and Recognition. (arXiv:2204.04654v2 [cs.CV] UPDATED)
120. Panoptic-PartFormer: Learning a Unified Model for Panoptic Part Segmentation. (arXiv:2204.04655v2 [cs.CV] UPDATED)
121. Calibrating Class Weights with Multi-Modal Information for Partial Video Domain Adaptation. (arXiv:2204.06187v3 [cs.CV] UPDATED)
122. Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
123. Rotationally Equivariant 3D Object Detection. (arXiv:2204.13630v2 [cs.CV] UPDATED)
124. Composition-aware Graphic Layout GAN for Visual-textual Presentation Designs. (arXiv:2205.00303v2 [cs.CV] UPDATED)
125. Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation. (arXiv:2205.01271v4 [cs.CV] UPDATED)
126. Generate and Edit Your Own Character in a Canonical View. (arXiv:2205.02974v2 [cs.CV] UPDATED)
127. FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects. (arXiv:2205.04382v2 [cs.RO] UPDATED)
128. Knowledge Distillation for Multi-Target Domain Adaptation in Real-Time Person Re-Identification. (arXiv:2205.06237v2 [cs.CV] UPDATED)
129. VLCDoC: Vision-Language Contrastive Pre-Training Model for Cross-Modal Document Classification. (arXiv:2205.12029v2 [cs.CV] UPDATED)
130. Sim-To-Real Transfer of Visual Grounding for Human-Aided Ambiguity Resolution. (arXiv:2205.12089v2 [cs.CV] UPDATED)
131. Few-Shot Adaptation of Pre-Trained Networks for Domain Shift. (arXiv:2205.15234v2 [cs.CV] UPDATED)
132. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v3 [cs.LG] UPDATED)
133. Learned reconstruction methods with convergence guarantees. (arXiv:2206.05431v2 [cs.CV] UPDATED)
134. Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric Segmentation. (arXiv:2206.06575v2 [eess.IV] UPDATED)
135. Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut Features. (arXiv:2206.07155v2 [cs.LG] UPDATED)
136. Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation. (arXiv:2206.07634v2 [cs.CV] UPDATED)
137. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v2 [cs.LG] UPDATED)
138. Rethinking Audio-visual Synchronization for Active Speaker Detection. (arXiv:2206.10421v2 [cs.SD] UPDATED)
139. Vision Transformer for Contrastive Clustering. (arXiv:2206.12925v2 [cs.CV] UPDATED)
140. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v2 [cs.LG] UPDATED)
141. PolarFormer: Multi-camera 3D Object Detection with Polar Transformers. (arXiv:2206.15398v3 [cs.CV] UPDATED)
142. How Far Can I Go ? : A Self-Supervised Approach for Deterministic Video Depth Forecasting. (arXiv:2207.00506v2 [cs.CV] UPDATED)
143. Test-time Adaptation with Calibration of Medical Image Classification Nets for Label Distribution Shift. (arXiv:2207.00769v2 [eess.IV] UPDATED)
144. Can Language Understand Depth?. (arXiv:2207.01077v2 [cs.CV] UPDATED)
145. DecisioNet: A Binary-Tree Structured Neural Network. (arXiv:2207.01127v3 [cs.CV] UPDATED)
146. Detection of ADHD based on Eye Movements during Natural Viewing. (arXiv:2207.01377v3 [cs.CV] UPDATED)
147. Memory Efficient Patch-based Training for INR-based GANs. (arXiv:2207.01395v2 [cs.CV] UPDATED)
148. Multiview Detection with Cardboard Human Modeling. (arXiv:2207.02013v2 [cs.CV] UPDATED)
149. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v3 [eess.IV] UPDATED)
150. Two-stage Decision Improves Open-Set Panoptic Segmentation. (arXiv:2207.02504v2 [cs.CV] UPDATED)
151. PIC 4th Challenge: Semantic-Assisted Multi-Feature Encoding and Multi-Head Decoding for Dense Video Captioning. (arXiv:2207.02583v2 [cs.CV] UPDATED)
152. Semi-supervised Human Pose Estimation in Art-historical Images. (arXiv:2207.02976v2 [cs.CV] UPDATED)
153. Design of Human Machine Interface through vision-based low-cost Hand Gesture Recognition system based on deep CNN. (arXiv:2207.03112v2 [cs.CV] UPDATED)
154. Boosting Zero-shot Learning via Contrastive Optimization of Attribute Representations. (arXiv:2207.03824v2 [cs.CV] UPDATED)
155. Event Collapse in Contrast Maximization Frameworks. (arXiv:2207.04007v2 [cs.CV] UPDATED)
156. Pruning Early Exit Networks. (arXiv:2207.03644v1 [cs.LG] CROSS LISTED)
## eess.IV
---
**40** new papers in eess.IV:-) 
1. Graph-based Multi-View Fusion and Local Adaptation: Mitigating Within-Household Confusability for Speaker Identification. (arXiv:2207.04081v1 [eess.AS])
2. FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
3. Multi-view Attention for gestational age at birth prediction. (arXiv:2207.04130v1 [eess.IV])
4. BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid Counterfactual Training for Robust Content-based Image Retrieval. (arXiv:2207.04211v1 [cs.AI])
5. COVID-19 Disease Identification on Chest-CT images using CNN and VGG16. (arXiv:2207.04212v1 [eess.IV])
6. Multi-Attribute Attention Network for Interpretable Diagnosis of Thyroid Nodules in Ultrasound Images. (arXiv:2207.04219v1 [eess.IV])
7. Spatiotemporal singular value decomposition for denoising in photoacoustic imaging with low-energy excitation light source. (arXiv:2207.04229v1 [eess.IV])
8. Rank-Enhanced Low-Dimensional Convolution Set for Hyperspectral Image Denoising. (arXiv:2207.04266v1 [eess.IV])
9. Video Coding Using Learned Latent GAN Compression. (arXiv:2207.04324v1 [eess.IV])
10. Unsupervised Joint Image Transfer and Uncertainty Quantification using Patch Invariant Networks. (arXiv:2207.04325v1 [cs.CV])
11. Segmentation of Blood Vessels, Optic Disc Localization, Detection of Exudates and Diabetic Retinopathy Diagnosis from Digital Fundus Images. (arXiv:2207.04345v1 [eess.IV])
12. Automating Detection of Papilledema in Pediatric Fundus Images with Explainable Machine Learning. (arXiv:2207.04565v1 [eess.IV])
13. Learned Video Compression via Heterogeneous Deformable Compensation Network. (arXiv:2207.04589v1 [eess.IV])
14. An Ultra-low Power TinyML System for **Real-time** Visual Processing at Edge. (arXiv:2207.04663v1 [eess.IV])
15. Hybrid Skip: A Biologically Inspired Skip Connection for the UNet Architecture. (arXiv:2207.04721v1 [cs.CV])
16. Randomized Kaczmarz Method for Single Particle X-ray Image Phase Retrieval. (arXiv:2207.04736v1 [q-bio.QM])
17. Fingerprint Liveness Detection Based on Quality Measures. (arXiv:2207.04809v1 [cs.CV])
18. On the vulnerability of fingerprint verification systems to fake fingerprint attacks. (arXiv:2207.04813v1 [cs.CV])
19. Forward Error Correction applied to JPEG-XS codestreams. (arXiv:2207.04825v1 [eess.IV])
20. Single-cell phase-contrast tomograms data encoded by 3D Zernike descriptors. (arXiv:2207.04854v1 [physics.optics])
21. Hierarchical Average Precision Training for Pertinent Image Retrieval. (arXiv:2207.04873v1 [cs.CV])
22. Audio-Visual Segmentation. (arXiv:2207.05042v1 [cs.CV])
23. Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis. (arXiv:2207.05049v1 [cs.CV])
24. Multi-Channel Deep Networks for Block-Based Image Compressive Sensing. (arXiv:1908.11221v2 [eess.IV] UPDATED)
25. A Probabilistic Bayesian Approach to Recover $R_2^*$ map and Phase Images for Quantitative Susceptibility Mapping. (arXiv:2103.05535v3 [eess.IV] UPDATED)
26. FourierNets enable the design of highly non-local optical encoders for computational imaging. (arXiv:2104.10611v5 [eess.IV] UPDATED)
27. TransAttUnet: Multi-level Attention-guided U-Net with Transformer for Medical Image Segmentation. (arXiv:2107.05274v2 [eess.IV] UPDATED)
28. Robust deep learning-based semantic organ segmentation in hyperspectral images. (arXiv:2111.05408v2 [eess.IV] UPDATED)
29. Multiple Hypothesis Hypergraph Tracking for Posture Identification in Embryonic Caenorhabditis elegans. (arXiv:2111.06425v2 [eess.IV] UPDATED)
30. Improving needle visibility in LED-based photoacoustic imaging using deep learning with semi-synthetic datasets. (arXiv:2111.07673v3 [eess.IV] UPDATED)
31. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v5 [eess.IV] UPDATED)
32. Classification of COVID-19 on chest X-Ray images using Deep Learning model with Histogram Equalization and Lungs Segmentation. (arXiv:2112.02478v3 [eess.IV] UPDATED)
33. Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding. (arXiv:2202.03323v2 [eess.IV] UPDATED)
34. Learning Contextually Fused Audio-visual Representations for Audio-visual Speech Recognition. (arXiv:2202.07428v2 [eess.IV] UPDATED)
35. A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v2 [eess.IV] UPDATED)
36. Med-DANet: Dynamic Architecture Network for Efficient Medical Volumetric Segmentation. (arXiv:2206.06575v2 [eess.IV] UPDATED)
37. Frame-type Sensitive RDO Control for Content-Adaptive-encoding. (arXiv:2206.11976v2 [eess.IV] UPDATED)
38. GreenBIQA: A Lightweight Blind Image Quality Assessment Method. (arXiv:2206.14400v2 [eess.IV] UPDATED)
39. Test-time Adaptation with Calibration of Medical Image Classification Nets for Label Distribution Shift. (arXiv:2207.00769v2 [eess.IV] UPDATED)
40. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v3 [eess.IV] UPDATED)
## cs.LG
---
**234** new papers in cs.LG:-) 
1. Learning Causal Effects on Hypergraphs. (arXiv:2207.04049v1 [cs.LG])
2. Few-Example Clustering via Contrastive Learning. (arXiv:2207.04050v1 [cs.LG])
3. On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v1 [cs.LG])
4. Online Learning in Supply-Chain Games. (arXiv:2207.04054v1 [cs.GT])
5. Causal Discovery using Model Invariance through Knockoff Interventions. (arXiv:2207.04055v1 [cs.LG])
6. Large Scale Mask Optimization Via Convolutional Fourier Neural Operator and Litho-Guided Self Training. (arXiv:2207.04056v1 [cs.LG])
7. Models Out of Line: A Fourier Lens on Distribution Shift Robustness. (arXiv:2207.04075v1 [cs.LG])
8. Graph-based Multi-View Fusion and Local Adaptation: Mitigating Within-Household Confusability for Speaker Identification. (arXiv:2207.04081v1 [eess.AS])
9. Adaptive Self-supervision Algorithms for Physics-informed Neural Networks. (arXiv:2207.04084v1 [cs.LG])
10. StatMix: Data augmentation method that relies on image statistics in federated learning. (arXiv:2207.04103v1 [cs.LG])
11. Evaluating Systemic Error Detection Methods using Synthetic Images. (arXiv:2207.04104v1 [cs.LG])
12. Seasonal Encoder-Decoder Architecture for Forecasting. (arXiv:2207.04113v1 [cs.LG])
13. Ablation Study of How Run Time Assurance Impacts the Training and Performance of Reinforcement Learning Agents. (arXiv:2207.04117v1 [cs.LG])
14. Braid-based architecture search. (arXiv:2207.04121v1 [cs.LG])
15. Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
16. Not all broken defenses are equal: The dead angles of adversarial accuracy. (arXiv:2207.04129v1 [cs.LG])
17. Multi-view Attention for gestational age at birth prediction. (arXiv:2207.04130v1 [eess.IV])
18. Modeling and Predicting Transistor Aging under Workload Dependency using Machine Learning. (arXiv:2207.04134v1 [cs.LG])
19. CompoSuite: A Compositional Reinforcement Learning Benchmark. (arXiv:2207.04136v1 [cs.LG])
20. Interactive Recommendations for Optimal Allocations in Markets with Constraints. (arXiv:2207.04143v1 [cs.LG])
21. L$_0$onie: Compressing COINs with L$_0$-constraints. (arXiv:2207.04144v1 [cs.LG])
22. Probing Classifiers are Unreliable for Concept Removal and Detection. (arXiv:2207.04153v1 [cs.LG])
23. TalkToModel: Understanding Machine Learning Models With Open Ended Dialogues. (arXiv:2207.04154v1 [cs.LG])
24. Few 'Zero Level Set'-Shot Learning of Shape Signed Distance Functions in Feature Space. (arXiv:2207.04161v1 [cs.CV])
25. Variational Mixtures of ODEs for Inferring Cellular Gene Expression Dynamics. (arXiv:2207.04166v1 [cs.LG])
26. Stochastic approximation with decision-dependent distributions: asymptotic normality and optimality. (arXiv:2207.04173v1 [math.OC])
27. Transformer Neural Processes: Uncertainty-Aware Meta Learning Via Sequence Modeling. (arXiv:2207.04179v1 [cs.LG])
28. Domain Alignment Meets Fully Test-Time Adaptation. (arXiv:2207.04185v1 [cs.CV])
29. Supervised Machine Learning for Effective Missile Launch Based on Beyond Visual Range Air Combat Simulations. (arXiv:2207.04188v1 [cs.LG])
30. Multi-label Classification with High-rank and High-order Label Correlations. (arXiv:2207.04197v1 [cs.LG])
31. Improved Binary Forward Exploration: Learning Rate Scheduling Method for Stochastic Optimization. (arXiv:2207.04198v1 [cs.LG])
32. Learning Structured Representations of Visual Scenes. (arXiv:2207.04200v1 [cs.CV])
33. Smart Multi-tenant Federated Learning. (arXiv:2207.04202v1 [cs.LG])
34. Learning to Separate Voices by Spatial Regions. (arXiv:2207.04203v1 [cs.SD])
35. SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare. (arXiv:2207.04208v1 [cs.AI])
36. Invisible Backdoor Attacks Using Data Poisoning in the Frequency Domain. (arXiv:2207.04209v1 [cs.LG])
37. BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid Counterfactual Training for Robust Content-based Image Retrieval. (arXiv:2207.04211v1 [cs.AI])
38. COVID-19 Disease Identification on Chest-CT images using CNN and VGG16. (arXiv:2207.04212v1 [eess.IV])
39. Dual-path Attention is All You Need for Audio-Visual Speech Extraction. (arXiv:2207.04213v1 [cs.MM])
40. Wasserstein Graph Distance based on $L_1$-Approximated Tree Edit Distance between Weisfeiler-Lehman Subtrees. (arXiv:2207.04216v1 [cs.LG])
41. Generating Pseudo-labels Adaptively for Few-shot Model-Agnostic Meta-Learning. (arXiv:2207.04217v1 [cs.LG])
42. Subclasses of Class Function used to Implement Transformations of Statistical Models. (arXiv:2207.04218v1 [cs.PL])
43. SiaTrans: Siamese Transformer Network for RGB-D Salient Object Detection with Depth Image Classification. (arXiv:2207.04224v1 [cs.CV])
44. On the Robustness and Anomaly Detection of Sparse Neural Networks. (arXiv:2207.04227v1 [cs.LG])
45. Batch-efficient EigenDecomposition for Small and Medium Matrices. (arXiv:2207.04228v1 [cs.CV])
46. CEG4N: Counter-Example Guided Neural Network Quantization Refinement. (arXiv:2207.04231v1 [cs.LG])
47. Few-shot training LLMs for project-specific code-summarization. (arXiv:2207.04237v1 [cs.SE])
48. A Statistically-Based Approach to Feedforward Neural Network Model Selection. (arXiv:2207.04248v1 [stat.ME])
49. A novel evaluation methodology for supervised Feature Ranking algorithms. (arXiv:2207.04258v1 [cs.LG])
50. Fuzzy Clustering by Hyperbolic Smoothing. (arXiv:2207.04261v1 [stat.ML])
51. Attention and Self-Attention in Random Forests. (arXiv:2207.04293v1 [cs.LG])
52. Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises and Challenges. (arXiv:2207.04295v1 [cs.LG])
53. TensorIR: An Abstraction for Automatic Tensorized Program Optimization. (arXiv:2207.04296v1 [cs.LG])
54. Training Robust Deep Models for Time-Series Domain: Novel Algorithms and Theoretical Analysis. (arXiv:2207.04305v1 [cs.LG])
55. Out-of-Distribution Detection in Time-Series Domain: A Novel Seasonal Ratio Scoring Approach. (arXiv:2207.04306v1 [cs.LG])
56. Adversarial Framework with Certified Robustness for Time-Series Domain via Statistical Features. (arXiv:2207.04307v1 [cs.LG])
57. Dynamic Time Warping based Adversarial Framework for Time-Series Domain. (arXiv:2207.04308v1 [cs.LG])
58. Improving Diffusion Model Efficiency Through Patching. (arXiv:2207.04316v1 [cs.LG])
59. Unsupervised Joint Image Transfer and Uncertainty Quantification using Patch Invariant Networks. (arXiv:2207.04325v1 [cs.CV])
60. Error Analysis of Tensor-Train Cross Approximation. (arXiv:2207.04327v1 [cs.LG])
61. Multi-Model Federated Learning with Provable Guarantees. (arXiv:2207.04330v1 [cs.LG])
62. Emerging Patterns in the Continuum Representation of Protein-Lipid Fingerprints. (arXiv:2207.04333v1 [q-bio.QM])
63. Variance Reduced ProxSkip: Algorithm, Theory and Application to Federated Learning. (arXiv:2207.04338v1 [cs.LG])
64. An Introduction to Lifelong Supervised Learning. (arXiv:2207.04354v1 [cs.LG])
65. A Comparative Study of Self-supervised Speech Representation Based Voice Conversion. (arXiv:2207.04356v1 [cs.SD])
66. State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections. (arXiv:2207.04361v1 [cs.RO])
67. Domain Adaptation Under Behavioral and Temporal Shifts for Natural Time Series Mobile Activity Recognition. (arXiv:2207.04367v1 [cs.LG])
68. On Graph Neural Network Fairness in the Presence of Heterophilous Neighborhoods. (arXiv:2207.04376v1 [cs.SI])
69. Connect the Dots: Tighter Discrete Approximations of Privacy Loss Distributions. (arXiv:2207.04380v1 [cs.DS])
70. Faster Privacy Accounting via Evolving Discretization. (arXiv:2207.04381v1 [cs.DS])
71. Bregman Proximal Langevin Monte Carlo via Bregman--Moreau Envelopes. (arXiv:2207.04387v1 [stat.ML])
72. Scalable Privacy-enhanced Benchmark Graph Generative Model for Graph Convolutional Networks. (arXiv:2207.04396v1 [cs.LG])
73. LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action. (arXiv:2207.04429v1 [cs.RO])
74. NGAME: Negative Mining-aware Mini-batching for Extreme Classification. (arXiv:2207.04452v1 [cs.LG])
75. TCR: A Transformer Based Deep Network for Predicting Cancer Drugs Response. (arXiv:2207.04457v1 [cs.LG])
76. Noisy Heuristics NAS: A Network Morphism based Neural Architecture Search using Heuristics. (arXiv:2207.04467v1 [cs.LG])
77. Finite-time High-probability Bounds for Polyak-Ruppert Averaged Iterates of Linear Stochastic Approximation. (arXiv:2207.04475v1 [stat.ML])
78. Scaling up ML-based Black-box Planning with Partial STRIPS Models. (arXiv:2207.04479v1 [cs.AI])
79. Automatic differentiation and the optimization of differential equation models in biology. (arXiv:2207.04487v1 [q-bio.QM])
80. A Forward Propagation Algorithm for Online Optimization of Nonlinear Stochastic Differential Equations. (arXiv:2207.04496v1 [math.PR])
81. One-shot Neural Backdoor Erasing via Adversarial Weight Masking. (arXiv:2207.04497v1 [cs.LG])
82. FIB: A Method for Evaluation of Feature Impact Balance in Multi-Dimensional Data. (arXiv:2207.04500v1 [cs.LG])
83. Efficient Multi-Task RGB-D Scene Analysis for Indoor Environments. (arXiv:2207.04526v1 [cs.CV])
84. Multi-task Envisioning Transformer-based Autoencoder for Corporate Credit Rating Migration Early Prediction. (arXiv:2207.04539v1 [cs.LG])
85. Multi-Frequency Information Enhanced Channel Attention Module for Speaker Representation Learning. (arXiv:2207.04540v1 [eess.AS])
86. Scaling the Number of Tasks in Continual Learning. (arXiv:2207.04543v1 [cs.LG])
87. FairDistillation: Mitigating Stereotyping in Language Models. (arXiv:2207.04546v1 [cs.CL])
88. Learning to Order for Inventory Systems with Lost Sales and Uncertain Supplies. (arXiv:2207.04550v1 [math.OC])
89. An empirical learning-based validation procedure for simulation workflow. (arXiv:1809.04441v2 [cs.LG] UPDATED)
90. swTVM: Towards Optimized Tensor Code Generation for Deep Learning on Sunway Many-Core Processor. (arXiv:1904.07404v3 [cs.LG] UPDATED)
91. Multi-Channel Deep Networks for Block-Based Image Compressive Sensing. (arXiv:1908.11221v2 [eess.IV] UPDATED)
92. Robust Dynamic Assortment Optimization in the Presence of Outlier Customers. (arXiv:1910.04183v2 [stat.ML] UPDATED)
93. Identifying and Compensating for Feature Deviation in Imbalanced Deep Learning. (arXiv:2001.01385v4 [cs.LG] UPDATED)
94. Semi-Structured Distributional Regression -- Extending Structured Additive Models by Arbitrary Deep Neural Networks and Data Modalities. (arXiv:2002.05777v5 [stat.ML] UPDATED)
95. CoLES: Contrastive Learning for Event Sequences with Self-Supervision. (arXiv:2002.08232v2 [cs.LG] UPDATED)
96. From Symmetry to Geometry: Tractable Nonconvex Problems. (arXiv:2007.06753v4 [cs.LG] UPDATED)
97. Heteroscedastic Uncertainty for Robust Generative Latent Dynamics. (arXiv:2008.08157v2 [cs.RO] UPDATED)
98. Tackling Over-Smoothing for General Graph Convolutional Networks. (arXiv:2008.09864v5 [cs.LG] UPDATED)
99. Towards End-to-end Car License Plate Location and Recognition in Unconstrained Scenarios. (arXiv:2008.10916v2 [cs.CV] UPDATED)
100. A Survey of Deep Learning Architectures for Intelligent Reflecting Surfaces. (arXiv:2009.02540v4 [eess.SP] UPDATED)
101. TensorBNN: Bayesian Inference for Neural Networks using Tensorflow. (arXiv:2009.14393v3 [physics.comp-ph] UPDATED)
102. Language for Description of Worlds. (arXiv:2010.16243v4 [cs.AI] UPDATED)
103. Visual explanation of black-box model: Similarity Difference and Uniqueness (SIDU) method. (arXiv:2101.10710v2 [cs.CV] UPDATED)
104. Enabling Binary Neural Network Training on the Edge. (arXiv:2102.04270v5 [cs.LG] UPDATED)
105. When and How Mixup Improves Calibration. (arXiv:2102.06289v3 [cs.LG] UPDATED)
106. Learning Purified Feature Representations from Task-irrelevant Labels. (arXiv:2102.10955v3 [cs.LG] UPDATED)
107. Inductive Bias of Multi-Channel Linear Convolutional Networks with Bounded Weight Norm. (arXiv:2102.12238v4 [cs.LG] UPDATED)
108. E$^2$CM: Early Exit via Class Means for Efficient Supervised and Unsupervised Learning. (arXiv:2103.01148v3 [cs.LG] UPDATED)
109. Modeling Censored Mobility Demand through Quantile Regression Neural Networks. (arXiv:2104.01214v2 [cs.LG] UPDATED)
110. Understanding Continual Learning Settings with Data Distribution Drift Analysis. (arXiv:2104.01678v2 [cs.LG] UPDATED)
111. ACERAC: Efficient reinforcement learning in fine time discretization. (arXiv:2104.04004v4 [cs.LG] UPDATED)
112. Coupling streaming AI and HPC ensembles to achieve 100-1000x faster biomolecular simulations. (arXiv:2104.04797v4 [cs.DC] UPDATED)
113. FourierNets enable the design of highly non-local optical encoders for computational imaging. (arXiv:2104.10611v5 [eess.IV] UPDATED)
114. Personalized Algorithm Generation: A Case Study in Learning ODE Integrators. (arXiv:2105.01303v3 [math.NA] UPDATED)
115. Fooling Partial Dependence via Data Poisoning. (arXiv:2105.12837v3 [cs.LG] UPDATED)
116. Density estimation on smooth manifolds with normalizing flows. (arXiv:2106.03500v2 [cs.LG] UPDATED)
117. GAN Cocktail: mixing GANs without dataset access. (arXiv:2106.03847v2 [cs.LG] UPDATED)
118. Inverting Adversarially Robust Networks for Image Synthesis. (arXiv:2106.06927v4 [cs.CV] UPDATED)
119. IQ-Learn: Inverse soft-Q Learning for Imitation. (arXiv:2106.12142v3 [cs.LG] UPDATED)
120. How to Train Your MAML to Excel in Few-Shot Classification. (arXiv:2106.16245v3 [cs.LG] UPDATED)
121. Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v2 [cs.CV] UPDATED)
122. On Bridging Generic and Personalized Federated Learning for Image Classification. (arXiv:2107.00778v2 [cs.LG] UPDATED)
123. End-to-End Balancing for Causal Continuous Treatment-Effect Estimation. (arXiv:2107.13068v3 [cs.LG] UPDATED)
124. Generalization Bounds using Lower Tail Exponents in Stochastic Optimizers. (arXiv:2108.00781v2 [stat.ML] UPDATED)
125. Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm. (arXiv:2108.03002v4 [math.NA] UPDATED)
126. The Benefits of Implicit Regularization from SGD in Least Squares Problems. (arXiv:2108.04552v2 [cs.LG] UPDATED)
127. A theory of representation learning in deep neural networks gives a deep generalisation of kernel methods. (arXiv:2108.13097v4 [stat.ML] UPDATED)
128. MEPG: A Minimalist Ensemble Policy Gradient Framework for Deep Reinforcement Learning. (arXiv:2109.10552v2 [cs.LG] UPDATED)
129. Tensor Full Feature Measure and Its Nonconvex Relaxation Applications to Tensor Recovery. (arXiv:2109.12257v2 [cs.CV] UPDATED)
130. Active Learning for Contextual Search with Binary Feedbacks. (arXiv:2110.01072v2 [stat.ML] UPDATED)
131. EdiTTS: Score-based Editing for Controllable Text-to-Speech. (arXiv:2110.02584v3 [cs.SD] UPDATED)
132. Is Attention always needed? A Case Study on Language Identification from Speech. (arXiv:2110.03427v2 [cs.LG] UPDATED)
133. Large Language Models Can Be Strong Differentially Private Learners. (arXiv:2110.05679v2 [cs.LG] UPDATED)
134. Last Iterate Risk Bounds of SGD with Decaying Stepsize for Overparameterized Linear Regression. (arXiv:2110.06198v2 [cs.LG] UPDATED)
135. Finding Local Minimax Points via (Stochastic) Cubic-Regularized GDA: Global Convergence and Complexity. (arXiv:2110.07098v4 [math.OC] UPDATED)
136. Human-robot collaboration and machine learning: a systematic review of recent research. (arXiv:2110.07448v4 [cs.RO] UPDATED)
137. Probabilistic Time Series Forecasts with Autoregressive Transformation Models. (arXiv:2110.08248v3 [cs.LG] UPDATED)
138. Lifelong Topological Visual Navigation. (arXiv:2110.08488v2 [cs.RO] UPDATED)
139. Bandits with Dynamic Arm-acquisition Costs. (arXiv:2110.12118v2 [cs.LG] UPDATED)
140. Improving Spectral Clustering Using Spectrum-Preserving Node Aggregation. (arXiv:2110.12328v5 [cs.LG] UPDATED)
141. Variational quantum algorithm for Gaussian discrete solitons and their boson sampling. (arXiv:2110.12379v3 [quant-ph] UPDATED)
142. Towards Model Reduction for Power System Transients with Physics-Informed PDE. (arXiv:2110.14066v2 [eess.SY] UPDATED)
143. Does Momentum Help? A Sample Complexity Analysis. (arXiv:2110.15547v3 [cs.LG] UPDATED)
144. A Theoretical Analysis on Independence-driven Importance Weighting for Covariate-shift Generalization. (arXiv:2111.02355v3 [cs.LG] UPDATED)
145. TACCL: Guiding Collective Algorithm Synthesis using Communication Sketches. (arXiv:2111.04867v3 [cs.DC] UPDATED)
146. Robust deep learning-based semantic organ segmentation in hyperspectral images. (arXiv:2111.05408v2 [eess.IV] UPDATED)
147. Multiple Hypothesis Hypergraph Tracking for Posture Identification in Embryonic Caenorhabditis elegans. (arXiv:2111.06425v2 [eess.IV] UPDATED)
148. Deep Learning Based Automated COVID-19 Classification from Computed Tomography Images. (arXiv:2111.11191v5 [eess.IV] UPDATED)
149. Amortized Implicit Differentiation for Stochastic Bilevel Optimization. (arXiv:2111.14580v3 [math.OC] UPDATED)
150. DOPE: Doubly Optimistic and Pessimistic Exploration for Safe Reinforcement Learning. (arXiv:2112.00885v2 [cs.LG] UPDATED)
151. Classification of COVID-19 on chest X-Ray images using Deep Learning model with Histogram Equalization and Lungs Segmentation. (arXiv:2112.02478v3 [eess.IV] UPDATED)
152. Doubly Optimal No-Regret Online Learning in Strongly Monotone Games with Bandit Feedback. (arXiv:2112.02856v3 [cs.LG] UPDATED)
153. Physically Consistent Neural Networks for building thermal modeling: theory and analysis. (arXiv:2112.03212v3 [cs.LG] UPDATED)
154. Risk and optimal policies in bandit experiments. (arXiv:2112.06363v7 [econ.EM] UPDATED)
155. DriPP: Driven Point Processes to Model Stimuli Induced Patterns in M/EEG Signals. (arXiv:2112.06652v2 [eess.SP] UPDATED)
156. On the Use of External Data for Spoken Named Entity Recognition. (arXiv:2112.07648v2 [cs.CL] UPDATED)
157. Learning Rich Representation of Keyphrases from Text. (arXiv:2112.08547v2 [cs.CL] UPDATED)
158. How Much of the Chemical Space Has Been Explored? Selecting the Right Exploration Measure for Drug Discovery. (arXiv:2112.12542v3 [cs.CE] UPDATED)
159. Last-Iterate Convergence of Saddle Point Optimizers via High-Resolution Differential Equations. (arXiv:2112.13826v2 [math.OC] UPDATED)
160. Offline Reinforcement Learning for Road Traffic Control. (arXiv:2201.02381v2 [cs.AI] UPDATED)
161. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v4 [cs.LG] UPDATED)
162. Linear Adversarial Concept Erasure. (arXiv:2201.12091v3 [cs.LG] UPDATED)
163. ReGAE: Graph autoencoder based on recursive neural networks. (arXiv:2201.12165v3 [cs.LG] UPDATED)
164. Tensor Recovery Based on Tensor Equivalent Minimax-Concave Penalty. (arXiv:2201.12709v2 [cs.CV] UPDATED)
165. skrl: Modular and Flexible Library for Reinforcement Learning. (arXiv:2202.03825v2 [cs.LG] UPDATED)
166. An Adaptive Mini-Block Fisher Method for Deep Neural Networks. (arXiv:2202.04124v3 [cs.LG] UPDATED)
167. On Almost Sure Convergence Rates of Stochastic Gradient Methods. (arXiv:2202.04295v2 [cs.LG] UPDATED)
168. Self-Supervised Representation Learning via Latent Graph Prediction. (arXiv:2202.08333v2 [cs.LG] UPDATED)
169. Rethinking Pareto Frontier for Performance Evaluation of Deep Neural Networks. (arXiv:2202.09275v2 [cs.LG] UPDATED)
170. Bitwidth Heterogeneous Federated Learning with Progressive Weight Dequantization. (arXiv:2202.11453v4 [cs.LG] UPDATED)
171. Automated Identification of Toxic Code Reviews Using ToxiCR. (arXiv:2202.13056v2 [cs.SE] UPDATED)
172. Point Label Aware Superpixels for Multi-species Segmentation of Underwater Imagery. (arXiv:2202.13487v2 [cs.CV] UPDATED)
173. Sampling Random Group Fair Rankings. (arXiv:2203.00887v2 [cs.LG] UPDATED)
174. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v3 [cs.LG] UPDATED)
175. Correlated quantization for distributed mean estimation and optimization. (arXiv:2203.04925v2 [cs.LG] UPDATED)
176. Efficient Model-based Multi-agent Reinforcement Learning via Optimistic Equilibrium Computation. (arXiv:2203.07322v2 [cs.LG] UPDATED)
177. Reconstructing Missing EHRs Using Time-Aware Within- and Cross-Visit Information for Septic Shock Early Prediction. (arXiv:2203.08245v2 [cs.LG] UPDATED)
178. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v2 [cs.LG] UPDATED)
179. Seamless lightning nowcasting with recurrent-convolutional deep learning. (arXiv:2203.10114v2 [physics.ao-ph] UPDATED)
180. Online Continual Learning for Embedded Devices. (arXiv:2203.10681v2 [cs.LG] UPDATED)
181. Robust Classification using Contractive Hamiltonian Neural ODEs. (arXiv:2203.11805v3 [cs.LG] UPDATED)
182. SpeechPrompt: An Exploration of Prompt Tuning on Generative Spoken Language Model for Speech Processing Tasks. (arXiv:2203.16773v3 [eess.AS] UPDATED)
183. WavThruVec: Latent speech representation as intermediate features for neural speech synthesis. (arXiv:2203.16930v2 [cs.SD] UPDATED)
184. Normalizing Flow-based Day-Ahead Wind Power Scenario Generation for Profitable and Reliable Delivery Commitments by Wind Farm Operators. (arXiv:2204.02242v2 [math.OC] UPDATED)
185. OccamNets: Mitigating Dataset Bias by Favoring Simpler Hypotheses. (arXiv:2204.02426v3 [cs.LG] UPDATED)
186. A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v2 [eess.IV] UPDATED)
187. Bayesian Negative Sampling for Recommendation. (arXiv:2204.06520v3 [cs.IR] UPDATED)
188. Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
189. Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding Methods and Architectures. (arXiv:2204.11190v2 [cs.CL] UPDATED)
190. Particle Swarm Optimization Based Demand Response Using Artificial Neural Network Based Load Prediction. (arXiv:2204.13990v2 [cs.NE] UPDATED)
191. A Deep Bayesian Bandits Approach for Anticancer Therapy: Exploration via Functional Prior. (arXiv:2205.02944v2 [cs.LG] UPDATED)
192. Orthogonal Gromov-Wasserstein Discrepancy with Efficient Lower Bound. (arXiv:2205.05838v2 [cs.LG] UPDATED)
193. Nearly Optimal Algorithms for Linear Contextual Bandits with Adversarial Corruptions. (arXiv:2205.06811v2 [cs.LG] UPDATED)
194. The Power of Fragmentation: A Hierarchical Transformer Model for Structural Segmentation in Symbolic Music Generation. (arXiv:2205.08579v2 [cs.SD] UPDATED)
195. HiPAL: A Deep Framework for Physician Burnout Prediction Using Activity Logs in Electronic Health Records. (arXiv:2205.11680v2 [cs.LG] UPDATED)
196. Linear Connectivity Reveals Generalization Strategies. (arXiv:2205.12411v4 [cs.LG] UPDATED)
197. Recipe for a General, Powerful, Scalable Graph Transformer. (arXiv:2205.12454v2 [cs.LG] UPDATED)
198. Improving Subgraph Representation Learning via Multi-View Augmentation. (arXiv:2205.13038v2 [cs.LG] UPDATED)
199. Automatic Short Math Answer Grading via In-context Meta-learning. (arXiv:2205.15219v3 [cs.CL] UPDATED)
200. Few-Shot Adaptation of Pre-Trained Networks for Domain Shift. (arXiv:2205.15234v2 [cs.CV] UPDATED)
201. Deep Learning-based Finite Element Analysis (FEA) surrogate for sub-sea pressure vessel. (arXiv:2206.03322v2 [cs.LG] UPDATED)
202. DeepCAVE: An Interactive Analysis Tool for Automated Machine Learning. (arXiv:2206.03493v2 [cs.LG] UPDATED)
203. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v3 [cs.LG] UPDATED)
204. Joint Entropy Search For Maximally-Informed Bayesian Optimization. (arXiv:2206.04771v2 [cs.LG] UPDATED)
205. Learned reconstruction methods with convergence guarantees. (arXiv:2206.05431v2 [cs.CV] UPDATED)
206. Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut Features. (arXiv:2206.07155v2 [cs.LG] UPDATED)
207. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v2 [cs.LG] UPDATED)
208. Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency. (arXiv:2206.08496v2 [cs.LG] UPDATED)
209. How You Start Matters for Generalization. (arXiv:2206.08558v2 [cs.LG] UPDATED)
210. Motley: Benchmarking Heterogeneity and Personalization in Federated Learning. (arXiv:2206.09262v3 [cs.LG] UPDATED)
211. Renormalized Sparse Neural Network Pruning. (arXiv:2206.10088v2 [cs.LG] UPDATED)
212. Neural Moving Horizon Estimation for Robust Flight Control. (arXiv:2206.10397v9 [cs.RO] UPDATED)
213. APPFLChain: A Privacy Protection Distributed Artificial-Intelligence Architecture Based on Federated Learning and Consortium Blockchain. (arXiv:2206.12790v2 [cs.CR] UPDATED)
214. Noise-aware Physics-informed Machine Learning for Robust PDE Discovery. (arXiv:2206.12901v4 [math.NA] UPDATED)
215. Vision Transformer for Contrastive Clustering. (arXiv:2206.12925v2 [cs.CV] UPDATED)
216. Efficient Private SCO for Heavy-Tailed Data via Clipping. (arXiv:2206.13011v2 [cs.LG] UPDATED)
217. Deep Active Learning for Regression Using $\epsilon$-weighted Hybrid Query Strategy. (arXiv:2206.13298v3 [cs.LG] UPDATED)
218. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v2 [cs.LG] UPDATED)
219. Neural Integro-Differential Equations. (arXiv:2206.14282v2 [cs.LG] UPDATED)
220. LIDL: Local Intrinsic Dimension Estimation Using Approximate Likelihood. (arXiv:2206.14882v2 [stat.ML] UPDATED)
221. Continual Learning for Human State Monitoring. (arXiv:2207.00010v2 [cs.LG] UPDATED)
222. When Does Differentially Private Learning Not Suffer in High Dimensions?. (arXiv:2207.00160v2 [cs.LG] UPDATED)
223. Improving Speech **Enhancement** through Fine-Grained Speech Characteristics. (arXiv:2207.00237v2 [cs.SD] UPDATED)
224. DecisioNet: A Binary-Tree Structured Neural Network. (arXiv:2207.01127v3 [cs.CV] UPDATED)
225. A New Index for Clustering Evaluation Based on Density Estimation. (arXiv:2207.01294v2 [cs.LG] UPDATED)
226. UniCR: Universally Approximated Certified Robustness via Randomized Smoothing. (arXiv:2207.02152v2 [cs.LG] UPDATED)
227. TractoFormer: A Novel Fiber-level Whole Brain Tractography Analysis Framework Using Spectral Embedding and Vision Transformers. (arXiv:2207.02327v3 [eess.IV] UPDATED)
228. AI-enhanced iterative solvers for accelerating the solution of large scale parametrized linear systems of equations. (arXiv:2207.02543v2 [math.NA] UPDATED)
229. voxel2vec: A Natural Language Processing Approach to Learning Distributed Representations for Scientific Data. (arXiv:2207.02565v2 [cs.LG] UPDATED)
230. Towards Substantive Conceptions of Algorithmic Fairness: Normative Guidance from Equal Opportunity Doctrines. (arXiv:2207.02912v2 [cs.CY] UPDATED)
231. Equivariant Representation Learning via Class-Pose Decomposition. (arXiv:2207.03116v2 [cs.LG] UPDATED)
232. Market Making with Scaled Beta Policies. (arXiv:2207.03352v2 [q-fin.TR] UPDATED)
233. Stochastic optimal well control in subsurface reservoirs using reinforcement learning. (arXiv:2207.03456v2 [cs.LG] UPDATED)
234. Pruning Early Exit Networks. (arXiv:2207.03644v1 [cs.LG] CROSS LISTED)
## cs.AI
---
**99** new papers in cs.AI:-) 
1. Runtime Analysis for Permutation-based Evolutionary Algorithms. (arXiv:2207.04045v1 [cs.NE])
2. A Framework Based on Generational and Environmental Response Strategies for Dynamic Multi-objective Optimization. (arXiv:2207.04047v1 [cs.NE])
3. Learning Causal Effects on Hypergraphs. (arXiv:2207.04049v1 [cs.LG])
4. Few-Example Clustering via Contrastive Learning. (arXiv:2207.04050v1 [cs.LG])
5. On the Need and Applicability of Causality for Fair Machine Learning. (arXiv:2207.04053v1 [cs.LG])
6. Causal Discovery using Model Invariance through Knockoff Interventions. (arXiv:2207.04055v1 [cs.LG])
7. Large Scale Mask Optimization Via Convolutional Fourier Neural Operator and Litho-Guided Self Training. (arXiv:2207.04056v1 [cs.LG])
8. FAIVConf: Face **enhancement** for AI-based Video Conference with Low Bit-rate. (arXiv:2207.04090v1 [eess.IV])
9. Seasonal Encoder-Decoder Architecture for Forecasting. (arXiv:2207.04113v1 [cs.LG])
10. Automatic Exploration of Textual Environments with Language-Conditioned Autotelic Agents. (arXiv:2207.04118v1 [cs.AI])
11. Braid-based architecture search. (arXiv:2207.04121v1 [cs.LG])
12. Out of Distribution Detection via Neural Network Anchoring. (arXiv:2207.04125v1 [cs.LG])
13. CompoSuite: A Compositional Reinforcement Learning Benchmark. (arXiv:2207.04136v1 [cs.LG])
14. TalkToModel: Understanding Machine Learning Models With Open Ended Dialogues. (arXiv:2207.04154v1 [cs.LG])
15. Few 'Zero Level Set'-Shot Learning of Shape Signed Distance Functions in Feature Space. (arXiv:2207.04161v1 [cs.CV])
16. A Systematic Review and Thematic Analysis of Community-Collaborative Approaches to Computing Research. (arXiv:2207.04171v1 [cs.HC])
17. Towards Multimodal Vision-Language Models Generating Non-Generic Text. (arXiv:2207.04174v1 [cs.CV])
18. Transformer Neural Processes: Uncertainty-Aware Meta Learning Via Sequence Modeling. (arXiv:2207.04179v1 [cs.LG])
19. Supervised Machine Learning for Effective Missile Launch Based on Beyond Visual Range Air Combat Simulations. (arXiv:2207.04188v1 [cs.LG])
20. Smart Multi-tenant Federated Learning. (arXiv:2207.04202v1 [cs.LG])
21. SCouT: Synthetic Counterfactuals via Spatiotemporal Transformers for Actionable Healthcare. (arXiv:2207.04208v1 [cs.AI])
22. BOSS: Bottom-up Cross-modal Semantic Composition with Hybrid Counterfactual Training for Robust Content-based Image Retrieval. (arXiv:2207.04211v1 [cs.AI])
23. Wasserstein Graph Distance based on $L_1$-Approximated Tree Edit Distance between Weisfeiler-Lehman Subtrees. (arXiv:2207.04216v1 [cs.LG])
24. Generating Pseudo-labels Adaptively for Few-shot Model-Agnostic Meta-Learning. (arXiv:2207.04217v1 [cs.LG])
25. CEG4N: Counter-Example Guided Neural Network Quantization Refinement. (arXiv:2207.04231v1 [cs.LG])
26. A novel evaluation methodology for supervised Feature Ranking algorithms. (arXiv:2207.04258v1 [cs.LG])
27. Explainable AI (XAI) in Biomedical Signal and Image Processing: Promises and Challenges. (arXiv:2207.04295v1 [cs.LG])
28. TensorIR: An Abstraction for Automatic Tensorized Program Optimization. (arXiv:2207.04296v1 [cs.LG])
29. QKVA grid: Attention in Image Perspective and Stacked DETR. (arXiv:2207.04313v1 [cs.CV])
30. Explaining Chest X-ray Pathologies in Natural Language. (arXiv:2207.04343v1 [cs.CV])
31. An Introduction to Lifelong Supervised Learning. (arXiv:2207.04354v1 [cs.LG])
32. State Dropout-Based Curriculum Reinforcement Learning for Self-Driving at Unsignalized Intersections. (arXiv:2207.04361v1 [cs.RO])
33. Planning Sequential Tasks on Contact Graph. (arXiv:2207.04364v1 [cs.RO])
34. Scalable Privacy-enhanced Benchmark Graph Generative Model for Graph Convolutional Networks. (arXiv:2207.04396v1 [cs.LG])
35. Self-supervised Learning with Local Contrastive Loss for Detection and Semantic Segmentation. (arXiv:2207.04398v1 [cs.CV])
36. LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action. (arXiv:2207.04429v1 [cs.RO])
37. TCR: A Transformer Based Deep Network for Predicting Cancer Drugs Response. (arXiv:2207.04457v1 [cs.LG])
38. Noisy Heuristics NAS: A Network Morphism based Neural Architecture Search using Heuristics. (arXiv:2207.04467v1 [cs.LG])
39. Towards Proper Contrastive Self-supervised Learning Strategies For Music Audio Representation. (arXiv:2207.04471v1 [cs.SD])
40. Scaling up ML-based Black-box Planning with Partial STRIPS Models. (arXiv:2207.04479v1 [cs.AI])
41. One-shot Neural Backdoor Erasing via Adversarial Weight Masking. (arXiv:2207.04497v1 [cs.LG])
42. FIB: A Method for Evaluation of Feature Impact Balance in Multi-Dimensional Data. (arXiv:2207.04500v1 [cs.LG])
43. Building Open Knowledge Graph for Metal-Organic Frameworks (MOF-KG): Challenges and Case Studies. (arXiv:2207.04502v1 [cs.AI])
44. Developing an AI-enabled IIoT platform -- Lessons learned from early use case validation. (arXiv:2207.04515v1 [cs.AI])
45. Local Area Routes for Vehicle Routing Problems. (arXiv:2207.04520v1 [math.OC])
46. Scaling the Number of Tasks in Continual Learning. (arXiv:2207.04543v1 [cs.LG])
47. Towards End-to-end Car License Plate Location and Recognition in Unconstrained Scenarios. (arXiv:2008.10916v2 [cs.CV] UPDATED)
48. Towards an Ethical Framework in the Complex Digital Era. (arXiv:2010.10028v2 [cs.CY] UPDATED)
49. Language for Description of Worlds. (arXiv:2010.16243v4 [cs.AI] UPDATED)
50. Visual explanation of black-box model: Similarity Difference and Uniqueness (SIDU) method. (arXiv:2101.10710v2 [cs.CV] UPDATED)
51. Understanding Continual Learning Settings with Data Distribution Drift Analysis. (arXiv:2104.01678v2 [cs.LG] UPDATED)
52. Objective-aware Traffic Simulation via Inverse Reinforcement Learning. (arXiv:2105.09560v3 [cs.AI] UPDATED)
53. ADVERT: An Adaptive and Data-Driven Attention **Enhancement** Mechanism for Phishing Prevention. (arXiv:2106.06907v3 [cs.HC] UPDATED)
54. IQ-Learn: Inverse soft-Q Learning for Imitation. (arXiv:2106.12142v3 [cs.LG] UPDATED)
55. How to Train Your MAML to Excel in Few-Shot Classification. (arXiv:2106.16245v3 [cs.LG] UPDATED)
56. Few-Shot Learning with a Strong Teacher. (arXiv:2107.00197v2 [cs.CV] UPDATED)
57. On Bridging Generic and Personalized Federated Learning for Image Classification. (arXiv:2107.00778v2 [cs.LG] UPDATED)
58. MDE4QAI: Towards Model-Driven Engineering for Quantum Artificial Intelligence. (arXiv:2107.06708v2 [cs.SE] UPDATED)
59. MEPG: A Minimalist Ensemble Policy Gradient Framework for Deep Reinforcement Learning. (arXiv:2109.10552v2 [cs.LG] UPDATED)
60. Lifelong Topological Visual Navigation. (arXiv:2110.08488v2 [cs.RO] UPDATED)
61. Phish-Defence: Phishing Detection Using Deep Recurrent Neural Networks. (arXiv:2110.13424v3 [cs.CR] UPDATED)
62. CTRN: Class-Temporal Relational Network for Action Detection. (arXiv:2110.13473v2 [cs.CV] UPDATED)
63. DOPE: Doubly Optimistic and Pessimistic Exploration for Safe Reinforcement Learning. (arXiv:2112.00885v2 [cs.LG] UPDATED)
64. **NeRF**-SR: High-Quality Neural Radiance Fields using Super-Sampling. (arXiv:2112.01759v2 [cs.CV] UPDATED)
65. Physically Consistent Neural Networks for building thermal modeling: theory and analysis. (arXiv:2112.03212v3 [cs.LG] UPDATED)
66. Offline Reinforcement Learning for Road Traffic Control. (arXiv:2201.02381v2 [cs.AI] UPDATED)
67. Imagined versus Remembered Stories: Quantifying Differences in Narrative Flow. (arXiv:2201.02662v2 [cs.CL] UPDATED)
68. Conditional entropy minimization principle for learning domain invariant representation features. (arXiv:2201.10460v4 [cs.LG] UPDATED)
69. skrl: Modular and Flexible Library for Reinforcement Learning. (arXiv:2202.03825v2 [cs.LG] UPDATED)
70. An Adaptive Mini-Block Fisher Method for Deep Neural Networks. (arXiv:2202.04124v3 [cs.LG] UPDATED)
71. Adaptive Algorithms, Tacit Collusion, and Design for Competition. (arXiv:2202.05946v2 [econ.TH] UPDATED)
72. Recent, rapid advancement in visual question answering architecture: a review. (arXiv:2203.01322v4 [cs.CV] UPDATED)
73. Ensemble Knowledge Guided Sub-network Search and Fine-tuning for Filter Pruning. (arXiv:2203.02651v3 [cs.LG] UPDATED)
74. ELLE: Efficient Lifelong Pre-training for Emerging Data. (arXiv:2203.06311v2 [cs.CL] UPDATED)
75. On Multi-Domain Long-Tailed Recognition, Imbalanced Domain Generalization and Beyond. (arXiv:2203.09513v2 [cs.LG] UPDATED)
76. Online Continual Learning for Embedded Devices. (arXiv:2203.10681v2 [cs.LG] UPDATED)
77. A Dempster-Shafer approach to trustworthy AI with application to fetal brain MRI segmentation. (arXiv:2204.02779v2 [eess.IV] UPDATED)
78. Bayesian Negative Sampling for Recommendation. (arXiv:2204.06520v3 [cs.IR] UPDATED)
79. Neighborhood Attention Transformer. (arXiv:2204.07143v2 [cs.CV] UPDATED)
80. Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding Methods and Architectures. (arXiv:2204.11190v2 [cs.CL] UPDATED)
81. FlowBot3D: Learning 3D Articulation Flow to Manipulate Articulated Objects. (arXiv:2205.04382v2 [cs.RO] UPDATED)
82. Sim-To-Real Transfer of Visual Grounding for Human-Aided Ambiguity Resolution. (arXiv:2205.12089v2 [cs.CV] UPDATED)
83. Improving Subgraph Representation Learning via Multi-View Augmentation. (arXiv:2205.13038v2 [cs.LG] UPDATED)
84. Deep Learning-based Finite Element Analysis (FEA) surrogate for sub-sea pressure vessel. (arXiv:2206.03322v2 [cs.LG] UPDATED)
85. SDQ: Stochastic Differentiable Quantization with Mixed Precision. (arXiv:2206.04459v3 [cs.LG] UPDATED)
86. Real3D-Aug: Point Cloud Augmentation by Placing Real Objects with Occlusion Handling for 3D Detection and Segmentation. (arXiv:2206.07634v2 [cs.CV] UPDATED)
87. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v2 [cs.LG] UPDATED)
88. Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency. (arXiv:2206.08496v2 [cs.LG] UPDATED)
89. Rethinking Audio-visual Synchronization for Active Speaker Detection. (arXiv:2206.10421v2 [cs.SD] UPDATED)
90. APPFLChain: A Privacy Protection Distributed Artificial-Intelligence Architecture Based on Federated Learning and Consortium Blockchain. (arXiv:2206.12790v2 [cs.CR] UPDATED)
91. Noise-aware Physics-informed Machine Learning for Robust PDE Discovery. (arXiv:2206.12901v4 [math.NA] UPDATED)
92. Deep Active Learning for Regression Using $\epsilon$-weighted Hybrid Query Strategy. (arXiv:2206.13298v3 [cs.LG] UPDATED)
93. Robustness Implies Generalization via Data-Dependent Generalization Bounds. (arXiv:2206.13497v2 [cs.LG] UPDATED)
94. PolarFormer: Multi-camera 3D Object Detection with Polar Transformers. (arXiv:2206.15398v3 [cs.CV] UPDATED)
95. Continual Learning for Human State Monitoring. (arXiv:2207.00010v2 [cs.LG] UPDATED)
96. Symbolic Regression is NP-hard. (arXiv:2207.01018v3 [cs.NE] UPDATED)
97. AI-enhanced iterative solvers for accelerating the solution of large scale parametrized linear systems of equations. (arXiv:2207.02543v2 [math.NA] UPDATED)
98. Towards Substantive Conceptions of Algorithmic Fairness: Normative Guidance from Equal Opportunity Doctrines. (arXiv:2207.02912v2 [cs.CY] UPDATED)
99. Market Making with Scaled Beta Policies. (arXiv:2207.03352v2 [q-fin.TR] UPDATED)

