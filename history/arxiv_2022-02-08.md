# Your interest papers
---
## cs.CV
---
### PrivPAS: A **real time** Privacy-Preserving AI System and applied ethics. (arXiv:2202.02524v1 [cs.CV])
- Authors : Vibhav Agarwal, Sourav Ghosh, Gopi Ramena, Sumit Kumar, andd Barath, Raj Kandur
- Link : [http://arxiv.org/abs/2202.02524](http://arxiv.org/abs/2202.02524)
> ABSTRACT  :  With 3.78 billion social media users worldwide in 2021 (48% of the human population), almost 3 billion images are shared daily. At the same time, a consistent evolution of smartphone cameras has led to a photography explosion with 85% of all new pictures being captured using smartphones. However, lately, there has been an increased discussion of privacy concerns when a person being photographed is unaware of the picture being taken or has reservations about the same being shared. These privacy violations are amplified for people with disabilities, who may find it challenging to raise dissent even if they are aware. Such unauthorized image captures may also be misused to gain sympathy by third-party organizations, leading to a privacy breach. Privacy for people with disabilities has so far received comparatively less attention from the AI community. This motivates us to work towards a solution to generate privacy-conscious cues for raising awareness in smartphone users of any sensitivity in their viewfinder content. To this end, we introduce PrivPAS (A **real time** Privacy-Preserving AI System) a novel framework to identify sensitive content. Additionally, we curate and annotate a dataset to identify and localize accessibility markers and classify whether an image is sensitive to a featured subject with a disability. We demonstrate that the proposed lightweight architecture, with a memory footprint of a mere 8.49MB, achieves a high mAP of 89.52% on resource-constrained devices. Furthermore, our pipeline, trained on face anonymized data, achieves an F1-score of 73.1%.  
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
### Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v1 [eess.IV])
- Authors : Amir Atapour
- Link : [http://arxiv.org/abs/2202.02832](http://arxiv.org/abs/2202.02832)
> ABSTRACT  :  Convolutional Neural Networks have demonstrated human-level performance in the classification of melanoma and other skin lesions, but evident performance disparities between differing skin tones should be addressed before widespread deployment. In this work, we utilise a modified variational autoencoder to uncover skin tone bias in datasets commonly used as benchmarks. We propose an efficient yet effective algorithm for automatically labelling the skin tone of lesion images, and use this to annotate the benchmark ISIC dataset. We subsequently use two leading bias unlearning techniques to mitigate skin tone bias. Our experimental results provide evidence that our skin tone detection algorithm outperforms existing solutions and that unlearning skin tone improves generalisation and can reduce the performance disparity between melanoma detection in lighter and **dark**er skin tones.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joesph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Rapidly expanding Clinical AI applications worldwide have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow that tracks data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI (4) creation of open-source tools enabling others to easily run their own workflows or scenarios. This work has important implications for addressing the translation gap related to continuous medical imaging AI model monitoring in dynamic healthcare environments.  
### Motion Deblurring with an Adaptive Network. (arXiv:1903.11394v4 [cs.CV] UPDATED)
- Authors : Kuldeep Purohit
- Link : [http://arxiv.org/abs/1903.11394](http://arxiv.org/abs/1903.11394)
> ABSTRACT  :  In this paper, we address the problem of dynamic scene deblurring in the presence of motion blur. **Restoration** of images affected by severe blur necessitates a network design with a large receptive field, which existing networks attempt to achieve through simple increment in the number of generic convolution layers, kernel-size, or the scales at which the image is processed. However, increasing the network capacity in this manner comes at the expense of increase in model size and inference speed, and ignoring the non-uniform nature of blur. We present a new architecture composed of spatially adaptive residual learning modules that implicitly discover the spatially varying shifts responsible for non-uniform blur in the input image and learn to modulate the filters. This capability is complemented by a self-attentive module which captures non-local relationships among the intermediate features and enhances the receptive field. We then incorporate a spatiotemporal recurrent module in the design to also facilitate efficient video deblurring. Our networks can implicitly model the spatially-varying deblurring process, while dispensing with multi-scale processing and large filters entirely. Extensive qualitative and quantitative comparisons with prior art on benchmark dynamic scene deblurring datasets clearly demonstrate the superiority of the proposed networks via reduction in model-size and significant improvements in accuracy and speed, enabling almost real-time deblurring.  
### Eigenbackground Revisited: Can We Model the Background with Eigenvectors?. (arXiv:2104.11379v2 [cs.CV] UPDATED)
- Authors : Mahmood Amintoosi, Farzam Farbiz
- Link : [http://arxiv.org/abs/2104.11379](http://arxiv.org/abs/2104.11379)
> ABSTRACT  :  Using dominant eigenvectors for background modeling (usually known as Eigenbackground) is a common technique in the literature. However, its results suffer from noticeable artifacts. Thus have been many attempts to reduce the artifacts by making some improvements/**enhancement** in the Eigenbackground algorithm.    In this paper, we show the main problem of the Eigenbackground is in its own core and in fact, it is not a good idea to use strongest eigenvectors for modeling the background. Instead, we propose an alternative solution by exploiting the weakest eigenvectors (which are usually thrown away and treated as garbage data) for background modeling. MATLAB codes are available at \url{https://github.com/mamintoosi/Eigenbackground-Revisited}  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
## eess.IV
---
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
### Diffractive deep neural network based adaptive optics scheme for vortex beam in oceanic turbulence. (arXiv:2202.02732v1 [eess.IV])
- Authors : Haichao Zhan, Le Wang, Wennai Wang, Shengmei Zhao
- Link : [http://arxiv.org/abs/2202.02732](http://arxiv.org/abs/2202.02732)
> ABSTRACT  :  Vortex beam carrying orbital angular momentum (OAM) is disturbed by oceanic turbulence (OT) when propagating in underwater wireless optical communication (UWOC) system. Adaptive optics (AO) is used to compensate for distortion and improve the performance of the UWOC system. In this work, we propose a diffractive deep neural network (DDNN) based AO scheme to compensate for the distortion caused by OT, where the DDNN is trained to obtain the mapping between the distortion intensity distribution of the vortex beam and its corresponding phase screen representating OT. The intensity pattern of the distorted vortex beam obtained in the experiment is input to the DDNN model, and the predicted phase screen can be used to compensate the distortion in **real time**. The experiment results show that the proposed scheme can extract quickly the characteristics of the intensity pattern of the distorted vortex beam, and output accurately the predicted phase screen. The mode purity of the compensated vortex beam is significantly improved, even with a strong OT. Our scheme may provide a new avenue for AO techniques, and is expected to promote the communication quality of UWOC system.  
### Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v1 [eess.IV])
- Authors : Amir Atapour
- Link : [http://arxiv.org/abs/2202.02832](http://arxiv.org/abs/2202.02832)
> ABSTRACT  :  Convolutional Neural Networks have demonstrated human-level performance in the classification of melanoma and other skin lesions, but evident performance disparities between differing skin tones should be addressed before widespread deployment. In this work, we utilise a modified variational autoencoder to uncover skin tone bias in datasets commonly used as benchmarks. We propose an efficient yet effective algorithm for automatically labelling the skin tone of lesion images, and use this to annotate the benchmark ISIC dataset. We subsequently use two leading bias unlearning techniques to mitigate skin tone bias. Our experimental results provide evidence that our skin tone detection algorithm outperforms existing solutions and that unlearning skin tone improves generalisation and can reduce the performance disparity between melanoma detection in lighter and **dark**er skin tones.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joesph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Rapidly expanding Clinical AI applications worldwide have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow that tracks data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI (4) creation of open-source tools enabling others to easily run their own workflows or scenarios. This work has important implications for addressing the translation gap related to continuous medical imaging AI model monitoring in dynamic healthcare environments.  
### A comprehensive benchmark analysis for sand dust image reconstruction. (arXiv:2202.03031v1 [eess.IV])
- Authors : Yazhong Si, Fan Yang, Ya Guo, Wei Zhang, Yipu Yang
- Link : [http://arxiv.org/abs/2202.03031](http://arxiv.org/abs/2202.03031)
> ABSTRACT  :  Numerous sand dust image **enhancement** algorithms have been proposed in recent years. To our best acknowledge, however, most methods evaluated their performance with no-reference way using few selected real-world images from internet. It is unclear how to quantitatively analysis the performance of the algorithms in a supervised way and how we could gauge the progress in the field. Moreover, due to the absence of large-scale benchmark datasets, there are no well-known reports of data-driven based method for sand dust image **enhancement** up till now. To advance the development of deep learning-based algorithms for sand dust image reconstruction, while enabling supervised objective evaluation of algorithm performance. In this paper, we presented a comprehensive perceptual study and analysis of real-world sand dust images, then constructed a Sand-dust Image Reconstruction Benchmark (SIRB) for training Convolutional Neural Networks (CNNs) and evaluating algorithms performance. In addition, we adopted the existing image transformation neural network trained on SIRB as baseline to illustrate the generalization of SIRB for training CNNs. Finally, we conducted the qualitative and quantitative evaluation to demonstrate the performance and limitations of the state-of-the-arts (SOTA), which shed light on future research in sand dust image reconstruction.  
### LEDNet: Joint Low-light **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v1 [eess.IV])
- Authors : Shangchen Zhou, **Chongyi Li**, Chen Change
- Link : [http://arxiv.org/abs/2202.03373](http://arxiv.org/abs/2202.03373)
> ABSTRACT  :  **Night** photography typically suffers from both **low light** and blurring issues due to the dim environment and the common use of long **exposure**. While existing light **enhancement** and deblurring methods could deal with each problem individually, a cascade of such methods cannot work harmoniously to cope well with joint degradation of visibility and textures. Training an end-to-end network is also infeasible as no paired data is available to characterize the coexistence of **low light** and blurs. We address the problem by introducing a novel data synthesis pipeline that models realistic **low-light** blurring degradations. With the pipeline, we present the first large-scale dataset for joint **low-light** **enhancement** and deblurring. The dataset, LOL-Blur, contains 12,000 low-blur/normal-sharp pairs with diverse **dark**ness and motion blurs in different scenarios. We further present an effective network, named LEDNet, to perform joint **low-light** **enhancement** and deblurring. Our network is unique as it is specially designed to consider the synergy between the two inter-connected tasks. Both the proposed dataset and network provide a foundation for this challenging joint task. Extensive experiments demonstrate the effectiveness of our method on both synthetic and real-world datasets.  
### Motion Deblurring with an Adaptive Network. (arXiv:1903.11394v4 [cs.CV] UPDATED)
- Authors : Kuldeep Purohit
- Link : [http://arxiv.org/abs/1903.11394](http://arxiv.org/abs/1903.11394)
> ABSTRACT  :  In this paper, we address the problem of dynamic scene deblurring in the presence of motion blur. **Restoration** of images affected by severe blur necessitates a network design with a large receptive field, which existing networks attempt to achieve through simple increment in the number of generic convolution layers, kernel-size, or the scales at which the image is processed. However, increasing the network capacity in this manner comes at the expense of increase in model size and inference speed, and ignoring the non-uniform nature of blur. We present a new architecture composed of spatially adaptive residual learning modules that implicitly discover the spatially varying shifts responsible for non-uniform blur in the input image and learn to modulate the filters. This capability is complemented by a self-attentive module which captures non-local relationships among the intermediate features and enhances the receptive field. We then incorporate a spatiotemporal recurrent module in the design to also facilitate efficient video deblurring. Our networks can implicitly model the spatially-varying deblurring process, while dispensing with multi-scale processing and large filters entirely. Extensive qualitative and quantitative comparisons with prior art on benchmark dynamic scene deblurring datasets clearly demonstrate the superiority of the proposed networks via reduction in model-size and significant improvements in accuracy and speed, enabling almost real-time deblurring.  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
## cs.LG
---
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
### CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
- Authors : Arjun Soin, Jameson Merkow, Jin Long, Joesph Paul, Smitha Saligrama, Stephen Kaiser, Steven Borg, Ivan Tarapov
- Link : [http://arxiv.org/abs/2202.02833](http://arxiv.org/abs/2202.02833)
> ABSTRACT  :  Rapidly expanding Clinical AI applications worldwide have the potential to impact to all areas of medical practice. Medical imaging applications constitute a vast majority of approved clinical AI applications. Though healthcare systems are eager to adopt AI solutions a fundamental question remains: \textit{what happens after the AI model goes into production?} We use the CheXpert and PadChest public datasets to build and test a medical imaging AI drift monitoring workflow that tracks data and model drift without contemporaneous ground truth. We simulate drift in multiple experiments to compare model performance with our novel multi-modal drift metric, which uses DICOM metadata, image appearance representation from a variational autoencoder (VAE), and model output probabilities as input. Through experimentation, we demonstrate a strong proxy for ground truth performance using unsupervised distributional shifts in relevant metadata, predicted probabilities, and VAE latent representation. Our key contributions include (1) proof-of-concept for medical imaging drift detection including use of VAE and domain specific statistical methods (2) a multi-modal methodology for measuring and unifying drift metrics (3) new insights into the challenges and solutions for observing deployed medical imaging AI (4) creation of open-source tools enabling others to easily run their own workflows or scenarios. This work has important implications for addressing the translation gap related to continuous medical imaging AI model monitoring in dynamic healthcare environments.  
### On Using Transformers for Speech-Separation. (arXiv:2202.02884v1 [eess.AS])
- Authors : Cem Subakan, Mirco Ravanelli, Samuele Cornell, Francois Grondin, Mirko Bronzi
- Link : [http://arxiv.org/abs/2202.02884](http://arxiv.org/abs/2202.02884)
> ABSTRACT  :  Transformers have enabled major improvements in deep learning. They often outperform recurrent and convolutional models in many tasks while taking advantage of parallel processing. Recently, we have proposed SepFormer, which uses self-attention and obtains state-of-the art results on WSJ0-2/3 Mix datasets for speech separation. In this paper, we extend our previous work by providing results on more datasets including LibriMix, and WHAM!, WHAMR! which include noisy and noisy-reverberant conditions. Moreover we provide denoising, and denoising+dereverberation results in the context of speech **enhancement**, respectively on WHAM! and WHAMR! datasets. We also investigate incorporating recently proposed efficient self-attention mechanisms inside the SepFormer model, and show that by using efficient self-attention mechanisms it is possible to reduce the memory requirements significantly while performing better than the popular convtasnet model on WSJ0-2Mix dataset.  
### Causal Inference Using Tractable Circuits. (arXiv:2202.02891v1 [cs.AI])
- Authors : Adnan Darwiche
- Link : [http://arxiv.org/abs/2202.02891](http://arxiv.org/abs/2202.02891)
> ABSTRACT  :  The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented **exposure** to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference.  
### Equitable Community Resilience: The Case of Winter Storm Uri in Texas. (arXiv:2201.06652v2 [stat.ML] UPDATED)
- Authors : Ali Nejat, Laura Solitare, Edward Pettitt, Hamed Mohsenian
- Link : [http://arxiv.org/abs/2201.06652](http://arxiv.org/abs/2201.06652)
> ABSTRACT  :  Community resilience in the face of natural hazards relies on a community's potential to bounce back. A failure to integrate equity into resilience considerations results in unequal recovery and disproportionate impacts on vulnerable populations, which has long been a concern in the United States. This research investigated aspects of equity related to community resilience in the aftermath of Winter Storm Uri in Texas which led to extended power outages for more than 4 million households. County level outage and recovery data was analyzed to explore potential significant links between various county attributes and their share of the outages during the recovery and **restoration** phases. Next, satellite imagery was used to examine data at a much higher geographical resolution focusing on census tracts in the city of Houston. The goal was to use computer vision to extract the extent of outages within census tracts and investigate their linkages to census tracts attributes. Results from various statistical procedures revealed statistically significant negative associations between counties' percentage of non-Hispanic whites and median household income with the ratio of outages. Additionally, at census tract level, variables including percentages of linguistically isolated population and public transport users exhibited positive associations with the group of census tracts that were affected by the outage as detected by computer vision analysis. Informed by these results, engineering solutions such as the applicability of grid modernization technologies, together with distributed and renewable energy resources, when controlled for the region's topographical characteristics, are proposed to enhance equitable power grid resiliency in the face of natural hazards.  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
### CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software. (arXiv:2107.08760v1 [cs.SE] CROSS LISTED)
- Authors : Guru Prasad, Amara Naseer, Leon Moonen, Simula Research
- Link : [http://arxiv.org/abs/2107.08760](http://arxiv.org/abs/2107.08760)
> ABSTRACT  :  Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and **Exposure**s (CVE) records in the public National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes.    The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits.    CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.  
## cs.AI
---
### HENRI: High Efficiency Negotiation-based Robust Interface for Multi-party Multi-issue Negotiation over the Internet. (arXiv:2202.02430v1 [cs.AI])
- Authors : Saurabh Deochake, Shashank Kanth, Subhadip Chakraborty, Suresh Sarode, Vidyasagar Potdar, Debajyoti Mukhopadhyay
- Link : [http://arxiv.org/abs/2202.02430](http://arxiv.org/abs/2202.02430)
> ABSTRACT  :  This paper proposes a framework for a full fledged negotiation system that allows multi party multi issue negotiation. It focuses on the negotiation protocol to be observed and provides a platform for concurrent and independent negotiation on individual issues using the concept of multi threading. It depicts the architecture of an agent detailing its components. The paper sets forth a hierarchical pattern for the multiple issues concerning every party. The system also provides **enhancement**s such as the time-to-live counters for every advertisement, refinement of utility considering non-functional attributes, prioritization of issues, by assigning weights to issues.  
### Causal Inference Using Tractable Circuits. (arXiv:2202.02891v1 [cs.AI])
- Authors : Adnan Darwiche
- Link : [http://arxiv.org/abs/2202.02891](http://arxiv.org/abs/2202.02891)
> ABSTRACT  :  The aim of this paper is to discuss a recent result which shows that probabilistic inference in the presence of (unknown) causal mechanisms can be tractable for models that have traditionally been viewed as intractable. This result was reported recently to facilitate model-based supervised learning but it can be interpreted in a causality context as follows. One can compile a non-parametric causal graph into an arithmetic circuit that supports inference in time linear in the circuit size. The circuit is also non-parametric so it can be used to estimate parameters from data and to further reason (in linear time) about the causal graph parametrized by these estimates. Moreover, the circuit size can sometimes be bounded even when the treewidth of the causal graph is not, leading to tractable inference on models that have been deemed intractable previously. This has been enabled by a new technique that can exploit causal mechanisms computationally but without needing to know their identities (the classical setup in causal inference). Our goal is to provide a causality-oriented **exposure** to these new results and to speculate on how they may potentially contribute to more scalable and versatile causal inference.  
### A Deep Knowledge Distillation framework for EEG assisted **enhancement** of single-lead ECG based sleep staging. (arXiv:2112.07252v2 [eess.SP] UPDATED)
- Authors : Vaibhav Joshi, Sricharan Vijayarangan, Preejith SP, Mohanasankar Sivaprakasam
- Link : [http://arxiv.org/abs/2112.07252](http://arxiv.org/abs/2112.07252)
> ABSTRACT  :  Automatic Sleep Staging study is presently done with the help of Electroencephalogram (EEG) signals. Recently, Deep Learning (DL) based approaches have enabled significant progress in this area, allowing for near-human accuracy in automated sleep staging. However, EEG based sleep staging requires an extensive as well as an expensive clinical setup. Moreover, the requirement of an expert for setup and the added inconvenience to the subject under study renders it unfavourable in a point of care context. Electrocardiogram (ECG), an unobtrusive alternative to EEG, is more suitable, but its performance, unsurprisingly, remains sub-par compared to EEG-based sleep staging. Naturally, it would be helpful to transfer knowledge from EEG to ECG, ultimately enhancing the model's performance on ECG based inputs. Knowledge Distillation (KD) is a renowned concept in DL that looks to transfer knowledge from a better but potentially more cumbersome teacher model to a compact student model. Building on this concept, we propose a cross-modal KD framework to improve ECG-based sleep staging performance with assistance from features learned through models trained on EEG. Additionally, we also conducted multiple experiments on the individual components of the proposed model to get better insight into the distillation approach. Data of 200 subjects from the Montreal Archive of Sleep Studies (MASS) was utilized for our study. The proposed model showed a 14.3\% and 13.4\% increase in weighted-F1-score in 4-class and 3-class sleep staging, respectively. This demonstrates the viability of KD for performance improvement of single-channel ECG based sleep staging in 4-class(W-L-D-R) and 3-class(W-N-R) classification.  
### CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software. (arXiv:2107.08760v1 [cs.SE] CROSS LISTED)
- Authors : Guru Prasad, Amara Naseer, Leon Moonen, Simula Research
- Link : [http://arxiv.org/abs/2107.08760](http://arxiv.org/abs/2107.08760)
> ABSTRACT  :  Data-driven research on the automated discovery and repair of security vulnerabilities in source code requires comprehensive datasets of real-life vulnerable code and their fixes. To assist in such research, we propose a method to automatically collect and curate a comprehensive vulnerability dataset from Common Vulnerabilities and **Exposure**s (CVE) records in the public National Vulnerability Database (NVD). We implement our approach in a fully automated dataset collection tool and share an initial release of the resulting vulnerability dataset named CVEfixes.    The CVEfixes collection tool automatically fetches all available CVE records from the NVD, gathers the vulnerable code and corresponding fixes from associated open-source repositories, and organizes the collected information in a relational database. Moreover, the dataset is enriched with meta-data such as programming language, and detailed code and security metrics at five levels of abstraction. The collection can easily be repeated to keep up-to-date with newly discovered or patched vulnerabilities. The initial release of CVEfixes spans all published CVEs up to 9 June 2021, covering 5365 CVE records for 1754 open-source projects that were addressed in a total of 5495 vulnerability fixing commits.    CVEfixes supports various types of data-driven software security research, such as vulnerability prediction, vulnerability classification, vulnerability severity prediction, analysis of vulnerability-related code changes, and automated vulnerability repair.  
# Paper List
---
## cs.CV
---
**92** new papers in cs.CV:-) 
1. Boundary-aware Information Maximization for Self-supervised Medical Image Segmentation. (arXiv:2202.02371v1 [eess.IV])
2. Fully Automated Tree Topology Estimation and Artery-Vein Classification. (arXiv:2202.02382v1 [eess.IV])
3. StandardSim: A Synthetic Dataset For Retail Environments. (arXiv:2202.02418v1 [cs.CV])
4. The influence of labeling techniques in classifying human manipulation movement of different speed. (arXiv:2202.02426v1 [cs.CV])
5. Stratification of carotid atheromatous plaque using interpretable deep learning methods on B-mode ultrasound images. (arXiv:2202.02428v1 [eess.IV])
6. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v1 [cs.CV])
7. Machine Learning Method for Functional Assessment of Retinal Models. (arXiv:2202.02443v1 [eess.IV])
8. Spelunking the Deep: Guaranteed Queries for General Neural Implicit Surfaces. (arXiv:2202.02444v1 [cs.CV])
9. Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric Approach. (arXiv:2202.02471v1 [cs.LG])
10. Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification. (arXiv:2202.02472v1 [eess.SP])
11. Investigating the Challenges of Class Imbalance and Scale Variation in Object Detection in Aerial Images. (arXiv:2202.02489v1 [cs.CV])
12. Adversarial Detector with Robust Classifier. (arXiv:2202.02503v1 [cs.CV])
13. Less is More: Reversible Steganography with Uncertainty-Aware Predictive Analytics. (arXiv:2202.02518v1 [cs.CV])
14. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v1 [cs.CV])
15. PrivPAS: A **real time** Privacy-Preserving AI System and applied ethics. (arXiv:2202.02524v1 [cs.CV])
16. Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting. (arXiv:2202.02543v1 [cs.CV])
17. DEVO: Depth-Event Camera Visual Odometry in Challenging Conditions. (arXiv:2202.02556v1 [cs.RO])
18. Catch Me if You Can: A Novel Task for Detection of Covert Geo-Locations (CGL). (arXiv:2202.02567v1 [cs.CV])
19. VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam. (arXiv:2202.02587v1 [cs.HC])
20. Memory Defense: More Robust Classification via a Memory-Masking Autoencoder. (arXiv:2202.02595v1 [cs.CV])
21. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
22. DSSIM: a structural similarity index for floating-point data. (arXiv:2202.02616v1 [stat.CO])
23. Layer-wise Regularized Adversarial Training using Layers Sustainability Analysis (LSA) framework. (arXiv:2202.02626v1 [cs.CV])
24. The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training. (arXiv:2202.02643v1 [cs.LG])
25. A survey of top-down approaches for human pose estimation. (arXiv:2202.02656v1 [cs.CV])
26. LiDAR dataset distillation within bayesian active learning framework: Understanding the effect of data augmentation. (arXiv:2202.02661v1 [cs.CV])
27. Simulation-to-Reality domain adaptation for offline 3D object annotation on pointclouds with correlation alignment. (arXiv:2202.02666v1 [cs.CV])
28. SRPCN: Structure Retrieval based Point Completion Network. (arXiv:2202.02669v1 [cs.CV])
29. Hyper-Convolutions via Implicit Kernels for Medical Imaging. (arXiv:2202.02701v1 [eess.IV])
30. Multi-modal Sensor Fusion for Auto Driving Perception: A Survey. (arXiv:2202.02703v1 [cs.CV])
31. Portrait Segmentation Using Deep Learning. (arXiv:2202.02705v1 [cs.CV])
32. FEAT: Face Editing with Attention. (arXiv:2202.02713v1 [cs.CV])
33. Enhancing variational generation through self-decomposition. (arXiv:2202.02738v1 [cs.CV])
34. On Smart Gaze based Annotation of Histopathology Images for Training of Deep Convolutional Neural Networks. (arXiv:2202.02764v1 [eess.IV])
35. Learning Features with Parameter-Free Layers. (arXiv:2202.02777v1 [cs.CV])
36. Multi-domain Unsupervised Image-to-Image Translation with Appearance Adaptive Convolution. (arXiv:2202.02779v1 [cs.CV])
37. Energy awareness in low precision neural networks. (arXiv:2202.02783v1 [cs.LG])
38. GLPanoDepth: Global-to-Local Panoramic Depth Estimation. (arXiv:2202.02796v1 [cs.CV])
39. Low-confidence Samples Matter for Domain Adaptation. (arXiv:2202.02802v1 [cs.CV])
40. Perceptual Coding for Compressed Video Understanding: A New Framework and Benchmark. (arXiv:2202.02813v1 [eess.IV])
41. Block shuffling learning for Deepfake Detection. (arXiv:2202.02819v1 [cs.CV])
42. Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v1 [eess.IV])
43. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
44. Motion Deblurring with an Adaptive Network. (arXiv:1903.11394v4 [cs.CV] UPDATED)
45. Planar Geometry and Image Recovery from Motion-Blur. (arXiv:1904.03710v3 [cs.CV] UPDATED)
46. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v4 [cs.CV] UPDATED)
47. FISR: Deep Joint Frame Interpolation and Super-Resolution with a Multi-scale Temporal Loss. (arXiv:1912.07213v2 [cs.CV] UPDATED)
48. FedOCR: Communication-Efficient Federated Learning for Scene Text Recognition. (arXiv:2007.11462v2 [cs.CV] UPDATED)
49. Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking. (arXiv:2008.12052v4 [cs.CV] UPDATED)
50. Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness. (arXiv:2009.09612v2 [cs.CV] UPDATED)
51. A Real-Time Predictive Pedestrian Collision Warning Service for Cooperative Intelligent Transportation Systems Using 3D Pose Estimation. (arXiv:2009.10868v2 [cs.CV] UPDATED)
52. Bridging 2D and 3D Segmentation Networks for Computation Efficient Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions. (arXiv:2010.06163v2 [eess.IV] UPDATED)
53. Deep Learning for Regularization Prediction in Diffeomorphic Image Registration. (arXiv:2011.14229v3 [eess.IV] UPDATED)
54. Dense outlier detection and open-set recognition based on training with noisy negative images. (arXiv:2101.09193v2 [cs.CV] UPDATED)
55. Kanerva++: extending The Kanerva Machine with differentiable, locally block allocated latent memory. (arXiv:2103.03905v3 [cs.NE] UPDATED)
56. Unsupervised and self-adaptative techniques for cross-domain person re-identification. (arXiv:2103.11520v3 [cs.CV] UPDATED)
57. A Survey on Image Aesthetic Assessment. (arXiv:2103.11616v2 [cs.CV] UPDATED)
58. Eigenbackground Revisited: Can We Model the Background with Eigenvectors?. (arXiv:2104.11379v2 [cs.CV] UPDATED)
59. MoCo-Flow: Neural Motion Consensus Flow for Dynamic Humans in Stationary Monocular Cameras. (arXiv:2106.04477v2 [cs.CV] UPDATED)
60. Sparse Training via Boosting Pruning Plasticity with Neuroregeneration. (arXiv:2106.10404v4 [cs.LG] UPDATED)
61. Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity. (arXiv:2106.14568v4 [cs.LG] UPDATED)
62. Conditional GANs with Auxiliary Discriminative Classifier. (arXiv:2107.10060v4 [cs.LG] UPDATED)
63. Medical Image Segmentation using 3D Convolutional Neural Networks: A Review. (arXiv:2108.08467v2 [eess.IV] UPDATED)
64. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v3 [cs.CV] UPDATED)
65. UMPNet: Universal Manipulation Policy Network for Articulated Objects. (arXiv:2109.05668v3 [cs.CV] UPDATED)
66. Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data. (arXiv:2109.06094v2 [cs.CV] UPDATED)
67. Predicting the Timing of Camera Movements From the Kinematics of Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks. (arXiv:2109.11192v3 [cs.LG] UPDATED)
68. HarrisZ$^+$: Harris Corner Selection for Next-Gen Image Matching Pipelines. (arXiv:2109.12925v4 [cs.CV] UPDATED)
69. Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting. (arXiv:2109.14128v2 [cs.CV] UPDATED)
70. Adversarial Unlearning of Backdoors via Implicit Hypergradient. (arXiv:2110.03735v4 [cs.LG] UPDATED)
71. Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v2 [cs.CR] UPDATED)
72. ADMM-DAD net: a deep unfolding network for analysis compressed sensing. (arXiv:2110.06986v2 [cs.IT] UPDATED)
73. Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?. (arXiv:2110.07472v4 [cs.LG] UPDATED)
74. TorchEsegeta: Framework for Interpretability and Explainability of Image-based Deep Learning Models. (arXiv:2110.08429v2 [cs.CV] UPDATED)
75. Demystifying How Self-Supervised Features Improve Training from Noisy Labels. (arXiv:2110.09022v2 [cs.LG] UPDATED)
76. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v7 [eess.IV] UPDATED)
77. csBoundary: City-scale Road-boundary Detection in Aerial Images for High-definition Maps. (arXiv:2111.06020v2 [cs.CV] UPDATED)
78. MPF6D: Masked Pyramid Fusion 6D Pose Estimation. (arXiv:2111.09378v2 [cs.CV] UPDATED)
79. ALIKE: Accurate and Lightweight Keypoint Detection and Descriptor Extraction. (arXiv:2112.02906v2 [cs.CV] UPDATED)
80. FLAVA: A Foundational Language And Vision Alignment Model. (arXiv:2112.04482v2 [cs.CV] UPDATED)
81. Hybrid Atlas Building with Deep Registration Priors. (arXiv:2112.06406v2 [cs.CV] UPDATED)
82. Dual-Key Multimodal Backdoors for Visual Question Answering. (arXiv:2112.07668v2 [cs.CV] UPDATED)
83. Multi-Image Visual Question Answering. (arXiv:2112.13706v2 [cs.CV] UPDATED)
84. Multi-Band Wi-Fi Sensing with Matched Feature Granularity. (arXiv:2112.14006v2 [cs.NI] UPDATED)
85. RePaint: Inpainting using Denoising Diffusion Probabilistic Models. (arXiv:2201.09865v2 [cs.CV] UPDATED)
86. Projective Urban Texturing. (arXiv:2201.10938v2 [cs.CV] UPDATED)
87. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
88. Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs). (arXiv:2201.12240v2 [cs.LG] UPDATED)
89. VC-GPT: Visual Conditioned GPT for End-to-End Generative Vision-and-Language Pre-training. (arXiv:2201.12723v2 [cs.CV] UPDATED)
90. Augmenting Novelty Search with a Surrogate Model to Engineer Meta-Diversity in Ensembles of Classifiers. (arXiv:2201.12896v2 [cs.LG] UPDATED)
91. Filtering In Neural Implicit Functions. (arXiv:2201.13013v2 [cs.CV] UPDATED)
92. MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection. (arXiv:2201.13392v2 [eess.IV] UPDATED)
## eess.IV
---
**42** new papers in eess.IV:-) 
1. Boundary-aware Information Maximization for Self-supervised Medical Image Segmentation. (arXiv:2202.02371v1 [eess.IV])
2. Fully Automated Tree Topology Estimation and Artery-Vein Classification. (arXiv:2202.02382v1 [eess.IV])
3. Bregman Plug-and-Play Priors. (arXiv:2202.02388v1 [eess.IV])
4. Stratification of carotid atheromatous plaque using interpretable deep learning methods on B-mode ultrasound images. (arXiv:2202.02428v1 [eess.IV])
5. Machine Learning Method for Functional Assessment of Retinal Models. (arXiv:2202.02443v1 [eess.IV])
6. Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification. (arXiv:2202.02472v1 [eess.SP])
7. Less is More: Reversible Steganography with Uncertainty-Aware Predictive Analytics. (arXiv:2202.02518v1 [cs.CV])
8. Complex-amplitude Fourier single-pixel imaging via coherent structured illumination. (arXiv:2202.02527v1 [physics.optics])
9. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
10. A method for virtual optical sectioning and tomography utilizing shallow depth of field. (arXiv:2202.02692v1 [physics.optics])
11. Hyper-Convolutions via Implicit Kernels for Medical Imaging. (arXiv:2202.02701v1 [eess.IV])
12. Diffractive deep neural network based adaptive optics scheme for vortex beam in oceanic turbulence. (arXiv:2202.02732v1 [eess.IV])
13. On Smart Gaze based Annotation of Histopathology Images for Training of Deep Convolutional Neural Networks. (arXiv:2202.02764v1 [eess.IV])
14. Perceptual Coding for Compressed Video Understanding: A New Framework and Benchmark. (arXiv:2202.02813v1 [eess.IV])
15. Wave-Encoded Model-based Deep Learning for Highly Accelerated Imaging with Joint Reconstruction. (arXiv:2202.02814v1 [eess.IV])
16. Detecting Melanoma Fairly: Skin Tone Detection and Debiasing for Skin Lesion Classification. (arXiv:2202.02832v1 [eess.IV])
17. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
18. Deep Deterministic Independent Component Analysis for Hyperspectral Unmixing. (arXiv:2202.02951v1 [eess.IV])
19. SUD: Supervision by Denoising for Medical Image Segmentation. (arXiv:2202.02952v1 [eess.IV])
20. Learning Sound Localization Better From Semantically Similar Samples. (arXiv:2202.03007v1 [cs.CV])
21. Free-breathing motion compensated 4D (3D+respiration) T2-weighted turbo spin-echo MRI for body imaging. (arXiv:2202.03021v1 [physics.med-ph])
22. A comprehensive benchmark analysis for sand dust image reconstruction. (arXiv:2202.03031v1 [eess.IV])
23. Neural Network based Inter bi-prediction Blending. (arXiv:2202.03149v1 [eess.IV])
24. SODA: Self-organizing data augmentation in deep neural networks -- Application to biomedical image segmentation tasks. (arXiv:2202.03223v1 [stat.ML])
25. Motion-Plane-Adaptive Inter Prediction in 360-Degree Video Coding. (arXiv:2202.03323v1 [eess.IV])
26. A Review of Landcover Classification with Very-High Resolution Remotely Sensed Optical Images-Analysis Unit,Model Scalability and Transferability. (arXiv:2202.03342v1 [eess.IV])
27. FrePGAN: Robust Deepfake Detection Using Frequency-level Perturbations. (arXiv:2202.03347v1 [cs.CV])
28. LEDNet: Joint Low-light **Enhancement** and Deblurring in the **Dark**. (arXiv:2202.03373v1 [eess.IV])
29. Motion Deblurring with an Adaptive Network. (arXiv:1903.11394v4 [cs.CV] UPDATED)
30. Planar Geometry and Image Recovery from Motion-Blur. (arXiv:1904.03710v3 [cs.CV] UPDATED)
31. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v4 [cs.CV] UPDATED)
32. Compensation Tracker: Reprocessing Lost Object for Multi-Object Tracking. (arXiv:2008.12052v4 [cs.CV] UPDATED)
33. Bridging 2D and 3D Segmentation Networks for Computation Efficient Volumetric Medical Image Segmentation: An Empirical Study of 2.5D Solutions. (arXiv:2010.06163v2 [eess.IV] UPDATED)
34. Deep Learning for Regularization Prediction in Diffeomorphic Image Registration. (arXiv:2011.14229v3 [eess.IV] UPDATED)
35. Medical Image Segmentation using 3D Convolutional Neural Networks: A Review. (arXiv:2108.08467v2 [eess.IV] UPDATED)
36. Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data. (arXiv:2109.06094v2 [cs.CV] UPDATED)
37. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v7 [eess.IV] UPDATED)
38. Depth-resolved vascular profile features for artery-vein classification in OCT and OCT angiography of human retina. (arXiv:2112.07775v2 [q-bio.TO] UPDATED)
39. Learning a microlocal priorfor limited-angle tomography. (arXiv:2201.00656v2 [eess.IV] UPDATED)
40. EASY: Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients. (arXiv:2201.09699v2 [cs.LG] UPDATED)
41. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
42. MHSnet: Multi-head and Spatial Attention Network with False-Positive Reduction for Pulmonary Nodules Detection. (arXiv:2201.13392v2 [eess.IV] UPDATED)
## cs.LG
---
**257** new papers in cs.LG:-) 
1. Frequency comb and machine learning-based breath analysis for COVID-19 classification. (arXiv:2202.02321v1 [physics.med-ph])
2. Towards Training Reproducible Deep Learning Models. (arXiv:2202.02326v1 [cs.LG])
3. Discovering Distribution Shifts using Latent Space Representations. (arXiv:2202.02339v1 [cs.LG])
4. Selective Network Linearization for Efficient Private Inference. (arXiv:2202.02340v1 [cs.CR])
5. Learning Interpretable, High-Performing Policies for Continuous Control Problems. (arXiv:2202.02352v1 [cs.LG])
6. A note on the complex and bicomplex valued neural networks. (arXiv:2202.02354v1 [cs.LG])
7. A Fast Network Exploration Strategy to Profile Low Energy Consumption for Keyword Spotting. (arXiv:2202.02361v1 [cs.LG])
8. A Discourse on MetODS: Meta-Optimized Dynamical Synapses for Meta-Reinforcement Learning. (arXiv:2202.02363v1 [cs.LG])
9. Marius++: Large-Scale Training of Graph Neural Networks on a Single Machine. (arXiv:2202.02365v1 [cs.LG])
10. Bregman Plug-and-Play Priors. (arXiv:2202.02388v1 [eess.IV])
11. The impact of feature importance methods on the interpretation of defect classifiers. (arXiv:2202.02389v1 [cs.LG])
12. Deep Dynamic Effective Connectivity Estimation from Multivariate Time Series. (arXiv:2202.02393v1 [cs.LG])
13. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v1 [cs.CL])
14. A Temporal-Difference Approach to Policy Gradient Estimation. (arXiv:2202.02396v1 [cs.LG])
15. Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary Time-Series. (arXiv:2202.02403v1 [cs.LG])
16. BAM: Bayes with Adaptive Memory. (arXiv:2202.02405v1 [cs.LG])
17. Parameter-free Online Linear Optimization with Side Information via Universal Coin Betting. (arXiv:2202.02406v1 [cs.IT])
18. An Experimental Design Approach for Regret Minimization in Logistic Bandits. (arXiv:2202.02407v1 [stat.ML])
19. OMLT: Optimization & Machine Learning Toolkit. (arXiv:2202.02414v1 [stat.ML])
20. Learning a Discrete Set of Optimal Allocation Rules in Queueing Systems with Unknown Service Rates. (arXiv:2202.02419v1 [eess.SY])
21. Improved Information Theoretic Generalization Bounds for Distributed and Federated Learning. (arXiv:2202.02423v1 [cs.IT])
22. The influence of labeling techniques in classifying human manipulation movement of different speed. (arXiv:2202.02426v1 [cs.CV])
23. Lightweight Compositional Embeddings for Incremental Streaming Recommendation. (arXiv:2202.02427v1 [cs.LG])
24. Stratification of carotid atheromatous plaque using interpretable deep learning methods on B-mode ultrasound images. (arXiv:2202.02428v1 [eess.IV])
25. Verifying Inverse Model Neural Networks. (arXiv:2202.02429v1 [cs.LG])
26. Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v1 [cs.CL])
27. SMODICE: Versatile Offline Imitation Learning via State Occupancy Matching. (arXiv:2202.02433v1 [cs.LG])
28. On Neural Differential Equations. (arXiv:2202.02435v1 [cs.LG])
29. Neural Logic Analogy Learning. (arXiv:2202.02436v1 [cs.CL])
30. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v1 [cs.CV])
31. SEED: Sound Event Early Detection via Evidential Uncertainty. (arXiv:2202.02441v1 [cs.SD])
32. Transfer Reinforcement Learning for Differing Action Spaces via Q-Network Representations. (arXiv:2202.02442v1 [cs.LG])
33. Machine Learning Method for Functional Assessment of Retinal Models. (arXiv:2202.02443v1 [eess.IV])
34. Spelunking the Deep: Guaranteed Queries for General Neural Implicit Surfaces. (arXiv:2202.02444v1 [cs.CV])
35. Adversarially Trained Actor Critic for Offline Reinforcement Learning. (arXiv:2202.02446v1 [cs.LG])
36. Linear Model with Local Differential Privacy. (arXiv:2202.02448v1 [cs.CR])
37. Supervised Learning based QoE Prediction of Video Streaming in Future Networks: A Tutorial with Comparative Study. (arXiv:2202.02454v1 [cs.NI])
38. Application of Machine Learning-Based Pattern Recognition in IoT Devices: Review. (arXiv:2202.02456v1 [cs.NI])
39. One-Nearest-Neighbor Search is All You Need for Minimax Optimal Regression and Classification. (arXiv:2202.02464v1 [math.ST])
40. ASHA: Assistive Teleoperation via Human-in-the-Loop Reinforcement Learning. (arXiv:2202.02465v1 [cs.RO])
41. Handling Distribution Shifts on Graphs: An Invariance Perspective. (arXiv:2202.02466v1 [cs.LG])
42. Rethinking ValueDice: Does It Really Improve Performance?. (arXiv:2202.02468v1 [cs.LG])
43. MarkovGNN: Graph Neural Networks on Markov Diffusion. (arXiv:2202.02470v1 [cs.LG])
44. Few-shot Learning as Cluster-induced Voronoi Diagrams: A Geometric Approach. (arXiv:2202.02471v1 [cs.LG])
45. Tensor-CSPNet: A Novel Geometric Deep Learning Framework for Motor Imagery Classification. (arXiv:2202.02472v1 [eess.SP])
46. Importance Weighting Approach in Kernel Bayes' Rule. (arXiv:2202.02474v1 [stat.ML])
47. LotRec: A Recommender for Urban Vacant Lot Conversion. (arXiv:2202.02481v1 [cs.CY])
48. Distributed Learning With Sparsified Gradient Differences. (arXiv:2202.02491v1 [cs.LG])
49. Weisfeiler-Lehman meets Gromov-Wasserstein. (arXiv:2202.02495v1 [cs.LG])
50. GraphEye: A Novel Solution for Detecting Vulnerable Functions Based on Graph Attention Network. (arXiv:2202.02501v1 [cs.CR])
51. A Coalition Formation Game Approach for Personalized Federated Learning. (arXiv:2202.02502v1 [cs.AI])
52. Adversarial Detector with Robust Classifier. (arXiv:2202.02503v1 [cs.CV])
53. A Survey on Poisoning Attacks Against Supervised Machine Learning. (arXiv:2202.02510v1 [cs.CR])
54. Score-based Generative Modeling of Graphs via the System of Stochastic Differential Equations. (arXiv:2202.02514v1 [cs.LG])
55. LyaNet: A Lyapunov Framework for Training Neural ODEs. (arXiv:2202.02526v1 [cs.LG])
56. Graph Neural Network with Curriculum Learning for Imbalanced Node Classification. (arXiv:2202.02529v1 [cs.LG])
57. Multidimensional Cybersecurity Framework for Strategic Foresight. (arXiv:2202.02537v1 [cs.CR])
58. TorchMD-NET: Equivariant Transformers for Neural Network based Molecular Potentials. (arXiv:2202.02541v1 [cs.LG])
59. Differentially Private Graph Classification with GNNs. (arXiv:2202.02575v1 [cs.LG])
60. Causal Disentanglement for Semantics-Aware Intent Learning in Recommendation. (arXiv:2202.02576v1 [cs.IR])
61. Communication Efficient Federated Learning via Ordered ADMM in a Fully Decentralized Setting. (arXiv:2202.02580v1 [cs.LG])
62. VIS-iTrack: Visual Intention through Gaze Tracking using Low-Cost Webcam. (arXiv:2202.02587v1 [cs.HC])
63. Memory Defense: More Robust Classification via a Memory-Masking Autoencoder. (arXiv:2202.02595v1 [cs.CV])
64. Exemplar-Based Contrastive Self-Supervised Learning with Few-Shot Class Incremental Learning. (arXiv:2202.02601v1 [cs.LG])
65. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v1 [eess.IV])
66. Privacy-preserving Speech Emotion Recognition through Semi-Supervised Federated Learning. (arXiv:2202.02611v1 [cs.LG])
67. Adaptive Fine-Tuning of Transformer-Based Language Models for Named Entity Recognition. (arXiv:2202.02617v1 [cs.CL])
68. Training Differentially Private Models with Secure Multiparty Computation. (arXiv:2202.02625v1 [cs.CR])
69. Improved Certified Defenses against Data Poisoning with (Deterministic) Finite Aggregation. (arXiv:2202.02628v1 [cs.LG])
70. Emblaze: Illuminating Machine Learning Representations through Interactive Comparison of Embedding Spaces. (arXiv:2202.02641v1 [cs.HC])
71. The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training. (arXiv:2202.02643v1 [cs.LG])
72. The Implicit Bias of Gradient Descent on Generalized Gated Linear Networks. (arXiv:2202.02649v1 [stat.ML])
73. Efficient Logistic Regression with Local Differential Privacy. (arXiv:2202.02650v1 [cs.CR])
74. Beyond Black Box Densities: Parameter Learning for the Deviated Components. (arXiv:2202.02651v1 [stat.ML])
75. A Graph Neural Network Framework for Grid-Based Simulation. (arXiv:2202.02652v1 [cs.LG])
76. Doing Right by Not Doing Wrong in Human-Robot Collaboration. (arXiv:2202.02654v1 [cs.RO])
77. A survey of top-down approaches for human pose estimation. (arXiv:2202.02656v1 [cs.CV])
78. Deep-HyROMnet: A deep learning-based operator approximation for hyper-reduction of nonlinear parametrized PDEs. (arXiv:2202.02658v1 [math.NA])
79. A Game-theoretic Understanding of Repeated Explanations in ML Models. (arXiv:2202.02659v1 [cs.GT])
80. LiDAR dataset distillation within bayesian active learning framework: Understanding the effect of data augmentation. (arXiv:2202.02661v1 [cs.CV])
81. No Parameters Left Behind: Sensitivity Guided Adaptive Learning Rate for Training Large Transformer Models. (arXiv:2202.02664v1 [cs.CL])
82. Simulation-to-Reality domain adaptation for offline 3D object annotation on pointclouds with correlation alignment. (arXiv:2202.02666v1 [cs.CV])
83. Featherweight Assisted Vulnerability Discovery. (arXiv:2202.02679v1 [cs.CR])
84. TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network. (arXiv:2202.02691v1 [cs.LG])
85. Exploration with Multi-Sample Target Values for Distributional Reinforcement Learning. (arXiv:2202.02693v1 [cs.LG])
86. How Effective is Incongruity? Implications for Code-mix Sarcasm Detection. (arXiv:2202.02702v1 [cs.CL])
87. Spectrally Adapted Physics-Informed Neural Networks for Solving Unbounded Domain Problems. (arXiv:2202.02710v1 [cs.LG])
88. Robust Anomaly Detection for Time-series Data. (arXiv:2202.02721v1 [cs.LG])
89. Portfolio Optimization on NIFTY Thematic Sector Stocks Using an LSTM Model. (arXiv:2202.02723v1 [q-fin.PM])
90. Energy-Aware Edge Association for Cluster-based Personalized Federated Learning. (arXiv:2202.02727v1 [cs.LG])
91. Estimating the Euclidean Quantum Propagator with Deep Generative Modelling of Feynman paths. (arXiv:2202.02750v1 [quant-ph])
92. Pipe Overflow: Smashing Voice Authentication for Fun and Profit. (arXiv:2202.02751v1 [cs.LG])
93. Riemannian Score-Based Generative Modeling. (arXiv:2202.02763v1 [cs.LG])
94. Pushing the Efficiency-Regret Pareto Frontier for Online Learning of Portfolios and Quantum States. (arXiv:2202.02765v1 [cs.LG])
95. Optimal Algorithms for Decentralized Stochastic Variational Inequalities. (arXiv:2202.02771v1 [math.OC])
96. Human rights, democracy, and the rule of law assurance framework for AI systems: A proposal. (arXiv:2202.02776v1 [cs.AI])
97. Learning Features with Parameter-Free Layers. (arXiv:2202.02777v1 [cs.CV])
98. Energy awareness in low precision neural networks. (arXiv:2202.02783v1 [cs.LG])
99. Learning Synthetic Environments and Reward Networks for Reinforcement Learning. (arXiv:2202.02790v1 [cs.LG])
100. Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets. (arXiv:2202.02794v1 [cs.LG])
101. SIGMA: A Structural Inconsistency Reducing Graph Matching Algorithm. (arXiv:2202.02797v1 [cs.LG])
102. Learning to be a Statistician: Learned Estimator for Number of Distinct Values. (arXiv:2202.02800v1 [cs.LG])
103. Low-confidence Samples Matter for Domain Adaptation. (arXiv:2202.02802v1 [cs.CV])
104. Lossy Gradient Compression: How Much Accuracy Can One Bit Buy?. (arXiv:2202.02812v1 [cs.LG])
105. Wave-Encoded Model-based Deep Learning for Highly Accelerated Imaging with Joint Reconstruction. (arXiv:2202.02814v1 [eess.IV])
106. Learning Sparse Graphs via Majorization-Minimization for Smooth Node Signals. (arXiv:2202.02815v1 [eess.SP])
107. BEAS: Blockchain Enabled Asynchronous & Secure Federated Machine Learning. (arXiv:2202.02817v1 [cs.CR])
108. Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors. (arXiv:2202.02830v1 [cs.IR])
109. Anticorrelated Noise Injection for Improved Generalization. (arXiv:2202.02831v1 [stat.ML])
110. CheXstray: **Real-time** Multi-Modal Data Concordance for Drift Detection in Medical Imaging AI. (arXiv:2202.02833v1 [eess.IV])
111. A new similarity measure for covariate shift with applications to nonparametric regression. (arXiv:2202.02837v1 [math.ST])
112. Evaluating natural language processing models with generalization metrics that do not need access to any training or testing data. (arXiv:2202.02842v1 [cs.CL])
113. A Novel Micro-service Based Platform for Composition, Deployment and Execution of BDA Applications. (arXiv:2202.02845v1 [cs.DC])
114. Stochastic Gradient Descent with Dependent Data for Offline Reinforcement Learning. (arXiv:2202.02850v1 [cs.LG])
115. Machine Learning Aided Holistic Handover Optimization for Emerging Networks. (arXiv:2202.02851v1 [cs.NI])
116. Deep Learning-Aided Spatial Multiplexing with Index Modulation. (arXiv:2202.02856v1 [eess.SP])
117. Applications of Machine Learning in Healthcare and Internet of Things (IOT): A Comprehensive Review. (arXiv:2202.02868v1 [cs.LG])
118. Differentiable Economics for Randomized Affine Maximizer Auctions. (arXiv:2202.02872v1 [cs.GT])
119. HARFE: Hard-Ridge Random Feature Expansion. (arXiv:2202.02877v1 [stat.ML])
120. Trusted Approximate Policy Iteration with Bisimulation Metrics. (arXiv:2202.02881v1 [cs.LG])
121. On Using Transformers for Speech-Separation. (arXiv:2202.02884v1 [eess.AS])
122. Causal Inference Using Tractable Circuits. (arXiv:2202.02891v1 [cs.AI])
123. Learning under Storage and Privacy Constraints. (arXiv:2202.02892v1 [cs.IT])
124. Effects of Parametric and Non-Parametric Methods on High Dimensional Sparse Matrix Representations. (arXiv:2202.02894v1 [cs.LG])
125. Evaluation Methods and Measures for Causal Learning Algorithms. (arXiv:2202.02896v1 [cs.LG])
126. Gradient boosting machines and careful pre-processing work best: ASHRAE Great Energy Predictor III lessons learned. (arXiv:2202.02898v1 [cs.LG])
127. Learning Optimal Resource Allocations in Wireless Systems. (arXiv:1807.08088v3 [cs.LG] UPDATED)
128. Free Component Analysis: Theory, Algorithms & Applications. (arXiv:1905.01713v3 [cs.LG] UPDATED)
129. One-Shot Neural Architecture Search via Compressive Sensing. (arXiv:1906.02869v2 [cs.LG] UPDATED)
130. Scaling-Translation-Equivariant Networks with Decomposed Convolutional Filters. (arXiv:1909.11193v3 [cs.LG] UPDATED)
131. Deep Learning for Deepfakes Creation and Detection: A Survey. (arXiv:1909.11573v4 [cs.CV] UPDATED)
132. Deep Layer-wise Networks Have Closed-Form Weights. (arXiv:2006.08539v5 [stat.ML] UPDATED)
133. Spectral Bias and Task-Model Alignment Explain Generalization in Kernel Regression and Infinitely Wide Neural Networks. (arXiv:2006.13198v6 [stat.ML] UPDATED)
134. Hedging using reinforcement learning: Contextual $k$-Armed Bandit versus $Q$-learning. (arXiv:2007.01623v2 [cs.LG] UPDATED)
135. REMAX: Relational Representation for Multi-Agent Exploration. (arXiv:2008.05214v2 [cs.LG] UPDATED)
136. Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions. (arXiv:2008.07343v3 [cs.CY] UPDATED)
137. Semi-Supervised Empirical Risk Minimization: Using unlabeled data to improve prediction. (arXiv:2009.00606v5 [stat.ML] UPDATED)
138. Improving Ensemble Robustness by Collaboratively Promoting and Demoting Adversarial Robustness. (arXiv:2009.09612v2 [cs.CV] UPDATED)
139. Deep Learning for Regularization Prediction in Diffeomorphic Image Registration. (arXiv:2011.14229v3 [eess.IV] UPDATED)
140. Bayesian Neural Ordinary Differential Equations. (arXiv:2012.07244v4 [cs.LG] UPDATED)
141. Topological obstructions in neural networks learning. (arXiv:2012.15834v2 [cs.LG] UPDATED)
142. Learning and Fast Adaptation for Grid Emergency Control via Deep Meta Reinforcement Learning. (arXiv:2101.05317v2 [cs.LG] UPDATED)
143. HYDRA: Hypergradient Data Relevance Analysis for Interpreting Deep Neural Networks. (arXiv:2102.02515v4 [cs.LG] UPDATED)
144. Kanerva++: extending The Kanerva Machine with differentiable, locally block allocated latent memory. (arXiv:2103.03905v3 [cs.NE] UPDATED)
145. A Hybrid Architecture for Federated and Centralized Learning. (arXiv:2105.03288v2 [cs.LG] UPDATED)
146. Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics. (arXiv:2105.03918v2 [cs.LG] UPDATED)
147. Principal Components Bias in Over-parameterized Linear Models, and its Manifestation in Deep Neural Networks. (arXiv:2105.05553v6 [cs.LG] UPDATED)
148. Online Algorithms and Policies Using Adaptive and Machine Learning Approaches. (arXiv:2105.06577v4 [cs.LG] UPDATED)
149. Regret Analysis of Distributed Online LQR Control for Unknown LTI Systems. (arXiv:2105.07310v2 [math.OC] UPDATED)
150. Bridging Data Center AI Systems with Edge Computing for Actionable Information Retrieval. (arXiv:2105.13967v3 [cs.LG] UPDATED)
151. DISSECT: Disentangled Simultaneous Explanations via Concept Traversals. (arXiv:2105.15164v3 [cs.LG] UPDATED)
152. Learning a Single Neuron with Bias Using Gradient Descent. (arXiv:2106.01101v2 [cs.LG] UPDATED)
153. Out-of-Distribution Generalization in Kernel Regression. (arXiv:2106.02261v3 [stat.ML] UPDATED)
154. Learning Curves for SGD on Structured Features. (arXiv:2106.02713v4 [stat.ML] UPDATED)
155. Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework. (arXiv:2106.06046v4 [cs.LG] UPDATED)
156. Semi-verified PAC Learning from the Crowd with Pairwise Comparisons. (arXiv:2106.07080v2 [cs.LG] UPDATED)
157. Memorization and Generalization in Neural Code Intelligence Models. (arXiv:2106.08704v2 [cs.LG] UPDATED)
158. Automatic Curricula via Expert Demonstrations. (arXiv:2106.09159v3 [cs.LG] UPDATED)
159. Sparse Training via Boosting Pruning Plasticity with Neuroregeneration. (arXiv:2106.10404v4 [cs.LG] UPDATED)
160. Multi-Agent Curricula and Emergent Implicit Signaling. (arXiv:2106.11156v3 [cs.MA] UPDATED)
161. Making Invisible Visible: Data-Driven Seismic Inversion with Spatio-temporally Constrained Data Augmentation. (arXiv:2106.11892v3 [cs.LG] UPDATED)
162. Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v4 [cs.CL] UPDATED)
163. Deep Ensembling with No Overhead for either Training or Testing: The All-Round Blessings of Dynamic Sparsity. (arXiv:2106.14568v4 [cs.LG] UPDATED)
164. Detecting Errors and Estimating Accuracy on Unlabeled Data with Self-training Ensembles. (arXiv:2106.15728v3 [cs.LG] UPDATED)
165. Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization. (arXiv:2107.01131v2 [stat.ML] UPDATED)
166. Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v2 [cs.LG] UPDATED)
167. On the expressivity of bi-Lipschitz normalizing flows. (arXiv:2107.07232v2 [cs.LG] UPDATED)
168. AutoBERT-Zero: Evolving BERT Backbone from Scratch. (arXiv:2107.07445v2 [cs.CL] UPDATED)
169. Conditional GANs with Auxiliary Discriminative Classifier. (arXiv:2107.10060v4 [cs.LG] UPDATED)
170. AASAE: Augmentation-Augmented Stochastic Autoencoders. (arXiv:2107.12329v2 [cs.LG] UPDATED)
171. An Adapter Based Pre-Training for Efficient and Scalable Self-Supervised Speech Representation Learning. (arXiv:2107.13530v2 [eess.AS] UPDATED)
172. Hyperparameter-free and Explainable Whole Graph Embedding. (arXiv:2108.02113v3 [cs.LG] UPDATED)
173. Redatuming physical systems using symmetric autoencoders. (arXiv:2108.02537v2 [physics.comp-ph] UPDATED)
174. On the Power of Differentiable Learning versus PAC and SQ Learning. (arXiv:2108.04190v2 [cs.LG] UPDATED)
175. A Brief Review of Machine Learning Techniques for Protein Phosphorylation Sites Prediction. (arXiv:2108.04951v2 [q-bio.QM] UPDATED)
176. Efficient Local Planning with Linear Function Approximation. (arXiv:2108.05533v3 [cs.LG] UPDATED)
177. Accounting for shared covariates in semi-parametric Bayesian additive regression trees. (arXiv:2108.07636v3 [stat.ML] UPDATED)
178. Medical Image Segmentation using 3D Convolutional Neural Networks: A Review. (arXiv:2108.08467v2 [eess.IV] UPDATED)
179. Adaptive Explainable Continual Learning Framework for Regression Problems with Focus on Power Forecasts. (arXiv:2108.10781v2 [cs.LG] UPDATED)
180. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v3 [cs.CV] UPDATED)
181. Single-stream CNN with Learnable Architecture for Multi-source Remote Sensing Data. (arXiv:2109.06094v2 [cs.CV] UPDATED)
182. Should We Be Pre-training? An Argument for End-task Aware Training as an Alternative. (arXiv:2109.07437v2 [cs.LG] UPDATED)
183. Federated Submodel Averaging. (arXiv:2109.07704v3 [cs.LG] UPDATED)
184. Predicting the Timing of Camera Movements From the Kinematics of Instruments in Robotic-Assisted Surgery Using Artificial Neural Networks. (arXiv:2109.11192v3 [cs.LG] UPDATED)
185. Stochastic Normalizing Flows for Inverse Problems: a Markov Chains Viewpoint. (arXiv:2109.11375v4 [cs.LG] UPDATED)
186. AbstractDifferentiation.jl: Backend-Agnostic Differentiable Programming in Julia. (arXiv:2109.12449v2 [cs.MS] UPDATED)
187. PAC-Bayes Information Bottleneck. (arXiv:2109.14509v3 [cs.LG] UPDATED)
188. Federated Dropout -- A Simple Approach for Enabling Federated Learning on Resource Constrained Devices. (arXiv:2109.15258v3 [cs.LG] UPDATED)
189. Machine Learning with Knowledge Constraints for Process Optimization of Open-Air Perovskite Solar Cell Manufacturing. (arXiv:2110.01387v4 [cs.LG] UPDATED)
190. Geometric Transformers for Protein Interface Contact Prediction. (arXiv:2110.02423v4 [cs.LG] UPDATED)
191. EvadeDroid: A Practical Evasion Attack on Machine Learning for Black-box Android Malware Detection. (arXiv:2110.03301v2 [cs.LG] UPDATED)
192. A Comparison of Neural Network Architectures for Data-Driven Reduced-Order Modeling. (arXiv:2110.03442v2 [cs.LG] UPDATED)
193. Adversarial Unlearning of Backdoors via Implicit Hypergradient. (arXiv:2110.03735v4 [cs.LG] UPDATED)
194. FAST-RIR: Fast neural diffuse room impulse response generator. (arXiv:2110.04057v2 [cs.SD] UPDATED)
195. Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v2 [cs.CR] UPDATED)
196. ADMM-DAD net: a deep unfolding network for analysis compressed sensing. (arXiv:2110.06986v2 [cs.IT] UPDATED)
197. ReGVD: Revisiting Graph Neural Networks for Vulnerability Detection. (arXiv:2110.07317v3 [cs.LG] UPDATED)
198. Capacity of Group-invariant Linear Readouts from Equivariant Representations: How Many Objects can be Linearly Classified Under All Possible Views?. (arXiv:2110.07472v4 [cs.LG] UPDATED)
199. Demystifying How Self-Supervised Features Improve Training from Noisy Labels. (arXiv:2110.09022v2 [cs.LG] UPDATED)
200. On the Global Convergence of Momentum-based Policy Gradient. (arXiv:2110.10116v2 [cs.LG] UPDATED)
201. Learning quantum dynamics with latent neural ODEs. (arXiv:2110.10721v2 [quant-ph] UPDATED)
202. Deep Generative Models in Engineering Design: A Review. (arXiv:2110.10863v3 [cs.LG] UPDATED)
203. Is High Variance Unavoidable in RL? A Case Study in Continuous Control. (arXiv:2110.11222v2 [cs.LG] UPDATED)
204. Likelihood Training of Schr\"odinger Bridge using Forward-Backward SDEs Theory. (arXiv:2110.11291v3 [stat.ML] UPDATED)
205. Physics Informed Machine Learning of SPH: Machine Learning Lagrangian Turbulence. (arXiv:2110.13311v2 [physics.flu-dyn] UPDATED)
206. Temporal Knowledge Distillation for On-device Audio Classification. (arXiv:2110.14131v2 [cs.SD] UPDATED)
207. Multi-Task Neural Processes. (arXiv:2110.14953v3 [cs.LG] UPDATED)
208. A Scalable AutoML Approach Based on Graph Neural Networks. (arXiv:2111.00083v2 [cs.LG] UPDATED)
209. Intrusion Prevention through Optimal Stopping. (arXiv:2111.00289v5 [cs.LG] UPDATED)
210. Coordinate Linear Variance Reduction for Generalized Linear Programming. (arXiv:2111.01842v3 [math.OC] UPDATED)
211. Linking Across Data Granularity: Fitting Multivariate Hawkes Processes to Partially Interval-Censored Data. (arXiv:2111.02062v2 [cs.LG] UPDATED)
212. Short-Term Power Prediction for Renewable Energy Using Hybrid Graph Convolutional Network and Long Short-Term Memory Approach. (arXiv:2111.07958v2 [eess.SY] UPDATED)
213. Automatic Sleep Staging of EEG Signals: Recent Development, Challenges, and Future Directions. (arXiv:2111.08446v2 [eess.SP] UPDATED)
214. MPF6D: Masked Pyramid Fusion 6D Pose Estimation. (arXiv:2111.09378v2 [cs.CV] UPDATED)
215. Scaling Law for Recommendation Models: Towards General-purpose User Representations. (arXiv:2111.11294v3 [cs.IR] UPDATED)
216. Local Permutation Equivariance For Graph Neural Networks. (arXiv:2111.11840v2 [cs.LG] UPDATED)
217. Deep Representation Learning with an Information-theoretic Loss. (arXiv:2111.12950v5 [cs.LG] UPDATED)
218. L\'evy Induced Stochastic Differential Equation Equipped with Neural Network for Time Series Forecasting. (arXiv:2111.13164v3 [cs.LG] UPDATED)
219. A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis. (arXiv:2112.03405v2 [cs.LG] UPDATED)
220. Test Set Sizing Via Random Matrix Theory. (arXiv:2112.05977v2 [stat.ML] UPDATED)
221. Selecting Parallel In-domain Sentences for Neural Machine Translation Using Monolingual Texts. (arXiv:2112.06096v3 [cs.CL] UPDATED)
222. Confidence-Aware Subject-to-Subject Transfer Learning for Brain-Computer Interface. (arXiv:2112.09243v2 [cs.HC] UPDATED)
223. Semi-Supervised Clustering via Information-Theoretic Markov Chain Aggregation. (arXiv:2112.09397v2 [cs.LG] UPDATED)
224. Towards a Principled Learning Rate Adaptation for Natural Evolution Strategies. (arXiv:2112.10680v2 [cs.NE] UPDATED)
225. Logarithmic Unbiased Quantization: Simple 4-bit Training in Deep Learning. (arXiv:2112.10769v2 [cs.LG] UPDATED)
226. PRONTO: Preamble Overhead Reduction with Neural Networks for Coarse Synchronization. (arXiv:2112.10885v2 [cs.LG] UPDATED)
227. Faster Rates for Compressed Federated Learning with Client-Variance Reduction. (arXiv:2112.13097v2 [cs.LG] UPDATED)
228. Multi-Image Visual Question Answering. (arXiv:2112.13706v2 [cs.CV] UPDATED)
229. BALanCe: Deep Bayesian Active Learning via Equivalence Class Annealing. (arXiv:2112.13737v2 [cs.LG] UPDATED)
230. Resource-Efficient and Delay-Aware Federated Learning Design under Edge Heterogeneity. (arXiv:2112.13926v3 [cs.NI] UPDATED)
231. Polyak-Ruppert-Averaged Q-Learning is Statistically Efficient. (arXiv:2112.14582v3 [stat.ML] UPDATED)
232. Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates. (arXiv:2112.15025v2 [cs.LG] UPDATED)
233. Deep Reinforcement Learning, a textbook. (arXiv:2201.02135v2 [cs.AI] UPDATED)
234. Improved Input Reprogramming for GAN Conditioning. (arXiv:2201.02692v3 [cs.LG] UPDATED)
235. Solving Inventory Management Problems with Inventory-dynamics-informed Neural Networks. (arXiv:2201.06126v2 [cs.LG] UPDATED)
236. Equitable Community Resilience: The Case of Winter Storm Uri in Texas. (arXiv:2201.06652v2 [stat.ML] UPDATED)
237. Deep Attention-Based Supernovae Classification of Multi-Band Light-Curves. (arXiv:2201.08482v2 [astro-ph.IM] UPDATED)
238. EASY: Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients. (arXiv:2201.09699v2 [cs.LG] UPDATED)
239. Constrained Policy Optimization via Bayesian World Models. (arXiv:2201.09802v4 [cs.LG] UPDATED)
240. Physics-informed ConvNet: Learning Physical Field from a Shallow Neural Network. (arXiv:2201.10967v2 [cs.LG] UPDATED)
241. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v2 [eess.IV] UPDATED)
242. Differential Privacy Guarantees for Stochastic Gradient Langevin Dynamics. (arXiv:2201.11980v2 [stat.ML] UPDATED)
243. Mixing Implicit and Explicit Deep Learning with Skip DEQs and Infinite Time Neural ODEs (Continuous DEQs). (arXiv:2201.12240v2 [cs.LG] UPDATED)
244. Augmenting Novelty Search with a Surrogate Model to Engineer Meta-Diversity in Ensembles of Classifiers. (arXiv:2201.12896v2 [cs.LG] UPDATED)
245. Out-of-distribution Detection Using Kernel Density Polytopes. (arXiv:2201.13001v2 [cs.LG] UPDATED)
246. An end-to-end deep learning approach for extracting stochastic dynamical systems with $\alpha$-stable L\'evy noise. (arXiv:2201.13114v2 [stat.ML] UPDATED)
247. Learning on Arbitrary Graph Topologies via Predictive Coding. (arXiv:2201.13180v2 [cs.LG] UPDATED)
248. DNS: Determinantal Point Process Based Neural Network Sampler for Ensemble Reinforcement Learning. (arXiv:2201.13357v2 [cs.LG] UPDATED)
249. Understanding Knowledge Integration in Language Models with Graph Convolutions. (arXiv:2202.00964v2 [cs.CL] UPDATED)
250. RescoreBERT: Discriminative Speech Recognition Rescoring with BERT. (arXiv:2202.01094v2 [eess.AS] UPDATED)
251. Deep Layer-wise Networks Have Closed-Form Weights. (arXiv:2202.01210v2 [stat.ML] UPDATED)
252. Fast Convex Optimization for Two-Layer ReLU Networks: Equivalent Model Classes and Cone Decompositions. (arXiv:2202.01331v2 [cs.LG] UPDATED)
253. An Empirical Review of Optimization Techniques for Quantum Variational Circuits. (arXiv:2202.01389v2 [quant-ph] UPDATED)
254. Transport Score Climbing: Variational Inference Using Forward KL and Adaptive Neural Transport. (arXiv:2202.01841v2 [stat.ML] UPDATED)
255. SignSGD: Fault-Tolerance to Blind and Byzantine Adversaries. (arXiv:2202.02085v2 [cs.LG] UPDATED)
256. COIL: Constrained Optimization in Learned Latent Space -- Learning Representations for Valid Solutions. (arXiv:2202.02163v2 [cs.NE] UPDATED)
257. CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software. (arXiv:2107.08760v1 [cs.SE] CROSS LISTED)
## cs.AI
---
**106** new papers in cs.AI:-) 
1. Towards Training Reproducible Deep Learning Models. (arXiv:2202.02326v1 [cs.LG])
2. A Discourse on MetODS: Meta-Optimized Dynamical Synapses for Meta-Reinforcement Learning. (arXiv:2202.02363v1 [cs.LG])
3. Using Large-scale Heterogeneous Graph Representation Learning for Code Review Recommendations. (arXiv:2202.02385v1 [cs.SE])
4. Automatic Identification of Self-Admitted Technical Debt from Different Sources. (arXiv:2202.02387v1 [cs.SE])
5. The impact of feature importance methods on the interpretation of defect classifiers. (arXiv:2202.02389v1 [cs.LG])
6. JARVix at SemEval-2022 Task 2: It Takes One to Know One? Idiomaticity Detection using Zero and One Shot Learning. (arXiv:2202.02394v1 [cs.CL])
7. Malleable Agents for Re-Configurable Robotic Manipulators. (arXiv:2202.02395v1 [cs.RO])
8. A Temporal-Difference Approach to Policy Gradient Estimation. (arXiv:2202.02396v1 [cs.LG])
9. Self-Adaptive Forecasting for Improved Deep Learning on Non-Stationary Time-Series. (arXiv:2202.02403v1 [cs.LG])
10. Model-Free Reinforcement Learning for Symbolic Automata-encoded Objectives. (arXiv:2202.02404v1 [cs.AI])
11. OMLT: Optimization & Machine Learning Toolkit. (arXiv:2202.02414v1 [stat.ML])
12. The influence of labeling techniques in classifying human manipulation movement of different speed. (arXiv:2202.02426v1 [cs.CV])
13. HENRI: High Efficiency Negotiation-based Robust Interface for Multi-party Multi-issue Negotiation over the Internet. (arXiv:2202.02430v1 [cs.AI])
14. Transformers and the representation of biomedical background knowledge. (arXiv:2202.02432v1 [cs.CL])
15. SMODICE: Versatile Offline Imitation Learning via State Occupancy Matching. (arXiv:2202.02433v1 [cs.LG])
16. Neural Logic Analogy Learning. (arXiv:2202.02436v1 [cs.CL])
17. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v1 [cs.CV])
18. Transfer Reinforcement Learning for Differing Action Spaces via Q-Network Representations. (arXiv:2202.02442v1 [cs.LG])
19. Security-Aware Virtual Network Embedding Algorithm based on Reinforcement Learning. (arXiv:2202.02452v1 [cs.NI])
20. Space-Air-Ground Integrated Multi-domain Network Resource Orchestration based on Virtual Network Architecture: a DRL Method. (arXiv:2202.02459v1 [cs.NI])
21. Handling Distribution Shifts on Graphs: An Invariance Perspective. (arXiv:2202.02466v1 [cs.LG])
22. MarkovGNN: Graph Neural Networks on Markov Diffusion. (arXiv:2202.02470v1 [cs.LG])
23. Distributed Learning With Sparsified Gradient Differences. (arXiv:2202.02491v1 [cs.LG])
24. A Coalition Formation Game Approach for Personalized Federated Learning. (arXiv:2202.02502v1 [cs.AI])
25. Intent Contrastive Learning for Sequential Recommendation. (arXiv:2202.02519v1 [cs.AI])
26. Comparative study of 3D object detection frameworks based on LiDAR data and sensor fusion techniques. (arXiv:2202.02521v1 [cs.CV])
27. LyaNet: A Lyapunov Framework for Training Neural ODEs. (arXiv:2202.02526v1 [cs.LG])
28. Graph Neural Network with Curriculum Learning for Imbalanced Node Classification. (arXiv:2202.02529v1 [cs.LG])
29. Science Facing Interoperability as a Necessary Condition of Success and Evil. (arXiv:2202.02540v1 [cs.CY])
30. TorchMD-NET: Equivariant Transformers for Neural Network based Molecular Potentials. (arXiv:2202.02541v1 [cs.LG])
31. Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting. (arXiv:2202.02543v1 [cs.CV])
32. Symmetric Volume Maps. (arXiv:2202.02568v1 [cs.GR])
33. Communication Efficient Federated Learning via Ordered ADMM in a Fully Decentralized Setting. (arXiv:2202.02580v1 [cs.LG])
34. Privacy-preserving Speech Emotion Recognition through Semi-Supervised Federated Learning. (arXiv:2202.02611v1 [cs.LG])
35. The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training. (arXiv:2202.02643v1 [cs.LG])
36. Ethics, Rules of Engagement, and AI: Neural Narrative Mapping Using Large Transformer Language Models. (arXiv:2202.02647v1 [cs.CL])
37. A Graph Neural Network Framework for Grid-Based Simulation. (arXiv:2202.02652v1 [cs.LG])
38. Doing Right by Not Doing Wrong in Human-Robot Collaboration. (arXiv:2202.02654v1 [cs.RO])
39. A survey of top-down approaches for human pose estimation. (arXiv:2202.02656v1 [cs.CV])
40. (Almost) Envy-Free, Proportional and Efficient Allocations of an Indivisible Mixed Manna. (arXiv:2202.02672v1 [cs.GT])
41. TTS-GAN: A Transformer-based Time-Series Generative Adversarial Network. (arXiv:2202.02691v1 [cs.LG])
42. Exploration with Multi-Sample Target Values for Distributional Reinforcement Learning. (arXiv:2202.02693v1 [cs.LG])
43. Triangle Graph Interest Network for Click-through Rate Prediction. (arXiv:2202.02698v1 [cs.AI])
44. Energy-Aware Edge Association for Cluster-based Personalized Federated Learning. (arXiv:2202.02727v1 [cs.LG])
45. The Self-Driving Car: Crossroads at the Bleeding Edge of Artificial Intelligence and Law. (arXiv:2202.02734v1 [cs.AI])
46. Pipe Overflow: Smashing Voice Authentication for Fun and Profit. (arXiv:2202.02751v1 [cs.LG])
47. Human rights, democracy, and the rule of law assurance framework for AI systems: A proposal. (arXiv:2202.02776v1 [cs.AI])
48. Learning Synthetic Environments and Reward Networks for Reinforcement Learning. (arXiv:2202.02790v1 [cs.LG])
49. SFMGNet: A Physics-based Neural Network To Predict Pedestrian Trajectories. (arXiv:2202.02791v1 [cs.RO])
50. Block shuffling learning for Deepfake Detection. (arXiv:2202.02819v1 [cs.CV])
51. Discovering Personalized Semantics for Soft Attributes in Recommender Systems using Concept Activation Vectors. (arXiv:2202.02830v1 [cs.IR])
52. Aligning Eyes between Humans and Deep Neural Network through Interactive Attention Alignment. (arXiv:2202.02838v1 [cs.AI])
53. Deep Learning-Aided Spatial Multiplexing with Index Modulation. (arXiv:2202.02856v1 [eess.SP])
54. Applications of Machine Learning in Healthcare and Internet of Things (IOT): A Comprehensive Review. (arXiv:2202.02868v1 [cs.LG])
55. Deep Convolutional Learning-Aided Detector for Generalized Frequency Division Multiplexing with Index Modulation. (arXiv:2202.02876v1 [eess.SP])
56. An Empirical Analysis of AI Contributions to Sustainable Cities (SDG11). (arXiv:2202.02879v1 [cs.AI])
57. Trusted Approximate Policy Iteration with Bisimulation Metrics. (arXiv:2202.02881v1 [cs.LG])
58. Leveraging Approximate Symbolic Models for Reinforcement Learning via Skill Diversity. (arXiv:2202.02886v1 [cs.AI])
59. Causal Inference Using Tractable Circuits. (arXiv:2202.02891v1 [cs.AI])
60. Evaluation Methods and Measures for Causal Learning Algorithms. (arXiv:2202.02896v1 [cs.LG])
61. REMAX: Relational Representation for Multi-Agent Exploration. (arXiv:2008.05214v2 [cs.LG] UPDATED)
62. Artificial Intelligence in the Battle against Coronavirus (COVID-19): A Survey and Future Research Directions. (arXiv:2008.07343v3 [cs.CY] UPDATED)
63. Residual Learning from Demonstration: Adapting DMPs for Contact-rich Manipulation. (arXiv:2008.07682v4 [cs.RO] UPDATED)
64. Topological obstructions in neural networks learning. (arXiv:2012.15834v2 [cs.LG] UPDATED)
65. Old but Gold: Reconsidering the value of feedforward learners for software analytics. (arXiv:2101.06319v2 [cs.SE] UPDATED)
66. Explaining Adversarial Vulnerability with a Data Sparsity Hypothesis. (arXiv:2103.00778v2 [cs.AI] UPDATED)
67. Kanerva++: extending The Kanerva Machine with differentiable, locally block allocated latent memory. (arXiv:2103.03905v3 [cs.NE] UPDATED)
68. Unsupervised and self-adaptative techniques for cross-domain person re-identification. (arXiv:2103.11520v3 [cs.CV] UPDATED)
69. DISSECT: Disentangled Simultaneous Explanations via Concept Traversals. (arXiv:2105.15164v3 [cs.LG] UPDATED)
70. Controller Synthesis for Omega-Regular and Steady-State Specifications. (arXiv:2106.02951v2 [eess.SY] UPDATED)
71. Information Theoretic Evaluation of Privacy-Leakage, Interpretability, and Transferability for a Novel Trustworthy AI Framework. (arXiv:2106.06046v4 [cs.LG] UPDATED)
72. A Syntax-Guided Edit Decoder for Neural Program Repair. (arXiv:2106.08253v5 [cs.SE] UPDATED)
73. Multi-Agent Curricula and Emergent Implicit Signaling. (arXiv:2106.11156v3 [cs.MA] UPDATED)
74. Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v4 [cs.CL] UPDATED)
75. Tight Mutual Information Estimation With Contrastive Fenchel-Legendre Optimization. (arXiv:2107.01131v2 [stat.ML] UPDATED)
76. Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v2 [cs.LG] UPDATED)
77. Centralized Model and Exploration Policy for Multi-Agent RL. (arXiv:2107.06434v2 [cs.AI] UPDATED)
78. Learning to Prompt for Vision-Language Models. (arXiv:2109.01134v3 [cs.CV] UPDATED)
79. Federated Submodel Averaging. (arXiv:2109.07704v3 [cs.LG] UPDATED)
80. The Case for Claim Difficulty Assessment in Automatic Fact Checking. (arXiv:2109.09689v2 [cs.CL] UPDATED)
81. Grouptron: Dynamic Multi-Scale Graph Convolutional Networks for Group-Aware Dense Crowd Trajectory Forecasting. (arXiv:2109.14128v2 [cs.CV] UPDATED)
82. PAC-Bayes Information Bottleneck. (arXiv:2109.14509v3 [cs.LG] UPDATED)
83. FAST-RIR: Fast neural diffuse room impulse response generator. (arXiv:2110.04057v2 [cs.SD] UPDATED)
84. Demystifying the Transferability of Adversarial Attacks in Computer Networks. (arXiv:2110.04488v2 [cs.CR] UPDATED)
85. TorchEsegeta: Framework for Interpretability and Explainability of Image-based Deep Learning Models. (arXiv:2110.08429v2 [cs.CV] UPDATED)
86. Is High Variance Unavoidable in RL? A Case Study in Continuous Control. (arXiv:2110.11222v2 [cs.LG] UPDATED)
87. Precise URL Phishing Detection Using Neural Networks. (arXiv:2110.13424v2 [cs.CR] UPDATED)
88. Intrusion Prevention through Optimal Stopping. (arXiv:2111.00289v5 [cs.LG] UPDATED)
89. Automatic Sleep Staging of EEG Signals: Recent Development, Challenges, and Future Directions. (arXiv:2111.08446v2 [eess.SP] UPDATED)
90. A Novel Deep Parallel Time-series Relation Network for Fault Diagnosis. (arXiv:2112.03405v2 [cs.LG] UPDATED)
91. Selecting Parallel In-domain Sentences for Neural Machine Translation Using Monolingual Texts. (arXiv:2112.06096v3 [cs.CL] UPDATED)
92. A Deep Knowledge Distillation framework for EEG assisted **enhancement** of single-lead ECG based sleep staging. (arXiv:2112.07252v2 [eess.SP] UPDATED)
93. AI Ethics Principles in Practice: Perspectives of Designers and Developers. (arXiv:2112.07467v2 [cs.CY] UPDATED)
94. ADBCMM : Acronym Disambiguation by Building Counterfactuals and Multilingual Mixing. (arXiv:2112.08991v2 [cs.CL] UPDATED)
95. Confidence-Aware Subject-to-Subject Transfer Learning for Brain-Computer Interface. (arXiv:2112.09243v2 [cs.HC] UPDATED)
96. Toward a New Science of Common Sense. (arXiv:2112.12754v2 [cs.AI] UPDATED)
97. Multi-Image Visual Question Answering. (arXiv:2112.13706v2 [cs.CV] UPDATED)
98. BALanCe: Deep Bayesian Active Learning via Equivalence Class Annealing. (arXiv:2112.13737v2 [cs.LG] UPDATED)
99. Deep Reinforcement Learning, a textbook. (arXiv:2201.02135v2 [cs.AI] UPDATED)
100. Improved Input Reprogramming for GAN Conditioning. (arXiv:2201.02692v3 [cs.LG] UPDATED)
101. EASY: Ensemble Augmented-Shot Y-shaped Learning: State-Of-The-Art Few-Shot Classification with Simple Ingredients. (arXiv:2201.09699v2 [cs.LG] UPDATED)
102. Constrained Policy Optimization via Bayesian World Models. (arXiv:2201.09802v4 [cs.LG] UPDATED)
103. Out-of-distribution Detection Using Kernel Density Polytopes. (arXiv:2201.13001v2 [cs.LG] UPDATED)
104. Computational Complexity of Segmentation. (arXiv:2201.13106v2 [cs.AI] UPDATED)
105. 5G Network on Wings: A Deep Reinforcement Learning Approach to UAV-based Integrated Access and Backhaul. (arXiv:2202.02006v2 [cs.NI] UPDATED)
106. CVEfixes: Automated Collection of Vulnerabilities and Their Fixes from Open-Source Software. (arXiv:2107.08760v1 [cs.SE] CROSS LISTED)

