# Your interest papers
---
## cs.CV
---
### RCRN: Real-world Character Image **Restoration** Network via Skeleton Extraction. (arXiv:2207.07795v1 [cs.CV])
- Authors : Daqian Shi, Xiaolei Diao, Hao Tang, Xiaomin Li, Hao Xing, Hao Xu
- Link : [http://arxiv.org/abs/2207.07795](http://arxiv.org/abs/2207.07795)
> ABSTRACT  :  Constructing high-quality character image datasets is challenging because real-world images are often affected by image degradation. There are limitations when applying current image **restoration** methods to such real-world character images, since (i) the categories of noise in character images are different from those in general images; (ii) real-world character images usually contain more complex image degradation, e.g., mixed noise at different noise levels. To address these problems, we propose a real-world character **restoration** network (RCRN) to effectively restore degraded character images, where character skeleton information and scale-ensemble feature extraction are utilized to obtain better **restoration** performance. The proposed method consists of a skeleton extractor (SENet) and a character image restorer (CiRNet). SENet aims to preserve the structural consistency of the character and normalize complex noise. Then, CiRNet reconstructs clean images from degraded character images and their skeletons. Due to the lack of benchmarks for real-world character image **restoration**, we constructed a dataset containing 1,606 character images with real-world degradation to evaluate the validity of the proposed method. The experimental results demonstrate that RCRN outperforms state-of-the-art methods quantitatively and qualitatively.  
### Structural Prior Guided Generative Adversarial Transformers for **Low-Light** Image **Enhancement**. (arXiv:2207.07828v1 [cs.CV])
- Authors : Cong Wang, Jinshan Pan, Ming Wu
- Link : [http://arxiv.org/abs/2207.07828](http://arxiv.org/abs/2207.07828)
> ABSTRACT  :  We propose an effective Structural Prior guided Generative Adversarial Transformer (SPGAT) to solve **low-light** image **enhancement**. Our SPGAT mainly contains a generator with two discriminators and a structural prior estimator (SPE). The generator is based on a U-shaped Transformer which is used to explore non-local information for better clear image **restoration**. The SPE is used to explore useful structures from images to guide the generator for better structural detail estimation. To generate more realistic images, we develop a new structural prior guided adversarial learning method by building the skip connections between the generator and discriminators so that the discriminators can better discriminate between real and fake features. Finally, we propose a parallel windows-based **Swin** Transformer block to aggregate different level hierarchical features for high-quality image **restoration**. Experimental results demonstrate that the proposed SPGAT performs favorably against recent state-of-the-art methods on both synthetic and real-world datasets.  
### Analysis of liver cancer detection based on image processing. (arXiv:2207.08032v1 [eess.IV])
- Authors : Mahmoudreza Moghimhanjani, Ali Taghavirashidizadeh
- Link : [http://arxiv.org/abs/2207.08032](http://arxiv.org/abs/2207.08032)
> ABSTRACT  :  Medical imaging is the most important tool for detecting complications in the inner body of medicine. Nowadays, with the development of image processing technology as well as changing the size of photos to higher resolution images in the field of digital medical imaging, there is an efficient and accurate system for segmenting this. Real-world images that for a variety of reasons have poor heterogeneity, noise and contrast are essential. Digital image segmentation in medicine is used for diagnostic and therapeutic analysis, which is very helpful for physicians. In this study, we aim at liver cancer photographs, which aim to more accurately detect the lesion or tumor of the liver because accurate and timely detection of the tumor is very important in the survival and life of the patient.The aim of this paper is to simplify the obnoxious study problems related to the study of MR images. The liver is the second organ most generic involved by metastatic disease being liver cancer one of the prominent causes of death worldwide. Without healthy liver a person cannot survive. It is life threatening disease which is very challenging perceptible for both medical and engineering technologists. Medical image processing is used as a non-invasive method to detect tumours. The chances of survival having liver Tumor highly depends on early detection of Tumor and then classification as cancerous and noncancerous tumours. Image processing techniques for automatic detection of brain are includes pre-processing and **enhancement**, image segmentation, classification and volume calculation, Poly techniques have been developed for the detection of liver Tumor and different liver toM oR detection algorithms and methodologies utilized for Tumor diagnosis. Novel methodology for the detection and diagnosis of liver Tumor.  
### E-NeRV: Expedite Neural Video Representation with Disentangled Spatial-Temporal Context. (arXiv:2207.08132v1 [cs.CV])
- Authors : Zizhang Li, Mengmeng Wang, Huaijin Pi, Kechun Xu, Jianbiao Mei, Yong Liu
- Link : [http://arxiv.org/abs/2207.08132](http://arxiv.org/abs/2207.08132)
> ABSTRACT  :  Recently, the image-wise **implicit neural representation** of videos, NeRV, has gained popularity for its promising results and swift speed compared to regular pixel-wise implicit representations. However, the redundant parameters within the network structure can cause a large model size when scaling up for desirable performance. The key reason of this phenomenon is the coupled formulation of NeRV, which outputs the spatial and temporal information of video frames directly from the frame index input. In this paper, we propose E-NeRV, which dramatically expedites NeRV by decomposing the image-wise **implicit neural representation** into separate spatial and temporal context. Under the guidance of this new formulation, our model greatly reduces the redundant model parameters, while retaining the representation ability. We experimentally find that our method can improve the performance to a large extent with fewer parameters, resulting in a more than $8\times$ faster speed on convergence. Code is available at https://github.com/kyleleey/E-NeRV.  
### Editing Out-of-domain GAN Inversion via Differential Activations. (arXiv:2207.08134v1 [cs.CV])
- Authors : Haorui Song, Yong Du, Tianyi Xiang, Junyu Dong, Jing Qin, Shengfeng He
- Link : [http://arxiv.org/abs/2207.08134](http://arxiv.org/abs/2207.08134)
> ABSTRACT  :  Despite the demonstrated editing capacity in the latent space of a pretrained GAN model, inverting real-world images is stuck in a dilemma that the reconstruction cannot be faithful to the original input. The main reason for this is that the distributions between training and real-world data are misaligned, and because of that, it is unstable of GAN inversion for real image editing. In this paper, we propose a novel GAN prior based editing framework to tackle the out-of-domain inversion problem with a composition-decomposition paradigm. In particular, during the phase of composition, we introduce a differential activation module for detecting semantic changes from a global perspective, \ie, the relative gap between the features of edited and unedited images. With the aid of the generated Diff-CAM mask, a coarse reconstruction can intuitively be composited by the paired original and edited images. In this way, the attribute-irrelevant regions can be survived in almost whole, while the quality of such an intermediate result is still limited by an unavoidable ghosting effect. Consequently, in the decomposition phase, we further present a GAN prior based **deghosting** network for separating the final fine edited image from the coarse reconstruction. Extensive experiments exhibit superiorities over the state-of-the-art methods, in terms of qualitative and quantitative evaluations. The robustness and flexibility of our method is also validated on both scenarios of single attribute and multi-attribute manipulations.  
### Synthesizing MR Image Contrast **Enhancement** Using 3D High-resolution ConvNets. (arXiv:2104.01592v3 [eess.IV] UPDATED)
- Authors : Chao Chen, Catalina Raymond, Bill Speier, Xinyu Jin, Dieter Enzmann
- Link : [http://arxiv.org/abs/2104.01592](http://arxiv.org/abs/2104.01592)
> ABSTRACT  :  \textit{Objective:} Gadolinium-based contrast agents (GBCAs) have been widely used to better visualize disease in brain magnetic resonance imaging (MRI). However, gadolinium deposition within the brain and body has raised safety concerns about the use of GBCAs. Therefore, the development of novel approaches that can decrease or even eliminate GBCA **exposure** while providing similar contrast information would be of significant use clinically. \textit{Methods:} In this work, we present a deep learning based approach for contrast-enhanced T1 synthesis on brain tumor patients. A 3D high-resolution fully convolutional network (FCN), which maintains high resolution information through processing and aggregates multi-scale information in parallel, is designed to map pre-contrast MRI sequences to contrast-enhanced MRI sequences. Specifically, three pre-contrast MRI sequences, T1, T2 and apparent diffusion coefficient map (ADC), are utilized as inputs and the post-contrast T1 sequences are utilized as target output. To alleviate the data imbalance problem between normal tissues and the tumor regions, we introduce a local loss to improve the contribution of the tumor regions, which leads to better **enhancement** results on tumors. \textit{Results:} Extensive quantitative and visual assessments are performed, with our proposed model achieving a PSNR of 28.24dB in the brain and 21.2dB in tumor regions. \textit{Conclusion and Significance:} Our results suggest the potential of substituting GBCAs with synthetic contrast images generated via deep learning. Code is available at \url{https://github.com/chenchao666/Contrast-enhanced-MRI-Synthesis  
### GMFlow: Learning Optical Flow via Global Matching. (arXiv:2111.13680v4 [cs.CV] UPDATED)
- Authors : Haofei Xu, Jing Zhang, Jianfei Cai, Hamid Rezatofighi, Dacheng Tao
- Link : [http://arxiv.org/abs/2111.13680](http://arxiv.org/abs/2111.13680)
> ABSTRACT  :  Learning-based optical flow estimation has been dominated with the pipeline of cost volume with convolutions for flow regression, which is inherently limited to local correlations and thus is hard to address the long-standing challenge of large displacements. To alleviate this, the state-of-the-art framework RAFT gradually improves its prediction quality by using a large number of iterative refinements, achieving remarkable performance but introducing linearly increasing inference time. To enable both high accuracy and efficiency, we completely revamp the dominant flow regression pipeline by reformulating optical flow as a global matching problem, which identifies the correspondences by directly comparing feature similarities. Specifically, we propose a GMFlow framework, which consists of three main components: a customized Transformer for feature **enhancement**, a correlation and softmax layer for global feature matching, and a self-attention layer for flow propagation. We further introduce a refinement step that reuses GMFlow at higher feature resolution for residual flow prediction. Our new framework outperforms 31-refinements RAFT on the challenging Sintel benchmark, while using only one refinement and running faster, suggesting a new paradigm for accurate and efficient optical flow estimation. Code is available at https://github.com/haofeixu/gmflow.  
### 3D-Aware Semantic-Guided Generative Model for Human Synthesis. (arXiv:2112.01422v2 [cs.CV] UPDATED)
- Authors : Jichao Zhang, Enver Sangineto, Hao Tang, Aliaksandr Siarohin, Zhun Zhong, Nicu Sebe, Wei Wang
- Link : [http://arxiv.org/abs/2112.01422](http://arxiv.org/abs/2112.01422)
> ABSTRACT  :  Generative Neural Radiance Field (G**NeRF**) models, which extract implicit 3D representations from 2D images, have recently been shown to produce realistic images representing rigid/semi-rigid objects, such as human faces or cars. However, they usually struggle to generate high-quality images representing non-rigid objects, such as the human body, which is of a great interest for many computer graphics applications. This paper proposes a 3D-aware Semantic-Guided Generative Model (3D-SGAN) for human image synthesis, which combines a G**NeRF** with a texture generator. The former learns an implicit 3D representation of the human body and outputs a set of 2D semantic segmentation masks. The latter transforms these semantic masks into a real image, adding a realistic texture to the human appearance. Without requiring additional 3D information, our model can learn 3D human representations with a photo-realistic, controllable generation. Our experiments on the DeepFashion dataset show that 3D-SGAN significantly outperforms the most recent baselines. The code is available at https://github.com/zhangqianhui/3DSGAN  
### iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images. (arXiv:2112.11325v6 [cs.CV] UPDATED)
- Authors : Qin Liu, Zhenlin Xu, Yining Jiao, Marc Niethammer
- Link : [http://arxiv.org/abs/2112.11325](http://arxiv.org/abs/2112.11325)
> ABSTRACT  :  We propose iSegFormer, a memory-efficient transformer that combines a **Swin** transformer with a lightweight multilayer perceptron (MLP) decoder. With the efficient **Swin** transformer blocks for hierarchical self-attention and the simple MLP decoder for aggregating both local and global attention, iSegFormer learns powerful representations while achieving high computational efficiencies. Specifically, we apply iSegFormer to interactive 3D medical image segmentation.  
### MINER: Multiscale Implicit Neural Representations. (arXiv:2202.03532v2 [cs.CV] UPDATED)
- Authors : Vishwanath Saragadam, Jasper Tan, Guha Balakrishnan, Ashok Veeraraghavan
- Link : [http://arxiv.org/abs/2202.03532](http://arxiv.org/abs/2202.03532)
> ABSTRACT  :  We introduce a new neural signal model designed for efficient high-resolution representation of large-scale signals. The key innovation in our multiscale **implicit neural representation** (MINER) is an internal representation via a Laplacian pyramid, which provides a sparse multiscale decomposition of the signal that captures orthogonal parts of the signal across scales. We leverage the advantages of the Laplacian pyramid by representing small disjoint patches of the pyramid at each scale with a small MLP. This enables the capacity of the network to adaptively increase from coarse to fine scales, and only represent parts of the signal with strong signal energy. The parameters of each MLP are optimized from coarse-to-fine scale which results in faster approximations at coarser scales, thereby ultimately an extremely fast training process. We apply MINER to a range of large-scale signal representation tasks, including gigapixel images and very large point clouds, and demonstrate that it requires fewer than 25% of the parameters, 33% of the memory footprint, and 10% of the computation time of competing techniques such as ACORN to reach the same representation accuracy.  
### ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification. (arXiv:2202.07570v3 [cs.CV] UPDATED)
- Authors : Thomas Stegm, Behzad Bozorgtabar, Antoine Spahr, Philippe Thiran
- Link : [http://arxiv.org/abs/2202.07570](http://arxiv.org/abs/2202.07570)
> ABSTRACT  :  Progress in digital pathology is hindered by high-resolution images and the prohibitive cost of exhaustive localized annotations. The commonly used paradigm to categorize pathology images is patch-based processing, which often incorporates multiple instance learning (MIL) to aggregate local patch-level representations yielding image-level prediction. Nonetheless, diagnostically relevant regions may only take a small fraction of the whole tissue, and current MIL-based approaches often process images uniformly, discarding the inter-patches interactions. To alleviate these issues, we propose ScoreNet, a new efficient transformer that exploits a differentiable recommendation stage to extract discriminative image regions and dedicate computational resources accordingly. The proposed transformer leverages the local and global attention of a few dynamically recommended high-resolution regions at an efficient computational cost. We further introduce a novel mixing data-augmentation, namely ScoreMix, by leveraging the image's semantic distribution to guide the data mixing and produce coherent sample-label pairs. ScoreMix is embarrassingly simple and mitigates the pitfalls of previous augmentations, which assume a uniform semantic distribution and risk mislabeling the samples. Thorough experiments and ablation studies on three breast cancer histology datasets of Haematoxylin &amp; Eosin (H&amp;E) have validated the superiority of our approach over prior arts, including transformer-based models on tumour regions-of-interest (TRoIs) classification. ScoreNet equipped with proposed ScoreMix augmentation demonstrates better generalization capabilities and achieves new state-of-the-art (SOTA) results with only 50% of the data compared to other mixing augmentation variants. Finally, ScoreNet yields high efficacy and outperforms SOTA efficient transformers, namely TransPath and **Swin**Transformer.  
### FAR: Fourier Aerial Video Recognition. (arXiv:2203.10694v2 [cs.CV] UPDATED)
- Authors : Divya Kothandaraman, Tianrui Guan, Xijun Wang, Sean Hu, Ming Lin, Dinesh Manocha
- Link : [http://arxiv.org/abs/2203.10694](http://arxiv.org/abs/2203.10694)
> ABSTRACT  :  We present an algorithm, Fourier Activity Recognition (FAR), for UAV video activity recognition. Our formulation uses a novel Fourier object disentanglement method to innately separate out the human agent (which is typically small) from the background. Our disentanglement technique operates in the frequency domain to characterize the extent of temporal change of spatial pixels, and exploits convolution-multiplication properties of Fourier transform to map this representation to the corresponding object-background entangled features obtained from the network. To encapsulate contextual information and long-range space-time dependencies, we present a novel Fourier Attention algorithm, which emulates the benefits of self-attention by modeling the weighted outer product in the frequency domain. Our Fourier attention formulation uses much fewer computations than self-attention. We have evaluated our approach on multiple UAV datasets including UAV Human RGB, UAV Human **Night**, Drone Action, and NEC Drone. We demonstrate a relative improvement of 8.02% - 38.69% in top-1 accuracy and up to 3 times faster over prior works.  
### ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer. (arXiv:2203.10790v2 [cs.CV] UPDATED)
- Authors : Rui Yang, Hailong Ma, Jie Wu, Yansong Tang, Xuefeng Xiao, Min Zheng, Xiu Li
- Link : [http://arxiv.org/abs/2203.10790](http://arxiv.org/abs/2203.10790)
> ABSTRACT  :  The vanilla self-attention mechanism inherently relies on pre-defined and steadfast computational dimensions. Such inflexibility restricts it from possessing context-oriented generalization that can bring more contextual cues and global representations. To mitigate this issue, we propose a Scalable Self-Attention (SSA) mechanism that leverages two scaling factors to release dimensions of query, key, and value matrices while unbinding them with the input. This scalability fetches context-oriented generalization and enhances object sensitivity, which pushes the whole network into a more effective trade-off state between accuracy and cost. Furthermore, we propose an Interactive Window-based Self-Attention (IWSA), which establishes interaction between non-overlapping regions by re-merging independent value tokens and aggregating spatial information from adjacent windows. By stacking the SSA and IWSA alternately, the Scalable Vision Transformer (ScalableViT) achieves state-of-the-art performance in general-purpose vision tasks. For example, ScalableViT-S outperforms Twins-SVT-S by 1.4% and **Swin**-T by 1.8% on ImageNet-1K classification.  
### Two Decades of Colorization and Decolorization for Images and Videos. (arXiv:2204.13322v2 [cs.CV] UPDATED)
- Authors : Shiguang Liu
- Link : [http://arxiv.org/abs/2204.13322](http://arxiv.org/abs/2204.13322)
> ABSTRACT  :  Colorization is a computer-aided process, which aims to give color to a gray image or video. It can be used to enhance black-and-white images, including black-and-white photos, old-fashioned films, and scientific imaging results. On the contrary, decolorization is to convert a color image or video into a grayscale one. A grayscale image or video refers to an image or video with only brightness information without color information. It is the basis of some downstream image processing applications such as pattern recognition, image segmentation, and image **enhancement**. Different from image decolorization, video decolorization should not only consider the image contrast preservation in each video frame, but also respect the temporal and spatial consistency between video frames. Researchers were devoted to develop decolorization methods by balancing spatial-temporal consistency and algorithm efficiency. With the prevalance of the digital cameras and mobile phones, image and video colorization and decolorization have been paid more and more attention by researchers. This paper gives an overview of the progress of image and video colorization and decolorization methods in the last two decades.  
### MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing. (arXiv:2207.05621v2 [cs.CV] UPDATED)
- Authors : Sixiang Chen, Tian Ye, Yun Liu, Taodong Liao, Yi Ye, Erkang Chen
- Link : [http://arxiv.org/abs/2207.05621](http://arxiv.org/abs/2207.05621)
> ABSTRACT  :  Image **restoration** of snow scenes in severe weather is a difficult task. Snow images have complex degradations and are cluttered over clean images, changing the distribution of clean images. The previous methods based on CNNs are challenging to remove perfectly in restoring snow scenes due to their local inductive biases' lack of a specific global modeling ability. In this paper, we apply the vision transformer to the task of snow removal from a single image. Specifically, we propose a parallel network architecture split along the channel, performing local feature refinement and global information modeling separately. We utilize a channel shuffle operation to combine their respective strengths to enhance network performance. Second, we propose the MSP module, which utilizes multi-scale avgpool to aggregate information of different sizes and simultaneously performs multi-scale projection self-attention on multi-head self-attention to improve the representation ability of the model under different scale degradations. Finally, we design a lightweight and simple local capture module, which can refine the local capture capability of the model.    In the experimental part, we conduct extensive experiments to demonstrate the superiority of our method. We compared the previous snow removal methods on three snow scene datasets. The experimental results show that our method surpasses the state-of-the-art methods with fewer parameters and computation. We achieve substantial growth by 1.99dB and SSIM 0.03 on the CSD test dataset. On the SRRS and Snow100K datasets, we also increased PSNR by 2.47dB and 1.62dB compared with the Transweather approach and improved by 0.03 in SSIM. In the visual comparison section, our MSP-Former also achieves better visual effects than existing methods, proving the usability of our method.  
## eess.IV
---
### Structural Prior Guided Generative Adversarial Transformers for **Low-Light** Image **Enhancement**. (arXiv:2207.07828v1 [cs.CV])
- Authors : Cong Wang, Jinshan Pan, Ming Wu
- Link : [http://arxiv.org/abs/2207.07828](http://arxiv.org/abs/2207.07828)
> ABSTRACT  :  We propose an effective Structural Prior guided Generative Adversarial Transformer (SPGAT) to solve **low-light** image **enhancement**. Our SPGAT mainly contains a generator with two discriminators and a structural prior estimator (SPE). The generator is based on a U-shaped Transformer which is used to explore non-local information for better clear image **restoration**. The SPE is used to explore useful structures from images to guide the generator for better structural detail estimation. To generate more realistic images, we develop a new structural prior guided adversarial learning method by building the skip connections between the generator and discriminators so that the discriminators can better discriminate between real and fake features. Finally, we propose a parallel windows-based **Swin** Transformer block to aggregate different level hierarchical features for high-quality image **restoration**. Experimental results demonstrate that the proposed SPGAT performs favorably against recent state-of-the-art methods on both synthetic and real-world datasets.  
### Analysis of liver cancer detection based on image processing. (arXiv:2207.08032v1 [eess.IV])
- Authors : Mahmoudreza Moghimhanjani, Ali Taghavirashidizadeh
- Link : [http://arxiv.org/abs/2207.08032](http://arxiv.org/abs/2207.08032)
> ABSTRACT  :  Medical imaging is the most important tool for detecting complications in the inner body of medicine. Nowadays, with the development of image processing technology as well as changing the size of photos to higher resolution images in the field of digital medical imaging, there is an efficient and accurate system for segmenting this. Real-world images that for a variety of reasons have poor heterogeneity, noise and contrast are essential. Digital image segmentation in medicine is used for diagnostic and therapeutic analysis, which is very helpful for physicians. In this study, we aim at liver cancer photographs, which aim to more accurately detect the lesion or tumor of the liver because accurate and timely detection of the tumor is very important in the survival and life of the patient.The aim of this paper is to simplify the obnoxious study problems related to the study of MR images. The liver is the second organ most generic involved by metastatic disease being liver cancer one of the prominent causes of death worldwide. Without healthy liver a person cannot survive. It is life threatening disease which is very challenging perceptible for both medical and engineering technologists. Medical image processing is used as a non-invasive method to detect tumours. The chances of survival having liver Tumor highly depends on early detection of Tumor and then classification as cancerous and noncancerous tumours. Image processing techniques for automatic detection of brain are includes pre-processing and **enhancement**, image segmentation, classification and volume calculation, Poly techniques have been developed for the detection of liver Tumor and different liver toM oR detection algorithms and methodologies utilized for Tumor diagnosis. Novel methodology for the detection and diagnosis of liver Tumor.  
### INFWIDE: Image and Feature Space Wiener Deconvolution Network for Non-blind Image Deblurring in **Low-Light** Conditions. (arXiv:2207.08201v1 [cs.CV])
- Authors : Zhihong Zhang, Yuxiao Cheng, Jinli Suo, Liheng Bian, Qionghai Dai
- Link : [http://arxiv.org/abs/2207.08201](http://arxiv.org/abs/2207.08201)
> ABSTRACT  :  Under **low-light** environment, handheld photography suffers from severe camera shake under long **exposure** settings. Although existing deblurring algorithms have shown promising performance on well-exposed blurry images, they still cannot cope with **low-light** snapshots. Sophisticated noise and saturation regions are two dominating challenges in practical **low-light** deblurring. In this work, we propose a novel non-blind deblurring method dubbed image and feature space Wiener deconvolution network (INFWIDE) to tackle these problems systematically. In terms of algorithm design, INFWIDE proposes a two-branch architecture, which explicitly removes noise and hallucinates saturated regions in the image space and suppresses ringing artifacts in the feature space, and integrates the two complementary outputs with a subtle multi-scale fusion network for high quality **night** photograph deblurring. For effective network training, we design a set of loss functions integrating a forward imaging model and backward reconstruction to form a close-loop regularization to secure good convergence of the deep neural network. Further, to optimize INFWIDE's applicability in real **low-light** conditions, a physical-process-based **low-light** noise model is employed to synthesize realistic noisy **night** photographs for model training. Taking advantage of the traditional Wiener deconvolution algorithm's physically driven characteristics and arisen deep neural network's representation ability, INFWIDE can recover fine details while suppressing the unpleasant artifacts during deblurring. Extensive experiments on synthetic data and real data demonstrate the superior performance of the proposed approach.  
### SepLUT: Separable Image-adaptive Lookup Tables for **Real-time** Image **Enhancement**. (arXiv:2207.08351v1 [cs.CV])
- Authors : Canqian Yang, Meiguang Jin, Yi Xu, Rui Zhang, Ying Chen, Huaida Liu
- Link : [http://arxiv.org/abs/2207.08351](http://arxiv.org/abs/2207.08351)
> ABSTRACT  :  Image-adaptive lookup tables (LUTs) have achieved great success in real-time image **enhancement** tasks due to their high efficiency for modeling color transforms. However, they embed the complete transform, including the color component-independent and the component-correlated parts, into only a single type of LUTs, either 1D or 3D, in a coupled manner. This scheme raises a dilemma of improving model expressiveness or efficiency due to two factors. On the one hand, the 1D LUTs provide high computational efficiency but lack the critical capability of color components interaction. On the other, the 3D LUTs present enhanced component-correlated transform capability but suffer from heavy memory footprint, high training difficulty, and limited cell utilization. Inspired by the conventional divide-and-conquer practice in the image signal processor, we present SepLUT (separable image-adaptive lookup table) to tackle the above limitations. Specifically, we separate a single color transform into a cascade of component-independent and component-correlated sub-transforms instantiated as 1D and 3D LUTs, respectively. In this way, the capabilities of two sub-transforms can facilitate each other, where the 3D LUT complements the ability to mix up color components, and the 1D LUT redistributes the input colors to increase the cell utilization of the 3D LUT and thus enable the use of a more lightweight 3D LUT. Experiments demonstrate that the proposed method presents enhanced performance on photo retouching benchmark datasets than the current state-of-the-art and achieves real-time processing on both GPUs and CPUs.  
### Multi-head Cascaded **Swin** Transformers with Attention to k-space Sampling Pattern for Accelerated MRI Reconstruction. (arXiv:2207.08412v1 [eess.IV])
- Authors : Mevan Ekanayake, Kamlesh Pawar, Mehrtash Harandi, Gary Egan, Zhaolin Chen
- Link : [http://arxiv.org/abs/2207.08412](http://arxiv.org/abs/2207.08412)
> ABSTRACT  :  Global correlations are widely seen in human anatomical structures due to similarity across tissues and bones. These correlations are reflected in magnetic resonance imaging (MRI) scans as a result of close-range proton density and T1/T2 parameter. Furthermore, to achieve accelerated MRI, k-space data are undersampled which causes global aliasing artifacts. Convolutional neural network (CNN) models are widely utilized for accelerated MRI reconstruction, but those models are limited in capturing global correlations due to the intrinsic locality of the convolution operation. The self-attention-based transformer models are capable of capturing global correlations among image features, however, the current contributions of transformer models for MRI reconstruction are minute. The existing contributions mostly provide CNN-transformer hybrid solutions and rarely leverage the physics of MRI. In this paper, we propose a physics-based stand-alone (convolution free) transformer model titled, the Multi-head Cascaded **Swin** Transformers (McSTRA) for accelerated MRI reconstruction. McSTRA combines several interconnected MRI physics-related concepts with the transformer networks: it exploits global MR features via the shifted window self-attention mechanism; it extracts MR features belonging to different spectral components separately using a multi-head setup; it iterates between intermediate de-aliasing and k-space correction via a cascaded network with data consistency in k-space and intermediate loss computations; furthermore, we propose a novel positional embedding generation mechanism to guide self-attention utilizing the point spread function corresponding to the undersampling mask. Our model significantly outperforms state-of-the-art MRI reconstruction methods both visually and quantitatively while depicting improved resolution and removal of aliasing artifacts.  
### Enhancing **HDR** Video Compression through CNN-based Effective Bit Depth Adaptation. (arXiv:2207.08634v1 [eess.IV])
- Authors : Chen Feng, Zihao Qi, Duolikun Danier, Fan Zhang, Xiaozhong Xu, Shan Liu, David Bull
- Link : [http://arxiv.org/abs/2207.08634](http://arxiv.org/abs/2207.08634)
> ABSTRACT  :  It is well known that **high dynamic range** (**HDR**) video can provide more immersive visual experiences compared to conventional standard dynamic range content. However, **HDR** content is typically more challenging to encode due to the increased detail associated with the wider dynamic range. In this paper, we improve **HDR** compression performance using the effective bit depth adaptation approach (EBDA). This method reduces the effective bit depth of the original video content before encoding and reconstructs the full bit depth using a CNN-based up-sampling method at the decoder. In this work, we modify the MFRNet network architecture to enable multiple frame processing, and the new network, multi-frame MFRNet, has been integrated into the EBDA framework using two Versatile Video Coding (VVC) host codecs: VTM 16.2 and the Fraunhofer Versatile Video Encoder (VVenC 1.4.0). The proposed approach was evaluated under the JVET **HDR** Common Test Conditions using the Random Access configuration. The results show coding gains over both the original VVC VTM 16.2 and VVenC 1.4.0 (w/o EBDA) on JVET **HDR** tested sequences, with average bitrate savings of 2.9% (over VTM) and 4.8% (against VVenC) based on the Bjontegaard Delta measurement. The source code of multi-frame MFRNet has been released at https://github.com/fan-aaron-zhang/MF-MFRNet.  
### Synthesizing MR Image Contrast **Enhancement** Using 3D High-resolution ConvNets. (arXiv:2104.01592v3 [eess.IV] UPDATED)
- Authors : Chao Chen, Catalina Raymond, Bill Speier, Xinyu Jin, Dieter Enzmann
- Link : [http://arxiv.org/abs/2104.01592](http://arxiv.org/abs/2104.01592)
> ABSTRACT  :  \textit{Objective:} Gadolinium-based contrast agents (GBCAs) have been widely used to better visualize disease in brain magnetic resonance imaging (MRI). However, gadolinium deposition within the brain and body has raised safety concerns about the use of GBCAs. Therefore, the development of novel approaches that can decrease or even eliminate GBCA **exposure** while providing similar contrast information would be of significant use clinically. \textit{Methods:} In this work, we present a deep learning based approach for contrast-enhanced T1 synthesis on brain tumor patients. A 3D high-resolution fully convolutional network (FCN), which maintains high resolution information through processing and aggregates multi-scale information in parallel, is designed to map pre-contrast MRI sequences to contrast-enhanced MRI sequences. Specifically, three pre-contrast MRI sequences, T1, T2 and apparent diffusion coefficient map (ADC), are utilized as inputs and the post-contrast T1 sequences are utilized as target output. To alleviate the data imbalance problem between normal tissues and the tumor regions, we introduce a local loss to improve the contribution of the tumor regions, which leads to better **enhancement** results on tumors. \textit{Results:} Extensive quantitative and visual assessments are performed, with our proposed model achieving a PSNR of 28.24dB in the brain and 21.2dB in tumor regions. \textit{Conclusion and Significance:} Our results suggest the potential of substituting GBCAs with synthetic contrast images generated via deep learning. Code is available at \url{https://github.com/chenchao666/Contrast-enhanced-MRI-Synthesis  
## cs.LG
---
### Associative Memory Based Experience Replay for Deep Reinforcement Learning. (arXiv:2207.07791v1 [cs.AR])
- Authors : Mengyuan Li, Arman Kazemi, Ann Franchesca, Sharon Hu
- Link : [http://arxiv.org/abs/2207.07791](http://arxiv.org/abs/2207.07791)
> ABSTRACT  :  Experience replay is an essential component in deep reinforcement learning (DRL), which stores the experiences and generates experiences for the agent to learn in **real time**. Recently, prioritized experience replay (PER) has been proven to be powerful and widely deployed in DRL agents. However, implementing PER on traditional CPU or GPU architectures incurs significant latency overhead due to its frequent and irregular memory accesses. This paper proposes a hardware-software co-design approach to design an associative memory (AM) based PER, AMPER, with an AM-friendly priority sampling operation. AMPER replaces the widely-used time-costly tree-traversal-based priority sampling in PER while preserving the learning performance. Further, we design an in-memory computing hardware architecture based on AM to support AMPER by leveraging parallel in-memory search operations. AMPER shows comparable learning performance while achieving 55x to 270x latency improvement when running on the proposed hardware compared to the state-of-the-art PER running on GPU.  
### Improving Multi-Interest Network with Stable Learning. (arXiv:2207.07910v1 [cs.IR])
- Authors : Zhaocheng Liu, Yingtao Luo, Di Zeng, Qiang Liu, Daqing Chang, Dongying Kong, Zhi Chen
- Link : [http://arxiv.org/abs/2207.07910](http://arxiv.org/abs/2207.07910)
> ABSTRACT  :  Modeling users' dynamic preferences from historical behaviors lies at the core of modern recommender systems. Due to the diverse nature of user interests, recent advances propose the multi-interest networks to encode historical behaviors into multiple interest vectors. In real scenarios, the corresponding items of captured interests are usually retrieved together to get **exposure** and collected into training data, which produces dependencies among interests. Unfortunately, multi-interest networks may incorrectly concentrate on subtle dependencies among captured interests. Misled by these dependencies, the spurious correlations between irrelevant interests and targets are captured, resulting in the instability of prediction results when training and test distributions do not match. In this paper, we introduce the widely used Hilbert-Schmidt Independence Criterion (HSIC) to measure the degree of independence among captured interests and empirically show that the continuous increase of HSIC may harm model performance. Based on this, we propose a novel multi-interest network, named DEep Stable Multi-Interest Learning (DESMIL), which tries to eliminate the influence of subtle dependencies among captured interests via learning weights for training samples and make model concentrate more on underlying true causation. We conduct extensive experiments on public recommendation datasets, a large-scale industrial dataset and the synthetic datasets which simulate the out-of-distribution data. Experimental results demonstrate that our proposed DESMIL outperforms state-of-the-art models by a significant margin. Besides, we also conduct comprehensive model analysis to reveal the reason why DESMIL works to a certain extent.  
### **Bilateral** Dependency Optimization: Defending Against Model-inversion Attacks. (arXiv:2206.05483v3 [cs.LG] UPDATED)
- Authors : Xiong Peng, Feng Liu, Jingfen Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han
- Link : [http://arxiv.org/abs/2206.05483](http://arxiv.org/abs/2206.05483)
> ABSTRACT  :  Through using only a well-trained classifier, model-inversion (MI) attacks can recover the data used for training the classifier, leading to the privacy leakage of the training data. To defend against MI attacks, previous work utilizes a unilateral dependency optimization strategy, i.e., minimizing the dependency between inputs (i.e., features) and outputs (i.e., labels) during training the classifier. However, such a minimization process conflicts with minimizing the supervised loss that aims to maximize the dependency between inputs and outputs, causing an explicit trade-off between model robustness against MI attacks and model utility on classification tasks. In this paper, we aim to minimize the dependency between the latent representations and the inputs while maximizing the dependency between latent representations and the outputs, named a **bilateral** dependency optimization (BiDO) strategy. In particular, we use the dependency constraints as a universally applicable regularizer in addition to commonly used losses for deep neural networks (e.g., cross-entropy), which can be instantiated with appropriate dependency criteria according to different tasks. To verify the efficacy of our strategy, we propose two implementations of BiDO, by using two different dependency measures: BiDO with constrained covariance (BiDO-COCO) and BiDO with Hilbert-Schmidt Independence Criterion (BiDO-HSIC). Experiments show that BiDO achieves the state-of-the-art defense performance for a variety of datasets, classifiers, and MI attacks while suffering a minor classification-accuracy drop compared to the well-trained classifier with no defense, which lights up a novel road to defend against MI attacks.  
## cs.AI
---
### Autonomously Untangling Long Cables. (arXiv:2207.07813v1 [cs.RO])
- Authors : Vainavi Viswanath, Kaushik Shivakumar, Justin Kerr, Brijen Thananjeyan, Ellen Novoseller, Jeffrey Ichnowski, Alejandro Escontrela, Michael Laskey, Ken Goldberg
- Link : [http://arxiv.org/abs/2207.07813](http://arxiv.org/abs/2207.07813)
> ABSTRACT  :  Cables are ubiquitous in many settings, but are prone to self-occlusions and knots, making them difficult to perceive and manipulate. The challenge often increases with cable length: long cables require more complex slack management and strategies to facilitate observability and reachability. In this paper, we focus on autonomously untangling cables up to 3 meters in length using a **bilateral** robot. We develop new motion primitives to efficiently untangle long cables and novel gripper jaws specialized for this task. We present Sliding and Grasping for Tangle Manipulation (SGTM), an algorithm that composes these primitives with RGBD vision to iteratively untangle. SGTM untangles cables with success rates of 67% on isolated overhand and figure eight knots and 50% on more complex configurations. Supplementary material, visualizations, and videos can be found at https://sites.google.com/view/rss-2022-untangling/home.  
### Improving Multi-Interest Network with Stable Learning. (arXiv:2207.07910v1 [cs.IR])
- Authors : Zhaocheng Liu, Yingtao Luo, Di Zeng, Qiang Liu, Daqing Chang, Dongying Kong, Zhi Chen
- Link : [http://arxiv.org/abs/2207.07910](http://arxiv.org/abs/2207.07910)
> ABSTRACT  :  Modeling users' dynamic preferences from historical behaviors lies at the core of modern recommender systems. Due to the diverse nature of user interests, recent advances propose the multi-interest networks to encode historical behaviors into multiple interest vectors. In real scenarios, the corresponding items of captured interests are usually retrieved together to get **exposure** and collected into training data, which produces dependencies among interests. Unfortunately, multi-interest networks may incorrectly concentrate on subtle dependencies among captured interests. Misled by these dependencies, the spurious correlations between irrelevant interests and targets are captured, resulting in the instability of prediction results when training and test distributions do not match. In this paper, we introduce the widely used Hilbert-Schmidt Independence Criterion (HSIC) to measure the degree of independence among captured interests and empirically show that the continuous increase of HSIC may harm model performance. Based on this, we propose a novel multi-interest network, named DEep Stable Multi-Interest Learning (DESMIL), which tries to eliminate the influence of subtle dependencies among captured interests via learning weights for training samples and make model concentrate more on underlying true causation. We conduct extensive experiments on public recommendation datasets, a large-scale industrial dataset and the synthetic datasets which simulate the out-of-distribution data. Experimental results demonstrate that our proposed DESMIL outperforms state-of-the-art models by a significant margin. Besides, we also conduct comprehensive model analysis to reveal the reason why DESMIL works to a certain extent.  
### ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer. (arXiv:2203.10790v2 [cs.CV] UPDATED)
- Authors : Rui Yang, Hailong Ma, Jie Wu, Yansong Tang, Xuefeng Xiao, Min Zheng, Xiu Li
- Link : [http://arxiv.org/abs/2203.10790](http://arxiv.org/abs/2203.10790)
> ABSTRACT  :  The vanilla self-attention mechanism inherently relies on pre-defined and steadfast computational dimensions. Such inflexibility restricts it from possessing context-oriented generalization that can bring more contextual cues and global representations. To mitigate this issue, we propose a Scalable Self-Attention (SSA) mechanism that leverages two scaling factors to release dimensions of query, key, and value matrices while unbinding them with the input. This scalability fetches context-oriented generalization and enhances object sensitivity, which pushes the whole network into a more effective trade-off state between accuracy and cost. Furthermore, we propose an Interactive Window-based Self-Attention (IWSA), which establishes interaction between non-overlapping regions by re-merging independent value tokens and aggregating spatial information from adjacent windows. By stacking the SSA and IWSA alternately, the Scalable Vision Transformer (ScalableViT) achieves state-of-the-art performance in general-purpose vision tasks. For example, ScalableViT-S outperforms Twins-SVT-S by 1.4% and **Swin**-T by 1.8% on ImageNet-1K classification.  
# Paper List
---
## cs.CV
---
**183** new papers in cs.CV:-) 
1. Localisation And Imaging Methods for Moving Target Ghost Imaging Radar Based On Correlation Intensity Weighting. (arXiv:2207.07649v1 [eess.IV])
2. POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging. (arXiv:2207.07697v1 [cs.LG])
3. Untrained, physics-informed neural networks for structured illumination microscopy. (arXiv:2207.07705v1 [eess.IV])
4. Adversarial Focal Loss: Asking Your Discriminator for Hard Examples. (arXiv:2207.07739v1 [cs.CV])
5. Human keypoint detection for close proximity human-robot interaction. (arXiv:2207.07742v1 [cs.CV])
6. HOME: High-Order Mixed-Moment-based Embedding for Representation Learning. (arXiv:2207.07743v1 [cs.LG])
7. ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video. (arXiv:2207.07759v1 [eess.IV])
8. Learning Long-Term Spatial-Temporal Graphs for Active Speaker Detection. (arXiv:2207.07783v1 [cs.CV])
9. Towards the Desirable Decision Boundary by Moderate-Margin Adversarial Training. (arXiv:2207.07793v1 [cs.CV])
10. RCRN: Real-world Character Image **Restoration** Network via Skeleton Extraction. (arXiv:2207.07795v1 [cs.CV])
11. CARBEN: Composite Adversarial Robustness Benchmark. (arXiv:2207.07797v1 [cs.CV])
12. CharFormer: A Glyph Fusion based Attentive Framework for High-precision Character Image Denoising. (arXiv:2207.07798v1 [cs.CV])
13. Learning Granularity-Unified Representations for Text-to-Image Person Re-identification. (arXiv:2207.07802v1 [cs.CV])
14. Masked Spatial-Spectral Autoencoders Are Excellent Hyperspectral Defenders. (arXiv:2207.07803v1 [cs.CV])
15. Self-calibrating Photometric Stereo by Neural Inverse Rendering. (arXiv:2207.07815v1 [cs.CV])
16. Bagging Regional Classification Activation Maps for Weakly Supervised Object Localization. (arXiv:2207.07818v1 [cs.CV])
17. Cross-Domain Cross-Set Few-Shot Learning via Learning Compact and Aligned Representations. (arXiv:2207.07826v1 [cs.CV])
18. Generalizable Memory-driven Transformer for Multivariate Long Sequence Time-series Forecasting. (arXiv:2207.07827v1 [cs.LG])
19. Structural Prior Guided Generative Adversarial Transformers for **Low-Light** Image **Enhancement**. (arXiv:2207.07828v1 [cs.CV])
20. TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval. (arXiv:2207.07852v1 [cs.CV])
21. The Lottery Ticket Hypothesis for Self-attention in Convolutional Neural Network. (arXiv:2207.07858v1 [cs.CV])
22. TransGrasp: Grasp Pose Estimation of a Category of Objects by Transferring Grasps from Only One Labeled Instance. (arXiv:2207.07861v1 [cs.RO])
23. Automatic dataset generation for specific object detection. (arXiv:2207.07867v1 [cs.CV])
24. CLOSE: Curriculum Learning On the Sharing Extent Towards Better One-shot NAS. (arXiv:2207.07868v1 [cs.CV])
25. CA-SpaceNet: Counterfactual Analysis for 6D Pose Estimation in Space. (arXiv:2207.07869v1 [cs.CV])
26. NeFSAC: Neurally Filtered Minimal Samples. (arXiv:2207.07872v1 [cs.CV])
27. On the Importance of Hyperparameters and Data Augmentation for Self-Supervised Learning. (arXiv:2207.07875v1 [cs.LG])
28. Clover: Towards A Unified Video-Language Alignment and Fusion Model. (arXiv:2207.07885v1 [cs.CV])
29. You Should Look at All Objects. (arXiv:2207.07889v1 [cs.CV])
30. Multi-Modal Unsupervised Pre-Training for Surgical Operating Room Workflow Analysis. (arXiv:2207.07894v1 [cs.CV])
31. JPerceiver: Joint Perception Network for Depth, Pose and Layout Estimation in Driving Scenes. (arXiv:2207.07895v1 [cs.CV])
32. Cross Vision-RF Gait Re-identification with Low-cost RGB-D Cameras and mmWave Radars. (arXiv:2207.07896v1 [cs.CV])
33. SPSN: Superpixel Prototype Sampling Network for RGB-D Salient Object Detection. (arXiv:2207.07898v1 [cs.CV])
34. Mutual Adaptive Reasoning for Monocular 3D Multi-Person Pose Estimation. (arXiv:2207.07900v1 [cs.CV])
35. Dual-branch Hybrid Learning Network for Unbiased Scene Graph Generation. (arXiv:2207.07913v1 [cs.CV])
36. Discriminative Kernel Convolution Network for Multi-Label Ophthalmic Disease Detection on Imbalanced Fundus Image Dataset. (arXiv:2207.07918v1 [eess.IV])
37. Explainable vision transformer enabled convolutional neural network for plant disease identification: PlantXViT. (arXiv:2207.07919v1 [cs.CV])
38. CNN-based Euler's Elastica Inpainting with Deep Energy and Deep Image Prior. (arXiv:2207.07921v1 [cs.CV])
39. Learning Quality-aware Dynamic Memory for Video Object Segmentation. (arXiv:2207.07922v1 [cs.CV])
40. Towards Lightweight Super-Resolution with Dual Regression Learning. (arXiv:2207.07929v1 [cs.CV])
41. Semi-Supervised Keypoint Detector and Descriptor for Retinal Image Matching. (arXiv:2207.07932v1 [cs.CV])
42. Consistency of Implicit and Explicit Features Matters for Monocular 3D Object Detection. (arXiv:2207.07933v1 [cs.CV])
43. Stochastic Attribute Modeling for Face Super-Resolution. (arXiv:2207.07945v1 [cs.CV])
44. Level Set-Based Camera Pose Estimation From Multiple 2D/3D Ellipse-Ellipsoid Correspondences. (arXiv:2207.07953v1 [cs.CV])
45. Learn-to-Decompose: Cascaded Decomposition Network for Cross-Domain Few-Shot Facial Expression Recognition. (arXiv:2207.07973v1 [cs.CV])
46. Knowledge Guided Bidirectional Attention Network for Human-Object Interaction Detection. (arXiv:2207.07979v1 [cs.CV])
47. DiffuStereo: High Quality Human Reconstruction via Diffusion-based Stereo Using Sparse Cameras. (arXiv:2207.08000v1 [cs.CV])
48. SVGraph: Learning Semantic Graphs from Instructional Videos. (arXiv:2207.08001v1 [cs.CV])
49. SSMTL++: Revisiting Self-Supervised Multi-Task Learning for Video Anomaly Detection. (arXiv:2207.08003v1 [cs.CV])
50. Monitoring Vegetation From Space at Extremely Fine Resolutions via Coarsely-Supervised Smooth U-Net. (arXiv:2207.08022v1 [cs.CV])
51. LAVA: Language Audio Vision Alignment for Contrastive Video Pre-Training. (arXiv:2207.08024v1 [cs.CV])
52. Analysis of liver cancer detection based on image processing. (arXiv:2207.08032v1 [eess.IV])
53. Progress and limitations of deep networks to recognize objects in unusual poses. (arXiv:2207.08034v1 [cs.CV])
54. Single MR Image Super-Resolution using Generative Adversarial Network. (arXiv:2207.08036v1 [eess.IV])
55. DIMBA: Discretely Masked Black-Box Attack in Single Object Tracking. (arXiv:2207.08044v1 [cs.CV])
56. MDM:Visual Explanations for Neural Networks via Multiple Dynamic Mask. (arXiv:2207.08046v1 [cs.CV])
57. SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery. (arXiv:2207.08051v1 [cs.CV])
58. Detecting Humans in RGB-D Data with CNNs. (arXiv:2207.08064v1 [cs.CV])
59. Effect of Instance Normalization on Fine-Grained Control for Sketch-Based Face Image Generation. (arXiv:2207.08072v1 [cs.CV])
60. Performance degradation of ImageNet trained models by simple image transformations. (arXiv:2207.08079v1 [cs.CV])
61. Neural Color Operators for Sequential Image Retouching. (arXiv:2207.08080v1 [cs.CV])
62. CATRE: Iterative Point Clouds Alignment for Category-level Object Pose Refinement. (arXiv:2207.08082v1 [cs.CV])
63. Threat Model-Agnostic Adversarial Defense using Diffusion Models. (arXiv:2207.08089v1 [cs.CV])
64. Learning from Temporal Spatial Cubism for Cross-Dataset Skeleton-based Action Recognition. (arXiv:2207.08095v1 [cs.CV])
65. BCS-Net: Boundary, Context and Semantic for Automatic COVID-19 Lung Infection Segmentation from CT Images. (arXiv:2207.08114v1 [eess.IV])
66. FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation. (arXiv:2207.08119v1 [eess.IV])
67. Source-free Unsupervised Domain Adaptation for Blind Image Quality Assessment. (arXiv:2207.08124v1 [cs.CV])
68. E-NeRV: Expedite Neural Video Representation with Disentangled Spatial-Temporal Context. (arXiv:2207.08132v1 [cs.CV])
69. Editing Out-of-domain GAN Inversion via Differential Activations. (arXiv:2207.08134v1 [cs.CV])
70. Deep Weakly-Supervised Learning Methods for Classification and Localization in Histology Images: A Survey. (arXiv:1909.03354v6 [cs.CV] UPDATED)
71. Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering. (arXiv:2009.09213v3 [cs.CV] UPDATED)
72. Task-Adaptive Negative Envision for Few-Shot Open-Set Recognition. (arXiv:2012.13073v3 [cs.CV] UPDATED)
73. Focal and Efficient IOU Loss for Accurate Bounding Box Regression. (arXiv:2101.08158v2 [cs.CV] UPDATED)
74. Synthesizing MR Image Contrast **Enhancement** Using 3D High-resolution ConvNets. (arXiv:2104.01592v3 [eess.IV] UPDATED)
75. CXR Segmentation by AdaIN-based Domain Adaptation and Knowledge Distillation. (arXiv:2104.05892v3 [eess.IV] UPDATED)
76. End-to-End Sequential Sampling and Reconstruction for MRI. (arXiv:2105.06460v2 [eess.IV] UPDATED)
77. Emotion Recognition in Horses with Convolutional Neural Networks. (arXiv:2105.11953v2 [cs.CV] UPDATED)
78. Language-Driven Image Style Transfer. (arXiv:2106.00178v3 [cs.CV] UPDATED)
79. Spatially Invariant Unsupervised 3D Object-Centric Learning and Scene Decomposition. (arXiv:2106.05607v3 [cs.CV] UPDATED)
80. Personalized Trajectory Prediction via Distribution Discrimination. (arXiv:2107.14204v2 [cs.CV] UPDATED)
81. AutoVideo: An Automated Video Action Recognition System. (arXiv:2108.04212v4 [cs.CV] UPDATED)
82. Blind Image Decomposition. (arXiv:2108.11364v3 [cs.CV] UPDATED)
83. Natural Synthetic Anomalies for Self-Supervised Anomaly Detection and Localization. (arXiv:2109.15222v2 [cs.CV] UPDATED)
84. Lightweight Transformer in Federated Setting for Human Activity Recognition. (arXiv:2110.00244v2 [cs.CV] UPDATED)
85. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v3 [eess.IV] UPDATED)
86. Multi-View Stereo Network with attention thin volume. (arXiv:2110.08556v2 [cs.CV] UPDATED)
87. Reachability Embeddings: Scalable Self-Supervised Representation Learning from Mobility Trajectories for Multimodal Geospatial Computer Vision. (arXiv:2110.12521v2 [cs.CV] UPDATED)
88. Authentication Attacks on Projection-based Cancelable Biometric Schemes. (arXiv:2110.15163v6 [cs.CR] UPDATED)
89. Multimodal Transformer with Variable-length Memory for Vision-and-Language Navigation. (arXiv:2111.05759v2 [cs.CV] UPDATED)
90. EMScore: Evaluating Video Captioning via Coarse-Grained and Fine-Grained Embedding Matching. (arXiv:2111.08919v2 [cs.CV] UPDATED)
91. Meta Clustering Learning for Large-scale Unsupervised Person Re-identification. (arXiv:2111.10032v3 [cs.CV] UPDATED)
92. Are Vision Transformers Robust to Patch Perturbations?. (arXiv:2111.10659v2 [cs.CV] UPDATED)
93. Semi-Supervised Vision Transformers. (arXiv:2111.11067v2 [cs.CV] UPDATED)
94. Class-agnostic Object Detection with Multi-modal Transformer. (arXiv:2111.11430v5 [cs.CV] UPDATED)
95. Efficient Video Transformers with Spatial-Temporal Token Selection. (arXiv:2111.11591v2 [cs.CV] UPDATED)
96. KTNet: Knowledge Transfer for Unpaired 3D Shape Completion. (arXiv:2111.11976v2 [cs.CV] UPDATED)
97. A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose. (arXiv:2111.12696v3 [cs.CV] UPDATED)
98. Improving the Perceptual Quality of 2D Animation Interpolation. (arXiv:2111.12792v3 [cs.CV] UPDATED)
99. Joint stereo 3D object detection and implicit surface reconstruction. (arXiv:2111.12924v2 [cs.CV] UPDATED)
100. Contrastive Vicinal Space for Unsupervised Domain Adaptation. (arXiv:2111.13353v3 [cs.CV] UPDATED)
101. GMFlow: Learning Optical Flow via Global Matching. (arXiv:2111.13680v4 [cs.CV] UPDATED)
102. AVA-AVD: Audio-Visual Speaker Diarization in the Wild. (arXiv:2111.14448v5 [cs.CV] UPDATED)
103. Semantic-Sparse Colorization Network for Deep Exemplar-based Colorization. (arXiv:2112.01335v2 [cs.CV] UPDATED)
104. 3D-Aware Semantic-Guided Generative Model for Human Synthesis. (arXiv:2112.01422v2 [cs.CV] UPDATED)
105. Adaptive Channel Encoding Transformer for Point Cloud Analysis. (arXiv:2112.02507v4 [cs.CV] UPDATED)
106. PolyphonicFormer: Unified Query Learning for Depth-aware Video Panoptic Segmentation. (arXiv:2112.02582v3 [cs.CV] UPDATED)
107. GreenPCO: An Unsupervised Lightweight Point Cloud Odometry Method. (arXiv:2112.04054v2 [cs.CV] UPDATED)
108. Transformaly -- Two (Feature Spaces) Are Better Than One. (arXiv:2112.04185v2 [cs.CV] UPDATED)
109. Marine Bubble Flow Quantification Using Wide-Baseline Stereo Photogrammetry. (arXiv:2112.07414v3 [cs.CV] UPDATED)
110. AFDetV2: Rethinking the Necessity of the Second Stage for Object Detection from Point Clouds. (arXiv:2112.09205v2 [cs.CV] UPDATED)
111. Contrastive Vision-Language Pre-training with Limited Resources. (arXiv:2112.09331v3 [cs.CV] UPDATED)
112. Efficient Visual Tracking with Exemplar Transformers. (arXiv:2112.09686v3 [cs.CV] UPDATED)
113. iSegFormer: Interactive Segmentation via Transformers with Application to 3D Knee MR Images. (arXiv:2112.11325v6 [cs.CV] UPDATED)
114. IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages. (arXiv:2201.11732v2 [cs.CL] UPDATED)
115. FedMed-ATL: Misaligned Unpaired Brain Image Synthesis via Affine Transform Loss. (arXiv:2201.12589v3 [eess.IV] UPDATED)
116. MINER: Multiscale Implicit Neural Representations. (arXiv:2202.03532v2 [cs.CV] UPDATED)
117. NIMBLE: A Non-rigid Hand Model with Bones and Muscles. (arXiv:2202.04533v5 [cs.CV] UPDATED)
118. Graph Neural Network for Cell Tracking in Microscopy Videos. (arXiv:2202.04731v2 [cs.CV] UPDATED)
119. FILM: Frame Interpolation for Large Motion. (arXiv:2202.04901v4 [cs.CV] UPDATED)
120. D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v4 [cs.CV] UPDATED)
121. Universal Adversarial Examples in Remote Sensing: Methodology and Benchmark. (arXiv:2202.07054v3 [cs.CV] UPDATED)
122. ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification. (arXiv:2202.07570v3 [cs.CV] UPDATED)
123. V2X-Sim: Multi-Agent Collaborative Perception Dataset and Benchmark for Autonomous Driving. (arXiv:2202.08449v2 [cs.CV] UPDATED)
124. A Survey of Vision-Language Pre-Trained Models. (arXiv:2202.10936v2 [cs.CV] UPDATED)
125. GroupViT: Semantic Segmentation Emerges from Text Supervision. (arXiv:2202.11094v5 [cs.CV] UPDATED)
126. LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras with Negative Plane. (arXiv:2202.12613v3 [cs.CV] UPDATED)
127. Discriminability-Transferability Trade-Off: An Information-Theoretic Perspective. (arXiv:2203.03871v2 [cs.CV] UPDATED)
128. GaitEdge: Beyond Plain End-to-end Gait Recognition for Better Practicality. (arXiv:2203.03972v2 [cs.CV] UPDATED)
129. Backbone is All Your Need: A Simplified Architecture for Visual Object Tracking. (arXiv:2203.05328v2 [cs.CV] UPDATED)
130. Prediction-Guided Distillation for Dense Object Detection. (arXiv:2203.05469v2 [cs.CV] UPDATED)
131. VPFusion: Joint 3D Volume and Pixel-Aligned Feature Fusion for Single and Multi-view 3D Reconstruction. (arXiv:2203.07553v2 [cs.CV] UPDATED)
132. Inverted Pyramid Multi-task Transformer for Dense Scene Understanding. (arXiv:2203.07997v2 [cs.CV] UPDATED)
133. Perspective Flow Aggregation for Data-Limited 6D Object Pose Estimation. (arXiv:2203.09836v2 [cs.CV] UPDATED)
134. FAR: Fourier Aerial Video Recognition. (arXiv:2203.10694v2 [cs.CV] UPDATED)
135. Compression of Generative Pre-trained Language Models via Quantization. (arXiv:2203.10705v2 [cs.CL] UPDATED)
136. ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer. (arXiv:2203.10790v2 [cs.CV] UPDATED)
137. Making Heads or Tails: Towards Semantically Consistent Visual Counterfactuals. (arXiv:2203.12892v2 [cs.CV] UPDATED)
138. A Perturbation-Constrained Adversarial Attack for Evaluating the Robustness of Optical Flow. (arXiv:2203.13214v2 [cs.CV] UPDATED)
139. PromptDet: Towards Open-vocabulary Detection using Uncurated Images. (arXiv:2203.16513v2 [cs.CV] UPDATED)
140. Point Scene Understanding via Disentangled Instance Mesh Reconstruction. (arXiv:2203.16832v2 [cs.CV] UPDATED)
141. Learning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining. (arXiv:2204.02393v2 [cs.CV] UPDATED)
142. BMD: A General Class-balanced Multicentric Dynamic Prototype Strategy for Source-free Domain Adaptation. (arXiv:2204.02811v2 [cs.CV] UPDATED)
143. ChildCI Framework: Analysis of Motor and Cognitive Development in Children-Computer Interaction for Age Detection. (arXiv:2204.04236v2 [cs.HC] UPDATED)
144. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v9 [cs.CV] UPDATED)
145. Two Decades of Colorization and Decolorization for Images and Videos. (arXiv:2204.13322v2 [cs.CV] UPDATED)
146. An Overview of Color Transfer and Style Transfer for Images and Videos. (arXiv:2204.13339v2 [cs.CV] UPDATED)
147. Learning to Retrieve Videos by Asking Questions. (arXiv:2205.05739v3 [cs.CV] UPDATED)
148. Self-mentoring: a new deep learning pipeline to train a self-supervised U-net for few-shot learning of bio-artificial capsule segmentation. (arXiv:2205.10840v2 [cs.CV] UPDATED)
149. SelfReformer: Self-Refined Network with Transformer for Salient Object Detection. (arXiv:2205.11283v4 [cs.CV] UPDATED)
150. Multi-Task Learning with Multi-Query Transformer for Dense Prediction. (arXiv:2205.14354v3 [cs.CV] UPDATED)
151. Co-Training for Unsupervised Domain Adaptation of Semantic Segmentation Models. (arXiv:2205.15781v2 [cs.CV] UPDATED)
152. Learning Invariant Visual Representations for Compositional Zero-Shot Learning. (arXiv:2206.00415v3 [cs.CV] UPDATED)
153. Turning a Curse Into a Blessing: Enabling Clean-Data-Free Defenses by Model Inversion. (arXiv:2206.07018v2 [cs.CV] UPDATED)
154. GAN2X: Non-Lambertian Inverse Rendering of Image GANs. (arXiv:2206.09244v2 [cs.CV] UPDATED)
155. GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles. (arXiv:2206.10255v3 [eess.SY] UPDATED)
156. SearchMorph:Multi-scale Correlation Iterative Network for Deformable Registration. (arXiv:2206.13076v3 [cs.CV] UPDATED)
157. CAM/CAD Point Cloud Part Segmentation via Few-Shot Learning. (arXiv:2207.01218v2 [eess.IV] UPDATED)
158. Embedding contrastive unsupervised features to cluster in- and out-of-distribution noise in corrupted image datasets. (arXiv:2207.01573v2 [cs.CV] UPDATED)
159. Network Binarization via Contrastive Learning. (arXiv:2207.02970v3 [cs.CV] UPDATED)
160. The Power of Transfer Learning in Agricultural Applications: AgriNet. (arXiv:2207.03881v2 [cs.CV] UPDATED)
161. CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical Expression Recognition. (arXiv:2207.04410v2 [cs.CV] UPDATED)
162. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v2 [cs.AI] UPDATED)
163. Exploring Contextual Relationships for Cervical Abnormal Cell Detection. (arXiv:2207.04693v2 [cs.CV] UPDATED)
164. CCPL: Contrastive Coherence Preserving Loss for Versatile Style Transfer. (arXiv:2207.04808v3 [cs.CV] UPDATED)
165. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v2 [cs.CV] UPDATED)
166. Video Graph Transformer for Video Question Answering. (arXiv:2207.05342v2 [cs.CV] UPDATED)
167. Compound Prototype Matching for Few-shot Action Recognition. (arXiv:2207.05515v2 [cs.CV] UPDATED)
168. MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing. (arXiv:2207.05621v2 [cs.CV] UPDATED)
169. A new database of Houma Alliance Book ancient handwritten characters and its baseline algorithm. (arXiv:2207.05993v2 [cs.CV] UPDATED)
170. Eliminating Gradient Conflict in Reference-based Line-Art Colorization. (arXiv:2207.06095v2 [cs.CV] UPDATED)
171. DynaST: Dynamic Sparse Transformer for Exemplar-Guided Image Generation. (arXiv:2207.06124v2 [cs.CV] UPDATED)
172. Organic Priors in Non-Rigid Structure from Motion. (arXiv:2207.06262v3 [cs.CV] UPDATED)
173. PyMAF-X: Towards Well-aligned Full-body Model Regression from Monocular Images. (arXiv:2207.06400v2 [cs.CV] UPDATED)
174. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v2 [eess.IV] UPDATED)
175. Lipschitz Continuity Retained Binary Neural Network. (arXiv:2207.06540v2 [cs.LG] UPDATED)
176. DEXTER: An end-to-end system to extract table contents from electronic medical health documents. (arXiv:2207.06823v2 [cs.CV] UPDATED)
177. Convolutional Bypasses Are Better Vision Transformer Adapters. (arXiv:2207.07039v2 [cs.CV] UPDATED)
178. Towards Grand Unification of Object Tracking. (arXiv:2207.07078v2 [cs.CV] UPDATED)
179. XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model. (arXiv:2207.07115v2 [cs.CV] UPDATED)
180. Decoupling Recognition from Detection: Single Shot Self-Reliant Scene Text Spotter. (arXiv:2207.07253v2 [cs.CV] UPDATED)
181. Privacy-Preserving Face Recognition with Learnable Privacy Budgets in Frequency Domain. (arXiv:2207.07316v2 [cs.CV] UPDATED)
182. 3D Instances as 1D Kernels. (arXiv:2207.07372v2 [cs.CV] UPDATED)
183. ST-P3: End-to-end Vision-based Autonomous Driving via Spatial-Temporal Feature Learning. (arXiv:2207.07601v2 [cs.CV] UPDATED)
## eess.IV
---
**51** new papers in eess.IV:-) 
1. Localisation And Imaging Methods for Moving Target Ghost Imaging Radar Based On Correlation Intensity Weighting. (arXiv:2207.07649v1 [eess.IV])
2. Untrained, physics-informed neural networks for structured illumination microscopy. (arXiv:2207.07705v1 [eess.IV])
3. ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video. (arXiv:2207.07759v1 [eess.IV])
4. Structural Prior Guided Generative Adversarial Transformers for **Low-Light** Image **Enhancement**. (arXiv:2207.07828v1 [cs.CV])
5. Adaptive t-vMF Dice Loss for Multi-class Medical Image Segmentation. (arXiv:2207.07842v1 [eess.IV])
6. Automatic dataset generation for specific object detection. (arXiv:2207.07867v1 [cs.CV])
7. Discriminative Kernel Convolution Network for Multi-Label Ophthalmic Disease Detection on Imbalanced Fundus Image Dataset. (arXiv:2207.07918v1 [eess.IV])
8. CNN-based Euler's Elastica Inpainting with Deep Energy and Deep Image Prior. (arXiv:2207.07921v1 [cs.CV])
9. Learnable Mixed-precision and Dimension Reduction Co-design for Low-storage Activation. (arXiv:2207.07931v1 [eess.IV])
10. Analysis of liver cancer detection based on image processing. (arXiv:2207.08032v1 [eess.IV])
11. Single MR Image Super-Resolution using Generative Adversarial Network. (arXiv:2207.08036v1 [eess.IV])
12. BCS-Net: Boundary, Context and Semantic for Automatic COVID-19 Lung Infection Segmentation from CT Images. (arXiv:2207.08114v1 [eess.IV])
13. Accelerating Magnetic Resonance Parametric Mapping Using Simultaneously Spatial Patch-based and Parametric Group-based Low-rank Tensors (SMART). (arXiv:2207.08117v1 [eess.IV])
14. FloLPIPS: A Bespoke Video Quality Metric for Frame Interpoation. (arXiv:2207.08119v1 [eess.IV])
15. Source-free Unsupervised Domain Adaptation for Blind Image Quality Assessment. (arXiv:2207.08124v1 [cs.CV])
16. INFWIDE: Image and Feature Space Wiener Deconvolution Network for Non-blind Image Deblurring in **Low-Light** Conditions. (arXiv:2207.08201v1 [cs.CV])
17. Unsupervised Medical Image Translation with Adversarial Diffusion Models. (arXiv:2207.08208v1 [eess.IV])
18. MLP-GAN for Brain Vessel Image Segmentation. (arXiv:2207.08265v1 [eess.IV])
19. MobileCodec: Neural Inter-frame Video Compression on Mobile Devices. (arXiv:2207.08338v1 [cs.CV])
20. SepLUT: Separable Image-adaptive Lookup Tables for **Real-time** Image **Enhancement**. (arXiv:2207.08351v1 [cs.CV])
21. GLEAM: Greedy Learning for Large-Scale Accelerated MRI Reconstruction. (arXiv:2207.08393v1 [eess.IV])
22. ORB-based SLAM accelerator on SoC FPGA. (arXiv:2207.08405v1 [eess.IV])
23. Multi-head Cascaded **Swin** Transformers with Attention to k-space Sampling Pattern for Accelerated MRI Reconstruction. (arXiv:2207.08412v1 [eess.IV])
24. Fully trainable Gaussian derivative convolutional layer. (arXiv:2207.08424v1 [cs.NE])
25. Segmenting white matter hyperintensities on isotropic three-dimensional Fluid Attenuated Inversion Recovery magnetic resonance images: A comparison of Deep learning tools on a Norwegian national imaging database. (arXiv:2207.08467v1 [eess.IV])
26. Neural Distributed Image Compression with Cross-Attention Feature Alignment. (arXiv:2207.08489v1 [eess.IV])
27. Study of the performance and scalablity of federated learning for medical imaging with intermittent clients. (arXiv:2207.08581v1 [cs.LG])
28. Learning Correspondency in Frequency Domain by a Latent-Space Similarity Loss for Multispectral Pansharpening. (arXiv:2207.08602v1 [eess.IV])
29. CACTUSS: Common Anatomical CT-US Space for US examinations. (arXiv:2207.08619v1 [eess.IV])
30. Enhancing **HDR** Video Compression through CNN-based Effective Bit Depth Adaptation. (arXiv:2207.08634v1 [eess.IV])
31. Quality Assessment of Image Super-Resolution: Balancing Deterministic and Statistical Fidelity. (arXiv:2207.08689v1 [cs.CV])
32. Deep Weakly-Supervised Learning Methods for Classification and Localization in Histology Images: A Survey. (arXiv:1909.03354v6 [cs.CV] UPDATED)
33. Synthesizing MR Image Contrast **Enhancement** Using 3D High-resolution ConvNets. (arXiv:2104.01592v3 [eess.IV] UPDATED)
34. CXR Segmentation by AdaIN-based Domain Adaptation and Knowledge Distillation. (arXiv:2104.05892v3 [eess.IV] UPDATED)
35. End-to-End Sequential Sampling and Reconstruction for MRI. (arXiv:2105.06460v2 [eess.IV] UPDATED)
36. AutoVideo: An Automated Video Action Recognition System. (arXiv:2108.04212v4 [cs.CV] UPDATED)
37. Blind Image Decomposition. (arXiv:2108.11364v3 [cs.CV] UPDATED)
38. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v3 [eess.IV] UPDATED)
39. Learn-Morph-Infer: a new way of solving the inverse problem for brain tumor modeling. (arXiv:2111.04090v2 [physics.med-ph] UPDATED)
40. Preserving Dense Features for Ki67 Nuclei Detection. (arXiv:2111.05482v3 [eess.IV] UPDATED)
41. Are Vision Transformers Robust to Patch Perturbations?. (arXiv:2111.10659v2 [cs.CV] UPDATED)
42. Compressed Smooth Sparse Decomposition. (arXiv:2201.07404v2 [eess.IV] UPDATED)
43. FedMed-ATL: Misaligned Unpaired Brain Image Synthesis via Affine Transform Loss. (arXiv:2201.12589v3 [eess.IV] UPDATED)
44. LF-VIO: A Visual-Inertial-Odometry Framework for Large Field-of-View Cameras with Negative Plane. (arXiv:2202.12613v3 [cs.CV] UPDATED)
45. Compression of user generated content using denoised references. (arXiv:2203.03553v2 [eess.IV] UPDATED)
46. Contrastive Graph Learning for Population-based fMRI Classification. (arXiv:2203.14044v2 [cs.LG] UPDATED)
47. Enhancing Speckle Statistics for Imaging inside Scattering Media. (arXiv:2203.14214v2 [physics.optics] UPDATED)
48. Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review. (arXiv:2206.11233v2 [q-bio.NC] UPDATED)
49. CAM/CAD Point Cloud Part Segmentation via Few-Shot Learning. (arXiv:2207.01218v2 [eess.IV] UPDATED)
50. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v2 [cs.CV] UPDATED)
51. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v2 [eess.IV] UPDATED)
## cs.LG
---
**207** new papers in cs.LG:-) 
1. Contrastive Brain Network Learning via Hierarchical Signed Graph Pooling Model. (arXiv:2207.07650v1 [cs.LG])
2. Learning inducing points and uncertainty on molecular data. (arXiv:2207.07654v1 [physics.chem-ph])
3. FLOWGEN: Fast and slow graph generation. (arXiv:2207.07656v1 [cs.LG])
4. Strict baselines for Covid-19 forecasting and ML perspective for USA and Russia. (arXiv:2207.07689v1 [cs.LG])
5. Support Vector Machines with the Hard-Margin Loss: Optimal Training via Combinatorial Benders' Cuts. (arXiv:2207.07690v1 [cs.LG])
6. Towards Understanding Confusion and Affective States Under Communication Failures in Voice-Based Human-Machine Interaction. (arXiv:2207.07693v1 [cs.HC])
7. An Exact Bitwise Reversible Integrator. (arXiv:2207.07695v1 [cs.GR])
8. Algorithmic Determination of the Combinatorial Structure of the Linear Regions of ReLU Neural Networks. (arXiv:2207.07696v1 [cs.LG])
9. POET: Training Neural Networks on Tiny Devices with Integrated Rematerialization and Paging. (arXiv:2207.07697v1 [cs.LG])
10. Introducing Federated Learning into Internet of Things ecosystems -- preliminary considerations. (arXiv:2207.07700v1 [cs.LG])
11. Outcome-Guided Counterfactuals for Reinforcement Learning Agents from a Jointly Trained Generative Latent Space. (arXiv:2207.07710v1 [cs.AI])
12. Temporal Forward-Backward Consistency, Not Residual Error, Measures the Prediction Accuracy of Extended Dynamic Mode Decomposition. (arXiv:2207.07719v1 [eess.SY])
13. Local Approximations, Real Interpolation and Machine Learning. (arXiv:2207.07720v1 [cs.LG])
14. More Data Can Lead Us Astray: Active Data Acquisition in the Presence of Label Bias. (arXiv:2207.07723v1 [cs.LG])
15. How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition. (arXiv:2207.07730v1 [cs.LG])
16. Distributed Learning of Neural Lyapunov Functions for Large-Scale Networked Dissipative Systems. (arXiv:2207.07731v1 [eess.SY])
17. Partial Disentanglement via Mechanism Sparsity. (arXiv:2207.07732v1 [stat.ML])
18. Optimizing Data Collection in Deep Reinforcement Learning. (arXiv:2207.07736v1 [cs.LG])
19. Adversarial Focal Loss: Asking Your Discriminator for Hard Examples. (arXiv:2207.07739v1 [cs.CV])
20. HOME: High-Order Mixed-Moment-based Embedding for Representation Learning. (arXiv:2207.07743v1 [cs.LG])
21. Bootstrap State Representation using Style Transfer for Better Generalization in Deep Reinforcement Learning. (arXiv:2207.07749v1 [cs.LG])
22. Do Not Sleep on Linear Models: Simple and Interpretable Techniques Outperform Deep Learning for Sleep Scoring. (arXiv:2207.07753v1 [stat.ML])
23. Anomalous behaviour in loss-gradient based interpretability methods. (arXiv:2207.07769v1 [cs.LG])
24. Subgroup Discovery in Unstructured Data. (arXiv:2207.07781v1 [cs.LG])
25. Greykite: Deploying Flexible Forecasting at Scale at LinkedIn. (arXiv:2207.07788v1 [cs.LG])
26. BCRLSP: An Offline Reinforcement Learning Framework for Sequential Targeted Promotion. (arXiv:2207.07790v1 [cs.LG])
27. Associative Memory Based Experience Replay for Deep Reinforcement Learning. (arXiv:2207.07791v1 [cs.AR])
28. CHARM: A Hierarchical Deep Learning Model for Classification of Complex Human Activities Using Motion Sensors. (arXiv:2207.07806v1 [cs.LG])
29. A Survey on Collaborative DNN Inference for Edge Intelligence. (arXiv:2207.07812v1 [cs.DC])
30. Adaptive Sketches for Robust Regression with Importance Sampling. (arXiv:2207.07822v1 [cs.LG])
31. ChronosPerseus: Randomized Point-based Value Iteration with Importance Sampling for POSMDPs. (arXiv:2207.07825v1 [cs.AI])
32. Generalizable Memory-driven Transformer for Multivariate Long Sequence Time-series Forecasting. (arXiv:2207.07827v1 [cs.LG])
33. Approximation Capabilities of Neural Networks using Morphological Perceptrons and Generalizations. (arXiv:2207.07832v1 [cs.LG])
34. Explain Influence Maximization with Sobol Indices. (arXiv:2207.07833v1 [cs.SI])
35. Class-Incremental Lifelong Learning in Multi-Label Classification. (arXiv:2207.07840v1 [cs.LG])
36. The Lottery Ticket Hypothesis for Self-attention in Convolutional Neural Network. (arXiv:2207.07858v1 [cs.CV])
37. Deep Learning and Its Applications to WiFi Human Sensing: A Benchmark and A Tutorial. (arXiv:2207.07859v1 [cs.LG])
38. NeFSAC: Neurally Filtered Minimal Samples. (arXiv:2207.07872v1 [cs.CV])
39. Model-Aware Contrastive Learning: Towards Escaping Uniformity-Tolerance Dilemma in Training. (arXiv:2207.07874v1 [cs.LG])
40. On the Importance of Hyperparameters and Data Augmentation for Self-Supervised Learning. (arXiv:2207.07875v1 [cs.LG])
41. Neural Modal ODEs: Integrating Physics-based Modeling with Neural ODEs for Modeling High Dimensional Monitored Structures. (arXiv:2207.07883v1 [cs.LG])
42. An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2207.07886v1 [cs.AR])
43. SizeShiftReg: a Regularization Method for Improving Size-Generalization in Graph Neural Networks. (arXiv:2207.07888v1 [cs.LG])
44. Transfer learning for time series classification using synthetic data generation. (arXiv:2207.07897v1 [cs.LG])
45. Unsupervised Ensemble Based Deep Learning Approach for Attack Detection in IoT Network. (arXiv:2207.07903v1 [cs.IT])
46. Multiscale Causal Structure Learning. (arXiv:2207.07908v1 [cs.LG])
47. Improving Multi-Interest Network with Stable Learning. (arXiv:2207.07910v1 [cs.IR])
48. Few-shot bioacoustic event detection at the DCASE 2022 challenge. (arXiv:2207.07911v1 [cs.SD])
49. On Curating Responsible and Representative Healthcare Video Recommendations for Patient Education and Health Literacy: An Augmented Intelligence Approach. (arXiv:2207.07915v1 [cs.IR])
50. Efficient One Sided Kolmogorov Approximation. (arXiv:2207.07916v1 [stat.ML])
51. Chimera: A Hybrid Machine Learning Driven Multi-Objective Design Space Exploration Tool for FPGA High-Level Synthesis. (arXiv:2207.07917v1 [cs.AR])
52. CNN-based Euler's Elastica Inpainting with Deep Energy and Deep Image Prior. (arXiv:2207.07921v1 [cs.CV])
53. Quantum Noise-Induced Reservoir Computing. (arXiv:2207.07924v1 [quant-ph])
54. Learnable Mixed-precision and Dimension Reduction Co-design for Low-storage Activation. (arXiv:2207.07931v1 [eess.IV])
55. Visually-aware Acoustic Event Detection using Heterogeneous Graphs. (arXiv:2207.07935v1 [cs.SD])
56. MixTailor: Mixed Gradient Aggregation for Robust Learning Against Tailored Attacks. (arXiv:2207.07941v1 [cs.LG])
57. Kernel-based Federated Learning with Personalization. (arXiv:2207.07948v1 [stat.ML])
58. A Nearly Tight Analysis of Greedy k-means++. (arXiv:2207.07949v1 [cs.DS])
59. FastML Science Benchmarks: Accelerating Real-Time Scientific Edge Machine Learning. (arXiv:2207.07958v1 [cs.LG])
60. Certified Neural Network Watermarks with Randomized Smoothing. (arXiv:2207.07972v1 [cs.LG])
61. Online Prediction in Sub-linear Space. (arXiv:2207.07974v1 [cs.DS])
62. Signed Cumulative Distribution Transform for Parameter Estimation of 1-D Signals. (arXiv:2207.07989v1 [cs.IT])
63. EEG2Vec: Learning Affective EEG Representations via Variational Autoencoders. (arXiv:2207.08002v1 [cs.LG])
64. SSMTL++: Revisiting Self-Supervised Multi-Task Learning for Video Anomaly Detection. (arXiv:2207.08003v1 [cs.CV])
65. S4: a High-sparsity, High-performance AI Accelerator. (arXiv:2207.08006v1 [cs.AR])
66. Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v1 [cs.CL])
67. Collaborative Best Arm Identification with Limited Communication on Non-IID Data. (arXiv:2207.08015v1 [cs.LG])
68. Distance-Geometric Graph Attention Network (DG-GAT) for 3D Molecular Geometry. (arXiv:2207.08023v1 [cs.LG])
69. Rewiring Networks for Graph Neural Network Training Using Discrete Geometry. (arXiv:2207.08026v1 [stat.ML])
70. Single MR Image Super-Resolution using Generative Adversarial Network. (arXiv:2207.08036v1 [eess.IV])
71. A Singular Woodbury and Pseudo-Determinant Matrix Identities and Application to Gaussian Process Regression. (arXiv:2207.08038v1 [math.ST])
72. Reinforcement Learning For Survival: A Clinically Motivated Method For Critically Ill Patients. (arXiv:2207.08040v1 [cs.LG])
73. Personalized PCA: Decoupling Shared and Unique Features. (arXiv:2207.08041v1 [cs.LG])
74. Repairing Systematic Outliers by Learning Clean Subspaces in VAEs. (arXiv:2207.08050v1 [cs.LG])
75. Balancing Accuracy and Integrity for Reconfigurable Intelligent Surface-aided Over-the-Air Federated Learning. (arXiv:2207.08057v1 [cs.LG])
76. Subclass Knowledge Distillation with Known Subclass Labels. (arXiv:2207.08063v1 [cs.LG])
77. Performance degradation of ImageNet trained models by simple image transformations. (arXiv:2207.08079v1 [cs.CV])
78. Model-Agnostic and Diverse Explanations for Streaming Rumour Graphs. (arXiv:2207.08098v1 [cs.SI])
79. Aspect-specific Context Modeling for Aspect-based Sentiment Analysis. (arXiv:2207.08099v1 [cs.CL])
80. A Multibias-mitigated and Sentiment Knowledge Enriched Transformer for Debiasing in Multimodal Conversational Emotion Recognition. (arXiv:2207.08104v1 [cs.CL])
81. Optimal Nonparametric Inference with Two-Scale Distributional Nearest Neighbors. (arXiv:1808.08469v4 [stat.ML] UPDATED)
82. Population Predictive Checks. (arXiv:1908.00882v5 [stat.ME] UPDATED)
83. Deep Weakly-Supervised Learning Methods for Classification and Localization in Histology Images: A Survey. (arXiv:1909.03354v6 [cs.CV] UPDATED)
84. Emotion Recognition From Gait Analyses: Current Research and Future Directions. (arXiv:2003.11461v4 [cs.HC] UPDATED)
85. Federated Learning in Vehicular Networks. (arXiv:2006.01412v3 [eess.SP] UPDATED)
86. Unsupervised Discretization by Two-dimensional MDL-based Histogram. (arXiv:2006.01893v3 [cs.LG] UPDATED)
87. Identifying Causal Structure in Dynamical Systems. (arXiv:2006.03906v2 [cs.LG] UPDATED)
88. Polynomial-time algorithms for Multimarginal Optimal Transport problems with structure. (arXiv:2008.03006v4 [math.OC] UPDATED)
89. Looking Deeper into Tabular LIME. (arXiv:2008.11092v3 [stat.ML] UPDATED)
90. Dynamic Batch Learning in High-Dimensional Sparse Linear Contextual Bandits. (arXiv:2008.11918v4 [stat.ML] UPDATED)
91. MACE: A Flexible Framework for Membership Privacy Estimation in Generative Models. (arXiv:2009.05683v4 [cs.CR] UPDATED)
92. Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering. (arXiv:2009.09213v3 [cs.CV] UPDATED)
93. PRVNet: A Novel Partially-Regularized Variational Autoencoders for Massive MIMO CSI Feedback. (arXiv:2011.04178v2 [cs.NI] UPDATED)
94. Impact of signal-to-noise ratio and bandwidth on graph Laplacian spectrum from high-dimensional noisy point cloud. (arXiv:2011.10725v3 [math.ST] UPDATED)
95. Sharp Bounds on the Approximation Rates, Metric Entropy, and $n$-widths of Shallow Neural Networks. (arXiv:2101.12365v9 [stat.ML] UPDATED)
96. Efficient Online ML API Selection for Multi-Label Classification Tasks. (arXiv:2102.09127v2 [cs.LG] UPDATED)
97. Slowly Varying Regression under Sparsity. (arXiv:2102.10773v3 [cs.LG] UPDATED)
98. Mixed Variable Bayesian Optimization with Frequency Modulated Kernels. (arXiv:2102.12792v2 [stat.ML] UPDATED)
99. Local Clustering in Contextual Multi-Armed Bandits. (arXiv:2103.00063v2 [cs.LG] UPDATED)
100. Learning to Shape Rewards using a Game of Two Partners. (arXiv:2103.09159v4 [cs.LG] UPDATED)
101. Active Structure Learning of Bayesian Networks in an Observational Setting. (arXiv:2103.13796v2 [cs.LG] UPDATED)
102. CXR Segmentation by AdaIN-based Domain Adaptation and Knowledge Distillation. (arXiv:2104.05892v3 [eess.IV] UPDATED)
103. Posterior Regularization on Bayesian Hierarchical Mixture Clustering. (arXiv:2105.06903v5 [stat.ML] UPDATED)
104. Policy Mirror Descent for Regularized Reinforcement Learning: A Generalized Framework with Linear Convergence. (arXiv:2105.11066v3 [cs.LG] UPDATED)
105. Emotion Recognition in Horses with Convolutional Neural Networks. (arXiv:2105.11953v2 [cs.CV] UPDATED)
106. The Graph Cut Kernel for Ranked Data. (arXiv:2105.12356v2 [cs.LG] UPDATED)
107. Learning MDPs from Features: Predict-Then-Optimize for Sequential Decision Problems by Reinforcement Learning. (arXiv:2106.03279v4 [cs.LG] UPDATED)
108. DiffCloth: Differentiable Cloth Simulation with Dry Frictional Contact. (arXiv:2106.05306v3 [cs.GR] UPDATED)
109. Variational multiple shooting for Bayesian ODEs with Gaussian processes. (arXiv:2106.10905v3 [cs.LG] UPDATED)
110. Benchmarking Contextual Factor Generalizability in Spatiotemporal Crowd Flow Prediction. (arXiv:2106.16046v2 [cs.LG] UPDATED)
111. Secure Quantized Training for Deep Learning. (arXiv:2107.00501v2 [cs.LG] UPDATED)
112. Sublinear Regret for Learning POMDPs. (arXiv:2107.03635v4 [cs.LG] UPDATED)
113. Mediated Uncoupled Learning: Learning Functions without Direct Input-output Correspondences. (arXiv:2107.08135v2 [stat.ML] UPDATED)
114. Structured Stochastic Gradient MCMC. (arXiv:2107.09028v4 [cs.LG] UPDATED)
115. Spatio-temporal estimation of wind speed and wind power using machine learning: predictions, uncertainty and technical potential. (arXiv:2108.00859v2 [eess.SP] UPDATED)
116. BOSS: Bidirectional One-Shot Synthesis of Adversarial Examples. (arXiv:2108.02756v2 [cs.LG] UPDATED)
117. AutoVideo: An Automated Video Action Recognition System. (arXiv:2108.04212v4 [cs.CV] UPDATED)
118. Layer-wise Adaptive Graph Convolution Networks Using Generalized Pagerank. (arXiv:2108.10636v3 [cs.LG] UPDATED)
119. Approximating Pandora's Box with Correlations. (arXiv:2108.12976v2 [cs.DS] UPDATED)
120. Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v3 [cs.LG] UPDATED)
121. A robust approach for deep neural networks in presence of label noise: relabelling and filtering instances during training. (arXiv:2109.03748v4 [cs.LG] UPDATED)
122. Modeling Adversarial Noise for Adversarial Training. (arXiv:2109.09901v5 [cs.LG] UPDATED)
123. Improved optimization strategies for deep Multi-Task Networks. (arXiv:2109.11678v3 [cs.LG] UPDATED)
124. MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning. (arXiv:2109.12674v3 [cs.LG] UPDATED)
125. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v3 [eess.IV] UPDATED)
126. Large Language Models Can Be Strong Differentially Private Learners. (arXiv:2110.05679v4 [cs.LG] UPDATED)
127. On the difficulty of learning chaotic dynamics with RNNs. (arXiv:2110.07238v2 [cs.LG] UPDATED)
128. Reachability Embeddings: Scalable Self-Supervised Representation Learning from Mobility Trajectories for Multimodal Geospatial Computer Vision. (arXiv:2110.12521v2 [cs.CV] UPDATED)
129. Causal Effect Estimation using Variational Information Bottleneck. (arXiv:2110.13705v2 [cs.LG] UPDATED)
130. Tight Concentrations and Confidence Sequences from the Regret of Universal Portfolio. (arXiv:2110.14099v2 [stat.ML] UPDATED)
131. Learn-Morph-Infer: a new way of solving the inverse problem for brain tumor modeling. (arXiv:2111.04090v2 [physics.med-ph] UPDATED)
132. A compact butterfly-style silicon photonic-electronic neural chip for hardware-efficient deep learning. (arXiv:2111.06705v2 [cs.ET] UPDATED)
133. DICE: Leveraging Sparsification for Out-of-Distribution Detection. (arXiv:2111.09805v2 [cs.LG] UPDATED)
134. Self-supervised Autoregressive Domain Adaptation for Time Series Data. (arXiv:2111.14834v2 [cs.LG] UPDATED)
135. Transformaly -- Two (Feature Spaces) Are Better Than One. (arXiv:2112.04185v2 [cs.CV] UPDATED)
136. Robust Voting Rules from Algorithmic Robust Statistics. (arXiv:2112.06380v2 [cs.DS] UPDATED)
137. Amortized Noisy Channel Neural Machine Translation. (arXiv:2112.08670v2 [cs.CL] UPDATED)
138. FedNI: Federated Graph Learning with Network Inpainting for Population-Based Disease Prediction. (arXiv:2112.10166v3 [cs.LG] UPDATED)
139. Universal Online Learning with Bounded Loss: Reduction to Binary Classification. (arXiv:2112.14638v2 [cs.LG] UPDATED)
140. Emotion Intensity and its Control for Emotional Voice Conversion. (arXiv:2201.03967v3 [cs.SD] UPDATED)
141. Compressed Smooth Sparse Decomposition. (arXiv:2201.07404v2 [eess.IV] UPDATED)
142. How Expressive are Transformers in Spectral Domain for Graphs?. (arXiv:2201.09332v4 [cs.LG] UPDATED)
143. Self-supervised Graphs for Audio Representation Learning with Limited Labeled Data. (arXiv:2202.00097v2 [cs.LG] UPDATED)
144. Regret Minimization with Performative Feedback. (arXiv:2202.00628v2 [cs.LG] UPDATED)
145. Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Care Domain. (arXiv:2202.00916v2 [cs.LG] UPDATED)
146. PSO-PINN: Physics-Informed Neural Networks Trained with Particle Swarm Optimization. (arXiv:2202.01943v2 [cs.LG] UPDATED)
147. Stochastic smoothing of the top-K calibrated hinge loss for deep imbalanced classification. (arXiv:2202.02193v2 [stat.ML] UPDATED)
148. FL_PyTorch: optimization research simulator for federated learning. (arXiv:2202.03099v2 [cs.LG] UPDATED)
149. Locally Random P-adic Alloy Codes with Channel Coding Theorems for Distributed Coded Tensors. (arXiv:2202.03469v3 [cs.IT] UPDATED)
150. On characterizations of learnability with computable learners. (arXiv:2202.05041v2 [cs.LG] UPDATED)
151. Personalization Improves Privacy-Accuracy Tradeoffs in Federated Learning. (arXiv:2202.05318v2 [stat.ML] UPDATED)
152. D2ADA: Dynamic Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v4 [cs.CV] UPDATED)
153. No One Left Behind: Inclusive Federated Learning over Heterogeneous Devices. (arXiv:2202.08036v2 [cs.LG] UPDATED)
154. Cross-Silo Heterogeneous Model Federated Multitask Learning. (arXiv:2202.08603v4 [cs.LG] UPDATED)
155. Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning. (arXiv:2202.09667v2 [cs.LG] UPDATED)
156. A Survey of Vision-Language Pre-Trained Models. (arXiv:2202.10936v2 [cs.CV] UPDATED)
157. Enhancing Mechanical Metamodels with a Generative Model-Based Augmented Training Dataset. (arXiv:2203.04183v3 [cs.LG] UPDATED)
158. Prediction-Guided Distillation for Dense Object Detection. (arXiv:2203.05469v2 [cs.CV] UPDATED)
159. Practical tradeoffs between memory, compute, and performance in learned optimizers. (arXiv:2203.11860v3 [cs.LG] UPDATED)
160. Contrastive Graph Learning for Population-based fMRI Classification. (arXiv:2203.14044v2 [cs.LG] UPDATED)
161. Learning to Drive by Watching YouTube Videos: Action-Conditioned Contrastive Policy Pretraining. (arXiv:2204.02393v2 [cs.CV] UPDATED)
162. Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift. (arXiv:2204.03342v2 [cs.LG] UPDATED)
163. Neural Operator with Regularity Structure for Modeling Dynamics Driven by SPDEs. (arXiv:2204.06255v4 [cs.LG] UPDATED)
164. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v9 [cs.CV] UPDATED)
165. Ultra-marginal Feature Importance. (arXiv:2204.09938v3 [stat.ML] UPDATED)
166. Online Deep Learning from Doubly-Streaming Data. (arXiv:2204.11793v3 [cs.LG] UPDATED)
167. Model Selection, Adaptation, and Combination for Transfer Learning in Wind and Photovoltaic Power Forecasts. (arXiv:2204.13293v3 [cs.LG] UPDATED)
168. Understanding the Generalization Performance of Spectral Clustering Algorithms. (arXiv:2205.00281v2 [cs.LG] UPDATED)
169. Perspectives on Incorporating Expert Feedback into Model Updates. (arXiv:2205.06905v2 [cs.LG] UPDATED)
170. A Correlation Information-based Spatiotemporal Network for Traffic Flow Forecasting. (arXiv:2205.10365v2 [cs.LG] UPDATED)
171. Self-mentoring: a new deep learning pipeline to train a self-supervised U-net for few-shot learning of bio-artificial capsule segmentation. (arXiv:2205.10840v2 [cs.CV] UPDATED)
172. SelfReformer: Self-Refined Network with Transformer for Salient Object Detection. (arXiv:2205.11283v4 [cs.CV] UPDATED)
173. RENs: Relevance Encoding Networks. (arXiv:2205.13061v2 [cs.LG] UPDATED)
174. Counterfactual Fairness with Partially Known Causal Graph. (arXiv:2205.13972v2 [cs.LG] UPDATED)
175. Machine Learning for Microcontroller-Class Hardware -- A Review. (arXiv:2205.14550v3 [cs.LG] UPDATED)
176. Evaluation of creating scoring opportunities for teammates in soccer via trajectory prediction. (arXiv:2206.01899v2 [cs.AI] UPDATED)
177. Policy Optimization for Markov Games: Unified Framework and Faster Convergence. (arXiv:2206.02640v2 [cs.LG] UPDATED)
178. Multi-channel neural networks for predicting influenza A virus hosts and antigenic types. (arXiv:2206.03823v2 [q-bio.QM] UPDATED)
179. Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-implementation Guidelines. (arXiv:2206.03944v2 [cs.LG] UPDATED)
180. ROI-Constrained Bidding via Curriculum-Guided Bayesian Reinforcement Learning. (arXiv:2206.05240v5 [cs.LG] UPDATED)
181. **Bilateral** Dependency Optimization: Defending Against Model-inversion Attacks. (arXiv:2206.05483v3 [cs.LG] UPDATED)
182. Plotly-Resampler: Effective Visual Analytics for Large Time Series. (arXiv:2206.08703v2 [cs.HC] UPDATED)
183. Truly Unordered Probabilistic Rule Sets for Multi-class Classification. (arXiv:2206.08804v3 [cs.LG] UPDATED)
184. Automatic Autism Spectrum Disorder Detection Using Artificial Intelligence Methods with MRI Neuroimaging: A Review. (arXiv:2206.11233v2 [q-bio.NC] UPDATED)
185. Data Augmentation for Dementia Detection in Spoken Language. (arXiv:2206.12879v2 [cs.CL] UPDATED)
186. Efficient Private SCO for Heavy-Tailed Data via Clipping. (arXiv:2206.13011v3 [cs.LG] UPDATED)
187. Data-Efficient Learning via Minimizing Hyperspherical Energy. (arXiv:2206.15204v2 [cs.LG] UPDATED)
188. Denoised MDPs: Learning World Models Better Than the World Itself. (arXiv:2206.15477v3 [cs.LG] UPDATED)
189. On the Learning and Learnablity of Quasimetrics. (arXiv:2206.15478v2 [cs.LG] UPDATED)
190. WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. (arXiv:2207.01206v2 [cs.CL] UPDATED)
191. Predicting Out-of-Domain Generalization with Local Manifold Smoothness. (arXiv:2207.02093v2 [cs.LG] UPDATED)
192. Robust Counterfactual Explanations for Tree-Based Ensembles. (arXiv:2207.02739v2 [cs.LG] UPDATED)
193. Network Binarization via Contrastive Learning. (arXiv:2207.02970v3 [cs.CV] UPDATED)
194. Safe reinforcement learning for multi-energy management systems with known constraint functions. (arXiv:2207.03830v2 [eess.SY] UPDATED)
195. The Power of Transfer Learning in Agricultural Applications: AgriNet. (arXiv:2207.03881v2 [cs.CV] UPDATED)
196. Multi-Model Federated Learning with Provable Guarantees. (arXiv:2207.04330v4 [cs.LG] UPDATED)
197. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v2 [cs.AI] UPDATED)
198. Don't Start From Scratch: Leveraging Prior Data to Automate Robotic Reinforcement Learning. (arXiv:2207.04703v2 [cs.RO] UPDATED)
199. Multiple-Modality Associative Memory: a framework for Learning. (arXiv:2207.04827v2 [cs.NE] UPDATED)
200. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v3 [cs.CL] UPDATED)
201. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v2 [cs.CV] UPDATED)
202. A Benchmark dataset for predictive maintenance. (arXiv:2207.05466v3 [cs.LG] UPDATED)
203. Physics-Informed Deep Neural Operator Networks. (arXiv:2207.05748v2 [cs.LG] UPDATED)
204. On Merging Feature Engineering and Deep Learning for Diagnosis, Risk-Prediction and Age Estimation Based on the 12-Lead ECG. (arXiv:2207.06096v2 [cs.LG] UPDATED)
205. A Data-Efficient Deep Learning Framework for Segmentation and Classification of Histopathology Images. (arXiv:2207.06489v2 [eess.IV] UPDATED)
206. Lipschitz Continuity Retained Binary Neural Network. (arXiv:2207.06540v2 [cs.LG] UPDATED)
207. QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v2 [quant-ph] UPDATED)
## cs.AI
---
**90** new papers in cs.AI:-) 
1. Contrastive Brain Network Learning via Hierarchical Signed Graph Pooling Model. (arXiv:2207.07650v1 [cs.LG])
2. FLOWGEN: Fast and slow graph generation. (arXiv:2207.07656v1 [cs.LG])
3. Strict baselines for Covid-19 forecasting and ML perspective for USA and Russia. (arXiv:2207.07689v1 [cs.LG])
4. Towards Understanding Confusion and Affective States Under Communication Failures in Voice-Based Human-Machine Interaction. (arXiv:2207.07693v1 [cs.HC])
5. Outcome-Guided Counterfactuals for Reinforcement Learning Agents from a Jointly Trained Generative Latent Space. (arXiv:2207.07710v1 [cs.AI])
6. How to Reuse and Compose Knowledge for a Lifetime of Tasks: A Survey on Continual Learning and Functional Composition. (arXiv:2207.07730v1 [cs.LG])
7. COEM: Cross-Modal Embedding for MetaCell Identification. (arXiv:2207.07734v1 [q-bio.GN])
8. A Comprehensive Survey on the Cyber-Security of Smart Grids: Cyber-Attacks, Detection, Countermeasure Techniques, and Future Directions. (arXiv:2207.07738v1 [cs.CR])
9. Knowledge Representation in Digital Agriculture: A Step Towards Standardised Model. (arXiv:2207.07740v1 [cs.AI])
10. HOME: High-Order Mixed-Moment-based Embedding for Representation Learning. (arXiv:2207.07743v1 [cs.LG])
11. Bootstrap State Representation using Style Transfer for Better Generalization in Deep Reinforcement Learning. (arXiv:2207.07749v1 [cs.LG])
12. Do Not Sleep on Linear Models: Simple and Interpretable Techniques Outperform Deep Learning for Sleep Scoring. (arXiv:2207.07753v1 [stat.ML])
13. Anomalous behaviour in loss-gradient based interpretability methods. (arXiv:2207.07769v1 [cs.LG])
14. Segment-level Metric Learning for Few-shot Bioacoustic Event Detection. (arXiv:2207.07773v1 [eess.AS])
15. CARBEN: Composite Adversarial Robustness Benchmark. (arXiv:2207.07797v1 [cs.CV])
16. Autonomously Untangling Long Cables. (arXiv:2207.07813v1 [cs.RO])
17. ChronosPerseus: Randomized Point-based Value Iteration with Importance Sampling for POSMDPs. (arXiv:2207.07825v1 [cs.AI])
18. Class-Incremental Lifelong Learning in Multi-Label Classification. (arXiv:2207.07840v1 [cs.LG])
19. The Lottery Ticket Hypothesis for Self-attention in Convolutional Neural Network. (arXiv:2207.07858v1 [cs.CV])
20. Deep Learning and Its Applications to WiFi Human Sensing: A Benchmark and A Tutorial. (arXiv:2207.07859v1 [cs.LG])
21. On the Importance of Hyperparameters and Data Augmentation for Self-Supervised Learning. (arXiv:2207.07875v1 [cs.LG])
22. An Experimental Evaluation of Machine Learning Training on a Real Processing-in-Memory System. (arXiv:2207.07886v1 [cs.AR])
23. Mutual Adaptive Reasoning for Monocular 3D Multi-Person Pose Estimation. (arXiv:2207.07900v1 [cs.CV])
24. Improving Multi-Interest Network with Stable Learning. (arXiv:2207.07910v1 [cs.IR])
25. On Curating Responsible and Representative Healthcare Video Recommendations for Patient Education and Health Literacy: An Augmented Intelligence Approach. (arXiv:2207.07915v1 [cs.IR])
26. Efficient One Sided Kolmogorov Approximation. (arXiv:2207.07916v1 [stat.ML])
27. Physics Embedded Neural Network Vehicle Model and Applications in Risk-Aware Autonomous Driving Using Latent Features. (arXiv:2207.07920v1 [cs.RO])
28. A Survey of Decision Making in Adversarial Games. (arXiv:2207.07971v1 [cs.GT])
29. Indivisible Participatory Budgeting under Weak Rankings. (arXiv:2207.07981v1 [cs.GT])
30. Characterization of Group-Fair Social Choice Rules under Single-Peaked Preferences. (arXiv:2207.07984v1 [cs.GT])
31. EEG2Vec: Learning Affective EEG Representations via Variational Autoencoders. (arXiv:2207.08002v1 [cs.LG])
32. Monitoring Vegetation From Space at Extremely Fine Resolutions via Coarsely-Supervised Smooth U-Net. (arXiv:2207.08022v1 [cs.CV])
33. Data Representativeness in Accessibility Datasets: A Meta-Analysis. (arXiv:2207.08037v1 [cs.HC])
34. SatMAE: Pre-training Transformers for Temporal and Multi-Spectral Satellite Imagery. (arXiv:2207.08051v1 [cs.CV])
35. Toward Efficient Task Planning for Dual-Arm Tabletop Object Rearrangement. (arXiv:2207.08078v1 [cs.RO])
36. Threat Model-Agnostic Adversarial Defense using Diffusion Models. (arXiv:2207.08089v1 [cs.CV])
37. Nonmyopic Distilled Data Association Belief Space Planning Under Budget Constraints. (arXiv:2207.08096v1 [cs.AI])
38. Model-Agnostic and Diverse Explanations for Streaming Rumour Graphs. (arXiv:2207.08098v1 [cs.SI])
39. Discover Life Skills for Planning with Bandits via Observing and Learning How the World Works. (arXiv:2207.08130v1 [cs.AI])
40. ProjectionPathExplorer: Exploring Visual Patterns in Projected Decision-Making Paths. (arXiv:2001.08372v3 [cs.AI] UPDATED)
41. Verifying Tight Logic Programs with anthem and Vampire. (arXiv:2008.02025v5 [cs.LO] UPDATED)
42. Looking Deeper into Tabular LIME. (arXiv:2008.11092v3 [stat.ML] UPDATED)
43. Efficient Online ML API Selection for Multi-Label Classification Tasks. (arXiv:2102.09127v2 [cs.LG] UPDATED)
44. Learning to Shape Rewards using a Game of Two Partners. (arXiv:2103.09159v4 [cs.LG] UPDATED)
45. Posterior Regularization on Bayesian Hierarchical Mixture Clustering. (arXiv:2105.06903v5 [stat.ML] UPDATED)
46. Convex Combination Belief Propagation Algorithms. (arXiv:2105.12815v2 [cs.AI] UPDATED)
47. Benchmarking Contextual Factor Generalizability in Spatiotemporal Crowd Flow Prediction. (arXiv:2106.16046v2 [cs.LG] UPDATED)
48. Spatio-temporal estimation of wind speed and wind power using machine learning: predictions, uncertainty and technical potential. (arXiv:2108.00859v2 [eess.SP] UPDATED)
49. Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v3 [cs.LG] UPDATED)
50. Improved optimization strategies for deep Multi-Task Networks. (arXiv:2109.11678v3 [cs.LG] UPDATED)
51. Lightweight Transformer in Federated Setting for Human Activity Recognition. (arXiv:2110.00244v2 [cs.CV] UPDATED)
52. Belief Evolution Network-based Probability Transformation and Fusion. (arXiv:2110.03468v2 [cs.AI] UPDATED)
53. Score-based diffusion models for accelerated MRI. (arXiv:2110.05243v3 [eess.IV] UPDATED)
54. Reachability Embeddings: Scalable Self-Supervised Representation Learning from Mobility Trajectories for Multimodal Geospatial Computer Vision. (arXiv:2110.12521v2 [cs.CV] UPDATED)
55. A Lightweight Graph Transformer Network for Human Mesh Reconstruction from 2D Human Pose. (arXiv:2111.12696v3 [cs.CV] UPDATED)
56. Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Care Domain. (arXiv:2202.00916v2 [cs.LG] UPDATED)
57. FL_PyTorch: optimization research simulator for federated learning. (arXiv:2202.03099v2 [cs.LG] UPDATED)
58. D2A-BSP: Distilled Data Association Belief Space Planning with Performance Guarantees Under Budget Constraints. (arXiv:2202.04954v2 [cs.AI] UPDATED)
59. Learning physics-informed simulation models for soft robotic manipulation: A case study with dielectric elastomer actuators. (arXiv:2202.12977v2 [cs.RO] UPDATED)
60. Pareto Frontier Approximation Network (PA-Net) to Solve Bi-objective TSP. (arXiv:2203.01298v3 [cs.RO] UPDATED)
61. Discriminability-Transferability Trade-Off: An Information-Theoretic Perspective. (arXiv:2203.03871v2 [cs.CV] UPDATED)
62. PALI-NLP at SemEval-2022 Task 4: Discriminative Fine-tuning of Transformers for Patronizing and Condescending Language Detection. (arXiv:2203.04616v2 [cs.CL] UPDATED)
63. Agile Maneuvers in Legged Robots: a Predictive Control Approach. (arXiv:2203.07554v2 [cs.RO] UPDATED)
64. ScalableViT: Rethinking the Context-oriented Generalization of Vision Transformer. (arXiv:2203.10790v2 [cs.CV] UPDATED)
65. Domain Adaptation for Time-Series Classification to Mitigate Covariate Shift. (arXiv:2204.03342v2 [cs.LG] UPDATED)
66. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v9 [cs.CV] UPDATED)
67. Model Selection, Adaptation, and Combination for Transfer Learning in Wind and Photovoltaic Power Forecasts. (arXiv:2204.13293v3 [cs.LG] UPDATED)
68. Interpretable collective intelligence of non-rational human agents. (arXiv:2204.13424v2 [cs.GT] UPDATED)
69. Learning to Retrieve Videos by Asking Questions. (arXiv:2205.05739v3 [cs.CV] UPDATED)
70. A Correlation Information-based Spatiotemporal Network for Traffic Flow Forecasting. (arXiv:2205.10365v2 [cs.LG] UPDATED)
71. Open Arms: Open-Source Arms, Hands & Control. (arXiv:2205.12992v2 [cs.RO] UPDATED)
72. Evaluation of creating scoring opportunities for teammates in soccer via trajectory prediction. (arXiv:2206.01899v2 [cs.AI] UPDATED)
73. Designing Reinforcement Learning Algorithms for Digital Interventions: Pre-implementation Guidelines. (arXiv:2206.03944v2 [cs.LG] UPDATED)
74. ROI-Constrained Bidding via Curriculum-Guided Bayesian Reinforcement Learning. (arXiv:2206.05240v5 [cs.LG] UPDATED)
75. Human Mobility Prediction with Causal and Spatial-constrained Multi-task Network. (arXiv:2206.05731v2 [cs.AI] UPDATED)
76. WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents. (arXiv:2207.01206v2 [cs.CL] UPDATED)
77. CAM/CAD Point Cloud Part Segmentation via Few-Shot Learning. (arXiv:2207.01218v2 [eess.IV] UPDATED)
78. Robust Counterfactual Explanations for Tree-Based Ensembles. (arXiv:2207.02739v2 [cs.LG] UPDATED)
79. Finite-rate sparse quantum codes aplenty. (arXiv:2207.03562v2 [quant-ph] UPDATED)
80. Safe reinforcement learning for multi-energy management systems with known constraint functions. (arXiv:2207.03830v2 [eess.SY] UPDATED)
81. Sequential Manipulation Planning on Scene Graph. (arXiv:2207.04364v4 [cs.RO] UPDATED)
82. On the Principles of Parsimony and Self-Consistency for the Emergence of Intelligence. (arXiv:2207.04630v2 [cs.AI] UPDATED)
83. Multiple-Modality Associative Memory: a framework for Learning. (arXiv:2207.04827v2 [cs.NE] UPDATED)
84. Knowledge Graph Induction enabling Recommending and Trend Analysis: A Corporate Research Community Use Case. (arXiv:2207.05188v2 [cs.AI] UPDATED)
85. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v3 [cs.CL] UPDATED)
86. A Benchmark dataset for predictive maintenance. (arXiv:2207.05466v3 [cs.LG] UPDATED)
87. A new database of Houma Alliance Book ancient handwritten characters and its baseline algorithm. (arXiv:2207.05993v2 [cs.CV] UPDATED)
88. Stochastic Market Games. (arXiv:2207.07388v2 [cs.MA] UPDATED)
89. Continual Learning For On-Device Environmental Sound Classification. (arXiv:2207.07429v2 [cs.SD] UPDATED)
90. QSAN: A Near-term Achievable Quantum Self-Attention Network. (arXiv:2207.07563v2 [quant-ph] UPDATED)

