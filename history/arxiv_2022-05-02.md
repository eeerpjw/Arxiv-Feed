# Your interest papers
---
## cs.CV
---
### One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation. (arXiv:2204.13738v1 [eess.IV])
- Authors : Jiang Liu, Srivathsa Pasumarthi, Ben Duffy, Enhao Gong, Greg Zaharchuk, Keshav Datta
- Link : [http://arxiv.org/abs/2204.13738](http://arxiv.org/abs/2204.13738)
> ABSTRACT  :  Multi-contrast magnetic resonance imaging (MRI) is widely used in clinical practice as each contrast provides complementary information. However, the availability of each contrast may vary amongst patients in reality. This poses challenges to both radiologists and automated image analysis algorithms. A general approach for tackling this problem is missing data imputation, which aims to synthesize the missing contrasts from existing ones. While several convolutional neural network (CNN) based algorithms have been proposed, they suffer from the fundamental limitations of CNN models, such as requirement for fixed numbers of input and output channels, inability to capture long-range dependencies, and lack of interpretability. In this paper, we formulate missing data imputation as a sequence-to-sequence learning problem and propose a multi-contrast multi-scale Transformer (MMT), which can take any subset of input contrasts and synthesize those that are missing. MMT consists of a multi-scale Transformer encoder that builds hierarchical representations of inputs combined with a multi-scale Transformer decoder that generates the outputs in a coarse-to-fine fashion. Thanks to the proposed multi-contrast **Swin** Transformer blocks, it can efficiently capture intra- and inter-contrast dependencies for accurate image synthesis. Moreover, MMT is inherently interpretable. It allows us to understand the importance of each input contrast in different regions by analyzing the in-built attention maps of Transformer blocks in the decoder. Extensive experiments on two large-scale multi-contrast MRI datasets demonstrate that MMT outperforms the state-of-the-art methods quantitatively and qualitatively.  
### SideRT: A **Real-time** Pure Transformer Architecture for Single Image Depth Estimation. (arXiv:2204.13892v1 [cs.CV])
- Authors : Chang Shu, Ziming Chen, Lei Chen, Kuan Ma, Minghui Wang, Haibing Ren
- Link : [http://arxiv.org/abs/2204.13892](http://arxiv.org/abs/2204.13892)
> ABSTRACT  :  Since context modeling is critical for estimating depth from a single image, researchers put tremendous effort into obtaining global context. Many global manipulations are designed for traditional CNN-based architectures to overcome the locality of convolutions. Attention mechanisms or transformers originally designed for capturing long-range dependencies might be a better choice, but usually complicates architectures and could lead to a decrease in inference speed. In this work, we propose a pure transformer architecture called SideRT that can attain excellent predictions in real-time. In order to capture better global context, Cross-Scale Attention (CSA) and Multi-Scale Refinement (MSR) modules are designed to work collaboratively to fuse features of different scales efficiently. CSA modules focus on fusing features of high semantic similarities, while MSR modules aim to fuse features at corresponding positions. These two modules contain a few learnable parameters without convolutions, based on which a lightweight yet effective model is built. This architecture achieves state-of-the-art performances in real-time (51.3 FPS) and becomes much faster with a reasonable performance drop on a smaller backbone **Swin**-T (83.1 FPS). Furthermore, its performance surpasses the previous state-of-the-art by a large margin, improving AbsRel metric 6.9% on KITTI and 9.7% on NYU. To the best of our knowledge, this is the first work to show that transformer-based networks can attain state-of-the-art performance in real-time in the single image depth estimation field. Code will be made available soon.  
### AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on **Real-time** Image **Enhancement**. (arXiv:2204.13983v1 [cs.CV])
- Authors : Canqian Yang, Meiguang Jin, Xu Jia, Yi Xu, Ying Chen
- Link : [http://arxiv.org/abs/2204.13983](http://arxiv.org/abs/2204.13983)
> ABSTRACT  :  The 3D Lookup Table (3D LUT) is a highly-efficient tool for real-time image **enhancement** tasks, which models a non-linear 3D color transform by sparsely sampling it into a discretized 3D lattice. Previous works have made efforts to learn image-adaptive output color values of LUTs for flexible **enhancement** but neglect the importance of sampling strategy. They adopt a sub-optimal uniform sampling point allocation, limiting the expressiveness of the learned LUTs since the (tri-)linear interpolation between uniform sampling points in the LUT transform might fail to model local non-linearities of the color transform. Focusing on this problem, we present AdaInt (Adaptive Intervals Learning), a novel mechanism to achieve a more flexible sampling point allocation by adaptively learning the non-uniform sampling intervals in the 3D color space. In this way, a 3D LUT can increase its capability by conducting dense sampling in color ranges requiring highly non-linear transforms and sparse sampling for near-linear transforms. The proposed AdaInt could be implemented as a compact and efficient plug-and-play module for a 3D LUT-based method. To enable the end-to-end learning of AdaInt, we design a novel differentiable operator called AiLUT-Transform (Adaptive Interval LUT Transform) to locate input colors in the non-uniform 3D LUT and provide gradients to the sampling intervals. Experiments demonstrate that methods equipped with AdaInt can achieve state-of-the-art performance on two public benchmark datasets with a negligible overhead increase. Our source code is available at https://github.com/ImCharlesY/AdaInt.  
### RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
- Authors : Xiangyu Gao, Guanbin Xing, Sumit Roy, Hui Liu
- Link : [http://arxiv.org/abs/2011.08981](http://arxiv.org/abs/2011.08981)
> ABSTRACT  :  Millimeter-wave radars are being increasingly integrated into commercial vehicles to support new advanced driver-assistance systems by enabling robust and high-performance object detection, localization, as well as recognition - a key component of new environmental perception. In this paper, we propose a novel radar multiple-perspectives convolutional neural network (RAMP-CNN) that extracts the location and class of objects based on further processing of the range-velocity-angle (RVA) heatmap sequences. To bypass the complexity of 4D convolutional neural networks (NN), we propose to combine several lower-dimension NN models within our RAMP-CNN model that nonetheless approaches the performance upper-bound with lower complexity. The extensive experiments show that the proposed RAMP-CNN model achieves better average recall and average precision than prior works in all testing scenarios. Besides, the RAMP-CNN model is validated to work robustly under **night**time, which enables low-cost radars as a potential substitute for pure optical sensing under severe conditions.  
## eess.IV
---
### One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation. (arXiv:2204.13738v1 [eess.IV])
- Authors : Jiang Liu, Srivathsa Pasumarthi, Ben Duffy, Enhao Gong, Greg Zaharchuk, Keshav Datta
- Link : [http://arxiv.org/abs/2204.13738](http://arxiv.org/abs/2204.13738)
> ABSTRACT  :  Multi-contrast magnetic resonance imaging (MRI) is widely used in clinical practice as each contrast provides complementary information. However, the availability of each contrast may vary amongst patients in reality. This poses challenges to both radiologists and automated image analysis algorithms. A general approach for tackling this problem is missing data imputation, which aims to synthesize the missing contrasts from existing ones. While several convolutional neural network (CNN) based algorithms have been proposed, they suffer from the fundamental limitations of CNN models, such as requirement for fixed numbers of input and output channels, inability to capture long-range dependencies, and lack of interpretability. In this paper, we formulate missing data imputation as a sequence-to-sequence learning problem and propose a multi-contrast multi-scale Transformer (MMT), which can take any subset of input contrasts and synthesize those that are missing. MMT consists of a multi-scale Transformer encoder that builds hierarchical representations of inputs combined with a multi-scale Transformer decoder that generates the outputs in a coarse-to-fine fashion. Thanks to the proposed multi-contrast **Swin** Transformer blocks, it can efficiently capture intra- and inter-contrast dependencies for accurate image synthesis. Moreover, MMT is inherently interpretable. It allows us to understand the importance of each input contrast in different regions by analyzing the in-built attention maps of Transformer blocks in the decoder. Extensive experiments on two large-scale multi-contrast MRI datasets demonstrate that MMT outperforms the state-of-the-art methods quantitatively and qualitatively.  
### Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent. (arXiv:2204.13940v1 [eess.IV])
- Authors : Rita Fermanian, Mikael Le, Christine Guillemot
- Link : [http://arxiv.org/abs/2204.13940](http://arxiv.org/abs/2204.13940)
> ABSTRACT  :  The Plug-and-Play (PnP) framework allows integrating advanced image denoising priors into optimization algorithms, to efficiently solve a variety of image **restoration** tasks. The Plug-and-Play alternating direction method of multipliers (ADMM) and the Regularization by Denoising (RED) algorithms are two examples of such methods that made a breakthrough in image **restoration**. However, while the former method only applies to proximal algorithms, it has recently been shown that there exists no regularization that explains the RED algorithm when the denoisers lack Jacobian symmetry, which happen to be the case of most practical denoisers. To the best of our knowledge, there exists no method for training a network that directly represents the gradient of a regularizer, which can be directly used in Plug-and-Play gradient-based algorithms. We show that it is possible to train a denoiser along with a network that corresponds to the gradient of its regularizer. We use this gradient of the regularizer in gradient-based optimization methods and obtain better results comparing to other generic Plug-and-Play approaches. We also show that the regularizer can be used as a pre-trained network for unrolled gradient descent. Lastly, we show that the resulting denoiser allows for a quick convergence of the Plug-and-Play ADMM.  
## cs.LG
---
### Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent. (arXiv:2204.13940v1 [eess.IV])
- Authors : Rita Fermanian, Mikael Le, Christine Guillemot
- Link : [http://arxiv.org/abs/2204.13940](http://arxiv.org/abs/2204.13940)
> ABSTRACT  :  The Plug-and-Play (PnP) framework allows integrating advanced image denoising priors into optimization algorithms, to efficiently solve a variety of image **restoration** tasks. The Plug-and-Play alternating direction method of multipliers (ADMM) and the Regularization by Denoising (RED) algorithms are two examples of such methods that made a breakthrough in image **restoration**. However, while the former method only applies to proximal algorithms, it has recently been shown that there exists no regularization that explains the RED algorithm when the denoisers lack Jacobian symmetry, which happen to be the case of most practical denoisers. To the best of our knowledge, there exists no method for training a network that directly represents the gradient of a regularizer, which can be directly used in Plug-and-Play gradient-based algorithms. We show that it is possible to train a denoiser along with a network that corresponds to the gradient of its regularizer. We use this gradient of the regularizer in gradient-based optimization methods and obtain better results comparing to other generic Plug-and-Play approaches. We also show that the regularizer can be used as a pre-trained network for unrolled gradient descent. Lastly, we show that the resulting denoiser allows for a quick convergence of the Plug-and-Play ADMM.  
### RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
- Authors : Xiangyu Gao, Guanbin Xing, Sumit Roy, Hui Liu
- Link : [http://arxiv.org/abs/2011.08981](http://arxiv.org/abs/2011.08981)
> ABSTRACT  :  Millimeter-wave radars are being increasingly integrated into commercial vehicles to support new advanced driver-assistance systems by enabling robust and high-performance object detection, localization, as well as recognition - a key component of new environmental perception. In this paper, we propose a novel radar multiple-perspectives convolutional neural network (RAMP-CNN) that extracts the location and class of objects based on further processing of the range-velocity-angle (RVA) heatmap sequences. To bypass the complexity of 4D convolutional neural networks (NN), we propose to combine several lower-dimension NN models within our RAMP-CNN model that nonetheless approaches the performance upper-bound with lower complexity. The extensive experiments show that the proposed RAMP-CNN model achieves better average recall and average precision than prior works in all testing scenarios. Besides, the RAMP-CNN model is validated to work robustly under **night**time, which enables low-cost radars as a potential substitute for pure optical sensing under severe conditions.  
### Toward Degradation-Robust Voice Conversion. (arXiv:2110.07537v3 [eess.AS] UPDATED)
- Authors : yu Huang, Wei Chang, yi Lee
- Link : [http://arxiv.org/abs/2110.07537](http://arxiv.org/abs/2110.07537)
> ABSTRACT  :  Any-to-any voice conversion technologies convert the vocal timbre of an utterance to any speaker even unseen during training. Although there have been several state-of-the-art any-to-any voice conversion models, they were all based on clean utterances to convert successfully. However, in real-world scenarios, it is difficult to collect clean utterances of a speaker, and they are usually degraded by noises or reverberations. It thus becomes highly desired to understand how these degradations affect voice conversion and build a degradation-robust model. We report in this paper the first comprehensive study on the degradation robustness of any-to-any voice conversion. We show that the performance of state-of-the-art models nowadays was severely hampered given degraded utterances. To this end, we then propose speech **enhancement** concatenation and denoising training to improve the robustness. In addition to common degradations, we also consider adversarial noises, which alter the model output significantly yet are human-imperceptible. It was shown that both concatenations with off-the-shelf speech **enhancement** models and denoising training on voice conversion models could improve the robustness, while each of them had pros and cons.  
## cs.AI
---
### RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
- Authors : Xiangyu Gao, Guanbin Xing, Sumit Roy, Hui Liu
- Link : [http://arxiv.org/abs/2011.08981](http://arxiv.org/abs/2011.08981)
> ABSTRACT  :  Millimeter-wave radars are being increasingly integrated into commercial vehicles to support new advanced driver-assistance systems by enabling robust and high-performance object detection, localization, as well as recognition - a key component of new environmental perception. In this paper, we propose a novel radar multiple-perspectives convolutional neural network (RAMP-CNN) that extracts the location and class of objects based on further processing of the range-velocity-angle (RVA) heatmap sequences. To bypass the complexity of 4D convolutional neural networks (NN), we propose to combine several lower-dimension NN models within our RAMP-CNN model that nonetheless approaches the performance upper-bound with lower complexity. The extensive experiments show that the proposed RAMP-CNN model achieves better average recall and average precision than prior works in all testing scenarios. Besides, the RAMP-CNN model is validated to work robustly under **night**time, which enables low-cost radars as a potential substitute for pure optical sensing under severe conditions.  
# Paper List
---
## cs.CV
---
**95** new papers in cs.CV:-) 
1. Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy. (arXiv:2204.13697v1 [cs.LG])
2. Channel Pruned YOLOv5-based Deep Learning Approach for Rapid and Accurate Outdoor Obstacles Detection. (arXiv:2204.13699v1 [cs.CV])
3. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v1 [q-bio.GN])
4. Learning cosmology and clustering with cosmic graphs. (arXiv:2204.13713v1 [astro-ph.CO])
5. One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation. (arXiv:2204.13738v1 [eess.IV])
6. Learning to Split for Automatic Bias Detection. (arXiv:2204.13749v1 [cs.LG])
7. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v1 [cs.CV])
8. A very preliminary analysis of DALL-E 2. (arXiv:2204.13807v1 [cs.CV])
9. Analysing the Influence of Attack Configurations on the Reconstruction of Medical Images in Federated Learning. (arXiv:2204.13808v1 [eess.IV])
10. Deep Learning-based Automatic Player Identification and Logging in American Football Videos. (arXiv:2204.13809v1 [cs.CV])
11. Understanding the impact of image and input resolution on deep digital pathology patch classifiers. (arXiv:2204.13829v1 [cs.CV])
12. Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcoma. (arXiv:2204.13838v1 [eess.IV])
13. GenDR: A Generalized Differentiable Renderer. (arXiv:2204.13845v1 [cs.CV])
14. Goldilocks-curriculum Domain Randomization and Fractal Perlin Noise with Application to Sim2Real Pneumonia Lesion Detection. (arXiv:2204.13849v1 [cs.CV])
15. COVID-Net US-X: Enhanced Deep Neural Network for Detection of COVID-19 Patient Cases from Convex Ultrasound Imaging Through Extended Linear-Convex Ultrasound Augmentation Learning. (arXiv:2204.13851v1 [eess.IV])
16. Equine radiograph classification using deep convolutional neural networks. (arXiv:2204.13857v1 [cs.CV])
17. Where in the World is this Image? Transformer-based Geo-localization in the Wild. (arXiv:2204.13861v1 [cs.CV])
18. Vision-Language Pre-Training for Boosting Scene Text Detectors. (arXiv:2204.13867v1 [cs.CV])
19. Multiple Degradation and Reconstruction Network for Single Image Denoising via Knowledge Distillation. (arXiv:2204.13873v1 [cs.CV])
20. Struct-MDC: Mesh-Refined Unsupervised Depth Completion Leveraging Structural Regularities from Visual SLAM. (arXiv:2204.13877v1 [cs.CV])
21. Learning Adaptive Warping for Real-World Rolling Shutter Correction. (arXiv:2204.13886v1 [cs.CV])
22. SideRT: A **Real-time** Pure Transformer Architecture for Single Image Depth Estimation. (arXiv:2204.13892v1 [cs.CV])
23. Leaner and Faster: Two-Stage Model Compression for Lightweight Text-Image Retrieval. (arXiv:2204.13913v1 [cs.CV])
24. Privacy-Preserving Model Upgrades with Bidirectional Compatible Training in Image Retrieval. (arXiv:2204.13919v1 [cs.CV])
25. Deep Geometry Post-Processing for Decompressed Point Clouds. (arXiv:2204.13952v1 [cs.CV])
26. SCS-Co: Self-Consistent Style Contrastive Learning for Image Harmonization. (arXiv:2204.13962v1 [cs.CV])
27. Using 3D Shadows to Detect Object Hiding Attacks on Autonomous Vehicle Perception. (arXiv:2204.13973v1 [cs.CV])
28. AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on **Real-time** Image **Enhancement**. (arXiv:2204.13983v1 [cs.CV])
29. Learning High-DOF Reaching-and-Grasping via Dynamic Representation of Gripper-Object Interaction. (arXiv:2204.13998v1 [cs.RO])
30. Searching for Efficient Neural Architectures for On-Device ML on Edge TPUs. (arXiv:2204.14007v1 [cs.DC])
31. Neural Implicit Representations for Physical Parameter Inference from a Single Video. (arXiv:2204.14030v1 [cs.CV])
32. A Challenging Benchmark of Anime Style Recognition. (arXiv:2204.14034v1 [cs.CV])
33. C3-STISR: Scene Text Image Super-resolution with Triple Clues. (arXiv:2204.14044v1 [cs.CV])
34. A Deep Learning based No-reference Quality Assessment Model for UGC Videos. (arXiv:2204.14047v1 [cs.CV])
35. Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype Contrast. (arXiv:2204.14057v1 [cs.SD])
36. Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v1 [cs.CV])
37. Learning Localization-aware Target Confidence for Siamese Visual Tracking. (arXiv:2204.14093v1 [cs.CV])
38. PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining. (arXiv:2204.14095v1 [cs.CV])
39. Adversarial Distortion Learning for Medical Image Denoising. (arXiv:2204.14100v1 [eess.IV])
40. TEMOS: Generating diverse human motions from textual descriptions. (arXiv:2204.14109v1 [cs.CV])
41. Seeing without Looking: Analysis Pipeline for Child Sexual Abuse Datasets. (arXiv:2204.14110v1 [cs.CV])
42. A Comparative Study of Meter Detection Methods for Automated Infrastructure Inspection. (arXiv:2204.14117v1 [cs.CV])
43. Towards Automatic Parsing of Structured Visual Content through the Use of Synthetic Data. (arXiv:2204.14136v1 [cs.CV])
44. Segmentation of kidney stones in endoscopic video feeds. (arXiv:2204.14175v1 [eess.IV])
45. Oracle Guided Image Synthesis with Relative Queries. (arXiv:2204.14189v1 [cs.CV])
46. Improving Transferability for Domain Adaptive Detection Transformers. (arXiv:2204.14195v1 [cs.CV])
47. Flamingo: a Visual Language Model for Few-Shot Learning. (arXiv:2204.14198v1 [cs.CV])
48. Preoperative brain tumor imaging: models and software for segmentation and standardized reporting. (arXiv:2204.14199v1 [eess.IV])
49. CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers. (arXiv:2204.14217v1 [cs.CV])
50. Application of machine learning methods to detect and classify Core images using GAN and texture recognition. (arXiv:2204.14224v1 [cs.CV])
51. Recommendations on test datasets for evaluating AI solutions in pathology. (arXiv:2204.14226v1 [eess.IV])
52. Hardware Trojan Detection Using Unsupervised Deep Learning on Quantum Diamond Microscope Magnetic Field Images. (arXiv:2204.14228v1 [cs.CV])
53. EndoMapper dataset of complete calibrated endoscopy procedures. (arXiv:2204.14240v1 [cs.CV])
54. CLIP-Art: Contrastive Pre-training for Fine-Grained Art Classification. (arXiv:2204.14244v1 [cs.CV])
55. OSSGAN: Open-Set Semi-Supervised Image Generation. (arXiv:2204.14249v1 [cs.CV])
56. VehicleNet: Learning Robust Visual Representation for Vehicle Re-identification. (arXiv:2004.06305v2 [cs.CV] UPDATED)
57. Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization. (arXiv:2010.08276v2 [cs.CV] UPDATED)
58. Duality-Gated Mutual Condition Network for RGBT Tracking. (arXiv:2011.07188v3 [cs.CV] UPDATED)
59. RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
60. TrackFormer: Multi-Object Tracking with Transformers. (arXiv:2101.02702v3 [cs.CV] UPDATED)
61. An Efficient Multitask Neural Network for Face Alignment, Head Pose Estimation and Face Tracking. (arXiv:2103.07615v3 [cs.CV] UPDATED)
62. The GIST and RIST of Iterative Self-Training for Semi-Supervised Segmentation. (arXiv:2103.17105v3 [cs.CV] UPDATED)
63. Pyramid Medical Transformer for Medical Image Segmentation. (arXiv:2104.14702v3 [cs.CV] UPDATED)
64. Smaller Is Better: An Analysis of Instance Quantity/Quality Trade-off in Rehearsal-based Continual Learning. (arXiv:2105.14106v4 [cs.CV] UPDATED)
65. DETReg: Unsupervised Pretraining with Region Priors for Object Detection. (arXiv:2106.04550v4 [cs.CV] UPDATED)
66. Learning to See by Looking at Noise. (arXiv:2106.05963v3 [cs.CV] UPDATED)
67. GLASS: Geometric Latent Augmentation for Shape Spaces. (arXiv:2108.03225v3 [cs.CV] UPDATED)
68. Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v3 [cs.CV] UPDATED)
69. Supervised Contrastive Learning for Detecting Anomalous Driving Behaviours from Multimodal Videos. (arXiv:2109.04021v2 [cs.CV] UPDATED)
70. ROS-X-Habitat: Bridging the ROS Ecosystem with Embodied AI. (arXiv:2109.07703v3 [cs.RO] UPDATED)
71. Unsolved Problems in ML Safety. (arXiv:2109.13916v4 [cs.LG] UPDATED)
72. CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation. (arXiv:2110.02624v2 [cs.CV] UPDATED)
73. To Trust or Not To Trust Prediction Scores for Membership Inference Attacks. (arXiv:2111.09076v2 [cs.LG] UPDATED)
74. Ice hockey player identification via transformers and weakly supervised learning. (arXiv:2111.11535v2 [cs.CV] UPDATED)
75. Intuitive Shape Editing in Latent Space. (arXiv:2111.12488v2 [cs.CV] UPDATED)
76. MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation. (arXiv:2111.12707v3 [cs.CV] UPDATED)
77. PokeBNN: A Binary Pursuit of Lightweight Accuracy. (arXiv:2112.00133v2 [cs.LG] UPDATED)
78. GANORCON: Are Generative Models Useful for Few-shot Segmentation?. (arXiv:2112.00854v2 [cs.CV] UPDATED)
79. CAVER: Cross-Modal View-Mixed Transformer for Bi-Modal Salient Object Detection. (arXiv:2112.02363v2 [cs.CV] UPDATED)
80. GUNNEL: Guided Mixup Augmentation and Multi-View Fusion for Aquatic Animal Segmentation. (arXiv:2112.06193v2 [cs.CV] UPDATED)
81. DeepAdversaries: Examining the Robustness of Deep Learning Models for Galaxy Morphology Classification. (arXiv:2112.14299v2 [cs.LG] UPDATED)
82. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v3 [cs.CV] UPDATED)
83. Conditional Generative Data-free Knowledge Distillation. (arXiv:2112.15358v3 [cs.CV] UPDATED)
84. CLIP-Event: Connecting Text and Images with Event Structures. (arXiv:2201.05078v2 [cs.CV] UPDATED)
85. Contrastive and Selective Hidden Embeddings for Medical Image Segmentation. (arXiv:2201.08779v2 [cs.CV] UPDATED)
86. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v2 [cs.CV] UPDATED)
87. Motion Sickness Modeling with Visual Vertical Estimation and Its Application to Autonomous Personal Mobility Vehicles. (arXiv:2202.06299v3 [cs.HC] UPDATED)
88. 3D Common Corruptions and Data Augmentation. (arXiv:2203.01441v3 [cs.CV] UPDATED)
89. Stochastic Video Prediction with Structure and Motion. (arXiv:2203.10528v2 [cs.CV] UPDATED)
90. Self-Supervised Road Layout Parsing with Graph Auto-Encoding. (arXiv:2203.11000v2 [cs.CV] UPDATED)
91. Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization. (arXiv:2203.13167v3 [cs.CV] UPDATED)
92. In-N-Out Generative Learning for Dense Unsupervised Video Segmentation. (arXiv:2203.15312v3 [cs.CV] UPDATED)
93. Monitoring social distancing with single image depth estimation. (arXiv:2204.01693v2 [cs.CV] UPDATED)
94. End-to-End Audio Strikes Back: Boosting Augmentations Towards An Efficient Audio Classification Network. (arXiv:2204.11479v4 [cs.SD] UPDATED)
95. Deeper Insights into ViTs Robustness towards Common Corruptions. (arXiv:2204.12143v2 [cs.CV] UPDATED)
## eess.IV
---
**19** new papers in eess.IV:-) 
1. Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy. (arXiv:2204.13697v1 [cs.LG])
2. One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation. (arXiv:2204.13738v1 [eess.IV])
3. Analysing the Influence of Attack Configurations on the Reconstruction of Medical Images in Federated Learning. (arXiv:2204.13808v1 [eess.IV])
4. Deep Learning-based Automatic Player Identification and Logging in American Football Videos. (arXiv:2204.13809v1 [cs.CV])
5. Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcoma. (arXiv:2204.13838v1 [eess.IV])
6. COVID-Net US-X: Enhanced Deep Neural Network for Detection of COVID-19 Patient Cases from Convex Ultrasound Imaging Through Extended Linear-Convex Ultrasound Augmentation Learning. (arXiv:2204.13851v1 [eess.IV])
7. Multiple Degradation and Reconstruction Network for Single Image Denoising via Knowledge Distillation. (arXiv:2204.13873v1 [cs.CV])
8. Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent. (arXiv:2204.13940v1 [eess.IV])
9. Deep Geometry Post-Processing for Decompressed Point Clouds. (arXiv:2204.13952v1 [cs.CV])
10. A Deep Learning based No-reference Quality Assessment Model for UGC Videos. (arXiv:2204.14047v1 [cs.CV])
11. Improving the estimation of directional area scattering factor (DASF) from canopy reflectance: theoretical basis and validation. (arXiv:2204.14059v1 [cs.CE])
12. Adversarial Distortion Learning for Medical Image Denoising. (arXiv:2204.14100v1 [eess.IV])
13. Segmentation of kidney stones in endoscopic video feeds. (arXiv:2204.14175v1 [eess.IV])
14. Complex-Valued Frequency Selective Extrapolation for Fast Image and Video Signal Extrapolation. (arXiv:2204.14193v1 [eess.IV])
15. A Fast Algorithm for Selective Signal Extrapolation with Arbitrary Basis Functions. (arXiv:2204.14194v1 [eess.IV])
16. Preoperative brain tumor imaging: models and software for segmentation and standardized reporting. (arXiv:2204.14199v1 [eess.IV])
17. Application of machine learning methods to detect and classify Core images using GAN and texture recognition. (arXiv:2204.14224v1 [cs.CV])
18. Recommendations on test datasets for evaluating AI solutions in pathology. (arXiv:2204.14226v1 [eess.IV])
19. Re-using Adversarial Mask Discriminators for Test-time Training under Distribution Shifts. (arXiv:2108.11926v3 [cs.CV] UPDATED)
## cs.LG
---
**135** new papers in cs.LG:-) 
1. Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy. (arXiv:2204.13697v1 [cs.LG])
2. Identifying Critical LMS Features for Predicting At-risk Students. (arXiv:2204.13700v1 [cs.LG])
3. Neighbor-Based Optimized Logistic Regression Machine Learning Model For Electric Vehicle Occupancy Detection. (arXiv:2204.13702v1 [cs.LG])
4. Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions. (arXiv:2204.13704v1 [cs.LG])
5. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v1 [q-bio.GN])
6. Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities. (arXiv:2204.13707v1 [cs.LG])
7. Learning cosmology and clustering with cosmic graphs. (arXiv:2204.13713v1 [astro-ph.CO])
8. An Intriguing Property of Geophysics Inversion. (arXiv:2204.13731v1 [cs.LG])
9. GCN-FFNN: A Two-Stream Deep Model for Learning Solution to Partial Differential Equations. (arXiv:2204.13744v1 [cs.LG])
10. CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines. (arXiv:2204.13746v1 [cs.CL])
11. Learning to Split for Automatic Bias Detection. (arXiv:2204.13749v1 [cs.LG])
12. BEINIT: Avoiding Barren Plateaus in Variational Quantum Algorithms. (arXiv:2204.13751v1 [quant-ph])
13. High Dimensional Bayesian Optimization with Kernel Principal Component Analysis. (arXiv:2204.13753v1 [cs.LG])
14. Probabilistic Permutation Graph Search: Black-Box Optimization for Fairness in Ranking. (arXiv:2204.13765v1 [cs.LG])
15. Triformer: Triangular, Variable-Specific Attentions for Long Sequence Multivariate Time Series Forecasting--Full Version. (arXiv:2204.13767v1 [cs.LG])
16. Formulating Robustness Against Unforeseen Attacks. (arXiv:2204.13779v1 [cs.LG])
17. AGIC: Approximate Gradient Inversion Attack on Federated Learning. (arXiv:2204.13784v1 [cs.LG])
18. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v1 [cs.CV])
19. Probabilistic Models for Manufacturing Lead Times. (arXiv:2204.13792v1 [cs.LG])
20. Analysing the Influence of Attack Configurations on the Reconstruction of Medical Images in Federated Learning. (arXiv:2204.13808v1 [eess.IV])
21. Visualization and Optimization Techniques for High Dimensional Parameter Spaces. (arXiv:2204.13812v1 [cs.HC])
22. An Online Ensemble Learning Model for Detecting Attacks in Wireless Sensor Networks. (arXiv:2204.13814v1 [cs.NI])
23. Automatic Machine Learning for Multi-Receiver CNN Technology Classifiers. (arXiv:2204.13819v1 [cs.LG])
24. A Neural Network-enhanced Reproducing Kernel Particle Method for Modeling Strain Localization. (arXiv:2204.13821v1 [cs.CE])
25. Noise-reducing attention cross fusion learning transformer for histological image classification of osteosarcoma. (arXiv:2204.13838v1 [eess.IV])
26. An Extensive Data Processing Pipeline for MIMIC-IV. (arXiv:2204.13841v1 [cs.LG])
27. VPNets: Volume-preserving neural networks for learning source-free dynamics. (arXiv:2204.13843v1 [cs.LG])
28. GenDR: A Generalized Differentiable Renderer. (arXiv:2204.13845v1 [cs.CV])
29. RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning. (arXiv:2204.13846v1 [cs.LG])
30. CATNet: Cross-event Attention-based Time-aware Network for Medical Event Prediction. (arXiv:2204.13847v1 [cs.LG])
31. Goldilocks-curriculum Domain Randomization and Fractal Perlin Noise with Application to Sim2Real Pneumonia Lesion Detection. (arXiv:2204.13849v1 [cs.CV])
32. COVID-Net US-X: Enhanced Deep Neural Network for Detection of COVID-19 Patient Cases from Convex Ultrasound Imaging Through Extended Linear-Convex Ultrasound Augmentation Learning. (arXiv:2204.13851v1 [eess.IV])
33. H2H: Heterogeneous Model to Heterogeneous System Mapping with Computation and Communication Awareness. (arXiv:2204.13852v1 [cs.LG])
34. Detecting Textual Adversarial Examples Based on Distributional Characteristics of Data Representations. (arXiv:2204.13853v1 [cs.CL])
35. One-Way Matching of Datasets with Low Rank Signals. (arXiv:2204.13858v1 [math.ST])
36. Energy Minimization for Federated Asynchronous Learning on Battery-Powered Mobile Devices via Application Co-running. (arXiv:2204.13878v1 [cs.DC])
37. Autonomous In-Situ Soundscape Augmentation via Joint Selection of Masker and Gain. (arXiv:2204.13883v1 [eess.AS])
38. Framework for Behavioral Disorder Detection Using Machine Learning and Application of Virtual Cognitive Behavioral Therapy in COVID-19 Pandemic. (arXiv:2204.13900v1 [cs.LG])
39. Fast Sampling of Diffusion Models with Exponential Integrator. (arXiv:2204.13902v1 [cs.LG])
40. Unsupervised Reinforcement Learning for Transferable Manipulation Skill Discovery. (arXiv:2204.13906v1 [cs.RO])
41. Task Embedding Temporal Convolution Networks for Transfer Learning Problems in Renewable Power Time-Series Forecast. (arXiv:2204.13908v1 [cs.LG])
42. A study of tree-based methods and their combination. (arXiv:2204.13916v1 [stat.ML])
43. A Mixed-Domain Self-Attention Network for Multilabel Cardiac Irregularity Classification Using Reduced-Lead Electrocardiogram. (arXiv:2204.13917v1 [cs.LG])
44. Short-Term Density Forecasting of Low-Voltage Load using Bernstein-Polynomial Normalizing Flows. (arXiv:2204.13939v1 [cs.LG])
45. Learned Gradient of a Regularizer for Plug-and-Play Gradient Descent. (arXiv:2204.13940v1 [eess.IV])
46. Tailored Uncertainty Estimation for Deep Learning Systems. (arXiv:2204.13963v1 [cs.LG])
47. Cost Effective MLaaS Federation: A Combinatorial Reinforcement Learning Approach. (arXiv:2204.13971v1 [cs.LG])
48. Making sense of violence risk predictions using clinical notes. (arXiv:2204.13976v1 [cs.LG])
49. Dynamic Diagnosis of the Progress and Shortcomings of Student Learning using Machine Learning based on Cognitive, Social, and Emotional Features. (arXiv:2204.13989v1 [cs.CY])
50. Particle Swarm Optimization Based Demand Response Using Artificial Neural Network Based Load Prediction. (arXiv:2204.13990v1 [cs.NE])
51. Physical Deep Learning with Biologically Plausible Training Method. (arXiv:2204.13991v1 [cs.NE])
52. Leveraging triplet loss and nonlinear dimensionality reduction for on-the-fly channel charting. (arXiv:2204.13996v1 [cs.NI])
53. Statistical applications of contrastive learning. (arXiv:2204.13999v1 [cs.LG])
54. Machine Learning-Based GPS Multipath Detection Method Using Dual Antennas. (arXiv:2204.14001v1 [cs.NI])
55. No Task Left Behind: Multi-Task Learning of Knowledge Tracing and Option Tracing for Better Student Assessment. (arXiv:2204.14006v1 [cs.CY])
56. Searching for Efficient Neural Architectures for On-Device ML on Edge TPUs. (arXiv:2204.14007v1 [cs.DC])
57. Biologically-inspired neuronal adaptation improves learning in neural networks. (arXiv:2204.14008v1 [cs.NE])
58. Local Explanation of Dimensionality Reduction. (arXiv:2204.14012v1 [cs.LG])
59. Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling. (arXiv:2204.14017v1 [cs.LG])
60. Exploration and Exploitation in Federated Learning to Exclude Clients with Poisoned Data. (arXiv:2204.14020v1 [cs.DC])
61. Data+Shift: Supporting visual investigation of data distribution shifts by data scientists. (arXiv:2204.14025v1 [cs.LG])
62. Who will stay? Using Deep Learning to predict engagement of citizen scientists. (arXiv:2204.14046v1 [cs.LG])
63. Topological Data Analysis in Time Series: Temporal Filtration and Application to Single-Cell Genomics. (arXiv:2204.14048v1 [cs.LG])
64. A Collection of Quality Diversity Optimization Problems Derived from Hyperparameter Optimization of Machine Learning Models. (arXiv:2204.14061v1 [cs.LG])
65. Multimodal Transformer-based Model for Buchwald-Hartwig and Suzuki-Miyaura Reaction Yield Prediction. (arXiv:2204.14062v1 [cs.LG])
66. Escaping Spurious Local Minima of Low-Rank Matrix Factorization Through Convex Lifting. (arXiv:2204.14067v1 [cs.LG])
67. Controlled Generation of Unseen Faults for Partial and OpenSet&Partial Domain Adaptation. (arXiv:2204.14068v1 [cs.LG])
68. Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v1 [cs.CV])
69. Few-shot learning for medical text: A systematic review. (arXiv:2204.14081v1 [cs.CL])
70. Bayesian Information Criterion for Event-based Multi-trial Ensemble data. (arXiv:2204.14096v1 [stat.ML])
71. Reducing Neural Architecture Search Spaces with Training-Free Statistics and Computational Graph Clustering. (arXiv:2204.14103v1 [cs.LG])
72. On the Optimization of Margin Distribution. (arXiv:2204.14118v1 [cs.LG])
73. Wide and Deep Neural Networks Achieve Optimality for Classification. (arXiv:2204.14126v1 [cs.LG])
74. Network Topology Optimization via Deep Reinforcement Learning. (arXiv:2204.14133v1 [cs.NI])
75. Learning Anisotropic Interaction Rules from Individual Trajectories in a Heterogeneous Cellular Population. (arXiv:2204.14141v1 [q-bio.QM])
76. A Framework for Constructing Machine Learning Models with Feature Set Optimisation for Evapotranspiration Partitioning. (arXiv:2204.14142v1 [cs.LG])
77. Learning from Natural Language Feedback. (arXiv:2204.14146v1 [cs.CL])
78. Tractable Uncertainty for Structure Learning. (arXiv:2204.14170v1 [cs.LG])
79. Explainable AI via Learning to Optimize. (arXiv:2204.14174v1 [math.OC])
80. Industry-academia research collaboration and knowledge co-creation: Patterns and anti-patterns. (arXiv:2204.14180v1 [cs.SE])
81. Randomized Smoothing under Attack: How Good is it in Pratice?. (arXiv:2204.14187v1 [cs.CR])
82. Human's Role in-the-Loop. (arXiv:2204.14192v1 [cs.DB])
83. Flamingo: a Visual Language Model for Few-Shot Learning. (arXiv:2204.14198v1 [cs.CV])
84. Preoperative brain tumor imaging: models and software for segmentation and standardized reporting. (arXiv:2204.14199v1 [eess.IV])
85. Modular Domain Adaptation. (arXiv:2204.14213v1 [cs.CL])
86. CogView2: Faster and Better Text-to-Image Generation via Hierarchical Transformers. (arXiv:2204.14217v1 [cs.CV])
87. Application of machine learning methods to detect and classify Core images using GAN and texture recognition. (arXiv:2204.14224v1 [cs.CV])
88. Recommendations on test datasets for evaluating AI solutions in pathology. (arXiv:2204.14226v1 [eess.IV])
89. Momentum-based variance-reduced proximal stochastic gradient method for composite nonconvex stochastic optimization. (arXiv:2006.00425v3 [math.OC] UPDATED)
90. Altruist: Argumentative Explanations through Local Interpretations of Predictive Models. (arXiv:2010.07650v2 [cs.LG] UPDATED)
91. RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
92. Semi-Discrete Optimal Transport: Hardness, Regularization and Numerical Solution. (arXiv:2103.06263v2 [cs.LG] UPDATED)
93. HyperJump: Accelerating HyperBand via Risk Modelling. (arXiv:2108.02479v3 [cs.LG] UPDATED)
94. Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v4 [cs.CL] UPDATED)
95. ROS-X-Habitat: Bridging the ROS Ecosystem with Embodied AI. (arXiv:2109.07703v3 [cs.RO] UPDATED)
96. Pre-training helps Bayesian optimization too. (arXiv:2109.08215v3 [cs.LG] UPDATED)
97. Unsolved Problems in ML Safety. (arXiv:2109.13916v4 [cs.LG] UPDATED)
98. Multi-Agent MDP Homomorphic Networks. (arXiv:2110.04495v2 [cs.LG] UPDATED)
99. The Geometry of Memoryless Stochastic Policy Optimization in Infinite-Horizon POMDPs. (arXiv:2110.07409v3 [math.OC] UPDATED)
100. Toward Degradation-Robust Voice Conversion. (arXiv:2110.07537v3 [eess.AS] UPDATED)
101. Fairer LP-based Online Allocation via Analytic Center. (arXiv:2110.14621v3 [cs.DS] UPDATED)
102. Mean-field Analysis of Piecewise Linear Solutions for Wide ReLU Networks. (arXiv:2111.02278v2 [cs.LG] UPDATED)
103. Testing the Generalization of Neural Language Models for COVID-19 Misinformation Detection. (arXiv:2111.07819v3 [cs.CL] UPDATED)
104. To Trust or Not To Trust Prediction Scores for Membership Inference Attacks. (arXiv:2111.09076v2 [cs.LG] UPDATED)
105. Intuitive Shape Editing in Latent Space. (arXiv:2111.12488v2 [cs.CV] UPDATED)
106. MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation. (arXiv:2111.12707v3 [cs.CV] UPDATED)
107. PokeBNN: A Binary Pursuit of Lightweight Accuracy. (arXiv:2112.00133v2 [cs.LG] UPDATED)
108. DeepAdversaries: Examining the Robustness of Deep Learning Models for Galaxy Morphology Classification. (arXiv:2112.14299v2 [cs.LG] UPDATED)
109. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v3 [cs.CV] UPDATED)
110. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v2 [cs.CV] UPDATED)
111. MarkovGNN: Graph Neural Networks on Markov Diffusion. (arXiv:2202.02470v2 [cs.LG] UPDATED)
112. SwiftAgg: Communication-Efficient and Dropout-Resistant Secure Aggregation for Federated Learning with Worst-Case Security Guarantees. (arXiv:2202.04169v2 [cs.IT] UPDATED)
113. Forecasting large-scale circulation regimes using deformable convolutional neural networks and global spatiotemporal climate data. (arXiv:2202.04964v2 [cs.LG] UPDATED)
114. SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography. (arXiv:2202.05735v4 [cs.LG] UPDATED)
115. Abstraction for Deep Reinforcement Learning. (arXiv:2202.05839v3 [cs.LG] UPDATED)
116. Adversarially-regularized mixed effects deep learning (ARMED) models for improved interpretability, performance, and generalization on clustered data. (arXiv:2202.11783v3 [cs.LG] UPDATED)
117. 3D Common Corruptions and Data Augmentation. (arXiv:2203.01441v3 [cs.CV] UPDATED)
118. Fiber Bundle Morphisms as a Framework for Modeling Many-to-Many Maps. (arXiv:2203.08189v2 [cs.LG] UPDATED)
119. Stochastic Video Prediction with Structure and Motion. (arXiv:2203.10528v2 [cs.CV] UPDATED)
120. Towards Exemplar-Free Continual Learning in Vision Transformers: an Account of Attention, Functional and Weight Regularization. (arXiv:2203.13167v3 [cs.CV] UPDATED)
121. On Exploiting Layerwise Gradient Statistics for Effective Training of Deep Neural Networks. (arXiv:2203.13273v4 [cs.LG] UPDATED)
122. Feature extraction using Spectral Clustering for Gene Function Prediction using Hierarchical Multi-label Classification. (arXiv:2203.13551v2 [cs.LG] UPDATED)
123. Convergence of gradient descent for deep neural networks. (arXiv:2203.16462v2 [cs.LG] UPDATED)
124. VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v4 [cs.LG] UPDATED)
125. Rockafellian Relaxation in Optimization under Uncertainty: Asymptotically Exact Formulations. (arXiv:2204.04762v2 [math.OC] UPDATED)
126. Towards Generalizable Semantic Product Search by Text Similarity Pre-training on Search Click Logs. (arXiv:2204.05231v2 [cs.IR] UPDATED)
127. Finding MNEMON: Reviving Memories of Node Embeddings. (arXiv:2204.06963v2 [cs.LG] UPDATED)
128. XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v2 [cs.CL] UPDATED)
129. KnowAugNet: Multi-Source Medical Knowledge Augmented Medication Prediction Network with Multi-Level Graph Contrastive Learning. (arXiv:2204.11736v2 [cs.AI] UPDATED)
130. Science Checker: Extractive-Boolean Question Answering For Scientific Fact Checking. (arXiv:2204.12263v2 [cs.CL] UPDATED)
131. A review of Federated Learning in Intrusion Detection Systems for IoT. (arXiv:2204.12443v2 [cs.CR] UPDATED)
132. Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering. (arXiv:2204.12496v2 [cs.LG] UPDATED)
133. Application of WGAN-GP in recommendation and Questioning the relevance of GAN-based approaches. (arXiv:2204.12527v2 [cs.IR] UPDATED)
134. Toward Policy Explanations for Multi-Agent Reinforcement Learning. (arXiv:2204.12568v2 [cs.AI] UPDATED)
135. Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks. (arXiv:2204.12589v2 [cs.LG] UPDATED)
## cs.AI
---
**84** new papers in cs.AI:-) 
1. Federated Learning: Balancing the Thin Line Between Data Intelligence and Privacy. (arXiv:2204.13697v1 [cs.LG])
2. Hyperbolic Hierarchical Knowledge Graph Embeddings for Link Prediction in Low Dimensions. (arXiv:2204.13704v1 [cs.LG])
3. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v1 [q-bio.GN])
4. Tag-assisted Multimodal Sentiment Analysis under Uncertain Missing Modalities. (arXiv:2204.13707v1 [cs.LG])
5. Learning to Split for Automatic Bias Detection. (arXiv:2204.13749v1 [cs.LG])
6. A First Runtime Analysis of the NSGA-II on a Multimodal Problem. (arXiv:2204.13750v1 [cs.NE])
7. CKH: Causal Knowledge Hierarchy for Estimating Structural Causal Models from Data and Priors. (arXiv:2204.13775v1 [cs.AI])
8. Pragmatic Clinical Trials in the Rubric of Structural Causal Models. (arXiv:2204.13782v1 [stat.ME])
9. Instilling Type Knowledge in Language Models via Multi-Task QA. (arXiv:2204.13796v1 [cs.CL])
10. BILP-Q: Quantum Coalition Structure Generation. (arXiv:2204.13802v1 [quant-ph])
11. A very preliminary analysis of DALL-E 2. (arXiv:2204.13807v1 [cs.CV])
12. Visualization and Optimization Techniques for High Dimensional Parameter Spaces. (arXiv:2204.13812v1 [cs.HC])
13. Designing for Responsible Trust in AI Systems: A Communication Perspective. (arXiv:2204.13828v1 [cs.HC])
14. A Bottom-Up End-User Intelligent Assistant Approach to Empower Gig Workers against AI Inequality. (arXiv:2204.13842v1 [cs.HC])
15. CATNet: Cross-event Attention-based Time-aware Network for Medical Event Prediction. (arXiv:2204.13847v1 [cs.LG])
16. Repro: An Open-Source Library for Improving the Reproducibility and Usability of Publicly Available Research Code. (arXiv:2204.13848v1 [cs.CL])
17. H2H: Heterogeneous Model to Heterogeneous System Mapping with Computation and Communication Awareness. (arXiv:2204.13852v1 [cs.LG])
18. Vision-Language Pre-Training for Boosting Scene Text Detectors. (arXiv:2204.13867v1 [cs.CV])
19. Maxmin Participatory Budgeting. (arXiv:2204.13923v1 [cs.GT])
20. KERMIT - A Transformer-Based Approach for Knowledge Graph Matching. (arXiv:2204.13931v1 [cs.CL])
21. User Experience Design for Automatic Credibility Assessment of News Content About COVID-19. (arXiv:2204.13943v1 [cs.CL])
22. PIE: a Parameter and Inference Efficient Solution for Large Scale Knowledge Graph Embedding Reasoning. (arXiv:2204.13957v1 [cs.CL])
23. Failed Disruption Propagation in Integer Genetic Programming. (arXiv:2204.13997v1 [cs.NE])
24. Robust Solutions for Multi-Defender Stackelberg Security Games. (arXiv:2204.14000v1 [cs.GT])
25. No Task Left Behind: Multi-Task Learning of Knowledge Tracing and Option Tracing for Better Student Assessment. (arXiv:2204.14006v1 [cs.CY])
26. Biologically-inspired neuronal adaptation improves learning in neural networks. (arXiv:2204.14008v1 [cs.NE])
27. Local Explanation of Dimensionality Reduction. (arXiv:2204.14012v1 [cs.LG])
28. Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling. (arXiv:2204.14017v1 [cs.LG])
29. Unsupervised Voice-Face Representation Learning by Cross-Modal Prototype Contrast. (arXiv:2204.14057v1 [cs.SD])
30. Multimodal Transformer-based Model for Buchwald-Hartwig and Suzuki-Miyaura Reaction Yield Prediction. (arXiv:2204.14062v1 [cs.LG])
31. Dynamic Noises of Multi-Agent Environments Can Improve Generalization: Agent-based Models meets Reinforcement Learning. (arXiv:2204.14076v1 [cs.AI])
32. Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN. (arXiv:2204.14079v1 [cs.CV])
33. PyramidCLIP: Hierarchical Feature Alignment for Vision-language Model Pretraining. (arXiv:2204.14095v1 [cs.CV])
34. SATfeatPy - A Python-based Feature Extraction System for Satisfiability. (arXiv:2204.14116v1 [cs.AI])
35. Network Topology Optimization via Deep Reinforcement Learning. (arXiv:2204.14133v1 [cs.NI])
36. Learning from Natural Language Feedback. (arXiv:2204.14146v1 [cs.CL])
37. Tractable Uncertainty for Structure Learning. (arXiv:2204.14170v1 [cs.LG])
38. Frontiers and Exact Learning of ELI Queries under DL-Lite Ontologies. (arXiv:2204.14172v1 [cs.AI])
39. Randomized Smoothing under Attack: How Good is it in Pratice?. (arXiv:2204.14187v1 [cs.CR])
40. Oracle Guided Image Synthesis with Relative Queries. (arXiv:2204.14189v1 [cs.CV])
41. Flamingo: a Visual Language Model for Few-Shot Learning. (arXiv:2204.14198v1 [cs.CV])
42. Recommendations on test datasets for evaluating AI solutions in pathology. (arXiv:2204.14226v1 [eess.IV])
43. Lipschitz-based Surrogate Model for High-dimensional Computationally Expensive Problems. (arXiv:2204.14236v1 [cs.NE])
44. Human-in-the-loop online multi-agent approach to increase trustworthiness in ML models through trust scores and data augmentation. (arXiv:2204.14255v1 [cs.AI])
45. Finite Entailment of UCRPQs over ALC Ontologies. (arXiv:2204.14261v1 [cs.LO])
46. How Robust is Neural Machine Translation to Language Imbalance in Multilingual Tokenizer Training?. (arXiv:2204.14268v1 [cs.CL])
47. End-to-end Spoken Conversational Question Answering: Task, Dataset and Model. (arXiv:2204.14272v1 [cs.CL])
48. Altruist: Argumentative Explanations through Local Interpretations of Predictive Models. (arXiv:2010.07650v2 [cs.LG] UPDATED)
49. RAMP-CNN: A Novel Neural Network for Enhanced Automotive Radar Object Recognition. (arXiv:2011.08981v2 [eess.SP] UPDATED)
50. What Makes a Good and Useful Summary? Incorporating Users in Automatic Summarization Research. (arXiv:2012.07619v3 [cs.CL] UPDATED)
51. Identifying Machine-Paraphrased Plagiarism. (arXiv:2103.11909v4 [cs.CL] UPDATED)
52. Are Neural Language Models Good Plagiarists? A Benchmark for Neural Paraphrase Detection. (arXiv:2103.12450v3 [cs.CL] UPDATED)
53. The Future is not One-dimensional: Complex Event Schema Induction by Graph Modeling for Event Prediction. (arXiv:2104.06344v3 [cs.AI] UPDATED)
54. An Extended Jump Functions Benchmark for the Analysis of Randomized Search Heuristics. (arXiv:2105.03090v3 [cs.NE] UPDATED)
55. Hybrid Encoding For Generating Large Scale Game Level Patterns With Local Variations. (arXiv:2105.12960v3 [cs.NE] UPDATED)
56. Learning to See by Looking at Noise. (arXiv:2106.05963v3 [cs.CV] UPDATED)
57. AI-driven Prices for Sustainable Production Markets. (arXiv:2106.06060v2 [cs.MA] UPDATED)
58. Learning Visual-Audio Representations for Voice-Controlled Robots. (arXiv:2109.02823v2 [cs.RO] UPDATED)
59. ROS-X-Habitat: Bridging the ROS Ecosystem with Embodied AI. (arXiv:2109.07703v3 [cs.RO] UPDATED)
60. Unsolved Problems in ML Safety. (arXiv:2109.13916v4 [cs.LG] UPDATED)
61. CLIP-Forge: Towards Zero-Shot Text-to-Shape Generation. (arXiv:2110.02624v2 [cs.CV] UPDATED)
62. On the Impact of Temporal Representations on Metaphor Detection. (arXiv:2111.03320v2 [cs.CL] UPDATED)
63. CoCo Games: Graphical Game-Theoretic Swarm Control for Communication-Aware Coverage. (arXiv:2111.04576v5 [cs.RO] UPDATED)
64. Testing the Generalization of Neural Language Models for COVID-19 Misinformation Detection. (arXiv:2111.07819v3 [cs.CL] UPDATED)
65. MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation. (arXiv:2111.12707v3 [cs.CV] UPDATED)
66. Analyzing the Limits of Self-Supervision in Handling Bias in Language. (arXiv:2112.08637v2 [cs.CL] UPDATED)
67. DeepAdversaries: Examining the Robustness of Deep Learning Models for Galaxy Morphology Classification. (arXiv:2112.14299v2 [cs.LG] UPDATED)
68. StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2. (arXiv:2112.14683v3 [cs.CV] UPDATED)
69. CLIP-Event: Connecting Text and Images with Event Structures. (arXiv:2201.05078v2 [cs.CV] UPDATED)
70. Zero Experience Required: Plug & Play Modular Transfer Learning for Semantic Visual Navigation. (arXiv:2202.02440v2 [cs.CV] UPDATED)
71. MarkovGNN: Graph Neural Networks on Markov Diffusion. (arXiv:2202.02470v2 [cs.LG] UPDATED)
72. Abstraction for Deep Reinforcement Learning. (arXiv:2202.05839v3 [cs.LG] UPDATED)
73. Towards Generalizable Semantic Product Search by Text Similarity Pre-training on Search Click Logs. (arXiv:2204.05231v2 [cs.IR] UPDATED)
74. XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding. (arXiv:2204.07316v2 [cs.CL] UPDATED)
75. Stateless and Rule-Based Verification For Compliance Checking Applications. (arXiv:2204.07430v2 [cs.SE] UPDATED)
76. WikiOmnia: generative QA corpus on the whole Russian Wikipedia. (arXiv:2204.08009v2 [cs.CL] UPDATED)
77. KnowAugNet: Multi-Source Medical Knowledge Augmented Medication Prediction Network with Multi-Level Graph Contrastive Learning. (arXiv:2204.11736v2 [cs.AI] UPDATED)
78. Science Checker: Extractive-Boolean Question Answering For Scientific Fact Checking. (arXiv:2204.12263v2 [cs.CL] UPDATED)
79. Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering. (arXiv:2204.12496v2 [cs.LG] UPDATED)
80. On the Verification of Belief Programs. (arXiv:2204.12562v2 [cs.AI] UPDATED)
81. Toward Policy Explanations for Multi-Agent Reinforcement Learning. (arXiv:2204.12568v2 [cs.AI] UPDATED)
82. On the Relationship Between Explanations, Fairness Perceptions, and Decisions. (arXiv:2204.13156v2 [cs.HC] UPDATED)
83. Neural Label Search for Zero-Shot Multi-Lingual Extractive Summarization. (arXiv:2204.13512v2 [cs.CL] UPDATED)
84. Justice in Misinformation Detection Systems: An Analysis of Algorithms, Stakeholders, and Potential Harms. (arXiv:2204.13568v2 [cs.CY] UPDATED)

