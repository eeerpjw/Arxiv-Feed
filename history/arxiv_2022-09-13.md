# Your interest papers
---
## cs.CV
---
### **Real-time** event simulation with frame-based cameras. (arXiv:2209.04634v1 [cs.RO])
- Authors : Andreas Ziegler, Daniel Teigland, Jonas Tebbe, Thomas Gossard, Andreas Zell
- Link : [http://arxiv.org/abs/2209.04634](http://arxiv.org/abs/2209.04634)
> ABSTRACT  :  Event cameras are becoming increasingly popular in robotics and computer vision due to their beneficial properties, e.g., high temporal resolution, high bandwidth, almost no motion blur, and low power consumption. However, these cameras remain expensive and scarce in the market, making them inaccessible to the majority. Using event simulators minimizes the need for real event cameras to develop novel algorithms. However, due to the computational complexity of the simulation, the event streams of existing simulators cannot be generated in real-time but rather have to be pre-calculated from existing video sequences or pre-rendered and then simulated from a virtual 3D scene. Although these offline generated event streams can be used as training data for learning tasks, all response time dependent applications cannot benefit from these simulators yet, as they still require an actual event camera. This work proposes simulation methods that improve the performance of event simulation by two orders of magnitude (making them real-time capable) while remaining competitive in the quality assessment.  
### Large-Field Contextual Feature Learning for Glass Detection. (arXiv:2209.04639v1 [cs.CV])
- Authors : Haiyang Mei, Xin Yang, Letian Yu, Qiang Zhang, Xiaopeng Wei
- Link : [http://arxiv.org/abs/2209.04639](http://arxiv.org/abs/2209.04639)
> ABSTRACT  :  Glass is very common in our daily life. Existing computer vision systems neglect it and thus may have severe consequences, e.g., a robot may crash into a glass wall. However, sensing the presence of glass is not straightforward. The key challenge is that arbitrary objects/scenes can appear behind the glass. In this paper, we propose an important problem of detecting glass surfaces from a single RGB image. To address this problem, we construct the first large-scale glass detection dataset (GDD) and propose a novel glass detection network, called GDNet-B, which explores abundant contextual cues in a large field-of-view via a novel large-field contextual feature integration (LCFI) module and integrates both high-level and low-level boundary features with a boundary feature **enhancement** (BFE) module. Extensive experiments demonstrate that our GDNet-B achieves satisfying glass detection results on the images within and beyond the GDD testing set. We further validate the effectiveness and generalization capability of our proposed GDNet-B by applying it to other vision tasks, including mirror segmentation and salient object detection. Finally, we show the potential applications of glass detection and discuss possible future research directions.  
### Learning A Unified 3D Point Cloud for View Synthesis. (arXiv:2209.05013v1 [cs.CV])
- Authors : Meng You, Mantang Guo, Xianqiang Lyu, Hui Liu, Junhui Hou
- Link : [http://arxiv.org/abs/2209.05013](http://arxiv.org/abs/2209.05013)
> ABSTRACT  :  3D point cloud representation-based view synthesis methods have demonstrated effectiveness. However, existing methods usually synthesize novel views only from a single source view, and it is non-trivial to generalize them to handle multiple source views for pursuing higher reconstruction quality. In this paper, we propose a new deep learning-based view synthesis paradigm, which learns a unified 3D point cloud from different source views. Specifically, we first construct sub-point clouds by projecting source views to 3D space based on their depth maps. Then, we learn the unified 3D point cloud by adaptively fusing points at a local neighborhood defined on the union of the sub-point clouds. Besides, we also propose a 3D geometry-guided image **restoration** module to fill the holes and recover high-frequency details of the rendered novel views. Experimental results on three benchmark datasets demonstrate that our method outperforms state-of-the-art view synthesis methods to a large extent both quantitatively and visually.  
### Struct**NeRF**: Neural Radiance Fields for Indoor Scenes with Structural Hints. (arXiv:2209.05277v1 [cs.CV])
- Authors : Zheng Chen, Chen Wang, Chen Guo, Hai Zhang
- Link : [http://arxiv.org/abs/2209.05277](http://arxiv.org/abs/2209.05277)
> ABSTRACT  :  Neural Radiance Fields (**NeRF**) achieve photo-realistic view synthesis with densely captured input images. However, the geometry of **NeRF** is extremely under-constrained given sparse views, resulting in significant degradation of novel view synthesis quality. Inspired by self-supervised depth estimation methods, we propose Struct**NeRF**, a solution to novel view synthesis for indoor scenes with sparse inputs. Struct**NeRF** leverages the structural hints naturally embedded in multi-view inputs to handle the unconstrained geometry issue in **NeRF**. Specifically, it tackles the texture and non-texture regions respectively: a patch-based multi-view consistent photometric loss is proposed to constrain the geometry of textured regions; for non-textured ones, we explicitly restrict them to be 3D consistent planes. Through the dense self-supervised depth constraints, our method improves both the geometry and the view synthesis performance of **NeRF** without any additional training on external data. Extensive experiments on several real-world datasets demonstrate that Struct**NeRF** surpasses state-of-the-art methods for indoor scenes with sparse inputs both quantitatively and qualitatively.  
### Reinforcement Learning of Self Enhancing Camera Image and Signal Processing. (arXiv:2111.07499v2 [cs.CV] UPDATED)
- Authors : Chandrajit Bajaj, Yi Wang, Yunhao Yang
- Link : [http://arxiv.org/abs/2111.07499](http://arxiv.org/abs/2111.07499)
> ABSTRACT  :  Current camera image and signal processing pipelines (ISPs), including deep-trained versions, tend to apply a single filter that is uniformly applied to the entire image. This is despite the fact that most acquired camera images have spatially heterogeneous artifacts. This spatial heterogeneity manifests itself across the image space as varied Moire ringing, motion-blur, color-bleaching, or lens-based projection distortions. Moreover, combinations of these image artifacts can be present in small or large pixel neighborhoods, within an acquired image. Here, we present a deep reinforcement learning model that works in learned latent subspaces, and recursively improves camera image quality through a patch-based spatially adaptive artifact filtering and image **enhancement**. Our \textit{Recursive Self **Enhancement** Reinforcement Learning}(RSE-RL) model views the identification and correction of artifacts as a recursive self-learning and self-improvement exercise and consists of two major sub-modules: (i) The latent feature sub-space clustering/grouping obtained through variational auto-encoders enabling rapid identification of the correspondence and discrepancy between noisy and clean image patches. (ii) The adaptive learned transformation is controlled by a soft actor-critic agent that progressively filters and enhances the noisy patches using its closest feature distance neighbors of clean patches. Artificial artifacts that may be introduced in a patch-based ISP, are also removed through a reward-based de-blocking recovery and image **enhancement**. We demonstrate the self-improvement feature of our model by recursively training and testing on images, wherein the enhanced images resulting from each epoch provide a natural data augmentation and robustness to the RSE-RL training-filtering pipeline. Our method shows advantage for heterogeneous noise and artifact removal.  
### TALISMAN: Targeted Active Learning for Object Detection with Rare Classes and Slices using Submodular Mutual Information. (arXiv:2112.00166v2 [cs.CV] UPDATED)
- Authors : Suraj Kothawade, Saikat Ghosh, Sumit Shekhar, Yu Xiang, Rishabh Iyer
- Link : [http://arxiv.org/abs/2112.00166](http://arxiv.org/abs/2112.00166)
> ABSTRACT  :  Deep neural networks based object detectors have shown great success in a variety of domains like autonomous vehicles, biomedical imaging, etc. It is known that their success depends on a large amount of data from the domain of interest. While deep models often perform well in terms of overall accuracy, they often struggle in performance on rare yet critical data slices. For example, data slices like "motorcycle at **night**" or "bicycle at **night**" are often rare but very critical slices for self-driving applications and false negatives on such rare slices could result in ill-fated failures and accidents. Active learning (AL) is a well-known paradigm to incrementally and adaptively build training datasets with a human in the loop. However, current AL based acquisition functions are not well-equipped to tackle real-world datasets with rare slices, since they are based on uncertainty scores or global descriptors of the image. We propose TALISMAN, a novel framework for Targeted Active Learning or object detectIon with rare slices using Submodular MutuAl iNformation. Our method uses the submodular mutual information functions instantiated using features of the region of interest (RoI) to efficiently target and acquire data points with rare slices. We evaluate our framework on the standard PASCAL VOC07+12 and BDD100K, a real-world self-driving dataset. We observe that TALISMAN outperforms other methods by in terms of average precision on rare slices, and in terms of mAP.  
### Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v3 [eess.IV] UPDATED)
- Authors : Sibi Catley, Thomas Tanay, Lucas Vandroux, Gregory Slabaugh
- Link : [http://arxiv.org/abs/2201.02625](http://arxiv.org/abs/2201.02625)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is of fundamental importance in modern digital photography pipelines and used to produce a high-quality photograph with well exposed regions despite varying illumination across the image. This is typically achieved by merging multiple low dynamic range (LDR) images taken at different **exposure**s. However, over-exposed regions and misalignment errors due to poorly compensated motion result in artefacts such as ghosting. In this paper, we present a new **HDR** imaging technique that specifically models alignment and **exposure** uncertainties to produce high quality **HDR** results. We introduce a strategy that learns to jointly align and assess the alignment and **exposure** reliability using an **HDR**-aware, uncertainty-driven attention map that robustly merges the frames into a single high quality **HDR** image. Further, we introduce a progressive, multi-stage image fusion approach that can flexibly merge any number of LDR images in a permutation-invariant manner. Experimental results show our method can produce better quality **HDR** images with up to 1.1dB PSNR improvement to the state-of-the-art, and subjective improvements in terms of better detail, colours, and fewer artefacts.  
### Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v5 [cs.CV] UPDATED)
- Authors : Zhiyuan You, Kai Yang, Wenhan Luo, Xin Lu, Lei Cui, Xinyi Le
- Link : [http://arxiv.org/abs/2201.08959](http://arxiv.org/abs/2201.08959)
> ABSTRACT  :  This work studies the problem of few-shot object counting, which counts the number of exemplar objects (i.e., described by one or several support images) occurring in the query image. The major challenge lies in that the target objects can be densely packed in the query image, making it hard to recognize every single one. To tackle the obstacle, we propose a novel learning block, equipped with a similarity comparison module and a feature **enhancement** module. Concretely, given a support image and a query image, we first derive a score map by comparing their projected features at every spatial position. The score maps regarding all support images are collected together and normalized across both the exemplar dimension and the spatial dimensions, producing a reliable similarity map. We then enhance the query feature with the support features by employing the developed point-wise similarities as the weighting coefficients. Such a design encourages the model to inspect the query image by focusing more on the regions akin to the support images, leading to much clearer boundaries between different objects. Extensive experiments on various benchmarks and training setups suggest that we surpass the state-of-the-art methods by a sufficiently large margin. For instance, on a recent large-scale FSC-147 dataset, we surpass the state-of-the-art method by improving the mean absolute error from 22.08 to 14.32 (35%$\uparrow$). Code has been released in https://github.com/zhiyuanyou/SAFECount.  
### Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v2 [cs.CV] UPDATED)
- Authors : Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, Christian Claudel
- Link : [http://arxiv.org/abs/2203.03057](http://arxiv.org/abs/2203.03057)
> ABSTRACT  :  Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in **real time** of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen at https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo . Code is available at https://github.com/abduallahmohamed/Social-Implicit .  
### Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v3 [eess.IV] UPDATED)
- Authors : Dihan Zheng, Xiaowen Zhang, Kaisheng Ma, Chenglong Bao
- Link : [http://arxiv.org/abs/2204.10090](http://arxiv.org/abs/2204.10090)
> ABSTRACT  :  Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. Our approach is based on a carefully designed probabilistic graphical model in which the clean and corrupted data domains are conditionally independent. Using variational inference, we maximize the evidence lower bound (ELBO) to estimate the joint probability density function. Furthermore, we show that the ELBO is computable without paired samples under the inference invariant assumption. This property provides the mathematical rationale of our approach in the unpaired setting. Finally, we apply our method to real-world image denoising, super-resolution, and **low-light** image **enhancement** tasks and train the models using the synthetic data generated by the LUD-VAE. Experimental results validate the advantages of our method over other approaches.  
### UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v2 [cs.CV] UPDATED)
- Authors : Jihao Liu, Xin Huang, Guanglu Song, Hongsheng Li, Yu Liu
- Link : [http://arxiv.org/abs/2207.05420](http://arxiv.org/abs/2207.05420)
> ABSTRACT  :  Recently, transformer and multi-layer perceptron (MLP) architectures have achieved impressive results on various vision tasks. However, how to effectively combine those operators to form high-performance hybrid visual architectures still remains a challenge. In this work, we study the learnable combination of convolution, transformer, and MLP by proposing a novel unified architecture search approach. Our approach contains two key designs to achieve the search for high-performance networks. First, we model the very different searchable operators in a unified form, and thus enable the operators to be characterized with the same set of configuration parameters. In this way, the overall search space size is significantly reduced, and the total search cost becomes affordable. Second, we propose context-aware downsampling modules (DSMs) to mitigate the gap between the different types of operators. Our proposed DSMs are able to better adapt features from different types of operators, which is important for identifying high-performance hybrid architectures. Finally, we integrate configurable operators and DSMs into a unified search space and search with a Reinforcement Learning-based search algorithm to fully explore the optimal combination of the operators. To this end, we search a baseline network and scale it up to obtain a family of models, named UniNets, which achieve much better accuracy and efficiency than previous ConvNets and Transformers. In particular, our UniNet-B5 achieves 84.9% top-1 accuracy on ImageNet, outperforming EfficientNet-B7 and BoTNet-T7 with 44% and 55% fewer FLOPs respectively. By pretraining on the ImageNet-21K, our UniNet-B6 achieves 87.4%, outperforming **Swin**-L with 51% fewer FLOPs and 41% fewer parameters. Code is available at https://github.com/Sense-X/UniNet.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v5 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Hsuan Yang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved more impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedures and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm for improving the performance of the diffusion model. In this article, we present the first comprehensive review of existing variants of diffusion models. Specifically, we provide the first taxonomy of diffusion models and categorize them into three types: sampling-acceleration **enhancement**, likelihood-maximization **enhancement**, and data-generalization **enhancement**. We also introduce the other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models) in detail and clarify the connections between diffusion models and these generative models. Then we thoroughly investigate the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
### UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v2 [eess.IV] UPDATED)
- Authors : Xina Liu, Jinfan Hu, Xiangyu Chen, Chao Dong
- Link : [http://arxiv.org/abs/2209.01809](http://arxiv.org/abs/2209.01809)
> ABSTRACT  :  Under-Display Camera (UDC) has been widely exploited to help smartphones realize full screen display. However, as the screen could inevitably affect the light propagation process, the images captured by the UDC system usually contain flare, haze, blur, and noise. Particularly, flare and blur in UDC images could severely deteriorate the user experience in **high dynamic range** (**HDR**) scenes. In this paper, we propose a new deep model, namely UDC-UNet, to address the UDC image **restoration** problem with the known Point Spread Function (PSF) in **HDR** scenes. On the premise that Point Spread Function (PSF) of the UDC system is known, we treat UDC image **restoration** as a non-blind image **restoration** problem and propose a novel learning-based approach. Our network consists of three parts, including a U-shape base network to utilize multi-scale information, a condition branch to perform spatially variant modulation, and a kernel branch to provide the prior knowledge of the given PSF. According to the characteristics of **HDR** data, we additionally design a tone mapping loss to stabilize network optimization and achieve better visual quality. Experimental results show that the proposed UDC-UNet outperforms the state-of-the-art methods in quantitative and qualitative comparisons. Our approach won the second place in the UDC image **restoration** track of MIPI challenge. Codes will be publicly available.  
### The Outcome of the 2022 Landslide4Sense Competition: Advanced Landslide Detection from Multi-Source Satellite Imagery. (arXiv:2209.02556v2 [cs.CV] UPDATED)
- Authors : Omid Ghorbanzadeh, Yonghao Xu, Hengwei Zhao, Junjue Wang, Yanfei Zhong, Dong Zhao, Qi Zang, Shuang Wang, Fahong Zhang, Yilei Shi, Xiao Xiang, Lin Bai, Weile Li, Weihang Peng, Pedram Ghamisi
- Link : [http://arxiv.org/abs/2209.02556](http://arxiv.org/abs/2209.02556)
> ABSTRACT  :  The scientific outcomes of the 2022 Landslide4Sense (L4S) competition organized by the Institute of Advanced Research in Artificial Intelligence (IARAI) are presented here. The objective of the competition is to automatically detect landslides based on large-scale multiple sources of satellite imagery collected globally. The 2022 L4S aims to foster interdisciplinary research on recent developments in deep learning (DL) models for the semantic segmentation task using satellite imagery. In the past few years, DL-based models have achieved performance that meets expectations on image interpretation, due to the development of convolutional neural networks (CNNs). The main objective of this article is to present the details and the best-performing algorithms featured in this competition. The winning solutions are elaborated with state-of-the-art models like the **Swin** Transformer, SegFormer, and U-Net. Advanced machine learning techniques and strategies such as hard example mining, self-training, and mix-up data augmentation are also considered. Moreover, we describe the L4S benchmark data set in order to facilitate further comparisons, and report the results of the accuracy assessment online. The data is accessible on \textit{Future Development Leaderboard} for future evaluation at \url{https://www.iarai.ac.at/landslide4sense/challenge/}, and researchers are invited to submit more prediction results, evaluate the accuracy of their methods, compare them with those of other users, and, ideally, improve the landslide detection results reported in this article.  
## eess.IV
---
### Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v3 [eess.IV] UPDATED)
- Authors : Sibi Catley, Thomas Tanay, Lucas Vandroux, Gregory Slabaugh
- Link : [http://arxiv.org/abs/2201.02625](http://arxiv.org/abs/2201.02625)
> ABSTRACT  :  **High dynamic range** (**HDR**) imaging is of fundamental importance in modern digital photography pipelines and used to produce a high-quality photograph with well exposed regions despite varying illumination across the image. This is typically achieved by merging multiple low dynamic range (LDR) images taken at different **exposure**s. However, over-exposed regions and misalignment errors due to poorly compensated motion result in artefacts such as ghosting. In this paper, we present a new **HDR** imaging technique that specifically models alignment and **exposure** uncertainties to produce high quality **HDR** results. We introduce a strategy that learns to jointly align and assess the alignment and **exposure** reliability using an **HDR**-aware, uncertainty-driven attention map that robustly merges the frames into a single high quality **HDR** image. Further, we introduce a progressive, multi-stage image fusion approach that can flexibly merge any number of LDR images in a permutation-invariant manner. Experimental results show our method can produce better quality **HDR** images with up to 1.1dB PSNR improvement to the state-of-the-art, and subjective improvements in terms of better detail, colours, and fewer artefacts.  
### Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v3 [eess.IV] UPDATED)
- Authors : Dihan Zheng, Xiaowen Zhang, Kaisheng Ma, Chenglong Bao
- Link : [http://arxiv.org/abs/2204.10090](http://arxiv.org/abs/2204.10090)
> ABSTRACT  :  Collecting paired training data is difficult in practice, but the unpaired samples broadly exist. Current approaches aim at generating synthesized training data from unpaired samples by exploring the relationship between the corrupted and clean data. This work proposes LUD-VAE, a deep generative method to learn the joint probability density function from data sampled from marginal distributions. Our approach is based on a carefully designed probabilistic graphical model in which the clean and corrupted data domains are conditionally independent. Using variational inference, we maximize the evidence lower bound (ELBO) to estimate the joint probability density function. Furthermore, we show that the ELBO is computable without paired samples under the inference invariant assumption. This property provides the mathematical rationale of our approach in the unpaired setting. Finally, we apply our method to real-world image denoising, super-resolution, and **low-light** image **enhancement** tasks and train the models using the synthetic data generated by the LUD-VAE. Experimental results validate the advantages of our method over other approaches.  
### Predicting microsatellite instability and key biomarkers in colorectal cancer from H&E-stained images: Achieving SOTA predictive performance with fewer data using **Swin** Transformer. (arXiv:2208.10495v2 [q-bio.QM] UPDATED)
- Authors : Bangwei Guo, Xingyu Li, Jitendra Jonnagaddala, Hong Zhang, Xu Steven
- Link : [http://arxiv.org/abs/2208.10495](http://arxiv.org/abs/2208.10495)
> ABSTRACT  :  Artificial intelligence (AI) models have been developed for predicting clinically relevant biomarkers, including microsatellite instability (MSI), for colorectal cancers (CRC). However, the current deep-learning networks are data-hungry and require large training datasets, which are often lacking in the medical domain. In this study, based on the latest Hierarchical Vision Transformer using Shifted Windows (**Swin**-T), we developed an efficient workflow for biomarkers in CRC (MSI, hypermutation, chromosomal instability, CpG island methylator phenotype, BRAF, and TP53 mutation) that only required relatively small datasets, but achieved the state-of-the-art (SOTA) predictive performance. Our **Swin**-T workflow not only substantially outperformed published models in an intra-study cross-validation experiment using TCGA-CRC-DX dataset (N = 462), but also showed excellent generalizability in cross-study external validation and delivered a SOTA AUROC of 0.90 for MSI using the MCO dataset for training (N = 1065) and the same TCGA-CRC-DX for testing. Similar performance (AUROC=0.91) was achieved by Echle and colleagues using approximately 8000 training samples (ResNet18) on the same testing dataset. **Swin**-T was extremely efficient using small training datasets and exhibits robust predictive performance with only 200-500 training samples. These data indicate that **Swin**-T may be 5-10 times more efficient than the current state-of-the-art algorithms for MSI based on ResNet18 and ShuffleNet. Furthermore, the **Swin**-T models showed promise as pre-screening tests for MSI status and BRAF mutation status, which could exclude and reduce the samples before the subsequent standard testing in a cascading diagnostic workflow to allow turnaround time reduction and cost saving.  
### UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v2 [eess.IV] UPDATED)
- Authors : Xina Liu, Jinfan Hu, Xiangyu Chen, Chao Dong
- Link : [http://arxiv.org/abs/2209.01809](http://arxiv.org/abs/2209.01809)
> ABSTRACT  :  Under-Display Camera (UDC) has been widely exploited to help smartphones realize full screen display. However, as the screen could inevitably affect the light propagation process, the images captured by the UDC system usually contain flare, haze, blur, and noise. Particularly, flare and blur in UDC images could severely deteriorate the user experience in **high dynamic range** (**HDR**) scenes. In this paper, we propose a new deep model, namely UDC-UNet, to address the UDC image **restoration** problem with the known Point Spread Function (PSF) in **HDR** scenes. On the premise that Point Spread Function (PSF) of the UDC system is known, we treat UDC image **restoration** as a non-blind image **restoration** problem and propose a novel learning-based approach. Our network consists of three parts, including a U-shape base network to utilize multi-scale information, a condition branch to perform spatially variant modulation, and a kernel branch to provide the prior knowledge of the given PSF. According to the characteristics of **HDR** data, we additionally design a tone mapping loss to stabilize network optimization and achieve better visual quality. Experimental results show that the proposed UDC-UNet outperforms the state-of-the-art methods in quantitative and qualitative comparisons. Our approach won the second place in the UDC image **restoration** track of MIPI challenge. Codes will be publicly available.  
## cs.LG
---
### Deep Baseline Network for Time Series Modeling and Anomaly Detection. (arXiv:2209.04561v1 [cs.LG])
- Authors : Cheng Ge, Xi Chen, Ming Wang, Jin Wang
- Link : [http://arxiv.org/abs/2209.04561](http://arxiv.org/abs/2209.04561)
> ABSTRACT  :  Deep learning has seen increasing applications in time series in recent years. For time series anomaly detection scenarios, such as in finance, Internet of Things, data center operations, etc., time series usually show very flexible baselines depending on various external factors. Anomalies unveil themselves by lying far away from the baseline. However, the detection is not always easy due to some challenges including baseline shifting, lacking of labels, noise interference, **real time** detection in streaming data, result interpretability, etc. In this paper, we develop a novel deep architecture to properly extract the baseline from time series, namely Deep Baseline Network (DBLN). By using this deep network, we can easily locate the baseline position and then provide reliable and interpretable anomaly detection result. Empirical evaluation on both synthetic and public real-world datasets shows that our purely unsupervised algorithm achieves superior performance compared with state-of-art methods and has good practical applications.  
### TruVR: Trustworthy Cybersickness Detection using Explainable Machine Learning. (arXiv:2209.05257v1 [cs.HC])
- Authors : Ripan Kumar, Rifatul Islam, Prasad Calyam, Khaza Anuarul
- Link : [http://arxiv.org/abs/2209.05257](http://arxiv.org/abs/2209.05257)
> ABSTRACT  :  Cybersickness can be characterized by nausea, vertigo, headache, eye strain, and other discomforts when using virtual reality (VR) systems. The previously reported machine learning (ML) and deep learning (DL) algorithms for detecting (classification) and predicting (regression) VR cybersickness use black-box models; thus, they lack explainability. Moreover, VR sensors generate a massive amount of data, resulting in complex and large models. Therefore, having inherent explainability in cybersickness detection models can significantly improve the model's trustworthiness and provide insight into why and how the ML/DL model arrived at a specific decision. To address this issue, we present three explainable machine learning (xML) models to detect and predict cybersickness: 1) explainable boosting machine (EBM), 2) decision tree (DT), and 3) logistic regression (LR). We evaluate xML-based models with publicly available physiological and gameplay datasets for cybersickness. The results show that the EBM can detect cybersickness with an accuracy of 99.75% and 94.10% for the physiological and gameplay datasets, respectively. On the other hand, while predicting the cybersickness, EBM resulted in a Root Mean Square Error (RMSE) of 0.071 for the physiological dataset and 0.27 for the gameplay dataset. Furthermore, the EBM-based global explanation reveals **exposure** length, rotation, and acceleration as key features causing cybersickness in the gameplay dataset. In contrast, galvanic skin responses and heart rate are most significant in the physiological dataset. Our results also suggest that EBM-based local explanation can identify cybersickness-causing factors for individual samples. We believe the proposed xML-based cybersickness detection method can help future researchers understand, analyze, and design simpler cybersickness detection and reduction models.  
### Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v2 [cs.CV] UPDATED)
- Authors : Abduallah Mohamed, Deyao Zhu, Warren Vu, Mohamed Elhoseiny, Christian Claudel
- Link : [http://arxiv.org/abs/2203.03057](http://arxiv.org/abs/2203.03057)
> ABSTRACT  :  Best-of-N (BoN) Average Displacement Error (ADE)/ Final Displacement Error (FDE) is the most used metric for evaluating trajectory prediction models. Yet, the BoN does not quantify the whole generated samples, resulting in an incomplete view of the model's prediction quality and performance. We propose a new metric, Average Mahalanobis Distance (AMD) to tackle this issue. AMD is a metric that quantifies how close the whole generated samples are to the ground truth. We also introduce the Average Maximum Eigenvalue (AMV) metric that quantifies the overall spread of the predictions. Our metrics are validated empirically by showing that the ADE/FDE is not sensitive to distribution shifts, giving a biased sense of accuracy, unlike the AMD/AMV metrics. We introduce the usage of Implicit Maximum Likelihood Estimation (IMLE) as a replacement for traditional generative models to train our model, Social-Implicit. IMLE training mechanism aligns with AMD/AMV objective of predicting trajectories that are close to the ground truth with a tight spread. Social-Implicit is a memory efficient deep model with only 5.8K parameters that runs in **real time** of about 580Hz and achieves competitive results. Interactive demo of the problem can be seen at https://www.abduallahmohamed.com/social-implicit-amdamv-adefde-demo . Code is available at https://github.com/abduallahmohamed/Social-Implicit .  
### Predicting microsatellite instability and key biomarkers in colorectal cancer from H&E-stained images: Achieving SOTA predictive performance with fewer data using **Swin** Transformer. (arXiv:2208.10495v2 [q-bio.QM] UPDATED)
- Authors : Bangwei Guo, Xingyu Li, Jitendra Jonnagaddala, Hong Zhang, Xu Steven
- Link : [http://arxiv.org/abs/2208.10495](http://arxiv.org/abs/2208.10495)
> ABSTRACT  :  Artificial intelligence (AI) models have been developed for predicting clinically relevant biomarkers, including microsatellite instability (MSI), for colorectal cancers (CRC). However, the current deep-learning networks are data-hungry and require large training datasets, which are often lacking in the medical domain. In this study, based on the latest Hierarchical Vision Transformer using Shifted Windows (**Swin**-T), we developed an efficient workflow for biomarkers in CRC (MSI, hypermutation, chromosomal instability, CpG island methylator phenotype, BRAF, and TP53 mutation) that only required relatively small datasets, but achieved the state-of-the-art (SOTA) predictive performance. Our **Swin**-T workflow not only substantially outperformed published models in an intra-study cross-validation experiment using TCGA-CRC-DX dataset (N = 462), but also showed excellent generalizability in cross-study external validation and delivered a SOTA AUROC of 0.90 for MSI using the MCO dataset for training (N = 1065) and the same TCGA-CRC-DX for testing. Similar performance (AUROC=0.91) was achieved by Echle and colleagues using approximately 8000 training samples (ResNet18) on the same testing dataset. **Swin**-T was extremely efficient using small training datasets and exhibits robust predictive performance with only 200-500 training samples. These data indicate that **Swin**-T may be 5-10 times more efficient than the current state-of-the-art algorithms for MSI based on ResNet18 and ShuffleNet. Furthermore, the **Swin**-T models showed promise as pre-screening tests for MSI status and BRAF mutation status, which could exclude and reduce the samples before the subsequent standard testing in a cascading diagnostic workflow to allow turnaround time reduction and cost saving.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v5 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Runsheng Xu, Yue Zhao, Yingxia Shao, Wentao Zhang, Hsuan Yang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved more impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedures and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm for improving the performance of the diffusion model. In this article, we present the first comprehensive review of existing variants of diffusion models. Specifically, we provide the first taxonomy of diffusion models and categorize them into three types: sampling-acceleration **enhancement**, likelihood-maximization **enhancement**, and data-generalization **enhancement**. We also introduce the other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models) in detail and clarify the connections between diffusion models and these generative models. Then we thoroughly investigate the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## cs.AI
---
### Causal Intervention for Fairness in Multi-behavior Recommendation. (arXiv:2209.04589v1 [cs.IR])
- Authors : Xi Wang, Wenjie Wang, Fuli Feng, Wenge Rong, Chuantao Yin
- Link : [http://arxiv.org/abs/2209.04589](http://arxiv.org/abs/2209.04589)
> ABSTRACT  :  Recommender systems usually learn user interests from various user behaviors, including clicks and post-click behaviors (e.g., like and favorite). However, these behaviors inevitably exhibit popularity bias, leading to some unfairness issues: 1) for items with similar quality, more popular ones get more **exposure**; and 2) even worse the popular items with lower popularity might receive more **exposure**. Existing work on mitigating popularity bias blindly eliminates the bias and usually ignores the effect of item quality. We argue that the relationships between different user behaviors (e.g., conversion rate) actually reflect the item quality. Therefore, to handle the unfairness issues, we propose to mitigate the popularity bias by considering multiple user behaviors.    In this work, we examine causal relationships behind the interaction generation procedure in multi-behavior recommendation. Specifically, we find that: 1) item popularity is a confounder between the exposed items and users' post-click interactions, leading to the first unfairness; and 2) some hidden confounders (e.g., the reputation of item producers) affect both item popularity and quality, resulting in the second unfairness. To alleviate these confounding issues, we propose a causal framework to estimate the causal effect, which leverages backdoor adjustment to block the backdoor paths caused by the confounders. In the inference stage, we remove the negative effect of popularity and utilize the good effect of quality for recommendation. Experiments on two real-world datasets validate the effectiveness of our proposed framework, which enhances fairness without sacrificing recommendation accuracy.  
### UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v2 [cs.CV] UPDATED)
- Authors : Jihao Liu, Xin Huang, Guanglu Song, Hongsheng Li, Yu Liu
- Link : [http://arxiv.org/abs/2207.05420](http://arxiv.org/abs/2207.05420)
> ABSTRACT  :  Recently, transformer and multi-layer perceptron (MLP) architectures have achieved impressive results on various vision tasks. However, how to effectively combine those operators to form high-performance hybrid visual architectures still remains a challenge. In this work, we study the learnable combination of convolution, transformer, and MLP by proposing a novel unified architecture search approach. Our approach contains two key designs to achieve the search for high-performance networks. First, we model the very different searchable operators in a unified form, and thus enable the operators to be characterized with the same set of configuration parameters. In this way, the overall search space size is significantly reduced, and the total search cost becomes affordable. Second, we propose context-aware downsampling modules (DSMs) to mitigate the gap between the different types of operators. Our proposed DSMs are able to better adapt features from different types of operators, which is important for identifying high-performance hybrid architectures. Finally, we integrate configurable operators and DSMs into a unified search space and search with a Reinforcement Learning-based search algorithm to fully explore the optimal combination of the operators. To this end, we search a baseline network and scale it up to obtain a family of models, named UniNets, which achieve much better accuracy and efficiency than previous ConvNets and Transformers. In particular, our UniNet-B5 achieves 84.9% top-1 accuracy on ImageNet, outperforming EfficientNet-B7 and BoTNet-T7 with 44% and 55% fewer FLOPs respectively. By pretraining on the ImageNet-21K, our UniNet-B6 achieves 87.4%, outperforming **Swin**-L with 51% fewer FLOPs and 41% fewer parameters. Code is available at https://github.com/Sense-X/UniNet.  
# Paper List
---
## cs.CV
---
**134** new papers in cs.CV:-) 
1. Monkeypox virus detection using pre-trained deep learning-based approaches. (arXiv:2209.04444v1 [eess.IV])
2. Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection. (arXiv:2209.04445v1 [eess.IV])
3. MCIBI++: Soft Mining Contextual Information Beyond Image for Semantic Segmentation. (arXiv:2209.04471v1 [cs.CV])
4. Fine-grain Inference on Out-of-Distribution Data with Hierarchical Classification. (arXiv:2209.04493v1 [cs.LG])
5. General Place Recognition Survey: Towards the Real-world Autonomy Age. (arXiv:2209.04497v1 [cs.RO])
6. DeepSTI: Towards Tensor Reconstruction using Fewer Orientations in Susceptibility Tensor Imaging. (arXiv:2209.04504v1 [eess.IV])
7. Affinity-VAE for disentanglement, clustering and classification of objects in multidimensional image data. (arXiv:2209.04517v1 [cs.CV])
8. PoliTO-IIT-CINI Submission to the EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition. (arXiv:2209.04525v1 [cs.CV])
9. Sparsity-guided Network Design for Frame Interpolation. (arXiv:2209.04551v1 [cs.CV])
10. Self-supervised Human Mesh Recovery with Cross-Representation Alignment. (arXiv:2209.04596v1 [cs.CV])
11. Preserving Privacy in Federated Learning with Ensemble Cross-Domain Knowledge Distillation. (arXiv:2209.04599v1 [cs.CR])
12. Self-supervised Learning for Panoptic Segmentation of Multiple Fruit Flower Species. (arXiv:2209.04618v1 [cs.CV])
13. **Real-time** event simulation with frame-based cameras. (arXiv:2209.04634v1 [cs.RO])
14. Large-Field Contextual Feature Learning for Glass Detection. (arXiv:2209.04639v1 [cs.CV])
15. LSDNet: Trainable Modification of LSD Algorithm for Real-Time Line Segment Detection. (arXiv:2209.04642v1 [cs.CV])
16. An Interactive Automation for Human Biliary Tree Diagnosis Using Computer Vision. (arXiv:2209.04646v1 [eess.IV])
17. CoreDeep: Improving Crack Detection Algorithms Using Width Stochasticity. (arXiv:2209.04648v1 [cs.CV])
18. IR-LPR: Large Scale of Iranian License Plate Recognition Dataset. (arXiv:2209.04680v1 [cs.CV])
19. Explainable Image Quality Assessments in Teledermatological Photography. (arXiv:2209.04699v1 [cs.CV])
20. People detection and social distancing classification in smart cities for COVID-19 by using thermal images and deep learning algorithms. (arXiv:2209.04704v1 [cs.CV])
21. Anticipating the Unseen Discrepancy for Vision and Language Navigation. (arXiv:2209.04725v1 [cs.CV])
22. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v1 [cs.CV])
23. Scattering Model Guided Adversarial Examples for SAR Target Recognition: Attack and Defense. (arXiv:2209.04779v1 [cs.CV])
24. MAiVAR: Multimodal Audio-Image and Video Action Recognizer. (arXiv:2209.04780v1 [cs.CV])
25. Learning to diagnose common thorax diseases on chest radiographs from radiology reports in Vietnamese. (arXiv:2209.04794v1 [eess.IV])
26. Multiple Object Tracking in Recent Times: A Literature Review. (arXiv:2209.04796v1 [cs.CV])
27. Pathfinding in Random Partially Observable Environments with Vision-Informed Deep Reinforcement Learning. (arXiv:2209.04801v1 [cs.LG])
28. OAIR: Object-Aware Image Retargeting Using PSO and Aesthetic Quality Assessment. (arXiv:2209.04804v1 [cs.CV])
29. Lexicon and Attention based Handwritten Text Recognition System. (arXiv:2209.04817v1 [cs.CV])
30. Local-Aware Global Attention Network for Person Re-Identification. (arXiv:2209.04821v1 [cs.CV])
31. Continual Learning for Pose-Agnostic Object Recognition in 3D Point Clouds. (arXiv:2209.04840v1 [cs.CV])
32. Deep Lossy Plus Residual Coding for Lossless and Near-lossless Image Compression. (arXiv:2209.04847v1 [eess.IV])
33. OpenMixup: Open Mixup Toolbox and Benchmark for Visual Representation Learning. (arXiv:2209.04851v1 [cs.CV])
34. Inverse Image Frequency for Long-tailed Image Recognition. (arXiv:2209.04861v1 [cs.CV])
35. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v1 [cs.RO])
36. Automatic Detection of Sentimentality from Facial Expressions. (arXiv:2209.04908v1 [cs.CV])
37. Diversity and Novelty MasterPrints: Generating Multiple DeepMasterPrints for Increased User Coverage. (arXiv:2209.04909v1 [cs.CV])
38. Vec2Face-v2: Unveil Human Faces from their Blackbox Features via Attention-based Network in Face Recognition. (arXiv:2209.04920v1 [cs.CV])
39. Clifford Neural Layers for PDE Modeling. (arXiv:2209.04934v1 [cs.LG])
40. Synthetic Wavelength Imaging -- Utilizing Spectral Correlations for High-Precision Time-of-Flight Sensing. (arXiv:2209.04941v1 [physics.optics])
41. Learning When to Say "I Don't Know". (arXiv:2209.04944v1 [cs.CV])
42. Unsupervised Learning of 3D Scene Flow with 3D Odometry Assistance. (arXiv:2209.04945v1 [cs.CV])
43. Multi-modal Streaming 3D Object Detection. (arXiv:2209.04966v1 [cs.CV])
44. Switchable Online Knowledge Distillation. (arXiv:2209.04996v1 [cs.CV])
45. Learning A Unified 3D Point Cloud for View Synthesis. (arXiv:2209.05013v1 [cs.CV])
46. TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction. (arXiv:2209.05036v1 [eess.IV])
47. Predicting the Next Action by Modeling the Abstract Goal. (arXiv:2209.05044v1 [cs.CV])
48. Is Synthetic Dataset Reliable for Benchmarking Generalizable Person Re-Identification?. (arXiv:2209.05047v1 [cs.CV])
49. High-Fidelity Variable-Rate Image Compression via Invertible Activation Transformation. (arXiv:2209.05054v1 [eess.IV])
50. Situation Awareness for Automated Surgical Check-listing in AI-Assisted Operating Room. (arXiv:2209.05056v1 [cs.CV])
51. mmBody Benchmark: 3D Body Reconstruction Dataset and Analysis for Millimeter Wave Radar. (arXiv:2209.05070v1 [cs.CV])
52. BON: An extended public domain dataset for human activity recognition. (arXiv:2209.05077v1 [cs.CV])
53. Bayesian Learning for Disparity Map Refinement for Semi-Dense Active Stereo Vision. (arXiv:2209.05082v1 [cs.CV])
54. Reproducibility in machine learning for medical imaging. (arXiv:2209.05097v1 [cs.CV])
55. SELTO: Sample-Efficient Learned Topology Optimization. (arXiv:2209.05098v1 [cs.LG])
56. Data Augmentation by Selecting Mixed Classes Considering Distance Between Classes. (arXiv:2209.05122v1 [cs.CV])
57. HandMime: Sign Language Fingerspelling Acquisition via Imitation Learning. (arXiv:2209.05135v1 [cs.RO])
58. Prototypical few-shot segmentation for cross-institution male pelvic structures with spatial registration. (arXiv:2209.05160v1 [eess.IV])
59. Global Prototype Encoding for Incremental Video Highlights Detection. (arXiv:2209.05166v1 [cs.CV])
60. Attitude-Guided Loop Closure for Cameras with Negative Plane. (arXiv:2209.05167v1 [cs.CV])
61. Graphing the Future: Activity and Next Active Object Prediction using Graph-based Activity Representations. (arXiv:2209.05194v1 [cs.CV])
62. MetaNetwork: A Task-agnostic Network Parameters Generation Framework for Improving Device Model Generalization. (arXiv:2209.05227v1 [cs.DC])
63. Low rank prior and l0 norm to remove impulse noise in images. (arXiv:2209.05234v1 [cs.CV])
64. Style Variable and Irrelevant Learning for Generalizable Person Re-identification. (arXiv:2209.05235v1 [cs.CV])
65. $\beta$-CapsNet: Learning Disentangled Representation for CapsNet by Information Bottleneck. (arXiv:2209.05239v1 [cs.CV])
66. Adaptive Perturbation Generation for Multiple Backdoors Detection. (arXiv:2209.05244v1 [cs.CV])
67. TrackletMapper: Ground Surface Segmentation and Mapping from Traffic Participant Trajectories. (arXiv:2209.05247v1 [cs.RO])
68. Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks. (arXiv:2209.05251v1 [cs.CV])
69. ErgoExplorer: Interactive Ergonomic Risk Assessment from Video Collections. (arXiv:2209.05252v1 [cs.CV])
70. Transfer Learning and Vision Transformer based State-of-Health prediction of Lithium-Ion Batteries. (arXiv:2209.05253v1 [cs.CV])
71. Detecting Driver Drowsiness as an Anomaly Using LSTM Autoencoders. (arXiv:2209.05269v1 [cs.CV])
72. Struct**NeRF**: Neural Radiance Fields for Indoor Scenes with Structural Hints. (arXiv:2209.05277v1 [cs.CV])
73. Exploring Simple and Transferable Recognition-Aware Image Processing. (arXiv:1910.09185v4 [cs.CV] UPDATED)
74. LIAAD: Lightweight Attentive Angular Distillation for Large-scale Age-Invariant Face Recognition. (arXiv:2004.05085v2 [cs.CV] UPDATED)
75. The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v6 [cs.CV] UPDATED)
76. Hierarchical Amortized Training for Memory-efficient High Resolution 3D GAN. (arXiv:2008.01910v4 [eess.IV] UPDATED)
77. Memory-Augmented Reinforcement Learning for Image-Goal Navigation. (arXiv:2101.05181v5 [cs.CV] UPDATED)
78. GRNN: Generative Regression Neural Network -- A Data Leakage Attack for Federated Learning. (arXiv:2105.00529v3 [cs.LG] UPDATED)
79. Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization. (arXiv:2105.05612v3 [cs.LG] UPDATED)
80. Context-Aware Mixup for Domain Adaptive Semantic Segmentation. (arXiv:2108.03557v3 [cs.CV] UPDATED)
81. Domain Adaptive Semantic Segmentation via Regional Contrastive Consistency Regularization. (arXiv:2110.05170v3 [cs.CV] UPDATED)
82. TPSNet: Reverse Thinking of Thin Plate Splines for Arbitrary Shape Scene Text Representation. (arXiv:2110.12826v2 [cs.CV] UPDATED)
83. Iterative Teaching by Label Synthesis. (arXiv:2110.14432v4 [cs.LG] UPDATED)
84. Reinforcement Learning of Self Enhancing Camera Image and Signal Processing. (arXiv:2111.07499v2 [cs.CV] UPDATED)
85. Low Precision Decentralized Distributed Training over IID and non-IID Data. (arXiv:2111.09389v3 [cs.LG] UPDATED)
86. Self-slimmed Vision Transformer. (arXiv:2111.12624v3 [cs.CV] UPDATED)
87. TALISMAN: Targeted Active Learning for Object Detection with Rare Classes and Slices using Submodular Mutual Information. (arXiv:2112.00166v2 [cs.CV] UPDATED)
88. Embedding Gradient-based Optimization in Image Registration Networks. (arXiv:2112.03915v2 [eess.IV] UPDATED)
89. Towards Unsupervised Open World Semantic Segmentation. (arXiv:2201.01073v2 [cs.CV] UPDATED)
90. Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v3 [eess.IV] UPDATED)
91. Few-shot Object Counting with Similarity-Aware Feature **Enhancement**. (arXiv:2201.08959v5 [cs.CV] UPDATED)
92. AttentionHTR: Handwritten Text Recognition Based on Attention Encoder-Decoder Networks. (arXiv:2201.09390v3 [cs.CV] UPDATED)
93. CortexODE: Learning Cortical Surface Reconstruction by Neural ODEs. (arXiv:2202.08329v2 [eess.IV] UPDATED)
94. Statistical and Topological Summaries Aid Disease Detection for Segmented Retinal Vascular Images. (arXiv:2202.09708v3 [q-bio.QM] UPDATED)
95. A Principled Design of Image Representation: Towards Forensic Tasks. (arXiv:2203.00913v3 [cs.CV] UPDATED)
96. Detecting Adversarial Perturbations in Multi-Task Perception. (arXiv:2203.01177v2 [cs.CV] UPDATED)
97. Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v2 [cs.CV] UPDATED)
98. Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training. (arXiv:2203.08959v3 [cs.LG] UPDATED)
99. Inferring Articulated Rigid Body Dynamics from RGBD Video. (arXiv:2203.10488v2 [cs.RO] UPDATED)
100. Learning from All Vehicles. (arXiv:2203.11934v3 [cs.RO] UPDATED)
101. An Improved Lightweight YOLOv5 Model Based on Attention Mechanism for Face Mask Detection. (arXiv:2203.16506v3 [cs.CV] UPDATED)
102. Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v2 [cs.LG] UPDATED)
103. Class-Incremental Learning with Strong Pre-trained Models. (arXiv:2204.03634v2 [cs.CV] UPDATED)
104. Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v3 [eess.IV] UPDATED)
105. Do Neural Networks Compress Manifolds Optimally?. (arXiv:2205.08518v2 [cs.IT] UPDATED)
106. Sparse MDOD: Training End-to-End Multi-Object Detector without Bipartite Matching. (arXiv:2205.08714v2 [cs.CV] UPDATED)
107. Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors. (arXiv:2205.13618v2 [cs.CV] UPDATED)
108. Semantic-aware Dense Representation Learning for Remote Sensing Image Change Detection. (arXiv:2205.13769v2 [cs.CV] UPDATED)
109. Long-tailed Recognition by Learning from Latent Categories. (arXiv:2206.01010v3 [cs.CV] UPDATED)
110. Robust Image Protection Countering Cropping Manipulation. (arXiv:2206.02405v2 [eess.IV] UPDATED)
111. SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving. (arXiv:2206.14116v3 [cs.CV] UPDATED)
112. Dynamic boxes fusion strategy in object detection. (arXiv:2207.00997v3 [cs.CV] UPDATED)
113. UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v2 [cs.CV] UPDATED)
114. Parameterization of Cross-Token Relations with Relative Positional Encoding for Vision MLP. (arXiv:2207.07284v2 [cs.CV] UPDATED)
115. TokenMix: Rethinking Image Mixing for Data Augmentation in Vision Transformers. (arXiv:2207.08409v2 [cs.CV] UPDATED)
116. Balanced Contrastive Learning for Long-Tailed Visual Recognition. (arXiv:2207.09052v3 [cs.CV] UPDATED)
117. Generative Domain Adaptation for Face Anti-Spoofing. (arXiv:2207.10015v2 [cs.CV] UPDATED)
118. A novel deep learning-based approach for sleep apnea detection using single-lead ECG signals. (arXiv:2208.03408v2 [cs.CV] UPDATED)
119. Adaptive Joint Optimization for 3D Reconstruction with Differentiable Rendering. (arXiv:2208.07003v2 [cs.CV] UPDATED)
120. One-shot Generative Prior in Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v3 [eess.IV] UPDATED)
121. Unifying Visual Perception by Dispersible Points Learning. (arXiv:2208.08630v2 [cs.CV] UPDATED)
122. Masked Video Modeling with Correlation-aware Contrastive Learning for Breast Cancer Diagnosis in Ultrasound. (arXiv:2208.09881v3 [cs.CV] UPDATED)
123. Multiresolution Neural Networks for Imaging. (arXiv:2208.11813v3 [cs.CV] UPDATED)
124. Towards Robust Face Recognition with Comprehensive Search. (arXiv:2208.13600v2 [cs.CV] UPDATED)
125. Treating Point Cloud as Moving Camera Videos: A No-Reference Quality Assessment Metric. (arXiv:2208.14085v2 [cs.CV] UPDATED)
126. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v5 [cs.LG] UPDATED)
127. UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v2 [eess.IV] UPDATED)
128. ScaleFace: Uncertainty-aware Deep Metric Learning. (arXiv:2209.01880v2 [cs.CV] UPDATED)
129. CAMO-MOT: Combined Appearance-Motion Optimization for 3D Multi-Object Tracking with Camera-LiDAR Fusion. (arXiv:2209.02540v3 [cs.CV] UPDATED)
130. The Outcome of the 2022 Landslide4Sense Competition: Advanced Landslide Detection from Multi-Source Satellite Imagery. (arXiv:2209.02556v2 [cs.CV] UPDATED)
131. Measuring Human Perception to Improve Open Set Recognition. (arXiv:2209.03519v2 [cs.CV] UPDATED)
132. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v2 [eess.IV] UPDATED)
133. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v3 [eess.IV] UPDATED)
134. TEACH: Temporal Action Composition for 3D Humans. (arXiv:2209.04066v2 [cs.CV] UPDATED)
## eess.IV
---
**32** new papers in eess.IV:-) 
1. Monkeypox virus detection using pre-trained deep learning-based approaches. (arXiv:2209.04444v1 [eess.IV])
2. Privacy-Preserving Deep Learning Model for Covid-19 Disease Detection. (arXiv:2209.04445v1 [eess.IV])
3. Learning sparse auto-encoders for green AI image coding. (arXiv:2209.04448v1 [eess.IV])
4. A detail-enhanced sampling strategy in Hadamard single-pixel imaging. (arXiv:2209.04449v1 [eess.IV])
5. DeepSTI: Towards Tensor Reconstruction using Fewer Orientations in Susceptibility Tensor Imaging. (arXiv:2209.04504v1 [eess.IV])
6. An Interactive Automation for Human Biliary Tree Diagnosis Using Computer Vision. (arXiv:2209.04646v1 [eess.IV])
7. People detection and social distancing classification in smart cities for COVID-19 by using thermal images and deep learning algorithms. (arXiv:2209.04704v1 [cs.CV])
8. Learning to diagnose common thorax diseases on chest radiographs from radiology reports in Vietnamese. (arXiv:2209.04794v1 [eess.IV])
9. Deep Lossy Plus Residual Coding for Lossless and Near-lossless Image Compression. (arXiv:2209.04847v1 [eess.IV])
10. TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction. (arXiv:2209.05036v1 [eess.IV])
11. High-Fidelity Variable-Rate Image Compression via Invertible Activation Transformation. (arXiv:2209.05054v1 [eess.IV])
12. BON: An extended public domain dataset for human activity recognition. (arXiv:2209.05077v1 [cs.CV])
13. Prototypical few-shot segmentation for cross-institution male pelvic structures with spatial registration. (arXiv:2209.05160v1 [eess.IV])
14. Low rank prior and l0 norm to remove impulse noise in images. (arXiv:2209.05234v1 [cs.CV])
15. Continual learning benefits from multiple sleep mechanisms: NREM, REM, and Synaptic Downscaling. (arXiv:2209.05245v1 [cs.NE])
16. Adaptive 3D Localization of 2D Freehand Ultrasound Brain Images. (arXiv:2209.05477v1 [eess.IV])
17. Fully-automated patient-level malaria assessment on field-prepared thin blood film microscopy images, including Supplementary Information. (arXiv:1908.01901v2 [cs.LG] UPDATED)
18. Hierarchical Amortized Training for Memory-efficient High Resolution 3D GAN. (arXiv:2008.01910v4 [eess.IV] UPDATED)
19. Embedding Gradient-based Optimization in Image Registration Networks. (arXiv:2112.03915v2 [eess.IV] UPDATED)
20. Flex**HDR**: Modelling Alignment and **Exposure** Uncertainties for Flexible **HDR** Imaging. (arXiv:2201.02625v3 [eess.IV] UPDATED)
21. Validation and Generalizability of Self-Supervised Image Reconstruction Methods for Undersampled MRI. (arXiv:2201.12535v3 [eess.IV] UPDATED)
22. CortexODE: Learning Cortical Surface Reconstruction by Neural ODEs. (arXiv:2202.08329v2 [eess.IV] UPDATED)
23. A crowdsourcing approach to video quality assessment. (arXiv:2204.06784v2 [eess.IV] UPDATED)
24. Learn from Unpaired Data for Image **Restoration**: A Variational Bayes Approach. (arXiv:2204.10090v3 [eess.IV] UPDATED)
25. Robust Image Protection Countering Cropping Manipulation. (arXiv:2206.02405v2 [eess.IV] UPDATED)
26. One-shot Generative Prior in Hankel-k-space for Parallel Imaging Reconstruction. (arXiv:2208.07181v3 [eess.IV] UPDATED)
27. Predicting microsatellite instability and key biomarkers in colorectal cancer from H&E-stained images: Achieving SOTA predictive performance with fewer data using **Swin** Transformer. (arXiv:2208.10495v2 [q-bio.QM] UPDATED)
28. Treating Point Cloud as Moving Camera Videos: A No-Reference Quality Assessment Metric. (arXiv:2208.14085v2 [cs.CV] UPDATED)
29. Joint Demosaicing and Fusion of Multiresolution Compressed Acquisitions: Image Formation and Reconstruction Methods. (arXiv:2209.01455v2 [eess.IV] UPDATED)
30. UDC-UNet: Under-Display Camera Image **Restoration** via U-Shape Dynamic Network. (arXiv:2209.01809v2 [eess.IV] UPDATED)
31. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v2 [eess.IV] UPDATED)
32. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v3 [eess.IV] UPDATED)
## cs.LG
---
**182** new papers in cs.LG:-) 
1. Monkeypox virus detection using pre-trained deep learning-based approaches. (arXiv:2209.04444v1 [eess.IV])
2. Hybrid Supervised and Reinforcement Learning for the Design and Optimization of Nanophotonic Structures. (arXiv:2209.04447v1 [cs.LG])
3. Learning sparse auto-encoders for green AI image coding. (arXiv:2209.04448v1 [eess.IV])
4. Fine-grain Inference on Out-of-Distribution Data with Hierarchical Classification. (arXiv:2209.04493v1 [cs.LG])
5. DeepSTI: Towards Tensor Reconstruction using Fewer Orientations in Susceptibility Tensor Imaging. (arXiv:2209.04504v1 [eess.IV])
6. Deep Learning with Non-Linear Factor Models: Adaptability and Avoidance of Curse of Dimensionality. (arXiv:2209.04512v1 [stat.ML])
7. Affinity-VAE for disentanglement, clustering and classification of objects in multidimensional image data. (arXiv:2209.04517v1 [cs.CV])
8. The Space of Adversarial Strategies. (arXiv:2209.04521v1 [cs.CR])
9. Gluformer: Transformer-Based Personalized Glucose Forecasting with Uncertainty Quantification. (arXiv:2209.04526v1 [cs.LG])
10. Improving Model Training via Self-learned Label Representations. (arXiv:2209.04528v1 [cs.LG])
11. Defend Data Poisoning Attacks on Voice Authentication. (arXiv:2209.04547v1 [cs.CR])
12. Deep Baseline Network for Time Series Modeling and Anomaly Detection. (arXiv:2209.04561v1 [cs.LG])
13. The Bayan Algorithm: Detecting Communities in Networks Through Exact and Approximate Optimization of Modularity. (arXiv:2209.04562v1 [cs.SI])
14. Explaining Results of Multi-Criteria Decision Making. (arXiv:2209.04582v1 [cs.AI])
15. Bayesian Algorithm Execution for Tuning Particle Accelerator Emittance with Partial Measurements. (arXiv:2209.04587v1 [physics.acc-ph])
16. Extended Feature Space-Based Automatic Melanoma Detection System. (arXiv:2209.04588v1 [cs.LG])
17. Unsupervised Domain Adaptation for Extra Features in the Target Domain Using Optimal Transport. (arXiv:2209.04594v1 [cs.LG])
18. Preserving Privacy in Federated Learning with Ensemble Cross-Domain Knowledge Distillation. (arXiv:2209.04599v1 [cs.CR])
19. Accelerated Primal-Dual Methods for Convex-Strongly-Concave Saddle Point Problems. (arXiv:2209.04604v1 [math.OC])
20. Gradient Descent Temporal Difference-difference Learning. (arXiv:2209.04624v1 [cs.LG])
21. A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis. (arXiv:2209.04635v1 [cs.LG])
22. Revisiting Active Sets for Gaussian Process Decoders. (arXiv:2209.04636v1 [stat.ML])
23. Examining stability of machine learning methods for predicting dementia at early phases of the disease. (arXiv:2209.04643v1 [cs.LG])
24. An Interactive Automation for Human Biliary Tree Diagnosis Using Computer Vision. (arXiv:2209.04646v1 [eess.IV])
25. Application of Machine Learning for Online Reputation Systems. (arXiv:2209.04650v1 [cs.LG])
26. Ask Before You Act: Generalising to Novel Environments by Asking Questions. (arXiv:2209.04665v1 [cs.AI])
27. Simple and Effective Gradient-Based Tuning of Sequence-to-Sequence Models. (arXiv:2209.04683v1 [cs.CL])
28. Reconstruction of Long-Term Historical Demand Data. (arXiv:2209.04693v1 [cs.LG])
29. Symbolic Knowledge Extraction from Opaque Predictors Applied to Cosmic-Ray Data Gathered with LISA Pathfinder. (arXiv:2209.04697v1 [astro-ph.HE])
30. Structured Q-learning For Antibody Design. (arXiv:2209.04698v1 [cs.LG])
31. Explainable Image Quality Assessments in Teledermatological Photography. (arXiv:2209.04699v1 [cs.CV])
32. People detection and social distancing classification in smart cities for COVID-19 by using thermal images and deep learning algorithms. (arXiv:2209.04704v1 [cs.CV])
33. Shape Analysis for Pediatric Upper Body Motor Function Assessment. (arXiv:2209.04710v1 [cs.LG])
34. Variational Autoencoder Kernel Interpretation and Selection for Classification. (arXiv:2209.04715v1 [cs.LG])
35. Batch Bayesian Optimization via Particle Gradient Flows. (arXiv:2209.04722v1 [stat.ML])
36. Data-driven, multi-moment fluid modeling of Landau damping. (arXiv:2209.04726v1 [physics.plasm-ph])
37. A Thermal Machine Learning Solver For Chip Simulation. (arXiv:2209.04741v1 [cs.LG])
38. Active Learning for Optimal Intervention Design in Causal Models. (arXiv:2209.04744v1 [cs.LG])
39. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v1 [cs.CV])
40. Towards Sparsification of Graph Neural Networks. (arXiv:2209.04766v1 [cs.LG])
41. Analyzing Wearables Dataset to Predict ADLs and Falls: A Pilot Study. (arXiv:2209.04785v1 [cs.LG])
42. Temporal Pattern Mining for Analysis of Longitudinal Clinical Data: Identifying Risk Factors for Alzheimer's Disease. (arXiv:2209.04793v1 [cs.LG])
43. Pathfinding in Random Partially Observable Environments with Vision-Informed Deep Reinforcement Learning. (arXiv:2209.04801v1 [cs.LG])
44. Examining Uniqueness and Permanence of the WAY EEG GAL dataset toward User Authentication. (arXiv:2209.04802v1 [cs.LG])
45. Efficiency Evaluation of Banks with Many Branches using a Heuristic Framework and Dynamic Data Envelopment Optimization Approach: A Real Case Study. (arXiv:2209.04822v1 [math.OC])
46. Rethink Decision Tree Traversal. (arXiv:2209.04825v1 [cs.LG])
47. Git Re-Basin: Merging Models modulo Permutation Symmetries. (arXiv:2209.04836v1 [cs.LG])
48. Performance-Driven Controller Tuning via Derivative-Free Reinforcement Learning. (arXiv:2209.04854v1 [eess.SY])
49. Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models. (arXiv:2209.04862v1 [cs.LG])
50. An Improved Algorithm For Online Reranking. (arXiv:2209.04870v1 [cs.DS])
51. Data-Driven Blind Synchronization and Interference Rejection for Digital Communication Signals. (arXiv:2209.04871v1 [eess.SP])
52. Subquadratic Kronecker Regression with Applications to Tensor Decomposition. (arXiv:2209.04876v1 [cs.DS])
53. On The Computational Complexity of Self-Attention. (arXiv:2209.04881v1 [cs.LG])
54. A Complex Network based Graph Embedding Method for Link Prediction. (arXiv:2209.04884v1 [cs.LG])
55. "Calibeating": Beating Forecasters at Their Own Game. (arXiv:2209.04892v1 [econ.TH])
56. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v1 [cs.RO])
57. Resisting Deep Learning Models Against Adversarial Attack Transferability via Feature Randomization. (arXiv:2209.04930v1 [cs.CR])
58. Dimensionality Reduction using Elastic Measures. (arXiv:2209.04933v1 [cs.LG])
59. Clifford Neural Layers for PDE Modeling. (arXiv:2209.04934v1 [cs.LG])
60. Learning Consumer Preferences from Bundle Sales Data. (arXiv:2209.04942v1 [stat.ML])
61. Learning When to Say "I Don't Know". (arXiv:2209.04944v1 [cs.CV])
62. Kernel Learning for Explainable Climate Science. (arXiv:2209.04947v1 [cs.LG])
63. Efficient Approximate Kernel Based Spike Sequence Classification. (arXiv:2209.04952v1 [cs.LG])
64. A novel learning-based robust model predictive control energy management strategy for fuel cell electric vehicles. (arXiv:2209.04995v1 [cs.SY])
65. An Investigation of Smart Contract for Collaborative Machine Learning Model Training. (arXiv:2209.05017v1 [cs.LG])
66. Graph Polynomial Convolution Models for Node Classification of Non-Homophilous Graphs. (arXiv:2209.05020v1 [cs.LG])
67. Vision Transformer with Convolutional Encoder-Decoder for Hand Gesture Recognition using 24 GHz Doppler Radar. (arXiv:2209.05032v1 [eess.SP])
68. TMSS: An End-to-End Transformer-based Multimodal Network for Segmentation and Survival Prediction. (arXiv:2209.05036v1 [eess.IV])
69. On the Optimization Landscape of Dynamic Output Feedback: A Case Study for Linear Quadratic Regulator. (arXiv:2209.05042v1 [cs.LG])
70. Gradient-Free Methods for Deterministic and Stochastic Nonsmooth Nonconvex Optimization. (arXiv:2209.05045v1 [math.OC])
71. Hyperbolic Self-supervised Contrastive Learning Based Network Anomaly Detection. (arXiv:2209.05049v1 [cs.SI])
72. CARE: Certifiably Robust Learning with Reasoning via Variational Inference. (arXiv:2209.05055v1 [cs.LG])
73. Explaining Predictions from Machine Learning Models: Algorithms, Users, and Pedagogy. (arXiv:2209.05084v1 [cs.LG])
74. Bilevel Optimization for Feature Selection in the Data-Driven Newsvendor Problem. (arXiv:2209.05093v1 [cs.LG])
75. Reproducibility in machine learning for medical imaging. (arXiv:2209.05097v1 [cs.CV])
76. SELTO: Sample-Efficient Learned Topology Optimization. (arXiv:2209.05098v1 [cs.LG])
77. Bias Challenges in Counterfactual Data Augmentation. (arXiv:2209.05104v1 [cs.LG])
78. Ordinal Graph Gamma Belief Network for Social Recommender Systems. (arXiv:2209.05106v1 [cs.IR])
79. On topological data analysis for structural dynamics: an introduction to persistent homology. (arXiv:2209.05134v1 [stat.ML])
80. HandMime: Sign Language Fingerspelling Acquisition via Imitation Learning. (arXiv:2209.05135v1 [cs.RO])
81. A Comparative Study of Classical and Quantum Machine Learning Models for Sentimental Analysis. (arXiv:2209.05142v1 [quant-ph])
82. Personalized Federated Learning with Communication Compression. (arXiv:2209.05148v1 [cs.LG])
83. Bounding The Rademacher Complexity of Fourier Neural Operator. (arXiv:2209.05150v1 [cs.LG])
84. Detecting Network-based Internet Censorship via Latent Feature Representation Learning. (arXiv:2209.05152v1 [cs.LG])
85. Statistical Estimation of Confounded Linear MDPs: An Instrumental Variable Approach. (arXiv:2209.05186v1 [stat.ML])
86. A Note on the Efficient Evaluation of PAC-Bayes Bounds. (arXiv:2209.05188v1 [cs.LG])
87. A Differentiable Loss Function for Learning Heuristics in A*. (arXiv:2209.05206v1 [cs.LG])
88. Graph Neural Modeling of Network Flows. (arXiv:2209.05208v1 [cs.LG])
89. Amortised Inference in Structured Generative Models with Explaining Away. (arXiv:2209.05212v1 [cs.LG])
90. SmartKex: Machine Learning Assisted SSH Keys Extraction From The Heap Dump. (arXiv:2209.05243v1 [cs.CR])
91. Continual learning benefits from multiple sleep mechanisms: NREM, REM, and Synaptic Downscaling. (arXiv:2209.05245v1 [cs.NE])
92. Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks. (arXiv:2209.05251v1 [cs.CV])
93. TruVR: Trustworthy Cybersickness Detection using Explainable Machine Learning. (arXiv:2209.05257v1 [cs.HC])
94. Fairness in Forecasting of Observations of Linear Dynamical Systems. (arXiv:2209.05274v1 [cs.LG])
95. A Nonparametric Contextual Bandit with Arm-level Eligibility Control for Customer Service Routing. (arXiv:2209.05278v1 [cs.LG])
96. Optimal mesh generation for a blade passage using deep reinforcement learning. (arXiv:2209.05280v1 [cs.LG])
97. Modeling Dependent Structure for Utterances in ASR Evaluation. (arXiv:2209.05281v1 [eess.AS])
98. Fully-automated patient-level malaria assessment on field-prepared thin blood film microscopy images, including Supplementary Information. (arXiv:1908.01901v2 [cs.LG] UPDATED)
99. Exploring Simple and Transferable Recognition-Aware Image Processing. (arXiv:1910.09185v4 [cs.CV] UPDATED)
100. Gradient-Free Methods for Saddle-Point Problem. (arXiv:2005.05913v4 [math.OC] UPDATED)
101. A Deterministic Approximation to Neural SDEs. (arXiv:2006.08973v6 [cs.LG] UPDATED)
102. The shape and simplicity biases of adversarially robust ImageNet-trained CNNs. (arXiv:2006.09373v6 [cs.CV] UPDATED)
103. SoK: Certified Robustness for Deep Neural Networks. (arXiv:2009.04131v8 [cs.LG] UPDATED)
104. Monitoring of functional profiles combining the notion of Fr\'echet mean and the framework of deformation models with application in ambient air pollution surveillance. (arXiv:2010.02968v2 [stat.ME] UPDATED)
105. Solving non-linear Kolmogorov equations in large dimensions by using deep learning: a numerical comparison of discretization schemes. (arXiv:2012.07747v3 [math.NA] UPDATED)
106. Model-Based Deep Learning. (arXiv:2012.08405v3 [eess.SP] UPDATED)
107. Stochastic Compositional Gradient Descent under Compositional Constraints. (arXiv:2012.09400v4 [cs.LG] UPDATED)
108. Exploration and Incentives in Reinforcement Learning. (arXiv:2103.00360v3 [cs.LG] UPDATED)
109. Two-step reinforcement learning for model-free redesign of nonlinear optimal regulator. (arXiv:2103.03808v2 [eess.SY] UPDATED)
110. On the Stability of Nonlinear Receding Horizon Control: A Geometric Perspective. (arXiv:2103.15010v2 [math.OC] UPDATED)
111. Fast Regression of the Tritium Breeding Ratio in Fusion Reactors. (arXiv:2104.04026v2 [physics.comp-ph] UPDATED)
112. Robust Uncertainty Bounds in Reproducing Kernel Hilbert Spaces: A Convex Optimization Approach. (arXiv:2104.09582v3 [cs.LG] UPDATED)
113. GRNN: Generative Regression Neural Network -- A Data Leakage Attack for Federated Learning. (arXiv:2105.00529v3 [cs.LG] UPDATED)
114. Evading the Simplicity Bias: Training a Diverse Set of Models Discovers Solutions with Superior OOD Generalization. (arXiv:2105.05612v3 [cs.LG] UPDATED)
115. Free Energy Node Embedding via Generalized Skip-gram with Negative Sampling. (arXiv:2105.09182v2 [cs.LG] UPDATED)
116. Exploring Autoencoder-based Error-bounded Compression for Scientific Data. (arXiv:2105.11730v6 [cs.LG] UPDATED)
117. Memorization and Generalization in Neural Code Intelligence Models. (arXiv:2106.08704v3 [cs.LG] UPDATED)
118. Robust Adaptive Submodular Maximization. (arXiv:2107.11333v4 [cs.DS] UPDATED)
119. $\mu$DARTS: Model Uncertainty-Aware Differentiable Architecture Search. (arXiv:2107.11500v2 [cs.LG] UPDATED)
120. On the Hyperparameters in Stochastic Gradient Descent with Momentum. (arXiv:2108.03947v2 [cs.LG] UPDATED)
121. The Interplay Between Implicit Bias and Benign Overfitting in Two-Layer Linear Networks. (arXiv:2108.11489v3 [stat.ML] UPDATED)
122. Decision Tree-Based Predictive Models for Academic Achievement Using College Students' Support Networks. (arXiv:2108.13947v2 [stat.ML] UPDATED)
123. SeanNet: Semantic Understanding Network for Localization Under Object Dynamics. (arXiv:2110.02276v2 [cs.RO] UPDATED)
124. Wake-Cough: cough spotting and cougher identification for personalised long-term cough monitoring. (arXiv:2110.03771v2 [cs.SD] UPDATED)
125. ProductAE: Towards Training Larger Channel Codes based on Neural Product Codes. (arXiv:2110.04466v2 [cs.IT] UPDATED)
126. Applications of Multi-Agent Reinforcement Learning in Future Internet: A Comprehensive Survey. (arXiv:2110.13484v3 [cs.AI] UPDATED)
127. Iterative Teaching by Label Synthesis. (arXiv:2110.14432v4 [cs.LG] UPDATED)
128. Low Precision Decentralized Distributed Training over IID and non-IID Data. (arXiv:2111.09389v3 [cs.LG] UPDATED)
129. Forecasting Daily COVID-19 Related Calls in VA Health Care System: Predictive Model Development. (arXiv:2111.13980v3 [cs.LG] UPDATED)
130. Black box tests for algorithmic stability. (arXiv:2111.15546v4 [cs.LG] UPDATED)
131. A cross-domain recommender system using deep coupled autoencoders. (arXiv:2112.07617v5 [cs.IR] UPDATED)
132. A Deep Learning Approach To Estimation Using Measurements Received Over a Network. (arXiv:2201.08020v2 [cs.LG] UPDATED)
133. Weight Expansion: A New Perspective on Dropout and Generalization. (arXiv:2201.09209v2 [cs.LG] UPDATED)
134. AttentionHTR: Handwritten Text Recognition Based on Attention Encoder-Decoder Networks. (arXiv:2201.09390v3 [cs.CV] UPDATED)
135. A framework for bilevel optimization that enables stochastic and global variance reduction algorithms. (arXiv:2201.13409v2 [stat.ML] UPDATED)
136. Combined Pruning for Nested Cross-Validation to Accelerate Automated Hyperparameter Optimization for Embedded Feature Selection in High-Dimensional Data with Very Small Sample Sizes. (arXiv:2202.00598v2 [cs.LG] UPDATED)
137. Federated Reinforcement Learning for Collective Navigation of Robotic Swarms. (arXiv:2202.01141v2 [cs.RO] UPDATED)
138. Conditional Gradients for the Approximatel Vanishing Ideal. (arXiv:2202.03349v12 [cs.LG] UPDATED)
139. Bilevel Optimization with a Lower-level Contraction: Optimal Sample Complexity without Warm-Start. (arXiv:2202.03397v2 [stat.ML] UPDATED)
140. Robust Geometric Metric Learning. (arXiv:2202.11550v2 [stat.ML] UPDATED)
141. Support Recovery in Mixture Models with Sparse Parameters. (arXiv:2202.11940v2 [cs.LG] UPDATED)
142. Social-Implicit: Rethinking Trajectory Prediction Evaluation and The Effectiveness of Implicit Maximum Likelihood Estimation. (arXiv:2203.03057v2 [cs.CV] UPDATED)
143. LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph Embeddings. (arXiv:2203.04703v2 [cs.AI] UPDATED)
144. On the Nash equilibrium of moment-matching GANs for stationary Gaussian processes. (arXiv:2203.07136v3 [stat.ML] UPDATED)
145. Robustness through Cognitive Dissociation Mitigation in Contrastive Adversarial Training. (arXiv:2203.08959v3 [cs.LG] UPDATED)
146. Learning from All Vehicles. (arXiv:2203.11934v3 [cs.RO] UPDATED)
147. Using Probabilistic Machine Learning to Better Model Temporal Patterns in Parameterizations: a case study with the Lorenz 96 model. (arXiv:2203.14814v4 [cs.LG] UPDATED)
148. An Improved Lightweight YOLOv5 Model Based on Attention Mechanism for Face Mask Detection. (arXiv:2203.16506v3 [cs.CV] UPDATED)
149. Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v2 [cs.LG] UPDATED)
150. Class-Incremental Learning with Strong Pre-trained Models. (arXiv:2204.03634v2 [cs.CV] UPDATED)
151. Near-Optimal Distributed Linear-Quadratic Regulator for Networked Systems. (arXiv:2204.05551v2 [math.OC] UPDATED)
152. Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v2 [cs.LG] UPDATED)
153. GFCL: A GRU-based Federated Continual Learning Framework against Data Poisoning Attacks in IoV. (arXiv:2204.11010v2 [cs.LG] UPDATED)
154. An Extensive Data Processing Pipeline for MIMIC-IV. (arXiv:2204.13841v4 [cs.LG] UPDATED)
155. Automatic Tuberculosis and COVID-19 cough classification using deep learning. (arXiv:2205.05480v2 [cs.LG] UPDATED)
156. Do Neural Networks Compress Manifolds Optimally?. (arXiv:2205.08518v2 [cs.IT] UPDATED)
157. Advanced Manufacturing Configuration by Sample-efficient Batch Bayesian Optimization. (arXiv:2205.11827v2 [cs.LG] UPDATED)
158. Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors. (arXiv:2205.13618v2 [cs.CV] UPDATED)
159. The Classification of Optical Galaxy Morphology Using Unsupervised Learning Techniques. (arXiv:2206.06165v2 [cs.LG] UPDATED)
160. AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models. (arXiv:2206.11719v2 [cs.CL] UPDATED)
161. An adaptive music generation architecture for games based on the deep learning Transformer mode. (arXiv:2207.01698v2 [cs.SD] UPDATED)
162. Federated Unlearning: How to Efficiently Erase a Client in FL?. (arXiv:2207.05521v2 [cs.LG] UPDATED)
163. Set-based value operators for non-stationary Markovian environments. (arXiv:2207.07271v2 [cs.LG] UPDATED)
164. Balanced Contrastive Learning for Long-Tailed Visual Recognition. (arXiv:2207.09052v3 [cs.CV] UPDATED)
165. Towards Better Evaluation for Dynamic Link Prediction. (arXiv:2207.10128v2 [cs.LG] UPDATED)
166. What Do Deep Neural Networks Find in Disordered Structures of Glasses?. (arXiv:2208.00349v2 [cond-mat.dis-nn] UPDATED)
167. Centroids Matching: an efficient Continual Learning approach operating in the embedding space. (arXiv:2208.02048v2 [cs.LG] UPDATED)
168. Delta Hedging Liquidity Positions on Automated Market Makers. (arXiv:2208.03318v2 [cs.CE] UPDATED)
169. Predicting microsatellite instability and key biomarkers in colorectal cancer from H&E-stained images: Achieving SOTA predictive performance with fewer data using **Swin** Transformer. (arXiv:2208.10495v2 [q-bio.QM] UPDATED)
170. Multiresolution Neural Networks for Imaging. (arXiv:2208.11813v3 [cs.CV] UPDATED)
171. Variance Reduction based Experience Replay for Policy Optimization. (arXiv:2208.12341v2 [stat.ML] UPDATED)
172. DR-DSGD: A Distributionally Robust Decentralized Learning Algorithm over Graphs. (arXiv:2208.13810v2 [cs.LG] UPDATED)
173. Optimizing the Performative Risk under Weak Convexity Assumptions. (arXiv:2209.00771v2 [cs.LG] UPDATED)
174. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v5 [cs.LG] UPDATED)
175. TransPolymer: a Transformer-based Language Model for Polymer Property Predictions. (arXiv:2209.01307v2 [cs.LG] UPDATED)
176. ScaleFace: Uncertainty-aware Deep Metric Learning. (arXiv:2209.01880v2 [cs.CV] UPDATED)
177. A Survey of Machine Unlearning. (arXiv:2209.02299v4 [cs.LG] UPDATED)
178. The (Un)Scalability of Heuristic Approximators for NP-Hard Search Problems. (arXiv:2209.03393v2 [cs.AI] UPDATED)
179. Bispectral Neural Networks. (arXiv:2209.03416v2 [cs.LG] UPDATED)
180. Blessing of Class Diversity in Pre-training. (arXiv:2209.03447v2 [cs.LG] UPDATED)
181. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v2 [eess.IV] UPDATED)
182. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v3 [eess.IV] UPDATED)
## cs.AI
---
**83** new papers in cs.AI:-) 
1. DeID-VC: Speaker De-identification via Zero-shot Pseudo Voice Conversion. (arXiv:2209.04530v1 [cs.SD])
2. Defend Data Poisoning Attacks on Voice Authentication. (arXiv:2209.04547v1 [cs.CR])
3. Avoiding Pragmatic Oddity: A Bottom-up Defeasible Deontic Logic. (arXiv:2209.04553v1 [cs.LO])
4. Explaining Results of Multi-Criteria Decision Making. (arXiv:2209.04582v1 [cs.AI])
5. Bayesian Algorithm Execution for Tuning Particle Accelerator Emittance with Partial Measurements. (arXiv:2209.04587v1 [physics.acc-ph])
6. Causal Intervention for Fairness in Multi-behavior Recommendation. (arXiv:2209.04589v1 [cs.IR])
7. Self-supervised Human Mesh Recovery with Cross-Representation Alignment. (arXiv:2209.04596v1 [cs.CV])
8. Code Compliance Assessment as a Learning Problem. (arXiv:2209.04602v1 [cs.SE])
9. A Comparative Study on Unsupervised Anomaly Detection for Time Series: Experiments and Analysis. (arXiv:2209.04635v1 [cs.LG])
10. Examining stability of machine learning methods for predicting dementia at early phases of the disease. (arXiv:2209.04643v1 [cs.LG])
11. CoreDeep: Improving Crack Detection Algorithms Using Width Stochasticity. (arXiv:2209.04648v1 [cs.CV])
12. Application of Machine Learning for Online Reputation Systems. (arXiv:2209.04650v1 [cs.LG])
13. Ask Before You Act: Generalising to Novel Environments by Asking Questions. (arXiv:2209.04665v1 [cs.AI])
14. Cooperation and Competition: Flocking with Evolutionary Multi-Agent Reinforcement Learning. (arXiv:2209.04696v1 [cs.MA])
15. Variational Autoencoder Kernel Interpretation and Selection for Classification. (arXiv:2209.04715v1 [cs.LG])
16. Ontologizing Health Systems Data at Scale: Making Translational Discovery a Reality. (arXiv:2209.04732v1 [cs.DB])
17. Diffusion Models in Vision: A Survey. (arXiv:2209.04747v1 [cs.CV])
18. A Semantic Tableau Method for Argument Construction. (arXiv:2209.04759v1 [cs.AI])
19. Testing Pre-trained Language Models' Understanding of Distributivity via Causal Mediation Analysis. (arXiv:2209.04761v1 [cs.CL])
20. Git Re-Basin: Merging Models modulo Permutation Symmetries. (arXiv:2209.04836v1 [cs.LG])
21. Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models. (arXiv:2209.04862v1 [cs.LG])
22. Data-Driven Blind Synchronization and Interference Rejection for Digital Communication Signals. (arXiv:2209.04871v1 [eess.SP])
23. Instruction-driven history-aware policies for robotic manipulations. (arXiv:2209.04899v1 [cs.RO])
24. Keke AI Competition: Solving puzzle levels in a dynamically changing mechanic space. (arXiv:2209.04911v1 [cs.AI])
25. Responsible AI Pattern Catalogue: a Multivocal Literature Review. (arXiv:2209.04963v1 [cs.AI])
26. Knowledge Base Question Answering: A Semantic Parsing Perspective. (arXiv:2209.04994v1 [cs.CL])
27. Domain Adaptation for Question Answering via Question Classification. (arXiv:2209.04998v1 [cs.CL])
28. Partial Observability during DRL for Robot Control. (arXiv:2209.04999v1 [cs.RO])
29. FiBiNet++:Improving FiBiNet by Greatly Reducing Model Size for CTR Prediction. (arXiv:2209.05016v1 [cs.IR])
30. PoseIt: A Visual-Tactile Dataset of Holding Poses for Grasp Stability Analysis. (arXiv:2209.05022v1 [cs.RO])
31. SANCL: Multimodal Review Helpfulness Prediction with Selective Attention and Natural Contrastive Learning. (arXiv:2209.05040v1 [cs.CL])
32. Predicting the Next Action by Modeling the Abstract Goal. (arXiv:2209.05044v1 [cs.CV])
33. Bridging between LegalRuleML and TPTP for Automated Normative Reasoning (extended version). (arXiv:2209.05090v1 [cs.AI])
34. Operational solar flare forecasting via video-based deep learning. (arXiv:2209.05128v1 [astro-ph.SR])
35. Personalized Federated Learning with Communication Compression. (arXiv:2209.05148v1 [cs.LG])
36. Resource Allocation to Agents with Restrictions: Maximizing Likelihood with Minimum Compromise. (arXiv:2209.05170v1 [cs.AI])
37. Learning Obstacle-Avoiding Lattice Paths using Swarm Heuristics: Exploring the Bijection to Ordered Trees. (arXiv:2209.05187v1 [cs.RO])
38. A Differentiable Loss Function for Learning Heuristics in A*. (arXiv:2209.05206v1 [cs.LG])
39. Graph Neural Modeling of Network Flows. (arXiv:2209.05208v1 [cs.LG])
40. A Review on Visual-SLAM: Advancements from Geometric Modelling to Learning-based Semantic Scene Understanding. (arXiv:2209.05222v1 [cs.RO])
41. Efficient Customer Service Combining Human Operators and Virtual Agents. (arXiv:2209.05226v1 [cs.AI])
42. MetaNetwork: A Task-agnostic Network Parameters Generation Framework for Improving Device Model Generalization. (arXiv:2209.05227v1 [cs.DC])
43. Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks. (arXiv:2209.05251v1 [cs.CV])
44. Transfer Learning and Vision Transformer based State-of-Health prediction of Lithium-Ion Batteries. (arXiv:2209.05253v1 [cs.CV])
45. Modeling Dependent Structure for Utterances in ASR Evaluation. (arXiv:2209.05281v1 [eess.AS])
46. Leveraging Artificial Intelligence Techniques for Smart Palm Tree Detection: A Decade Systematic Review. (arXiv:2209.05282v1 [cs.CY])
47. Case-Based Abductive Natural Language Inference. (arXiv:2009.14539v4 [cs.AI] UPDATED)
48. Interpreting intermediate convolutional layers of generative CNNs trained on waveforms. (arXiv:2104.09489v4 [cs.SD] UPDATED)
49. Diversifying Neural Text Generation with Part-of-Speech Guided Softmax and Sampling. (arXiv:2105.03641v3 [cs.CL] UPDATED)
50. Exploring Autoencoder-based Error-bounded Compression for Scientific Data. (arXiv:2105.11730v6 [cs.LG] UPDATED)
51. $\mu$DARTS: Model Uncertainty-Aware Differentiable Architecture Search. (arXiv:2107.11500v2 [cs.LG] UPDATED)
52. Smoothed Contrastive Learning for Unsupervised Sentence Embedding. (arXiv:2109.04321v2 [cs.CL] UPDATED)
53. ESimCSE: Enhanced Sample Building Method for Contrastive Learning of Unsupervised Sentence Embedding. (arXiv:2109.04380v2 [cs.CL] UPDATED)
54. Applications of Multi-Agent Reinforcement Learning in Future Internet: A Comprehensive Survey. (arXiv:2110.13484v3 [cs.AI] UPDATED)
55. Iterative Teaching by Label Synthesis. (arXiv:2110.14432v4 [cs.LG] UPDATED)
56. Outlining and Filling: Hierarchical Query Graph Generation for Answering Complex Questions over Knowledge Graphs. (arXiv:2111.00732v2 [cs.AI] UPDATED)
57. LipSound2: Self-Supervised Pre-Training for Lip-to-Speech Reconstruction and Lip Reading. (arXiv:2112.04748v2 [cs.SD] UPDATED)
58. Validation and Generalizability of Self-Supervised Image Reconstruction Methods for Undersampled MRI. (arXiv:2201.12535v3 [eess.IV] UPDATED)
59. LEMON: LanguagE ModeL for Negative Sampling of Knowledge Graph Embeddings. (arXiv:2203.04703v2 [cs.AI] UPDATED)
60. Inferring Articulated Rigid Body Dynamics from RGBD Video. (arXiv:2203.10488v2 [cs.RO] UPDATED)
61. Towards a Change Taxonomy for Machine Learning Systems. (arXiv:2203.11365v2 [cs.SE] UPDATED)
62. Automatic generation of semantic corpora for improving intent estimation of taxonomy-driven search engines. (arXiv:2203.16230v2 [cs.CL] UPDATED)
63. Stream-based Active Learning with Verification Latency in Non-stationary Environments. (arXiv:2204.06822v2 [cs.LG] UPDATED)
64. GFCL: A GRU-based Federated Continual Learning Framework against Data Poisoning Attacks in IoV. (arXiv:2204.11010v2 [cs.LG] UPDATED)
65. How Robust is Neural Machine Translation to Language Imbalance in Multilingual Tokenizer Training?. (arXiv:2204.14268v2 [cs.CL] UPDATED)
66. Prismal view of ethics. (arXiv:2205.13370v2 [cs.CY] UPDATED)
67. How to talk so your AI will learn: Instructions, descriptions, and autonomy. (arXiv:2206.07870v2 [cs.AI] UPDATED)
68. AST-Probe: Recovering abstract syntax trees from hidden representations of pre-trained language models. (arXiv:2206.11719v2 [cs.CL] UPDATED)
69. SSL-Lanes: Self-Supervised Learning for Motion Forecasting in Autonomous Driving. (arXiv:2206.14116v3 [cs.CV] UPDATED)
70. Projectivity revisited. (arXiv:2207.00625v2 [cs.AI] UPDATED)
71. UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v2 [cs.CV] UPDATED)
72. Parameterization of Cross-Token Relations with Relative Positional Encoding for Vision MLP. (arXiv:2207.07284v2 [cs.CV] UPDATED)
73. Learning Flexible Translation between Robot Actions and Language Descriptions. (arXiv:2207.07437v2 [cs.RO] UPDATED)
74. SpeedFolding: Learning Efficient Bimanual Folding of Garments. (arXiv:2208.10552v2 [cs.RO] UPDATED)
75. Influence Maximization (IM) in Complex Networks with Limited Visibility Using Statistical Methods. (arXiv:2208.13166v2 [cs.SI] UPDATED)
76. ScaleFace: Uncertainty-aware Deep Metric Learning. (arXiv:2209.01880v2 [cs.CV] UPDATED)
77. A Survey of Machine Unlearning. (arXiv:2209.02299v4 [cs.LG] UPDATED)
78. A Survey on Generative Diffusion Model. (arXiv:2209.02646v2 [cs.AI] UPDATED)
79. Representing Social Networks as Dynamic Heterogeneous Graphs. (arXiv:2209.03144v2 [cs.SI] UPDATED)
80. The (Un)Scalability of Heuristic Approximators for NP-Hard Search Problems. (arXiv:2209.03393v2 [cs.AI] UPDATED)
81. Sell Me the Blackbox! Regulating eXplainable Artificial Intelligence (XAI) May Harm Consumers. (arXiv:2209.03499v2 [cs.AI] UPDATED)
82. CGAN-ECT: Tomography Image Reconstruction from Electrical Capacitance Measurements Using CGANs. (arXiv:2209.03737v2 [eess.IV] UPDATED)
83. Double Q-Learning for Citizen Relocation During Natural Hazards. (arXiv:2209.03800v2 [cs.RO] UPDATED)

