# Your interest papers
---
## cs.CV
---
### DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
- Authors : Haibo Jin, Ruoxi Chen, Haibin Zheng, Jinyin Chen, Zhenguang Liu, Qi Xuan, Yue Yu, Yao Cheng
- Link : [http://arxiv.org/abs/2202.07464](http://arxiv.org/abs/2202.07464)
> ABSTRACT  :  Despite impressive capabilities and outstanding performance, deep neural network(DNN) has captured increasing public concern for its security problem, due to frequent occurrence of erroneous behaviors. Therefore, it is necessary to conduct systematically testing before its deployment to real-world applications. Existing testing methods have provided fine-grained criteria based on neuron coverage and reached high exploratory degree of testing. But there is still a gap between the neuron coverage and model's robustness evaluation. To bridge the gap, we observed that neurons which change the activation value dramatically due to minor perturbation are prone to trigger incorrect corner cases. Motivated by it, we propose neuron sensitivity and develop a novel white-box testing framework for DNN, donated as DeepSensor. The number of sensitive neurons is maximized by particle swarm optimization, thus diverse corner cases could be triggered and neuron coverage be further improved when compared with baselines. Besides, considerable robustness **enhancement** can be reached when adopting testing examples based on neuron sensitivity for retraining. Extensive experiments implemented on scalable datasets and models can well demonstrate the testing effectiveness and robustness improvement of DeepSensor.  
### A **Real-time** System for Detecting Landslide Reports on Social Media using Artificial Intelligence. (arXiv:2202.07475v1 [cs.CY])
- Authors : Ferda Ofli, Umair Qazi, Muhammad Imran, Julien Roch, Catherine Pennington, Vanessa Banks, Remy Bossu
- Link : [http://arxiv.org/abs/2202.07475](http://arxiv.org/abs/2202.07475)
> ABSTRACT  :  This paper presents an online system that leverages social media data in **real time** to identify landslide-related information automatically using state-of-the-art artificial intelligence techniques. The designed system can (i) reduce the information overload by eliminating duplicate and irrelevant content, (ii) identify landslide images, (iii) infer geolocation of the images, and (iv) categorize the user type (organization or person) of the account sharing the information. The system was deployed in February 2020 online at https://landslide-aidr.qcri.org/landslide_system.php to monitor live Twitter data stream and has been running continuously since then to provide time-critical information to partners such as British Geological Survey and European Mediterranean Seismological Centre. We trust this system can both contribute to harvesting of global landslide data for further research and support global landslide maps to facilitate emergency response and decision making.  
### Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v1 [eess.IV])
- Authors : Ziwei Luo, Haibin Huang, Lei Yu, Youwei Li, Haoqiang Fan, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2202.07508](http://arxiv.org/abs/2202.07508)
> ABSTRACT  :  In this paper, we tackle the problem of blind image super-resolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel based high resolution image **restoration**. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yields more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements against state-of-the-art methods.  
### Adverse Weather Image Translation with Asymmetric and Uncertainty-aware GAN. (arXiv:2112.04283v3 [cs.CV] UPDATED)
- Authors : gi Kwak, Youngsaeng Jin, Yuanming Li, Dongsik Yoon, Donghyeon Kim, Hanseok Ko
- Link : [http://arxiv.org/abs/2112.04283](http://arxiv.org/abs/2112.04283)
> ABSTRACT  :  Adverse weather image translation belongs to the unsupervised image-to-image (I2I) translation task which aims to transfer adverse condition domain (eg, rainy **night**) to standard domain (eg, day). It is a challenging task because images from adverse domains have some artifacts and insufficient information. Recently, many studies employing Generative Adversarial Networks (GANs) have achieved notable success in I2I translation but there are still limitations in applying them to adverse weather **enhancement**. Symmetric architecture based on bidirectional cycle-consistency loss is adopted as a standard framework for unsupervised domain transfer methods. However, it can lead to inferior translation result if the two domains have imbalanced information. To address this issue, we propose a novel GAN model, i.e., AU-GAN, which has an asymmetric architecture for adverse domain translation. We insert a proposed feature transfer network (${T}$-net) in only a normal domain generator (i.e., rainy **night**-&gt; day) to enhance encoded features of the adverse domain image. In addition, we introduce asymmetric feature matching for disentanglement of encoded features. Finally, we propose uncertainty-aware cycle-consistency loss to address the regional uncertainty of a cyclic reconstructed image. We demonstrate the effectiveness of our method by qualitative and quantitative comparisons with state-of-the-art models. Codes are available at https://github.com/jgkwak95/AU-GAN.  
### **Low-light** Image **Enhancement** by Retinex Based Algorithm Unrolling and Adjustment. (arXiv:2202.05972v2 [cs.CV] UPDATED)
- Authors : Xinyi Liu, Qi Xie, Qian Zhao, Hong Wang, Deyu Meng
- Link : [http://arxiv.org/abs/2202.05972](http://arxiv.org/abs/2202.05972)
> ABSTRACT  :  Motivated by their recent advances, deep learning techniques have been widely applied to **low-light** image **enhancement** (LIE) problem. Among which, Retinex theory based ones, mostly following a decomposition-adjustment pipeline, have taken an important place due to its physical interpretation and promising performance. However, current investigations on Retinex based deep learning are still not sufficient, ignoring many useful experiences from traditional methods. Besides, the adjustment step is either performed with simple image processing techniques, or by complicated networks, both of which are unsatisfactory in practice. To address these issues, we propose a new deep learning framework for the LIE problem. The proposed framework contains a decomposition network inspired by algorithm unrolling, and adjustment networks considering both global brightness and local brightness sensitivity. By virtue of algorithm unrolling, both implicit priors learned from data and explicit priors borrowed from traditional methods can be embedded in the network, facilitate to better decomposition. Meanwhile, the consideration of global and local brightness can guide designing simple yet effective network modules for adjustment. Besides, to avoid manually parameter tuning, we also propose a self-supervised fine-tuning strategy, which can always guarantee a promising performance. Experiments on a series of typical LIE datasets demonstrated the effectiveness of the proposed method, both quantitatively and visually, as compared with existing methods.  
## eess.IV
---
### Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v1 [eess.IV])
- Authors : Ziwei Luo, Haibin Huang, Lei Yu, Youwei Li, Haoqiang Fan, Shuaicheng Liu
- Link : [http://arxiv.org/abs/2202.07508](http://arxiv.org/abs/2202.07508)
> ABSTRACT  :  In this paper, we tackle the problem of blind image super-resolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel based high resolution image **restoration**. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yields more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements against state-of-the-art methods.  
### **Low-light** Image **Enhancement** by Retinex Based Algorithm Unrolling and Adjustment. (arXiv:2202.05972v2 [cs.CV] UPDATED)
- Authors : Xinyi Liu, Qi Xie, Qian Zhao, Hong Wang, Deyu Meng
- Link : [http://arxiv.org/abs/2202.05972](http://arxiv.org/abs/2202.05972)
> ABSTRACT  :  Motivated by their recent advances, deep learning techniques have been widely applied to **low-light** image **enhancement** (LIE) problem. Among which, Retinex theory based ones, mostly following a decomposition-adjustment pipeline, have taken an important place due to its physical interpretation and promising performance. However, current investigations on Retinex based deep learning are still not sufficient, ignoring many useful experiences from traditional methods. Besides, the adjustment step is either performed with simple image processing techniques, or by complicated networks, both of which are unsatisfactory in practice. To address these issues, we propose a new deep learning framework for the LIE problem. The proposed framework contains a decomposition network inspired by algorithm unrolling, and adjustment networks considering both global brightness and local brightness sensitivity. By virtue of algorithm unrolling, both implicit priors learned from data and explicit priors borrowed from traditional methods can be embedded in the network, facilitate to better decomposition. Meanwhile, the consideration of global and local brightness can guide designing simple yet effective network modules for adjustment. Besides, to avoid manually parameter tuning, we also propose a self-supervised fine-tuning strategy, which can always guarantee a promising performance. Experiments on a series of typical LIE datasets demonstrated the effectiveness of the proposed method, both quantitatively and visually, as compared with existing methods.  
## cs.LG
---
### Scaling up Ranking under Constraints for Live Recommendations by Replacing Optimization with Prediction. (arXiv:2202.07088v1 [cs.IR])
- Authors : Yegor Tkachenko, Wassim Dhaouadi, Kamel Jedidi
- Link : [http://arxiv.org/abs/2202.07088](http://arxiv.org/abs/2202.07088)
> ABSTRACT  :  Many important multiple-objective decision problems can be cast within the framework of ranking under constraints and solved via a weighted bipartite matching linear program. Some of these optimization problems, such as personalized content recommendations, may need to be solved in **real time** and thus must comply with strict time requirements to prevent the perception of latency by consumers. Classical linear programming is too computationally inefficient for such settings. We propose a novel approach to scale up ranking under constraints by replacing the weighted bipartite matching optimization with a prediction problem in the algorithm deployment stage. We show empirically that the proposed approximate solution to the ranking problem leads to a major reduction in required computing resources without much sacrifice in constraint compliance and achieved utility, allowing us to solve larger constrained ranking problems real-time, within the required 50 milliseconds, than previously reported.  
### DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
- Authors : Haibo Jin, Ruoxi Chen, Haibin Zheng, Jinyin Chen, Zhenguang Liu, Qi Xuan, Yue Yu, Yao Cheng
- Link : [http://arxiv.org/abs/2202.07464](http://arxiv.org/abs/2202.07464)
> ABSTRACT  :  Despite impressive capabilities and outstanding performance, deep neural network(DNN) has captured increasing public concern for its security problem, due to frequent occurrence of erroneous behaviors. Therefore, it is necessary to conduct systematically testing before its deployment to real-world applications. Existing testing methods have provided fine-grained criteria based on neuron coverage and reached high exploratory degree of testing. But there is still a gap between the neuron coverage and model's robustness evaluation. To bridge the gap, we observed that neurons which change the activation value dramatically due to minor perturbation are prone to trigger incorrect corner cases. Motivated by it, we propose neuron sensitivity and develop a novel white-box testing framework for DNN, donated as DeepSensor. The number of sensitive neurons is maximized by particle swarm optimization, thus diverse corner cases could be triggered and neuron coverage be further improved when compared with baselines. Besides, considerable robustness **enhancement** can be reached when adopting testing examples based on neuron sensitivity for retraining. Extensive experiments implemented on scalable datasets and models can well demonstrate the testing effectiveness and robustness improvement of DeepSensor.  
### Bayesian Optimisation for Active Monitoring of Air Pollution. (arXiv:2202.07595v1 [cs.LG])
- Authors : Sigrid Passano
- Link : [http://arxiv.org/abs/2202.07595](http://arxiv.org/abs/2202.07595)
> ABSTRACT  :  Air pollution is one of the leading causes of mortality globally, resulting in millions of deaths each year. Efficient monitoring is important to measure **exposure** and enforce legal limits. New low-cost sensors can be deployed in greater numbers and in more varied locations, motivating the problem of efficient automated placement. Previous work suggests Bayesian optimisation is an appropriate method, but only considered a satellite data set, with data aggregated over all altitudes. It is ground-level pollution, that humans breathe, which matters most. We improve on those results using hierarchical models and evaluate our models on urban pollution data in London to show that Bayesian optimisation can be successfully applied to the problem.  
### Toward Degradation-Robust Voice Conversion. (arXiv:2110.07537v2 [eess.AS] UPDATED)
- Authors : yu Huang, Wei Chang, yi Lee
- Link : [http://arxiv.org/abs/2110.07537](http://arxiv.org/abs/2110.07537)
> ABSTRACT  :  Any-to-any voice conversion technologies convert the vocal timbre of an utterance to any speaker even unseen during training. Although there have been several state-of-the-art any-to-any voice conversion models, they were all based on clean utterances to convert successfully. However, in real-world scenarios, it is difficult to collect clean utterances of a speaker, and they are usually degraded by noises or reverberations. It thus becomes highly desired to understand how these degradations affect voice conversion and build a degradation-robust model. We report in this paper the first comprehensive study on the degradation robustness of any-to-any voice conversion. We show that the performance of state-of-the-art models nowadays was severely hampered given degraded utterances. To this end, we then propose speech **enhancement** concatenation and denoising training to improve the robustness. In addition to common degradations, we also consider adversarial noises, which alter the model output significantly yet are human-imperceptible. It was shown that both concatenations with off-the-shelf speech **enhancement** models and denoising training on voice conversion models could improve the robustness, while each of them had pros and cons.  
### End-to-End Neural Speech Coding for Real-Time Communications. (arXiv:2201.09429v3 [cs.SD] UPDATED)
- Authors : Xue Jiang, Xiulian Peng, Chengyu Zheng, Huaying Xue, Yuan Zhang, Yan Lu
- Link : [http://arxiv.org/abs/2201.09429](http://arxiv.org/abs/2201.09429)
> ABSTRACT  :  Deep-learning based methods have shown their advantages in audio coding over traditional ones but limited attention has been paid on real-time communications (RTC). This paper proposes the TFNet, an end-to-end neural speech codec with low latency for RTC. It takes an encoder-temporal filtering-decoder paradigm that has seldom been investigated in audio coding. An interleaved structure is proposed for temporal filtering to capture both short-term and long-term temporal dependencies. Furthermore, with end-to-end optimization, the TFNet is jointly optimized with speech **enhancement** and packet loss concealment, yielding a one-for-all network for three tasks. Both subjective and objective results demonstrate the efficiency of the proposed TFNet.  
### Flexible learning of quantum states with generative query neural networks. (arXiv:2202.06804v1 [quant-ph] CROSS LISTED)
- Authors : Yan Zhu, Dong Wu, Ge Bai, Yuexuan Wang, Giulio Chiribella
- Link : [http://arxiv.org/abs/2202.06804](http://arxiv.org/abs/2202.06804)
> ABSTRACT  :  Deep neural networks are a powerful tool for characterizing quantum states. In this task, neural networks are typically trained with measurement data gathered from the quantum state to be characterized. But is it possible to train a neural network in a general-purpose way, which makes it applicable to multiple unknown quantum states? Here we show that learning across multiple quantum states and different measurement settings can be achieved by a generative query neural network, a type of neural network originally used in the classical domain for learning 3D scenes from 2D pictures. Our network can be trained offline with classically simulated data, and later be used to characterize unknown quantum states from real experimental data. With little guidance of quantum physics, the network builds its own data-driven representation of quantum states, and then uses it to predict the outcome probabilities of requested quantum measurements on the states of interest. This approach can be applied to state learning scenarios where quantum measurement settings are not informationally complete and predictions must be given in **real time**, as experimental data become available, as well as to adversarial scenarios where measurement choices and prediction requests are designed to expose learning inaccuracies. The internal representation produced by the network can be used for other tasks beyond state characterization, including clustering of states and prediction of physical properties. The features of our method are illustrated on many-qubit ground states of Ising model and continuous-variable non-Gaussian states.  
## cs.AI
---
### DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
- Authors : Haibo Jin, Ruoxi Chen, Haibin Zheng, Jinyin Chen, Zhenguang Liu, Qi Xuan, Yue Yu, Yao Cheng
- Link : [http://arxiv.org/abs/2202.07464](http://arxiv.org/abs/2202.07464)
> ABSTRACT  :  Despite impressive capabilities and outstanding performance, deep neural network(DNN) has captured increasing public concern for its security problem, due to frequent occurrence of erroneous behaviors. Therefore, it is necessary to conduct systematically testing before its deployment to real-world applications. Existing testing methods have provided fine-grained criteria based on neuron coverage and reached high exploratory degree of testing. But there is still a gap between the neuron coverage and model's robustness evaluation. To bridge the gap, we observed that neurons which change the activation value dramatically due to minor perturbation are prone to trigger incorrect corner cases. Motivated by it, we propose neuron sensitivity and develop a novel white-box testing framework for DNN, donated as DeepSensor. The number of sensitive neurons is maximized by particle swarm optimization, thus diverse corner cases could be triggered and neuron coverage be further improved when compared with baselines. Besides, considerable robustness **enhancement** can be reached when adopting testing examples based on neuron sensitivity for retraining. Extensive experiments implemented on scalable datasets and models can well demonstrate the testing effectiveness and robustness improvement of DeepSensor.  
# Paper List
---
## cs.CV
---
**81** new papers in cs.CV:-) 
1. DermX: an end-to-end framework for explainable automated dermatological diagnosis. (arXiv:2202.06956v1 [eess.IV])
2. ASC me to Do Anything: Multi-task Training for Embodied AI. (arXiv:2202.06987v1 [cs.CV])
3. A Survey of Cross-Modality Brain Image Synthesis. (arXiv:2202.06997v1 [eess.IV])
4. Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images. (arXiv:2202.07001v1 [eess.IV])
5. A Survey of Visual Sensory Anomaly Detection. (arXiv:2202.07006v1 [cs.CV])
6. Building Inspection Toolkit: Unified Evaluation and Strong Baselines for Damage Recognition. (arXiv:2202.07012v1 [cs.CV])
7. Box Supervised Video Segmentation Proposal Network. (arXiv:2202.07025v1 [cs.CV])
8. One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones. (arXiv:2202.07028v1 [cs.AI])
9. Universal Adversarial Examples in Remote Sensing: Methodology and Benchmark. (arXiv:2202.07054v1 [cs.CV])
10. Discriminability-enforcing loss to improve representation learning. (arXiv:2202.07073v1 [cs.CV])
11. Gaze-Guided Class Activation Mapping: Leveraging Human Attention for Network Attention in Chest X-rays Classification. (arXiv:2202.07107v1 [eess.IV])
12. Multi-task UNet: Jointly Boosting Saliency Prediction and Disease Classification on Chest X-ray Images. (arXiv:2202.07118v1 [eess.IV])
13. Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework. (arXiv:2202.07123v1 [cs.CV])
14. Sim-to-Real Domain Adaptation for Lane Detection and Classification in Autonomous Driving. (arXiv:2202.07133v1 [cs.CV])
15. Compositional Scene Representation Learning via Reconstruction: A Survey. (arXiv:2202.07135v1 [cs.LG])
16. Debiased Pseudo Labeling in Self-Training. (arXiv:2202.07136v1 [cs.LG])
17. GAN-generated Faces Detection: A Survey and New Perspectives. (arXiv:2202.07145v1 [cs.CV])
18. To what extent can Plug-and-Play methods outperform neural networks alone in low-dose CT reconstruction. (arXiv:2202.07173v1 [eess.IV])
19. A Survey of Neural Trojan Attacks and Defenses in Deep Learning. (arXiv:2202.07183v1 [cs.CR])
20. Pruning Networks with Cross-Layer Ranking & k-Reciprocal Nearest Filters. (arXiv:2202.07190v1 [cs.CV])
21. Improving Human Sperm Head Morphology Classification with Unsupervised Anatomical Feature Distillation. (arXiv:2202.07191v1 [cs.CV])
22. Balancing Domain Experts for Long-Tailed Camera-Trap Recognition. (arXiv:2202.07215v1 [cs.CV])
23. MeshLeTemp: Leveraging the Learnable Vertex-Vertex Relationship to Generalize Human Pose and Mesh Reconstruction for In-the-Wild Scenes. (arXiv:2202.07228v1 [cs.CV])
24. Few-shot semantic segmentation via mask aggregation. (arXiv:2202.07231v1 [cs.CV])
25. Neural Architecture Search for Dense Prediction Tasks in Computer Vision. (arXiv:2202.07242v1 [cs.CV])
26. CommerceMM: Large-Scale Commerce MultiModal Representation Learning with Omni Retrieval. (arXiv:2202.07247v1 [cs.CV])
27. Review of the Fingerprint Liveness Detection (LivDet) competition series: from 2009 to 2021. (arXiv:2202.07259v1 [cs.CV])
28. Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks. (arXiv:2202.07261v1 [cs.CV])
29. Hyper-relationship Learning Network for Scene Graph Generation. (arXiv:2202.07271v1 [cs.CV])
30. Beyond Natural Motion: Exploring Discontinuity for Video Frame Interpolation. (arXiv:2202.07291v1 [cs.CV])
31. ViNTER: Image Narrative Generation with Emotion-Arc-Aware Transformer. (arXiv:2202.07305v1 [cs.CV])
32. HAA4D: Few-Shot Human Atomic Action Recognition via 3D Spatio-Temporal Skeletal Alignment. (arXiv:2202.07308v1 [cs.CV])
33. Using Social Media Images for Building Function Classification. (arXiv:2202.07315v1 [cs.CV])
34. A Unified Framework for Masked and Mask-Free Face Recognition via Feature Rectification. (arXiv:2202.07358v1 [cs.CV])
35. Multimodal Driver Referencing: A Comparison of Pointing to Objects Inside and Outside the Vehicle. (arXiv:2202.07360v1 [cs.HC])
36. Deep Learning-based Anomaly Detection on X-ray Images of Fuel Cell Electrodes. (arXiv:2202.07361v1 [cs.CV])
37. SODAR: Segmenting Objects by DynamicallyAggregating Neighboring Mask Representations. (arXiv:2202.07402v1 [cs.CV])
38. Explainable COVID-19 Infections Identification and Delineation Using Calibrated Pseudo Labels. (arXiv:2202.07422v1 [eess.IV])
39. On the Complementarity of Images and Text for the Expression of Emotions in Social Media. (arXiv:2202.07427v1 [cs.CV])
40. A precortical module for robust CNNs to light variations. (arXiv:2202.07432v1 [cs.CV])
41. Mathematical Cookbook for Snapshot Compressive Imaging. (arXiv:2202.07437v1 [cs.CV])
42. An Automated Analysis Framework for Trajectory Datasets. (arXiv:2202.07438v1 [cs.CV])
43. Random Walks for Adversarial Meshes. (arXiv:2202.07453v1 [cs.CV])
44. A Survey on Image Deblurring. (arXiv:2202.07456v1 [cs.CV])
45. DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
46. Federated Contrastive Learning for Dermatological Disease Diagnosis via On-device Learning. (arXiv:2202.07470v1 [cs.LG])
47. Do Lessons from Metric Learning Generalize to Image-Caption Retrieval?. (arXiv:2202.07474v1 [cs.CV])
48. A **Real-time** System for Detecting Landslide Reports on Social Media using Artificial Intelligence. (arXiv:2202.07475v1 [cs.CY])
49. DualConv: Dual Convolutional Kernels for Lightweight Deep Neural Networks. (arXiv:2202.07481v1 [cs.CV])
50. Texture Aware Autoencoder Pre-training And Pairwise Learning Refinement For Improved Iris Recognition. (arXiv:2202.07499v1 [cs.CV])
51. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v1 [cs.CV])
52. Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v1 [eess.IV])
53. Post-Training Quantization for Cross-Platform Learned Image Compression. (arXiv:2202.07513v1 [eess.IV])
54. Label fusion and training methods for reliable representation of inter-rater uncertainty. (arXiv:2202.07550v1 [eess.IV])
55. Improving the repeatability of deep learning models with Monte Carlo dropout. (arXiv:2202.07562v1 [eess.IV])
56. ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification. (arXiv:2202.07570v1 [cs.CV])
57. On Representation Learning with Feedback. (arXiv:2202.07572v1 [cs.CV])
58. Fairness Indicators for Systematic Assessments of Visual Feature Extractors. (arXiv:2202.07603v1 [cs.CV])
59. Lie Point Symmetry Data Augmentation for Neural PDE Solvers. (arXiv:2202.07643v1 [cs.LG])
60. Cyclic Differentiable Architecture Search. (arXiv:2006.10724v3 [cs.CV] UPDATED)
61. FILTRA: Rethinking Steerable CNN by Filter Transform. (arXiv:2105.11636v2 [cs.CV] UPDATED)
62. Learning distinct features helps, provably. (arXiv:2106.06012v2 [cs.LG] UPDATED)
63. Exploring convolutional neural networks with transfer learning for diagnosing Lyme disease from skin lesion images. (arXiv:2106.14465v2 [eess.IV] UPDATED)
64. Keypoints-Based Deep Feature Fusion for Cooperative Vehicle Detection of Autonomous Driving. (arXiv:2109.11615v2 [cs.CV] UPDATED)
65. Graph Representation Learning for Spatial Image Steganalysis. (arXiv:2110.00957v3 [cs.MM] UPDATED)
66. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v8 [eess.IV] UPDATED)
67. Stochastic Primal-Dual Deep Unrolling. (arXiv:2110.10093v4 [eess.IV] UPDATED)
68. Track Boosting and Synthetic Data Aided Drone Detection. (arXiv:2111.12389v3 [cs.CV] UPDATED)
69. Unity is strength: Improving the Detection of Adversarial Examples with Ensemble Approaches. (arXiv:2111.12631v3 [cs.CV] UPDATED)
70. Adverse Weather Image Translation with Asymmetric and Uncertainty-aware GAN. (arXiv:2112.04283v3 [cs.CV] UPDATED)
71. A Real-Time Rendering Method for Light Field Display. (arXiv:2201.08266v3 [cs.GR] UPDATED)
72. BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation. (arXiv:2201.12086v2 [cs.CV] UPDATED)
73. Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting. (arXiv:2202.02543v2 [cs.CV] UPDATED)
74. Layer-wise Regularized Adversarial Training using Layers Sustainability Analysis (LSA) framework. (arXiv:2202.02626v3 [cs.CV] UPDATED)
75. Deep Deterministic Independent Component Analysis for Hyperspectral Unmixing. (arXiv:2202.02951v2 [eess.IV] UPDATED)
76. Feature-level augmentation to improve robustness of deep neural networks to affine transformations. (arXiv:2202.05152v3 [cs.CV] UPDATED)
77. Optimal Transport for Super Resolution Applied to Astronomy Imaging. (arXiv:2202.05354v2 [eess.IV] UPDATED)
78. **Low-light** Image **Enhancement** by Retinex Based Algorithm Unrolling and Adjustment. (arXiv:2202.05972v2 [cs.CV] UPDATED)
79. Diverse facial inpainting guided by exemplars. (arXiv:2202.06358v2 [cs.CV] UPDATED)
80. ADeADA: Adaptive Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v2 [cs.CV] UPDATED)
81. Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection. (arXiv:2202.06934v2 [cs.CV] UPDATED)
## eess.IV
---
**27** new papers in eess.IV:-) 
1. DermX: an end-to-end framework for explainable automated dermatological diagnosis. (arXiv:2202.06956v1 [eess.IV])
2. A Survey of Cross-Modality Brain Image Synthesis. (arXiv:2202.06997v1 [eess.IV])
3. Handcrafted Histological Transformer (H2T): Unsupervised Representation of Whole Slide Images. (arXiv:2202.07001v1 [eess.IV])
4. Cerebrovascular morphology in aging and disease -- imaging biomarkers for ischemic stroke and Alzheimers disease. (arXiv:2202.07093v1 [q-bio.QM])
5. Gaze-Guided Class Activation Mapping: Leveraging Human Attention for Network Attention in Chest X-rays Classification. (arXiv:2202.07107v1 [eess.IV])
6. Dynamic optical contrast imaging for real-time delineation of tumor resection margins using head and neck cancer as a model. (arXiv:2202.07108v1 [eess.IV])
7. Multi-task UNet: Jointly Boosting Saliency Prediction and Disease Classification on Chest X-ray Images. (arXiv:2202.07118v1 [eess.IV])
8. To what extent can Plug-and-Play methods outperform neural networks alone in low-dose CT reconstruction. (arXiv:2202.07173v1 [eess.IV])
9. Exploring the Devil in Graph Spectral Domain for 3D Point Cloud Attacks. (arXiv:2202.07261v1 [cs.CV])
10. A Unified Framework for Masked and Mask-Free Face Recognition via Feature Rectification. (arXiv:2202.07358v1 [cs.CV])
11. Deep Learning-based Anomaly Detection on X-ray Images of Fuel Cell Electrodes. (arXiv:2202.07361v1 [cs.CV])
12. A Low-Parametric Model for Bit-Rate Estimation of VVC Residual Coding. (arXiv:2202.07369v1 [eess.IV])
13. Explainable COVID-19 Infections Identification and Delineation Using Calibrated Pseudo Labels. (arXiv:2202.07422v1 [eess.IV])
14. Learning Contextually Fused Audio-visual Representations for Audio-visual Speech Recognition. (arXiv:2202.07428v1 [eess.IV])
15. Federated Contrastive Learning for Dermatological Disease Diagnosis via On-device Learning. (arXiv:2202.07470v1 [cs.LG])
16. Deep Constrained Least Squares for Blind Image Super-Resolution. (arXiv:2202.07508v1 [eess.IV])
17. Post-Training Quantization for Cross-Platform Learned Image Compression. (arXiv:2202.07513v1 [eess.IV])
18. Label fusion and training methods for reliable representation of inter-rater uncertainty. (arXiv:2202.07550v1 [eess.IV])
19. Improving the repeatability of deep learning models with Monte Carlo dropout. (arXiv:2202.07562v1 [eess.IV])
20. Covariance Estimation from Compressive Data Partitions using a Projected Gradient-based Algorithm. (arXiv:2101.04027v2 [eess.IV] UPDATED)
21. Exploring convolutional neural networks with transfer learning for diagnosing Lyme disease from skin lesion images. (arXiv:2106.14465v2 [eess.IV] UPDATED)
22. Graph Representation Learning for Spatial Image Steganalysis. (arXiv:2110.00957v3 [cs.MM] UPDATED)
23. Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization. (arXiv:2110.09113v8 [eess.IV] UPDATED)
24. Stochastic Primal-Dual Deep Unrolling. (arXiv:2110.10093v4 [eess.IV] UPDATED)
25. Deep Deterministic Independent Component Analysis for Hyperspectral Unmixing. (arXiv:2202.02951v2 [eess.IV] UPDATED)
26. Optimal Transport for Super Resolution Applied to Astronomy Imaging. (arXiv:2202.05354v2 [eess.IV] UPDATED)
27. **Low-light** Image **Enhancement** by Retinex Based Algorithm Unrolling and Adjustment. (arXiv:2202.05972v2 [cs.CV] UPDATED)
## cs.LG
---
**194** new papers in cs.LG:-) 
1. Towards Best Practice of Interpreting Deep Learning Models for EEG-based Brain Computer Interfaces. (arXiv:2202.06948v1 [cs.NE])
2. Minimax in Geodesic Metric Spaces: Sion's Theorem and Algorithms. (arXiv:2202.06950v1 [math.OC])
3. DermX: an end-to-end framework for explainable automated dermatological diagnosis. (arXiv:2202.06956v1 [eess.IV])
4. Deep Ensembles Work, But Are They Necessary?. (arXiv:2202.06985v1 [cs.LG])
5. Learned Turbulence Modelling with Differentiable Fluid Solvers. (arXiv:2202.06988v1 [physics.flu-dyn])
6. Transformer Memory as a Differentiable Search Index. (arXiv:2202.06991v1 [cs.CL])
7. Unlabeled Data Help: Minimax Analysis and Adversarial Robustness. (arXiv:2202.06996v1 [stat.ML])
8. Continuously Generalized Ordinal Regression for Linear and Deep Models. (arXiv:2202.07005v1 [cs.LG])
9. Robust Policy Learning over Multiple Uncertainty Sets. (arXiv:2202.07013v1 [cs.LG])
10. Strategy Discovery and Mixture in Lifelong Learning from Heterogeneous Demonstration. (arXiv:2202.07014v1 [cs.LG])
11. QuadSim: A Quadcopter Rotational Dynamics Simulation Framework For Reinforcement Learning Algorithms. (arXiv:2202.07021v1 [cs.LG])
12. Recurrent Neural Networks for Dynamical Systems: Applications to Ordinary Differential Equations, Collective Motion, and Hydrological Modeling. (arXiv:2202.07022v1 [math.DS])
13. Analysis of Neural Fragility: Bounding the Norm of a Rank-One Perturbation Matrix. (arXiv:2202.07026v1 [cs.LG])
14. One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones. (arXiv:2202.07028v1 [cs.AI])
15. Benchmarking Online Sequence-to-Sequence and Character-based Handwriting Recognition from IMU-Enhanced Pens. (arXiv:2202.07036v1 [cs.LG])
16. Principal Manifold Flows. (arXiv:2202.07037v1 [stat.ML])
17. Orthogonalising gradients to speed up neural network optimisation. (arXiv:2202.07052v1 [cs.LG])
18. A Unified Perspective on Value Backup and Exploration in Monte-Carlo Tree Search. (arXiv:2202.07071v1 [cs.AI])
19. Discriminability-enforcing loss to improve representation learning. (arXiv:2202.07073v1 [cs.CV])
20. Synthetically Controlled Bandits. (arXiv:2202.07079v1 [stat.ML])
21. Graph Neural Networks for Graphs with Heterophily: A Survey. (arXiv:2202.07082v1 [cs.LG])
22. Scaling up Ranking under Constraints for Live Recommendations by Replacing Optimization with Prediction. (arXiv:2202.07088v1 [cs.IR])
23. Statistical Inference After Adaptive Sampling in Non-Markovian Environments. (arXiv:2202.07098v1 [cs.LG])
24. A Survey on Dynamic Neural Networks for Natural Language Processing. (arXiv:2202.07101v1 [cs.CL])
25. A Survey on Model Compression for Natural Language Processing. (arXiv:2202.07105v1 [cs.CL])
26. Recent Advances in Reliable Deep Graph Learning: Adversarial Attack, Inherent Noise, and Distribution Shift. (arXiv:2202.07114v1 [cs.LG])
27. Transformers in Time Series: A Survey. (arXiv:2202.07125v1 [cs.LG])
28. STaR: Knowledge Graph Embedding by Scaling, Translation and Rotation. (arXiv:2202.07130v1 [cs.LG])
29. Memory via Temporal Delays in weightless Spiking Neural Network. (arXiv:2202.07132v1 [cs.NE])
30. Compositional Scene Representation Learning via Reconstruction: A Survey. (arXiv:2202.07135v1 [cs.LG])
31. Debiased Pseudo Labeling in Self-Training. (arXiv:2202.07136v1 [cs.LG])
32. Machine Learning in Aerodynamic Shape Optimization. (arXiv:2202.07141v1 [cs.LG])
33. L2C2: Locally Lipschitz Continuous Constraint towards Stable and Smooth Reinforcement Learning. (arXiv:2202.07152v1 [cs.RO])
34. OLIVE: Oblivious and Differentially Private Federated Learning on Trusted Execution Environment. (arXiv:2202.07165v1 [cs.LG])
35. Fairness Amidst Non-IID Graph Data: A Literature Review. (arXiv:2202.07170v1 [cs.LG])
36. TURF: A Two-factor, Universal, Robust, Fast Distribution Learning Algorithm. (arXiv:2202.07172v1 [stat.ML])
37. DeepONet-Grid-UQ: A Trustworthy Deep Operator Framework for Predicting the Power Grid's Post-Fault Trajectories. (arXiv:2202.07176v1 [math.NA])
38. Federated Learning with Sparsified Model Perturbation: Improving Accuracy under Client-Level Differential Privacy. (arXiv:2202.07178v1 [cs.LG])
39. G-Mixup: Graph Data Augmentation for Graph Classification. (arXiv:2202.07179v1 [cs.LG])
40. On the Origins of the Block Structure Phenomenon in Neural Network Representations. (arXiv:2202.07184v1 [cs.LG])
41. Improving Human Sperm Head Morphology Classification with Unsupervised Anatomical Feature Distillation. (arXiv:2202.07191v1 [cs.CV])
42. One-bit Submission for Locally Private Quasi-MLE: Its Asymptotic Normality and Limitation. (arXiv:2202.07194v1 [stat.ML])
43. Unsupervised word-level prosody tagging for controllable speech synthesis. (arXiv:2202.07200v1 [eess.AS])
44. Holistic Adversarial Robustness of Deep Learning Models. (arXiv:2202.07201v1 [cs.LG])
45. Multi-style Training for South African Call Centre Audio. (arXiv:2202.07219v1 [cs.SD])
46. Navigating Local Minima in Quantized Spiking Neural Networks. (arXiv:2202.07221v1 [cs.LG])
47. Geometrically Equivariant Graph Neural Networks: A Survey. (arXiv:2202.07230v1 [cs.LG])
48. Eliciting Best Practices for Collaboration with Computational Notebooks. (arXiv:2202.07233v1 [cs.HC])
49. Learning to Solve Routing Problems via Distributionally Robust Optimization. (arXiv:2202.07241v1 [cs.LG])
50. Neural Architecture Search for Dense Prediction Tasks in Computer Vision. (arXiv:2202.07242v1 [cs.CV])
51. Explaining Reject Options of Learning Vector Quantization Classifiers. (arXiv:2202.07244v1 [cs.LG])
52. Exploiting Data Sparsity in Secure Cross-Platform Social Recommendation. (arXiv:2202.07253v1 [cs.LG])
53. REPID: Regional Effect Plots with implicit Interaction Detection. (arXiv:2202.07254v1 [stat.ML])
54. Federated Graph Neural Networks: Overview, Techniques and Challenges. (arXiv:2202.07256v1 [cs.DC])
55. Accelerating Non-Negative and Bounded-Variable Linear Regression Algorithms with Safe Screening. (arXiv:2202.07258v1 [cs.LG])
56. Learning Disentangled Behaviour Patterns for Wearable-based Human Activity Recognition. (arXiv:2202.07260v1 [cs.LG])
57. Stochastic Gradient Descent-Ascent: Unified Theory and New Efficient Methods. (arXiv:2202.07262v1 [math.OC])
58. Convolutional Network Fabric Pruning With Label Noise. (arXiv:2202.07268v1 [cs.LG])
59. SpeechPainter: Text-conditioned Speech Inpainting. (arXiv:2202.07273v1 [cs.SD])
60. HiMA: A Fast and Scalable History-based Memory Access Engine for Differentiable Neural Computer. (arXiv:2202.07275v1 [cs.AR])
61. Adaptive Conformal Predictions for Time Series. (arXiv:2202.07282v1 [stat.ML])
62. Don't stop the training: continuously-updating self-supervised algorithms best account for auditory responses in the cortex. (arXiv:2202.07290v1 [q-bio.NC])
63. Contextual Importance and Utility: aTheoretical Foundation. (arXiv:2202.07292v1 [cs.AI])
64. User-Oriented Robust Reinforcement Learning. (arXiv:2202.07301v1 [cs.LG])
65. XAI for Transformers: Better Explanations through Conservative Propagation. (arXiv:2202.07304v1 [cs.LG])
66. An algorithmic solution to the Blotto game using multi-marginal couplings. (arXiv:2202.07318v1 [cs.GT])
67. Unreasonable Effectiveness of Last Hidden Layer Activations. (arXiv:2202.07342v1 [cs.LG])
68. Generalisation and the Risk--Entropy Curve. (arXiv:2202.07350v1 [cs.LG])
69. Realistic Counterfactual Explanations by Learned Relations. (arXiv:2202.07356v1 [stat.ML])
70. A Unified Framework for Masked and Mask-Free Face Recognition via Feature Rectification. (arXiv:2202.07358v1 [cs.CV])
71. textless-lib: a Library for Textless Spoken Language Processing. (arXiv:2202.07359v1 [cs.CL])
72. Zero-Shot Assistance in Novel Decision Problems. (arXiv:2202.07364v1 [cs.LG])
73. A Statistical Learning View of Simple Kriging. (arXiv:2202.07365v1 [stat.ML])
74. Personalized Prompt Learning for Explainable Recommendation. (arXiv:2202.07371v1 [cs.IR])
75. Exploring Deep Reinforcement Learning-Assisted Federated Learning for Online Resource Allocation in EdgeIoT. (arXiv:2202.07391v1 [cs.LG])
76. Deep learning and differential equations for modeling changes in individual-level latent dynamics between observation periods. (arXiv:2202.07403v1 [stat.ML])
77. Interpretable Reinforcement Learning with Multilevel Subgoal Discovery. (arXiv:2202.07414v1 [cs.AI])
78. NeuPL: Neural Population Learning. (arXiv:2202.07415v1 [cs.AI])
79. Adversarial Attacks and Defense Methods for Power Quality Recognition. (arXiv:2202.07421v1 [cs.CR])
80. Explainable COVID-19 Infections Identification and Delineation Using Calibrated Pseudo Labels. (arXiv:2202.07422v1 [eess.IV])
81. DeepPAMM: Deep Piecewise Exponential Additive Mixed Models for Complex Hazard Structures in Survival Analysis. (arXiv:2202.07423v1 [stat.ML])
82. Algebraic function based Banach space valued ordinary and fractional neural network approximations. (arXiv:2202.07425v1 [stat.ML])
83. Artificial Intelligence-Based Analytics for Impacts of COVID-19 and Online Learning on College Students' Mental Health. (arXiv:2202.07441v1 [cs.CY])
84. Vau da muntanialas: Energy-efficient multi-die scalable acceleration of RNN inference. (arXiv:2202.07462v1 [cs.LG])
85. Can Online Customer Reviews Help Design More Sustainable Products? A Preliminary Study on Amazon Climate Pledge Friendly Products. (arXiv:2202.07463v1 [cs.CY])
86. DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
87. Federated Contrastive Learning for Dermatological Disease Diagnosis via On-device Learning. (arXiv:2202.07470v1 [cs.LG])
88. SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation. (arXiv:2202.07471v1 [cs.LG])
89. Sequential Bayesian experimental designs via reinforcement learning. (arXiv:2202.07472v1 [cs.LG])
90. MGCVAE: Multi-objective Inverse Design via Molecular Graph Conditional Variational Autoencoder. (arXiv:2202.07476v1 [cs.LG])
91. Understanding DDPM Latent Codes Through Optimal Transport. (arXiv:2202.07477v1 [stat.ML])
92. DualConv: Dual Convolutional Kernels for Lightweight Deep Neural Networks. (arXiv:2202.07481v1 [cs.CV])
93. Beyond the Policy Gradient Theorem for Efficient Policy Updates in Actor-Critic Algorithms. (arXiv:2202.07496v1 [cs.LG])
94. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v1 [cs.CV])
95. Confidence Threshold Neural Diving. (arXiv:2202.07506v1 [math.OC])
96. Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets. (arXiv:2202.07511v1 [cs.LG])
97. Optimal Algorithms for Stochastic Multi-Level Compositional Optimization. (arXiv:2202.07530v1 [cs.LG])
98. Closing the Management Gap for Satellite-Integrated Community Networks: A Hierarchical Approach to Self-Maintenance. (arXiv:2202.07532v1 [cs.NI])
99. Information-Theoretic Analysis of Minimax Excess Risk. (arXiv:2202.07537v1 [cs.LG])
100. Robust Multi-Objective Bayesian Optimization Under Input Noise. (arXiv:2202.07549v1 [cs.LG])
101. A Theory of PAC Learnability under Transformation Invariances. (arXiv:2202.07552v1 [cs.LG])
102. Between Stochastic and Adversarial Online Convex Optimization: Improved Regret Bounds via Smoothness. (arXiv:2202.07554v1 [cs.LG])
103. Unsupervised Learning of Group Invariant and Equivariant Representations. (arXiv:2202.07559v1 [cs.LG])
104. CUP: A Conservative Update Policy Algorithm for Safe Reinforcement Learning. (arXiv:2202.07565v1 [cs.LG])
105. StratDef: a strategic defense against adversarial attacks in malware detection. (arXiv:2202.07568v1 [cs.LG])
106. Damped Online Newton Step for Portfolio Selection. (arXiv:2202.07574v1 [cs.LG])
107. Forecasting Global Weather with Graph Neural Networks. (arXiv:2202.07575v1 [physics.ao-ph])
108. Multi-class granular approximation by means of disjoint and adjacent fuzzy granules. (arXiv:2202.07584v1 [cs.AI])
109. Deep Generative model with Hierarchical Latent Factors for Time Series Anomaly Detection. (arXiv:2202.07586v1 [cs.LG])
110. Identifying equivalent Calabi--Yau topologies: A discrete challenge from math and physics for machine learning. (arXiv:2202.07590v1 [hep-th])
111. Deep Convolutional Autoencoder for Assessment of Anomalies in Multi-stream Sensor Data. (arXiv:2202.07592v1 [cs.LG])
112. Bayesian Optimisation for Active Monitoring of Air Pollution. (arXiv:2202.07595v1 [cs.LG])
113. Bayesian Imitation Learning for End-to-End Mobile Manipulation. (arXiv:2202.07600v1 [cs.RO])
114. UserBERT: Modeling Long- and Short-Term User Preferences via Self-Supervision. (arXiv:2202.07605v1 [cs.LG])
115. Defending against Reconstruction Attacks with R\'enyi Differential Privacy. (arXiv:2202.07623v1 [cs.LG])
116. Random Feature Amplification: Feature Learning and Generalization in Neural Networks. (arXiv:2202.07626v1 [cs.LG])
117. Lie Point Symmetry Data Augmentation for Neural PDE Solvers. (arXiv:2202.07643v1 [cs.LG])
118. Quantifying Memorization Across Neural Language Models. (arXiv:2202.07646v1 [cs.LG])
119. EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning over Temporal Knowledge Graphs. (arXiv:2202.07648v1 [cs.LG])
120. Conformal Prediction Sets with Limited False Positives. (arXiv:2202.07650v1 [cs.LG])
121. Predicting on the Edge: Identifying Where a Larger Model Does Better. (arXiv:2202.07652v1 [cs.LG])
122. Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation. (arXiv:2202.07654v1 [cs.CL])
123. XEM: An Explainable-by-Design Ensemble Method for Multivariate Time Series Classification. (arXiv:2005.03645v5 [cs.LG] UPDATED)
124. Network Comparison with Interpretable Contrastive Network Representation Learning. (arXiv:2005.12419v2 [cs.LG] UPDATED)
125. MetaPerturb: Transferable Regularizer for Heterogeneous Tasks and Architectures. (arXiv:2006.07540v3 [cs.LG] UPDATED)
126. Approximate Midpoint Policy Iteration for Linear Quadratic Control. (arXiv:2011.14212v3 [math.OC] UPDATED)
127. Domain Invariant Representation Learning with Domain Density Transformations. (arXiv:2102.05082v3 [cs.LG] UPDATED)
128. Two Sides of the Same Coin: Heterophily and Oversmoothing in Graph Convolutional Neural Networks. (arXiv:2102.06462v6 [cs.LG] UPDATED)
129. Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others. (arXiv:2102.11938v4 [cs.AI] UPDATED)
130. A Survey on Graph Structure Learning: Progress and Opportunities. (arXiv:2103.03036v2 [cs.LG] UPDATED)
131. From Distributed Machine Learning to Federated Learning: A Survey. (arXiv:2104.14362v3 [cs.DC] UPDATED)
132. Development and evaluation of an Explainable Prediction Model for Chronic Kidney Disease Patients based on Ensemble Trees. (arXiv:2105.10368v3 [cs.LG] UPDATED)
133. FILTRA: Rethinking Steerable CNN by Filter Transform. (arXiv:2105.11636v2 [cs.CV] UPDATED)
134. Stein Latent Optimization for Generative Adversarial Networks. (arXiv:2106.05319v5 [cs.LG] UPDATED)
135. Learning distinct features helps, provably. (arXiv:2106.06012v2 [cs.LG] UPDATED)
136. Predicting cognitive scores with graph neural networks through sample selection learning. (arXiv:2106.09408v3 [cs.LG] UPDATED)
137. On Incorporating Inductive Biases into VAEs. (arXiv:2106.13746v2 [stat.ML] UPDATED)
138. Exploring convolutional neural networks with transfer learning for diagnosing Lyme disease from skin lesion images. (arXiv:2106.14465v2 [eess.IV] UPDATED)
139. A Non-parametric View of FedAvg and FedProx: Beyond Stationary Points. (arXiv:2106.15216v2 [stat.ML] UPDATED)
140. Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v3 [cs.LG] UPDATED)
141. Dual Training of Energy-Based Models with Overparametrized Shallow Neural Networks. (arXiv:2107.05134v2 [cs.LG] UPDATED)
142. FAST-PCA: A Fast and Exact Algorithm for Distributed Principal Component Analysis. (arXiv:2108.12373v2 [cs.LG] UPDATED)
143. A Guide to Computational Reproducibility in Signal Processing and Machine Learning. (arXiv:2108.12383v2 [eess.SP] UPDATED)
144. Scalable Spatiotemporally Varying Coefficient Modelling with Bayesian Kernelized Tensor Regression. (arXiv:2109.00046v2 [stat.ML] UPDATED)
145. A Robust Cybersecurity Topic Classification Tool. (arXiv:2109.02473v2 [cs.IR] UPDATED)
146. LEAF: Navigating Concept Drift in Cellular Networks. (arXiv:2109.03011v3 [cs.NI] UPDATED)
147. iRNN: Integer-only Recurrent Neural Network. (arXiv:2109.09828v2 [cs.LG] UPDATED)
148. Exploratory State Representation Learning. (arXiv:2109.13596v2 [cs.LG] UPDATED)
149. A Comprehensive Survey and Performance Analysis of Activation Functions in Deep Learning. (arXiv:2109.14545v2 [cs.LG] UPDATED)
150. A Generalized Hierarchical Nonnegative Tensor Decomposition. (arXiv:2109.14820v2 [cs.LG] UPDATED)
151. Coding for Straggler Mitigation in Federated Learning. (arXiv:2109.15226v2 [cs.LG] UPDATED)
152. Generating Disentangled Arguments with Prompts: A Simple Event Extraction Framework that Works. (arXiv:2110.04525v2 [cs.CL] UPDATED)
153. Implicit Bias of Linear Equivariant Networks. (arXiv:2110.06084v2 [cs.LG] UPDATED)
154. Toward Degradation-Robust Voice Conversion. (arXiv:2110.07537v2 [eess.AS] UPDATED)
155. Label-Wise Message Passing Graph Neural Network on Heterophilic Graphs. (arXiv:2110.08128v2 [cs.LG] UPDATED)
156. Probabilistic Time Series Forecasts with Autoregressive Transformation Models. (arXiv:2110.08248v2 [cs.LG] UPDATED)
157. RL4RS: A Real-World Benchmark for Reinforcement Learning based Recommender System. (arXiv:2110.11073v2 [cs.IR] UPDATED)
158. Wav2CLIP: Learning Robust Audio Representations From CLIP. (arXiv:2110.11499v2 [cs.SD] UPDATED)
159. Constrained Optimization Involving Nonconvex $\ell_p$ Norms: Optimality Conditions, Algorithm and Convergence. (arXiv:2110.14127v2 [math.OC] UPDATED)
160. Quasi-Newton Methods for Saddle Point Problems and Beyond. (arXiv:2111.02708v4 [math.OC] UPDATED)
161. Look back, look around: a systematic analysis of effective predictors for new outlinks in focused Web crawling. (arXiv:2111.05062v3 [cs.LG] UPDATED)
162. Textless Speech Emotion Conversion using Discrete and Decomposed Representations. (arXiv:2111.07402v2 [cs.CL] UPDATED)
163. Common Language for Goal-Oriented Semantic Communications: A Curriculum Learning Framework. (arXiv:2111.08051v3 [cs.NI] UPDATED)
164. Score-Based Generative Models for Robust Channel Estimation. (arXiv:2111.08177v2 [eess.SP] UPDATED)
165. Resilience from Diversity: Population-based approach to harden models against adversarial attacks. (arXiv:2111.10272v2 [cs.LG] UPDATED)
166. Track Boosting and Synthetic Data Aided Drone Detection. (arXiv:2111.12389v3 [cs.CV] UPDATED)
167. Self-Training of Halfspaces with Generalization Guarantees under Massart Mislabeling Noise Model. (arXiv:2111.14427v3 [cs.LG] UPDATED)
168. A machine learning analysis of the relationship between some underlying medical conditions and COVID-19 susceptibility. (arXiv:2112.12901v2 [cs.LG] UPDATED)
169. Deep convolutional neural network for shape optimization using level-set approach. (arXiv:2201.06210v3 [math.OC] UPDATED)
170. SCOTCH: An Efficient Secure Computation Framework for Secure Aggregation. (arXiv:2201.07730v2 [cs.CR] UPDATED)
171. Stochastic normalizing flows as non-equilibrium transformations. (arXiv:2201.08862v2 [hep-lat] UPDATED)
172. End-to-End Neural Speech Coding for Real-Time Communications. (arXiv:2201.09429v3 [cs.SD] UPDATED)
173. Analytic Mutual Information in Bayesian Neural Networks. (arXiv:2201.09815v2 [cs.IT] UPDATED)
174. OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v2 [q-bio.BM] UPDATED)
175. Constructing coarse-scale bifurcation diagrams from spatio-temporal observations of microscopic simulations: A parsimonious machine learning approach. (arXiv:2201.13323v2 [math.DS] UPDATED)
176. SUGAR: Efficient Subgraph-level Training via Resource-aware Graph Partitioning. (arXiv:2202.00075v2 [cs.LG] UPDATED)
177. On solutions of the distributional Bellman equation. (arXiv:2202.00081v2 [stat.ML] UPDATED)
178. Imbedding Deep Neural Networks. (arXiv:2202.00113v2 [cs.LG] UPDATED)
179. Context Uncertainty in Contextual Bandits with Applications to Recommender Systems. (arXiv:2202.00805v2 [cs.LG] UPDATED)
180. Understanding Knowledge Integration in Language Models with Graph Convolutions. (arXiv:2202.00964v4 [cs.CL] UPDATED)
181. A survey on computational learning methods for analysis of gene expression data in genomics. (arXiv:2202.02958v3 [q-bio.GN] UPDATED)
182. Log-based Anomaly Detection with Deep Learning: How Far Are We?. (arXiv:2202.04301v2 [cs.SE] UPDATED)
183. AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks. (arXiv:2202.04996v2 [cs.LG] UPDATED)
184. Feature-level augmentation to improve robustness of deep neural networks to affine transformations. (arXiv:2202.05152v3 [cs.CV] UPDATED)
185. Machine Learning and Data Science: Foundations, Concepts, Algorithms, and Tools. (arXiv:2202.05163v2 [cs.LG] UPDATED)
186. End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking. (arXiv:2202.05826v2 [cs.LG] UPDATED)
187. Physics-Guided Problem Decomposition for Scaling Deep Learning of High-dimensional Eigen-Solvers: The Case of Schr\"{o}dinger's Equation. (arXiv:2202.05994v2 [cs.LG] UPDATED)
188. Robust Learning from Observation with Model Misspecification. (arXiv:2202.06003v2 [cs.LG] UPDATED)
189. Asymptotically Unbiased Estimation for Delayed Feedback Modeling via Label Correction. (arXiv:2202.06472v2 [cs.LG] UPDATED)
190. ADeADA: Adaptive Density-aware Active Domain Adaptation for Semantic Segmentation. (arXiv:2202.06484v2 [cs.CV] UPDATED)
191. Partially Fake Audio Detection by Self-attention-based Fake Span Discovery. (arXiv:2202.06684v2 [eess.AS] UPDATED)
192. Continual Learning from Demonstration of Robotic Skills. (arXiv:2202.06843v2 [cs.RO] UPDATED)
193. Slicing Aided Hyper Inference and Fine-tuning for Small Object Detection. (arXiv:2202.06934v2 [cs.CV] UPDATED)
194. Flexible learning of quantum states with generative query neural networks. (arXiv:2202.06804v1 [quant-ph] CROSS LISTED)
## cs.AI
---
**88** new papers in cs.AI:-) 
1. ASC me to Do Anything: Multi-task Training for Embodied AI. (arXiv:2202.06987v1 [cs.CV])
2. Transformer Memory as a Differentiable Search Index. (arXiv:2202.06991v1 [cs.CL])
3. Robust Policy Learning over Multiple Uncertainty Sets. (arXiv:2202.07013v1 [cs.LG])
4. QuadSim: A Quadcopter Rotational Dynamics Simulation Framework For Reinforcement Learning Algorithms. (arXiv:2202.07021v1 [cs.LG])
5. One Step at a Time: Long-Horizon Vision-and-Language Navigation with Milestones. (arXiv:2202.07028v1 [cs.AI])
6. Artificial Intelligence-Based Smart Grid Vulnerabilities and Potential Solutions for Fake-Normal Attacks: A Short Review. (arXiv:2202.07050v1 [cs.CR])
7. Automatic Generation of Individual Fuzzy Cognitive Maps from Longitudinal Data. (arXiv:2202.07065v1 [cs.AI])
8. Motivating Physical Activity via Competitive Human-Robot Interaction. (arXiv:2202.07068v1 [cs.RO])
9. A Unified Perspective on Value Backup and Exploration in Monte-Carlo Tree Search. (arXiv:2202.07071v1 [cs.AI])
10. Benchmarking Robot Manipulation with the Rubik's Cube. (arXiv:2202.07074v1 [cs.RO])
11. Learning to Discover Medicines. (arXiv:2202.07096v1 [cs.AI])
12. A Survey on Dynamic Neural Networks for Natural Language Processing. (arXiv:2202.07101v1 [cs.CL])
13. A Survey on Model Compression for Natural Language Processing. (arXiv:2202.07105v1 [cs.CL])
14. Learning to Mitigate AI Collusion on Economic Platforms. (arXiv:2202.07106v1 [cs.MA])
15. Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework. (arXiv:2202.07123v1 [cs.CV])
16. Transformers in Time Series: A Survey. (arXiv:2202.07125v1 [cs.LG])
17. Integrating AI Planning with Natural Language Processing: A Combination of Explicit and Tacit Knowledge. (arXiv:2202.07138v1 [cs.AI])
18. On Tracking Dialogue State by Inheriting Slot Values in Mentioned Slot Pools. (arXiv:2202.07156v1 [cs.CL])
19. Fairness Amidst Non-IID Graph Data: A Literature Review. (arXiv:2202.07170v1 [cs.LG])
20. G-Mixup: Graph Data Augmentation for Graph Classification. (arXiv:2202.07179v1 [cs.LG])
21. A Survey of Neural Trojan Attacks and Defenses in Deep Learning. (arXiv:2202.07183v1 [cs.CR])
22. Unsupervised word-level prosody tagging for controllable speech synthesis. (arXiv:2202.07200v1 [eess.AS])
23. Holistic Adversarial Robustness of Deep Learning Models. (arXiv:2202.07201v1 [cs.LG])
24. Case law retrieval: problems, methods, challenges and evaluations in the last 20 years. (arXiv:2202.07209v1 [cs.IR])
25. Few-shot semantic segmentation via mask aggregation. (arXiv:2202.07231v1 [cs.CV])
26. Eliciting Best Practices for Collaboration with Computational Notebooks. (arXiv:2202.07233v1 [cs.HC])
27. Learning to Solve Routing Problems via Distributionally Robust Optimization. (arXiv:2202.07241v1 [cs.LG])
28. Explaining Reject Options of Learning Vector Quantization Classifiers. (arXiv:2202.07244v1 [cs.LG])
29. CommerceMM: Large-Scale Commerce MultiModal Representation Learning with Omni Retrieval. (arXiv:2202.07247v1 [cs.CV])
30. Enhancing Cross-lingual Prompting with Mask Token Augmentation. (arXiv:2202.07255v1 [cs.CL])
31. HiMA: A Fast and Scalable History-based Memory Access Engine for Differentiable Neural Computer. (arXiv:2202.07275v1 [cs.AR])
32. Don't stop the training: continuously-updating self-supervised algorithms best account for auditory responses in the cortex. (arXiv:2202.07290v1 [q-bio.NC])
33. Contextual Importance and Utility: aTheoretical Foundation. (arXiv:2202.07292v1 [cs.AI])
34. Unreasonable Effectiveness of Last Hidden Layer Activations. (arXiv:2202.07342v1 [cs.LG])
35. MuLD: The Multitask Long Document Benchmark. (arXiv:2202.07362v1 [cs.CL])
36. Zero-Shot Assistance in Novel Decision Problems. (arXiv:2202.07364v1 [cs.LG])
37. Personalized Prompt Learning for Explainable Recommendation. (arXiv:2202.07371v1 [cs.IR])
38. Interpreting a Machine Learning Model for Detecting Gravitational Waves. (arXiv:2202.07399v1 [gr-qc])
39. Knowledge Graph Reasoning with Logics and Embeddings: Survey and Perspective. (arXiv:2202.07412v1 [cs.AI])
40. Interpretable Reinforcement Learning with Multilevel Subgoal Discovery. (arXiv:2202.07414v1 [cs.AI])
41. NeuPL: Neural Population Learning. (arXiv:2202.07415v1 [cs.AI])
42. Adversarial Attacks and Defense Methods for Power Quality Recognition. (arXiv:2202.07421v1 [cs.CR])
43. A precortical module for robust CNNs to light variations. (arXiv:2202.07432v1 [cs.CV])
44. State of AI Ethics Report (Volume 6, February 2022). (arXiv:2202.07435v1 [cs.CY])
45. Relational Artificial Intelligence. (arXiv:2202.07446v1 [cs.CY])
46. Trustworthy Autonomous Systems (TAS): Engaging TAS experts in curriculum design. (arXiv:2202.07447v1 [cs.CY])
47. Vau da muntanialas: Energy-efficient multi-die scalable acceleration of RNN inference. (arXiv:2202.07462v1 [cs.LG])
48. DeepSensor: Deep Learning Testing Framework Based on Neuron Sensitivity. (arXiv:2202.07464v1 [cs.LG])
49. Federated Contrastive Learning for Dermatological Disease Diagnosis via On-device Learning. (arXiv:2202.07470v1 [cs.LG])
50. SQuant: On-the-Fly Data-Free Quantization via Diagonal Hessian Approximation. (arXiv:2202.07471v1 [cs.LG])
51. Do Lessons from Metric Learning Generalize to Image-Caption Retrieval?. (arXiv:2202.07474v1 [cs.CV])
52. Understanding DDPM Latent Codes Through Optimal Transport. (arXiv:2202.07477v1 [stat.ML])
53. Beyond the Policy Gradient Theorem for Efficient Policy Updates in Actor-Critic Algorithms. (arXiv:2202.07496v1 [cs.LG])
54. BED: A Real-Time Object Detection System for Edge Devices. (arXiv:2202.07503v1 [cs.CV])
55. Confidence Threshold Neural Diving. (arXiv:2202.07506v1 [math.OC])
56. Robust Multi-Objective Bayesian Optimization Under Input Noise. (arXiv:2202.07549v1 [cs.LG])
57. On Deciding Feature Membership in Explanations of SDD & Related Classifiers. (arXiv:2202.07553v1 [cs.AI])
58. CUP: A Conservative Update Policy Algorithm for Safe Reinforcement Learning. (arXiv:2202.07565v1 [cs.LG])
59. Multi-class granular approximation by means of disjoint and adjacent fuzzy granules. (arXiv:2202.07584v1 [cs.AI])
60. A General Framework for Modelling Conditional Reasoning -- Preliminary Report. (arXiv:2202.07596v1 [cs.AI])
61. Fairness Indicators for Systematic Assessments of Visual Feature Extractors. (arXiv:2202.07603v1 [cs.CV])
62. UserBERT: Modeling Long- and Short-Term User Preferences via Self-Supervision. (arXiv:2202.07605v1 [cs.LG])
63. Defending against Reconstruction Attacks with R\'enyi Differential Privacy. (arXiv:2202.07623v1 [cs.LG])
64. Wireless Resource Management in Intelligent Semantic Communication Networks. (arXiv:2202.07632v1 [cs.NI])
65. EvoKG: Jointly Modeling Event Time and Network Structure for Reasoning over Temporal Knowledge Graphs. (arXiv:2202.07648v1 [cs.LG])
66. Predicting on the Edge: Identifying Where a Larger Model Does Better. (arXiv:2202.07652v1 [cs.LG])
67. Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others. (arXiv:2102.11938v4 [cs.AI] UPDATED)
68. From Distributed Machine Learning to Federated Learning: A Survey. (arXiv:2104.14362v3 [cs.DC] UPDATED)
69. Development and evaluation of an Explainable Prediction Model for Chronic Kidney Disease Patients based on Ensemble Trees. (arXiv:2105.10368v3 [cs.LG] UPDATED)
70. Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v3 [cs.LG] UPDATED)
71. Multi-Scale STATCN: Self-Attention based Spatiotemporal Model for Short-Term Metro Origin-Destination Matrix Prediction. (arXiv:2108.03900v5 [cs.AI] UPDATED)
72. Team Power Dynamics and Team Impact: New Perspectives on Scientific Collaboration using Career Age as a Proxy for Team Power. (arXiv:2108.04108v4 [physics.soc-ph] UPDATED)
73. Vision-Aided Autonomous Navigation of Underactuated Bipedal Robots in Height-Constrained Environments. (arXiv:2109.05714v3 [cs.RO] UPDATED)
74. Generating Disentangled Arguments with Prompts: A Simple Event Extraction Framework that Works. (arXiv:2110.04525v2 [cs.CL] UPDATED)
75. Implicit Bias of Linear Equivariant Networks. (arXiv:2110.06084v2 [cs.LG] UPDATED)
76. Knowledge Graph informed Fake News Classification via Heterogeneous Representation Ensembles. (arXiv:2110.10457v2 [cs.CL] UPDATED)
77. Textless Speech Emotion Conversion using Discrete and Decomposed Representations. (arXiv:2111.07402v2 [cs.CL] UPDATED)
78. Variational Autoencoders for Precoding Matrices with High Spectral Efficiency. (arXiv:2111.15626v4 [eess.SP] UPDATED)
79. Semantic and sentiment analysis of selected Bhagavad Gita translations using BERT-based language framework. (arXiv:2201.03115v2 [cs.CL] UPDATED)
80. SUGAR: Efficient Subgraph-level Training via Resource-aware Graph Partitioning. (arXiv:2202.00075v2 [cs.LG] UPDATED)
81. Context Uncertainty in Contextual Bandits with Applications to Recommender Systems. (arXiv:2202.00805v2 [cs.LG] UPDATED)
82. Zero-Shot Aspect-Based Sentiment Analysis. (arXiv:2202.01924v3 [cs.CL] UPDATED)
83. Unsupervised Learning on 3D Point Clouds by Clustering and Contrasting. (arXiv:2202.02543v2 [cs.CV] UPDATED)
84. A survey on computational learning methods for analysis of gene expression data in genomics. (arXiv:2202.02958v3 [q-bio.GN] UPDATED)
85. AA-TransUNet: Attention Augmented TransUNet For Nowcasting Tasks. (arXiv:2202.04996v2 [cs.LG] UPDATED)
86. End-to-end Algorithm Synthesis with Recurrent Networks: Logical Extrapolation Without Overthinking. (arXiv:2202.05826v2 [cs.LG] UPDATED)
87. Improving Graph Collaborative Filtering with Neighborhood-enriched Contrastive Learning. (arXiv:2202.06200v2 [cs.IR] UPDATED)
88. Diverse facial inpainting guided by exemplars. (arXiv:2202.06358v2 [cs.CV] UPDATED)

