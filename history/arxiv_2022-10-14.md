# Your interest papers
---
## cs.CV
---
### VR-SFT: Reproducing **Swin**ging Flashlight Test in Virtual Reality to Detect Relative Afferent Pupillary Defect. (arXiv:2210.06474v1 [cs.HC])
- Authors : Prithul Sarker, Nasif Zaman, Alireza Tavakkoli
- Link : [http://arxiv.org/abs/2210.06474](http://arxiv.org/abs/2210.06474)
> ABSTRACT  :  The relative afferent asymmetry between two eyes can be diagnosed using swinging flashlight test, also known as the alternating light test. This remains one of the most used clinical tests to this day. Despite the swinging flashlight test's straightforward approach, a number of factors can add variability into the clinical methodology and reduce the measurement's validity and reliability. This includes small and poorly responsive pupils, **dark** iris, anisocoria, uneven illumination in both eyes. Due to these limitations, the true condition of relative afferent asymmetry may create confusion and various observers may quantify the relative afferent pupillary defect differently. Consequently, the results of the swinging flashlight test are subjective and ambiguous. In order to eliminate the limitations of traditional swinging flashlight test and introduce objectivity, we propose a novel approach to the swinging flashlight exam, VR-SFT, by making use of virtual reality (VR). We suggest that the clinical records of the subjects and the results of VR-SFT are comparable. In this paper, we describe how we exploit the features of immersive VR experience to create a reliable and objective swinging flashlight test.  
### Flare7K: A Phenomenological **Night**time Flare Removal Dataset. (arXiv:2210.06570v1 [cs.CV])
- Authors : Yuekun Dai, **Chongyi Li**, Shangchen Zhou, Ruicheng Feng, Chen Change
- Link : [http://arxiv.org/abs/2210.06570](http://arxiv.org/abs/2210.06570)
> ABSTRACT  :  Artificial lights commonly leave strong lens flare artifacts on images captured at **night**. **Night**time flare not only affects the visual quality but also degrades the performance of vision algorithms. Existing flare removal methods mainly focus on removing daytime flares and fail in **night**time. **Night**time flare removal is challenging because of the unique luminance and spectrum of artificial lights and the diverse patterns and image degradation of the flares captured at **night**. The scarcity of **night**time flare removal datasets limits the research on this crucial task. In this paper, we introduce, Flare7K, the first **night**time flare removal dataset, which is generated based on the observation and statistics of real-world **night**time lens flares. It offers 5,000 scattering and 2,000 reflective flare images, consisting of 25 types of scattering flares and 10 types of reflective flares. The 7,000 flare patterns can be randomly added to flare-free images, forming the flare-corrupted and flare-free image pairs. With the paired data, we can train deep models to restore flare-corrupted images taken in the real world effectively. Apart from abundant flare patterns, we also provide rich annotations, including the labeling of light source, glare with shimmer, reflective flare, and streak, which are commonly absent from existing datasets. Hence, our dataset can facilitate new work in **night**time flare removal and more fine-grained analysis of flare patterns. Extensive experiments show that our dataset adds diversity to existing flare datasets and pushes the frontier of **night**time flare removal.  
### Automatic **Real-time** Vehicle Classification by Image Colour Component Based Template Matching. (arXiv:2210.06586v1 [cs.CV])
- Authors : Ahmet Orun
- Link : [http://arxiv.org/abs/2210.06586](http://arxiv.org/abs/2210.06586)
> ABSTRACT  :  Selection of appropriate template matching algorithms to run effectively on real-time low-cost systems is always major issue. This is due to unpredictable changes in image scene which often necessitate more sophisticated real-time algorithms to retain image consistency. Inefficiency of low cost auxiliary hardware and time limitations are the major constraints in using these sorts of algorithms. The real-time system introduced here copes with these problems utilising a fast running template matching algorithm, which makes use of best colour band selection. The system uses fast running real-time algorithms to achieve template matching and vehicle classification at about 4 frames /sec. on low-cost hardware. The colour image sequences have been taken by a fixed CCTV camera overlooking a busy multi-lane road  
### Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer. (arXiv:2210.06707v1 [cs.CV])
- Authors : Yanjing Li, Sheng Xu, Baochang Zhang, Xianbin Cao, Peng Gao, Guodong Guo
- Link : [http://arxiv.org/abs/2210.06707](http://arxiv.org/abs/2210.06707)
> ABSTRACT  :  The large pre-trained vision transformers (ViTs) have demonstrated remarkable performance on various visual tasks, but suffer from expensive computational and memory cost problems when deployed on resource-constrained devices. Among the powerful compression approaches, quantization extremely reduces the computation and memory consumption by low-bit parameters and bit-wise operations. However, low-bit ViTs remain largely unexplored and usually suffer from a significant performance drop compared with the real-valued counterparts. In this work, through extensive empirical analysis, we first identify the bottleneck for severe performance drop comes from the information distortion of the low-bit quantized self-attention map. We then develop an information rectification module (IRM) and a distribution guided distillation (DGD) scheme for fully quantized vision transformers (Q-ViT) to effectively eliminate such distortion, leading to a fully quantized ViTs. We evaluate our methods on popular DeiT and **Swin** backbones. Extensive experimental results show that our method achieves a much better performance than the prior arts. For example, our Q-ViT can theoretically accelerates the ViT-S by 6.14x and achieves about 80.9% Top-1 accuracy, even surpassing the full-precision counterpart by 1.0% on ImageNet dataset. Our codes and models are attached on https://github.com/YanjingLi0202/Q-ViT  
### Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
- Authors : Jesus Pineda, Daniela Rueda, Alejandro Tello, Virgilio Galvis, Giovanni Volpe
- Link : [http://arxiv.org/abs/2210.07102](http://arxiv.org/abs/2210.07102)
> ABSTRACT  :  Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of **dark** image regions called guttae. This paper proposes a UNet-based segmentation approach that requires minimal post-processing and achieves reliable CE morphometric assessment and guttae identification across all degrees of Fuchs' dystrophy. We cast the segmentation problem as a regression task of the cell and gutta signed distance maps instead of a pixel-level classification task as typically done with UNets. Compared to the conventional UNet classification approach, the distance-map regression approach converges faster in clinically relevant parameters. It also produces morphometric parameters that agree with the manually-segmented ground-truth data, namely the average cell density difference of -41.9 cells/mm2 (95% confidence interval (CI) [-306.2, 222.5]) and the average difference of mean cell area of 14.8 um2 (95% CI [-41.9, 71.5]). These results suggest a promising alternative for CE assessment.  
### **Swin**Track: A Simple and Strong Baseline for Transformer Tracking. (arXiv:2112.00995v3 [cs.CV] UPDATED)
- Authors : Liting Lin, Heng Fan, Zhipeng Zhang, Yong Xu, Haibin Ling
- Link : [http://arxiv.org/abs/2112.00995](http://arxiv.org/abs/2112.00995)
> ABSTRACT  :  Recently Transformer has been largely explored in tracking and shown state-of-the-art (SOTA) performance. However, existing efforts mainly focus on fusing and enhancing features generated by convolutional neural networks (CNNs). The potential of Transformer in representation learning remains under-explored. In this paper, we aim to further unleash the power of Transformer by proposing a simple yet efficient fully-attentional tracker, dubbed **Swin**Track, within classic Siamese framework. In particular, both representation learning and feature fusion in **Swin**Track leverage the Transformer architecture, enabling better feature interactions for tracking than pure CNN or hybrid CNN-Transformer frameworks. Besides, to further enhance robustness, we present a novel motion token that embeds historical target trajectory to improve tracking by providing temporal context. Our motion token is lightweight with negligible computation but brings clear gains. In our thorough experiments, **Swin**Track exceeds existing approaches on multiple benchmarks. Particularly, on the challenging LaSOT, **Swin**Track sets a new record with 0.713 SUC score. It also achieves SOTA results on other benchmarks. We expect **Swin**Track to serve as a solid baseline for Transformer tracking and facilitate future research. Our codes and results are released at https://github.com/LitingLin/**Swin**Track.  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
### LDRNet: Enabling **Real-time** Document Localization on Mobile Devices. (arXiv:2206.02136v2 [cs.CV] UPDATED)
- Authors : Han Wu, Holland Qian, Huaming Wu, Aad van
- Link : [http://arxiv.org/abs/2206.02136](http://arxiv.org/abs/2206.02136)
> ABSTRACT  :  While Identity Document Verification (IDV) technology on mobile devices becomes ubiquitous in modern business operations, the risk of identity theft and fraud is increasing. The identity document holder is normally required to participate in an online video interview to circumvent impostors. However, the current IDV process depends on an additional human workforce to support online step-by-step guidance which is inefficient and expensive. The performance of existing AI-based approaches cannot meet the real-time and lightweight demands of mobile devices. In this paper, we address those challenges by designing an edge intelligence-assisted approach for real-time IDV. Aiming at improving the responsiveness of the IDV process, we propose a new document localization model for mobile devices, LDRNet, to Localize the identity Document in **Real-time**. On the basis of a lightweight backbone network, we build three prediction branches for LDRNet, the corner points prediction, the line borders prediction and the document classification. We design novel supplementary targets, the equal-division points, and use a new loss function named Line Loss, to improve the speed and accuracy of our approach. In addition to the IDV process, LDRNet is an efficient and reliable document localization alternative for all kinds of mobile applications. As a matter of proof, we compare the performance of LDRNet with other popular approaches on localizing general document datasets. The experimental results show that LDRNet runs at a speed up to 790 FPS which is 47x faster, while still achieving comparable Jaccard Index(JI) in single-model and single-scale tests.  
### PP-StructureV2: A Stronger Document Analysis System. (arXiv:2210.05391v2 [cs.CV] UPDATED)
- Authors : Chenxia Li, Ruoyu Guo, Jun Zhou, Mengtao An, Yuning Du, Lingfeng Zhu, Yi Liu, Xiaoguang Hu, Dianhai Yu
- Link : [http://arxiv.org/abs/2210.05391](http://arxiv.org/abs/2210.05391)
> ABSTRACT  :  A large amount of document data exists in unstructured form such as raw images without any text information. Designing a practical document image analysis system is a meaningful but challenging task. In previous work, we proposed an intelligent document analysis system PP-Structure. In order to further upgrade the function and performance of PP-Structure, we propose PP-StructureV2 in this work, which contains two subsystems: Layout Information Extraction and Key Information Extraction. Firstly, we integrate Image Direction Correction module and Layout **Restoration** module to enhance the functionality of the system. Secondly, 8 practical strategies are utilized in PP-StructureV2 for better performance. For Layout Analysis model, we introduce ultra light-weight detector PP-PicoDet and knowledge distillation algorithm FGD for model lightweighting, which increased the inference speed by 11 times with comparable mAP. For Table Recognition model, we utilize PP-LCNet, CSP-PAN and SLAHead to optimize the backbone module, feature fusion module and decoding module, respectively, which improved the table structure accuracy by 6\% with comparable inference speed. For Key Information Extraction model, we introduce VI-LayoutXLM which is a visual-feature independent LayoutXLM architecture, TB-YX sorting algorithm and U-DML knowledge distillation algorithm, which brought 2.8\% and 9.1\% improvement respectively on the Hmean of Semantic Entity Recognition and Relation Extraction tasks. All the above mentioned models and code are open-sourced in the GitHub repository PaddleOCR.  
## eess.IV
---
### Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
- Authors : Jesus Pineda, Daniela Rueda, Alejandro Tello, Virgilio Galvis, Giovanni Volpe
- Link : [http://arxiv.org/abs/2210.07102](http://arxiv.org/abs/2210.07102)
> ABSTRACT  :  Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of **dark** image regions called guttae. This paper proposes a UNet-based segmentation approach that requires minimal post-processing and achieves reliable CE morphometric assessment and guttae identification across all degrees of Fuchs' dystrophy. We cast the segmentation problem as a regression task of the cell and gutta signed distance maps instead of a pixel-level classification task as typically done with UNets. Compared to the conventional UNet classification approach, the distance-map regression approach converges faster in clinically relevant parameters. It also produces morphometric parameters that agree with the manually-segmented ground-truth data, namely the average cell density difference of -41.9 cells/mm2 (95% confidence interval (CI) [-306.2, 222.5]) and the average difference of mean cell area of 14.8 um2 (95% CI [-41.9, 71.5]). These results suggest a promising alternative for CE assessment.  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
## cs.LG
---
### An $\alpha$-regret analysis of Adversarial **Bilateral** Trade. (arXiv:2210.06846v1 [cs.GT])
- Authors : Yossi Azar, Amos Fiat, Federico Fusco
- Link : [http://arxiv.org/abs/2210.06846](http://arxiv.org/abs/2210.06846)
> ABSTRACT  :  We study sequential **bilateral** trade where sellers and buyers valuations are completely arbitrary (i.e., determined by an adversary). Sellers and buyers are strategic agents with private valuations for the good and the goal is to design a mechanism that maximizes efficiency (or gain from trade) while being incentive compatible, individually rational and budget balanced. In this paper we consider gain from trade which is harder to approximate than social welfare.    We consider a variety of feedback scenarios and distinguish the cases where the mechanism posts one price and when it can post different prices for buyer and seller. We show several surprising results about the separation between the different scenarios. In particular we show that (a) it is impossible to achieve sublinear $\alpha$-regret for any $\alpha&lt;2$, (b) but with full feedback sublinear $2$-regret is achievable (c) with a single price and partial feedback one cannot get sublinear $\alpha$ regret for any constant $\alpha$ (d) nevertheless, posting two prices even with one-bit feedback achieves sublinear $2$-regret, and (e) there is a provable separation in the $2$-regret bounds between full and partial feedback.  
### Learning Physical Dynamics with Subequivariant Graph Neural Networks. (arXiv:2210.06876v1 [cs.LG])
- Authors : Jiaqi Han, Wenbing Huang, Hengbo Ma, Jiachen Li, Chuang Gan
- Link : [http://arxiv.org/abs/2210.06876](http://arxiv.org/abs/2210.06876)
> ABSTRACT  :  Graph Neural Networks (GNNs) have become a prevailing tool for learning physical dynamics. However, they still encounter several challenges: 1) Physical laws abide by symmetry, which is a vital inductive bias accounting for model generalization and should be incorporated into the model design. Existing simulators either consider insufficient symmetry, or enforce excessive equivariance in practice when symmetry is partially broken by gravity. 2) Objects in the physical world possess diverse shapes, sizes, and properties, which should be appropriately processed by the model. To tackle these difficulties, we propose a novel backbone, Subequivariant Graph Neural Network, which 1) relaxes equivariance to subequivariance by considering external fields like gravity, where the universal approximation ability holds theoretically; 2) introduces a new subequivariant object-aware message passing for learning physical interactions between multiple objects of various shapes in the particle-based representation; 3) operates in a hierarchical fashion, allowing for modeling long-range and complex interactions. Our model achieves on average over 3% **enhancement** in contact prediction accuracy across 8 scenarios on Physion and 2X lower rollout MSE on RigidFall compared with state-of-the-art GNN simulators, while exhibiting strong generalization and data efficiency.  
### Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
- Authors : Jesus Pineda, Daniela Rueda, Alejandro Tello, Virgilio Galvis, Giovanni Volpe
- Link : [http://arxiv.org/abs/2210.07102](http://arxiv.org/abs/2210.07102)
> ABSTRACT  :  Specular microscopy assessment of the human corneal endothelium (CE) in Fuchs' dystrophy is challenging due to the presence of **dark** image regions called guttae. This paper proposes a UNet-based segmentation approach that requires minimal post-processing and achieves reliable CE morphometric assessment and guttae identification across all degrees of Fuchs' dystrophy. We cast the segmentation problem as a regression task of the cell and gutta signed distance maps instead of a pixel-level classification task as typically done with UNets. Compared to the conventional UNet classification approach, the distance-map regression approach converges faster in clinically relevant parameters. It also produces morphometric parameters that agree with the manually-segmented ground-truth data, namely the average cell density difference of -41.9 cells/mm2 (95% confidence interval (CI) [-306.2, 222.5]) and the average difference of mean cell area of 14.8 um2 (95% CI [-41.9, 71.5]). These results suggest a promising alternative for CE assessment.  
### Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
- Authors : Bahjat Kawar, Michael Elad, Stefano Ermon, Jiaming Song
- Link : [http://arxiv.org/abs/2201.11793](http://arxiv.org/abs/2201.11793)
> ABSTRACT  :  Many interesting tasks in image **restoration** can be cast as linear inverse problems. A recent family of approaches for solving these problems uses stochastic algorithms that sample from the posterior distribution of natural images given the measurements. However, efficient solutions often require problem-specific supervised training to model the posterior, whereas unsupervised methods that are not problem-specific typically rely on inefficient iterative methods. This work addresses these issues by introducing Denoising Diffusion **Restoration** Models (DDRM), an efficient, unsupervised posterior sampling method. Motivated by variational inference, DDRM takes advantage of a pre-trained denoising diffusion generative model for solving any linear inverse problem. We demonstrate DDRM's versatility on several image datasets for super-resolution, deblurring, inpainting, and colorization under various amounts of measurement noise. DDRM outperforms the current leading unsupervised methods on the diverse ImageNet dataset in reconstruction quality, perceptual quality, and runtime, being 5x faster than the nearest competitor. DDRM also generalizes well for natural images out of the distribution of the observed ImageNet training set.  
### FedRecAttack: Model Poisoning Attack to Federated Recommendation. (arXiv:2204.01499v2 [cs.CR] UPDATED)
- Authors : Dazhong Rong, Shuai Ye, Ruoyan Zhao, Hon Ning, Jianhai Chen, Qinming He
- Link : [http://arxiv.org/abs/2204.01499](http://arxiv.org/abs/2204.01499)
> ABSTRACT  :  Federated Recommendation (FR) has received considerable popularity and attention in the past few years. In FR, for each user, its feature vector and interaction data are kept locally on its own client thus are private to others. Without the access to above information, most existing poisoning attacks against recommender systems or federated learning lose validity. Benifiting from this characteristic, FR is commonly considered fairly secured. However, we argue that there is still possible and necessary security improvement could be made in FR. To prove our opinion, in this paper we present FedRecAttack, a model poisoning attack to FR aiming to raise the **exposure** ratio of target items. In most recommendation scenarios, apart from private user-item interactions (e.g., clicks, watches and purchases), some interactions are public (e.g., likes, follows and comments). Motivated by this point, in FedRecAttack we make use of the public interactions to approximate users' feature vectors, thereby attacker can generate poisoned gradients accordingly and control malicious users to upload the poisoned gradients in a well-designed way. To evaluate the effectiveness and side effects of FedRecAttack, we conduct extensive experiments on three real-world datasets of different sizes from two completely different scenarios. Experimental results demonstrate that our proposed FedRecAttack achieves the state-of-the-art effectiveness while its side effects are negligible. Moreover, even with small proportion (3%) of malicious users and small proportion (1%) of public interactions, FedRecAttack remains highly effective, which reveals that FR is more vulnerable to attack than people commonly considered.  
### SongDriver: **Real-time** Music Accompaniment Generation without Logical Latency nor **Exposure** Bias. (arXiv:2209.06054v2 [cs.SD] UPDATED)
- Authors : Zihao Wang, Qihao Liang, Kejun Zhang, Yuxing Wang, Chen Zhang, Pengfei Yu, Yongsheng Feng, Wenbo Liu, Yikai Wang, Yuntai Bao, Yiheng Yang
- Link : [http://arxiv.org/abs/2209.06054](http://arxiv.org/abs/2209.06054)
> ABSTRACT  :  **Real-time** music accompaniment generation has a wide range of applications in the music industry, such as music education and live performances. However, automatic real-time music accompaniment generation is still understudied and often faces a trade-off between logical latency and **exposure** bias. In this paper, we propose SongDriver, a real-time music accompaniment generation system without logical latency nor **exposure** bias. Specifically, SongDriver divides one accompaniment generation task into two phases: 1) The arrangement phase, where a Transformer model first arranges chords for input melodies in real-time, and caches the chords for the next phase instead of playing them out. 2) The prediction phase, where a CRF model generates playable multi-track accompaniments for the coming melodies based on previously cached chords. With this two-phase strategy, SongDriver directly generates the accompaniment for the upcoming melody, achieving zero logical latency. Furthermore, when predicting chords for a timestep, SongDriver refers to the cached chords from the first phase rather than its previous predictions, which avoids the **exposure** bias problem. Since the input length is often constrained under real-time conditions, another potential problem is the loss of long-term sequential information. To make up for this disadvantage, we extract four musical features from a long-term music piece before the current time step as global information. In the experiment, we train SongDriver on some open-source datasets and an original \`aiSong Dataset built from Chinese-style modern pop music scores. The results show that SongDriver outperforms existing SOTA (state-of-the-art) models on both objective and subjective metrics, meanwhile significantly reducing the physical latency.  
## cs.AI
---
### VR-SFT: Reproducing **Swin**ging Flashlight Test in Virtual Reality to Detect Relative Afferent Pupillary Defect. (arXiv:2210.06474v1 [cs.HC])
- Authors : Prithul Sarker, Nasif Zaman, Alireza Tavakkoli
- Link : [http://arxiv.org/abs/2210.06474](http://arxiv.org/abs/2210.06474)
> ABSTRACT  :  The relative afferent asymmetry between two eyes can be diagnosed using swinging flashlight test, also known as the alternating light test. This remains one of the most used clinical tests to this day. Despite the swinging flashlight test's straightforward approach, a number of factors can add variability into the clinical methodology and reduce the measurement's validity and reliability. This includes small and poorly responsive pupils, **dark** iris, anisocoria, uneven illumination in both eyes. Due to these limitations, the true condition of relative afferent asymmetry may create confusion and various observers may quantify the relative afferent pupillary defect differently. Consequently, the results of the swinging flashlight test are subjective and ambiguous. In order to eliminate the limitations of traditional swinging flashlight test and introduce objectivity, we propose a novel approach to the swinging flashlight exam, VR-SFT, by making use of virtual reality (VR). We suggest that the clinical records of the subjects and the results of VR-SFT are comparable. In this paper, we describe how we exploit the features of immersive VR experience to create a reliable and objective swinging flashlight test.  
### Automatic **Real-time** Vehicle Classification by Image Colour Component Based Template Matching. (arXiv:2210.06586v1 [cs.CV])
- Authors : Ahmet Orun
- Link : [http://arxiv.org/abs/2210.06586](http://arxiv.org/abs/2210.06586)
> ABSTRACT  :  Selection of appropriate template matching algorithms to run effectively on real-time low-cost systems is always major issue. This is due to unpredictable changes in image scene which often necessitate more sophisticated real-time algorithms to retain image consistency. Inefficiency of low cost auxiliary hardware and time limitations are the major constraints in using these sorts of algorithms. The real-time system introduced here copes with these problems utilising a fast running template matching algorithm, which makes use of best colour band selection. The system uses fast running real-time algorithms to achieve template matching and vehicle classification at about 4 frames /sec. on low-cost hardware. The colour image sequences have been taken by a fixed CCTV camera overlooking a busy multi-lane road  
### Learning Physical Dynamics with Subequivariant Graph Neural Networks. (arXiv:2210.06876v1 [cs.LG])
- Authors : Jiaqi Han, Wenbing Huang, Hengbo Ma, Jiachen Li, Chuang Gan
- Link : [http://arxiv.org/abs/2210.06876](http://arxiv.org/abs/2210.06876)
> ABSTRACT  :  Graph Neural Networks (GNNs) have become a prevailing tool for learning physical dynamics. However, they still encounter several challenges: 1) Physical laws abide by symmetry, which is a vital inductive bias accounting for model generalization and should be incorporated into the model design. Existing simulators either consider insufficient symmetry, or enforce excessive equivariance in practice when symmetry is partially broken by gravity. 2) Objects in the physical world possess diverse shapes, sizes, and properties, which should be appropriately processed by the model. To tackle these difficulties, we propose a novel backbone, Subequivariant Graph Neural Network, which 1) relaxes equivariance to subequivariance by considering external fields like gravity, where the universal approximation ability holds theoretically; 2) introduces a new subequivariant object-aware message passing for learning physical interactions between multiple objects of various shapes in the particle-based representation; 3) operates in a hierarchical fashion, allowing for modeling long-range and complex interactions. Our model achieves on average over 3% **enhancement** in contact prediction accuracy across 8 scenarios on Physion and 2X lower rollout MSE on RigidFall compared with state-of-the-art GNN simulators, while exhibiting strong generalization and data efficiency.  
### Threshold Treewidth and Hypertree Width. (arXiv:2210.07040v1 [cs.DS])
- Authors : Andre Schidler, Robert Ganian, Manuel Sorge, Stefan Szeider
- Link : [http://arxiv.org/abs/2210.07040](http://arxiv.org/abs/2210.07040)
> ABSTRACT  :  Treewidth and hypertree width have proven to be highly successful structural parameters in the context of the Constraint Satisfaction Problem (CSP). When either of these parameters is bounded by a constant, then CSP becomes solvable in polynomial time. However, here the order of the polynomial in the running time depends on the width, and this is known to be unavoidable; therefore, the problem is not fixed-parameter tractable parameterized by either of these width measures. Here we introduce an **enhancement** of tree and hypertree width through a novel notion of thresholds, allowing the associated decompositions to take into account information about the computational costs associated with solving the given CSP instance. Aside from introducing these notions, we obtain efficient theoretical as well as empirical algorithms for computing threshold treewidth and hypertree width and show that these parameters give rise to fixed-parameter algorithms for CSP as well as other, more general problems. We complement our theoretical results with experimental evaluations in terms of heuristics as well as exact methods based on SAT/SMT encodings.  
# Paper List
---
## cs.CV
---
**137** new papers in cs.CV:-) 
1. Subject-specific quantitative susceptibility mapping using patch based deep image priors. (arXiv:2210.06471v1 [eess.IV])
2. VR-SFT: Reproducing **Swin**ging Flashlight Test in Virtual Reality to Detect Relative Afferent Pupillary Defect. (arXiv:2210.06474v1 [cs.HC])
3. Attention-Based Generative Neural Image Compression on Solar Dynamics Observatory. (arXiv:2210.06478v1 [eess.IV])
4. Robust Action Segmentation from Timestamp Supervision. (arXiv:2210.06501v1 [cs.CV])
5. Quantifying U-Net Uncertainty in Multi-Parametric MRI-based Glioma Segmentation by Spherical Image Projection. (arXiv:2210.06512v1 [q-bio.QM])
6. Prepended Domain Transformer: Heterogeneous Face Recognition without Bells and Whistles. (arXiv:2210.06529v1 [cs.CV])
7. MotionBERT: Unified Pretraining for Human Motion Analysis. (arXiv:2210.06551v1 [cs.CV])
8. That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data. (arXiv:2210.06565v1 [cs.LG])
9. Flare7K: A Phenomenological **Night**time Flare Removal Dataset. (arXiv:2210.06570v1 [cs.CV])
10. GraspNeRF: Multiview-based 6-DoF Grasp Detection for Transparent and Specular Objects Using Generalizable NeRF. (arXiv:2210.06575v1 [cs.RO])
11. Task-Free Continual Learning via Online Discrepancy Distance Learning. (arXiv:2210.06579v1 [cs.CV])
12. S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces. (arXiv:2210.06583v1 [cs.CV])
13. Towards an Efficient ML System: Unveiling a Trade-off between Task Accuracy and Engineering Efficiency in a Large-scale Car Sharing Platform. (arXiv:2210.06585v1 [cs.CV])
14. Automatic **Real-time** Vehicle Classification by Image Colour Component Based Template Matching. (arXiv:2210.06586v1 [cs.CV])
15. Adversarial Attack Against Image-Based Localization Neural Networks. (arXiv:2210.06589v1 [cs.CV])
16. Reducing The Mismatch Between Marginal and Learned Distributions in Neural Video Compression. (arXiv:2210.06596v1 [cs.CV])
17. QMRNet: Quality Metric Regression for EO Image Quality Assessment and Super-Resolution. (arXiv:2210.06618v1 [cs.CV])
18. Fairness via Adversarial Attribute Neighbourhood Robust Learning. (arXiv:2210.06630v1 [cs.LG])
19. What's in a Decade? Transforming Faces Through Time. (arXiv:2210.06642v1 [cs.CV])
20. Structural Pruning via Latency-Saliency Knapsack. (arXiv:2210.06659v1 [cs.CV])
21. Are Macula or Optic Nerve Head Structures better at Diagnosing Glaucoma? An Answer using AI and Wide-Field Optical Coherence Tomography. (arXiv:2210.06664v1 [eess.IV])
22. Understanding the Effect of Smartphone Cameras on Estimating Munsell Soil Colors from Imagery. (arXiv:2210.06667v1 [cs.CV])
23. Brain Network Transformer. (arXiv:2210.06681v1 [cs.LG])
24. Application-Driven AI Paradigm for Hand-Held Action Detection. (arXiv:2210.06682v1 [cs.CV])
25. Overlooked Video Classification in Weakly Supervised Video Anomaly Detection. (arXiv:2210.06688v1 [cs.CV])
26. COLLIDER: A Robust Training Framework for Backdoor Data. (arXiv:2210.06704v1 [cs.LG])
27. Q-ViT: Accurate and Fully Quantized Low-bit Vision Transformer. (arXiv:2210.06707v1 [cs.CV])
28. A Stream Learning Approach for Real-Time Identification of False Data Injection Attacks in Cyber-Physical Power Systems. (arXiv:2210.06729v1 [cs.LG])
29. H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection. (arXiv:2210.06742v1 [cs.CV])
30. Reducing Annotation Effort by Identifying and Labeling Contextually Diverse Classes for Semantic Segmentation Under Domain Shift. (arXiv:2210.06749v1 [cs.CV])
31. Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features. (arXiv:2210.06756v1 [cs.CV])
32. Improving the Reliability for Confidence Estimation. (arXiv:2210.06776v1 [cs.CV])
33. X-Align: Cross-Modal Cross-View Alignment for Bird's-Eye-View Segmentation. (arXiv:2210.06778v1 [cs.CV])
34. Generalized Inter-class Loss for Gait Recognition. (arXiv:2210.06779v1 [cs.CV])
35. Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation. (arXiv:2210.06780v1 [cs.CV])
36. Evaluating the Label Efficiency of Contrastive Self-Supervised Learning for Multi-Resolution Satellite Imagery. (arXiv:2210.06786v1 [eess.IV])
37. Large-Scale Open-Set Classification Protocols for ImageNet. (arXiv:2210.06789v1 [cs.CV])
38. SDW-ASL: A Dynamic System to Generate Large Scale Dataset for Continuous American Sign Language. (arXiv:2210.06791v1 [cs.CL])
39. OOOE: Only-One-Object-Exists Assumption to Find Very Small Objects in Chest Radiographs. (arXiv:2210.06806v1 [cs.CV])
40. On the calibration of underrepresented classes in LiDAR-based semantic segmentation. (arXiv:2210.06811v1 [cs.CV])
41. ALIFE: Adaptive Logit Regularizer and Feature Replay for Incremental Semantic Segmentation. (arXiv:2210.06816v1 [cs.CV])
42. Scalable Neural Video Representations with Learnable Positional Features. (arXiv:2210.06823v1 [cs.CV])
43. Retrospectives on the Embodied AI Workshop. (arXiv:2210.06849v1 [cs.CV])
44. NeuralRoom: Geometry-Constrained Neural Implicit Surfaces for Indoor Scene Reconstruction. (arXiv:2210.06853v1 [cs.CV])
45. Adv-Attribute: Inconspicuous and Transferable Adversarial Attack on Face Recognition. (arXiv:2210.06871v1 [cs.CV])
46. RaP: Redundancy-aware Video-language Pre-training for Text-Video Retrieval. (arXiv:2210.06881v1 [cs.CV])
47. Geometric Active Learning for Segmentation of Large 3D Volumes. (arXiv:2210.06885v1 [cs.CV])
48. ImaginaryNet: Learning Object Detectors without Real Images and Annotations. (arXiv:2210.06886v1 [cs.CV])
49. AccelAT: A Framework for Accelerating the Adversarial Training of Deep Neural Networks through Accuracy Gradient. (arXiv:2210.06888v1 [cs.LG])
50. Hierarchical and Progressive Image Matting. (arXiv:2210.06906v1 [cs.CV])
51. Feature-Proxy Transformer for Few-Shot Segmentation. (arXiv:2210.06908v1 [cs.CV])
52. HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks. (arXiv:2210.06909v1 [cs.CV])
53. CNTN: Cyclic Noise-tolerant Network for Gait Recognition. (arXiv:2210.06910v1 [cs.CV])
54. Wider and Higher: Intensive Integration and Global Foreground Perception for Image Matting. (arXiv:2210.06919v1 [cs.CV])
55. Scene Text Image Super-Resolution via Content Perceptual Loss and Criss-Cross Transformer Blocks. (arXiv:2210.06924v1 [cs.CV])
56. NoMorelization: Building Normalizer-Free Models from a Sample's Perspective. (arXiv:2210.06932v1 [cs.LG])
57. SageMix: Saliency-Guided Mixup for Point Clouds. (arXiv:2210.06944v1 [cs.CV])
58. Darwinian Model Upgrades: Model Evolving with Selective Compatibility. (arXiv:2210.06954v1 [cs.CV])
59. Feature-Adaptive Interactive Thresholding of Large 3D Volumes. (arXiv:2210.06961v1 [cs.CV])
60. CUF: Continuous Upsampling Filters. (arXiv:2210.06965v1 [cs.LG])
61. LION: Latent Point Diffusion Models for 3D Shape Generation. (arXiv:2210.06978v1 [cs.CV])
62. Probabilistic Integration of Object Level Annotations in Chest X-ray Classification. (arXiv:2210.06980v1 [cs.CV])
63. Denoising Masked AutoEncoders are Certifiable Robust Vision Learners. (arXiv:2210.06983v1 [cs.CV])
64. QDTrack: Quasi-Dense Similarity Learning for Appearance-Only Multiple Object Tracking. (arXiv:2210.06984v1 [cs.CV])
65. Multi-Task Meta Learning: learn how to adapt to unseen tasks. (arXiv:2210.06989v1 [cs.CV])
66. Two approaches to inpainting microstructure with deep convolutional generative adversarial networks. (arXiv:2210.06997v1 [cs.CV])
67. DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models. (arXiv:2210.06998v1 [cs.CR])
68. Learning with Style: Continual Semantic Segmentation Across Tasks and Domains. (arXiv:2210.07016v1 [cs.CV])
69. Rebalanced Zero-shot Learning. (arXiv:2210.07031v1 [cs.CV])
70. Dimensionality of datasets in object detection networks. (arXiv:2210.07049v1 [cs.CV])
71. Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors. (arXiv:2210.07055v1 [cs.CV])
72. ConvTransSeg: A Multi-resolution Convolution-Transformer Network for Medical Image Segmentation. (arXiv:2210.07072v1 [cs.CV])
73. Few-Shot Visual Question Generation: A Novel Task and Benchmark Datasets. (arXiv:2210.07076v1 [cs.CV])
74. Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
75. Deep Idempotent Network for Efficient Single Image Blind Deblurring. (arXiv:2210.07122v1 [cs.CV])
76. RTFormer: Efficient Design for Real-Time Semantic Segmentation with Transformer. (arXiv:2210.07124v1 [cs.CV])
77. U-HRNet: Delving into Improving Semantic Representation of High Resolution Network for Dense Prediction. (arXiv:2210.07140v1 [cs.CV])
78. Unsupervised MRI Super-Resolution Using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors. (arXiv:2008.11921v3 [eess.IV] UPDATED)
79. Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v3 [cs.LG] UPDATED)
80. Fully Convolutional Networks for Panoptic Segmentation with Point-based Supervision. (arXiv:2108.07682v3 [cs.CV] UPDATED)
81. Emergent Graphical Conventions in a Visual Communication Game. (arXiv:2111.14210v3 [cs.CL] UPDATED)
82. **Swin**Track: A Simple and Strong Baseline for Transformer Tracking. (arXiv:2112.00995v3 [cs.CV] UPDATED)
83. Hamiltonian latent operators for content and motion disentanglement in image sequences. (arXiv:2112.01641v4 [cs.CV] UPDATED)
84. Structure-Aware Image Segmentation with Homotopy Warping. (arXiv:2112.07812v3 [cs.CV] UPDATED)
85. Closer Look at the Transferability of Adversarial Examples: How They Fool Different Models Differently. (arXiv:2112.14337v2 [cs.LG] UPDATED)
86. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
87. Rigidity Preserving Image Transformations and Equivariance in Perspective. (arXiv:2201.13065v2 [cs.CV] UPDATED)
88. Refining Self-Supervised Learning in Imaging: Beyond Linear Metric. (arXiv:2202.12921v2 [cs.CV] UPDATED)
89. Deep Transformers Thirst for Comprehensive-Frequency Data. (arXiv:2203.07116v2 [cs.CV] UPDATED)
90. STPLS3D: A Large-Scale Synthetic and Real Aerial Photogrammetry 3D Point Cloud Dataset. (arXiv:2203.09065v2 [cs.CV] UPDATED)
91. Efficient Convolutional Neural Networks on Raspberry Pi for Image Classification. (arXiv:2204.00943v3 [cs.CV] UPDATED)
92. General Incremental Learning with Domain-aware Categorical Representations. (arXiv:2204.04078v2 [cs.CV] UPDATED)
93. ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models. (arXiv:2204.08790v6 [cs.CV] UPDATED)
94. ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation. (arXiv:2204.12484v3 [cs.CV] UPDATED)
95. Sparse Regularized Correlation Filter for UAV Object Tracking with adaptive Contextual Learning and Keyfilter Selection. (arXiv:2205.03627v2 [cs.CV] UPDATED)
96. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v4 [cs.CV] UPDATED)
97. Visual Concepts Tokenization. (arXiv:2205.10093v2 [cs.CV] UPDATED)
98. Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners. (arXiv:2205.10747v4 [cs.CV] UPDATED)
99. 6N-DoF Pose Tracking for Tensegrity Robots. (arXiv:2205.14764v2 [cs.RO] UPDATED)
100. Towards Efficient 3D Object Detection with Knowledge Distillation. (arXiv:2205.15156v2 [cs.CV] UPDATED)
101. Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer. (arXiv:2206.00481v2 [cs.CV] UPDATED)
102. Unifying Voxel-based Representation with Transformer for 3D Object Detection. (arXiv:2206.00630v2 [cs.CV] UPDATED)
103. Egocentric Video-Language Pretraining. (arXiv:2206.01670v2 [cs.CV] UPDATED)
104. LDRNet: Enabling **Real-time** Document Localization on Mobile Devices. (arXiv:2206.02136v2 [cs.CV] UPDATED)
105. PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies. (arXiv:2206.04670v2 [cs.CV] UPDATED)
106. Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?. (arXiv:2206.05266v3 [cs.LG] UPDATED)
107. APT-36K: A Large-scale Benchmark for Animal Pose Estimation and Tracking. (arXiv:2206.05683v2 [cs.CV] UPDATED)
108. Peripheral Vision Transformer. (arXiv:2206.06801v2 [cs.CV] UPDATED)
109. Diffusion models as plug-and-play priors. (arXiv:2206.09012v2 [cs.LG] UPDATED)
110. Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space. (arXiv:2206.11895v2 [cs.CV] UPDATED)
111. HARU: Haptic Augmented Reality-Assisted User-Centric Industrial Network Planning. (arXiv:2206.12139v2 [cs.NI] UPDATED)
112. ST-Adapter: Parameter-Efficient Image-to-Video Transfer Learning. (arXiv:2206.13559v3 [cs.CV] UPDATED)
113. Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection. (arXiv:2207.03482v2 [cs.CV] UPDATED)
114. Adversarial Style Augmentation for Domain Generalized Urban-Scene Segmentation. (arXiv:2207.04892v2 [cs.CV] UPDATED)
115. Is one annotation enough? A data-centric image classification benchmark for noisy and ambiguous label estimation. (arXiv:2207.06214v2 [cs.CV] UPDATED)
116. Fine-grained Few-shot Recognition by Deep Object Parsing. (arXiv:2207.07110v4 [cs.CV] UPDATED)
117. ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model. (arXiv:2207.09446v2 [cs.CV] UPDATED)
118. Global-Local Self-Distillation for Visual Representation Learning. (arXiv:2207.14676v2 [cs.CV] UPDATED)
119. ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries. (arXiv:2208.01582v2 [cs.CV] UPDATED)
120. A Monotonicity Constrained Attention Module for Emotion Classification with Limited EEG Data. (arXiv:2208.08155v2 [eess.SP] UPDATED)
121. RLIP: Relational Language-Image Pre-training for Human-Object Interaction Detection. (arXiv:2209.01814v2 [cs.CV] UPDATED)
122. Poisson Flow Generative Models. (arXiv:2209.11178v2 [cs.LG] UPDATED)
123. Multimodal Exponentially Modified Gaussian Oscillators. (arXiv:2209.12202v2 [cs.SD] UPDATED)
124. Complementary consistency semi-supervised learning for 3D left atrial image segmentation. (arXiv:2210.01438v2 [eess.IV] UPDATED)
125. Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces. (arXiv:2210.03529v2 [cs.CV] UPDATED)
126. CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Image Manipulation. (arXiv:2210.03919v2 [cs.CV] UPDATED)
127. Few-Shot Continual Active Learning by a Robot. (arXiv:2210.04137v2 [cs.LG] UPDATED)
128. ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object Detection. (arXiv:2210.04574v2 [cs.CV] UPDATED)
129. NerfAcc: A General NeRF Acceleration Toolbox. (arXiv:2210.04847v2 [cs.CV] UPDATED)
130. What the DAAM: Interpreting Stable Diffusion Using Cross Attention. (arXiv:2210.04885v3 [cs.CV] UPDATED)
131. PP-StructureV2: A Stronger Document Analysis System. (arXiv:2210.05391v2 [cs.CV] UPDATED)
132. Learning to Locate Visual Answer in Video Corpus Using Question. (arXiv:2210.05423v2 [cs.CV] UPDATED)
133. The Unreasonable Effectiveness of Fully-Connected Layers for Low-Data Regimes. (arXiv:2210.05657v2 [cs.CV] UPDATED)
134. Visual Language Maps for Robot Navigation. (arXiv:2210.05714v2 [cs.RO] UPDATED)
135. Hate-CLIPper: Multimodal Hateful Meme Classification based on Cross-modal Interaction of CLIP Features. (arXiv:2210.05916v2 [cs.CL] UPDATED)
136. FontTransformer: Few-shot High-resolution Chinese Glyph Image Synthesis via Stacked Transformers. (arXiv:2210.06301v2 [cs.CV] UPDATED)
137. IBISCape: A Simulated Benchmark for multi-modal SLAM Systems Evaluation in Large-scale Dynamic Environments. (arXiv:2206.13455v1 [eess.IV] CROSS LISTED)
## eess.IV
---
**19** new papers in eess.IV:-) 
1. Subject-specific quantitative susceptibility mapping using patch based deep image priors. (arXiv:2210.06471v1 [eess.IV])
2. Attention-Based Generative Neural Image Compression on Solar Dynamics Observatory. (arXiv:2210.06478v1 [eess.IV])
3. Quantifying U-Net Uncertainty in Multi-Parametric MRI-based Glioma Segmentation by Spherical Image Projection. (arXiv:2210.06512v1 [q-bio.QM])
4. That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data. (arXiv:2210.06565v1 [cs.LG])
5. S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces. (arXiv:2210.06583v1 [cs.CV])
6. QMRNet: Quality Metric Regression for EO Image Quality Assessment and Super-Resolution. (arXiv:2210.06618v1 [cs.CV])
7. Are Macula or Optic Nerve Head Structures better at Diagnosing Glaucoma? An Answer using AI and Wide-Field Optical Coherence Tomography. (arXiv:2210.06664v1 [eess.IV])
8. Imrpoving Strain Estimation in Breast Ultrasound Images Using Novel 1.5D Approach (Simulation and In-vivo results. (arXiv:2210.06677v1 [eess.IV])
9. Real-Time Dense Field Phase-to-Space Simulation of Imaging through Atmospheric Turbulence. (arXiv:2210.06713v1 [eess.IV])
10. DCANet: Differential Convolution Attention Network for RGB-D Semantic Segmentation. (arXiv:2210.06747v1 [eess.IV])
11. Evaluating the Label Efficiency of Contrastive Self-Supervised Learning for Multi-Resolution Satellite Imagery. (arXiv:2210.06786v1 [eess.IV])
12. Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing. (arXiv:2210.06901v1 [cs.LG])
13. Two approaches to inpainting microstructure with deep convolutional generative adversarial networks. (arXiv:2210.06997v1 [cs.CV])
14. Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
15. Unsupervised MRI Super-Resolution Using Deep External Learning and Guided Residual Dense Network with Multimodal Image Priors. (arXiv:2008.11921v3 [eess.IV] UPDATED)
16. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
17. Refining Self-Supervised Learning in Imaging: Beyond Linear Metric. (arXiv:2202.12921v2 [cs.CV] UPDATED)
18. Complementary consistency semi-supervised learning for 3D left atrial image segmentation. (arXiv:2210.01438v2 [eess.IV] UPDATED)
19. Channel Modeling for UAV-to-Ground Communications with Posture Variation and Fuselage Scattering Effect. (arXiv:2210.02245v3 [eess.SP] UPDATED)
## cs.LG
---
**272** new papers in cs.LG:-) 
1. Emergence of Shared Sensory-motor Graphical Language from Visual Input. (arXiv:2210.06468v1 [cs.AI])
2. Subject-specific quantitative susceptibility mapping using patch based deep image priors. (arXiv:2210.06471v1 [eess.IV])
3. Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models. (arXiv:2210.06475v1 [cs.LG])
4. Real World Offline Reinforcement Learning with Realistic Data Source. (arXiv:2210.06479v1 [cs.RO])
5. SUMBot: Summarizing Context in Open-Domain Dialogue Systems. (arXiv:2210.06496v1 [cs.CL])
6. Evaluated CMI Bounds for Meta Learning: Tightness and Expressiveness. (arXiv:2210.06511v1 [cs.LG])
7. How to Sift Out a Clean Data Subset in the Presence of Data Poisoning?. (arXiv:2210.06516v1 [cs.CR])
8. Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories. (arXiv:2210.06518v1 [cs.LG])
9. Microscopy is All You Need. (arXiv:2210.06526v1 [cond-mat.dis-nn])
10. Quantum Algorithms for Sampling Log-Concave Distributions and Estimating Normalizing Constants. (arXiv:2210.06539v1 [quant-ph])
11. MicroLib: A library of 3D microstructures generated from 2D micrographs using SliceGAN. (arXiv:2210.06541v1 [cs.LG])
12. A General Stochastic Optimization Framework for Convergence Bidding. (arXiv:2210.06543v1 [math.OC])
13. GULP: a prediction-based metric between representations. (arXiv:2210.06545v1 [cs.LG])
14. Auto-Encoding Goodness of Fit. (arXiv:2210.06546v1 [cs.LG])
15. Scenario-based Evaluation of Prediction Models for Automated Vehicles. (arXiv:2210.06553v1 [cs.AI])
16. Toward the application of XAI methods in EEG-based systems. (arXiv:2210.06554v1 [cs.LG])
17. Robust Neural Posterior Estimation and Statistical Model Criticism. (arXiv:2210.06564v1 [stat.ML])
18. That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data. (arXiv:2210.06565v1 [cs.LG])
19. Gaussian Processes on Distributions based on Regularized Optimal Transport. (arXiv:2210.06574v1 [stat.ML])
20. FASTER-CE: Fast, Sparse, Transparent, and Robust Counterfactual Explanations. (arXiv:2210.06578v1 [cs.LG])
21. Task-Free Continual Learning via Online Discrepancy Distance Learning. (arXiv:2210.06579v1 [cs.CV])
22. S4ND: Modeling Images and Videos as Multidimensional Signals Using State Spaces. (arXiv:2210.06583v1 [cs.CV])
23. Towards an Efficient ML System: Unveiling a Trade-off between Task Accuracy and Engineering Efficiency in a Large-scale Car Sharing Platform. (arXiv:2210.06585v1 [cs.CV])
24. BLADERUNNER: Rapid Countermeasure for Synthetic (AI-Generated) StyleGAN Faces. (arXiv:2210.06587v1 [cs.CR])
25. Efficient Deep Unfolding for SISO-OFDM Channel Estimation. (arXiv:2210.06588v1 [cs.IT])
26. Adversarial Attack Against Image-Based Localization Neural Networks. (arXiv:2210.06589v1 [cs.CV])
27. Rigorous dynamical mean field theory for stochastic gradient descent methods. (arXiv:2210.06591v1 [math-ph])
28. Can Calibration Improve Sample Prioritization?. (arXiv:2210.06592v1 [cs.LG])
29. Differentially Private Online-to-Batch for Smooth Losses. (arXiv:2210.06593v1 [cs.LG])
30. Sample Constrained Treatment Effect Estimation. (arXiv:2210.06594v1 [cs.LG])
31. Find Your Friends: Personalized Federated Learning with the Right Collaborators. (arXiv:2210.06597v1 [cs.LG])
32. Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks. (arXiv:2210.06601v1 [cs.RO])
33. A Neural Mean Embedding Approach for Back-door and Front-door Adjustment. (arXiv:2210.06610v1 [cs.LG])
34. Anomaly Detection via Federated Learning. (arXiv:2210.06614v1 [cs.LG])
35. When does deep learning fail and how to tackle it? A critical analysis on polymer sequence-property surrogate models. (arXiv:2210.06622v1 [cond-mat.mtrl-sci])
36. OpenCQA: Open-ended Question Answering with Charts. (arXiv:2210.06628v1 [cs.LG])
37. Fairness via Adversarial Attribute Neighbourhood Robust Learning. (arXiv:2210.06630v1 [cs.LG])
38. A Bayesian Optimization Framework for Finding Local Optima in Expensive Multi-Modal Functions. (arXiv:2210.06635v1 [math.OC])
39. Compute-Efficient Deep Learning: Algorithmic Trends and Opportunities. (arXiv:2210.06640v1 [cs.LG])
40. Interpreting Neural Policies with Disentangled Tree Representations. (arXiv:2210.06650v1 [cs.LG])
41. Action Matching: A Variational Method for Learning Stochastic Dynamics from Samples. (arXiv:2210.06662v1 [cs.LG])
42. Wasserstein Barycenter-based Model Fusion and Linear Mode Connectivity of Neural Networks. (arXiv:2210.06671v1 [cs.LG])
43. Variance-Aware Estimation of Kernel Mean Embedding. (arXiv:2210.06672v1 [math.ST])
44. Walk a Mile in Their Shoes: a New Fairness Criterion for Machine Learning. (arXiv:2210.06680v1 [cs.LG])
45. Brain Network Transformer. (arXiv:2210.06681v1 [cs.LG])
46. Augmenting Flight Training with AI to Efficiently Train Pilots. (arXiv:2210.06683v1 [cs.LG])
47. Real Spike: Learning Real-valued Spikes for Spiking Neural Networks. (arXiv:2210.06686v1 [cs.NE])
48. Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief. (arXiv:2210.06692v1 [cs.LG])
49. Parameter-Efficient Masking Networks. (arXiv:2210.06699v1 [cs.LG])
50. Empirical Evaluation of Data Augmentations for Biobehavioral Time Series Data with Deep Learning. (arXiv:2210.06701v1 [cs.LG])
51. A Mixture of Surprises for Unsupervised Reinforcement Learning. (arXiv:2210.06702v1 [cs.LG])
52. COLLIDER: A Robust Training Framework for Backdoor Data. (arXiv:2210.06704v1 [cs.LG])
53. From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent. (arXiv:2210.06705v1 [cs.LG])
54. Weighted Distillation with Unlabeled Examples. (arXiv:2210.06711v1 [cs.LG])
55. Hybrid RL: Using Both Offline and Online Data Can Make RL Efficient. (arXiv:2210.06718v1 [cs.LG])
56. Partial Information as Full: Reward Imputation with Sketching in Bandits. (arXiv:2210.06719v1 [cs.LG])
57. Few-shot Relational Reasoning via Connection Subgraph Pretraining. (arXiv:2210.06722v1 [cs.LG])
58. Noise can be helpful for variational quantum algorithms. (arXiv:2210.06723v1 [quant-ph])
59. On the Efficient Implementation of High Accuracy Optimality of Profile Maximum Likelihood. (arXiv:2210.06728v1 [stat.ML])
60. A Stream Learning Approach for Real-Time Identification of False Data Injection Attacks in Cyber-Physical Power Systems. (arXiv:2210.06729v1 [cs.LG])
61. Equal Improvability: A New Fairness Notion Considering the Long-term Impact. (arXiv:2210.06732v1 [cs.LG])
62. Why self-attention is Natural for Sequence-to-Sequence Problems? A Perspective from Symmetries. (arXiv:2210.06741v1 [cs.LG])
63. Learning Driving Policies for End-to-End Autonomous Driving. (arXiv:2210.06758v1 [cs.RO])
64. Outlier-Robust Group Inference via Gradient Space Clustering. (arXiv:2210.06759v1 [cs.LG])
65. Policy Gradient With Serial Markov Chain Reasoning. (arXiv:2210.06766v1 [cs.LG])
66. Feature Reconstruction Attacks and Countermeasures of DNN training in Vertical Federated Learning. (arXiv:2210.06771v1 [cs.LG])
67. Mitigating Unintended Memorization in Language Models via Alternating Teaching. (arXiv:2210.06772v1 [cs.CL])
68. An Additive Autoencoder for Dimension Estimation. (arXiv:2210.06773v1 [cs.LG])
69. Efficient circuit implementation for coined quantum walks on binary trees and application to reinforcement learning. (arXiv:2210.06784v1 [cs.ET])
70. An efficient combination strategy for hybird quantum ensemble classifier. (arXiv:2210.06785v1 [quant-ph])
71. Evaluating the Label Efficiency of Contrastive Self-Supervised Learning for Multi-Resolution Satellite Imagery. (arXiv:2210.06786v1 [eess.IV])
72. Observed Adversaries in Deep Reinforcement Learning. (arXiv:2210.06787v1 [cs.LG])
73. TiDAL: Learning Training Dynamics for Active Learning. (arXiv:2210.06788v1 [cs.LG])
74. Large-Scale Open-Set Classification Protocols for ImageNet. (arXiv:2210.06789v1 [cs.CV])
75. SDW-ASL: A Dynamic System to Generate Large Scale Dataset for Continuous American Sign Language. (arXiv:2210.06791v1 [cs.CL])
76. Subspace-Contrastive Multi-View Clustering. (arXiv:2210.06795v1 [cs.LG])
77. Improving Out-of-Distribution Generalization by Adversarial Training with Structured Priors. (arXiv:2210.06807v1 [cs.LG])
78. Utilizing supervised models to infer consensus labels and their quality from data with multiple annotators. (arXiv:2210.06812v1 [cs.LG])
79. Mean-field analysis for heavy ball methods: Dropout-stability, connectivity, and global convergence. (arXiv:2210.06819v1 [cs.LG])
80. Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning. (arXiv:2210.06820v1 [cs.LG])
81. Scalable Neural Video Representations with Learnable Positional Features. (arXiv:2210.06823v1 [cs.CV])
82. Fast Optimization of Weighted Sparse Decision Trees for use in Optimal Treatment Regimes and Optimal Policy Design. (arXiv:2210.06825v1 [cs.LG])
83. Ensemble Creation via Anchored Regularization for Unsupervised Aspect Extraction. (arXiv:2210.06829v1 [cs.CL])
84. Multi-Target XGBoostLSS Regression. (arXiv:2210.06831v1 [cs.LG])
85. Exploiting Mixed Unlabeled Data for Detecting Samples of Seen and Unseen Out-of-Distribution Classes. (arXiv:2210.06833v1 [cs.LG])
86. Multi-agent Dynamic Algorithm Configuration. (arXiv:2210.06835v1 [cs.LG])
87. An $\alpha$-regret analysis of Adversarial **Bilateral** Trade. (arXiv:2210.06846v1 [cs.GT])
88. Sample-Then-Optimize Batch Neural Thompson Sampling. (arXiv:2210.06850v1 [cs.LG])
89. Dirichlet process mixture models for non-stationary data streams. (arXiv:2210.06872v1 [stat.ML])
90. Data augmentation on-the-fly and active learning in data stream classification. (arXiv:2210.06873v1 [cs.LG])
91. Learning Physical Dynamics with Subequivariant Graph Neural Networks. (arXiv:2210.06876v1 [cs.LG])
92. ROS-PyBullet Interface: A Framework for Reliable Contact Simulation and Human-Robot Interaction. (arXiv:2210.06887v1 [cs.RO])
93. AccelAT: A Framework for Accelerating the Adversarial Training of Deep Neural Networks through Accuracy Gradient. (arXiv:2210.06888v1 [cs.LG])
94. An Experiment Design Paradigm using Joint Feature Selection and Task Optimization. (arXiv:2210.06891v1 [cs.LG])
95. Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation. (arXiv:2210.06894v1 [cs.LG])
96. GA-SAM: Gradient-Strength based Adaptive Sharpness-Aware Minimization for Improved Generalization. (arXiv:2210.06895v1 [cs.LG])
97. Entropy Approximation by Machine Learning Regression: Application for Irregularity Evaluation of Images in Remote Sensing. (arXiv:2210.06901v1 [cs.LG])
98. HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks. (arXiv:2210.06909v1 [cs.CV])
99. A Direct Approximation of AIXI Using Logical State Abstractions. (arXiv:2210.06917v1 [cs.AI])
100. Delta-Closure Structure for Studying Data Distribution. (arXiv:2210.06926v1 [cs.LG])
101. NoMorelization: Building Normalizer-Free Models from a Sample's Perspective. (arXiv:2210.06932v1 [cs.LG])
102. SageMix: Saliency-Guided Mixup for Point Clouds. (arXiv:2210.06944v1 [cs.CV])
103. A Survey on Explainable Anomaly Detection. (arXiv:2210.06959v1 [cs.LG])
104. Causality-driven Hierarchical Structure Discovery for Reinforcement Learning. (arXiv:2210.06964v1 [cs.LG])
105. CUF: Continuous Upsampling Filters. (arXiv:2210.06965v1 [cs.LG])
106. Behavioral graph fraud detection in E-commerce. (arXiv:2210.06968v1 [cs.LG])
107. Reliable quantum kernel classification using fewer circuit evaluations. (arXiv:2210.06971v1 [quant-ph])
108. Parallel photonic accelerator for decision making using optical spatiotemporal chaos. (arXiv:2210.06976v1 [cs.ET])
109. LION: Latent Point Diffusion Models for 3D Shape Generation. (arXiv:2210.06978v1 [cs.CV])
110. Denoising Masked AutoEncoders are Certifiable Robust Vision Learners. (arXiv:2210.06983v1 [cs.CV])
111. DICTDIS: Dictionary Constrained Disambiguation for Improved NMT. (arXiv:2210.06996v1 [cs.CL])
112. DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models. (arXiv:2210.06998v1 [cs.CR])
113. Sustainable Online Reinforcement Learning for Auto-bidding. (arXiv:2210.07006v1 [cs.LG])
114. Variational Graph Generator for Multi-View Graph Clustering. (arXiv:2210.07011v1 [cs.LG])
115. Transfer Deep Reinforcement Learning-based Large-scale V2G Continuous Charging Coordination with Renewable Energy Sources. (arXiv:2210.07013v1 [eess.SY])
116. Self-explaining deep models with logic rule reasoning. (arXiv:2210.07024v1 [cs.AI])
117. Self-Supervised Learning of Linear Precoders under Non-Linear PA Distortion for Energy-Efficient Massive MIMO Systems. (arXiv:2210.07037v1 [cs.LG])
118. Sparse in Space and Time: Audio-visual Synchronisation with Trainable Selectors. (arXiv:2210.07055v1 [cs.CV])
119. Deep Clustering With Consensus Representations. (arXiv:2210.07063v1 [cs.LG])
120. ConvTransSeg: A Multi-resolution Convolution-Transformer Network for Medical Image Segmentation. (arXiv:2210.07072v1 [cs.CV])
121. CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing. (arXiv:2210.07074v1 [cs.CL])
122. Implicit Bias in Leaky ReLU Networks Trained on High-Dimensional Data. (arXiv:2210.07082v1 [cs.LG])
123. Meta-learning Based Short-Term Passenger Flow Prediction for Newly-Operated Urban Rail Transit Stations. (arXiv:2210.07098v1 [cs.LG])
124. Dissipative residual layers for unsupervised implicit parameterization of data manifolds. (arXiv:2210.07100v1 [cs.LG])
125. Corneal endothelium assessment in specular microscopy images with Fuchs' dystrophy via deep regression of signed distance maps. (arXiv:2210.07102v1 [eess.IV])
126. CORL: Research-oriented Deep Offline Reinforcement Learning Library. (arXiv:2210.07105v1 [cs.LG])
127. Towards End-to-End Open Conversational Machine Reading. (arXiv:2210.07113v1 [cs.CL])
128. Precision QCD corrections to gluon-initiated diphoton-plus-jet production at the LHC. (arXiv:2210.07115v1 [hep-ph])
129. Graph-based Neural Modules to Inspect Attention-based Architectures: A Position Paper. (arXiv:2210.07117v1 [cs.LG])
130. Language Models of Code are Few-Shot Commonsense Learners. (arXiv:2210.07128v1 [cs.CL])
131. Learning Multivariate CDFs and Copulas using Tensor Factorization. (arXiv:2210.07132v1 [stat.ML])
132. Performance Evaluation of Query Plan Recommendation with Apache Hadoop and Apache Spark. (arXiv:2210.07143v1 [cs.DB])
133. Reprogramming Large Pretrained Language Models for Antibody Sequence Infilling. (arXiv:2210.07144v1 [q-bio.BM])
134. Accurate, reliable and interpretable solubility prediction of druglike molecules with attention pooling and Bayesian learning. (arXiv:2210.07145v1 [q-bio.BM])
135. Global Explainability of GNNs via Logic Combination of Learned Concepts. (arXiv:2210.07147v1 [cs.LG])
136. A method to construct exponential families by representation theory. (arXiv:1811.01394v4 [math.ST] UPDATED)
137. Shapley Q-value: A Local Reward Approach to Solve Global Reward Games. (arXiv:1907.05707v6 [cs.LG] UPDATED)
138. A Multilabel Classification Framework for Approximate Nearest Neighbor Search. (arXiv:1910.08322v5 [cs.LG] UPDATED)
139. LIMEADE: From AI Explanations to Advice Taking. (arXiv:2003.04315v4 [cs.IR] UPDATED)
140. On the Theoretical Equivalence of Several Trade-Off Curves Assessing Statistical Proximity. (arXiv:2006.11809v3 [cs.LG] UPDATED)
141. Imitative Planning using Conditional Normalizing Flow. (arXiv:2007.16162v3 [cs.RO] UPDATED)
142. BayesAdapter: Being Bayesian, Inexpensively and Reliably, via Bayesian Fine-tuning. (arXiv:2010.01979v5 [cs.LG] UPDATED)
143. On the Paradox of Certified Training. (arXiv:2102.06700v3 [cs.LG] UPDATED)
144. Near-Optimal Randomized Exploration for Tabular Markov Decision Processes. (arXiv:2102.09703v5 [cs.LG] UPDATED)
145. SYNFIX: Automatically Fixing Syntax Errors using Compiler Diagnostics. (arXiv:2104.14671v2 [cs.SE] UPDATED)
146. Theoretically Better and Numerically Faster Distributed Optimization with Smoothness-Aware Quantization Techniques. (arXiv:2106.03524v2 [cs.LG] UPDATED)
147. RNNs of RNNs: Recursive Construction of Stable Assemblies of Recurrent Neural Networks. (arXiv:2106.08928v5 [cs.LG] UPDATED)
148. Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from Scratch. (arXiv:2106.08970v3 [cs.LG] UPDATED)
149. SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction. (arXiv:2106.09305v3 [cs.LG] UPDATED)
150. Generalization Bounds with Minimal Dependency on Hypothesis Class via Distributionally Robust Optimization. (arXiv:2106.11180v4 [math.OC] UPDATED)
151. Deep Multiagent Reinforcement Learning: Challenges and Directions. (arXiv:2106.15691v2 [cs.LG] UPDATED)
152. Online Minimax Multiobjective Optimization: Multicalibeating and Other Applications. (arXiv:2108.03837v3 [cs.LG] UPDATED)
153. Reliable Neural Networks for Regression Uncertainty Estimation. (arXiv:2109.08213v2 [cs.LG] UPDATED)
154. Scale-invariant Learning by Physics Inversion. (arXiv:2109.15048v3 [cs.LG] UPDATED)
155. Characterizing SARS-CoV-2 Spike Sequences Based on Geographical Location. (arXiv:2110.00809v4 [cs.LG] UPDATED)
156. Inducing Equilibria via Incentives: Simultaneous Design-and-Play Ensures Global Convergence. (arXiv:2110.01212v3 [cs.GT] UPDATED)
157. Contextual Combinatorial Bandits with Changing Action Sets via Gaussian Processes. (arXiv:2110.02248v2 [cs.LG] UPDATED)
158. The Eigenlearning Framework: A Conservation Law Perspective on Kernel Regression and Wide Neural Networks. (arXiv:2110.03922v4 [cs.LG] UPDATED)
159. On minimizers and convolutional filters: a partial justification for the effectiveness of CNNs in categorical sequence analysis. (arXiv:2111.08452v3 [cs.LG] UPDATED)
160. Hamiltonian latent operators for content and motion disentanglement in image sequences. (arXiv:2112.01641v4 [cs.CV] UPDATED)
161. Continual Learning In Environments With Polynomial Mixing Times. (arXiv:2112.07066v2 [cs.LG] UPDATED)
162. SkipNode: On Alleviating Performance Degradation for Deep Graph Convolutional Networks. (arXiv:2112.11628v3 [cs.LG] UPDATED)
163. Closer Look at the Transferability of Adversarial Examples: How They Fool Different Models Differently. (arXiv:2112.14337v2 [cs.LG] UPDATED)
164. SAE: Sequential Anchored Ensembles. (arXiv:2201.00649v2 [cs.LG] UPDATED)
165. FedDTG:Federated Data-Free Knowledge Distillation via Three-Player Generative Adversarial Networks. (arXiv:2201.03169v2 [cs.LG] UPDATED)
166. Online POI Recommendation: Learning Dynamic Geo-Human Interactions in Streams. (arXiv:2201.10983v3 [cs.IR] UPDATED)
167. Denoising Diffusion **Restoration** Models. (arXiv:2201.11793v3 [eess.IV] UPDATED)
168. Explaining Graph Neural Networks with Structure-Aware Cooperative Games. (arXiv:2201.12380v4 [cs.LG] UPDATED)
169. Rigidity Preserving Image Transformations and Equivariance in Perspective. (arXiv:2201.13065v2 [cs.CV] UPDATED)
170. When Do Flat Minima Optimizers Work?. (arXiv:2202.00661v4 [cs.LG] UPDATED)
171. Giga-scale Kernel Matrix Vector Multiplication on GPU. (arXiv:2202.01085v3 [math.NA] UPDATED)
172. Communication Efficient Federated Learning for Generalized Linear Bandits. (arXiv:2202.01087v2 [cs.LG] UPDATED)
173. Adjoint-aided inference of Gaussian process driven differential equations. (arXiv:2202.04589v3 [stat.ML] UPDATED)
174. Stochastic Contextual Dueling Bandits under Linear Stochastic Transitivity Models. (arXiv:2202.04593v2 [cs.LG] UPDATED)
175. Reproducibility in Optimization: Theoretical Framework and Limits. (arXiv:2202.04598v3 [math.OC] UPDATED)
176. STG-GAN: A spatiotemporal graph generative adversarial networks for short-term passenger flow prediction in urban rail transit systems. (arXiv:2202.06727v2 [cs.LG] UPDATED)
177. Deep Ensembles Work, But Are They Necessary?. (arXiv:2202.06985v2 [cs.LG] UPDATED)
178. Invariance Learning in Deep Neural Networks with Differentiable Laplace Approximations. (arXiv:2202.10638v3 [stat.ML] UPDATED)
179. Refining Self-Supervised Learning in Imaging: Beyond Linear Metric. (arXiv:2202.12921v2 [cs.CV] UPDATED)
180. Testing Stationarity and Change Point Detection in Reinforcement Learning. (arXiv:2203.01707v2 [stat.ML] UPDATED)
181. Zero-shot Transfer Learning within a Heterogeneous Graph via Knowledge Transfer Networks. (arXiv:2203.02018v4 [cs.LG] UPDATED)
182. Pitfalls of Epistemic Uncertainty Quantification through Loss Minimisation. (arXiv:2203.06102v2 [cs.LG] UPDATED)
183. Fair Federated Learning via Bounded Group Loss. (arXiv:2203.10190v3 [cs.LG] UPDATED)
184. Linearizing Transformer with Key-Value Memory. (arXiv:2203.12644v4 [cs.CL] UPDATED)
185. FedRecAttack: Model Poisoning Attack to Federated Recommendation. (arXiv:2204.01499v2 [cs.CR] UPDATED)
186. Forecasting Cryptocurrency Returns from Sentiment Signals: An Analysis of BERT Classifiers and Weak Supervision. (arXiv:2204.05781v2 [q-fin.ST] UPDATED)
187. ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models. (arXiv:2204.08790v6 [cs.CV] UPDATED)
188. Beyond backpropagation: implicit gradients for bilevel optimization. (arXiv:2205.03076v2 [cs.LG] UPDATED)
189. GRU-TV: Time- and velocity-aware GRU for patient representation on multivariate clinical time-series data. (arXiv:2205.04892v2 [cs.LG] UPDATED)
190. A Communication-Efficient Distributed Gradient Clipping Algorithm for Training Deep Neural Networks. (arXiv:2205.05040v2 [cs.LG] UPDATED)
191. DDXPlus: A New Dataset For Automatic Medical Diagnosis. (arXiv:2205.09148v3 [cs.CL] UPDATED)
192. Neural Network Architecture Beyond Width and Depth. (arXiv:2205.09459v2 [cs.LG] UPDATED)
193. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v4 [cs.CV] UPDATED)
194. KERPLE: Kernelized Relative Positional Embedding for Length Extrapolation. (arXiv:2205.09921v2 [cs.CL] UPDATED)
195. Visual Concepts Tokenization. (arXiv:2205.10093v2 [cs.CV] UPDATED)
196. Memory-efficient Reinforcement Learning with Knowledge Consolidation. (arXiv:2205.10868v2 [cs.LG] UPDATED)
197. Learning to branch with Tree MDPs. (arXiv:2205.11107v3 [cs.LG] UPDATED)
198. Neur2SP: Neural Two-Stage Stochastic Programming. (arXiv:2205.12006v2 [math.OC] UPDATED)
199. Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT. (arXiv:2205.12399v2 [cs.LG] UPDATED)
200. A Rotated Hyperbolic Wrapped Normal Distribution for Hierarchical Representation Learning. (arXiv:2205.13371v2 [cs.LG] UPDATED)
201. Pruning has a disparate impact on model accuracy. (arXiv:2205.13574v3 [cs.LG] UPDATED)
202. Maximum Likelihood Training of Implicit Nonlinear Diffusion Models. (arXiv:2205.13699v3 [cs.LG] UPDATED)
203. Deterministic Langevin Monte Carlo with Normalizing Flows for Bayesian Inference. (arXiv:2205.14240v2 [stat.ML] UPDATED)
204. Universality of Group Convolutional Neural Networks Based on Ridgelet Analysis on Groups. (arXiv:2205.14819v2 [cs.LG] UPDATED)
205. Towards Efficient 3D Object Detection with Knowledge Distillation. (arXiv:2205.15156v2 [cs.CV] UPDATED)
206. Non-convex online learning via algorithmic equivalence. (arXiv:2205.15235v2 [cs.LG] UPDATED)
207. A Computation and Communication Efficient Method for Distributed Nonconvex Problems in the Partial Participation Setting. (arXiv:2205.15580v2 [cs.LG] UPDATED)
208. One Policy is Enough: Parallel Exploration with a Single Policy is Near-Optimal for Reward-Free Reinforcement Learning. (arXiv:2205.15891v2 [cs.LG] UPDATED)
209. Online PAC-Bayes Learning. (arXiv:2206.00024v2 [cs.LG] UPDATED)
210. Asymptotic Properties for Bayesian Neural Network in Besov Space. (arXiv:2206.00241v2 [stat.ML] UPDATED)
211. Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer. (arXiv:2206.00481v2 [cs.CV] UPDATED)
212. SPD domain-specific batch normalization to crack interpretable unsupervised domain adaptation in EEG. (arXiv:2206.01323v2 [cs.LG] UPDATED)
213. Neuro-Symbolic Procedural Planning with Commonsense Prompting. (arXiv:2206.02928v5 [cs.CL] UPDATED)
214. pFL-Bench: A Comprehensive Benchmark for Personalized Federated Learning. (arXiv:2206.03655v4 [cs.LG] UPDATED)
215. Learning to Generate Prompts for Dialogue Generation through Reinforcement Learning. (arXiv:2206.03931v3 [cs.CL] UPDATED)
216. Communication Efficient Distributed Learning for Kernelized Contextual Bandits. (arXiv:2206.04835v2 [cs.LG] UPDATED)
217. Does Self-supervised Learning Really Improve Reinforcement Learning from Pixels?. (arXiv:2206.05266v3 [cs.LG] UPDATED)
218. Gradient Boosting Performs Gaussian Process Inference. (arXiv:2206.05608v2 [cs.LG] UPDATED)
219. Robust Time Series Denoising with Learnable Wavelet Packet Transform. (arXiv:2206.06126v2 [cs.SD] UPDATED)
220. Partial Identifiability for Nonnegative Matrix Factorization. (arXiv:2206.08022v3 [math.NA] UPDATED)
221. Diffusion models as plug-and-play priors. (arXiv:2206.09012v2 [cs.LG] UPDATED)
222. Primal Estimated Subgradient Solver for SVM for Imbalanced Classification. (arXiv:2206.09311v2 [cs.LG] UPDATED)
223. EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL. (arXiv:2206.09674v4 [cs.CL] UPDATED)
224. SoteriaFL: A Unified Framework for Private Federated Learning with Communication Compression. (arXiv:2206.09888v2 [cs.LG] UPDATED)
225. D-CIPHER: Discovery of Closed-form Partial Differential Equations. (arXiv:2206.10586v2 [cs.LG] UPDATED)
226. Learning Neuro-Symbolic Skills for Bilevel Planning. (arXiv:2206.10680v2 [cs.RO] UPDATED)
227. A consistent and flexible framework for deep matrix factorizations. (arXiv:2206.10693v2 [cs.LG] UPDATED)
228. Learning Viewpoint-Agnostic Visual Representations by Recovering Tokens in 3D Space. (arXiv:2206.11895v2 [cs.CV] UPDATED)
229. A systematic review of biologically-informed deep learning models for cancer: fundamental trends for encoding and interpreting oncology data. (arXiv:2207.00812v2 [q-bio.QM] UPDATED)
230. Cascaded Deep Hybrid Models for Multistep Household Energy Consumption Forecasting. (arXiv:2207.02589v2 [cs.LG] UPDATED)
231. DeepTime: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting. (arXiv:2207.06046v3 [cs.LG] UPDATED)
232. Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v2 [cs.LG] UPDATED)
233. Parameter Averaging for Feature Ranking. (arXiv:2208.03249v2 [cs.LG] UPDATED)
234. Differentiable WORLD Synthesizer-based Neural Vocoder With Application To End-To-End Audio Style Transfer. (arXiv:2208.07282v3 [eess.AS] UPDATED)
235. MoCapAct: A Multi-Task Dataset for Simulated Humanoid Control. (arXiv:2208.07363v2 [cs.RO] UPDATED)
236. A Monotonicity Constrained Attention Module for Emotion Classification with Limited EEG Data. (arXiv:2208.08155v2 [eess.SP] UPDATED)
237. Interpreting Black-box Machine Learning Models for High Dimensional Datasets. (arXiv:2208.13405v2 [cs.LG] UPDATED)
238. Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms. (arXiv:2208.14837v2 [cs.LG] UPDATED)
239. Effective Class-Imbalance learning based on SMOTE and Convolutional Neural Networks. (arXiv:2209.00653v2 [cs.LG] UPDATED)
240. Geometric multimodal representation learning. (arXiv:2209.03299v2 [cs.LG] UPDATED)
241. Kernel-Segregated Transpose Convolution Operation. (arXiv:2209.03704v3 [cs.LG] UPDATED)
242. SongDriver: **Real-time** Music Accompaniment Generation without Logical Latency nor **Exposure** Bias. (arXiv:2209.06054v2 [cs.SD] UPDATED)
243. Wasserstein $K$-means for clustering probability distributions. (arXiv:2209.06975v2 [stat.ML] UPDATED)
244. Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango. (arXiv:2209.07686v2 [cs.CL] UPDATED)
245. Improved Generalization Bound and Learning of Sparsity Patterns for Data-Driven Low-Rank Approximation. (arXiv:2209.08281v3 [cs.LG] UPDATED)
246. Proximal Point Imitation Learning. (arXiv:2209.10968v2 [cs.LG] UPDATED)
247. Identifiability and generalizability from multiple experts in Inverse Reinforcement Learning. (arXiv:2209.10974v2 [cs.LG] UPDATED)
248. Poisson Flow Generative Models. (arXiv:2209.11178v2 [cs.LG] UPDATED)
249. RADio -- Rank-Aware Divergence Metrics to Measure Normative Diversity in News Recommendations. (arXiv:2209.13520v2 [cs.IR] UPDATED)
250. SecureFedYJ: a safe feature Gaussianization protocol for Federated Learning. (arXiv:2210.01639v2 [cs.LG] UPDATED)
251. SECOE: Alleviating Sensors Failure in Machine Learning-Coupled IoT Systems. (arXiv:2210.02144v2 [cs.LG] UPDATED)
252. Extending Conformal Prediction to Hidden Markov Models with Exact Validity via de Finetti's Theorem for Markov Chains. (arXiv:2210.02271v2 [stat.ME] UPDATED)
253. Deep learning for ECoG brain-computer interface: end-to-end vs. hand-crafted features. (arXiv:2210.02544v2 [eess.SP] UPDATED)
254. CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Image Manipulation. (arXiv:2210.03919v2 [cs.CV] UPDATED)
255. Advancing Model Pruning via Bi-level Optimization. (arXiv:2210.04092v3 [cs.LG] UPDATED)
256. Few-Shot Continual Active Learning by a Robot. (arXiv:2210.04137v2 [cs.LG] UPDATED)
257. On the Performance of Gradient Tracking with Local Updates. (arXiv:2210.04757v2 [math.OC] UPDATED)
258. DeepVol: Volatility Forecasting from High-Frequency Data with Dilated Causal Convolutions. (arXiv:2210.04797v2 [q-fin.RM] UPDATED)
259. Mining Causality from Continuous-time Dynamics Models: An Application to Tsunami Forecasting. (arXiv:2210.04958v2 [cs.LG] UPDATED)
260. Discovered Policy Optimisation. (arXiv:2210.05639v2 [cs.LG] UPDATED)
261. Transformers generalize differently from information stored in context vs in weights. (arXiv:2210.05675v2 [cs.CL] UPDATED)
262. Visual Language Maps for Robot Navigation. (arXiv:2210.05714v2 [cs.RO] UPDATED)
263. Vote'n'Rank: Revision of Benchmarking with Social Choice Theory. (arXiv:2210.05769v2 [cs.LG] UPDATED)
264. Deep Counterfactual Estimation with Categorical Background Variables. (arXiv:2210.05811v2 [cs.LG] UPDATED)
265. Hate-CLIPper: Multimodal Hateful Meme Classification based on Cross-modal Interaction of CLIP Features. (arXiv:2210.05916v2 [cs.CL] UPDATED)
266. Classification by estimating the cumulative distribution function for small data. (arXiv:2210.05953v2 [cs.LG] UPDATED)
267. Modular Flows: Differential Molecular Generation. (arXiv:2210.06032v2 [cs.LG] UPDATED)
268. Transfer Learning on Electromyography (EMG) Tasks: Approaches and Beyond. (arXiv:2210.06295v2 [eess.SP] UPDATED)
269. Generalised Mutual Information for Discriminative Clustering. (arXiv:2210.06300v2 [stat.ML] UPDATED)
270. Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors. (arXiv:2210.06340v2 [cs.CL] UPDATED)
271. Relational Graph Convolutional Neural Networks for Multihop Reasoning: A Comparative Study. (arXiv:2210.06418v2 [cs.CL] UPDATED)
272. Predictive Querying for Autoregressive Neural Sequence Models. (arXiv:2210.06464v2 [cs.LG] UPDATED)
## cs.AI
---
**123** new papers in cs.AI:-) 
1. Emergence of Shared Sensory-motor Graphical Language from Visual Input. (arXiv:2210.06468v1 [cs.AI])
2. Who Wrote this? How Smart Replies Impact Language and Agency in the Workplace. (arXiv:2210.06470v1 [cs.HC])
3. Inner speech recognition through electroencephalographic signals. (arXiv:2210.06472v1 [cs.HC])
4. VR-SFT: Reproducing **Swin**ging Flashlight Test in Virtual Reality to Detect Relative Afferent Pupillary Defect. (arXiv:2210.06474v1 [cs.HC])
5. SUMBot: Summarizing Context in Open-Domain Dialogue Systems. (arXiv:2210.06496v1 [cs.CL])
6. Understanding Impacts of Task Similarity on Backdoor Attack and Detection. (arXiv:2210.06509v1 [cs.CR])
7. How to Sift Out a Clean Data Subset in the Presence of Data Poisoning?. (arXiv:2210.06516v1 [cs.CR])
8. Semi-Supervised Offline Reinforcement Learning with Action-Free Trajectories. (arXiv:2210.06518v1 [cs.LG])
9. Scenario-based Evaluation of Prediction Models for Automated Vehicles. (arXiv:2210.06553v1 [cs.AI])
10. Toward the application of XAI methods in EEG-based systems. (arXiv:2210.06554v1 [cs.LG])
11. That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data. (arXiv:2210.06565v1 [cs.LG])
12. Automatic **Real-time** Vehicle Classification by Image Colour Component Based Template Matching. (arXiv:2210.06586v1 [cs.CV])
13. Efficient Deep Unfolding for SISO-OFDM Channel Estimation. (arXiv:2210.06588v1 [cs.IT])
14. Sample Constrained Treatment Effect Estimation. (arXiv:2210.06594v1 [cs.LG])
15. Generalization with Lossy Affordances: Leveraging Broad Offline Data for Learning Visuomotor Tasks. (arXiv:2210.06601v1 [cs.RO])
16. Anomaly Detection via Federated Learning. (arXiv:2210.06614v1 [cs.LG])
17. QMRNet: Quality Metric Regression for EO Image Quality Assessment and Super-Resolution. (arXiv:2210.06618v1 [cs.CV])
18. Fairness via Adversarial Attribute Neighbourhood Robust Learning. (arXiv:2210.06630v1 [cs.LG])
19. Neuro-symbolic Explainable Artificial Intelligence Twin for Zero-touch IoE in Wireless Network. (arXiv:2210.06649v1 [cs.AI])
20. Interpreting Neural Policies with Disentangled Tree Representations. (arXiv:2210.06650v1 [cs.LG])
21. Are Macula or Optic Nerve Head Structures better at Diagnosing Glaucoma? An Answer using AI and Wide-Field Optical Coherence Tomography. (arXiv:2210.06664v1 [eess.IV])
22. Application-Driven AI Paradigm for Hand-Held Action Detection. (arXiv:2210.06682v1 [cs.CV])
23. Model-Based Offline Reinforcement Learning with Pessimism-Modulated Dynamics Belief. (arXiv:2210.06692v1 [cs.LG])
24. SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller. (arXiv:2210.06694v1 [cs.CL])
25. Empirical Evaluation of Data Augmentations for Biobehavioral Time Series Data with Deep Learning. (arXiv:2210.06701v1 [cs.LG])
26. A Mixture of Surprises for Unsupervised Reinforcement Learning. (arXiv:2210.06702v1 [cs.LG])
27. From Gradient Flow on Population Loss to Learning with Stochastic Gradient Descent. (arXiv:2210.06705v1 [cs.LG])
28. Jointly Reinforced User Simulator and Task-oriented Dialog System with Simplified Generative Architecture. (arXiv:2210.06706v1 [cs.CL])
29. Weighted Distillation with Unlabeled Examples. (arXiv:2210.06711v1 [cs.LG])
30. Partial Information as Full: Reward Imputation with Sketching in Bandits. (arXiv:2210.06719v1 [cs.LG])
31. LIME: Weakly-Supervised Text Classification Without Seeds. (arXiv:2210.06720v1 [cs.CL])
32. Few-shot Relational Reasoning via Connection Subgraph Pretraining. (arXiv:2210.06722v1 [cs.LG])
33. H2RBox: Horizonal Box Annotation is All You Need for Oriented Object Detection. (arXiv:2210.06742v1 [cs.CV])
34. Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features. (arXiv:2210.06756v1 [cs.CV])
35. Policy Gradient With Serial Markov Chain Reasoning. (arXiv:2210.06766v1 [cs.LG])
36. An Additive Autoencoder for Dimension Estimation. (arXiv:2210.06773v1 [cs.LG])
37. Re3: Generating Longer Stories With Recursive Reprompting and Revision. (arXiv:2210.06774v1 [cs.CL])
38. SDW-ASL: A Dynamic System to Generate Large Scale Dataset for Continuous American Sign Language. (arXiv:2210.06791v1 [cs.CL])
39. Personalized Federated Hypernetworks for Privacy Preservation in Multi-Task Reinforcement Learning. (arXiv:2210.06820v1 [cs.LG])
40. Fast Optimization of Weighted Sparse Decision Trees for use in Optimal Treatment Regimes and Optimal Policy Design. (arXiv:2210.06825v1 [cs.LG])
41. Multi-agent Dynamic Algorithm Configuration. (arXiv:2210.06835v1 [cs.LG])
42. Sample-Then-Optimize Batch Neural Thompson Sampling. (arXiv:2210.06850v1 [cs.LG])
43. Overview of BioASQ 2022: The tenth BioASQ challenge on Large-Scale Biomedical Semantic Indexing and Question Answering. (arXiv:2210.06852v1 [cs.CL])
44. Learning Physical Dynamics with Subequivariant Graph Neural Networks. (arXiv:2210.06876v1 [cs.LG])
45. Pre-Avatar: An Automatic Presentation Generation Framework Leveraging Talking Avatar. (arXiv:2210.06877v1 [cs.AI])
46. RaP: Redundancy-aware Video-language Pre-training for Text-Video Retrieval. (arXiv:2210.06881v1 [cs.CV])
47. An Experiment Design Paradigm using Joint Feature Selection and Task Optimization. (arXiv:2210.06891v1 [cs.LG])
48. Adapting Behaviour Based On Trust In Human-Agent Ad Hoc Teamwork. (arXiv:2210.06915v1 [cs.HC])
49. A Direct Approximation of AIXI Using Logical State Abstractions. (arXiv:2210.06917v1 [cs.AI])
50. On-Premise Artificial Intelligence as a Service for Small and Medium Size Setups. (arXiv:2210.06956v1 [cs.SE])
51. Sustainable Online Reinforcement Learning for Auto-bidding. (arXiv:2210.07006v1 [cs.LG])
52. Over-the-Air Computation Based on Balanced Number Systems for Federated Edge Learning. (arXiv:2210.07012v1 [cs.IT])
53. Transfer Deep Reinforcement Learning-based Large-scale V2G Continuous Charging Coordination with Renewable Energy Sources. (arXiv:2210.07013v1 [eess.SY])
54. Augmentation for Learning From Demonstration with Environmental Constraints. (arXiv:2210.07015v1 [cs.RO])
55. Self-explaining deep models with logic rule reasoning. (arXiv:2210.07024v1 [cs.AI])
56. Threshold Treewidth and Hypertree Width. (arXiv:2210.07040v1 [cs.DS])
57. Spontaneous Emerging Preference in Two-tower Language Model. (arXiv:2210.07041v1 [cs.CL])
58. Dimensionality of datasets in object detection networks. (arXiv:2210.07049v1 [cs.CV])
59. Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation. (arXiv:2210.07054v1 [cs.CL])
60. Deep Clustering With Consensus Representations. (arXiv:2210.07063v1 [cs.LG])
61. Advancing the cybersecurity of the healthcare system with self-optimising and self-adaptative artificial intelligence (part 2). (arXiv:2210.07065v1 [cs.SE])
62. CLASP: Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing. (arXiv:2210.07074v1 [cs.CL])
63. CORL: Research-oriented Deep Offline Reinforcement Learning Library. (arXiv:2210.07105v1 [cs.LG])
64. Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence. (arXiv:2210.07109v1 [cs.CL])
65. A Multi-dimensional Evaluation of Tokenizer-free Multilingual Pretrained Models. (arXiv:2210.07111v1 [cs.CL])
66. Towards End-to-End Open Conversational Machine Reading. (arXiv:2210.07113v1 [cs.CL])
67. How (Not) To Evaluate Explanation Quality. (arXiv:2210.07126v1 [cs.CL])
68. Counterfactual Multihop QA: A Cause-Effect Approach for Reducing Disconnected Reasoning. (arXiv:2210.07138v1 [cs.AI])
69. Scalable Multi-robot Motion Planning for Congested Environments Using Topological Guidance. (arXiv:2210.07141v1 [cs.RO])
70. Accurate, reliable and interpretable solubility prediction of druglike molecules with attention pooling and Bayesian learning. (arXiv:2210.07145v1 [q-bio.BM])
71. Global Explainability of GNNs via Logic Combination of Learned Concepts. (arXiv:2210.07147v1 [cs.LG])
72. Shapley Q-value: A Local Reward Approach to Solve Global Reward Games. (arXiv:1907.05707v6 [cs.LG] UPDATED)
73. Imitative Planning using Conditional Normalizing Flow. (arXiv:2007.16162v3 [cs.RO] UPDATED)
74. A Tensor-Based Formulation of Hetero-functional Graph Theory. (arXiv:2101.07220v2 [cs.AI] UPDATED)
75. On the Paradox of Certified Training. (arXiv:2102.06700v3 [cs.LG] UPDATED)
76. A unified logical framework for explanations in classifier systems. (arXiv:2105.14452v4 [cs.LO] UPDATED)
77. SCINet: Time Series Modeling and Forecasting with Sample Convolution and Interaction. (arXiv:2106.09305v3 [cs.LG] UPDATED)
78. Deep Multiagent Reinforcement Learning: Challenges and Directions. (arXiv:2106.15691v2 [cs.LG] UPDATED)
79. On minimizers and convolutional filters: a partial justification for the effectiveness of CNNs in categorical sequence analysis. (arXiv:2111.08452v3 [cs.LG] UPDATED)
80. Hamiltonian latent operators for content and motion disentanglement in image sequences. (arXiv:2112.01641v4 [cs.CV] UPDATED)
81. Online POI Recommendation: Learning Dynamic Geo-Human Interactions in Streams. (arXiv:2201.10983v3 [cs.IR] UPDATED)
82. A Survey of Methods for Automated Algorithm Configuration. (arXiv:2202.01651v3 [cs.AI] UPDATED)
83. Lazy Rearrangement Planning in Confined Spaces. (arXiv:2203.10379v4 [cs.RO] UPDATED)
84. GRU-TV: Time- and velocity-aware GRU for patient representation on multivariate clinical time-series data. (arXiv:2205.04892v2 [cs.LG] UPDATED)
85. DDXPlus: A New Dataset For Automatic Medical Diagnosis. (arXiv:2205.09148v3 [cs.CL] UPDATED)
86. MCVD: Masked Conditional Video Diffusion for Prediction, Generation, and Interpolation. (arXiv:2205.09853v4 [cs.CV] UPDATED)
87. Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners. (arXiv:2205.10747v4 [cs.CV] UPDATED)
88. Memory-efficient Reinforcement Learning with Knowledge Consolidation. (arXiv:2205.10868v2 [cs.LG] UPDATED)
89. Local Byte Fusion for Neural Machine Translation. (arXiv:2205.11490v2 [cs.CL] UPDATED)
90. Using Natural Language and Program Abstractions to Instill Human Inductive Biases in Machines. (arXiv:2205.11558v2 [cs.AI] UPDATED)
91. Neur2SP: Neural Two-Stage Stochastic Programming. (arXiv:2205.12006v2 [math.OC] UPDATED)
92. Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v2 [cs.CL] UPDATED)
93. Perturbation Augmentation for Fairer NLP. (arXiv:2205.12586v2 [cs.CL] UPDATED)
94. Towards Efficient 3D Object Detection with Knowledge Distillation. (arXiv:2205.15156v2 [cs.CV] UPDATED)
95. Egocentric Video-Language Pretraining. (arXiv:2206.01670v2 [cs.CV] UPDATED)
96. Neuro-Symbolic Procedural Planning with Commonsense Prompting. (arXiv:2206.02928v5 [cs.CL] UPDATED)
97. Learning to Generate Prompts for Dialogue Generation through Reinforcement Learning. (arXiv:2206.03931v3 [cs.CL] UPDATED)
98. PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies. (arXiv:2206.04670v2 [cs.CV] UPDATED)
99. EAGER: Asking and Answering Questions for Automatic Reward Shaping in Language-guided RL. (arXiv:2206.09674v4 [cs.CL] UPDATED)
100. Learning Neuro-Symbolic Skills for Bilevel Planning. (arXiv:2206.10680v2 [cs.RO] UPDATED)
101. A systematic review of biologically-informed deep learning models for cancer: fundamental trends for encoding and interpreting oncology data. (arXiv:2207.00812v2 [q-bio.QM] UPDATED)
102. Bridging the Gap between Object and Image-level Representations for Open-Vocabulary Detection. (arXiv:2207.03482v2 [cs.CV] UPDATED)
103. DeepTime: Deep Time-Index Meta-Learning for Non-Stationary Time-Series Forecasting. (arXiv:2207.06046v3 [cs.LG] UPDATED)
104. Fine-grained Few-shot Recognition by Deep Object Parsing. (arXiv:2207.07110v4 [cs.CV] UPDATED)
105. Active Exploration for Inverse Reinforcement Learning. (arXiv:2207.08645v2 [cs.LG] UPDATED)
106. ShapeCrafter: A Recursive Text-Conditioned 3D Shape Generation Model. (arXiv:2207.09446v2 [cs.CV] UPDATED)
107. Batch-Size Independent Regret Bounds for Combinatorial Semi-Bandits with Probabilistically Triggered Arms or Independent Arms. (arXiv:2208.14837v2 [cs.LG] UPDATED)
108. Focus-Driven Contrastive Learniang for Medical Question Summarization. (arXiv:2209.00484v2 [cs.CL] UPDATED)
109. Geometric multimodal representation learning. (arXiv:2209.03299v2 [cs.LG] UPDATED)
110. Kernel-Segregated Transpose Convolution Operation. (arXiv:2209.03704v3 [cs.LG] UPDATED)
111. Examining Large Pre-Trained Language Models for Machine Translation: What You Don't Know About It. (arXiv:2209.07417v4 [cs.CL] UPDATED)
112. Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango. (arXiv:2209.07686v2 [cs.CL] UPDATED)
113. CLIP-PAE: Projection-Augmentation Embedding to Extract Relevant Features for a Disentangled, Interpretable, and Controllable Text-Guided Image Manipulation. (arXiv:2210.03919v2 [cs.CV] UPDATED)
114. Discovered Policy Optimisation. (arXiv:2210.05639v2 [cs.LG] UPDATED)
115. The Unreasonable Effectiveness of Fully-Connected Layers for Low-Data Regimes. (arXiv:2210.05657v2 [cs.CV] UPDATED)
116. Transformers generalize differently from information stored in context vs in weights. (arXiv:2210.05675v2 [cs.CL] UPDATED)
117. Visual Language Maps for Robot Navigation. (arXiv:2210.05714v2 [cs.RO] UPDATED)
118. Deep Counterfactual Estimation with Categorical Background Variables. (arXiv:2210.05811v2 [cs.LG] UPDATED)
119. Transfer Learning on Electromyography (EMG) Tasks: Approaches and Beyond. (arXiv:2210.06295v2 [eess.SP] UPDATED)
120. Generalised Mutual Information for Discriminative Clustering. (arXiv:2210.06300v2 [stat.ML] UPDATED)
121. Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors. (arXiv:2210.06340v2 [cs.CL] UPDATED)
122. Relational Graph Convolutional Neural Networks for Multihop Reasoning: A Comparative Study. (arXiv:2210.06418v2 [cs.CL] UPDATED)
123. Predictive Querying for Autoregressive Neural Sequence Models. (arXiv:2210.06464v2 [cs.LG] UPDATED)

