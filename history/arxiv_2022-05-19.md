# Your interest papers
---
## cs.CV
---
### Towards Robust **Low Light** Image **Enhancement**. (arXiv:2205.08615v1 [cs.CV])
- Authors : Sara Aghajanzadeh, David Forsyth
- Link : [http://arxiv.org/abs/2205.08615](http://arxiv.org/abs/2205.08615)
> ABSTRACT  :  In this paper, we study the problem of making brighter images from **dark** images found in the wild. The images are **dark** because they are taken in dim environments. They suffer from color shifts caused by quantization and from sensor noise. We don't know the true camera reponse function for such images and they are not RAW. We use a supervised learning method, relying on a straightforward simulation of an imaging pipeline to generate usable dataset for training and testing. On a number of standard datasets, our approach outperforms the state of the art quantitatively. Qualitative comparisons suggest strong improvements in reconstruction accuracy.  
### Speckle Image **Restoration** without Clean Data. (arXiv:2205.08833v1 [eess.IV])
- Authors : Ming Tai, Jie Jhang, Jyi Hwang, Jern Cheng
- Link : [http://arxiv.org/abs/2205.08833](http://arxiv.org/abs/2205.08833)
> ABSTRACT  :  Speckle noise is an inherent disturbance in coherent imaging systems such as digital holography, synthetic aperture radar, optical coherence tomography, or ultrasound systems. These systems usually produce only single observation per view angle of the same interest object, imposing the difficulty to leverage the statistic among observations. We propose a novel image **restoration** algorithm that can perform speckle noise removal without clean data and does not require multiple noisy observations in the same view angle. Our proposed method can also be applied to the situation without knowing the noise distribution as prior. We demonstrate our method is especially well-suited for spectral images by first validating on the synthetic dataset, and also applied on real-world digital holography samples. The results are superior in both quantitative measurement and visual inspection compared to several widely applied baselines. Our method even shows promising results across different speckle noise strengths, without the clean data needed.  
### Remote Sensing Novel View Synthesis with Implicit Multiplane Representations. (arXiv:2205.08908v1 [cs.CV])
- Authors : Yongchang Wu, Zhengxia Zou, Zhenwei Shi
- Link : [http://arxiv.org/abs/2205.08908](http://arxiv.org/abs/2205.08908)
> ABSTRACT  :  Novel view synthesis of remote sensing scenes is of great significance for scene visualization, human-computer interaction, and various downstream applications. Despite the recent advances in computer graphics and photogrammetry technology, generating novel views is still challenging particularly for remote sensing images due to its high complexity, view sparsity and limited view-perspective variations. In this paper, we propose a novel remote sensing view synthesis method by leveraging the recent advances in **implicit neural representation**s. Considering the overhead and far depth imaging of remote sensing images, we represent the 3D space by combining implicit multiplane images (MPI) representation and deep neural networks. The 3D scene is reconstructed under a self-supervised optimization paradigm through a differentiable multiplane renderer with multi-view input constraints. Images from any novel views thus can be freely rendered on the basis of the reconstructed model. As a by-product, the depth maps corresponding to the given viewpoint can be generated along with the rendering output. We refer to our method as Implicit Multiplane Images (ImMPI). To further improve the view synthesis under sparse-view inputs, we explore the learning-based initialization of remote sensing 3D scenes and proposed a neural network based Prior extractor to accelerate the optimization process. In addition, we propose a new dataset for remote sensing novel view synthesis with multi-view real-world google earth images. Extensive experiments demonstrate the superiority of the ImMPI over previous state-of-the-art methods in terms of reconstruction accuracy, visual fidelity, and time efficiency. Ablation experiments also suggest the effectiveness of our methodology design. Our dataset and code can be found at https://github.com/wyc-Chang/ImMPI  
### DIVeR: **Real-time** and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering. (arXiv:2111.10427v2 [cs.CV] UPDATED)
- Authors : Liwen Wu, Jae Yong, Anand Bhattad, Yuxiong Wang, David Forsyth
- Link : [http://arxiv.org/abs/2111.10427](http://arxiv.org/abs/2111.10427)
> ABSTRACT  :  DIVeR builds on the key ideas of **NeRF** and its variants -- density models and volume rendering -- to learn 3D object models that can be rendered realistically from small numbers of images. In contrast to all previous **NeRF** methods, DIVeR uses deterministic rather than stochastic estimates of the volume rendering integral. DIVeR's representation is a voxel based field of features. To compute the volume rendering integral, a ray is broken into intervals, one per voxel; components of the volume rendering integral are estimated from the features for each interval using an MLP, and the components are aggregated. As a result, DIVeR can render thin translucent structures that are missed by other integrators. Furthermore, DIVeR's representation has semantics that is relatively exposed compared to other such methods -- moving feature vectors around in the voxel space results in natural edits. Extensive qualitative and quantitative comparisons to current state-of-the-art methods show that DIVeR produces models that (1) render at or above state-of-the-art quality, (2) are very small without being baked, (3) render very fast without being baked, and (4) can be edited in natural ways.  
### FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer. (arXiv:2111.13824v3 [cs.CV] UPDATED)
- Authors : Yang Lin, Tianyu Zhang, Peiqin Sun, Zheng Li, Shuchang Zhou
- Link : [http://arxiv.org/abs/2111.13824](http://arxiv.org/abs/2111.13824)
> ABSTRACT  :  Network quantization significantly reduces model inference complexity and has been widely used in real-world deployments. However, most existing quantization methods have been developed mainly on Convolutional Neural Networks (CNNs), and suffer severe degradation when applied to fully quantized vision transformers. In this work, we demonstrate that many of these difficulties arise because of serious inter-channel variation in LayerNorm inputs, and present, Power-of-Two Factor (PTF), a systematic method to reduce the performance degradation and inference complexity of fully quantized vision transformers. In addition, observing an extreme non-uniform distribution in attention maps, we propose Log-Int-Softmax (LIS) to sustain that and simplify inference by using 4-bit quantization and the BitShift operator. Comprehensive experiments on various transformer-based architectures and benchmarks show that our Fully Quantized Vision Transformer (FQ-ViT) outperforms previous works while even using lower bit-width on attention maps. For instance, we reach 84.89% top-1 accuracy with ViT-L on ImageNet and 50.8 mAP with Cascade Mask R-CNN (**Swin**-S) on COCO. To our knowledge, we are the first to achieve lossless accuracy degradation (~1%) on fully quantized vision transformers. The code is available at https://github.com/megvii-research/FQ-ViT.  
### Neural 3D Scene Reconstruction with the Manhattan-world Assumption. (arXiv:2205.02836v2 [cs.CV] UPDATED)
- Authors : Haoyu Guo, Sida Peng, Haotong Lin, Qianqian Wang, Guofeng Zhang, Hujun Bao, Xiaowei Zhou
- Link : [http://arxiv.org/abs/2205.02836](http://arxiv.org/abs/2205.02836)
> ABSTRACT  :  This paper addresses the challenge of reconstructing 3D indoor scenes from multi-view images. Many previous works have shown impressive reconstruction results on textured objects, but they still have difficulty in handling low-textured planar regions, which are common in indoor scenes. An approach to solving this issue is to incorporate planer constraints into the depth map estimation in multi-view stereo-based methods, but the per-view plane estimation and depth optimization lack both efficiency and multi-view consistency. In this work, we show that the planar constraints can be conveniently integrated into the recent **implicit neural representation**-based reconstruction methods. Specifically, we use an MLP network to represent the signed distance function as the scene geometry. Based on the Manhattan-world assumption, planar constraints are employed to regularize the geometry in floor and wall regions predicted by a 2D semantic segmentation network. To resolve the inaccurate segmentation, we encode the semantics of 3D points with another MLP and design a novel loss that jointly optimizes the scene geometry and semantics in 3D space. Experiments on ScanNet and 7-Scenes datasets show that the proposed method outperforms previous methods by a large margin on 3D reconstruction quality. The code is available at https://zju3dv.github.io/manhattan_sdf.  
### Vision Transformer Adapter for Dense Predictions. (arXiv:2205.08534v2 [cs.CV] UPDATED)
- Authors : Zhe Chen, Yuchen Duan, Wenhai Wang, Junjun He, Tong Lu, Jifeng Dai, Yu Qiao
- Link : [http://arxiv.org/abs/2205.08534](http://arxiv.org/abs/2205.08534)
> ABSTRACT  :  This work investigates a simple yet powerful adapter for Vision Transformer (ViT). Unlike recent visual transformers that introduce vision-specific inductive biases into their architectures, ViT achieves inferior performance on dense prediction tasks due to lacking prior information of images. To solve this issue, we propose a Vision Transformer Adapter (ViT-Adapter), which can remedy the defects of ViT and achieve comparable performance to vision-specific models by introducing inductive biases via an additional architecture. Specifically, the backbone in our framework is a vanilla transformer that can be pre-trained with multi-modal data. When fine-tuning on downstream tasks, a modality-specific adapter is used to introduce the data and tasks' prior information into the model, making it suitable for these tasks. We verify the effectiveness of our ViT-Adapter on multiple downstream tasks, including object detection, instance segmentation, and semantic segmentation. Notably, when using HTC++, our ViT-Adapter-L yields 60.1 box AP and 52.1 mask AP on COCO test-dev, surpassing **Swin**-L by 1.4 box AP and 1.0 mask AP. For semantic segmentation, our ViT-Adapter-L establishes a new state-of-the-art of 60.5 mIoU on ADE20K val, 0.6 points higher than **Swin**V2-G. We hope that the proposed ViT-Adapter could serve as an alternative for vision-specific transformers and facilitate future research. The code and models will be released at https://github.com/czczup/ViT-Adapter.  
### **Real-time** semantic segmentation on FPGAs for autonomous vehicles with hls4ml. (arXiv:2205.07690v1 [cs.CV] CROSS LISTED)
- Authors : Vladimir Loncar, Maurizio Pierini, Marcel Roed, Sioni Summers, Thea Aarrestad, Christoffer Petersson, Hampus Linander, Jennifer Ngadiuba, Kelvin Lin, Philip Harris
- Link : [http://arxiv.org/abs/2205.07690](http://arxiv.org/abs/2205.07690)
> ABSTRACT  :  In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.  
## eess.IV
---
### Speckle Image **Restoration** without Clean Data. (arXiv:2205.08833v1 [eess.IV])
- Authors : Ming Tai, Jie Jhang, Jyi Hwang, Jern Cheng
- Link : [http://arxiv.org/abs/2205.08833](http://arxiv.org/abs/2205.08833)
> ABSTRACT  :  Speckle noise is an inherent disturbance in coherent imaging systems such as digital holography, synthetic aperture radar, optical coherence tomography, or ultrasound systems. These systems usually produce only single observation per view angle of the same interest object, imposing the difficulty to leverage the statistic among observations. We propose a novel image **restoration** algorithm that can perform speckle noise removal without clean data and does not require multiple noisy observations in the same view angle. Our proposed method can also be applied to the situation without knowing the noise distribution as prior. We demonstrate our method is especially well-suited for spectral images by first validating on the synthetic dataset, and also applied on real-world digital holography samples. The results are superior in both quantitative measurement and visual inspection compared to several widely applied baselines. Our method even shows promising results across different speckle noise strengths, without the clean data needed.  
### A Survey on Hyperspectral Image **Restoration**: From the View of Low-Rank Tensor Approximation. (arXiv:2205.08839v1 [eess.IV])
- Authors : Na Liu, Wei Li, Yinjian Wang, Rao Tao, Qian Du, Jocelyn Chanussot
- Link : [http://arxiv.org/abs/2205.08839](http://arxiv.org/abs/2205.08839)
> ABSTRACT  :  The ability of capturing fine spectral discriminative information enables hyperspectral images (HSIs) to observe, detect and identify objects with subtle spectral discrepancy. However, the captured HSIs may not represent true distribution of ground objects and the received reflectance at imaging instruments may be degraded, owing to environmental disturbances, atmospheric effects and sensors' hardware limitations. These degradations include but are not limited to: complex noise (i.e., Gaussian noise, impulse noise, sparse stripes, and their mixtures), heavy stripes, deadlines, cloud and shadow occlusion, blurring and spatial-resolution degradation and spectral absorption, etc. These degradations dramatically reduce the quality and usefulness of HSIs. Low-rank tensor approximation (LRTA) is such an emerging technique, having gained much attention in HSI **restoration** community, with ever-growing theoretical foundation and pivotal technological innovation. Compared to low-rank matrix approximation (LRMA), LRTA is capable of characterizing more complex intrinsic structure of high-order data and owns more efficient learning abilities, being established to address convex and non-convex inverse optimization problems induced by HSI **restoration**. This survey mainly attempts to present a sophisticated, cutting-edge, and comprehensive technical survey of LRTA toward HSI **restoration**, specifically focusing on the following six topics: Denoising, Destriping, Inpainting, Deblurring, Super--resolution and Fusion. The theoretical development and variants of LRTA techniques are also elaborated. For each topic, the state-of-the-art **restoration** methods are compared by assessing their performance both quantitatively and visually. Open issues and challenges are also presented, including model formulation, algorithm design, prior exploration and application concerning the interpretation requirements.  
## cs.LG
---
### Fast Neural Network based Solving of Partial Differential Equations. (arXiv:2205.08978v1 [cs.LG])
- Authors : Jaroslaw Rzepecki, Chris Doran
- Link : [http://arxiv.org/abs/2205.08978](http://arxiv.org/abs/2205.08978)
> ABSTRACT  :  We present a novel method for using Neural Networks (NNs) for finding solutions to a class of Partial Differential Equations (PDEs). Our method builds on recent advances in Neural Radiance Field research (**NeRF**s) and allows for a NN to converge to a PDE solution much faster than classic Physically Informed Neural Network (PINNs) approaches.  
### Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v2 [cs.CE] UPDATED)
- Authors : Deqing Zhai, Xiuju Fu, Xiao Feng, Haiyan Xu, Wanbing Zhang
- Link : [http://arxiv.org/abs/2204.04085](http://arxiv.org/abs/2204.04085)
> ABSTRACT  :  Given the trend of digitization and increasing number of maritime transport, prediction of vessel berth stay has been triggered for requirements of operation research and scheduling optimization problem in the era of maritime big data, which takes a significant part in port efficiency and maritime logistics **enhancement**. This study proposes a systematic and dynamic approach of predicting berth stay for tanker terminals. The approach covers three innovative aspects: 1) Data source employed is multi-faceted, including cargo operation data from tanker terminals, time-series data from automatic identification system (AIS), etc. 2) The process of berth stay is decomposed into multiple blocks according to data analysis and information extraction innovatively, and practical operation scenarios are also developed accordingly. 3) The predictive models of berth stay are developed on the basis of prior data analysis and information extraction under two methods, including regression and decomposed distribution. The models are evaluated under four dynamic scenarios with certain designated cargoes among two different terminals. The evaluation results show that the proposed approach can predict berth stay with the accuracy up to 98.81% validated by historical baselines, and also demonstrate the proposed approach has dynamic capability of predicting berth stay among the scenarios. The model may be potentially applied for short-term pilot-booking or scheduling optimizations within a reasonable time frame for advancement of port intelligence and logistics efficiency.  
### **Real-time** semantic segmentation on FPGAs for autonomous vehicles with hls4ml. (arXiv:2205.07690v1 [cs.CV] CROSS LISTED)
- Authors : Vladimir Loncar, Maurizio Pierini, Marcel Roed, Sioni Summers, Thea Aarrestad, Christoffer Petersson, Hampus Linander, Jennifer Ngadiuba, Kelvin Lin, Philip Harris
- Link : [http://arxiv.org/abs/2205.07690](http://arxiv.org/abs/2205.07690)
> ABSTRACT  :  In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.  
## cs.AI
---
### Intuitive and Efficient Human-robot Collaboration via **Real-time** Approximate Bayesian Inference. (arXiv:2205.08657v1 [cs.RO])
- Authors : Javier Felip, David Gonzalez, Lama Nachman
- Link : [http://arxiv.org/abs/2205.08657](http://arxiv.org/abs/2205.08657)
> ABSTRACT  :  The combination of collaborative robots and end-to-end AI, promises flexible automation of human tasks in factories and warehouses. However, such promise seems a few breakthroughs away. In the meantime, humans and cobots will collaborate helping each other. For these collaborations to be effective and safe, robots need to model, predict and exploit human's intents for responsive decision making processes.    Approximate Bayesian Computation (ABC) is an analysis-by-synthesis approach to perform probabilistic predictions upon uncertain quantities. ABC includes priors conveniently, leverages sampling algorithms for inference and is flexible to benefit from complex models, e.g. via simulators. However, ABC is known to be computationally too intensive to run at interactive frame rates required for effective human-robot collaboration tasks.    In this paper, we formulate human reaching intent prediction as an ABC problem and describe two key performance innovations which allow computations at interactive rates. Our real-world experiments with a collaborative robot set-up, demonstrate the viability of our proposed approach. Experimental evaluations convey the advantages and value of human intent prediction for packing cooperative tasks. Qualitative results show how anticipating human's reaching intent improves human-robot collaboration without compromising safety. Quantitative task fluency metrics confirm the qualitative claims.  
### Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v2 [cs.CE] UPDATED)
- Authors : Deqing Zhai, Xiuju Fu, Xiao Feng, Haiyan Xu, Wanbing Zhang
- Link : [http://arxiv.org/abs/2204.04085](http://arxiv.org/abs/2204.04085)
> ABSTRACT  :  Given the trend of digitization and increasing number of maritime transport, prediction of vessel berth stay has been triggered for requirements of operation research and scheduling optimization problem in the era of maritime big data, which takes a significant part in port efficiency and maritime logistics **enhancement**. This study proposes a systematic and dynamic approach of predicting berth stay for tanker terminals. The approach covers three innovative aspects: 1) Data source employed is multi-faceted, including cargo operation data from tanker terminals, time-series data from automatic identification system (AIS), etc. 2) The process of berth stay is decomposed into multiple blocks according to data analysis and information extraction innovatively, and practical operation scenarios are also developed accordingly. 3) The predictive models of berth stay are developed on the basis of prior data analysis and information extraction under two methods, including regression and decomposed distribution. The models are evaluated under four dynamic scenarios with certain designated cargoes among two different terminals. The evaluation results show that the proposed approach can predict berth stay with the accuracy up to 98.81% validated by historical baselines, and also demonstrate the proposed approach has dynamic capability of predicting berth stay among the scenarios. The model may be potentially applied for short-term pilot-booking or scheduling optimizations within a reasonable time frame for advancement of port intelligence and logistics efficiency.  
# Paper List
---
## cs.CV
---
**71** new papers in cs.CV:-) 
1. Text Detection & Recognition in the Wild for Robot Localization. (arXiv:2205.08565v1 [cs.CV])
2. Label-Efficient Self-Supervised Federated Learning for Tackling Data Heterogeneity in Medical Imaging. (arXiv:2205.08576v1 [cs.CV])
3. CV4Code: Sourcecode Understanding via Visual Code Representations. (arXiv:2205.08585v1 [cs.SE])
4. RARITYNet: Rarity Guided Affective Emotion Learning Framework. (arXiv:2205.08595v1 [cs.CV])
5. Towards Robust **Low Light** Image **Enhancement**. (arXiv:2205.08615v1 [cs.CV])
6. Semantically Accurate Super-Resolution Generative Adversarial Networks. (arXiv:2205.08659v1 [cs.CV])
7. Learning Monocular Depth Estimation via Selective Distillation of Stereo Knowledge. (arXiv:2205.08668v1 [cs.CV])
8. K-textures, a self supervised hard clustering deep learning algorithm for satellite images segmentation. (arXiv:2205.08671v1 [cs.CV])
9. Deep learning on rail profiles matching. (arXiv:2205.08687v1 [cs.CV])
10. Hyperparameter Optimization with Neural Network Pruning. (arXiv:2205.08695v1 [cs.CV])
11. SemiCurv: Semi-Supervised Curvilinear Structure Segmentation. (arXiv:2205.08706v1 [cs.CV])
12. It Isn't Sh!tposting, It's My CAT Posting. (arXiv:2205.08710v1 [cs.CV])
13. Sparse MDOD: Training End-to-End Multi-Object Detector without Bipartite Matching. (arXiv:2205.08714v1 [cs.CV])
14. RandomMix: A mixed sample data augmentation method with multiple mixed modes. (arXiv:2205.08728v1 [cs.CV])
15. TTAPS: Test-Time Adaption by Aligning Prototypes using Self-Supervision. (arXiv:2205.08731v1 [cs.LG])
16. Deep-learned orthogonal basis patterns for fast, noise-robust single-pixel imaging. (arXiv:2205.08736v1 [eess.IV])
17. Passive Defense Against 3D Adversarial Point Clouds Through the Lens of 3D Steganalysis. (arXiv:2205.08738v1 [cs.MM])
18. Validation of a photogrammetric approach for the study of ancient bowed instruments. (arXiv:2205.08745v1 [cs.CV])
19. Visual Attention-based Self-supervised Absolute Depth Estimation using Geometric Priors in Autonomous Driving. (arXiv:2205.08780v1 [cs.CV])
20. Cross-subject Action Unit Detection with Meta Learning and Transformer-based Relation Modeling. (arXiv:2205.08787v1 [cs.CV])
21. PhoCaL: A Multi-Modal Dataset for Category-Level Object Pose Estimation with Photometrically Challenging Objects. (arXiv:2205.08811v1 [cs.CV])
22. Anomaly detection using prediction error with Spatio-Temporal Convolutional LSTM. (arXiv:2205.08812v1 [cs.CV])
23. Speckle Image **Restoration** without Clean Data. (arXiv:2205.08833v1 [eess.IV])
24. Large Neural Networks Learning from Scratch with Very Few Data and without Regularization. (arXiv:2205.08836v1 [cs.CV])
25. Positional Information is All You Need: A Novel Pipeline for Self-Supervised SVDE from Videos. (arXiv:2205.08851v1 [cs.CV])
26. Transformer based multiple instance learning for weakly supervised histopathology image segmentation. (arXiv:2205.08878v1 [cs.CV])
27. 3D Segmentation Guided Style-based Generative Adversarial Networks for PET Synthesis. (arXiv:2205.08887v1 [eess.IV])
28. Remote Sensing Novel View Synthesis with Implicit Multiplane Representations. (arXiv:2205.08908v1 [cs.CV])
29. Financial Time Series Data Augmentation with Generative Adversarial Networks and extended Intertemporal Return Plots. (arXiv:2205.08924v1 [cs.CV])
30. COVID-Net UV: An End-to-End Spatio-Temporal Deep Neural Network Architecture for Automated Diagnosis of COVID-19 Infection from Ultrasound Videos. (arXiv:2205.08932v1 [eess.IV])
31. Deep Features for CBIR with Scarce Data using Hebbian Learning. (arXiv:2205.08935v1 [cs.CV])
32. A lightweight multi-scale context network for salient object detection in optical remote sensing images. (arXiv:2205.08959v1 [cs.CV])
33. DL4DS -- Deep Learning for empirical DownScaling. (arXiv:2205.08967v1 [cs.LG])
34. Trading Positional Complexity vs. Deepness in Coordinate Networks. (arXiv:2205.08987v1 [cs.CV])
35. Constraining the Attack Space of Machine Learning Models with Distribution Clamping Preprocessing. (arXiv:2205.08989v1 [cs.LG])
36. Empirical Advocacy of Bio-inspired Models for Robust Image Recognition. (arXiv:2205.09037v1 [cs.CV])
37. Global Contrast Masked Autoencoders Are Powerful Pathological Representation Learners. (arXiv:2205.09048v1 [cs.CV])
38. VRAG: Region Attention Graphs for Content-Based Video Retrieval. (arXiv:2205.09068v1 [cs.CV])
39. Pluralistic Image Completion with Probabilistic Mixture-of-Experts. (arXiv:2205.09086v1 [cs.CV])
40. BodyMap: Learning Full-Body Dense Correspondence Map. (arXiv:2205.09111v1 [cs.CV])
41. Masked Autoencoders As Spatiotemporal Learners. (arXiv:2205.09113v1 [cs.CV])
42. Learning Selective Sensor Fusion for States Estimation. (arXiv:1912.13077v2 [cs.CV] UPDATED)
43. Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks. (arXiv:2005.09147v8 [cs.CV] UPDATED)
44. Moderately Supervised Learning: Definition, Framework and Generality. (arXiv:2008.11945v3 [cs.CV] UPDATED)
45. Medical Deep Learning -- A systematic Meta-Review. (arXiv:2010.14881v5 [eess.IV] UPDATED)
46. PocketNet: A Smaller Neural Network for Medical Image Analysis. (arXiv:2104.10745v3 [eess.IV] UPDATED)
47. Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v2 [eess.IV] UPDATED)
48. Physics-informed Guided Disentanglement in Generative Networks. (arXiv:2107.14229v2 [cs.CV] UPDATED)
49. Cohort Bias Adaptation in Aggregated Datasets for Lesion Segmentation. (arXiv:2108.00713v2 [eess.IV] UPDATED)
50. GRI: General Reinforced Imitation and its Application to Vision-Based Autonomous Driving. (arXiv:2111.08575v2 [cs.RO] UPDATED)
51. DIVeR: **Real-time** and Accurate Neural Radiance Fields with Deterministic Integration for Volume Rendering. (arXiv:2111.10427v2 [cs.CV] UPDATED)
52. MegLoc: A Robust and Accurate Visual Localization Pipeline. (arXiv:2111.13063v2 [cs.CV] UPDATED)
53. FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer. (arXiv:2111.13824v3 [cs.CV] UPDATED)
54. AdaAfford: Learning to Adapt Manipulation Affordance for 3D Articulated Objects via Few-shot Interactions. (arXiv:2112.00246v4 [cs.CV] UPDATED)
55. Object-aware Video-language Pre-training for Retrieval. (arXiv:2112.00656v6 [cs.CV] UPDATED)
56. Holistic Interpretation of Public Scenes Using Computer Vision and Temporal Graphs to Identify Social Distancing Violations. (arXiv:2112.06428v3 [cs.CV] UPDATED)
57. Robust photon-efficient imaging using a pixel-wise residual shrinkage network. (arXiv:2201.01453v2 [eess.IV] UPDATED)
58. You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v2 [cs.CV] UPDATED)
59. UQGAN: A Unified Model for Uncertainty Quantification of Deep Classifiers trained via Conditional GANs. (arXiv:2201.13279v2 [cs.CV] UPDATED)
60. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v4 [cs.CV] UPDATED)
61. Mobile authentication of copy detection patterns. (arXiv:2203.02397v2 [cs.CR] UPDATED)
62. Contrastive Transformer-based Multiple Instance Learning for Weakly Supervised Polyp Frame Detection. (arXiv:2203.12121v2 [cs.CV] UPDATED)
63. MonoTrack: Shuttle trajectory reconstruction from monocular badminton video. (arXiv:2204.01899v2 [cs.CV] UPDATED)
64. Dite-HRNet: Dynamic Lightweight High-Resolution Network for Human Pose Estimation. (arXiv:2204.10762v2 [cs.CV] UPDATED)
65. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v2 [eess.IV] UPDATED)
66. Neural 3D Scene Reconstruction with the Manhattan-world Assumption. (arXiv:2205.02836v2 [cs.CV] UPDATED)
67. LatentKeypointGAN: Controlling Images via Latent Keypoints -- Extended Abstract. (arXiv:2205.03448v2 [cs.CV] UPDATED)
68. Identical Image Retrieval using Deep Learning. (arXiv:2205.04883v2 [cs.CV] UPDATED)
69. Gender and Racial Bias in Visual Question Answering Datasets. (arXiv:2205.08148v2 [cs.CV] UPDATED)
70. Vision Transformer Adapter for Dense Predictions. (arXiv:2205.08534v2 [cs.CV] UPDATED)
71. **Real-time** semantic segmentation on FPGAs for autonomous vehicles with hls4ml. (arXiv:2205.07690v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**20** new papers in eess.IV:-) 
1. Semantically Accurate Super-Resolution Generative Adversarial Networks. (arXiv:2205.08659v1 [cs.CV])
2. Deep-learned orthogonal basis patterns for fast, noise-robust single-pixel imaging. (arXiv:2205.08736v1 [eess.IV])
3. Passive Defense Against 3D Adversarial Point Clouds Through the Lens of 3D Steganalysis. (arXiv:2205.08738v1 [cs.MM])
4. Speckle Image **Restoration** without Clean Data. (arXiv:2205.08833v1 [eess.IV])
5. A Survey on Hyperspectral Image **Restoration**: From the View of Low-Rank Tensor Approximation. (arXiv:2205.08839v1 [eess.IV])
6. Positional Information is All You Need: A Novel Pipeline for Self-Supervised SVDE from Videos. (arXiv:2205.08851v1 [cs.CV])
7. 3D Segmentation Guided Style-based Generative Adversarial Networks for PET Synthesis. (arXiv:2205.08887v1 [eess.IV])
8. COVID-Net UV: An End-to-End Spatio-Temporal Deep Neural Network Architecture for Automated Diagnosis of COVID-19 Infection from Ultrasound Videos. (arXiv:2205.08932v1 [eess.IV])
9. Sensing Time Effectiveness for Fitness to Drive Evaluation in Neurological Patients. (arXiv:2205.08942v1 [eess.IV])
10. Field Distortion Model Based on Fredholm Integral. (arXiv:2205.09022v1 [eess.IV])
11. Leveraging Global Binary Masks for Structure Segmentation in Medical Images. (arXiv:2205.09107v1 [eess.IV])
12. Adaptive Compressive Sampling for Mid-infrared Spectroscopic Imaging. (arXiv:2008.00566v2 [eess.IV] UPDATED)
13. Moderately Supervised Learning: Definition, Framework and Generality. (arXiv:2008.11945v3 [cs.CV] UPDATED)
14. Medical Deep Learning -- A systematic Meta-Review. (arXiv:2010.14881v5 [eess.IV] UPDATED)
15. Detecting micro fractures: A comprehensive comparison of conventional and machine-learning based segmentation methods. (arXiv:2103.12821v2 [cs.LG] UPDATED)
16. PocketNet: A Smaller Neural Network for Medical Image Analysis. (arXiv:2104.10745v3 [eess.IV] UPDATED)
17. Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v2 [eess.IV] UPDATED)
18. Cohort Bias Adaptation in Aggregated Datasets for Lesion Segmentation. (arXiv:2108.00713v2 [eess.IV] UPDATED)
19. Robust photon-efficient imaging using a pixel-wise residual shrinkage network. (arXiv:2201.01453v2 [eess.IV] UPDATED)
20. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v2 [eess.IV] UPDATED)
## cs.LG
---
**155** new papers in cs.LG:-) 
1. Learning Quantum Entanglement Distillation with Noisy Classical Communications. (arXiv:2205.08561v1 [quant-ph])
2. Strategizing against Learners in Bayesian Games. (arXiv:2205.08562v1 [cs.LG])
3. Label-Efficient Self-Supervised Federated Learning for Tackling Data Heterogeneity in Medical Imaging. (arXiv:2205.08576v1 [cs.CV])
4. The Power of Reuse: A Multi-Scale Transformer Model for Structural Dynamic Segmentation in Symbolic Music Generation. (arXiv:2205.08579v1 [cs.SD])
5. CV4Code: Sourcecode Understanding via Visual Code Representations. (arXiv:2205.08585v1 [cs.SE])
6. Hierarchical Distribution-Aware Testing of Deep Learning. (arXiv:2205.08589v1 [cs.SE])
7. Quantum Transfer Learning for Wi-Fi Sensing. (arXiv:2205.08590v1 [cs.LG])
8. Deep Neural Network Classifier for Multi-dimensional Functional Data. (arXiv:2205.08592v1 [stat.ML])
9. Universal characteristics of deep neural network loss surfaces from random matrix theory. (arXiv:2205.08601v1 [math-ph])
10. Variational Quantum Compressed Sensing for Joint User and Channel State Acquisition in Grant-Free Device Access Systems. (arXiv:2205.08603v1 [eess.SP])
11. OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource Language Pair for Low-Resource Sentence Retrieval. (arXiv:2205.08605v1 [cs.CL])
12. Multibit Tries Packet Classification with Deep Reinforcement Learning. (arXiv:2205.08606v1 [cs.NI])
13. All-Photonic Artificial Neural Network Processor Via Non-linear Optics. (arXiv:2205.08608v1 [physics.optics])
14. Bagged Polynomial Regression and Neural Networks. (arXiv:2205.08609v1 [stat.ML])
15. Learning to Learn Quantum Turbo Detection. (arXiv:2205.08611v1 [eess.SP])
16. A graph representation of molecular ensembles for polymer property prediction. (arXiv:2205.08619v1 [cs.LG])
17. Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks. (arXiv:2205.08625v1 [cs.CL])
18. Classification as Direction Recovery: Improved Guarantees via Scale Invariance. (arXiv:2205.08633v1 [stat.ML])
19. Frank Wolfe Meets Metric Entropy. (arXiv:2205.08634v1 [stat.ML])
20. Need is All You Need: Homeostatic Neural Networks Adapt to Concept Shift. (arXiv:2205.08645v1 [cs.LG])
21. QAPPA: Quantization-Aware Power, Performance, and Area Modeling of DNN Accelerators. (arXiv:2205.08648v1 [cs.AR])
22. Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability. (arXiv:2205.08685v1 [cs.LG])
23. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v1 [cs.LG])
24. Hyperparameter Optimization with Neural Network Pruning. (arXiv:2205.08695v1 [cs.CV])
25. The Solvability of Interpretability Evaluation Metrics. (arXiv:2205.08696v1 [cs.LG])
26. Optimal Adaptive Prediction Intervals for Electricity Load Forecasting in Distribution Systems via Reinforcement Learning. (arXiv:2205.08698v1 [stat.AP])
27. Accurate Fairness: Improving Individual Fairness without Trading Accuracy. (arXiv:2205.08704v1 [cs.LG])
28. It Isn't Sh!tposting, It's My CAT Posting. (arXiv:2205.08710v1 [cs.CV])
29. CARNet: A Dynamic Autoencoder for Learning Latent Dynamics in Autonomous Driving Tasks. (arXiv:2205.08712v1 [cs.LG])
30. Customizing ML Predictions for Online Algorithms. (arXiv:2205.08715v1 [cs.LG])
31. No More Pesky Hyperparameters: Offline Hyperparameter Tuning for RL. (arXiv:2205.08716v1 [cs.LG])
32. A Regression Approach to Learning-Augmented Online Algorithms. (arXiv:2205.08717v1 [cs.LG])
33. TTAPS: Test-Time Adaption by Aligning Prototypes using Self-Supervision. (arXiv:2205.08731v1 [cs.LG])
34. Deep-learned orthogonal basis patterns for fast, noise-robust single-pixel imaging. (arXiv:2205.08736v1 [eess.IV])
35. Revisiting PINNs: Generative Adversarial Physics-informed Neural Networks and Point-weighting Method. (arXiv:2205.08754v1 [cs.LG])
36. Marginal and Joint Cross-Entropies & Predictives for Online Bayesian Inference, Active Learning, and Active Sampling. (arXiv:2205.08766v1 [cs.LG])
37. Probability trees and the value of a single intervention. (arXiv:2205.08779v1 [cs.LG])
38. On-device modeling of user's social context and familiar places from smartphone-embedded sensor data. (arXiv:2205.08790v1 [cs.LG])
39. Markov Chain Monte Carlo for Continuous-Time Switching Dynamical Systems. (arXiv:2205.08803v1 [cs.LG])
40. Entity Alignment with Reliable Path Reasoning and Relation-Aware Heterogeneous Graph Transformer. (arXiv:2205.08806v1 [cs.CL])
41. Evaluation of Transfer Learning for Polish with a Text-to-Text Model. (arXiv:2205.08808v1 [cs.CL])
42. Property Unlearning: A Defense Strategy Against Property Inference Attacks. (arXiv:2205.08821v1 [cs.CR])
43. Automating In-Network Machine Learning. (arXiv:2205.08824v1 [cs.NI])
44. World Value Functions: Knowledge Representation for Multitask Reinforcement Learning. (arXiv:2205.08827v1 [cs.LG])
45. Fair and Green Hyperparameter Optimization via Multi-objective and Multiple Information Source Bayesian Optimization. (arXiv:2205.08835v1 [cs.LG])
46. Large Neural Networks Learning from Scratch with Very Few Data and without Regularization. (arXiv:2205.08836v1 [cs.CV])
47. Bridging the gap between QP-based and MPC-based RL. (arXiv:2205.08856v1 [eess.SY])
48. The Kernelized Taylor Diagram. (arXiv:2205.08864v1 [stat.ML])
49. Multi-disciplinary fairness considerations in machine learning for clinical trials. (arXiv:2205.08875v1 [cs.LG])
50. GeoPointGAN: Synthetic Spatial Data with Local Label Differential Privacy. (arXiv:2205.08886v1 [cs.LG])
51. FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting. (arXiv:2205.08897v1 [cs.LG])
52. Price Interpretability of Prediction Markets: A Convergence Analysis. (arXiv:2205.08913v1 [q-fin.TR])
53. Generating Explanations from Deep Reinforcement Learning Using Episodic Memory. (arXiv:2205.08926v1 [cs.AI])
54. Imagining new futures beyond predictive systems in child welfare: A qualitative study with impacted stakeholders. (arXiv:2205.08928v1 [cs.HC])
55. Deep Features for CBIR with Scarce Data using Hebbian Learning. (arXiv:2205.08935v1 [cs.CV])
56. SoK: The Impact of Unlabelled Data in Cyberthreat Detection. (arXiv:2205.08944v1 [cs.CR])
57. Representation Learning for Content-Sensitive Anomaly Detection in Industrial Networks. (arXiv:2205.08953v1 [cs.LG])
58. One-way Explainability Isn't The Message. (arXiv:2205.08954v1 [cs.LG])
59. Structural Extensions of Basis Pursuit: Guarantees on Adversarial Robustness. (arXiv:2205.08955v1 [cs.LG])
60. Meta-Learning Sparse Compression Networks. (arXiv:2205.08957v1 [stat.ML])
61. DL4DS -- Deep Learning for empirical DownScaling. (arXiv:2205.08967v1 [cs.LG])
62. One Explanation to Rule them All -- Ensemble Consistent Explanations. (arXiv:2205.08974v1 [cs.AI])
63. Fast Neural Network based Solving of Partial Differential Equations. (arXiv:2205.08978v1 [cs.LG])
64. Constraining the Attack Space of Machine Learning Models with Distribution Clamping Preprocessing. (arXiv:2205.08989v1 [cs.LG])
65. A weakly supervised framework for high-resolution crop yield forecasts. (arXiv:2205.09016v1 [cs.LG])
66. Exploring the Advantages of Dense-Vector to One-Hot Encoding of Intent Classes in Out-of-Scope Detection Tasks. (arXiv:2205.09021v1 [cs.LG])
67. Learning latent representations for operational nitrogen response rate prediction. (arXiv:2205.09025v1 [cs.LG])
68. Maslow's Hammer for Catastrophic Forgetting: Node Re-Use vs Node Activation. (arXiv:2205.09029v1 [stat.ML])
69. Learning Shared Kernel Models: the Shared Kernel EM algorithm. (arXiv:2205.09041v1 [cs.LG])
70. POViT: Vision Transformer for Multi-objective Design and Characterization of Nanophotonic Devices. (arXiv:2205.09045v1 [cs.LG])
71. Position Aided Beam Prediction in the Real World: How Useful GPS Locations Actually Are?. (arXiv:2205.09054v1 [eess.SP])
72. Slowly Changing Adversarial Bandit Algorithms are Provably Efficient for Discounted MDPs. (arXiv:2205.09056v1 [cs.LG])
73. Unsupervised Features Ranking via Coalitional Game Theory for Categorical Data. (arXiv:2205.09060v1 [cs.LG])
74. Multilayer Perceptron Based Stress Evolution Analysis under DC Current Stressing for Multi-segment Wires. (arXiv:2205.09065v1 [cs.LG])
75. Exact Gaussian Processes for Massive Datasets via Non-Stationary Sparsity-Discovering Kernels. (arXiv:2205.09070v1 [stat.ML])
76. On the Effective Number of Linear Regions in Shallow Univariate ReLU Networks: Convergence Guarantees and Implicit Bias. (arXiv:2205.09072v1 [cs.LG])
77. Predicting failure characteristics of structural materials via deep learning based on nondestructive void topology. (arXiv:2205.09075v1 [cond-mat.mtrl-sci])
78. Pluralistic Image Completion with Probabilistic Mixture-of-Experts. (arXiv:2205.09086v1 [cs.CV])
79. Conformalized Online Learning: Online Calibration Without a Holdout Set. (arXiv:2205.09095v1 [cs.LG])
80. Single-Shot Optical Neural Network. (arXiv:2205.09103v1 [cs.ET])
81. Leveraging Global Binary Masks for Structure Segmentation in Medical Images. (arXiv:2205.09107v1 [eess.IV])
82. Masked Autoencoders As Spatiotemporal Learners. (arXiv:2205.09113v1 [cs.CV])
83. Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement. (arXiv:1810.09103v3 [cs.LG] UPDATED)
84. A simple yet effective baseline for non-attributed graph classification. (arXiv:1811.03508v3 [cs.LG] UPDATED)
85. On the Efficiency of Entropic Regularized Algorithms for Optimal Transport. (arXiv:1906.01437v9 [cs.DS] UPDATED)
86. Learning Selective Sensor Fusion for States Estimation. (arXiv:1912.13077v2 [cs.CV] UPDATED)
87. SoQal: Selective Oracle Questioning for Consistency Based Active Learning of Cardiac Signals. (arXiv:2004.09557v3 [cs.LG] UPDATED)
88. Dynamic Predictions of Postoperative Complications from Explainable, Uncertainty-Aware, and Multi-Task Deep Neural Networks. (arXiv:2004.12551v2 [cs.LG] UPDATED)
89. Increasing-Margin Adversarial (IMA) Training to Improve Adversarial Robustness of Neural Networks. (arXiv:2005.09147v8 [cs.CV] UPDATED)
90. A Unified Linear Speedup Analysis of Stochastic FedAvg and Nesterov Accelerated FedAvg. (arXiv:2007.05690v3 [cs.LG] UPDATED)
91. Moderately Supervised Learning: Definition, Framework and Generality. (arXiv:2008.11945v3 [cs.CV] UPDATED)
92. Medical Deep Learning -- A systematic Meta-Review. (arXiv:2010.14881v5 [eess.IV] UPDATED)
93. Enhancing the Transformer Decoder with Transition-based Syntax. (arXiv:2101.12640v3 [cs.CL] UPDATED)
94. CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation. (arXiv:2103.06874v4 [cs.CL] UPDATED)
95. Detecting micro fractures: A comprehensive comparison of conventional and machine-learning based segmentation methods. (arXiv:2103.12821v2 [cs.LG] UPDATED)
96. SimCSE: Simple Contrastive Learning of Sentence Embeddings. (arXiv:2104.08821v4 [cs.CL] UPDATED)
97. PocketNet: A Smaller Neural Network for Medical Image Analysis. (arXiv:2104.10745v3 [eess.IV] UPDATED)
98. Efficient PAC Reinforcement Learning in Regular Decision Processes. (arXiv:2105.06784v3 [cs.AI] UPDATED)
99. A Central Limit Theorem, Loss Aversion and Multi-Armed Bandits. (arXiv:2106.05472v2 [math.PR] UPDATED)
100. FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning. (arXiv:2107.04271v5 [cs.DC] UPDATED)
101. Translatotron 2: High-quality direct speech-to-speech translation with voice preservation. (arXiv:2107.08661v5 [cs.CL] UPDATED)
102. Finite-Bit Quantization For Distributed Algorithms With Linear Convergence. (arXiv:2107.11304v3 [math.OC] UPDATED)
103. Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v2 [eess.IV] UPDATED)
104. Physics-informed Guided Disentanglement in Generative Networks. (arXiv:2107.14229v2 [cs.CV] UPDATED)
105. Cohort Bias Adaptation in Aggregated Datasets for Lesion Segmentation. (arXiv:2108.00713v2 [eess.IV] UPDATED)
106. Phy-Q: A Testbed for Physical Reasoning. (arXiv:2108.13696v2 [cs.AI] UPDATED)
107. Link Scheduling using Graph Neural Networks. (arXiv:2109.05536v2 [eess.SP] UPDATED)
108. Assisted Learning for Organizations with Limited Data. (arXiv:2109.09307v3 [cs.LG] UPDATED)
109. ACReL: Adversarial Conditional value-at-risk Reinforcement Learning. (arXiv:2109.09470v2 [cs.LG] UPDATED)
110. Molformer: Motif-based Transformer on 3D Heterogeneous Molecular Graphs. (arXiv:2110.01191v5 [q-bio.QM] UPDATED)
111. SOUL: An Energy-Efficient Unsupervised Online Learning Seizure Detection Classifier. (arXiv:2110.02169v2 [eess.SP] UPDATED)
112. HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism. (arXiv:2110.07246v2 [cs.MA] UPDATED)
113. A Scalable AutoML Approach Based on Graph Neural Networks. (arXiv:2111.00083v3 [cs.LG] UPDATED)
114. FastCover: An Unsupervised Learning Framework for Multi-Hop Influence Maximization in Social Networks. (arXiv:2111.00463v2 [cs.SI] UPDATED)
115. Linear Speedup in Personalized Collaborative Learning. (arXiv:2111.05968v3 [cs.LG] UPDATED)
116. A label efficient two-sample test. (arXiv:2111.08861v3 [cs.LG] UPDATED)
117. Variational autoencoders in the presence of low-dimensional data: landscape and implicit bias. (arXiv:2112.06868v2 [cs.LG] UPDATED)
118. Detecting Model Misspecification in Amortized Bayesian Inference with Neural Networks. (arXiv:2112.08866v3 [stat.ME] UPDATED)
119. Model-based Clustering with Missing Not At Random Data. (arXiv:2112.10425v2 [stat.ML] UPDATED)
120. Testing the Robustness of a BiLSTM-based Structural Story Classifier. (arXiv:2201.02733v2 [cs.CL] UPDATED)
121. SLISEMAP: Supervised dimensionality reduction through local explanations. (arXiv:2201.04455v2 [cs.LG] UPDATED)
122. GPU-accelerated partially linear multiuser detection for 5G and beyond URLLC systems. (arXiv:2201.05024v3 [eess.SP] UPDATED)
123. Bayesian Inference with Nonlinear Generative Models: Comments on Secure Learning. (arXiv:2201.09986v2 [cs.IT] UPDATED)
124. You Only Cut Once: Boosting Data Augmentation with a Single Cut. (arXiv:2201.12078v2 [cs.CV] UPDATED)
125. Describing Differences between Text Distributions with Natural Language. (arXiv:2201.12323v2 [cs.CL] UPDATED)
126. GSN: A Graph Neural Network Inspired by Spring Network. (arXiv:2201.12994v3 [cs.LG] UPDATED)
127. Approximation of Images via Generalized Higher Order Singular Value Decomposition over Finite-dimensional Commutative Semisimple Algebra. (arXiv:2202.00450v6 [cs.LG] UPDATED)
128. Preserving Privacy and Security in Federated Learning. (arXiv:2202.03402v2 [cs.LG] UPDATED)
129. PFGE: Parsimonious Fast Geometric Ensembling of DNNs. (arXiv:2202.06658v5 [cs.LG] UPDATED)
130. Exploring Deep Reinforcement Learning-Assisted Federated Learning for Online Resource Allocation in Privacy-Persevering EdgeIoT. (arXiv:2202.07391v2 [cs.LG] UPDATED)
131. Probing Pretrained Models of Source Code. (arXiv:2202.08975v2 [cs.SE] UPDATED)
132. Computing Multiple Image Reconstructions with a Single Hypernetwork. (arXiv:2202.11009v4 [cs.CV] UPDATED)
133. Finite-Sum Coupled Compositional Stochastic Optimization: Theory and Applications. (arXiv:2202.12396v3 [math.OC] UPDATED)
134. Ranking of Communities in Multiplex Spatiotemporal Models of Brain Dynamics. (arXiv:2203.09281v2 [q-bio.NC] UPDATED)
135. Doubly Robust Collaborative Targeted Learning for Debiased Recommendations. (arXiv:2203.10258v2 [cs.IR] UPDATED)
136. MonoTrack: Shuttle trajectory reconstruction from monocular badminton video. (arXiv:2204.01899v2 [cs.CV] UPDATED)
137. Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v2 [cs.CE] UPDATED)
138. Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning. (arXiv:2204.09418v2 [cs.MA] UPDATED)
139. Noise mitigation strategies in physical feedforward neural networks. (arXiv:2204.09461v2 [cs.NE] UPDATED)
140. Learning to Parallelize in a Shared-Memory Environment with Transformers. (arXiv:2204.12835v2 [cs.DC] UPDATED)
141. Markov Abstractions for PAC Reinforcement Learning in Non-Markov Decision Processes. (arXiv:2205.01053v2 [cs.LG] UPDATED)
142. Evaluating Transferability for Covid 3D Localization Using CT SARS-CoV-2 segmentation models. (arXiv:2205.02152v2 [eess.IV] UPDATED)
143. dPRO: A Generic Profiling and Optimization System for Expediting Distributed DNN Training. (arXiv:2205.02473v2 [cs.DC] UPDATED)
144. Perseus: A Simple High-Order Regularization Method for Variational Inequalities. (arXiv:2205.03202v2 [math.OC] UPDATED)
145. Stabilized Doubly Robust Learning for Recommendation on Data Missing Not at Random. (arXiv:2205.04701v2 [cs.LG] UPDATED)
146. Incident duration prediction using a bi-level machine learning framework with outlier removal and intra-extra joint optimisation. (arXiv:2205.05197v2 [cs.LG] UPDATED)
147. Analyzing Hate Speech Data along Racial, Gender and Intersectional Axes. (arXiv:2205.06621v2 [cs.CL] UPDATED)
148. Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v2 [cs.LG] UPDATED)
149. Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review. (arXiv:2205.07855v2 [cs.LG] UPDATED)
150. Shape complexity in cluster analysis. (arXiv:2205.08046v2 [cs.LG] UPDATED)
151. "What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v2 [cs.CL] UPDATED)
152. Sharp asymptotics on the compression of two-layer neural networks. (arXiv:2205.08199v2 [cs.IT] UPDATED)
153. A Comparative Analysis of Machine Learning Techniques for IoT Intrusion Detection. (arXiv:2111.13149v2 [cs.CR] CROSS LISTED)
154. Practical Insights of Repairing Model Problems on Image Classification. (arXiv:2205.07116v1 [cs.LG] CROSS LISTED)
155. **Real-time** semantic segmentation on FPGAs for autonomous vehicles with hls4ml. (arXiv:2205.07690v1 [cs.CV] CROSS LISTED)
## cs.AI
---
**56** new papers in cs.AI:-) 
1. Learning Quantum Entanglement Distillation with Noisy Classical Communications. (arXiv:2205.08561v1 [quant-ph])
2. CV4Code: Sourcecode Understanding via Visual Code Representations. (arXiv:2205.08585v1 [cs.SE])
3. Hierarchical Distribution-Aware Testing of Deep Learning. (arXiv:2205.08589v1 [cs.SE])
4. OneAligner: Zero-shot Cross-lingual Transfer with One Rich-Resource Language Pair for Low-Resource Sentence Retrieval. (arXiv:2205.08605v1 [cs.CL])
5. Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation. (arXiv:2205.08621v1 [cs.CL])
6. Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks. (arXiv:2205.08625v1 [cs.CL])
7. DPO: Dynamic-Programming Optimization on Hybrid Constraints. (arXiv:2205.08632v1 [cs.LO])
8. Need is All You Need: Homeostatic Neural Networks Adapt to Concept Shift. (arXiv:2205.08645v1 [cs.LG])
9. Intuitive and Efficient Human-robot Collaboration via **Real-time** Approximate Bayesian Inference. (arXiv:2205.08657v1 [cs.RO])
10. Addressing Resource and Privacy Constraints in Semantic Parsing Through Data Augmentation. (arXiv:2205.08675v1 [cs.CL])
11. A Pulse-and-Glide-driven Adaptive Cruise Control System for Electric Vehicle. (arXiv:2205.08682v1 [cs.RO])
12. Terrain Analysis in StarCraft 1 and 2 as Combinatorial Optimization. (arXiv:2205.08683v1 [cs.AI])
13. Policy Distillation with Selective Input Gradient Regularization for Efficient Interpretability. (arXiv:2205.08685v1 [cs.LG])
14. Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting. (arXiv:2205.08689v1 [cs.LG])
15. The Solvability of Interpretability Evaluation Metrics. (arXiv:2205.08696v1 [cs.LG])
16. Optimal Adaptive Prediction Intervals for Electricity Load Forecasting in Distribution Systems via Reinforcement Learning. (arXiv:2205.08698v1 [stat.AP])
17. It Isn't Sh!tposting, It's My CAT Posting. (arXiv:2205.08710v1 [cs.CV])
18. $(O,G)$-granular variable precision fuzzy rough sets based on overlap and grouping functions. (arXiv:2205.08719v1 [cs.AI])
19. A reproducible experimental survey on biomedical sentence similarity: a string-based method sets the state of the art. (arXiv:2205.08740v1 [cs.CL])
20. Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification. (arXiv:2205.08772v1 [cs.CL])
21. Entity Alignment For Knowledge Graphs: Progress, Challenges, and Empirical Studies. (arXiv:2205.08777v1 [cs.AI])
22. Deep Reinforcement Learning Based on Location-Aware Imitation Environment for RIS-Aided mmWave MIMO Systems. (arXiv:2205.08788v1 [eess.SP])
23. Entity Alignment with Reliable Path Reasoning and Relation-Aware Heterogeneous Graph Transformer. (arXiv:2205.08806v1 [cs.CL])
24. Large Neural Networks Learning from Scratch with Very Few Data and without Regularization. (arXiv:2205.08836v1 [cs.CV])
25. GPoeT-2: A GPT-2 Based Poem Generator. (arXiv:2205.08847v1 [cs.CL])
26. Bridging the gap between QP-based and MPC-based RL. (arXiv:2205.08856v1 [eess.SY])
27. GeoPointGAN: Synthetic Spatial Data with Local Label Differential Privacy. (arXiv:2205.08886v1 [cs.LG])
28. Generating Explanations from Deep Reinforcement Learning Using Episodic Memory. (arXiv:2205.08926v1 [cs.AI])
29. Meta-Learning Sparse Compression Networks. (arXiv:2205.08957v1 [stat.ML])
30. One Explanation to Rule them All -- Ensemble Consistent Explanations. (arXiv:2205.08974v1 [cs.AI])
31. Confidential Machine Learning within Graphcore IPUs. (arXiv:2205.09005v1 [cs.CR])
32. Exploring the Advantages of Dense-Vector to One-Hot Encoding of Intent Classes in Out-of-Scope Detection Tasks. (arXiv:2205.09021v1 [cs.LG])
33. Dialog Inpainting: Turning Documents into Dialogs. (arXiv:2205.09073v1 [cs.CL])
34. Leveraging Global Binary Masks for Structure Segmentation in Medical Images. (arXiv:2205.09107v1 [eess.IV])
35. Greedy Actor-Critic: A New Conditional Cross-Entropy Method for Policy Improvement. (arXiv:1810.09103v3 [cs.LG] UPDATED)
36. Efficient PAC Reinforcement Learning in Regular Decision Processes. (arXiv:2105.06784v3 [cs.AI] UPDATED)
37. Physics-informed Guided Disentanglement in Generative Networks. (arXiv:2107.14229v2 [cs.CV] UPDATED)
38. Phy-Q: A Testbed for Physical Reasoning. (arXiv:2108.13696v2 [cs.AI] UPDATED)
39. Evolving Decomposed Plasticity Rules for Information-Bottlenecked Meta-Learning. (arXiv:2109.03554v5 [cs.AI] UPDATED)
40. HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism. (arXiv:2110.07246v2 [cs.MA] UPDATED)
41. Making Document-Level Information Extraction Right for the Right Reasons. (arXiv:2110.07686v2 [cs.CL] UPDATED)
42. Towards Integrative Multi-Modal Personal Health Navigation Systems: Framework and Application. (arXiv:2111.10403v2 [cs.AI] UPDATED)
43. SLISEMAP: Supervised dimensionality reduction through local explanations. (arXiv:2201.04455v2 [cs.LG] UPDATED)
44. Describing Differences between Text Distributions with Natural Language. (arXiv:2201.12323v2 [cs.CL] UPDATED)
45. PFGE: Parsimonious Fast Geometric Ensembling of DNNs. (arXiv:2202.06658v5 [cs.LG] UPDATED)
46. Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v2 [cs.CE] UPDATED)
47. Trigger-GNN: A Trigger-Based Graph Neural Network for Nested Named Entity Recognition. (arXiv:2204.05518v2 [cs.CL] UPDATED)
48. Mingling Foresight with Imagination: Model-Based Cooperative Multi-Agent Reinforcement Learning. (arXiv:2204.09418v2 [cs.MA] UPDATED)
49. Markov Abstractions for PAC Reinforcement Learning in Non-Markov Decision Processes. (arXiv:2205.01053v2 [cs.LG] UPDATED)
50. A Self-aware Personal Assistant for Making Personalized Privacy Decisions. (arXiv:2205.06544v2 [cs.AI] UPDATED)
51. Analyzing Hate Speech Data along Racial, Gender and Intersectional Axes. (arXiv:2205.06621v2 [cs.CL] UPDATED)
52. Incorporating Prior Knowledge into Neural Networks through an Implicit Composite Kernel. (arXiv:2205.07384v2 [cs.LG] UPDATED)
53. Decentral and Incentivized Federated Learning Frameworks: A Systematic Literature Review. (arXiv:2205.07855v2 [cs.LG] UPDATED)
54. Shape complexity in cluster analysis. (arXiv:2205.08046v2 [cs.LG] UPDATED)
55. "What makes a question inquisitive?" A Study on Type-Controlled Inquisitive Question Generation. (arXiv:2205.08056v2 [cs.CL] UPDATED)
56. A Comparative Analysis of Machine Learning Techniques for IoT Intrusion Detection. (arXiv:2111.13149v2 [cs.CR] CROSS LISTED)

