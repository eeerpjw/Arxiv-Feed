# Your interest papers
---
## cs.CV
---
### BP-Triplet Net for Unsupervised Domain Adaptation: A Bayesian Perspective. (arXiv:2202.09541v1 [cs.CV])
- Authors : Shanshan Wang, **Lei Zhang**, Pichao Wang
- Link : [http://arxiv.org/abs/2202.09541](http://arxiv.org/abs/2202.09541)
> ABSTRACT  :  Triplet loss, one of the deep metric learning (DML) methods, is to learn the embeddings where examples from the same class are closer than examples from different classes. Motivated by DML, we propose an effective BP-Triplet Loss for unsupervised domain adaption (UDA) from the perspective of Bayesian learning and we name the model as BP-Triplet Net. In previous metric learning based methods for UDA, sample pairs across domains are treated equally, which is not appropriate due to the domain bias. In our work, considering the different importance of pair-wise samples for both feature learning and domain alignment, we deduce our BP-Triplet loss for effective UDA from the perspective of Bayesian learning. Our BP-Triplet loss adjusts the weights of pair-wise samples in intra domain and inter domain. Especially, it can self attend to the hard pairs (including hard positive pair and hard negative pair). Together with the commonly used adversarial loss for domain alignment, the quality of target pseudo labels is progressively improved. Our method achieved low joint error of the ideal source and target hypothesis. The expected target error can then be upper bounded following Ben-David s theorem. Comprehensive evaluations on five benchmark datasets, handwritten digits, Office31, ImageCLEF-DA, Office-Home and VisDA-2017 demonstrate the effectiveness of the proposed approach for UDA.  
### Going Deeper into Recognizing Actions in **Dark** Environments: A Comprehensive Benchmark Study. (arXiv:2202.09545v1 [cs.CV])
- Authors : Yuecong Xu, Jianfei Yang, Haozhi Cao, Jianxiong Yin, Zhenghua Chen, Xiaoli Li, Zhengguo Li, Qianwen Xu
- Link : [http://arxiv.org/abs/2202.09545](http://arxiv.org/abs/2202.09545)
> ABSTRACT  :  While action recognition (AR) has gained large improvements with the introduction of large-scale video datasets and the development of deep neural networks, AR models robust to challenging environments in real-world scenarios are still under-explored. We focus on the task of action recognition in **dark** environments, which can be applied to fields such as surveillance and autonomous driving at **night**. Intuitively, current deep networks along with visual **enhancement** techniques should be able to handle AR in **dark** environments, however, it is observed that this is not always the case in practice. To dive deeper into exploring solutions for AR in **dark** environments, we launched the UG2+ Challenge Track 2 (UG2-2) in IEEE CVPR 2021, with a goal of evaluating and advancing the robustness of AR models in **dark** environments. The challenge builds and expands on top of a novel ARID dataset, the first dataset for the task of **dark** video AR, and guides models to tackle such a task in both fully and semi-supervised manners. Baseline results utilizing current AR models and **enhancement** methods are reported, justifying the challenging nature of this task with substantial room for improvements. Thanks to the active participation from the research community, notable advances have been made in participants' solutions, while analysis of these solutions helped better identify possible directions to tackle the challenge of AR in **dark** environments.  
### Punctuation **Restoration**. (arXiv:2202.09695v1 [cs.CL])
- Authors : Viet Dac, Amir Pouran, Ben Veyseh, Franck Dernoncourt, Thien Huu
- Link : [http://arxiv.org/abs/2202.09695](http://arxiv.org/abs/2202.09695)
> ABSTRACT  :  Given the increasing number of livestreaming videos, automatic speech recognition and post-processing for livestreaming video transcripts are crucial for efficient data management as well as knowledge mining. A key step in this process is punctuation **restoration** which restores fundamental text structures such as phrase and sentence boundaries from the video transcripts. This work presents a new human-annotated corpus, called BehancePR, for punctuation **restoration** in livestreaming video transcripts. Our experiments on BehancePR demonstrate the challenges of punctuation **restoration** for this domain. Furthermore, we show that popular natural language processing toolkits are incapable of detecting sentence boundary on non-punctuated transcripts of livestreaming videos, calling for more research effort to develop robust models for this area.  
### The Loop Game: Quality Assessment and Optimization for Low-Light Image **Enhancement**. (arXiv:2202.09738v1 [eess.IV])
- Authors : Baoliang Chen, Lingyu Zhu, Hanwei Zhu, **Wenhan Yang**, Fangbo Lu, Shiqi Wang
- Link : [http://arxiv.org/abs/2202.09738](http://arxiv.org/abs/2202.09738)
> ABSTRACT  :  There is an increasing consensus that the design and optimization of **low light** image **enhancement** methods need to be fully driven by perceptual quality. With numerous approaches proposed to enhance **low-light** images, much less work has been dedicated to quality assessment and quality optimization of **low-light** **enhancement**. In this paper, to close the gap between **enhancement** and assessment, we propose a loop **enhancement** framework that produces a clear picture of how the **enhancement** of **low-light** images could be optimized towards better visual quality. In particular, we create a large-scale database for QUality assessment Of The Enhanced LOw-Light Image (QUOTE-LOL), which serves as the foundation in studying and developing objective quality assessment measures. The objective quality assessment measure plays a critical bridging role between visual quality and **enhancement** and is further incorporated in the optimization in learning the **enhancement** model towards perceptual optimally. Finally, we iteratively perform the **enhancement** and optimization tasks, enhancing the **low-light** images continuously. The superiority of the proposed scheme is validated based on various **low-light** scenes. The database as well as the code will be available.  
### Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
- Authors : Mingyuan Jiu, Nelly Pustelnik
- Link : [http://arxiv.org/abs/2202.09810](http://arxiv.org/abs/2202.09810)
> ABSTRACT  :  This work designs an image **restoration** deep network relying on unfolded Chambolle-Pock primal-dual iterations. Each layer of our network is built from Chambolle-Pock iterations when specified for minimizing a sum of a $\ell_2$-norm data-term and an analysis sparse prior. The parameters of our network are the step-sizes of the Chambolle-Pock scheme and the linear operator involved in sparsity-based penalization, including implicitly the regularization parameter. A backpropagation procedure is fully described. Preliminary experiments illustrate the good behavior of such a deep primal-dual network in the context of image **restoration** on BSD68 database.  
### VILENS: Visual, Inertial, Lidar, and Leg Odometry for All-Terrain Legged Robots. (arXiv:2107.07243v2 [cs.RO] UPDATED)
- Authors : David Wisth, Marco Camurri, Maurice Fallon
- Link : [http://arxiv.org/abs/2107.07243](http://arxiv.org/abs/2107.07243)
> ABSTRACT  :  We present VILENS (Visual Inertial Lidar Legged Navigation System), an odometry system for legged robots based on factor graphs. The key novelty is the tight fusion of four different sensor modalities to achieve reliable operation when the individual sensors would otherwise produce degenerate estimation. To minimize leg odometry drift, we extend the robot's state with a linear velocity bias term which is estimated online. This bias is observable because of the tight fusion of this preintegrated velocity factor with vision, lidar, and IMU factors. Extensive experimental validation on different ANYmal quadruped robots is presented, for a total duration of 2 h and 1.8 km traveled. The experiments involved dynamic locomotion over loose rocks, slopes, and mud which caused challenges like slippage and terrain deformation. Perceptual challenges included **dark** and dusty underground caverns, and open and feature-deprived areas. We show an average improvement of 62% translational and 51% rotational errors compared to a state-of-the-art loosely coupled approach. To demonstrate its robustness, VILENS was also integrated with a perceptive controller and a local path planner.  
### Vision Transformer with Deformable Attention. (arXiv:2201.00520v2 [cs.CV] UPDATED)
- Authors : Zhuofan Xia, Xuran Pan, Shiji Song, Li Erran, Gao Huang
- Link : [http://arxiv.org/abs/2201.00520](http://arxiv.org/abs/2201.00520)
> ABSTRACT  :  Transformers have recently shown superior performances on various vision tasks. The large, sometimes even global, receptive field endows Transformer models with higher representation power over their CNN counterparts. Nevertheless, simply enlarging receptive field also gives rise to several concerns. On the one hand, using dense attention e.g., in ViT, leads to excessive memory and computational cost, and features can be influenced by irrelevant parts which are beyond the region of interests. On the other hand, the sparse attention adopted in PVT or **Swin** Transformer is data agnostic and may limit the ability to model long range relations. To mitigate these issues, we propose a novel deformable self-attention module, where the positions of key and value pairs in self-attention are selected in a data-dependent way. This flexible scheme enables the self-attention module to focus on relevant regions and capture more informative features. On this basis, we present Deformable Attention Transformer, a general backbone model with deformable attention for both image classification and dense prediction tasks. Extensive experiments show that our models achieve consistently improved results on comprehensive benchmarks. Code is available at https://github.com/LeapLabTHU/DAT.  
### Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization. (arXiv:2201.13256v2 [math.OC] UPDATED)
- Authors : Samuel Hurault, Arthur Leclaire, Nicolas Papadakis
- Link : [http://arxiv.org/abs/2201.13256](http://arxiv.org/abs/2201.13256)
> ABSTRACT  :  Plug-and-Play (PnP) methods solve ill-posed inverse problems through iterative proximal algorithms by replacing a proximal operator by a denoising operation. When applied with deep neural network denoisers, these methods have shown state-of-the-art visual performance for image **restoration** problems. However, their theoretical convergence analysis is still incomplete. Most of the existing convergence results consider nonexpansive denoisers, which is non-realistic, or limit their analysis to strongly convex data-fidelity terms in the inverse problem to solve. Recently, it was proposed to train the denoiser as a gradient descent step on a functional parameterized by a deep neural network. Using such a denoiser guarantees the convergence of the PnP version of the Half-Quadratic-Splitting (PnP-HQS) iterative algorithm. In this paper, we show that this gradient denoiser can actually correspond to the proximal operator of another scalar function. Given this new result, we exploit the convergence theory of proximal algorithms in the nonconvex setting to obtain convergence results for PnP-PGD (Proximal Gradient Descent) and PnP-ADMM (Alternating Direction Method of Multipliers). When built on top of a smooth gradient denoiser, we show that PnP-PGD and PnP-ADMM are convergent and target stationary points of an explicit functional. These convergence results are confirmed with numerical experiments on deblurring, super-resolution and inpainting.  
## eess.IV
---
### Model-Based Reconstruction for Collimated Beam Ultrasound Systems. (arXiv:2202.09703v1 [eess.IV])
- Authors : Abdulrahman Alanazi, Singanallur Venkatakrishnan, Hector Santos, Gregery Buzzard, Charles Bouman
- Link : [http://arxiv.org/abs/2202.09703](http://arxiv.org/abs/2202.09703)
> ABSTRACT  :  Collimated beam ultrasound systems are a novel technology for imaging inside multi-layered structures such as geothermal wells. Such systems include a transmitter and multiple receivers to capture reflected signals. Common algorithms for ultrasound reconstruction use delay-and-sum (DAS) approaches; these have low computational complexity but produce inaccurate images in the presence of complex structures and specialized geometries such as collimated beams.    In this paper, we propose a multi-layer, ultrasonic, model-based iterative reconstruction algorithm designed for collimated beam systems. We introduce a physics-based forward model to accurately account for the propagation of a collimated ultrasonic beam in multi-layer media and describe an efficient implementation using binary search. We model direct arrival signals, detector noise, and a spatially varying image prior, then cast the reconstruction as a maximum a posteriori estimation problem. Using simulated and experimental data we obtain significantly fewer artifacts relative to DAS while running in near **real time** using commodity compute resources.  
### The Loop Game: Quality Assessment and Optimization for Low-Light Image **Enhancement**. (arXiv:2202.09738v1 [eess.IV])
- Authors : Baoliang Chen, Lingyu Zhu, Hanwei Zhu, **Wenhan Yang**, Fangbo Lu, Shiqi Wang
- Link : [http://arxiv.org/abs/2202.09738](http://arxiv.org/abs/2202.09738)
> ABSTRACT  :  There is an increasing consensus that the design and optimization of **low light** image **enhancement** methods need to be fully driven by perceptual quality. With numerous approaches proposed to enhance **low-light** images, much less work has been dedicated to quality assessment and quality optimization of **low-light** **enhancement**. In this paper, to close the gap between **enhancement** and assessment, we propose a loop **enhancement** framework that produces a clear picture of how the **enhancement** of **low-light** images could be optimized towards better visual quality. In particular, we create a large-scale database for QUality assessment Of The Enhanced LOw-Light Image (QUOTE-LOL), which serves as the foundation in studying and developing objective quality assessment measures. The objective quality assessment measure plays a critical bridging role between visual quality and **enhancement** and is further incorporated in the optimization in learning the **enhancement** model towards perceptual optimally. Finally, we iteratively perform the **enhancement** and optimization tasks, enhancing the **low-light** images continuously. The superiority of the proposed scheme is validated based on various **low-light** scenes. The database as well as the code will be available.  
### Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
- Authors : Mingyuan Jiu, Nelly Pustelnik
- Link : [http://arxiv.org/abs/2202.09810](http://arxiv.org/abs/2202.09810)
> ABSTRACT  :  This work designs an image **restoration** deep network relying on unfolded Chambolle-Pock primal-dual iterations. Each layer of our network is built from Chambolle-Pock iterations when specified for minimizing a sum of a $\ell_2$-norm data-term and an analysis sparse prior. The parameters of our network are the step-sizes of the Chambolle-Pock scheme and the linear operator involved in sparsity-based penalization, including implicitly the regularization parameter. A backpropagation procedure is fully described. Preliminary experiments illustrate the good behavior of such a deep primal-dual network in the context of image **restoration** on BSD68 database.  
### LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v1 [cs.CV])
- Authors : Yongjun Zhang, Siyuan Zou, Xinyi Liu, Xu Huang, Yi Wan, Yongxiang Yao
- Link : [http://arxiv.org/abs/2202.09953](http://arxiv.org/abs/2202.09953)
> ABSTRACT  :  The complementary fusion of light detection and ranging (LiDAR) data and image data is a promising but challenging task for generating high-precision and high-density point clouds. This study proposes an innovative LiDAR-guided stereo matching approach called LiDAR-guided stereo matching (LGSM), which considers the spatial consistency represented by continuous disparity or depth changes in the homogeneous region of an image. The LGSM first detects the homogeneous pixels of each LiDAR projection point based on their color or intensity similarity. Next, we propose a riverbed **enhancement** function to optimize the cost volume of the LiDAR projection points and their homogeneous pixels to improve the matching robustness. Our formulation expands the constraint scopes of sparse LiDAR projection points with the guidance of image information to optimize the cost volume of pixels as much as possible. We applied LGSM to semi-global matching and AD-Census on both simulated and real datasets. When the percentage of LiDAR points in the simulated datasets was 0.16%, the matching accuracy of our method achieved a subpixel level, while that of the original stereo matching algorithm was 3.4 pixels. The experimental results show that LGSM is suitable for indoor, street, aerial, and satellite image datasets and provides good transferability across semi-global matching and AD-Census. Furthermore, the qualitative and quantitative evaluations demonstrate that LGSM is superior to two state-of-the-art optimizing cost volume methods, especially in reducing mismatches in difficult matching areas and refining the boundaries of objects.  
### Fourier ptychography multi-parameter neural network with composite physical priori optimization. (arXiv:2202.10239v1 [physics.optics])
- Authors : Delong Yang, Shaohui Zhang, Chuanjian Zheng, Guocheng Zhou, Lei Cao, Yao Hu, Qun Hao
- Link : [http://arxiv.org/abs/2202.10239](http://arxiv.org/abs/2202.10239)
> ABSTRACT  :  Fourier ptychography microscopy(FP) is a recently developed computational imaging approach for microscopic super-resolution imaging. By turning on each light-emitting-diode (LED) located on different position on the LED array sequentially and acquiring the corresponding images that contain different spatial frequency components, high spatial resolution and quantitative phase imaging can be achieved in the case of large field-of-view. Nevertheless, FPM has high requirements for the system construction and data acquisition processes, such as precise LEDs position, accurate focusing and appropriate **exposure** time, which brings many limitations to its practical applications. In this paper, inspired by artificial neural network, we propose a Fourier ptychography multi-parameter neural network (FPMN) with composite physical prior optimization. A hybrid parameter determination strategy combining physical imaging model and data-driven network training is proposed to recover the multi layers of the network corresponding to different physical parameters, including sample complex function, system pupil function, defocus distance, LED array position deviation and illumination intensity fluctuation, etc. Among these parameters, LED array position deviation is recovered based on the features of brightfield to **dark**field transition low-resolution images while the others are recovered in the process of training of the neural network. The feasibility and effectiveness of FPMN are verified through simulations and actual experiments. Therefore FPMN can evidently reduce the requirement for practical applications of FPM.  
## cs.LG
---
### Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
- Authors : Mingyuan Jiu, Nelly Pustelnik
- Link : [http://arxiv.org/abs/2202.09810](http://arxiv.org/abs/2202.09810)
> ABSTRACT  :  This work designs an image **restoration** deep network relying on unfolded Chambolle-Pock primal-dual iterations. Each layer of our network is built from Chambolle-Pock iterations when specified for minimizing a sum of a $\ell_2$-norm data-term and an analysis sparse prior. The parameters of our network are the step-sizes of the Chambolle-Pock scheme and the linear operator involved in sparsity-based penalization, including implicitly the regularization parameter. A backpropagation procedure is fully described. Preliminary experiments illustrate the good behavior of such a deep primal-dual network in the context of image **restoration** on BSD68 database.  
### Benchmarking the Linear Algebra Awareness of TensorFlow and PyTorch. (arXiv:2202.09888v1 [cs.MS])
- Authors : Aravind Sankaran, Navid Akbari, Christos Psarras, Paolo Bientinesi
- Link : [http://arxiv.org/abs/2202.09888](http://arxiv.org/abs/2202.09888)
> ABSTRACT  :  Linear algebra operations, which are ubiquitous in machine learning, form major performance bottlenecks. The High-Performance Computing community invests significant effort in the development of architecture-specific optimized kernels, such as those provided by the BLAS and LAPACK libraries, to speed up linear algebra operations. However, end users are progressively less likely to go through the error prone and time-consuming process of directly using said kernels; instead, frameworks such as TensorFlow (TF) and PyTorch (PyT), which facilitate the development of machine learning applications, are becoming more and more popular. Although such frameworks link to BLAS and LAPACK, it is not clear whether or not they make use of linear algebra knowledge to speed up computations. For this reason, in this paper we develop benchmarks to investigate the linear algebra optimization capabilities of TF and PyT. Our analyses reveal that a number of linear algebra optimizations are still missing; for instance, reducing the number of scalar operations by applying the distributive law, and automatically identifying the optimal parenthesization of a matrix chain. In this work, we focus on linear algebra computations in TF and PyT; we both expose opportunities for performance **enhancement** to the benefit of the developers of the frameworks and provide end users with guidelines on how to achieve performance gains.  
### CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile Application. (arXiv:2008.09264v4 [eess.AS] UPDATED)
- Authors : Wen Chen, Hsuan Hung, Jin Li, Alexander Chao, Fu Kang, Hsin Lai, Chun Liu, Wei Fu, Siang Wang, Yu Tsao
- Link : [http://arxiv.org/abs/2008.09264](http://arxiv.org/abs/2008.09264)
> ABSTRACT  :  This study presents a deep learning-based speech signal-processing mobile application known as CITISEN. The CITISEN provides three functions: speech **enhancement** (SE), model adaptation (MA), and background noise conversion (BNC), allowing CITISEN to be used as a platform for utilizing and evaluating SE models and flexibly extend the models to address various noise environments and users. For SE, a pretrained SE model downloaded from the cloud server is used to effectively reduce noise components from instant or saved recordings provided by users. For encountering unseen noise or speaker environments, the MA function is applied to promote CITISEN. A few audio samples recording on a noisy environment are uploaded and used to adapt the pretrained SE model on the server. Finally, for BNC, CITISEN first removes the background noises through an SE model and then mixes the processed speech with new background noise. The novel BNC function can evaluate SE performance under specific conditions, cover people's tracks, and provide entertainment. The experimental results confirmed the effectiveness of SE, MA, and BNC functions. Compared with the noisy speech signals, the enhanced speech signals achieved about 6\% and 33\% of improvements, respectively, in terms of short-time objective intelligibility (STOI) and perceptual evaluation of speech quality (PESQ). With MA, the STOI and PESQ could be further improved by approximately 6\% and 11\%, respectively. Finally, the BNC experiment results indicated that the speech signals converted from noisy and silent backgrounds have a close scene identification accuracy and similar embeddings in an acoustic scene classification model. Therefore, the proposed BNC can effectively convert the background noise of a speech signal and be a data augmentation method when clean speech signals are unavailable.  
### DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v2 [physics.comp-ph] UPDATED)
- Authors : Lidong Fang, Pei Ge, **Lei Zhang**, Huan Lei
- Link : [http://arxiv.org/abs/2112.14798](http://arxiv.org/abs/2112.14798)
> ABSTRACT  :  A long-standing problem in the modeling of non-Newtonian hydrodynamics of polymeric flows is the availability of reliable and interpretable hydrodynamic models that faithfully encode the underlying micro-scale polymer dynamics. The main complication arises from the long polymer relaxation time, the complex molecular structure and heterogeneous interaction. DeePN$^2$, a deep learning-based non-Newtonian hydrodynamic model, has been proposed and has shown some success in systematically passing the micro-scale structural mechanics information to the macro-scale hydrodynamics for suspensions with simple polymer conformation and bond potential. The model retains a multi-scaled nature by mapping the polymer configurations into a set of symmetry-preserving macro-scale features. The extended constitutive laws for these macro-scale features can be directly learned from the kinetics of their micro-scale counterparts. In this paper, we develop DeePN$^2$ using more complex micro-structural models. We show that DeePN$^2$ can faithfully capture the broadly overlooked viscoelastic differences arising from the specific molecular structural mechanics without human intervention.  
### Latent Outlier **Exposure** for Anomaly Detection with Contaminated Data. (arXiv:2202.08088v2 [cs.LG] UPDATED)
- Authors : Chen Qiu, Aodong Li, Marius Kloft, Maja Rudolph, Stephan Mandt
- Link : [http://arxiv.org/abs/2202.08088](http://arxiv.org/abs/2202.08088)
> ABSTRACT  :  Anomaly detection aims at identifying data points that show systematic deviations from the majority of data in an unlabeled dataset. A common assumption is that clean training data (free of anomalies) is available, which is often violated in practice. We propose a strategy for training an anomaly detector in the presence of unlabeled anomalies that is compatible with a broad class of models. The idea is to jointly infer binary labels to each datum (normal vs. anomalous) while updating the model parameters. Inspired by outlier **exposure** (Hendrycks et al., 2018) that considers synthetically created, labeled anomalies, we thereby use a combination of two losses that share parameters: one for the normal and one for the anomalous data. We then iteratively proceed with block coordinate updates on the parameters and the most likely (latent) labels. Our experiments with several backbone models on three image datasets, 30 tabular data sets, and a video anomaly detection benchmark showed consistent and significant improvements over the baselines.  
## cs.AI
---
### Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer. (arXiv:2202.09574v1 [cs.RO])
- Authors : Heecheol Kim, Yoshiyuki Ohmura, Akihiko Nagakubo, Yasuo Kuniyoshi
- Link : [http://arxiv.org/abs/2202.09574](http://arxiv.org/abs/2202.09574)
> ABSTRACT  :  Deep imitation learning is a promising method for dexterous robot manipulation because it only requires demonstration samples for learning manipulation skills. In this paper, deep imitation learning is applied to tasks that require force feedback, such as bottle opening. However, simple visual feedback systems, such as teleoperation, cannot be applied because they do not provide force feedback to operators. **Bilateral** teleoperation has been used for demonstration with force feedback; however, this requires an expensive and complex **bilateral** robot system. In this paper, a new master-to-robot (M2R) transfer learning system is presented that does not require robots but can still teach dexterous force feedback-based manipulation tasks to robots. The human directly demonstrates a task using a low-cost controller that resembles the kinematic parameters of the robot arm. Using this controller, the operator can naturally feel the force feedback without any expensive **bilateral** system. Furthermore, the M2R transfer system can overcome domain gaps between the master and robot using the gaze-based imitation learning framework and a simple calibration method. To demonstrate this, the proposed system was evaluated on a bottle-cap-opening task that requires force feedback only for the master demonstration.  
### Safety **Enhancement** for Deep Reinforcement Learning in Autonomous Separation Assurance. (arXiv:2105.02331v3 [cs.AI] UPDATED)
- Authors : Wei Guo, Marc Brittain, Peng Wei
- Link : [http://arxiv.org/abs/2105.02331](http://arxiv.org/abs/2105.02331)
> ABSTRACT  :  The separation assurance task will be extremely challenging for air traffic controllers in a complex and high density airspace environment. Deep reinforcement learning (DRL) was used to develop an autonomous separation assurance framework in our previous work where the learned model advised speed maneuvers. In order to improve the safety of this model in unseen environments with uncertainties, in this work we propose a safety module for DRL in autonomous separation assurance applications. The proposed module directly addresses both model uncertainty and state uncertainty to improve safety. Our safety module consists of two sub-modules: (1) the state safety sub-module is based on the execution-time data augmentation method to introduce state disturbances in the model input state; (2) the model safety sub-module is a Monte-Carlo dropout extension that learns the posterior distribution of the DRL model policy. We demonstrate the effectiveness of the two sub-modules in an open-source air traffic simulator with challenging environment settings. Through extensive numerical experiments, our results show that the proposed sub-safety modules help the DRL agent significantly improve its safety performance in an autonomous separation assurance task.  
### Latent Outlier **Exposure** for Anomaly Detection with Contaminated Data. (arXiv:2202.08088v2 [cs.LG] UPDATED)
- Authors : Chen Qiu, Aodong Li, Marius Kloft, Maja Rudolph, Stephan Mandt
- Link : [http://arxiv.org/abs/2202.08088](http://arxiv.org/abs/2202.08088)
> ABSTRACT  :  Anomaly detection aims at identifying data points that show systematic deviations from the majority of data in an unlabeled dataset. A common assumption is that clean training data (free of anomalies) is available, which is often violated in practice. We propose a strategy for training an anomaly detector in the presence of unlabeled anomalies that is compatible with a broad class of models. The idea is to jointly infer binary labels to each datum (normal vs. anomalous) while updating the model parameters. Inspired by outlier **exposure** (Hendrycks et al., 2018) that considers synthetically created, labeled anomalies, we thereby use a combination of two losses that share parameters: one for the normal and one for the anomalous data. We then iteratively proceed with block coordinate updates on the parameters and the most likely (latent) labels. Our experiments with several backbone models on three image datasets, 30 tabular data sets, and a video anomaly detection benchmark showed consistent and significant improvements over the baselines.  
# Paper List
---
## cs.CV
---
**98** new papers in cs.CV:-) 
1. Snowflake Point Deconvolution for Point Cloud Completion and Generation with Skip-Transformer. (arXiv:2202.09367v1 [cs.CV])
2. A Molecular Prior Distribution for Bayesian Inference Based on Wilson Statistics. (arXiv:2202.09388v1 [q-bio.QM])
3. Learning Representations Robust to Group Shifts and Adversarial Examples. (arXiv:2202.09446v1 [cs.LG])
4. Modern Augmented Reality: Applications, Trends, and Future Directions. (arXiv:2202.09450v1 [cs.CV])
5. SAGE: SLAM with Appearance and Geometry Prior for Endoscopy. (arXiv:2202.09487v1 [cs.CV])
6. Highlighting Object Category Immunity for the Generalization of Human-Object Interaction Detection. (arXiv:2202.09492v1 [cs.CV])
7. PMP-Net++: Point Cloud Completion by Transformer-Enhanced Multi-step Point Moving Paths. (arXiv:2202.09507v1 [cs.CV])
8. SPNet: A novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss. (arXiv:2202.09515v1 [eess.IV])
9. C2N: Practical Generative Noise Modeling for Real-World Denoising. (arXiv:2202.09533v1 [cs.CV])
10. BP-Triplet Net for Unsupervised Domain Adaptation: A Bayesian Perspective. (arXiv:2202.09541v1 [cs.CV])
11. Going Deeper into Recognizing Actions in **Dark** Environments: A Comprehensive Benchmark Study. (arXiv:2202.09545v1 [cs.CV])
12. student dangerous behavior detection in school. (arXiv:2202.09550v1 [cs.CV])
13. Holistic Attention-Fusion Adversarial Network for Single Image Defogging. (arXiv:2202.09553v1 [cs.CV])
14. SODA: Site Object Detection dAtaset for Deep Learning in Construction. (arXiv:2202.09554v1 [cs.CV])
15. HDAM: Heuristic Difference Attention Module for Convolutional Neural Networks. (arXiv:2202.09556v1 [cs.CV])
16. Priming Cross-Session Motor Imagery Classification with A Universal Deep Domain Adaptation Framework. (arXiv:2202.09559v1 [cs.CV])
17. Bit-wise Training of Neural Network Weights. (arXiv:2202.09571v1 [cs.LG])
18. Diversity aware image generation. (arXiv:2202.09573v1 [cs.CV])
19. Tripartite: Tackle Noisy Labels by a More Precise Partition. (arXiv:2202.09579v1 [cs.CV])
20. Image-to-Graph Transformers for Chemical Structure Recognition. (arXiv:2202.09580v1 [cs.CV])
21. A Lightweight Dual-Domain Attention Framework for Sparse-View CT Reconstruction. (arXiv:2202.09609v1 [eess.IV])
22. An Unsupervised Attentive-Adversarial Learning Framework for Single Image Deraining. (arXiv:2202.09635v1 [cs.CV])
23. Echofilter: A Deep Learning Segmentation Model Improves the Automation, Standardization, and Timeliness for Post-Processing Echosounder Data in Tidal Energy Streams. (arXiv:2202.09648v1 [cs.LG])
24. Region-Based Semantic Factorization in GANs. (arXiv:2202.09649v1 [cs.CV])
25. MSSNet: Multi-Scale-Stage Network for Single Image Deblurring. (arXiv:2202.09652v1 [cs.CV])
26. Punctuation **Restoration**. (arXiv:2202.09695v1 [cs.CL])
27. MANet: Improving Video Denoising with a Multi-Alignment Network. (arXiv:2202.09704v1 [cs.CV])
28. Statistical and Topological Summaries Aid Disease Detection for Segmented Retinal Vascular Images. (arXiv:2202.09708v1 [q-bio.QM])
29. ARM3D: Attention-based relation module for indoor 3D object detection. (arXiv:2202.09715v1 [cs.CV])
30. Towards a Unified Approach to Homography Estimation Using Image Features and Pixel Intensities. (arXiv:2202.09716v1 [cs.CV])
31. 3DRM:Pair-wise relation module for 3D object detection. (arXiv:2202.09721v1 [cs.CV])
32. Overparametrization improves robustness against adversarial attacks: A replication study. (arXiv:2202.09735v1 [cs.LG])
33. The Loop Game: Quality Assessment and Optimization for Low-Light Image **Enhancement**. (arXiv:2202.09738v1 [eess.IV])
34. Visual Attention Network. (arXiv:2202.09741v1 [cs.CV])
35. RDP-Net: Region Detail Preserving Network for Change Detection. (arXiv:2202.09745v1 [eess.IV])
36. Dynamic Spatial Propagation Network for Depth Completion. (arXiv:2202.09769v1 [cs.CV])
37. Pseudo Numerical Methods for Diffusion Models on Manifolds. (arXiv:2202.09778v1 [cs.CV])
38. Clustering by the Probability Distributions from Extreme Value Theory. (arXiv:2202.09784v1 [cs.LG])
39. Image quality assessment by overlapping task-specific and task-agnostic measures: application to prostate multiparametric MR images for cancer segmentation. (arXiv:2202.09798v1 [eess.IV])
40. Distortion-Aware Loop Filtering of Intra 360^o Video Coding with Equirectangular Projection. (arXiv:2202.09802v1 [cs.CV])
41. Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
42. Sparsity Winning Twice: Better Robust Generaliztion from More Efficient Training. (arXiv:2202.09844v1 [cs.CV])
43. A Novel Framework for Brain Tumor Detection Based on Convolutional Variational Generative Models. (arXiv:2202.09850v1 [eess.IV])
44. Non-Deterministic Face Mask Removal Based On 3D Priors. (arXiv:2202.09856v1 [cs.CV])
45. SRL-SOA: Self-Representation Learning with Sparse 1D-Operational Autoencoder for Hyperspectral Image Band Selection. (arXiv:2202.09918v1 [cs.CV])
46. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v1 [cs.LG])
47. Imbalanced Malware Images Classification: a CNN based Approach. (arXiv:1708.08042v2 [cs.CV] UPDATED)
48. Pyramid Convolutional RNN for MRI Image Reconstruction. (arXiv:1912.00543v6 [eess.IV] UPDATED)
49. Towards Causality-Aware Inferring: A Sequential Discriminative Approach for Medical Diagnosis. (arXiv:2003.06534v4 [cs.CV] UPDATED)
50. Isotropic multichannel total variation framework for joint reconstruction of multicontrast parallel MRI. (arXiv:2006.04128v5 [eess.IV] UPDATED)
51. Post-hoc Calibration of Neural Networks by g-Layers. (arXiv:2006.12807v2 [cs.LG] UPDATED)
52. Spatio-Temporal EEG Representation Learning on Riemannian Manifold and Euclidean Space. (arXiv:2008.08633v2 [cs.CV] UPDATED)
53. Learning to Attack with Fewer Pixels: A Probabilistic Post-hoc Framework for Refining Arbitrary Dense Adversarial Attacks. (arXiv:2010.06131v2 [cs.CV] UPDATED)
54. Stochastic sparse adversarial attacks. (arXiv:2011.12423v4 [cs.LG] UPDATED)
55. Video Reenactment as Inductive Bias for Content-Motion Disentanglement. (arXiv:2102.00324v3 [cs.CV] UPDATED)
56. Child-Computer Interaction: Recent Works, New Dataset, and Age Detection. (arXiv:2102.01405v2 [cs.HC] UPDATED)
57. PURSUhInT: In Search of Informative Hint Points Based on Layer Clustering for Knowledge Distillation. (arXiv:2103.00053v2 [cs.LG] UPDATED)
58. Recent Advances on Neural Network Pruning at Initialization. (arXiv:2103.06460v2 [cs.LG] UPDATED)
59. Retrieve Fast, Rerank Smart: Cooperative and Joint Approaches for Improved Cross-Modal Retrieval. (arXiv:2103.11920v2 [cs.CV] UPDATED)
60. M6-UFC: Unifying Multi-Modal Controls for Conditional Image Synthesis via Non-Autoregressive Generative Transformers. (arXiv:2105.14211v4 [cs.CV] UPDATED)
61. Z2P: Instant Visualization of Point Clouds. (arXiv:2105.14548v2 [cs.GR] UPDATED)
62. The 2021 Image Similarity Dataset and Challenge. (arXiv:2106.09672v4 [cs.CV] UPDATED)
63. Deep Learning for Technical Document Classification. (arXiv:2106.14269v5 [cs.LG] UPDATED)
64. Application of artificial intelligence techniques for automated detection of myocardial infarction: A review. (arXiv:2107.06179v2 [eess.SP] UPDATED)
65. VILENS: Visual, Inertial, Lidar, and Leg Odometry for All-Terrain Legged Robots. (arXiv:2107.07243v2 [cs.RO] UPDATED)
66. GANmapper: geographical data translation. (arXiv:2108.04232v2 [cs.CV] UPDATED)
67. DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v4 [cs.LG] UPDATED)
68. Fair Representation: Guaranteeing Approximate Multiple Group Fairness for Unknown Tasks. (arXiv:2109.00545v2 [cs.LG] UPDATED)
69. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v2 [eess.IV] UPDATED)
70. Learning a Metacognition for Object Detection. (arXiv:2110.03105v2 [cs.AI] UPDATED)
71. Subspace Regularizers for Few-Shot Class Incremental Learning. (arXiv:2110.07059v2 [cs.CV] UPDATED)
72. Deep multi-modal aggregation network for MR image reconstruction with auxiliary modality. (arXiv:2110.08080v3 [eess.IV] UPDATED)
73. Uncertainty-Aware Lung Nodule Segmentation with Multiple Annotations. (arXiv:2110.12372v2 [eess.IV] UPDATED)
74. IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. (arXiv:2110.13214v3 [cs.CV] UPDATED)
75. RRNet: Relational Reasoning Network with Parallel Multi-scale Attention for Salient Object Detection in Optical Remote Sensing Images. (arXiv:2110.14223v2 [cs.CV] UPDATED)
76. Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts. (arXiv:2111.08276v2 [cs.CL] UPDATED)
77. Learning Modified Indicator Functions for Surface Reconstruction. (arXiv:2111.09526v2 [cs.CV] UPDATED)
78. Spatial-context-aware deep neural network for multi-class image classification. (arXiv:2111.12296v2 [cs.CV] UPDATED)
79. Human Pose Manipulation and Novel View Synthesis using Differentiable Rendering. (arXiv:2111.12731v2 [cs.CV] UPDATED)
80. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v3 [eess.IV] UPDATED)
81. PTTR: Relational 3D Point Cloud Object Tracking with Transformer. (arXiv:2112.02857v3 [cs.CV] UPDATED)
82. Annotation-efficient cancer detection with report-guided lesion annotation for deep learning-based prostate cancer detection in bpMRI. (arXiv:2112.05151v2 [eess.IV] UPDATED)
83. Homography Decomposition Networks for Planar Object Tracking. (arXiv:2112.07909v4 [cs.CV] UPDATED)
84. Vision Transformer with Deformable Attention. (arXiv:2201.00520v2 [cs.CV] UPDATED)
85. UniFormer: Unifying Convolution and Self-attention for Visual Recognition. (arXiv:2201.09450v2 [cs.CV] UPDATED)
86. Proximal denoiser for convergent plug-and-play optimization with nonconvex regularization. (arXiv:2201.13256v2 [math.OC] UPDATED)
87. A Coding Framework and Benchmark towards Compressed Video Understanding. (arXiv:2202.02813v2 [eess.IV] UPDATED)
88. Patch-Based Stochastic Attention for Image Editing. (arXiv:2202.03163v2 [cs.CV] UPDATED)
89. Self-Paced Imbalance Rectification for Class Incremental Learning. (arXiv:2202.03703v2 [cs.CV] UPDATED)
90. Face2PPG: An unsupervised pipeline for blood volume pulse extraction from faces. (arXiv:2202.04101v2 [cs.CV] UPDATED)
91. Motion Sickness Modeling with Visual Vertical Estimation and Its Application to Autonomous Personal Mobility Vehicles. (arXiv:2202.06299v2 [cs.HC] UPDATED)
92. A precortical module for robust CNNs to light variations. (arXiv:2202.07432v2 [cs.CV] UPDATED)
93. Continuously Learning to Detect People on the Fly: A Bio-inspired Visual System for Drones. (arXiv:2202.08023v2 [cs.CV] UPDATED)
94. When Did It Happen? Duration-informed Temporal Localization of Narrated Actions in Vlogs. (arXiv:2202.08138v2 [cs.CV] UPDATED)
95. Contextualize differential privacy in image database: a lightweight image differential privacy approach based on principle component analysis inverse. (arXiv:2202.08309v2 [cs.CR] UPDATED)
96. Colonoscopy polyp detection with massive endoscopic images. (arXiv:2202.08730v2 [cs.CV] UPDATED)
97. VLP: A Survey on Vision-Language Pre-training. (arXiv:2202.09061v2 [cs.CV] UPDATED)
98. Unsupervised Multiple-Object Tracking with a Dynamical Variational Autoencoder. (arXiv:2202.09315v2 [cs.LG] UPDATED)
## eess.IV
---
**36** new papers in eess.IV:-) 
1. Functional Optical Coherence Tomography for Intrinsic Signal Optoretinography: Recent Developments and Deployment Challenges. (arXiv:2202.09414v1 [physics.med-ph])
2. SPNet: A novel deep neural network for retinal vessel segmentation based on shared decoder and pyramid-like loss. (arXiv:2202.09515v1 [eess.IV])
3. C2N: Practical Generative Noise Modeling for Real-World Denoising. (arXiv:2202.09533v1 [cs.CV])
4. A Lightweight Dual-Domain Attention Framework for Sparse-View CT Reconstruction. (arXiv:2202.09609v1 [eess.IV])
5. An Unsupervised Attentive-Adversarial Learning Framework for Single Image Deraining. (arXiv:2202.09635v1 [cs.CV])
6. Model-Based Reconstruction for Collimated Beam Ultrasound Systems. (arXiv:2202.09703v1 [eess.IV])
7. The Loop Game: Quality Assessment and Optimization for Low-Light Image **Enhancement**. (arXiv:2202.09738v1 [eess.IV])
8. RDP-Net: Region Detail Preserving Network for Change Detection. (arXiv:2202.09745v1 [eess.IV])
9. Image quality assessment by overlapping task-specific and task-agnostic measures: application to prostate multiparametric MR images for cancer segmentation. (arXiv:2202.09798v1 [eess.IV])
10. Distortion-Aware Loop Filtering of Intra 360^o Video Coding with Equirectangular Projection. (arXiv:2202.09802v1 [cs.CV])
11. Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
12. A Novel Framework for Brain Tumor Detection Based on Convolutional Variational Generative Models. (arXiv:2202.09850v1 [eess.IV])
13. Deep learning-guided weighted averaging for signal dropout compensation in diffusion-weighted imaging of the liver. (arXiv:2202.09912v1 [eess.IV])
14. LiDAR-guided Stereo Matching with a Spatial Consistency Constraint. (arXiv:2202.09953v1 [cs.CV])
15. Deep Feature based Cross-slide Registration. (arXiv:2202.09971v1 [cs.CV])
16. Outlier-based Autism Detection using Longitudinal Structural MRI. (arXiv:2202.09988v1 [eess.IV])
17. Simplified Learning of CAD Features Leveraging a Deep Residual Autoencoder. (arXiv:2202.10099v1 [cs.CV])
18. OSegNet: Operational Segmentation Network for COVID-19 Detection using Chest X-ray Images. (arXiv:2202.10185v1 [eess.IV])
19. Fourier ptychography multi-parameter neural network with composite physical priori optimization. (arXiv:2202.10239v1 [physics.optics])
20. MIST GAN: Modality Imputation Using Style Transfer for MRI. (arXiv:2202.10396v1 [eess.IV])
21. Malaria detection in Segmented Blood Cell using Convolutional Neural Networks and Canny Edge Detection. (arXiv:2202.10426v1 [eess.IV])
22. Pyramid Convolutional RNN for MRI Image Reconstruction. (arXiv:1912.00543v6 [eess.IV] UPDATED)
23. BVI-CC: A Dataset for Research on Video Compression and Quality Assessment. (arXiv:2003.10282v2 [eess.IV] UPDATED)
24. Isotropic multichannel total variation framework for joint reconstruction of multicontrast parallel MRI. (arXiv:2006.04128v5 [eess.IV] UPDATED)
25. Image Response Regression via Deep Neural Networks. (arXiv:2006.09911v3 [stat.ML] UPDATED)
26. Generative Adversarial Networks for Robust Cryo-EM Image Denoising. (arXiv:2008.07307v4 [eess.IV] UPDATED)
27. Fully automated 3D segmentation of dopamine transporter SPECT images using an estimation-based approach. (arXiv:2101.06729v2 [physics.med-ph] UPDATED)
28. ReconResNet: Regularised Residual Learning for MR Image Reconstruction of Undersampled Cartesian and Radial Data. (arXiv:2103.09203v2 [eess.IV] UPDATED)
29. Region-of-Interest Prioritised Sampling for Constrained Autonomous Exploration Systems. (arXiv:2107.07186v2 [eess.IV] UPDATED)
30. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v2 [eess.IV] UPDATED)
31. Deep multi-modal aggregation network for MR image reconstruction with auxiliary modality. (arXiv:2110.08080v3 [eess.IV] UPDATED)
32. Uncertainty-Aware Lung Nodule Segmentation with Multiple Annotations. (arXiv:2110.12372v2 [eess.IV] UPDATED)
33. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v3 [eess.IV] UPDATED)
34. Annotation-efficient cancer detection with report-guided lesion annotation for deep learning-based prostate cancer detection in bpMRI. (arXiv:2112.05151v2 [eess.IV] UPDATED)
35. A Coding Framework and Benchmark towards Compressed Video Understanding. (arXiv:2202.02813v2 [eess.IV] UPDATED)
36. Contextualize differential privacy in image database: a lightweight image differential privacy approach based on principle component analysis inverse. (arXiv:2202.08309v2 [cs.CR] UPDATED)
## cs.LG
---
**229** new papers in cs.LG:-) 
1. Mixture-of-Experts with Expert Choice Routing. (arXiv:2202.09368v1 [cs.LG])
2. Explaining, Evaluating and Enhancing Neural Networks' Learned Representations. (arXiv:2202.09374v1 [cs.LG])
3. Black-box Node Injection Attack for Graph Neural Networks. (arXiv:2202.09389v1 [cs.LG])
4. Differentially Private Federated Learning via Inexact ADMM with Multiple Local Updates. (arXiv:2202.09409v1 [cs.LG])
5. Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games. (arXiv:2202.09422v1 [cs.MA])
6. Learning Representations Robust to Group Shifts and Adversarial Examples. (arXiv:2202.09446v1 [cs.LG])
7. Interactive Visual Pattern Search on Graph Data via Graph Representation Learning. (arXiv:2202.09459v1 [cs.LG])
8. Towards Enabling Dynamic Convolution Neural Network Inference for Edge Intelligence. (arXiv:2202.09461v1 [cs.LG])
9. Mixed Effects Neural ODE: A Variational Approximation for Analyzing the Dynamics of Panel Data. (arXiv:2202.09463v1 [cs.LG])
10. Attacks, Defenses, And Tools: A Framework To Facilitate Robust AI/ML Systems. (arXiv:2202.09465v1 [cs.CR])
11. Predictive Coding: Towards a Future of Deep Learning beyond Backpropagation?. (arXiv:2202.09467v1 [cs.NE])
12. Automated Attack Synthesis by Extracting Finite State Machines from Protocol Specification Documents. (arXiv:2202.09470v1 [cs.CR])
13. FedEmbed: Personalized Private Federated Learning. (arXiv:2202.09472v1 [cs.LG])
14. Graph Reparameterizations for Enabling 1000+ Monte Carlo Iterations in Bayesian Deep Neural Networks. (arXiv:2202.09478v1 [cs.LG])
15. Reciprocity in Machine Learning. (arXiv:2202.09480v1 [cs.LG])
16. TransDreamer: Reinforcement Learning with Transformer World Models. (arXiv:2202.09481v1 [cs.LG])
17. Missing Data Infill with Automunge. (arXiv:2202.09484v1 [cs.LG])
18. Suitability of Different Metric Choices for Concept Drift Detection. (arXiv:2202.09486v1 [cs.LG])
19. Shaping Advice in Deep Reinforcement Learning. (arXiv:2202.09489v1 [cs.MA])
20. Numeric Encoding Options with Automunge. (arXiv:2202.09496v1 [cs.LG])
21. Gradient Estimation with Discrete Stein Operators. (arXiv:2202.09497v1 [stat.ML])
22. Parsed Categoric Encodings with Automunge. (arXiv:2202.09498v1 [cs.LG])
23. From Quantum Graph Computing to Quantum Graph Learning: A Survey. (arXiv:2202.09506v1 [quant-ph])
24. Who Are the Best Adopters? User Selection Model for Free Trial Item Promotion. (arXiv:2202.09508v1 [cs.IR])
25. PETCI: A Parallel English Translation Dataset of Chinese Idioms. (arXiv:2202.09509v1 [cs.CL])
26. Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training. (arXiv:2202.09514v1 [cs.LG])
27. Learning a Shield from Catastrophic Action Effects: Never Repeat the Same Mistake. (arXiv:2202.09516v1 [cs.LG])
28. Deep Learning for Hate Speech Detection: A Comparative Study. (arXiv:2202.09517v1 [cs.CL])
29. Distributed Out-of-Memory NMF of Dense and Sparse Data on CPU/GPU Architectures with Automatic Model Selection for Exascale Data. (arXiv:2202.09518v1 [cs.DC])
30. The four-fifths rule is not disparate impact: a woeful tale of epistemic trespassing in algorithmic fairness. (arXiv:2202.09519v1 [cs.CY])
31. Improving the Level of Autism Discrimination through GraphRNN Link Prediction. (arXiv:2202.09538v1 [cs.LG])
32. Learning to Detect Slip with Barometric Tactile Sensors and a Temporal Convolutional Neural Network. (arXiv:2202.09549v1 [cs.RO])
33. Bit-wise Training of Neural Network Weights. (arXiv:2202.09571v1 [cs.LG])
34. Image-to-Graph Transformers for Chemical Structure Recognition. (arXiv:2202.09580v1 [cs.CV])
35. Polytopic Matrix Factorization: Determinant Maximization Based Criterion and Identifiability. (arXiv:2202.09638v1 [stat.ML])
36. Echofilter: A Deep Learning Segmentation Model Improves the Automation, Standardization, and Timeliness for Post-Processing Echosounder Data in Tidal Energy Streams. (arXiv:2202.09648v1 [cs.LG])
37. The Pareto Frontier of Instance-Dependent Guarantees in Multi-Player Multi-Armed Bandits with no Communication. (arXiv:2202.09653v1 [cs.LG])
38. Survey of Machine Learning Based Intrusion Detection Methods for Internet of Medical Things. (arXiv:2202.09657v1 [cs.CR])
39. Accurate Prediction and Uncertainty Estimation using Decoupled Prediction Interval Networks. (arXiv:2202.09664v1 [cs.LG])
40. Doubly Robust Distributionally Robust Off-Policy Evaluation and Learning. (arXiv:2202.09667v1 [cs.LG])
41. Truncated Diffusion Probabilistic Models. (arXiv:2202.09671v1 [stat.ML])
42. A Regularized Implicit Policy for Offline Reinforcement Learning. (arXiv:2202.09673v1 [stat.ML])
43. Generalized Optimistic Methods for Convex-Concave Saddle Point Problems. (arXiv:2202.09674v1 [math.OC])
44. A Variance-Reduced Stochastic Accelerated Primal Dual Algorithm. (arXiv:2202.09688v1 [math.OC])
45. Parallel Sampling for Efficient High-dimensional Bayesian Network Structure Learning. (arXiv:2202.09691v1 [cs.LG])
46. Selective Credit Assignment. (arXiv:2202.09699v1 [cs.LG])
47. A History of Meta-gradient: Gradient Methods for Meta-learning. (arXiv:2202.09701v1 [cs.LG])
48. Runtime-Assured, Real-Time Neural Control of Microgrids. (arXiv:2202.09710v1 [eess.SY])
49. Understanding Robust Generalization in Learning Regular Languages. (arXiv:2202.09717v1 [cs.LG])
50. Bayes-Optimal Classifiers under Group Fairness. (arXiv:2202.09724v1 [stat.ML])
51. It's Raw! Audio Generation with State-Space Models. (arXiv:2202.09729v1 [cs.SD])
52. Overparametrization improves robustness against adversarial attacks: A replication study. (arXiv:2202.09735v1 [cs.LG])
53. Enhancing Affective Representations of Music-Induced EEG through Multimodal Supervision and latent Domain Adaptation. (arXiv:2202.09750v1 [cs.SD])
54. Learning to Control Partially Observed Systems with Finite Memory. (arXiv:2202.09753v1 [cs.LG])
55. Dynamic and Efficient Gray-Box Hyperparameter Optimization for Deep Learning. (arXiv:2202.09774v1 [cs.LG])
56. An Analysis of Complex-Valued CNNs for RF Data-Driven Wireless Device Classification. (arXiv:2202.09777v1 [cs.LG])
57. Clustering by the Probability Distributions from Extreme Value Theory. (arXiv:2202.09784v1 [cs.LG])
58. Learning logic programs by discovering where not to search. (arXiv:2202.09806v1 [cs.LG])
59. Alternative design of DeepPDNet in the context of image **restoration**. (arXiv:2202.09810v1 [eess.IV])
60. $\mathcal{Y}$-Tuning: An Efficient Tuning Paradigm for Large-Scale Pre-Trained Models via Label Representation Learning. (arXiv:2202.09817v1 [cs.CL])
61. Efficient Continual Learning Ensembles in Neural Network Subspaces. (arXiv:2202.09826v1 [cs.LG])
62. Dissecting graph measure performance for node clustering in LFR parameter space. (arXiv:2202.09827v1 [cs.SI])
63. Sparsity Winning Twice: Better Robust Generaliztion from More Efficient Training. (arXiv:2202.09844v1 [cs.CV])
64. Personalized Federated Learning with Exact Stochastic Gradient Descent. (arXiv:2202.09848v1 [cs.LG])
65. A Novel Framework for Brain Tumor Detection Based on Convolutional Variational Generative Models. (arXiv:2202.09850v1 [eess.IV])
66. Cross-Task Knowledge Distillation in Multi-Task Recommendation. (arXiv:2202.09852v1 [cs.IR])
67. ChemTab: A Physics Guided Chemistry Modeling Framework. (arXiv:2202.09855v1 [cs.LG])
68. Interacting Contour Stochastic Gradient Langevin Dynamics. (arXiv:2202.09867v1 [stat.ML])
69. ExAIS: Executable AI Semantics. (arXiv:2202.09868v1 [cs.AI])
70. NetSentry: A Deep Learning Approach to Detecting Incipient Large-scale Network Attacks. (arXiv:2202.09873v1 [cs.CR])
71. Trying to Outrun Causality in Machine Learning: Limitations of Model Explainabilty Techniques for Identifying Predictive Variables. (arXiv:2202.09875v1 [stat.ML])
72. On Optimal Early Stopping: Over-informative versus Under-informative Parametrization. (arXiv:2202.09885v1 [cs.LG])
73. Benchmarking the Linear Algebra Awareness of TensorFlow and PyTorch. (arXiv:2202.09888v1 [cs.MS])
74. Memorize to Generalize: on the Necessity of Interpolation in High Dimensional Linear Regression. (arXiv:2202.09889v1 [stat.ML])
75. Equivariant Graph Attention Networks for Molecular Property Prediction. (arXiv:2202.09891v1 [cs.LG])
76. SOInter: A Novel Deep Energy Based Interpretation Method for Explaining Structured Output Models. (arXiv:2202.09914v1 [cs.LG])
77. SRL-SOA: Self-Representation Learning with Sparse 1D-Operational Autoencoder for Hyperspectral Image Band Selection. (arXiv:2202.09918v1 [cs.CV])
78. Generalized Bayesian Additive Regression Trees Models: Beyond Conditional Conjugacy. (arXiv:2202.09924v1 [stat.ML])
79. Disentangling Autoencoders (DAE). (arXiv:2202.09926v1 [cs.LG])
80. Mining Robust Default Configurations for Resource-constrained AutoML. (arXiv:2202.09927v1 [cs.LG])
81. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v1 [cs.LG])
82. Imbalanced Malware Images Classification: a CNN based Approach. (arXiv:1708.08042v2 [cs.CV] UPDATED)
83. Efficacy of regularized multi-task learning based on SVM models. (arXiv:1805.12507v2 [stat.ML] UPDATED)
84. On the Complexity of Approximating Multimarginal Optimal Transport. (arXiv:1910.00152v3 [stat.ML] UPDATED)
85. Pyramid Convolutional RNN for MRI Image Reconstruction. (arXiv:1912.00543v6 [eess.IV] UPDATED)
86. Explicit Group Sparse Projection with Applications to Deep Learning and NMF. (arXiv:1912.03896v3 [cs.LG] UPDATED)
87. Symplectic Neural Networks in Taylor Series Form for Hamiltonian Systems. (arXiv:2005.04986v4 [cs.LG] UPDATED)
88. Image Response Regression via Deep Neural Networks. (arXiv:2006.09911v3 [stat.ML] UPDATED)
89. Post-hoc Calibration of Neural Networks by g-Layers. (arXiv:2006.12807v2 [cs.LG] UPDATED)
90. Necessary and Sufficient Conditions for Inverse Reinforcement Learning of Bayesian Stopping Time Problems. (arXiv:2007.03481v4 [cs.LG] UPDATED)
91. Optimal Coreset for Gaussian Kernel Density Estimation. (arXiv:2007.08031v5 [cs.DS] UPDATED)
92. Spatio-Temporal EEG Representation Learning on Riemannian Manifold and Euclidean Space. (arXiv:2008.08633v2 [cs.CV] UPDATED)
93. CITISEN: A Deep Learning-Based Speech Signal-Processing Mobile Application. (arXiv:2008.09264v4 [eess.AS] UPDATED)
94. Learning to Attack with Fewer Pixels: A Probabilistic Post-hoc Framework for Refining Arbitrary Dense Adversarial Attacks. (arXiv:2010.06131v2 [cs.CV] UPDATED)
95. Nonseparable Symplectic Neural Networks. (arXiv:2010.12636v3 [cs.LG] UPDATED)
96. Adversarial Examples in Constrained Domains. (arXiv:2011.01183v2 [cs.CR] UPDATED)
97. Stochastic sparse adversarial attacks. (arXiv:2011.12423v4 [cs.LG] UPDATED)
98. Towards Scalable and Privacy-Preserving Deep Neural Network via Algorithmic-Cryptographic Co-design. (arXiv:2012.09364v2 [cs.LG] UPDATED)
99. Signal Processing on Higher-Order Networks: Livin' on the Edge ... and Beyond. (arXiv:2101.05510v4 [cs.SI] UPDATED)
100. Finite Sample Analysis of Two-Time-Scale Natural Actor-Critic Algorithm. (arXiv:2101.10506v2 [cs.LG] UPDATED)
101. Maximum n-times Coverage for Vaccine Design. (arXiv:2101.10902v4 [q-bio.QM] UPDATED)
102. Video Reenactment as Inductive Bias for Content-Motion Disentanglement. (arXiv:2102.00324v3 [cs.CV] UPDATED)
103. MultiRocket: Multiple pooling operators and transformations for fast and effective time series classification. (arXiv:2102.00457v4 [cs.LG] UPDATED)
104. MSPM: A Modularized and Scalable Multi-Agent Reinforcement Learning-based System for Financial Portfolio Management. (arXiv:2102.03502v4 [q-fin.PM] UPDATED)
105. Kronecker-factored Quasi-Newton Methods for Deep Learning. (arXiv:2102.06737v3 [cs.LG] UPDATED)
106. Domain Adaptation for Time Series Forecasting via Attention Sharing. (arXiv:2102.06828v6 [cs.LG] UPDATED)
107. Double-descent curves in neural networks: a new perspective using Gaussian processes. (arXiv:2102.07238v4 [stat.ML] UPDATED)
108. DiffCo: Auto-Differentiable Proxy Collision Detection with Multi-class Labels for Safety-Aware Trajectory Optimization. (arXiv:2102.07413v2 [cs.RO] UPDATED)
109. Adversarially Robust Kernel Smoothing. (arXiv:2102.08474v4 [cs.LG] UPDATED)
110. A Meta-embedding-based Ensemble Approach for ICD Coding Prediction. (arXiv:2102.13622v2 [cs.CL] UPDATED)
111. PURSUhInT: In Search of Informative Hint Points Based on Layer Clustering for Knowledge Distillation. (arXiv:2103.00053v2 [cs.LG] UPDATED)
112. Demystifying Batch Normalization in ReLU Networks: Equivalent Convex Optimization Models and Implicit Regularization. (arXiv:2103.01499v2 [cs.LG] UPDATED)
113. Natural Language Understanding for Argumentative Dialogue Systems in the Opinion Building Domain. (arXiv:2103.02691v2 [cs.CL] UPDATED)
114. Recent Advances on Neural Network Pruning at Initialization. (arXiv:2103.06460v2 [cs.LG] UPDATED)
115. Internal Wasserstein Distance for Adversarial Attack and Defense. (arXiv:2103.07598v2 [cs.LG] UPDATED)
116. ReconResNet: Regularised Residual Learning for MR Image Reconstruction of Undersampled Cartesian and Radial Data. (arXiv:2103.09203v2 [eess.IV] UPDATED)
117. Improving Attribution Methods by Learning Submodular Functions. (arXiv:2104.09073v3 [cs.LG] UPDATED)
118. AdaGNN: Graph Neural Networks with Adaptive Frequency Response Filter. (arXiv:2104.12840v3 [cs.LG] UPDATED)
119. Non-asymptotic analysis and inference for an outlyingness induced winsorized mean. (arXiv:2105.02337v2 [stat.ML] UPDATED)
120. Open-world Machine Learning: Applications, Challenges, and Opportunities. (arXiv:2105.13448v2 [cs.LG] UPDATED)
121. Z2P: Instant Visualization of Point Clouds. (arXiv:2105.14548v2 [cs.GR] UPDATED)
122. Opening the Black Box of Deep Neural Networks in Physical Layer Communication. (arXiv:2106.01124v3 [eess.SP] UPDATED)
123. Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits. (arXiv:2106.02575v4 [cs.LG] UPDATED)
124. Hermite Polynomial Features for Private Data Generation. (arXiv:2106.05042v3 [cs.LG] UPDATED)
125. PriorGrad: Improving Conditional Denoising Diffusion Models with Data-Dependent Adaptive Prior. (arXiv:2106.06406v2 [stat.ML] UPDATED)
126. Security Analysis of Camera-LiDAR Fusion Against Black-Box Attacks on Autonomous Vehicles. (arXiv:2106.07098v4 [cs.CR] UPDATED)
127. Zeroth-Order Methods for Convex-Concave Minmax Problems: Applications to Decision-Dependent Risk Minimization. (arXiv:2106.09082v2 [math.OC] UPDATED)
128. Routine Clustering of Mobile Sensor Data Facilitates Psychotic Relapse Prediction in Schizophrenia Patients. (arXiv:2106.11487v2 [cs.LG] UPDATED)
129. Provably efficient machine learning for quantum many-body problems. (arXiv:2106.12627v3 [quant-ph] UPDATED)
130. Limitations of machine learning for building energy prediction: ASHRAE Great Energy Predictor III Kaggle competition error analysis. (arXiv:2106.13475v3 [cs.LG] UPDATED)
131. Deep Learning for Technical Document Classification. (arXiv:2106.14269v5 [cs.LG] UPDATED)
132. Dual Optimization for Kolmogorov Model Learning Using Enhanced Gradient Descent. (arXiv:2107.05011v2 [cs.LG] UPDATED)
133. Strategic Instrumental Variable Regression: Recovering Causal Relationships From Strategic Responses. (arXiv:2107.05762v2 [cs.LG] UPDATED)
134. An Overview and Experimental Study of Learning-based Optimization Algorithms for Vehicle Routing Problem. (arXiv:2107.07076v2 [cs.LG] UPDATED)
135. Structured second-order methods via natural gradient descent. (arXiv:2107.10884v3 [stat.ML] UPDATED)
136. Pointer Value Retrieval: A new benchmark for understanding the limits of neural network generalization. (arXiv:2107.12580v2 [cs.LG] UPDATED)
137. Massive feature extraction for explaining and foretelling hydroclimatic time series forecastability at the global scale. (arXiv:2108.00846v2 [physics.ao-ph] UPDATED)
138. Mean-Field Multi-Agent Reinforcement Learning: A Decentralized Network Approach. (arXiv:2108.02731v2 [cs.LG] UPDATED)
139. Generalizing Dynamic Mode Decomposition: Balancing Accuracy and Expressiveness in Koopman Approximations. (arXiv:2108.03712v2 [eess.SY] UPDATED)
140. EDITS: Modeling and Mitigating Data Bias for Graph Neural Networks. (arXiv:2108.05233v2 [cs.LG] UPDATED)
141. Implicit Regularization of Bregman Proximal Point Algorithm and Mirror Descent on Separable Data. (arXiv:2108.06808v4 [cs.LG] UPDATED)
142. Towards Secure and Practical Machine Learning via Secret Sharing and Random Permutation. (arXiv:2108.07463v3 [cs.LG] UPDATED)
143. Quantization Backdoors to Deep Learning Commercial Frameworks. (arXiv:2108.09187v2 [cs.CR] UPDATED)
144. DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v4 [cs.LG] UPDATED)
145. Deep kernel machines: exact inference with representation learning in infinite Bayesian neural networks. (arXiv:2108.13097v3 [stat.ML] UPDATED)
146. Using a one dimensional parabolic model of the full-batch loss to estimate learning rates during training. (arXiv:2108.13880v2 [cs.LG] UPDATED)
147. Fair Representation: Guaranteeing Approximate Multiple Group Fairness for Unknown Tasks. (arXiv:2109.00545v2 [cs.LG] UPDATED)
148. Node Feature Kernels Increase Graph Convolutional Network Robustness. (arXiv:2109.01785v3 [cs.LG] UPDATED)
149. Urban Fire Station Location Planning using Predicted Demand and Service Quality Index. (arXiv:2109.02160v2 [cs.LG] UPDATED)
150. Sqrt(d) Dimension Dependence of Langevin Monte Carlo. (arXiv:2109.03839v3 [cs.LG] UPDATED)
151. Fair Conformal Predictors for Applications in Medical Imaging. (arXiv:2109.04392v2 [eess.IV] UPDATED)
152. On the Efficiency of Subclass Knowledge Distillation in Classification Tasks. (arXiv:2109.05587v2 [cs.LG] UPDATED)
153. CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting. (arXiv:2109.07438v2 [cs.LG] UPDATED)
154. Bad priors, their threats to Bayesian optimization and some remedies via prior learning. (arXiv:2109.08215v2 [cs.LG] UPDATED)
155. Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep Multi-Agent Reinforcement Learning for Collision Avoidance. (arXiv:2109.15266v2 [cs.RO] UPDATED)
156. SHARP: Shielding-Aware Robust Planning for Safe and Efficient Human-Robot Interaction. (arXiv:2110.00843v2 [cs.RO] UPDATED)
157. A manifold learning approach for gesture recognition from micro-Doppler radar measurements. (arXiv:2110.01670v3 [cs.LG] UPDATED)
158. Deep Neural Networks and Tabular Data: A Survey. (arXiv:2110.01889v2 [cs.LG] UPDATED)
159. Meta-learning an Intermediate Representation for Few-shot Block-wise Prediction of Landslide Susceptibility. (arXiv:2110.04922v2 [cs.LG] UPDATED)
160. A Deep Generative Model for Reordering Adjacency Matrices. (arXiv:2110.04971v2 [cs.HC] UPDATED)
161. Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition. (arXiv:2110.05354v3 [cs.CL] UPDATED)
162. Signal Processing on Cell Complexes. (arXiv:2110.05614v2 [cs.LG] UPDATED)
163. On out-of-distribution detection with Bayesian neural networks. (arXiv:2110.06020v2 [cs.LG] UPDATED)
164. Subspace Regularizers for Few-Shot Class Incremental Learning. (arXiv:2110.07059v2 [cs.CV] UPDATED)
165. Towards Understanding the Data Dependency of Mixup-style Training. (arXiv:2110.07647v3 [cs.LG] UPDATED)
166. Simplest Streaming Trees. (arXiv:2110.08483v3 [cs.LG] UPDATED)
167. A Variational Bayesian Approach to Learning Latent Variables for Acoustic Knowledge Transfer. (arXiv:2110.08598v2 [eess.AS] UPDATED)
168. Physics-guided Deep Markov Models for Learning Nonlinear Dynamical Systems with Uncertainty. (arXiv:2110.08607v2 [cs.LG] UPDATED)
169. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v4 [cs.LG] UPDATED)
170. RL4RS: A Real-World Benchmark for Reinforcement Learning based Recommender System. (arXiv:2110.11073v4 [cs.IR] UPDATED)
171. A Last Switch Dependent Analysis of Satiation and Seasonality in Bandits. (arXiv:2110.11819v2 [cs.LG] UPDATED)
172. On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning. (arXiv:2110.11891v2 [cs.LG] UPDATED)
173. Quantifying Epistemic Uncertainty in Deep Learning. (arXiv:2110.12122v3 [cs.LG] UPDATED)
174. Adaptive Gaussian Processes on Graphs via Spectral Graph Wavelets. (arXiv:2110.12752v2 [cs.LG] UPDATED)
175. IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. (arXiv:2110.13214v3 [cs.CV] UPDATED)
176. Towards Fine-Grained Reasoning for Fake News Detection. (arXiv:2110.15064v3 [cs.CL] UPDATED)
177. CAFE: Catastrophic Data Leakage in Vertical Federated Learning. (arXiv:2110.15122v4 [cs.LG] UPDATED)
178. Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions. (arXiv:2111.01235v2 [cs.LG] UPDATED)
179. Learning Filterbanks for End-to-End Acoustic Beamforming. (arXiv:2111.04614v2 [eess.AS] UPDATED)
180. A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes. (arXiv:2111.06784v2 [cs.LG] UPDATED)
181. Differentially private stochastic expectation propagation (DP-SEP). (arXiv:2111.13219v4 [cs.LG] UPDATED)
182. Exploiting full Resolution Feature Context for Liver Tumor and Vessel Segmentation via Fusion Encoder: Application to Liver Tumor and Vessel 3D reconstruction. (arXiv:2111.13299v3 [eess.IV] UPDATED)
183. Dimension Reduction with Prior Information for Knowledge Discovery. (arXiv:2111.13646v3 [stat.ML] UPDATED)
184. Why KDAC? A general activation function for knowledge discovery. (arXiv:2111.13858v2 [cs.LG] UPDATED)
185. A Survey of Large-Scale Deep Learning Serving System Optimization: Challenges and Opportunities. (arXiv:2111.14247v2 [cs.LG] UPDATED)
186. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v2 [cs.LG] UPDATED)
187. Embedding Decomposition for Artifacts Removal in EEG Signals. (arXiv:2112.00989v2 [cs.LG] UPDATED)
188. Bayesian Persuasion for Algorithmic Recourse. (arXiv:2112.06283v2 [cs.GT] UPDATED)
189. How Good are Low-Rank Approximations in Gaussian Process Regression?. (arXiv:2112.06410v3 [stat.ML] UPDATED)
190. ImportantAug: a data augmentation agent for speech. (arXiv:2112.07156v2 [eess.AS] UPDATED)
191. RELAX: Representation Learning Explainability. (arXiv:2112.10161v2 [stat.ML] UPDATED)
192. DeepHAM: A Global Solution Method for Heterogeneous Agent Models with Aggregate Shocks. (arXiv:2112.14377v2 [econ.GN] UPDATED)
193. DeePN$^2$: A deep learning-based non-Newtonian hydrodynamic model. (arXiv:2112.14798v2 [physics.comp-ph] UPDATED)
194. Regret Lower Bounds for Learning Linear Quadratic Gaussian Systems. (arXiv:2201.01680v2 [cs.LG] UPDATED)
195. Transfer Learning in Quantum Parametric Classifiers: An Information-Theoretic Generalization Analysis. (arXiv:2201.06297v2 [quant-ph] UPDATED)
196. Reinforcement Learning for Personalized Drug Discovery and Design for Complex Diseases: A Systems Pharmacology Perspective. (arXiv:2201.08894v2 [q-bio.BM] UPDATED)
197. Approximation bounds for norm constrained neural networks with applications to regression and GANs. (arXiv:2201.09418v2 [cs.LG] UPDATED)
198. GraphTune: A Learning-based Graph Generative Model with Tunable Structural Features. (arXiv:2201.11494v2 [cs.LG] UPDATED)
199. The Challenges of Exploration for Offline Reinforcement Learning. (arXiv:2201.11861v2 [cs.LG] UPDATED)
200. Achieving Efficient Distributed Machine Learning Using a Novel Non-Linear Class of Aggregation Functions. (arXiv:2201.12488v2 [cs.LG] UPDATED)
201. Approximate Bayesian Computation Based on Maxima Weighted Isolation Kernel Mapping. (arXiv:2201.12745v2 [stat.ML] UPDATED)
202. Generalized Bayesian Upper Confidence Bound with Approximate Inference for Bandit Problems. (arXiv:2201.12955v2 [cs.LG] UPDATED)
203. Generalization in Cooperative Multi-Agent Systems. (arXiv:2202.00104v2 [cs.LG] UPDATED)
204. CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery. (arXiv:2202.00161v2 [cs.LG] UPDATED)
205. Yordle: An Efficient Imitation Learning for Branch and Bound. (arXiv:2202.01896v2 [math.OC] UPDATED)
206. Theoretical Exploration of Solutions of Feedforward ReLU networks. (arXiv:2202.01919v4 [cs.LG] UPDATED)
207. Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets. (arXiv:2202.02794v3 [cs.LG] UPDATED)
208. Detecting Anomalies within Time Series using Local Neural Transformations. (arXiv:2202.03944v2 [cs.LG] UPDATED)
209. Regulatory Instruments for Fair Personalized Pricing. (arXiv:2202.04245v2 [cs.CY] UPDATED)
210. Conditional Drums Generation using Compound Word Representations. (arXiv:2202.04464v2 [cs.SD] UPDATED)
211. Augmenting Neural Networks with Priors on Function Values. (arXiv:2202.04798v3 [cs.LG] UPDATED)
212. Quantune: Post-training Quantization of Convolutional Neural Networks using Extreme Gradient Boosting for Fast Deployment. (arXiv:2202.05048v2 [cs.LG] UPDATED)
213. Regularized Q-learning. (arXiv:2202.05404v3 [cs.LG] UPDATED)
214. SleepPPG-Net: a deep learning algorithm for robust sleep staging from continuous photoplethysmography. (arXiv:2202.05735v2 [cs.LG] UPDATED)
215. Identification of Flux Rope Orientation via Neural Networks. (arXiv:2202.05901v2 [physics.space-ph] UPDATED)
216. Deep Performer: Score-to-Audio Music Performance Synthesis. (arXiv:2202.06034v2 [cs.SD] UPDATED)
217. Improving Fraud Detection via Hierarchical Attention-based Graph Neural Network. (arXiv:2202.06096v2 [cs.LG] UPDATED)
218. Distribution augmentation for low-resource expressive text-to-speech. (arXiv:2202.06409v2 [eess.AS] UPDATED)
219. Information Flow in Deep Neural Networks. (arXiv:2202.06749v2 [cs.LG] UPDATED)
220. CycleGAN for Undamaged-to-Damaged Domain Translation for Structural Health Monitoring and Damage Detection. (arXiv:2202.07831v2 [cs.LG] UPDATED)
221. DeepTx: Deep Learning Beamforming with Channel Prediction. (arXiv:2202.07998v2 [eess.SP] UPDATED)
222. Latent Outlier **Exposure** for Anomaly Detection with Contaminated Data. (arXiv:2202.08088v2 [cs.LG] UPDATED)
223. Single Trajectory Nonparametric Learning of Nonlinear Dynamics. (arXiv:2202.08311v2 [cs.LG] UPDATED)
224. Deep Interest Highlight Network for Click-Through Rate Prediction in Trigger-Induced Recommendation. (arXiv:2202.08959v2 [cs.IR] UPDATED)
225. Unsupervised Multiple-Object Tracking with a Dynamical Variational Autoencoder. (arXiv:2202.09315v2 [cs.LG] UPDATED)
226. Generative Adversarial Networks for Labeled Data Creation for Structural Monitoring and Damage Detection. (arXiv:2112.03478v2 [cs.LG] CROSS LISTED)
227. Generative Adversarial Networks for Labelled Vibration Data Generation. (arXiv:2112.08195v1 [cs.LG] CROSS LISTED)
228. Generative Adversarial Networks for Data Generation in Structural Health Monitoring. (arXiv:2112.08196v1 [cs.LG] CROSS LISTED)
229. Memory via Temporal Delays in weightless Spiking Neural Network. (arXiv:2202.07132v1 [cs.NE] CROSS LISTED)
## cs.AI
---
**109** new papers in cs.AI:-) 
1. Parameter Identification of a PN-Guided Incoming Missile Using an Improved Multiple-Model Mechanism. (arXiv:2202.09361v1 [eess.SY])
2. Towards Digital Twin Oriented Modelling of Complex Networked Systems and Their Dynamics: A Comprehensive Survey. (arXiv:2202.09363v1 [eess.SY])
3. Playing against no-regret players. (arXiv:2202.09364v1 [cs.GT])
4. Mixture-of-Experts with Expert Choice Routing. (arXiv:2202.09368v1 [cs.LG])
5. Black-box Node Injection Attack for Graph Neural Networks. (arXiv:2202.09389v1 [cs.LG])
6. Counterfactual Analysis of the Impact of the IMF Program on Child Poverty in the Global-South Region using Causal-Graphical Normalizing Flows. (arXiv:2202.09391v1 [cs.AI])
7. Communication-Efficient Actor-Critic Methods for Homogeneous Markov Games. (arXiv:2202.09422v1 [cs.MA])
8. A Mental-Model Centric Landscape of Human-AI Symbiosis. (arXiv:2202.09447v1 [cs.AI])
9. Towards Enabling Dynamic Convolution Neural Network Inference for Edge Intelligence. (arXiv:2202.09461v1 [cs.LG])
10. Mixed Effects Neural ODE: A Variational Approximation for Analyzing the Dynamics of Panel Data. (arXiv:2202.09463v1 [cs.LG])
11. Geometric Algebra based Embeddings for Staticand Temporal Knowledge Graph Completion. (arXiv:2202.09464v1 [cs.AI])
12. Predictive Coding: Towards a Future of Deep Learning beyond Backpropagation?. (arXiv:2202.09467v1 [cs.NE])
13. Graph Reparameterizations for Enabling 1000+ Monte Carlo Iterations in Bayesian Deep Neural Networks. (arXiv:2202.09478v1 [cs.LG])
14. Reciprocity in Machine Learning. (arXiv:2202.09480v1 [cs.LG])
15. SAGE: SLAM with Appearance and Geometry Prior for Endoscopy. (arXiv:2202.09487v1 [cs.CV])
16. Shaping Advice in Deep Reinforcement Learning. (arXiv:2202.09489v1 [cs.MA])
17. Graph Spring Network and Informative Anchor Selection for Session-based Recommendation. (arXiv:2202.09502v1 [cs.IR])
18. Robust Reinforcement Learning as a Stackelberg Game via Adaptively-Regularized Adversarial Training. (arXiv:2202.09514v1 [cs.LG])
19. Learning a Shield from Catastrophic Action Effects: Never Repeat the Same Mistake. (arXiv:2202.09516v1 [cs.LG])
20. Deep Learning for Hate Speech Detection: A Comparative Study. (arXiv:2202.09517v1 [cs.CL])
21. The four-fifths rule is not disparate impact: a woeful tale of epistemic trespassing in algorithmic fairness. (arXiv:2202.09519v1 [cs.CY])
22. student dangerous behavior detection in school. (arXiv:2202.09550v1 [cs.CV])
23. A Probabilistic Programming Idiom for Active Knowledge Search. (arXiv:2202.09555v1 [cs.RO])
24. Priming Cross-Session Motor Imagery Classification with A Universal Deep Domain Adaptation Framework. (arXiv:2202.09559v1 [cs.CV])
25. Bit-wise Training of Neural Network Weights. (arXiv:2202.09571v1 [cs.LG])
26. Diversity aware image generation. (arXiv:2202.09573v1 [cs.CV])
27. Training Robots without Robots: Deep Imitation Learning for Master-to-Robot Policy Transfer. (arXiv:2202.09574v1 [cs.RO])
28. MixKG: Mixing for harder negative samples in knowledge graph. (arXiv:2202.09606v1 [cs.AI])
29. Illuminating the Space of Enemies Through MAP-Elites. (arXiv:2202.09615v1 [cs.AI])
30. ValAsp: a tool for data validation in Answer Set Programming. (arXiv:2202.09626v1 [cs.LO])
31. Multi-task Safe Reinforcement Learning for Navigating Intersections in Dense Traffic. (arXiv:2202.09644v1 [cs.RO])
32. Navigating Conceptual Space; A new take on Artificial General Intelligence. (arXiv:2202.09646v1 [cs.AI])
33. Reward Modeling for Mitigating Toxicity in Transformer-based Language Models. (arXiv:2202.09662v1 [cs.CL])
34. Parallel Sampling for Efficient High-dimensional Bayesian Network Structure Learning. (arXiv:2202.09691v1 [cs.LG])
35. Selective Credit Assignment. (arXiv:2202.09699v1 [cs.LG])
36. Runtime-Assured, Real-Time Neural Control of Microgrids. (arXiv:2202.09710v1 [eess.SY])
37. PooL: Pheromone-inspired Communication Framework forLarge Scale Multi-Agent Reinforcement Learning. (arXiv:2202.09722v1 [cs.AI])
38. It's Raw! Audio Generation with State-Space Models. (arXiv:2202.09729v1 [cs.SD])
39. Graph-based Extractive Explainer for Recommendations. (arXiv:2202.09730v1 [cs.IR])
40. Overparametrization improves robustness against adversarial attacks: A replication study. (arXiv:2202.09735v1 [cs.LG])
41. Learning to Help Emergency Vehicles Arrive Faster: A Cooperative Vehicle-Road Scheduling Approach. (arXiv:2202.09773v1 [cs.AI])
42. Dynamic and Efficient Gray-Box Hyperparameter Optimization for Deep Learning. (arXiv:2202.09774v1 [cs.LG])
43. Clustering by the Probability Distributions from Extreme Value Theory. (arXiv:2202.09784v1 [cs.LG])
44. Contextual Semantic Embeddings for Ontology Subsumption Prediction. (arXiv:2202.09791v1 [cs.AI])
45. Hierarchical Interpretation of Neural Text Classification. (arXiv:2202.09792v1 [cs.CL])
46. Learning logic programs by discovering where not to search. (arXiv:2202.09806v1 [cs.LG])
47. Contextual Intelligent Decisions: Expert Moderation of Machine Outputs for Fair Assessment of Commercial Driving. (arXiv:2202.09816v1 [cs.HC])
48. Efficient Continual Learning Ensembles in Neural Network Subspaces. (arXiv:2202.09826v1 [cs.LG])
49. Automated Reasoning in Non-classical Logics in the TPTP World. (arXiv:2202.09836v1 [cs.AI])
50. Cross-Task Knowledge Distillation in Multi-Task Recommendation. (arXiv:2202.09852v1 [cs.IR])
51. Cooperative Artificial Intelligence. (arXiv:2202.09859v1 [cs.AI])
52. ExAIS: Executable AI Semantics. (arXiv:2202.09868v1 [cs.AI])
53. Collusion Resistant Federated Learning with Oblivious Distributed Differential Privacy. (arXiv:2202.09897v1 [cs.CR])
54. Disentangling Autoencoders (DAE). (arXiv:2202.09926v1 [cs.LG])
55. Conflict-Based Search for Explainable Multi-Agent Path Finding. (arXiv:2202.09930v1 [cs.AI])
56. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v1 [cs.LG])
57. Metaheuristics for the Online Printing Shop Scheduling Problem. (arXiv:2006.12344v2 [cs.AI] UPDATED)
58. RBF-HS: Recursive Best-First Hitting Set Search. (arXiv:2010.04282v2 [cs.AI] UPDATED)
59. MSPM: A Modularized and Scalable Multi-Agent Reinforcement Learning-based System for Financial Portfolio Management. (arXiv:2102.03502v4 [q-fin.PM] UPDATED)
60. Recent Advances on Neural Network Pruning at Initialization. (arXiv:2103.06460v2 [cs.LG] UPDATED)
61. Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets. (arXiv:2103.12028v4 [cs.CL] UPDATED)
62. Safety **Enhancement** for Deep Reinforcement Learning in Autonomous Separation Assurance. (arXiv:2105.02331v3 [cs.AI] UPDATED)
63. Open-world Machine Learning: Applications, Challenges, and Opportunities. (arXiv:2105.13448v2 [cs.LG] UPDATED)
64. CCGL: Contrastive Cascade Graph Learning. (arXiv:2107.12576v2 [cs.SI] UPDATED)
65. Pointer Value Retrieval: A new benchmark for understanding the limits of neural network generalization. (arXiv:2107.12580v2 [cs.LG] UPDATED)
66. GANmapper: geographical data translation. (arXiv:2108.04232v2 [cs.CV] UPDATED)
67. Quantization Backdoors to Deep Learning Commercial Frameworks. (arXiv:2108.09187v2 [cs.CR] UPDATED)
68. DKM: Differentiable K-Means Clustering Layer for Neural Network Compression. (arXiv:2108.12659v4 [cs.LG] UPDATED)
69. Impossibility Results in AI: A Survey. (arXiv:2109.00484v2 [cs.AI] UPDATED)
70. ArchivalQA: A Large-scale Benchmark Dataset for Open Domain Question Answering over Archival News Collections. (arXiv:2109.03438v3 [cs.CL] UPDATED)
71. CAMul: Calibrated and Accurate Multi-view Time-Series Forecasting. (arXiv:2109.07438v2 [cs.LG] UPDATED)
72. Modeling Interactions of Autonomous Vehicles and Pedestrians with Deep Multi-Agent Reinforcement Learning for Collision Avoidance. (arXiv:2109.15266v2 [cs.RO] UPDATED)
73. Learning a Metacognition for Object Detection. (arXiv:2110.03105v2 [cs.AI] UPDATED)
74. Meta-learning an Intermediate Representation for Few-shot Block-wise Prediction of Landslide Susceptibility. (arXiv:2110.04922v2 [cs.LG] UPDATED)
75. Internal Language Model Adaptation with Text-Only Data for End-to-End Speech Recognition. (arXiv:2110.05354v3 [cs.CL] UPDATED)
76. On out-of-distribution detection with Bayesian neural networks. (arXiv:2110.06020v2 [cs.LG] UPDATED)
77. Towards Understanding the Data Dependency of Mixup-style Training. (arXiv:2110.07647v3 [cs.LG] UPDATED)
78. Simplest Streaming Trees. (arXiv:2110.08483v3 [cs.LG] UPDATED)
79. A Variational Bayesian Approach to Learning Latent Variables for Acoustic Knowledge Transfer. (arXiv:2110.08598v2 [eess.AS] UPDATED)
80. One-Step Abductive Multi-Target Learning with Diverse Noisy Samples: An Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v4 [cs.LG] UPDATED)
81. On the Necessity of Auditable Algorithmic Definitions for Machine Unlearning. (arXiv:2110.11891v2 [cs.LG] UPDATED)
82. IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning. (arXiv:2110.13214v3 [cs.CV] UPDATED)
83. CAFE: Catastrophic Data Leakage in Vertical Federated Learning. (arXiv:2110.15122v4 [cs.LG] UPDATED)
84. A Decentralized Reinforcement Learning Framework for Efficient Passage of Emergency Vehicles. (arXiv:2111.00278v3 [cs.AI] UPDATED)
85. Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions. (arXiv:2111.01235v2 [cs.LG] UPDATED)
86. Patent Data for Engineering Design: A Review. (arXiv:2111.08500v2 [cs.DL] UPDATED)
87. Machines & Influence: An Information Systems Lens. (arXiv:2111.13365v4 [cs.CY] UPDATED)
88. Trap of Feature Diversity in the Learning of MLPs. (arXiv:2112.00980v2 [cs.LG] UPDATED)
89. Learning a Robust Multiagent Driving Policy for Traffic Congestion Reduction. (arXiv:2112.03759v2 [cs.AI] UPDATED)
90. A Brief History of Updates of Answer-Set Programs. (arXiv:2112.13477v2 [cs.AI] UPDATED)
91. Safe Equilibrium. (arXiv:2201.04266v3 [cs.GT] UPDATED)
92. Transfering Hierarchical Structure with Dual Meta Imitation Learning. (arXiv:2201.11981v2 [cs.RO] UPDATED)
93. Generalization in Cooperative Multi-Agent Systems. (arXiv:2202.00104v2 [cs.LG] UPDATED)
94. CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery. (arXiv:2202.00161v2 [cs.LG] UPDATED)
95. Yordle: An Efficient Imitation Learning for Branch and Bound. (arXiv:2202.01896v2 [math.OC] UPDATED)
96. Theoretical Exploration of Solutions of Feedforward ReLU networks. (arXiv:2202.01919v4 [cs.LG] UPDATED)
97. Detecting Anomalies within Time Series using Local Neural Transformations. (arXiv:2202.03944v2 [cs.LG] UPDATED)
98. ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification. (arXiv:2202.06335v2 [cs.CR] UPDATED)
99. A precortical module for robust CNNs to light variations. (arXiv:2202.07432v2 [cs.CV] UPDATED)
100. CycleGAN for Undamaged-to-Damaged Domain Translation for Structural Health Monitoring and Damage Detection. (arXiv:2202.07831v2 [cs.LG] UPDATED)
101. Singularity: Planet-Scale, Preemptive and Elastic Scheduling of AI Workloads. (arXiv:2202.07848v2 [cs.DC] UPDATED)
102. Latent Outlier **Exposure** for Anomaly Detection with Contaminated Data. (arXiv:2202.08088v2 [cs.LG] UPDATED)
103. Listing Maximal k-Plexes in Large Real-World Graphs. (arXiv:2202.08737v2 [cs.DS] UPDATED)
104. SGPT: GPT Sentence Embeddings for Semantic Search. (arXiv:2202.08904v2 [cs.CL] UPDATED)
105. Selection Strategies for Commonsense Knowledge. (arXiv:2202.09163v2 [cs.AI] UPDATED)
106. Generative Adversarial Networks for Labeled Data Creation for Structural Monitoring and Damage Detection. (arXiv:2112.03478v2 [cs.LG] CROSS LISTED)
107. Generative Adversarial Networks for Labelled Vibration Data Generation. (arXiv:2112.08195v1 [cs.LG] CROSS LISTED)
108. Generative Adversarial Networks for Data Generation in Structural Health Monitoring. (arXiv:2112.08196v1 [cs.LG] CROSS LISTED)
109. Memory via Temporal Delays in weightless Spiking Neural Network. (arXiv:2202.07132v1 [cs.NE] CROSS LISTED)

