# Your interest papers
---
## cs.CV
---
### im2nerf: Image to Neural Radiance Field in the Wild. (arXiv:2209.04061v1 [cs.CV])
- Authors : Lu Mi, Abhijit Kundu, David Ross, Frank Dellaert, Noah Snavely, Alireza Fathi
- Link : [http://arxiv.org/abs/2209.04061](http://arxiv.org/abs/2209.04061)
> ABSTRACT  :  We propose im2nerf, a learning framework that predicts a continuous neural object representation given a single input image in the wild, supervised by only segmentation output from off-the-shelf recognition methods. The standard approach to constructing neural radiance fields takes advantage of multi-view consistency and requires many calibrated views of a scene, a requirement that cannot be satisfied when learning on large-scale image data in the wild. We take a step towards addressing this shortcoming by introducing a model that encodes the input image into a disentangled object representation that contains a code for object shape, a code for object appearance, and an estimated camera pose from which the object image is captured. Our model conditions a **NeRF** on the predicted object representation and uses volume rendering to generate images from novel views. We train the model end-to-end on a large collection of input images. As the model is only provided with single-view images, the problem is highly under-constrained. Therefore, in addition to using a reconstruction loss on the synthesized input view, we use an auxiliary adversarial loss on the novel rendered views. Furthermore, we leverage object symmetry and cycle camera pose consistency. We conduct extensive quantitative and qualitative experiments on the ShapeNet dataset as well as qualitative experiments on Open Images dataset. We show that in all cases, im2nerf achieves the state-of-the-art performance for novel view synthesis from a single-view unposed image in the wild.  
### Generative Deformable Radiance Fields for Disentangled Image Synthesis of Topology-Varying Objects. (arXiv:2209.04183v1 [cs.CV])
- Authors : Ziyu Wang, Yu Deng, Jiaolong Yang, Jingyi Yu, Xin Tong
- Link : [http://arxiv.org/abs/2209.04183](http://arxiv.org/abs/2209.04183)
> ABSTRACT  :  3D-aware generative models have demonstrated their superb performance to generate 3D neural radiance fields (**NeRF**) from a collection of monocular 2D images even for topology-varying object categories. However, these methods still lack the capability to separately control the shape and appearance of the objects in the generated radiance fields. In this paper, we propose a generative model for synthesizing radiance fields of topology-varying objects with disentangled shape and appearance variations. Our method generates deformable radiance fields, which builds the dense correspondence between the density fields of the objects and encodes their appearances in a shared template field. Our disentanglement is achieved in an unsupervised manner without introducing extra labels to previous 3D-aware GAN training. We also develop an effective image inversion scheme for reconstructing the radiance field of an object in a real monocular image and manipulating its shape and appearance. Experiments show that our method can successfully learn the generative model from unstructured monocular images and well disentangle the shape and appearance for objects (e.g., chairs) with large topological variance. The model trained on synthetic data can faithfully reconstruct the real object in a given single image and achieve high-quality texture and shape editing results.  
### An Indian Roads Dataset for Supported and Suspended Traffic Lights Detection. (arXiv:2209.04203v1 [cs.CV])
- Authors : Sarita Gautam, Anuj Kumar
- Link : [http://arxiv.org/abs/2209.04203](http://arxiv.org/abs/2209.04203)
> ABSTRACT  :  Autonomous vehicles are growing rapidly, in well-developed nations like America, Europe, and China. Tech giants like Google, Tesla, Audi, BMW, and Mercedes are building highly efficient self-driving vehicles. However, the technology is still not mainstream for developing nations like India, Thailand, Africa, etc., In this paper, we present a thorough comparison of the existing datasets based on well-developed nations as well as Indian roads. We then developed a new dataset "Indian Roads Dataset" (IRD) having more than 8000 annotations extracted from 3000+ images shot using a 64 (megapixel) camera. All the annotations are manually labelled adhering to the strict rules of annotations. **Real-time** video sequences have been captured from two different cities in India namely New Delhi and Chandigarh during the day and **night**-light conditions. Our dataset exceeds previous Indian traffic light datasets in size, annotations, and variance. We prove the amelioration of our dataset by providing an extensive comparison with existing Indian datasets. Various dataset criteria like size, capturing device, a number of cities, and variations of traffic light orientations are considered. The dataset can be downloaded from here https://sites.google.com/view/ird-dataset/home  
### Retinal Image **Restoration** and Vessel Segmentation using Modified Cycle-CBAM and CBAM-UNet. (arXiv:2209.04234v1 [eess.IV])
- Authors : Alnur Alimanov, Md Baharul
- Link : [http://arxiv.org/abs/2209.04234](http://arxiv.org/abs/2209.04234)
> ABSTRACT  :  Clinical screening with low-quality fundus images is challenging and significantly leads to misdiagnosis. This paper addresses the issue of improving the retinal image quality and vessel segmentation through retinal image **restoration**. More specifically, a cycle-consistent generative adversarial network (CycleGAN) with a convolution block attention module (CBAM) is used for retinal image **restoration**. A modified UNet is used for retinal vessel segmentation for the restored retinal images (CBAM-UNet). The proposed model consists of two generators and two discriminators. Generators translate images from one domain to another, i.e., from low to high quality and vice versa. Discriminators classify generated and original images. The retinal vessel segmentation model uses downsampling, bottlenecking, and upsampling layers to generate segmented images. The CBAM has been used to enhance the feature extraction of these models. The proposed method does not require paired image datasets, which are challenging to produce. Instead, it uses unpaired data that consists of low- and high-quality fundus images retrieved from publicly available datasets. The **restoration** performance of the proposed method was evaluated using full-reference evaluation metrics, e.g., peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM). The retinal vessel segmentation performance was compared with the ground-truth fundus images. The proposed method can significantly reduce the degradation effects caused by out-of-focus blurring, color distortion, low, high, and uneven illumination. Experimental results show the effectiveness of the proposed method for retinal image **restoration** and vessel segmentation.  
### GRASP-Net: Geometric Residual Analysis and Synthesis for Point Cloud Compression. (arXiv:2209.04401v1 [eess.IV])
- Authors : Jiahao Pang, Muhammad Asad, Dong Tian
- Link : [http://arxiv.org/abs/2209.04401](http://arxiv.org/abs/2209.04401)
> ABSTRACT  :  Point cloud compression (PCC) is a key enabler for various 3-D applications, owing to the universality of the point cloud format. Ideally, 3D point clouds endeavor to depict object/scene surfaces that are continuous. Practically, as a set of discrete samples, point clouds are locally disconnected and sparsely distributed. This sparse nature is hindering the discovery of local correlation among points for compression. Motivated by an analysis with fractal dimension, we propose a heterogeneous approach with deep learning for lossy point cloud geometry compression. On top of a base layer compressing a coarse representation of the input, an **enhancement** layer is designed to cope with the challenging geometric residual/details. Specifically, a point-based network is applied to convert the erratic local details to latent features residing on the coarse point cloud. Then a sparse convolutional neural network operating on the coarse point cloud is launched. It utilizes the continuity/smoothness of the coarse geometry to compress the latent features as an **enhancement** bit-stream that greatly benefits the reconstruction quality. When this bit-stream is unavailable, e.g., due to packet loss, we support a skip mode with the same architecture which generates geometric details from the coarse point cloud directly. Experimentation on both dense and sparse point clouds demonstrate the state-of-the-art compression performance achieved by our proposal. Our code is available at https://github.com/InterDigitalInc/GRASP-Net.  
### Panoptic **NeRF**: 3D-to-2D Label Transfer for Panoptic Urban Scene Segmentation. (arXiv:2203.15224v2 [cs.CV] UPDATED)
- Authors : Xiao Fu, Shangzhan Zhang, Tianrun Chen, Yichong Lu, Lanyun Zhu, Xiaowei Zhou, Andreas Geiger, Yiyi Liao
- Link : [http://arxiv.org/abs/2203.15224](http://arxiv.org/abs/2203.15224)
> ABSTRACT  :  Large-scale training data with high-quality annotations is critical for training semantic and instance segmentation models. Unfortunately, pixel-wise annotation is labor-intensive and costly, raising the demand for more efficient labeling strategies. In this work, we present a novel 3D-to-2D label transfer method, Panoptic **NeRF**, which aims for obtaining per-pixel 2D semantic and instance labels from easy-to-obtain coarse 3D bounding primitives. Our method utilizes **NeRF** as a differentiable tool to unify coarse 3D annotations and 2D semantic cues transferred from existing datasets. We demonstrate that this combination allows for improved geometry guided by semantic information, enabling rendering of accurate semantic maps across multiple views. Furthermore, this fusion process resolves label ambiguity of the coarse 3D annotations and filters noise in the 2D predictions. By inferring in 3D space and rendering to 2D labels, our 2D semantic and instance labels are multi-view consistent by design. Experimental results show that Panoptic **NeRF** outperforms existing label transfer methods in terms of accuracy and multi-view consistency on challenging urban scenes of the KITTI-360 dataset.  
### MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
- Authors : Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, **Peyman Milanfar**, Alan Bovik, Yinxiao Li
- Link : [http://arxiv.org/abs/2204.01697](http://arxiv.org/abs/2204.01697)
> ABSTRACT  :  Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to ''see'' globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v4 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedure and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm on improving the performance of diffusion model. In this article, we present a first comprehensive review of existing variants of the diffusion models. Specifically, we provide a first taxonomy of diffusion models and categorize them variants to three types, namely sampling-acceleration **enhancement**, likelihood-maximization **enhancement** and data-generalization **enhancement**. We also introduce in detail other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models), and clarify the connections between diffusion models and these generative models. Then we make a thorough investigation into the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## eess.IV
---
### Retinal Image **Restoration** and Vessel Segmentation using Modified Cycle-CBAM and CBAM-UNet. (arXiv:2209.04234v1 [eess.IV])
- Authors : Alnur Alimanov, Md Baharul
- Link : [http://arxiv.org/abs/2209.04234](http://arxiv.org/abs/2209.04234)
> ABSTRACT  :  Clinical screening with low-quality fundus images is challenging and significantly leads to misdiagnosis. This paper addresses the issue of improving the retinal image quality and vessel segmentation through retinal image **restoration**. More specifically, a cycle-consistent generative adversarial network (CycleGAN) with a convolution block attention module (CBAM) is used for retinal image **restoration**. A modified UNet is used for retinal vessel segmentation for the restored retinal images (CBAM-UNet). The proposed model consists of two generators and two discriminators. Generators translate images from one domain to another, i.e., from low to high quality and vice versa. Discriminators classify generated and original images. The retinal vessel segmentation model uses downsampling, bottlenecking, and upsampling layers to generate segmented images. The CBAM has been used to enhance the feature extraction of these models. The proposed method does not require paired image datasets, which are challenging to produce. Instead, it uses unpaired data that consists of low- and high-quality fundus images retrieved from publicly available datasets. The **restoration** performance of the proposed method was evaluated using full-reference evaluation metrics, e.g., peak signal-to-noise ratio (PSNR) and structural similarity index measure (SSIM). The retinal vessel segmentation performance was compared with the ground-truth fundus images. The proposed method can significantly reduce the degradation effects caused by out-of-focus blurring, color distortion, low, high, and uneven illumination. Experimental results show the effectiveness of the proposed method for retinal image **restoration** and vessel segmentation.  
### GRASP-Net: Geometric Residual Analysis and Synthesis for Point Cloud Compression. (arXiv:2209.04401v1 [eess.IV])
- Authors : Jiahao Pang, Muhammad Asad, Dong Tian
- Link : [http://arxiv.org/abs/2209.04401](http://arxiv.org/abs/2209.04401)
> ABSTRACT  :  Point cloud compression (PCC) is a key enabler for various 3-D applications, owing to the universality of the point cloud format. Ideally, 3D point clouds endeavor to depict object/scene surfaces that are continuous. Practically, as a set of discrete samples, point clouds are locally disconnected and sparsely distributed. This sparse nature is hindering the discovery of local correlation among points for compression. Motivated by an analysis with fractal dimension, we propose a heterogeneous approach with deep learning for lossy point cloud geometry compression. On top of a base layer compressing a coarse representation of the input, an **enhancement** layer is designed to cope with the challenging geometric residual/details. Specifically, a point-based network is applied to convert the erratic local details to latent features residing on the coarse point cloud. Then a sparse convolutional neural network operating on the coarse point cloud is launched. It utilizes the continuity/smoothness of the coarse geometry to compress the latent features as an **enhancement** bit-stream that greatly benefits the reconstruction quality. When this bit-stream is unavailable, e.g., due to packet loss, we support a skip mode with the same architecture which generates geometric details from the coarse point cloud directly. Experimentation on both dense and sparse point clouds demonstrate the state-of-the-art compression performance achieved by our proposal. Our code is available at https://github.com/InterDigitalInc/GRASP-Net.  
## cs.LG
---
### In-situ animal behavior classification using knowledge distillation and fixed-point quantization. (arXiv:2209.04130v1 [cs.LG])
- Authors : Reza Arablouei, Liang Wang, Caitlin Phillips, Lachlan Currie, Jordan Yates, Greg Bishop
- Link : [http://arxiv.org/abs/2209.04130](http://arxiv.org/abs/2209.04130)
> ABSTRACT  :  We explore the use of knowledge distillation (KD) for learning compact and accurate models that enable classification of animal behavior from accelerometry data on wearable devices. To this end, we take a deep and complex convolutional neural network, known as residual neural network (ResNet), as the teacher model. ResNet is specifically designed for multivariate time-series classification. We use ResNet to distil the knowledge of animal behavior classification datasets into soft labels, which consist of the predicted pseudo-probabilities of every class for each datapoint. We then use the soft labels to train our significantly less complex student models, which are based on the gated recurrent unit (GRU) and multilayer perceptron (MLP). The evaluation results using two real-world animal behavior classification datasets show that the classification accuracy of the student GRU-MLP models improves appreciably through KD, approaching that of the teacher ResNet model. To further reduce the computational and memory requirements of performing inference using the student models trained via KD, we utilize dynamic fixed-point quantization through an appropriate modification of the computational graphs of the models. We implement both unquantized and quantized versions of the developed KD-based models on the embedded systems of our purpose-built collar and ear tag devices to classify animal behavior in situ and in **real time**. The results corroborate the effectiveness of KD and quantization in improving the inference performance in terms of both classification accuracy and computational and memory efficiency.  
### Investigation of a Machine learning methodology for the SKA pulsar search pipeline. (arXiv:2209.04430v1 [astro-ph.IM])
- Authors : Shashank Sanjay, Prabu Thiagaraj, Ben Stappers, Atul Ghalame, Snehanshu Saha, Zaffirah Hosenie
- Link : [http://arxiv.org/abs/2209.04430](http://arxiv.org/abs/2209.04430)
> ABSTRACT  :  The SKA pulsar search pipeline will be used for **real time** detection of pulsars. Modern radio telescopes such as SKA will be generating petabytes of data in their full scale of operation. Hence experience-based and data-driven algorithms become indispensable for applications such as candidate detection. Here we describe our findings from testing a state of the art object detection algorithm called Mask R-CNN to detect candidate signatures in the SKA pulsar search pipeline. We have trained the Mask R-CNN model to detect candidate images. A custom annotation tool was developed to mark the regions of interest in large datasets efficiently. We have successfully demonstrated this algorithm by detecting candidate signatures on a simulation dataset. The paper presents details of this work with a highlight on the future prospects.  
### MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
- Authors : Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, **Peyman Milanfar**, Alan Bovik, Yinxiao Li
- Link : [http://arxiv.org/abs/2204.01697](http://arxiv.org/abs/2204.01697)
> ABSTRACT  :  Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to ''see'' globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.  
### Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v4 [cs.LG] UPDATED)
- Authors : Ling Yang, Zhilong Zhang, Shenda Hong, Wentao Zhang, Bin Cui
- Link : [http://arxiv.org/abs/2209.00796](http://arxiv.org/abs/2209.00796)
> ABSTRACT  :  Diffusion models are a class of deep generative models that have shown impressive results on various tasks with dense theoretical founding. Although diffusion models have achieved impressive quality and diversity of sample synthesis than other state-of-the-art models, they still suffer from costly sampling procedure and sub-optimal likelihood estimation. Recent studies have shown great enthusiasm on improving the performance of diffusion model. In this article, we present a first comprehensive review of existing variants of the diffusion models. Specifically, we provide a first taxonomy of diffusion models and categorize them variants to three types, namely sampling-acceleration **enhancement**, likelihood-maximization **enhancement** and data-generalization **enhancement**. We also introduce in detail other five generative models (i.e., variational autoencoders, generative adversarial networks, normalizing flow, autoregressive models, and energy-based models), and clarify the connections between diffusion models and these generative models. Then we make a thorough investigation into the applications of diffusion models, including computer vision, natural language processing, waveform signal processing, multi-modal modeling, molecular graph generation, time series modeling, and adversarial purification. Furthermore, we propose new perspectives pertaining to the development of this generative model.  
## cs.AI
---
### In-situ animal behavior classification using knowledge distillation and fixed-point quantization. (arXiv:2209.04130v1 [cs.LG])
- Authors : Reza Arablouei, Liang Wang, Caitlin Phillips, Lachlan Currie, Jordan Yates, Greg Bishop
- Link : [http://arxiv.org/abs/2209.04130](http://arxiv.org/abs/2209.04130)
> ABSTRACT  :  We explore the use of knowledge distillation (KD) for learning compact and accurate models that enable classification of animal behavior from accelerometry data on wearable devices. To this end, we take a deep and complex convolutional neural network, known as residual neural network (ResNet), as the teacher model. ResNet is specifically designed for multivariate time-series classification. We use ResNet to distil the knowledge of animal behavior classification datasets into soft labels, which consist of the predicted pseudo-probabilities of every class for each datapoint. We then use the soft labels to train our significantly less complex student models, which are based on the gated recurrent unit (GRU) and multilayer perceptron (MLP). The evaluation results using two real-world animal behavior classification datasets show that the classification accuracy of the student GRU-MLP models improves appreciably through KD, approaching that of the teacher ResNet model. To further reduce the computational and memory requirements of performing inference using the student models trained via KD, we utilize dynamic fixed-point quantization through an appropriate modification of the computational graphs of the models. We implement both unquantized and quantized versions of the developed KD-based models on the embedded systems of our purpose-built collar and ear tag devices to classify animal behavior in situ and in **real time**. The results corroborate the effectiveness of KD and quantization in improving the inference performance in terms of both classification accuracy and computational and memory efficiency.  
### Investigation of a Machine learning methodology for the SKA pulsar search pipeline. (arXiv:2209.04430v1 [astro-ph.IM])
- Authors : Shashank Sanjay, Prabu Thiagaraj, Ben Stappers, Atul Ghalame, Snehanshu Saha, Zaffirah Hosenie
- Link : [http://arxiv.org/abs/2209.04430](http://arxiv.org/abs/2209.04430)
> ABSTRACT  :  The SKA pulsar search pipeline will be used for **real time** detection of pulsars. Modern radio telescopes such as SKA will be generating petabytes of data in their full scale of operation. Hence experience-based and data-driven algorithms become indispensable for applications such as candidate detection. Here we describe our findings from testing a state of the art object detection algorithm called Mask R-CNN to detect candidate signatures in the SKA pulsar search pipeline. We have trained the Mask R-CNN model to detect candidate images. A custom annotation tool was developed to mark the regions of interest in large datasets efficiently. We have successfully demonstrated this algorithm by detecting candidate signatures on a simulation dataset. The paper presents details of this work with a highlight on the future prospects.  
### MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
- Authors : Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, **Peyman Milanfar**, Alan Bovik, Yinxiao Li
- Link : [http://arxiv.org/abs/2204.01697](http://arxiv.org/abs/2204.01697)
> ABSTRACT  :  Transformers have recently gained significant attention in the computer vision community. However, the lack of scalability of self-attention mechanisms with respect to image size has limited their wide adoption in state-of-the-art vision backbones. In this paper we introduce an efficient and scalable attention model we call multi-axis attention, which consists of two aspects: blocked local and dilated global attention. These design choices allow global-local spatial interactions on arbitrary input resolutions with only linear complexity. We also present a new architectural element by effectively blending our proposed attention model with convolutions, and accordingly propose a simple hierarchical vision backbone, dubbed MaxViT, by simply repeating the basic building block over multiple stages. Notably, MaxViT is able to ''see'' globally throughout the entire network, even in earlier, high-resolution stages. We demonstrate the effectiveness of our model on a broad spectrum of vision tasks. On image classification, MaxViT achieves state-of-the-art performance under various settings: without extra data, MaxViT attains 86.5% ImageNet-1K top-1 accuracy; with ImageNet-21K pre-training, our model achieves 88.7% top-1 accuracy. For downstream tasks, MaxViT as a backbone delivers favorable performance on object detection as well as visual aesthetic assessment. We also show that our proposed model expresses strong generative modeling capability on ImageNet, demonstrating the superior potential of MaxViT blocks as a universal vision module. The source code and trained models will be available at https://github.com/google-research/maxvit.  
# Paper List
---
## cs.CV
---
**44** new papers in cs.CV:-) 
1. Cross-Modal Knowledge Transfer Without Task-Relevant Source Data. (arXiv:2209.04027v1 [cs.CV])
2. im2nerf: Image to Neural Radiance Field in the Wild. (arXiv:2209.04061v1 [cs.CV])
3. TEACH: Temporal Action Composition for 3D Humans. (arXiv:2209.04066v1 [cs.CV])
4. Learning Audio-Visual embedding for Wild Person Verification. (arXiv:2209.04093v1 [cs.CV])
5. MassMIND: Massachusetts Maritime INfrared Dataset. (arXiv:2209.04097v1 [cs.CV])
6. Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled Membership Inference. (arXiv:2209.04113v1 [cs.CR])
7. ISS: Image as Stetting Stone for Text-Guided 3D Shape Generation. (arXiv:2209.04145v1 [cs.CV])
8. Domain-specific Learning of Multi-scale Facial Dynamics for Apparent Personality Traits Prediction. (arXiv:2209.04148v1 [cs.CV])
9. Generative Deformable Radiance Fields for Disentangled Image Synthesis of Topology-Varying Objects. (arXiv:2209.04183v1 [cs.CV])
10. An Indian Roads Dataset for Supported and Suspended Traffic Lights Detection. (arXiv:2209.04203v1 [cs.CV])
11. Selecting Related Knowledge via Efficient Channel Attention for Online Continual Learning. (arXiv:2209.04212v1 [cs.CV])
12. Self-supervised Learning for Heterogeneous Graph via Structure Information based on Metapath. (arXiv:2209.04218v1 [cs.LG])
13. Pathology Synthesis of 3D Consistent Cardiac MR Im-ages Using 2D VAEs and GANs. (arXiv:2209.04223v1 [eess.IV])
14. Retinal Image **Restoration** and Vessel Segmentation using Modified Cycle-CBAM and CBAM-UNet. (arXiv:2209.04234v1 [eess.IV])
15. EchoCoTr: Estimation of the Left Ventricular Ejection Fraction from Spatiotemporal Echocardiography. (arXiv:2209.04242v1 [cs.CV])
16. Talking Head from Speech Audio using a Pre-trained Image Generator. (arXiv:2209.04252v1 [cs.CV])
17. Temporally Adjustable Longitudinal Fluid-Attenuated Inversion Recovery MRI Estimation / Synthesis for Multiple Sclerosis. (arXiv:2209.04275v1 [eess.IV])
18. Deep learning-based Crop Row Following for Infield Navigation of Agri-Robots. (arXiv:2209.04278v1 [cs.CV])
19. Tracking Small and Fast Moving Objects: A Benchmark. (arXiv:2209.04284v1 [cs.CV])
20. Towards Confidence-guided Shape Completion for Robotic Applications. (arXiv:2209.04300v1 [cs.CV])
21. Saliency Guided Adversarial Training for Learning Generalizable Features with Applications to Medical Imaging Classification System. (arXiv:2209.04326v1 [eess.IV])
22. Bridging the Gap: Differentially Private Equivariant Deep Learning for Medical Image Analysis. (arXiv:2209.04338v1 [eess.IV])
23. EDeNN: Event Decay Neural Networks for low latency vision. (arXiv:2209.04362v1 [cs.CV])
24. Pre-training image-language transformers for open-vocabulary tasks. (arXiv:2209.04372v1 [cs.CV])
25. Energy-Aware JPEG Image Compression: A Multi-Objective Approach. (arXiv:2209.04374v1 [cs.CV])
26. GRASP-Net: Geometric Residual Analysis and Synthesis for Point Cloud Compression. (arXiv:2209.04401v1 [eess.IV])
27. Multi-NeuS: 3D Head Portraits from Single Image with Neural Implicit Functions. (arXiv:2209.04436v1 [cs.CV])
28. Improved Masked Image Generation with Token-Critic. (arXiv:2209.04439v1 [cs.CV])
29. Convolutional Neural Networks combined with Runge-Kutta Methods. (arXiv:1802.08831v7 [cs.CV] UPDATED)
30. The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction. (arXiv:2101.07295v5 [cs.LG] UPDATED)
31. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v4 [cs.LG] UPDATED)
32. Learning to Rank Ace Neural Architectures via Normalized Discounted Cumulative Gain. (arXiv:2108.03001v2 [cs.CV] UPDATED)
33. Harnessing Perceptual Adversarial Patches for Crowd Counting. (arXiv:2109.07986v2 [cs.CV] UPDATED)
34. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v2 [cs.HC] UPDATED)
35. Class-Aware Contrastive Semi-Supervised Learning. (arXiv:2203.02261v3 [cs.CV] UPDATED)
36. Continuous Self-Localization on Aerial Images Using Visual and Lidar Sensors. (arXiv:2203.03334v2 [cs.CV] UPDATED)
37. A Thermodynamics-informed Active Learning Approach to Perception and Reasoning about Fluids. (arXiv:2203.05775v2 [cs.CV] UPDATED)
38. Panoptic **NeRF**: 3D-to-2D Label Transfer for Panoptic Urban Scene Segmentation. (arXiv:2203.15224v2 [cs.CV] UPDATED)
39. MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
40. Contrastive Domain Adaptation for Early Misinformation Detection: A Case Study on COVID-19. (arXiv:2208.09578v3 [cs.CV] UPDATED)
41. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v4 [cs.LG] UPDATED)
42. Fuzzy Attention Neural Network to Tackle Discontinuity in Airway Segmentation. (arXiv:2209.02048v2 [eess.IV] UPDATED)
43. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v2 [eess.IV] UPDATED)
44. Self-Supervised Learning of Context-Aware Pitch Prosody Representations. (arXiv:2007.09060v4 [cs.SD] CROSS LISTED)
## eess.IV
---
**13** new papers in eess.IV:-) 
1. Pathology Synthesis of 3D Consistent Cardiac MR Im-ages Using 2D VAEs and GANs. (arXiv:2209.04223v1 [eess.IV])
2. Retinal Image **Restoration** and Vessel Segmentation using Modified Cycle-CBAM and CBAM-UNet. (arXiv:2209.04234v1 [eess.IV])
3. Temporally Adjustable Longitudinal Fluid-Attenuated Inversion Recovery MRI Estimation / Synthesis for Multiple Sclerosis. (arXiv:2209.04275v1 [eess.IV])
4. Saliency Guided Adversarial Training for Learning Generalizable Features with Applications to Medical Imaging Classification System. (arXiv:2209.04326v1 [eess.IV])
5. Bridging the Gap: Differentially Private Equivariant Deep Learning for Medical Image Analysis. (arXiv:2209.04338v1 [eess.IV])
6. Unsupervised segmentation of biomedical hyperspectral image data: tackling high dimensionality with convolutional autoencoders. (arXiv:2209.04375v1 [physics.med-ph])
7. GRASP-Net: Geometric Residual Analysis and Synthesis for Point Cloud Compression. (arXiv:2209.04401v1 [eess.IV])
8. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v4 [cs.LG] UPDATED)
9. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v2 [cs.HC] UPDATED)
10. JR2net: A Joint Non-Linear Representation and Recovery Network for Compressive Spectral Imaging. (arXiv:2205.07770v2 [eess.IV] UPDATED)
11. Deep Spatial and Tonal Data Optimisation for Homogeneous Diffusion Inpainting. (arXiv:2208.14371v2 [eess.IV] UPDATED)
12. Fuzzy Attention Neural Network to Tackle Discontinuity in Airway Segmentation. (arXiv:2209.02048v2 [eess.IV] UPDATED)
13. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v2 [eess.IV] UPDATED)
## cs.LG
---
**103** new papers in cs.LG:-) 
1. $\Delta$-PINNs: physics-informed neural networks on complex geometries. (arXiv:2209.03984v1 [cs.LG])
2. Q-learning Decision Transformer: Leveraging Dynamic Programming for Conditional Sequence Modelling in Offline RL. (arXiv:2209.03993v1 [cs.LG])
3. Active Learning of Classifiers with Label and Seed Queries. (arXiv:2209.03996v1 [cs.LG])
4. Online Low Rank Matrix Completion. (arXiv:2209.03997v1 [cs.LG])
5. FedDAR: Federated Domain-Aware Representation Learning. (arXiv:2209.04007v1 [cs.LG])
6. From Shapley Values to Generalized Additive Models and back. (arXiv:2209.04012v1 [cs.LG])
7. Functional dimension of feedforward ReLU neural networks. (arXiv:2209.04036v1 [math.MG])
8. Assessing Lower Limb Strength using Internet-of-Things Enabled Chair and Processing of Time-Series Data in Google GPU Tensorflow CoLab. (arXiv:2209.04042v1 [cs.LG])
9. Studying Drowsiness Detection Performance while Driving through Scalable Machine Learning Models using Electroencephalography. (arXiv:2209.04048v1 [eess.SP])
10. Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics. (arXiv:2209.04049v1 [cs.AI])
11. Algorithms with More Granular Differential Privacy Guarantees. (arXiv:2209.04053v1 [cs.CR])
12. Generating Contextual Load Profiles Using a Conditional Variational Autoencoder. (arXiv:2209.04056v1 [cs.LG])
13. RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk. (arXiv:2209.04067v1 [cs.LG])
14. Stochastic Compositional Optimization with Compositional Constraints. (arXiv:2209.04086v1 [math.OC])
15. MATT: A Multiple-instance Attention Mechanism for Long-tail Music Genre Classification. (arXiv:2209.04109v1 [cs.SD])
16. Gaussian Process Koopman Mode Decomposition. (arXiv:2209.04111v1 [stat.ML])
17. Fast Neural Kernel Embeddings for General Activations. (arXiv:2209.04121v1 [cs.LG])
18. In-situ animal behavior classification using knowledge distillation and fixed-point quantization. (arXiv:2209.04130v1 [cs.LG])
19. SPT-NRTL: A physics-guided machine learning model to predict thermodynamically consistent activity coefficients. (arXiv:2209.04135v1 [physics.chem-ph])
20. Joint Non-parametric Point Process model for Treatments and Outcomes: Counterfactual Time-series Prediction Under Policy Interventions. (arXiv:2209.04142v1 [cs.LG])
21. Extending Open Bandit Pipeline to Simulate Industry Challenges. (arXiv:2209.04147v1 [cs.LG])
22. ApproxTrain: Fast Simulation of Approximate Multipliers for DNN Training and Inference. (arXiv:2209.04161v1 [cs.AR])
23. Estimating Multi-label Accuracy using Labelset Distributions. (arXiv:2209.04163v1 [cs.LG])
24. Explanation Method for Anomaly Detection on Mixed Numerical and Categorical Spaces. (arXiv:2209.04173v1 [cs.LG])
25. FLInt: Exploiting Floating Point Enabled Integer Arithmetic for Efficient Random Forest Inference. (arXiv:2209.04181v1 [cs.LG])
26. Anomaly Detection through Unsupervised Federated Learning. (arXiv:2209.04184v1 [cs.LG])
27. Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning. (arXiv:2209.04187v1 [cs.LG])
28. Differentially Private Stochastic Gradient Descent with Low-Noise. (arXiv:2209.04188v1 [stat.ML])
29. Selecting Related Knowledge via Efficient Channel Attention for Online Continual Learning. (arXiv:2209.04212v1 [cs.CV])
30. Autoencoder Based Iterative Modeling and Multivariate Time-Series Subsequence Clustering Algorithm. (arXiv:2209.04213v1 [eess.SP])
31. Fast and Accurate Importance Weighting for Correcting Sample Bias. (arXiv:2209.04215v1 [cs.LG])
32. Self-supervised Learning for Heterogeneous Graph via Structure Information based on Metapath. (arXiv:2209.04218v1 [cs.LG])
33. Modelling Patient Trajectories Using Multimodal Information. (arXiv:2209.04224v1 [cs.LG])
34. Survey on Deep Fuzzy Systems in regression applications: a view on interpretability. (arXiv:2209.04230v1 [cs.LG])
35. Shapley value-based approaches to explain the robustness of classifiers in machine learning. (arXiv:2209.04254v1 [cs.LG])
36. Knowledge-based Deep Learning for Modeling Chaotic Systems. (arXiv:2209.04259v1 [cs.LG])
37. Robust-by-Design Classification via Unitary-Gradient Neural Networks. (arXiv:2209.04293v1 [cs.LG])
38. Towards Confidence-guided Shape Completion for Robotic Applications. (arXiv:2209.04300v1 [cs.CV])
39. Saliency Guided Adversarial Training for Learning Generalizable Features with Applications to Medical Imaging Classification System. (arXiv:2209.04326v1 [eess.IV])
40. Design of a Supervisory Control System for Autonomous Operation of Advanced Reactors. (arXiv:2209.04334v1 [eess.SY])
41. Bridging the Gap: Differentially Private Equivariant Deep Learning for Medical Image Analysis. (arXiv:2209.04338v1 [eess.IV])
42. Multi-objective hyperparameter optimization with performance uncertainty. (arXiv:2209.04340v1 [cs.LG])
43. Risk-Averse Multi-Armed Bandits with Unobserved Confounders: A Case Study in Emotion Regulation in Mobile Health. (arXiv:2209.04356v1 [cs.LG])
44. SC-Square: Future Progress with Machine Learning?. (arXiv:2209.04361v1 [cs.SC])
45. EDeNN: Event Decay Neural Networks for low latency vision. (arXiv:2209.04362v1 [cs.CV])
46. MICO: Selective Search with Mutual Information Co-training. (arXiv:2209.04378v1 [cs.IR])
47. Deep autoencoders for physics-constrained data-driven nonlinear materials modeling. (arXiv:2209.04416v1 [math.NA])
48. Expected Worst Case Regret via Stochastic Sequential Covering. (arXiv:2209.04417v1 [cs.LG])
49. Trustworthy Federated Learning via Blockchain. (arXiv:2209.04418v1 [cs.LG])
50. Majority Vote for Distributed Differentially Private Sign Selection. (arXiv:2209.04419v1 [cs.CR])
51. The Role Of Biology In Deep Learning. (arXiv:2209.04425v1 [cs.NE])
52. Zydeco-Style Spike Sorting Low Power VLSI Architecture for IoT BCI Implants. (arXiv:2209.04427v1 [cs.AR])
53. Investigation of a Machine learning methodology for the SKA pulsar search pipeline. (arXiv:2209.04430v1 [astro-ph.IM])
54. Convolutional Neural Networks combined with Runge-Kutta Methods. (arXiv:1802.08831v7 [cs.CV] UPDATED)
55. Towards Sharp Analysis for Distributed Learning with Random Features. (arXiv:1906.03155v5 [cs.LG] UPDATED)
56. Improving Certified Robustness via Statistical Learning with Logical Reasoning. (arXiv:2003.00120v5 [cs.LG] UPDATED)
57. Hcore-Init: Neural Network Initialization based on Graph Degeneracy. (arXiv:2004.07636v2 [cs.LG] UPDATED)
58. Learning Branching Heuristics for Propositional Model Counting. (arXiv:2007.03204v2 [cs.LG] UPDATED)
59. Random Vector Functional Link Networks for Function Approximation on Manifolds. (arXiv:2007.15776v2 [stat.ML] UPDATED)
60. Adversarial Examples in Constrained Domains. (arXiv:2011.01183v3 [cs.CR] UPDATED)
61. ExpFinder: An Ensemble Expert Finding Model Integrating $N$-gram Vector Space Model and $\mu$CO-HITS. (arXiv:2101.06821v2 [cs.IR] UPDATED)
62. The Surprising Positive Knowledge Transfer in Continual 3D Object Shape Reconstruction. (arXiv:2101.07295v5 [cs.LG] UPDATED)
63. Differential Privacy Dynamics of Langevin Diffusion and Noisy Gradient Descent. (arXiv:2102.05855v5 [stat.ML] UPDATED)
64. The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. (arXiv:2102.06387v4 [cs.LG] UPDATED)
65. ANITA: An Optimal Loopless Accelerated Variance-Reduced Gradient Method. (arXiv:2103.11333v3 [math.OC] UPDATED)
66. Exact Recovery in the General Hypergraph Stochastic Block Model. (arXiv:2105.04770v2 [cs.IT] UPDATED)
67. BERT is to NLP what AlexNet is to CV: Can Pre-Trained Language Models Identify Analogies?. (arXiv:2105.04949v4 [cs.CL] UPDATED)
68. Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices. (arXiv:2106.01958v3 [cs.LG] UPDATED)
69. Cross-Subject Domain Adaptation for Classifying Working Memory Load with Multi-Frame EEG Images. (arXiv:2106.06769v4 [cs.LG] UPDATED)
70. On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs. (arXiv:2107.01495v2 [cs.LG] UPDATED)
71. Survey: Leakage and Privacy at Inference Time. (arXiv:2107.01614v2 [cs.LG] UPDATED)
72. Solving Multistage Stochastic Linear Programming via Regularized Linear Decision Rules: An Application to Hydrothermal Dispatch Planning. (arXiv:2110.03146v2 [math.OC] UPDATED)
73. Review of Pedestrian Trajectory Prediction Methods: Comparing Deep Learning and Knowledge-based Approaches. (arXiv:2111.06740v2 [cs.LG] UPDATED)
74. On a Conjecture Regarding the Adam Optimizer. (arXiv:2111.08162v4 [cs.LG] UPDATED)
75. Newton methods based convolution neural networks using parallel processing. (arXiv:2112.01401v2 [cs.LG] UPDATED)
76. Constrained multi-objective optimization of process design parameters in settings with scarce data: an application to adhesive bonding. (arXiv:2112.08760v2 [cs.NE] UPDATED)
77. The need for a more human-centered approach to designing and validating transparent AI in medical image analysis -- Guidelines and Evidence from a Systematic Review. (arXiv:2112.12596v2 [cs.HC] UPDATED)
78. Explainability Is in the Mind of the Beholder: Establishing the Foundations of Explainable Artificial Intelligence. (arXiv:2112.14466v2 [cs.AI] UPDATED)
79. Data-Driven Deep Learning Based Hybrid Beamforming for Aerial Massive MIMO-OFDM Systems with Implicit CSI. (arXiv:2201.06778v3 [eess.SP] UPDATED)
80. A PDE-Based Analysis of the Symmetric Two-Armed Bernoulli Bandit. (arXiv:2202.05767v2 [cs.LG] UPDATED)
81. Bit-Metric Decoding Rate in Multi-User MIMO Systems: Applications. (arXiv:2203.06273v3 [cs.IT] UPDATED)
82. Using Probabilistic Machine Learning to Better Model Temporal Patterns in Parameterizations: a case study with the Lorenz 96 model. (arXiv:2203.14814v3 [cs.LG] UPDATED)
83. MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
84. Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning for Robotics. (arXiv:2204.04308v2 [cs.LG] UPDATED)
85. JR2net: A Joint Non-Linear Representation and Recovery Network for Compressive Spectral Imaging. (arXiv:2205.07770v2 [eess.IV] UPDATED)
86. Differentially Private Decoding in Large Language Models. (arXiv:2205.13621v2 [cs.CL] UPDATED)
87. HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks. (arXiv:2205.15745v2 [cs.LG] UPDATED)
88. PhML-DyR: A Physics-Informed ML framework for Dynamic Reconfiguration in Power Systems. (arXiv:2206.06789v2 [eess.SY] UPDATED)
89. Condensing Graphs via One-Step Gradient Matching. (arXiv:2206.07746v3 [cs.LG] UPDATED)
90. Controllable Data Generation by Deep Learning: A Review. (arXiv:2207.09542v3 [cs.LG] UPDATED)
91. Are Gradients on Graph Structure Reliable in Gray-box Attacks?. (arXiv:2208.05514v2 [cs.CR] UPDATED)
92. Safety and Performance, Why not Both? Bi-Objective Optimized Model Compression toward AI Software Deployment. (arXiv:2208.05969v2 [cs.LG] UPDATED)
93. Universal Solutions of Feedforward ReLU Networks for Interpolations. (arXiv:2208.07498v2 [cs.LG] UPDATED)
94. Learning Generative Models for Active Inference using Tensor Networks. (arXiv:2208.08713v2 [cs.LG] UPDATED)
95. FedEgo: Privacy-preserving Personalized Federated Graph Learning with Ego-graphs. (arXiv:2208.13685v2 [cs.LG] UPDATED)
96. Diffusion Models: A Comprehensive Survey of Methods and Applications. (arXiv:2209.00796v4 [cs.LG] UPDATED)
97. Fuzzy Attention Neural Network to Tackle Discontinuity in Airway Segmentation. (arXiv:2209.02048v2 [eess.IV] UPDATED)
98. Rare but Severe Neural Machine Translation Errors Induced by Minimal Deletion: An Empirical Study on Chinese and English. (arXiv:2209.02145v2 [cs.CL] UPDATED)
99. Improving Out-of-Distribution Detection via Epistemic Uncertainty Adversarial Training. (arXiv:2209.03148v2 [cs.LG] UPDATED)
100. A Framework for Evaluating Privacy-Utility Trade-off in Vertical Federated Learning. (arXiv:2209.03885v2 [cs.LG] UPDATED)
101. Analyzing the Effect of Sampling in GNNs on Individual Fairness. (arXiv:2209.03904v2 [cs.LG] UPDATED)
102. A multi view multi stage and multi window framework for pulmonary artery segmentation from CT scans. (arXiv:2209.03918v2 [eess.IV] UPDATED)
103. Self-Supervised Learning of Context-Aware Pitch Prosody Representations. (arXiv:2007.09060v4 [cs.SD] CROSS LISTED)
## cs.AI
---
**57** new papers in cs.AI:-) 
1. Technology and Consciousness. (arXiv:2209.03956v1 [q-bio.NC])
2. Vision for Bosnia and Herzegovina in Artificial Intelligence Age: Global Trends, Potential Opportunities, Selected Use-cases and Realistic Goals. (arXiv:2209.03990v1 [cs.AI])
3. Privacy of Autonomous Vehicles: Risks, Protection Methods, and Future Directions. (arXiv:2209.04022v1 [cs.AI])
4. Uncovering the Connection Between Differential Privacy and Certified Robustness of Federated Learning against Poisoning Attacks. (arXiv:2209.04030v1 [cs.CR])
5. Who Pays? Personalization, Bossiness and the Cost of Fairness. (arXiv:2209.04043v1 [cs.IR])
6. Dr. Neurosymbolic, or: How I Learned to Stop Worrying and Accept Statistics. (arXiv:2209.04049v1 [cs.AI])
7. RASR: Risk-Averse Soft-Robust MDPs with EVaR and Entropic Risk. (arXiv:2209.04067v1 [cs.LG])
8. Audio Analytics-based Human Trafficking Detection Framework for Autonomous Vehicles. (arXiv:2209.04071v1 [cs.AI])
9. Improving the Environmental Perception of Autonomous Vehicles using Deep Learning-based Audio Classification. (arXiv:2209.04075v1 [cs.SD])
10. A Memory-Related Multi-Task Method Based on Task-Agnostic Exploration. (arXiv:2209.04100v1 [cs.AI])
11. MATT: A Multiple-instance Attention Mechanism for Long-tail Music Genre Classification. (arXiv:2209.04109v1 [cs.SD])
12. Joint Alignment of Multi-Task Feature and Label Spaces for Emotion Cause Pair Extraction. (arXiv:2209.04112v1 [cs.CL])
13. Robust and Lossless Fingerprinting of Deep Neural Networks via Pooled Membership Inference. (arXiv:2209.04113v1 [cs.CR])
14. Fast Neural Kernel Embeddings for General Activations. (arXiv:2209.04121v1 [cs.LG])
15. In-situ animal behavior classification using knowledge distillation and fixed-point quantization. (arXiv:2209.04130v1 [cs.LG])
16. SUPER-Rec: SUrrounding Position-Enhanced Representation for Recommendation. (arXiv:2209.04154v1 [cs.IR])
17. Metaverse for Healthcare: A Survey on Potential Applications, Challenges and Future Directions. (arXiv:2209.04160v1 [cs.AI])
18. ApproxTrain: Fast Simulation of Approximate Multipliers for DNN Training and Inference. (arXiv:2209.04161v1 [cs.AR])
19. Overlapped speech and gender detection with WavLM pre-trained features. (arXiv:2209.04167v1 [cs.SD])
20. Explanation Method for Anomaly Detection on Mixed Numerical and Categorical Spaces. (arXiv:2209.04173v1 [cs.LG])
21. Enhancing Pre-trained Models with Text Structure Knowledge for Question Generation. (arXiv:2209.04179v1 [cs.CL])
22. Efficient Multi-view Clustering via Unified and Discrete Bipartite Graph Learning. (arXiv:2209.04187v1 [cs.LG])
23. Conversion of Acoustic Signal (Speech) Into Text By Digital Filter using Natural Language Processing. (arXiv:2209.04189v1 [cs.AI])
24. Shapley value-based approaches to explain the robustness of classifiers in machine learning. (arXiv:2209.04254v1 [cs.LG])
25. Location-Routing Planning for Last-Mile Deliveries Using Mobile Parcel Lockers: A Hybrid Q-Learning Network Approach. (arXiv:2209.04265v1 [cs.AI])
26. Deep learning-based Crop Row Following for Infield Navigation of Agri-Robots. (arXiv:2209.04278v1 [cs.CV])
27. Robust-by-Design Classification via Unitary-Gradient Neural Networks. (arXiv:2209.04293v1 [cs.LG])
28. Alignment-based conformance checking over probabilistic events. (arXiv:2209.04309v1 [cs.AI])
29. Multi-Document Scientific Summarization from a Knowledge Graph-Centric View. (arXiv:2209.04319v1 [cs.CL])
30. Multi-objective hyperparameter optimization with performance uncertainty. (arXiv:2209.04340v1 [cs.LG])
31. MIntRec: A New Dataset for Multimodal Intent Recognition. (arXiv:2209.04355v1 [cs.AI])
32. A Semi-Supervised Algorithm for Improving the Consistency of Crowdsourced Datasets: The COVID-19 Case Study on Respiratory Disorder Classification. (arXiv:2209.04360v1 [cs.SD])
33. EDeNN: Event Decay Neural Networks for low latency vision. (arXiv:2209.04362v1 [cs.CV])
34. Energy-Aware JPEG Image Compression: A Multi-Objective Approach. (arXiv:2209.04374v1 [cs.CV])
35. Trust Calibration as a Function of the Evolution of Uncertainty in Knowledge Generation: A Survey. (arXiv:2209.04388v1 [cs.HC])
36. The Role Of Biology In Deep Learning. (arXiv:2209.04425v1 [cs.NE])
37. Investigation of a Machine learning methodology for the SKA pulsar search pipeline. (arXiv:2209.04430v1 [astro-ph.IM])
38. Learning Branching Heuristics for Propositional Model Counting. (arXiv:2007.03204v2 [cs.LG] UPDATED)
39. ExpFinder: An Ensemble Expert Finding Model Integrating $N$-gram Vector Space Model and $\mu$CO-HITS. (arXiv:2101.06821v2 [cs.IR] UPDATED)
40. On Meritocracy in Optimal Set Selection. (arXiv:2102.11932v3 [cs.AI] UPDATED)
41. Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices. (arXiv:2106.01958v3 [cs.LG] UPDATED)
42. On Positional and Structural Node Features for Graph Neural Networks on Non-attributed Graphs. (arXiv:2107.01495v2 [cs.LG] UPDATED)
43. Learning to Rank Ace Neural Architectures via Normalized Discounted Cumulative Gain. (arXiv:2108.03001v2 [cs.CV] UPDATED)
44. Newton methods based convolution neural networks using parallel processing. (arXiv:2112.01401v2 [cs.LG] UPDATED)
45. Explainability Is in the Mind of the Beholder: Establishing the Foundations of Explainable Artificial Intelligence. (arXiv:2112.14466v2 [cs.AI] UPDATED)
46. MaxViT: Multi-Axis Vision Transformer. (arXiv:2204.01697v4 [cs.CV] UPDATED)
47. Grounding Hindsight Instructions in Multi-Goal Reinforcement Learning for Robotics. (arXiv:2204.04308v2 [cs.LG] UPDATED)
48. Contextualizing Artificially Intelligent Morality: A Meta-Ethnography of Top-Down, Bottom-Up, and Hybrid Models for Theoretical and Applied Ethics in Artificial Intelligence. (arXiv:2204.07612v2 [cs.AI] UPDATED)
49. On Designing Data Models for Energy Feature Stores. (arXiv:2205.04267v2 [cs.AI] UPDATED)
50. HyperMAML: Few-Shot Adaptation of Deep Models with Hypernetworks. (arXiv:2205.15745v2 [cs.LG] UPDATED)
51. Condensing Graphs via One-Step Gradient Matching. (arXiv:2206.07746v3 [cs.LG] UPDATED)
52. Controllable Data Generation by Deep Learning: A Review. (arXiv:2207.09542v3 [cs.LG] UPDATED)
53. Learning Generative Models for Active Inference using Tensor Networks. (arXiv:2208.08713v2 [cs.LG] UPDATED)
54. Contrastive Domain Adaptation for Early Misinformation Detection: A Case Study on COVID-19. (arXiv:2208.09578v3 [cs.CV] UPDATED)
55. Rare but Severe Neural Machine Translation Errors Induced by Minimal Deletion: An Empirical Study on Chinese and English. (arXiv:2209.02145v2 [cs.CL] UPDATED)
56. Why So Toxic? Measuring and Triggering Toxic Behavior in Open-Domain Chatbots. (arXiv:2209.03463v2 [cs.CY] UPDATED)
57. Analyzing the Effect of Sampling in GNNs on Individual Fairness. (arXiv:2209.03904v2 [cs.LG] UPDATED)

