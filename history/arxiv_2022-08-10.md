# Your interest papers
---
## cs.CV
---
### OL-DN: Online learning based dual-domain network for HEVC intra frame quality **enhancement**. (arXiv:2208.04661v1 [eess.IV])
- Authors : Renwei Yang, Shuyuan Zhu, Xiaozhen Zheng, Bing Zeng
- Link : [http://arxiv.org/abs/2208.04661](http://arxiv.org/abs/2208.04661)
> ABSTRACT  :  Convolution neural network (CNN) based methods offer effective solutions for enhancing the quality of compressed image and video. However, these methods ignore using the raw data to enhance the quality. In this paper, we adopt the raw data in the quality **enhancement** for the HEVC intra-coded image by proposing an online learning-based method. When quality **enhancement** is demanded, we online train our proposed model at encoder side and then use the parameters to update the model of decoder side. This method not only improves model performance, but also makes one model adoptable to multiple coding scenarios. Besides, quantization error in discrete cosine transform (DCT) coefficients is the root cause of various HEVC compression artifacts. Thus, we combine frequency domain priors to assist image reconstruction. We design a DCT based convolution layer, to produce DCT coefficients that are suitable for CNN learning. Experimental results show that our proposed online learning based dual-domain network (OL-DN) has achieved superior performance, compared with the state-of-the-art methods.  
### JPD-SE: High-Level Semantics for Joint Perception-Distortion **Enhancement** in Image Compression. (arXiv:2005.12810v3 [eess.IV] UPDATED)
- Authors : Shiyu Duan, Huaijin Chen, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2005.12810](http://arxiv.org/abs/2005.12810)
> ABSTRACT  :  While humans can effortlessly transform complex visual scenes into simple words and the other way around by leveraging their high-level understanding of the content, conventional or the more recent learned image compression codecs do not seem to utilize the semantic meanings of visual content to their full potential. Moreover, they focus mostly on rate-distortion and tend to underperform in perception quality especially in low bitrate regime, and often disregard the performance of downstream computer vision algorithms, which is a fast-growing consumer group of compressed images in addition to human viewers. In this paper, we (1) present a generic framework that can enable any image codec to leverage high-level semantics and (2) study the joint optimization of perception quality and distortion. Our idea is that given any codec, we utilize high-level semantics to augment the low-level visual features extracted by it and produce essentially a new, semantic-aware codec. We propose a three-phase training scheme that teaches semantic-aware codecs to leverage the power of semantic to jointly optimize rate-perception-distortion (R-PD) performance. As an additional benefit, semantic-aware codecs also boost the performance of downstream computer vision algorithms. To validate our claim, we perform extensive empirical evaluations and provide both quantitative and qualitative results.  
### A Novel Framework for Image-to-image Translation and Image Compression. (arXiv:2111.13105v2 [eess.IV] UPDATED)
- Authors : Fei Yang, Yaxing Wang, Luis Herranz, Yongmei Cheng, Mikhail Mozerov
- Link : [http://arxiv.org/abs/2111.13105](http://arxiv.org/abs/2111.13105)
> ABSTRACT  :  Data-driven paradigms using machine learning are becoming ubiquitous in image processing and communications. In particular, image-to-image (I2I) translation is a generic and widely used approach to image processing problems, such as image synthesis, style transfer, and image **restoration**. At the same time, neural image compression has emerged as a data-driven alternative to traditional coding approaches in visual communications. In this paper, we study the combination of these two paradigms into a joint I2I compression and translation framework, focusing on multi-domain image synthesis. We first propose distributed I2I translation by integrating quantization and entropy coding into an I2I translation framework (i.e. I2Icodec). In practice, the image compression functionality (i.e. autoencoding) is also desirable, requiring to deploy alongside I2Icodec a regular image codec. Thus, we further propose a unified framework that allows both translation and autoencoding capabilities in a single codec. Adaptive residual blocks conditioned on the translation/compression mode provide flexible adaptation to the desired functionality. The experiments show promising results in both I2I translation and image compression using a single model.  
### **Real-time** End-to-End Video Text Spotter with Contrastive Representation Learning. (arXiv:2207.08417v2 [cs.CV] UPDATED)
- Authors : Wejia Wu, Zhuang Li, Jiahong Li, Chunhua Shen, Hong Zhou, Size Li, Zhongyuan Wang, Ping Luo
- Link : [http://arxiv.org/abs/2207.08417](http://arxiv.org/abs/2207.08417)
> ABSTRACT  :  Video text spotting(VTS) is the task that requires simultaneously detecting, tracking and recognizing text in the video. Existing video text spotting methods typically develop sophisticated pipelines and multiple models, which is not friend for real-time applications. Here we propose a real-time end-to-end video text spotter with Contrastive Representation learning (CoText). Our contributions are three-fold: 1) CoText simultaneously address the three tasks (e.g., text detection, tracking, recognition) in a real-time end-to-end trainable framework. 2) With contrastive learning, CoText models long-range dependencies and learning temporal information across multiple frames. 3) A simple, lightweight architecture is designed for effective and accurate performance, including GPU-parallel detection post-processing, CTC-based recognition head with Masked RoI. Extensive experiments show the superiority of our method. Especially, CoText achieves an video text spotting IDF1 of 72.0% at 41.0 FPS on ICDAR2015video, with 10.5% and 32.0 FPS improvement the previous best method. The code can be found at github.com/weijiawu/CoText.  
### HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions. (arXiv:2207.14284v2 [cs.CV] UPDATED)
- Authors : Yongming Rao, Wenliang Zhao, Yansong Tang, Jie Zhou, Nam Lim, Jiwen Lu
- Link : [http://arxiv.org/abs/2207.14284](http://arxiv.org/abs/2207.14284)
> ABSTRACT  :  Recent progress in vision Transformers exhibits great success in various tasks driven by the new spatial modeling mechanism based on dot-product self-attention. In this paper, we show that the key ingredients behind the vision Transformers, namely input-adaptive, long-range and high-order spatial interactions, can also be efficiently implemented with a convolution-based framework. We present the Recursive Gated Convolution ($\textit{g}^\textit{n}$Conv) that performs high-order spatial interactions with gated convolutions and recursive designs. The new operation is highly flexible and customizable, which is compatible with various variants of convolution and extends the two-order interactions in self-attention to arbitrary orders without introducing significant extra computation. $\textit{g}^\textit{n}$Conv can serve as a plug-and-play module to improve various vision Transformers and convolution-based models. Based on the operation, we construct a new family of generic vision backbones named HorNet. Extensive experiments on ImageNet classification, COCO object detection and ADE20K semantic segmentation show HorNet outperform **Swin** Transformers and ConvNeXt by a significant margin with similar overall architecture and training configurations. HorNet also shows favorable scalability to more training data and a larger model size. Apart from the effectiveness in visual encoders, we also show $\textit{g}^\textit{n}$Conv can be applied to task-specific decoders and consistently improve dense prediction performance with less computation. Our results demonstrate that $\textit{g}^\textit{n}$Conv can be a new basic module for visual modeling that effectively combines the merits of both vision Transformers and CNNs. Code is available at https://github.com/raoyongming/HorNet  
## eess.IV
---
### A Topological Loss Function for **Low-Light** Image Denoising. (arXiv:2208.04573v1 [eess.IV])
- Authors : Alexandra Malyugina, Nantheera Anantrasirichai, David Bull
- Link : [http://arxiv.org/abs/2208.04573](http://arxiv.org/abs/2208.04573)
> ABSTRACT  :  Although image denoising algorithms have attracted significant research attention, surprisingly few have been proposed for, or evaluated on, noise from imagery acquired under real **low-light** conditions. Moreover, noise characteristics are often assumed to be spatially invariant, leading to edges and textures being distorted after denoising. Here, we introduce a novel topological loss function which is based on persistent homology, offering true features with resistance to noise across multiple scales. The method performs in the space of image patches, where topological invariants are calculated and represented in persistent diagrams. The loss function is a combination of $\ell_1$ or $\ell_2$ losses with the new persistence-based topological loss. We compare its performance across popular denoising architectures, training the networks on our new comprehensive dataset of natural images captured in **low-light** conditions -- BVI-LOWLIGHT. Analysis reveals that this approach outperforms existing methods, adapting well to edges and complex structures and suppressing common artifacts.  
### OL-DN: Online learning based dual-domain network for HEVC intra frame quality **enhancement**. (arXiv:2208.04661v1 [eess.IV])
- Authors : Renwei Yang, Shuyuan Zhu, Xiaozhen Zheng, Bing Zeng
- Link : [http://arxiv.org/abs/2208.04661](http://arxiv.org/abs/2208.04661)
> ABSTRACT  :  Convolution neural network (CNN) based methods offer effective solutions for enhancing the quality of compressed image and video. However, these methods ignore using the raw data to enhance the quality. In this paper, we adopt the raw data in the quality **enhancement** for the HEVC intra-coded image by proposing an online learning-based method. When quality **enhancement** is demanded, we online train our proposed model at encoder side and then use the parameters to update the model of decoder side. This method not only improves model performance, but also makes one model adoptable to multiple coding scenarios. Besides, quantization error in discrete cosine transform (DCT) coefficients is the root cause of various HEVC compression artifacts. Thus, we combine frequency domain priors to assist image reconstruction. We design a DCT based convolution layer, to produce DCT coefficients that are suitable for CNN learning. Experimental results show that our proposed online learning based dual-domain network (OL-DN) has achieved superior performance, compared with the state-of-the-art methods.  
### JPD-SE: High-Level Semantics for Joint Perception-Distortion **Enhancement** in Image Compression. (arXiv:2005.12810v3 [eess.IV] UPDATED)
- Authors : Shiyu Duan, Huaijin Chen, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2005.12810](http://arxiv.org/abs/2005.12810)
> ABSTRACT  :  While humans can effortlessly transform complex visual scenes into simple words and the other way around by leveraging their high-level understanding of the content, conventional or the more recent learned image compression codecs do not seem to utilize the semantic meanings of visual content to their full potential. Moreover, they focus mostly on rate-distortion and tend to underperform in perception quality especially in low bitrate regime, and often disregard the performance of downstream computer vision algorithms, which is a fast-growing consumer group of compressed images in addition to human viewers. In this paper, we (1) present a generic framework that can enable any image codec to leverage high-level semantics and (2) study the joint optimization of perception quality and distortion. Our idea is that given any codec, we utilize high-level semantics to augment the low-level visual features extracted by it and produce essentially a new, semantic-aware codec. We propose a three-phase training scheme that teaches semantic-aware codecs to leverage the power of semantic to jointly optimize rate-perception-distortion (R-PD) performance. As an additional benefit, semantic-aware codecs also boost the performance of downstream computer vision algorithms. To validate our claim, we perform extensive empirical evaluations and provide both quantitative and qualitative results.  
### A Novel Framework for Image-to-image Translation and Image Compression. (arXiv:2111.13105v2 [eess.IV] UPDATED)
- Authors : Fei Yang, Yaxing Wang, Luis Herranz, Yongmei Cheng, Mikhail Mozerov
- Link : [http://arxiv.org/abs/2111.13105](http://arxiv.org/abs/2111.13105)
> ABSTRACT  :  Data-driven paradigms using machine learning are becoming ubiquitous in image processing and communications. In particular, image-to-image (I2I) translation is a generic and widely used approach to image processing problems, such as image synthesis, style transfer, and image **restoration**. At the same time, neural image compression has emerged as a data-driven alternative to traditional coding approaches in visual communications. In this paper, we study the combination of these two paradigms into a joint I2I compression and translation framework, focusing on multi-domain image synthesis. We first propose distributed I2I translation by integrating quantization and entropy coding into an I2I translation framework (i.e. I2Icodec). In practice, the image compression functionality (i.e. autoencoding) is also desirable, requiring to deploy alongside I2Icodec a regular image codec. Thus, we further propose a unified framework that allows both translation and autoencoding capabilities in a single codec. Adaptive residual blocks conditioned on the translation/compression mode provide flexible adaptation to the desired functionality. The experiments show promising results in both I2I translation and image compression using a single model.  
## cs.LG
---
### Liquid State Machine-Empowered Reflection Tracking in RIS-Aided THz Communications. (arXiv:2208.04400v1 [cs.LG])
- Authors : Hosein Zarini, Narges Gholipoor, Mohamad Robat, Mehdi Rasti, Hina Tabassum, Ekram Hossain
- Link : [http://arxiv.org/abs/2208.04400](http://arxiv.org/abs/2208.04400)
> ABSTRACT  :  Passive beamforming in reconfigurable intelligent surfaces (RISs) enables a feasible and efficient way of communication when the RIS reflection coefficients are precisely adjusted. In this paper, we present a framework to track the RIS reflection coefficients with the aid of deep learning from a time-series prediction perspective in a terahertz (THz) communication system. The proposed framework achieves a two-step **enhancement** over the similar learning-driven counterparts. Specifically, in the first step, we train a liquid state machine (LSM) to track the historical RIS reflection coefficients at prior time steps (known as a time-series sequence) and predict their upcoming time steps. We also fine-tune the trained LSM through Xavier initialization technique to decrease the prediction variance, thus resulting in a higher prediction accuracy. In the second step, we use ensemble learning technique which leverages on the prediction power of multiple LSMs to minimize the prediction variance and improve the precision of the first step. It is numerically demonstrated that, in the first step, employing the Xavier initialization technique to fine-tune the LSM results in at most 26% lower LSM prediction variance and as much as 46% achievable spectral efficiency (SE) improvement over the existing counterparts, when an RIS of size 11x11 is deployed. In the second step, under the same computational complexity of training a single LSM, the ensemble learning with multiple LSMs degrades the prediction variance of a single LSM up to 66% and improves the system achievable SE at most 54%.  
## cs.AI
---
### Soft Sensors and Process Control using AI and Dynamic Simulation. (arXiv:2208.04373v1 [cs.AI])
- Authors : Shumpei Kubosawa, Takashi Onishi, Yoshimasa Tsuruoka
- Link : [http://arxiv.org/abs/2208.04373](http://arxiv.org/abs/2208.04373)
> ABSTRACT  :  During the operation of a chemical plant, product quality must be consistently maintained, and the production of off-specification products should be minimized. Accordingly, process variables related to the product quality, such as the temperature and composition of materials at various parts of the plant must be measured, and appropriate operations (that is, control) must be performed based on the measurements. Some process variables, such as temperature and flow rate, can be measured continuously and instantaneously. However, other variables, such as composition and viscosity, can only be obtained through time-consuming analysis after sampling substances from the plant. Soft sensors have been proposed for estimating process variables that cannot be obtained in **real time** from easily measurable variables. However, the estimation accuracy of conventional statistical soft sensors, which are constructed from recorded measurements, can be very poor in unrecorded situations (extrapolation). In this study, we estimate the internal state variables of a plant by using a dynamic simulator that can estimate and predict even unrecorded situations on the basis of chemical engineering knowledge and an artificial intelligence (AI) technology called reinforcement learning, and propose to use the estimated internal state variables of a plant as soft sensors. In addition, we describe the prospects for plant operation and control using such soft sensors and the methodology to obtain the necessary prediction models (i.e., simulators) for the proposed system.  
# Paper List
---
## cs.CV
---
**92** new papers in cs.CV:-) 
1. Adaptive Local Implicit Image Function for Arbitrary-scale Super-resolution. (arXiv:2208.04318v1 [eess.IV])
2. Neural Architecture Search as Multiobjective Optimization Benchmarks: Problem Formulation and Performance Assessment. (arXiv:2208.04321v1 [cs.NE])
3. QSAM-Net: Rain streak removal by quaternion neural network with self-attention module. (arXiv:2208.04346v1 [cs.CV])
4. Rethinking Robust Representation Learning Under Fine-grained Noisy Faces. (arXiv:2208.04352v1 [cs.CV])
5. Semi-Supervised Cross-Modal Salient Object Detection with U-Structure Networks. (arXiv:2208.04361v1 [cs.CV])
6. Learning to Identify Drilling Defects in Turbine Blades with Single Stage Detectors. (arXiv:2208.04363v1 [cs.CV])
7. Understanding Weight Similarity of Neural Networks via Chain Normalization Rule and Hypothesis-Training-Testing. (arXiv:2208.04369v1 [cs.LG])
8. Contrast-Phys: Unsupervised Video-based Remote Physiological Measurement via Spatiotemporal Contrast. (arXiv:2208.04378v1 [cs.CV])
9. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v1 [cs.CV])
10. Occlusion-Aware Instance Segmentation via BiLayer Network Architectures. (arXiv:2208.04438v1 [cs.CV])
11. Txt2Img-MHN: Remote Sensing Image Generation from Text Using Modern Hopfield Networks. (arXiv:2208.04441v1 [cs.CV])
12. NeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks. (arXiv:2208.04448v1 [cs.LG])
13. In the Eye of Transformer: Global-Local Correlation for Egocentric Gaze Estimation. (arXiv:2208.04464v1 [cs.CV])
14. Synthetic Aperture Radar Image Change Detection via Layer Attention-Based Noise-Tolerant Network. (arXiv:2208.04481v1 [eess.IV])
15. Speaker-adaptive Lip Reading with User-dependent Padding. (arXiv:2208.04498v1 [cs.CV])
16. Unsupervised Domain Adaptation for Point Cloud Semantic Segmentation via Graph Matching. (arXiv:2208.04510v1 [cs.CV])
17. Object Detection with Deep Reinforcement Learning. (arXiv:2208.04511v1 [cs.CV])
18. Attribute Controllable Beautiful Caucasian Face Generation by Aesthetics Driven Reinforcement Learning. (arXiv:2208.04517v1 [cs.CV])
19. Aesthetic Attributes Assessment of Images with AMANv2 and DPC-CaptionsV2. (arXiv:2208.04522v1 [cs.CV])
20. Using Large Context for Kidney Multi-Structure Segmentation from CTA Images. (arXiv:2208.04525v1 [eess.IV])
21. VectorFlow: Combining Images and Vectors for Traffic Occupancy and Flow Prediction. (arXiv:2208.04530v1 [cs.CV])
22. Inconsistencies in Measuring Student Engagement in Virtual Learning -- A Critical Review. (arXiv:2208.04548v1 [cs.HC])
23. Disentangled Representation Learning Using ($\beta$-)VAE and GAN. (arXiv:2208.04549v1 [cs.CV])
24. Multi-target Tracking of Zebrafish based on Particle Filter. (arXiv:2208.04553v1 [cs.CV])
25. Hierarchical Residual Learning Based Vector Quantized Variational Autoencoder for Image Reconstruction and Generation. (arXiv:2208.04554v1 [cs.CV])
26. SBPF: Sensitiveness Based Pruning Framework For Convolutional Neural Network On Image Classification. (arXiv:2208.04588v1 [cs.CV])
27. Comparison of semi-supervised learning methods for High Content Screening quality control. (arXiv:2208.04592v1 [cs.CV])
28. Generative models-based data labeling for deep networks regression: application to seed maturity estimation from UAV multispectral images. (arXiv:2208.04611v1 [cs.CV])
29. Res-Dense Net for 3D Covid Chest CT-scan classification. (arXiv:2208.04613v1 [eess.IV])
30. Classification of electromagnetic interference induced image noise in an analog video link. (arXiv:2208.04614v1 [cs.CV])
31. EfficientNet for Brain-Lesion classification. (arXiv:2208.04616v1 [eess.IV])
32. RDA: Reciprocal Distribution Alignment for Robust SSL. (arXiv:2208.04619v1 [cs.LG])
33. Efficient Out-of-Distribution Detection of Melanoma with Wavelet-based Normalizing Flows. (arXiv:2208.04639v1 [cs.CV])
34. Choose qualified instructor for university based on rule-based weighted expert system. (arXiv:2208.04657v1 [cs.AI])
35. OL-DN: Online learning based dual-domain network for HEVC intra frame quality **enhancement**. (arXiv:2208.04661v1 [eess.IV])
36. Improved Multiple-Image-Based Reflection Removal Algorithm Using Deep Neural Networks. (arXiv:2208.04679v1 [eess.IV])
37. Boundary Distance Loss for Intra-/Extra-meatal Segmentation of Vestibular Schwannoma. (arXiv:2208.04680v1 [eess.IV])
38. How Well Do Vision Transformers (VTs) Transfer To The Non-Natural Image Domain? An Empirical Study Involving Art Classification. (arXiv:2208.04693v1 [cs.CV])
39. COROID: A Crowdsourcing-based Companion Drones to Tackle Current and Future Pandemics. (arXiv:2208.04704v1 [cs.CY])
40. HRF-Net: Holistic Radiance Fields from Sparse Inputs. (arXiv:2208.04717v1 [cs.CV])
41. Improving COVID-19 CT Classification of CNNs by Learning Parameter-Efficient Representation. (arXiv:2208.04718v1 [eess.IV])
42. Deep Patch Visual Odometry. (arXiv:2208.04726v1 [cs.CV])
43. Aesthetic Language Guidance Generation of Images Using Attribute Comparison. (arXiv:2208.04740v1 [cs.CV])
44. Semantic Segmentation-Assisted Instance Feature Fusion for Multi-Level 3D Part Instance Segmentation. (arXiv:2208.04766v1 [cs.CV])
45. HyperNST: Hyper-Networks for Neural Style Transfer. (arXiv:2208.04807v1 [cs.CV])
46. Longitudinal Prediction of Postnatal Brain Magnetic Resonance Images via a Metamorphic Generative Adversarial Network. (arXiv:2208.04825v1 [eess.IV])
47. From Scratch to Sketch: Deep Decoupled Hierarchical Reinforcement Learning for Robotic Sketching Agent. (arXiv:2208.04833v1 [cs.RO])
48. sim2real: Cardiac MR Image Simulation-to-Real Translation via Unsupervised GANs. (arXiv:2208.04874v1 [eess.IV])
49. Localizing the conceptual difference of two scenes using deep learning for house keeping usages. (arXiv:2208.04884v1 [cs.CV])
50. Sports Video Analysis on Large-Scale Data. (arXiv:2208.04897v1 [cs.CV])
51. Deep Learning-Based Objective and Reproducible Osteosarcoma Chemotherapy Response Assessment and Outcome Prediction. (arXiv:2208.04910v1 [cs.CV])
52. TSRFormer: Table Structure Recognition with Transformers. (arXiv:2208.04921v1 [cs.CV])
53. JPD-SE: High-Level Semantics for Joint Perception-Distortion **Enhancement** in Image Compression. (arXiv:2005.12810v3 [eess.IV] UPDATED)
54. EAN: Event Adaptive Network for Enhanced Action Recognition. (arXiv:2107.10771v2 [cs.CV] UPDATED)
55. A Novel Framework for Image-to-image Translation and Image Compression. (arXiv:2111.13105v2 [eess.IV] UPDATED)
56. Specificity-Preserving Federated Learning for MR Image Reconstruction. (arXiv:2112.05752v2 [eess.IV] UPDATED)
57. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v3 [cs.CV] UPDATED)
58. Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data. (arXiv:2201.04569v3 [cs.CR] UPDATED)
59. A Survey on RGB-D Datasets. (arXiv:2201.05761v2 [cs.CV] UPDATED)
60. K-Means for Noise-Insensitive Multi-Dimensional Feature Learning. (arXiv:2202.07754v3 [cs.CV] UPDATED)
61. Instance-aware multi-object self-supervision for monocular depth prediction. (arXiv:2203.00809v2 [cs.CV] UPDATED)
62. The Unsurprising Effectiveness of Pre-Trained Vision Models for Control. (arXiv:2203.03580v2 [cs.CV] UPDATED)
63. ChiTransformer:Towards Reliable Stereo from Cues. (arXiv:2203.04554v3 [cs.CV] UPDATED)
64. Unsupervised Learning Based Focal Stack Camera Depth Estimation. (arXiv:2203.07904v2 [eess.IV] UPDATED)
65. A Real World Dataset for Multi-view 3D Reconstruction. (arXiv:2203.11397v2 [cs.CV] UPDATED)
66. CP2: Copy-Paste Contrastive Pretraining for Semantic Segmentation. (arXiv:2203.11709v2 [cs.CV] UPDATED)
67. FindIt: Generalized Localization with Natural Language Queries. (arXiv:2203.17273v2 [cs.CV] UPDATED)
68. Streaming Multiscale Deep Equilibrium Models. (arXiv:2204.13492v3 [cs.CV] UPDATED)
69. Towards Individual Grevy's Zebra Identification via Deep 3D Fitting and Metric Learning. (arXiv:2206.02261v3 [cs.CV] UPDATED)
70. GLF-CR: SAR-Enhanced Cloud Removal with Global-Local Fusion. (arXiv:2206.02850v3 [cs.CV] UPDATED)
71. The Missing Link: Finding label relations across datasets. (arXiv:2206.04453v2 [cs.CV] UPDATED)
72. PR-DARTS: Pruning-Based Differentiable Architecture Search. (arXiv:2207.06968v2 [cs.CV] UPDATED)
73. Convolutional Bypasses Are Better Vision Transformer Adapters. (arXiv:2207.07039v3 [cs.CV] UPDATED)
74. WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation. (arXiv:2207.07288v2 [cs.CV] UPDATED)
75. MDM: Multiple Dynamic Masks for Visual Explanation of Neural Networks. (arXiv:2207.08046v4 [cs.CV] UPDATED)
76. **Real-time** End-to-End Video Text Spotter with Contrastive Representation Learning. (arXiv:2207.08417v2 [cs.CV] UPDATED)
77. Segmenting white matter hyperintensities on isotropic three-dimensional Fluid Attenuated Inversion Recovery magnetic resonance images: A comparison of Deep learning tools on a Norwegian national imaging database. (arXiv:2207.08467v3 [eess.IV] UPDATED)
78. Grounding Visual Representations with Texts for Domain Generalization. (arXiv:2207.10285v2 [cs.CV] UPDATED)
79. Class-Aware Universum Inspired Re-Balance Learning for Long-Tailed Recognition. (arXiv:2207.12808v2 [cs.CV] UPDATED)
80. Post-Train Adaptive MobileNet for Fast Anti-Spoofing. (arXiv:2207.13410v2 [cs.CV] UPDATED)
81. HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions. (arXiv:2207.14284v2 [cs.CV] UPDATED)
82. Image-based Contextual Pill Recognition with Medical Knowledge Graph Assistance. (arXiv:2208.02432v2 [cs.CV] UPDATED)
83. UTOPIC: Uncertainty-aware Overlap Prediction Network for Partial Point Cloud Registration. (arXiv:2208.02712v3 [cs.CV] UPDATED)
84. LaTTe: Language Trajectory TransformEr. (arXiv:2208.02918v2 [cs.RO] UPDATED)
85. Discover the Mysteries of the Maya: Selected Contributions from the Machine Learning Challenge & The Discovery Challenge Workshop at ECML PKDD 2021. (arXiv:2208.03163v2 [cs.CV] UPDATED)
86. Shap-CAM: Visual Explanations for Convolutional Neural Networks based on Shapley Value. (arXiv:2208.03608v2 [cs.CV] UPDATED)
87. See What You See: Self-supervised Cross-modal Retrieval of Visual Stimuli from Brain Activity. (arXiv:2208.03666v2 [cs.MM] UPDATED)
88. Eight Years of Face Recognition Research: Reproducibility, Achievements and Open Issues. (arXiv:2208.04040v2 [cs.CV] UPDATED)
89. Boosting Video-Text Retrieval with Explicit High-Level Semantics. (arXiv:2208.04215v2 [cs.CV] UPDATED)
90. Spherical formulation of geometric motion segmentation constraints in fisheye cameras. (arXiv:2104.12404v1 [cs.CV] CROSS LISTED)
91. Learning Generalizable Light Field Networks from Few Images. (arXiv:2207.11757v1 [cs.CV] CROSS LISTED)
92. Smart Explorer: Recognizing Objects in Dense Clutter via Interactive Exploration. (arXiv:2208.03496v1 [cs.RO] CROSS LISTED)
## eess.IV
---
**26** new papers in eess.IV:-) 
1. Adaptive Local Implicit Image Function for Arbitrary-scale Super-resolution. (arXiv:2208.04318v1 [eess.IV])
2. Learning to Identify Drilling Defects in Turbine Blades with Single Stage Detectors. (arXiv:2208.04363v1 [cs.CV])
3. Synthetic Aperture Radar Image Change Detection via Layer Attention-Based Noise-Tolerant Network. (arXiv:2208.04481v1 [eess.IV])
4. Speaker-adaptive Lip Reading with User-dependent Padding. (arXiv:2208.04498v1 [cs.CV])
5. Using Large Context for Kidney Multi-Structure Segmentation from CTA Images. (arXiv:2208.04525v1 [eess.IV])
6. Disentangled Representation Learning Using ($\beta$-)VAE and GAN. (arXiv:2208.04549v1 [cs.CV])
7. A Topological Loss Function for **Low-Light** Image Denoising. (arXiv:2208.04573v1 [eess.IV])
8. Res-Dense Net for 3D Covid Chest CT-scan classification. (arXiv:2208.04613v1 [eess.IV])
9. EfficientNet for Brain-Lesion classification. (arXiv:2208.04616v1 [eess.IV])
10. OL-DN: Online learning based dual-domain network for HEVC intra frame quality **enhancement**. (arXiv:2208.04661v1 [eess.IV])
11. Improved Multiple-Image-Based Reflection Removal Algorithm Using Deep Neural Networks. (arXiv:2208.04679v1 [eess.IV])
12. Boundary Distance Loss for Intra-/Extra-meatal Segmentation of Vestibular Schwannoma. (arXiv:2208.04680v1 [eess.IV])
13. Improving COVID-19 CT Classification of CNNs by Learning Parameter-Efficient Representation. (arXiv:2208.04718v1 [eess.IV])
14. Longitudinal Prediction of Postnatal Brain Magnetic Resonance Images via a Metamorphic Generative Adversarial Network. (arXiv:2208.04825v1 [eess.IV])
15. Imaging-based representation and stratification of intra-tumor Heterogeneity via tree-edit distance. (arXiv:2208.04829v1 [stat.ME])
16. sim2real: Cardiac MR Image Simulation-to-Real Translation via Unsupervised GANs. (arXiv:2208.04874v1 [eess.IV])
17. JPD-SE: High-Level Semantics for Joint Perception-Distortion **Enhancement** in Image Compression. (arXiv:2005.12810v3 [eess.IV] UPDATED)
18. A Novel Framework for Image-to-image Translation and Image Compression. (arXiv:2111.13105v2 [eess.IV] UPDATED)
19. Specificity-Preserving Federated Learning for MR Image Reconstruction. (arXiv:2112.05752v2 [eess.IV] UPDATED)
20. Fast and High-Quality Image Denoising via Malleable Convolutions. (arXiv:2201.00392v3 [cs.CV] UPDATED)
21. SSCU-Net: Spatial-Spectral Collaborative Unmixing Network for Hyperspectral Images. (arXiv:2203.06375v2 [eess.IV] UPDATED)
22. Unsupervised Learning Based Focal Stack Camera Depth Estimation. (arXiv:2203.07904v2 [eess.IV] UPDATED)
23. GLF-CR: SAR-Enhanced Cloud Removal with Global-Local Fusion. (arXiv:2206.02850v3 [cs.CV] UPDATED)
24. High-fidelity intensity diffraction tomography with a non-paraxial multiple-scattering model. (arXiv:2207.06532v2 [physics.optics] UPDATED)
25. WaveGAN: Frequency-aware GAN for High-Fidelity Few-shot Image Generation. (arXiv:2207.07288v2 [cs.CV] UPDATED)
26. Segmenting white matter hyperintensities on isotropic three-dimensional Fluid Attenuated Inversion Recovery magnetic resonance images: A comparison of Deep learning tools on a Norwegian national imaging database. (arXiv:2207.08467v3 [eess.IV] UPDATED)
## cs.LG
---
**139** new papers in cs.LG:-) 
1. NRBdMF: A recommendation algorithm for predicting drug effects considering directionality. (arXiv:2208.04312v1 [q-bio.QM])
2. AUTOSHAPE: An Autoencoder-Shapelet Approach for Time Series Clustering. (arXiv:2208.04313v1 [cs.LG])
3. TripHLApan: predicting HLA molecules binding peptides based on triple coding matrix and transfer learning. (arXiv:2208.04314v1 [q-bio.QM])
4. Patient-Specific Game-Based Transfer Method for Parkinson's Disease Severity Prediction. (arXiv:2208.04315v1 [cs.LG])
5. An example of use of Variational Methods in Quantum Machine Learning. (arXiv:2208.04316v1 [quant-ph])
6. Implementation of fast ICA using memristor crossbar arrays for blind image source separations. (arXiv:2208.04317v1 [cs.ET])
7. Adaptive Local Implicit Image Function for Arbitrary-scale Super-resolution. (arXiv:2208.04318v1 [eess.IV])
8. PhyGNNet: Solving spatiotemporal PDEs with Physics-informed Graph Neural Network. (arXiv:2208.04319v1 [cs.NE])
9. Learning-Based Client Selection for Federated Learning Services Over Wireless Networks with Constrained Monetary Budgets. (arXiv:2208.04322v1 [cs.LG])
10. Partial Least Square Regression via Three-factor SVD-type Manifold Optimization for EEG Decoding. (arXiv:2208.04324v1 [cs.LG])
11. EFI: A Toolbox for Feature Importance Fusion and Interpretation in Python. (arXiv:2208.04343v1 [cs.LG])
12. A Visual Analytics System for Improving Attention-based Traffic Forecasting Models. (arXiv:2208.04350v1 [cs.HC])
13. Learning to Learn to Predict Performance Regressions in Production at Meta. (arXiv:2208.04351v1 [cs.SE])
14. SDWPF: A Dataset for Spatial Dynamic Wind Power Forecasting Challenge at KDD Cup 2022. (arXiv:2208.04360v1 [cs.LG])
15. Gradient Flows for L2 Support Vector Machine Training. (arXiv:2208.04365v1 [cs.LG])
16. Understanding Weight Similarity of Neural Networks via Chain Normalization Rule and Hypothesis-Training-Testing. (arXiv:2208.04369v1 [cs.LG])
17. Generalization and Overfitting in Matrix Product State Machine Learning Architectures. (arXiv:2208.04372v1 [cs.LG])
18. On Taking Advantage of Opportunistic Meta-knowledge to Reduce Configuration Spaces for Automated Machine Learning. (arXiv:2208.04376v1 [cs.LG])
19. Liquid State Machine-Empowered Reflection Tracking in RIS-Aided THz Communications. (arXiv:2208.04400v1 [cs.LG])
20. Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach. (arXiv:2208.04405v1 [cs.LG])
21. Controlled Sparsity via Constrained Optimization or: How I Learned to Stop Tuning Penalties and Love Constraints. (arXiv:2208.04425v1 [cs.LG])
22. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v1 [cs.CV])
23. NeuralVDB: High-resolution Sparse Volume Representation using Hierarchical Neural Networks. (arXiv:2208.04448v1 [cs.LG])
24. A Theoretical View on Sparsely Activated Networks. (arXiv:2208.04461v1 [cs.LG])
25. Optimal scheduling of entropy regulariser for continuous-time linear-quadratic reinforcement learning. (arXiv:2208.04466v1 [cs.LG])
26. Deep Maxout Network Gaussian Process. (arXiv:2208.04468v1 [stat.ML])
27. A Time-to-first-spike Coding and Conversion Aware Training for Energy-Efficient Deep Spiking Neural Network Processor Design. (arXiv:2208.04494v1 [cs.NE])
28. EAFL: Towards Energy-Aware Federated Learning on Battery-Powered Edge Devices. (arXiv:2208.04505v1 [cs.LG])
29. Second Order Ensemble Langevin Method for Sampling and Inverse Problems. (arXiv:2208.04506v1 [math.DS])
30. Training Overparametrized Neural Networks in Sublinear Time. (arXiv:2208.04508v1 [cs.LG])
31. Multiple Instance Neural Networks Based on Sparse Attention for Cancer Detection using T-cell Receptor Sequences. (arXiv:2208.04524v1 [stat.ML])
32. Motif-based Graph Representation Learning with Application to Chemical Molecules. (arXiv:2208.04529v1 [cs.LG])
33. Automating DBSCAN via Deep Reinforcement Learning. (arXiv:2208.04537v1 [cs.LG])
34. Disentangled Representation Learning Using ($\beta$-)VAE and GAN. (arXiv:2208.04549v1 [cs.CV])
35. Hierarchical Residual Learning Based Vector Quantized Variational Autoencoder for Image Reconstruction and Generation. (arXiv:2208.04554v1 [cs.CV])
36. Analyzing and Enhancing Closed-loop Stability in Reactive Simulation. (arXiv:2208.04559v1 [cs.RO])
37. Statistical Properties of the log-cosh Loss Function Used in Machine Learning. (arXiv:2208.04564v1 [stat.ML])
38. Adaptive Zeroth-Order Optimisation of Nonconvex Composite Objectives. (arXiv:2208.04579v1 [math.OC])
39. More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference. (arXiv:2208.04580v1 [cs.LG])
40. Long-term Causal Effects Estimation via Latent Surrogates Representation Learning. (arXiv:2208.04589v1 [cs.LG])
41. Stronger Privacy Amplification by Shuffling for R\'enyi and Approximate Differential Privacy. (arXiv:2208.04591v1 [cs.CR])
42. Comparison of semi-supervised learning methods for High Content Screening quality control. (arXiv:2208.04592v1 [cs.CV])
43. IDNP: Interest Dynamics Modeling using Generative Neural Processes for Sequential Recommendation. (arXiv:2208.04600v1 [cs.IR])
44. E2EG: End-to-End Node Classification Using Graph Topology and Text-based Node Attributes. (arXiv:2208.04609v1 [cs.LG])
45. LAMDA-SSL: Semi-Supervised Learning in Python. (arXiv:2208.04610v1 [cs.LG])
46. Generative models-based data labeling for deep networks regression: application to seed maturity estimation from UAV multispectral images. (arXiv:2208.04611v1 [cs.CV])
47. Res-Dense Net for 3D Covid Chest CT-scan classification. (arXiv:2208.04613v1 [eess.IV])
48. EfficientNet for Brain-Lesion classification. (arXiv:2208.04616v1 [eess.IV])
49. RDA: Reciprocal Distribution Alignment for Robust SSL. (arXiv:2208.04619v1 [cs.LG])
50. Cascade-based Echo Chamber Detection. (arXiv:2208.04620v1 [cs.SI])
51. Causal Discovery in Probabilistic Networks with an Identifiable Causal Effect. (arXiv:2208.04627v1 [cs.LG])
52. A Means-End Account of Explainable Artificial Intelligence. (arXiv:2208.04638v1 [cs.AI])
53. Extending GCC-PHAT using Shift Equivariant Neural Networks. (arXiv:2208.04654v1 [eess.AS])
54. Application of federated learning in manufacturing. (arXiv:2208.04664v1 [cs.LG])
55. Representation learning of rare temporal conditions for travel time prediction. (arXiv:2208.04667v1 [stat.ML])
56. Boundary Distance Loss for Intra-/Extra-meatal Segmentation of Vestibular Schwannoma. (arXiv:2208.04680v1 [eess.IV])
57. Applying data technologies to combat AMR: current status, challenges, and opportunities on the way forward. (arXiv:2208.04683v1 [cs.CY])
58. COROID: A Crowdsourcing-based Companion Drones to Tackle Current and Future Pandemics. (arXiv:2208.04704v1 [cs.CY])
59. Classification of Stress via Ambulatory ECG and GSR Data. (arXiv:2208.04705v1 [cs.CY])
60. Context sequence theory: a common explanation for multiple types of learning. (arXiv:2208.04707v1 [q-bio.NC])
61. Towards a General Pre-training Framework for Adaptive Learning in MOOCs. (arXiv:2208.04708v1 [cs.CY])
62. Areas of Strategic Visibility: Disability Bias in Biometrics. (arXiv:2208.04712v1 [cs.CY])
63. Computationally Identifying Funneling and Focusing Questions in Classroom Discourse. (arXiv:2208.04715v1 [cs.CY])
64. Clustering Optimisation Method for Highly Connected Biological Data. (arXiv:2208.04720v1 [q-bio.QM])
65. Efficient Novelty Detection Methods for Early Warning of Potential Fatal Diseases. (arXiv:2208.04732v1 [cs.CY])
66. Combining Variational Modeling with Partial Gradient Perturbation to Prevent Deep Gradient Leakage. (arXiv:2208.04767v1 [cs.LG])
67. Learning Mean-Field Control for Delayed Information Load Balancing in Large Queuing Systems. (arXiv:2208.04777v1 [cs.DC])
68. Exploring the trade off between human driving imitation and safety for traffic simulation. (arXiv:2208.04803v1 [cs.LG])
69. An Unconstrained Symmetric Nonnegative Latent Factor Analysis for Large-scale Undirected Weighted Networks. (arXiv:2208.04811v1 [cs.LG])
70. Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v1 [cs.LG])
71. Global Evaluation for Decision Tree Learning. (arXiv:2208.04828v1 [cs.LG])
72. On the Importance of Critical Period in Multi-stage Reinforcement Learning. (arXiv:2208.04832v1 [cs.AI])
73. Risk-averse Stochastic Optimization for Farm Management Practices and Cultivar Selection Under Uncertainty. (arXiv:2208.04840v1 [math.OC])
74. Quantization enabled Privacy Protection in Decentralized Stochastic Optimization. (arXiv:2208.04845v1 [math.OC])
75. Mining Reaction and Diffusion Dynamics in Social Activities. (arXiv:2208.04846v1 [cs.SI])
76. Graph neural networks for the prediction of molecular structure-property relationships. (arXiv:2208.04852v1 [q-bio.BM])
77. Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA. (arXiv:2208.04854v1 [cs.AR])
78. Deep Probabilistic Models for Forward and Inverse Problems in Parametric PDEs. (arXiv:2208.04856v1 [stat.ML])
79. Neural-Rendezvous: Learning-based Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v1 [cs.RO])
80. Intrinsically Motivated Learning of Causal World Models. (arXiv:2208.04892v1 [cs.AI])
81. Basis for Intentions: Efficient Inverse Reinforcement Learning using Past Experience. (arXiv:2208.04919v1 [cs.LG])
82. On the Activation Function Dependence of the Spectral Bias of Neural Networks. (arXiv:2208.04924v1 [cs.LG])
83. Literature Review: Graph Kernels in Chemoinformatics. (arXiv:2208.04929v1 [stat.ML])
84. Simplified State Space Layers for Sequence Modeling. (arXiv:2208.04933v1 [cs.LG])
85. A Bayesian Bradley-Terry model to compare multiple ML algorithms on multiple data sets. (arXiv:2208.04935v1 [cs.LG])
86. Boosting Simple Learners. (arXiv:2001.11704v5 [cs.LG] UPDATED)
87. Learning from Sparse Demonstrations. (arXiv:2008.02159v3 [cs.RO] UPDATED)
88. Machine Learning in Event-Triggered Control: Recent Advances and Open Issues. (arXiv:2009.12783v2 [eess.SY] UPDATED)
89. Representation learning for maximization of MI, nonlinear ICA and nonlinear subspaces with robust density ratio estimation. (arXiv:2101.02083v2 [cs.LG] UPDATED)
90. Training Deep Architectures Without End-to-End Backpropagation: A Survey on the Provably Optimal Methods. (arXiv:2101.03419v3 [cs.LG] UPDATED)
91. Hierarchical Reinforcement Learning By Discovering Intrinsic Options. (arXiv:2101.06521v3 [cs.LG] UPDATED)
92. Reinforcement Learning for Freight Booking Control Problems. (arXiv:2102.00092v2 [math.OC] UPDATED)
93. Deep Learning for Android Malware Defenses: a Systematic Literature Review. (arXiv:2103.05292v3 [cs.CR] UPDATED)
94. Labels, Information, and Computation: Efficient Learning Using Sufficient Labels. (arXiv:2104.09015v2 [cs.LG] UPDATED)
95. RoFormer: Enhanced Transformer with Rotary Position Embedding. (arXiv:2104.09864v4 [cs.CL] UPDATED)
96. Predicting Intraoperative Hypoxemia with Hybrid Inference Sequence Autoencoder Networks. (arXiv:2104.14756v5 [cs.LG] UPDATED)
97. Implicit differentiation for fast hyperparameter selection in non-smooth convex learning. (arXiv:2105.01637v3 [stat.ML] UPDATED)
98. Multiple Kernel Representation Learning on Networks. (arXiv:2106.05057v2 [cs.SI] UPDATED)
99. Test for non-negligible adverse shifts. (arXiv:2107.02990v4 [stat.ML] UPDATED)
100. Low-Complexity Algorithm for Restless Bandits with Imperfect Observations. (arXiv:2108.03812v2 [cs.LG] UPDATED)
101. The application of adaptive minimum match k-nearest neighbors to identify at-risk students in health professions education. (arXiv:2108.07709v3 [cs.CY] UPDATED)
102. Wasserstein Generative Adversarial Uncertainty Quantification in Physics-Informed Neural Networks. (arXiv:2108.13054v2 [math.NA] UPDATED)
103. Satisficing Paths and Independent Multi-Agent Reinforcement Learning in Stochastic Games. (arXiv:2110.04638v3 [cs.GT] UPDATED)
104. The Rich Get Richer: Disparate Impact of Semi-Supervised Learning. (arXiv:2110.06282v3 [cs.LG] UPDATED)
105. Comparison of Markov chains via weak Poincar\'e inequalities with application to pseudo-marginal MCMC. (arXiv:2112.05605v2 [stat.CO] UPDATED)
106. Risk and optimal policies in bandit experiments. (arXiv:2112.06363v9 [econ.EM] UPDATED)
107. Expression might be enough: representing pressure and demand for reinforcement learning based traffic signal control. (arXiv:2112.10107v3 [cs.AI] UPDATED)
108. Consistent Approximations in Composite Optimization. (arXiv:2201.05250v2 [math.OC] UPDATED)
109. A causal model of safety assurance for machine learning. (arXiv:2201.05451v3 [cs.SE] UPDATED)
110. DDPG-Driven Deep-Unfolding with Adaptive Depth for Channel Estimation with Sparse Bayesian Learning. (arXiv:2201.08477v2 [eess.SP] UPDATED)
111. Multiple Similarity Drug-Target Interaction Prediction with Random Walks and Matrix Factorization. (arXiv:2201.09508v2 [q-bio.QM] UPDATED)
112. Rank List Sensitivity of Recommender Systems to Interaction Perturbations. (arXiv:2201.12686v2 [cs.IR] UPDATED)
113. A Novel Ontology-guided Attribute Partitioning Ensemble Learning Model for Early Prediction of Cognitive Deficits using Quantitative Structural MRI in Very Preterm Infants. (arXiv:2202.04134v2 [cs.LG] UPDATED)
114. PPA: Preference Profiling Attack Against Federated Learning. (arXiv:2202.04856v2 [cs.LG] UPDATED)
115. Monotone Learning. (arXiv:2202.05246v2 [cs.LG] UPDATED)
116. Formalization of a Stochastic Approximation Theorem. (arXiv:2202.05959v2 [cs.LO] UPDATED)
117. An optimal scheduled learning rate for a randomized Kaczmarz algorithm. (arXiv:2202.12224v4 [math.NA] UPDATED)
118. The Unsurprising Effectiveness of Pre-Trained Vision Models for Control. (arXiv:2203.03580v2 [cs.CV] UPDATED)
119. Unsupervised Learning Based Focal Stack Camera Depth Estimation. (arXiv:2203.07904v2 [eess.IV] UPDATED)
120. Overcoming challenges in leveraging GANs for few-shot data augmentation. (arXiv:2203.16662v3 [stat.ML] UPDATED)
121. Maze Learning using a Hyperdimensional Predictive Processing Cognitive Architecture. (arXiv:2204.00619v2 [cs.AI] UPDATED)
122. Causality, Causal Discovery, and Causal Inference in Structural Engineering. (arXiv:2204.01543v3 [cs.LG] UPDATED)
123. Measurement-based Admission Control in Sliced Networks: A Best Arm Identification Approach. (arXiv:2204.06910v2 [cs.NI] UPDATED)
124. The Sufficiency of Off-policyness and Soft Clipping: PPO is insufficient according to an Off-policy Measure. (arXiv:2205.10047v5 [cs.LG] UPDATED)
125. Open-environment Machine Learning. (arXiv:2206.00423v2 [cs.LG] UPDATED)
126. Towards Individual Grevy's Zebra Identification via Deep 3D Fitting and Metric Learning. (arXiv:2206.02261v3 [cs.CV] UPDATED)
127. Unsupervised Recognition of Informative Features via Tensor Network Machine Learning and Quantum Entanglement Variations. (arXiv:2207.06031v2 [quant-ph] UPDATED)
128. Grounding Visual Representations with Texts for Domain Generalization. (arXiv:2207.10285v2 [cs.CV] UPDATED)
129. Information We Can Extract About a User From 'One Minute Mobile Application Usage'. (arXiv:2207.13222v2 [cs.LG] UPDATED)
130. Post-Train Adaptive MobileNet for Fast Anti-Spoofing. (arXiv:2207.13410v2 [cs.CV] UPDATED)
131. HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein Language Model as an Alternative. (arXiv:2207.13921v2 [q-bio.BM] UPDATED)
132. MULTIPAR: Supervised Irregular Tensor Factorization with Multi-task Learning. (arXiv:2208.00993v2 [cs.LG] UPDATED)
133. Machine learning optimization of Majorana hybrid nanowires. (arXiv:2208.02182v2 [cond-mat.mes-hall] UPDATED)
134. Visual Analysis and Detection of Contrails in Aircraft Engine Simulations. (arXiv:2208.02321v2 [cs.HC] UPDATED)
135. LaTTe: Language Trajectory TransformEr. (arXiv:2208.02918v2 [cs.RO] UPDATED)
136. Discover the Mysteries of the Maya: Selected Contributions from the Machine Learning Challenge & The Discovery Challenge Workshop at ECML PKDD 2021. (arXiv:2208.03163v2 [cs.CV] UPDATED)
137. Interpretable Uncertainty Quantification in AI for HEP. (arXiv:2208.03284v2 [hep-ex] UPDATED)
138. The Influence of Network Structural Preference on Node Classification and Link Prediction. (arXiv:2208.03712v2 [cs.LG] UPDATED)
139. Rapid Flow Behavior Modeling of Thermal Interface Materials Using Deep Neural Networks. (arXiv:2208.04045v2 [cs.LG] UPDATED)
## cs.AI
---
**67** new papers in cs.AI:-) 
1. AUTOSHAPE: An Autoencoder-Shapelet Approach for Time Series Clustering. (arXiv:2208.04313v1 [cs.LG])
2. Patient-Specific Game-Based Transfer Method for Parkinson's Disease Severity Prediction. (arXiv:2208.04315v1 [cs.LG])
3. Adaptive Local Implicit Image Function for Arbitrary-scale Super-resolution. (arXiv:2208.04318v1 [eess.IV])
4. Learning-Based Client Selection for Federated Learning Services Over Wireless Networks with Constrained Monetary Budgets. (arXiv:2208.04322v1 [cs.LG])
5. Soft Sensors and Process Control using AI and Dynamic Simulation. (arXiv:2208.04373v1 [cs.AI])
6. Deep Learning Driven Natural Languages Text to SQL Query Conversion: A Survey. (arXiv:2208.04415v1 [cs.CL])
7. Debiased Large Language Models Still Associate Muslims with Uniquely Violent Acts. (arXiv:2208.04417v1 [cs.CL])
8. What are Your Powers? -- Truth Set Algebras. (arXiv:2208.04422v1 [cs.AI])
9. Bayesian Pseudo Labels: Expectation Maximization for Robust and Efficient Semi-Supervised Segmentation. (arXiv:2208.04435v1 [cs.CV])
10. Denoising Induction Motor Sounds Using an Autoencoder. (arXiv:2208.04462v1 [cs.SD])
11. Speaker-adaptive Lip Reading with User-dependent Padding. (arXiv:2208.04498v1 [cs.CV])
12. Object Detection with Deep Reinforcement Learning. (arXiv:2208.04511v1 [cs.CV])
13. VectorFlow: Combining Images and Vectors for Traffic Occupancy and Flow Prediction. (arXiv:2208.04530v1 [cs.CV])
14. High Recall Data-to-text Generation with Progressive Edit. (arXiv:2208.04558v1 [cs.CL])
15. Analyzing and Enhancing Closed-loop Stability in Reactive Simulation. (arXiv:2208.04559v1 [cs.RO])
16. Multi-Task Fusion via Reinforcement Learning for Long-Term User Satisfaction in Recommender Systems. (arXiv:2208.04560v1 [cs.IR])
17. Effects of Annotations' Density on Named Entity Recognition Models' Performance in the Context of African Languages. (arXiv:2208.04568v1 [cs.CL])
18. More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference. (arXiv:2208.04580v1 [cs.LG])
19. SBPF: Sensitiveness Based Pruning Framework For Convolutional Neural Network On Image Classification. (arXiv:2208.04588v1 [cs.CV])
20. Long-term Causal Effects Estimation via Latent Surrogates Representation Learning. (arXiv:2208.04589v1 [cs.LG])
21. Using Sentence Embeddings and Semantic Similarity for Seeking Consensus when Assessing Trustworthy AI. (arXiv:2208.04608v1 [cs.IR])
22. A Means-End Account of Explainable Artificial Intelligence. (arXiv:2208.04638v1 [cs.AI])
23. Choose qualified instructor for university based on rule-based weighted expert system. (arXiv:2208.04657v1 [cs.AI])
24. DeepHider: A Multi-module and Invisibility Watermarking Scheme for Language Model. (arXiv:2208.04676v1 [cs.CR])
25. Applying data technologies to combat AMR: current status, challenges, and opportunities on the way forward. (arXiv:2208.04683v1 [cs.CY])
26. AI in Telemedicine: An Appraisal on Deep Learning-Based Approaches to Virtual Diagnostic Solutions (VDS). (arXiv:2208.04690v1 [cs.CY])
27. Investigating the Impact of Backward Strategy Learning in a Logic Tutor: Aiding Subgoal Learning towards Improved Problem Solving. (arXiv:2208.04696v1 [cs.CY])
28. Let it RAIN for Social Good. (arXiv:2208.04697v1 [cs.CY])
29. AI Approaches in Processing and Using Data in Personalized Medicine. (arXiv:2208.04698v1 [cs.CY])
30. Context sequence theory: a common explanation for multiple types of learning. (arXiv:2208.04707v1 [q-bio.NC])
31. Towards a General Pre-training Framework for Adaptive Learning in MOOCs. (arXiv:2208.04708v1 [cs.CY])
32. The Transform-o-meter: A method to forecast the transformative impact of innovation. (arXiv:2208.04711v1 [cs.CY])
33. Areas of Strategic Visibility: Disability Bias in Biometrics. (arXiv:2208.04712v1 [cs.CY])
34. The History of AI Rights Research. (arXiv:2208.04714v1 [cs.CY])
35. Combining Variational Modeling with Partial Gradient Perturbation to Prevent Deep Gradient Leakage. (arXiv:2208.04767v1 [cs.LG])
36. Integrating connection search in graph queries. (arXiv:2208.04802v1 [cs.DB])
37. Generalized Reinforcement Learning: Experience Particles, Action Operator, Reinforcement Field, Memory Association, and Decision Concepts. (arXiv:2208.04822v1 [cs.LG])
38. Global Evaluation for Decision Tree Learning. (arXiv:2208.04828v1 [cs.LG])
39. On the Importance of Critical Period in Multi-stage Reinforcement Learning. (arXiv:2208.04832v1 [cs.AI])
40. Mining Reaction and Diffusion Dynamics in Social Activities. (arXiv:2208.04846v1 [cs.SI])
41. Design of High-Throughput Mixed-Precision CNN Accelerators on FPGA. (arXiv:2208.04854v1 [cs.AR])
42. Kill Chaos with Kindness: Agreeableness Improves Team Performance Under Uncertainty. (arXiv:2208.04873v1 [cs.AI])
43. Neural-Rendezvous: Learning-based Robust Guidance and Control to Encounter Interstellar Objects. (arXiv:2208.04883v1 [cs.RO])
44. Localizing the conceptual difference of two scenes using deep learning for house keeping usages. (arXiv:2208.04884v1 [cs.CV])
45. Intrinsically Motivated Learning of Causal World Models. (arXiv:2208.04892v1 [cs.AI])
46. Labels, Information, and Computation: Efficient Learning Using Sufficient Labels. (arXiv:2104.09015v2 [cs.LG] UPDATED)
47. RoFormer: Enhanced Transformer with Rotary Position Embedding. (arXiv:2104.09864v4 [cs.CL] UPDATED)
48. Expression might be enough: representing pressure and demand for reinforcement learning based traffic signal control. (arXiv:2112.10107v3 [cs.AI] UPDATED)
49. Get your Foes Fooled: Proximal Gradient Split Learning for Defense against Model Inversion Attacks on IoMT data. (arXiv:2201.04569v3 [cs.CR] UPDATED)
50. Monotone Learning. (arXiv:2202.05246v2 [cs.LG] UPDATED)
51. Hierarchical Interpretation of Neural Text Classification. (arXiv:2202.09792v3 [cs.CL] UPDATED)
52. From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems. (arXiv:2202.12107v2 [cs.AI] UPDATED)
53. The Unsurprising Effectiveness of Pre-Trained Vision Models for Control. (arXiv:2203.03580v2 [cs.CV] UPDATED)
54. A Real World Dataset for Multi-view 3D Reconstruction. (arXiv:2203.11397v2 [cs.CV] UPDATED)
55. CP2: Copy-Paste Contrastive Pretraining for Semantic Segmentation. (arXiv:2203.11709v2 [cs.CV] UPDATED)
56. Actual Causality and Responsibility Attribution in Decentralized Partially Observable Markov Decision Processes. (arXiv:2204.00302v2 [cs.AI] UPDATED)
57. Maze Learning using a Hyperdimensional Predictive Processing Cognitive Architecture. (arXiv:2204.00619v2 [cs.AI] UPDATED)
58. A recipe of training neural network-based LDPC decoders. (arXiv:2205.00481v2 [cs.IT] UPDATED)
59. Object Type Clustering using Markov Directly-Follow Multigraph in Object-Centric Process Mining. (arXiv:2206.11017v3 [cs.AI] UPDATED)
60. Troll Tweet Detection Using Contextualized Word Representations. (arXiv:2207.08230v2 [cs.CL] UPDATED)
61. HelixFold-Single: MSA-free Protein Structure Prediction by Using Protein Language Model as an Alternative. (arXiv:2207.13921v2 [q-bio.BM] UPDATED)
62. LaTTe: Language Trajectory TransformEr. (arXiv:2208.02918v2 [cs.RO] UPDATED)
63. Discover the Mysteries of the Maya: Selected Contributions from the Machine Learning Challenge & The Discovery Challenge Workshop at ECML PKDD 2021. (arXiv:2208.03163v2 [cs.CV] UPDATED)
64. BlenderBot 3: a deployed conversational agent that continually learns to responsibly engage. (arXiv:2208.03188v2 [cs.CL] UPDATED)
65. The Influence of Network Structural Preference on Node Classification and Link Prediction. (arXiv:2208.03712v2 [cs.LG] UPDATED)
66. AI-based Optimal scheduling of Renewable AC Microgrids with bidirectional LSTM-Based Wind Power Forecasting. (arXiv:2208.04156v2 [eess.SY] UPDATED)
67. Learning Generalizable Light Field Networks from Few Images. (arXiv:2207.11757v1 [cs.CV] CROSS LISTED)

