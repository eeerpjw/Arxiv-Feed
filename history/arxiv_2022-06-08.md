# Your interest papers
---
## cs.CV
---
### Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
- Authors : Siyuan Dong, Lin Zhao, Xiao Chen, Yikang Liu, Terrence Chen, Shanhui Sun
- Link : [http://arxiv.org/abs/2206.02838](http://arxiv.org/abs/2206.02838)
> ABSTRACT  :  High-quality MRI reconstruction plays a critical role in clinical applications. Deep learning-based methods have achieved promising results on MRI reconstruction. However, most state-of-the-art methods were designed to optimize the evaluation metrics commonly used for natural images, such as PSNR and SSIM, whereas the visual quality is not primarily pursued. Compared to the fully-sampled images, the reconstructed images are often blurry, where high-frequency features might not be sharp enough for confident clinical diagnosis. To this end, we propose an invertible sharpening network (InvSharpNet) to improve the visual quality of MRI reconstructions. During training, unlike the traditional methods that learn to map the input data to the ground truth, InvSharpNet adapts a backward training strategy that learns a blurring transform from the ground truth (fully-sampled image) to the input data (blurry reconstruction). During inference, the learned blurring transform can be inverted to a sharpening transform leveraging the network's invertibility. The experiments on various MRI datasets demonstrate that InvSharpNet can improve reconstruction sharpness with few artifacts. The results were also evaluated by radiologists, indicating better visual quality and diagnostic confidence of our proposed method.  
### SpikiLi: A Spiking Simulation of LiDAR based **Real-time** Object Detection for Autonomous Driving. (arXiv:2206.02876v1 [cs.CV])
- Authors : Sambit Mohapatra, Thomas Mesquida, Mona Hodaei, Senthil Yogamani, Heinrich Gotzig, Patrick Mader
- Link : [http://arxiv.org/abs/2206.02876](http://arxiv.org/abs/2206.02876)
> ABSTRACT  :  Spiking Neural Networks are a recent and new neural network design approach that promises tremendous improvements in power efficiency, computation efficiency, and processing latency. They do so by using asynchronous spike-based data flow, event-based signal generation, processing, and modifying the neuron model to resemble biological neurons closely. While some initial works have shown significant initial evidence of applicability to common deep learning tasks, their applications in complex real-world tasks has been relatively low. In this work, we first illustrate the applicability of spiking neural networks to a complex deep learning task namely Lidar based 3D object detection for automated driving. Secondly, we make a step-by-step demonstration of simulating spiking behavior using a pre-trained convolutional neural network. We closely model essential aspects of spiking neural networks in simulation and achieve equivalent run-time and accuracy on a GPU. When the model is realized on a neuromorphic hardware, we expect to have significantly improved power efficiency.  
### Dual **Swin**-Transformer based Mutual Interactive Network for RGB-D Salient Object Detection. (arXiv:2206.03105v1 [cs.CV])
- Authors : Chao Zeng, Sam Kwong
- Link : [http://arxiv.org/abs/2206.03105](http://arxiv.org/abs/2206.03105)
> ABSTRACT  :  Salient Object Detection is the task of predicting the human attended region in a given scene. Fusing depth information has been proven effective in this task. The main challenge of this problem is how to aggregate the complementary information from RGB modality and depth modality. However, conventional deep models heavily rely on CNN feature extractors, and the long-range contextual dependencies are usually ignored. In this work, we propose Dual **Swin**-Transformer based Mutual Interactive Network. We adopt **Swin**-Transformer as the feature extractor for both RGB and depth modality to model the long-range dependencies in visual inputs. Before fusing the two branches of features into one, attention-based modules are applied to enhance features from each modality. We design a self-attention-based cross-modality interaction module and a gated modality attention module to leverage the complementary information between the two modalities. For the saliency decoding, we create different stages enhanced with dense connections and keep a decoding memory while the multi-level encoding features are considered simultaneously. Considering the inaccurate depth map issue, we collect the RGB features of early stages into a skip convolution module to give more guidance from RGB modality to the final saliency prediction. In addition, we add edge supervision to regularize the feature learning process. Comprehensive experiments on five standard RGB-D SOD benchmark datasets over four evaluation metrics demonstrate the superiority of the proposed DTMINet method.  
### NeMF: Neural Motion Fields for Kinematic Animation. (arXiv:2206.03287v1 [cs.CV])
- Authors : Chengan He, Jun Saito, James Zachary, Holly Rushmeier, Yi Zhou
- Link : [http://arxiv.org/abs/2206.03287](http://arxiv.org/abs/2206.03287)
> ABSTRACT  :  We present an **implicit neural representation** to learn the spatio-temporal space of kinematic motions. Unlike previous work that represents motion as discrete sequential samples, we propose to express the vast motion space as a continuous function over time, hence the name Neural Motion Fields (NeMF). Specifically, we use a neural network to learn this function for miscellaneous sets of motions, which is designed to be a generative model conditioned on a temporal coordinate $t$ and a random vector $z$ for controlling the style. The model is then trained as a Variational Autoencoder (VAE) with motion encoders to sample the latent space. We train our model with diverse human motion dataset and quadruped dataset to prove its versatility, and finally deploy it as a generic motion prior to solve task-agnostic problems and show its superiority in different motion generation and editing applications, such as motion interpolation, in-betweening, and re-navigating.  
### Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
- Authors : Yin Dai, an Xu, Fayu Liu, Siqi Li, Sheng Liu, Lifu Shi, Jun Fu
- Link : [http://arxiv.org/abs/2206.03336](http://arxiv.org/abs/2206.03336)
> ABSTRACT  :  Parotid gland tumors account for approximately 2% to 10% of head and neck tumors. Preoperative tumor localization, differential diagnosis, and subsequent selection of appropriate treatment for parotid gland tumors is critical. However, the relative rarity of these tumors and the highly dispersed tissue types have left an unmet need for a subtle differential diagnosis of such neoplastic lesions based on preoperative radiomics. Recently, deep learning methods have developed rapidly, especially Transformer beats the traditional convolutional neural network in computer vision. Many new Transformer-based networks have been proposed for computer vision tasks. In this study, multicenter multimodal parotid gland MRI images were collected. The **Swin**-Unet which was based on Transformer was used. MRI images of STIR, T1 and T2 modalities were combined into a three-channel data to train the network. We achieved segmentation of the region of interest for parotid gland and tumor. The DSC of the model on the test set was 88.63%, MPA was 99.31%, MIoU was 83.99%, and HD was 3.04. Then a series of comparison experiments were designed in this paper to further validate the segmentation performance of the algorithm.  
### Tutel: Adaptive Mixture-of-Experts at Scale. (arXiv:2206.03382v1 [cs.DC])
- Authors : Changho Hwang, Wei Cui, Yifan Xiong, Ziyue Yang, Ze Liu, Han Hu, Zilong Wang, Rafael Salas, Jithin Jose, Prabhat Ram, Joe Chau, Peng Cheng, Fan Yang, Mao Yang, Yongqiang Xiong
- Link : [http://arxiv.org/abs/2206.03382](http://arxiv.org/abs/2206.03382)
> ABSTRACT  :  In recent years, Mixture-of-Experts (MoE) has emerged as a promising technique for deep learning that can scale the model capacity to trillion-plus parameters while reducing the computing cost via sparse computation. While MoE opens a new frontier of exceedingly large models, its implementation over thousands of GPUs has been limited due to mismatch between the dynamic nature of MoE and static parallelism/pipelining of the system. We present Tutel, a highly scalable stack design and implementation for MoE with dynamically adaptive parallelism and pipelining. Tutel delivers adaptive parallelism switching and adaptive pipelining at runtime, which achieves up to 1.74x and 2.00x single MoE layer speedup, respectively. We also propose a novel two-dimensional hierarchical algorithm for MoE communication speedup that outperforms the previous state-of-the-art up to 20.7x over 2,048 GPUs. Aggregating all techniques, Tutel finally delivers 4.96x and 5.75x speedup of a single MoE layer on 16 GPUs and 2,048 GPUs, respectively, over Fairseq: Meta's Facebook AI Research Sequence-to-Sequence Toolkit (Tutel is now partially adopted by Fairseq). Tutel source code is available in public: https://github.com/microsoft/tutel . Our evaluation shows that Tutel efficiently and effectively runs a real-world MoE-based model named **Swin**V2-MoE, built upon **Swin** Transformer V2, a state-of-the-art computer vision architecture. On efficiency, Tutel accelerates **Swin**V2-MoE, achieving up to 1.55x and 2.11x speedup in training and inference over Fairseq, respectively. On effectiveness, the **Swin**V2-MoE model achieves superior accuracy in both pre-training and down-stream computer vision tasks such as COCO object detection than the counterpart dense model, indicating the readiness of Tutel for end-to-end real-world model training and inference. **Swin**V2-MoE is open sourced in https://github.com/microsoft/**Swin**-Transformer .  
## eess.IV
---
### Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
- Authors : Siyuan Dong, Lin Zhao, Xiao Chen, Yikang Liu, Terrence Chen, Shanhui Sun
- Link : [http://arxiv.org/abs/2206.02838](http://arxiv.org/abs/2206.02838)
> ABSTRACT  :  High-quality MRI reconstruction plays a critical role in clinical applications. Deep learning-based methods have achieved promising results on MRI reconstruction. However, most state-of-the-art methods were designed to optimize the evaluation metrics commonly used for natural images, such as PSNR and SSIM, whereas the visual quality is not primarily pursued. Compared to the fully-sampled images, the reconstructed images are often blurry, where high-frequency features might not be sharp enough for confident clinical diagnosis. To this end, we propose an invertible sharpening network (InvSharpNet) to improve the visual quality of MRI reconstructions. During training, unlike the traditional methods that learn to map the input data to the ground truth, InvSharpNet adapts a backward training strategy that learns a blurring transform from the ground truth (fully-sampled image) to the input data (blurry reconstruction). During inference, the learned blurring transform can be inverted to a sharpening transform leveraging the network's invertibility. The experiments on various MRI datasets demonstrate that InvSharpNet can improve reconstruction sharpness with few artifacts. The results were also evaluated by radiologists, indicating better visual quality and diagnostic confidence of our proposed method.  
### Patch-based image Super Resolution using generalized Gaussian mixture model. (arXiv:2206.03069v1 [eess.IV])
- Authors : Lan Nguyen, ois Aujol, Yannick Berthoumieu
- Link : [http://arxiv.org/abs/2206.03069](http://arxiv.org/abs/2206.03069)
> ABSTRACT  :  Single Image Super Resolution (SISR) methods aim to recover the clean images in high resolution from low resolution observations.A family of patch-based approaches have received considerable attention and development. The minimum mean square error (MMSE) methodis a powerful image **restoration** method that uses a probability model on the patches of images. This paper proposes an algorithm to learn a jointgeneralized Gaussian mixture model (GGMM) from a pair of the low resolution patches and the corresponding high resolution patches fromthe reference data. We then reconstruct the high resolution image based on the MMSE method. Our numerical evaluations indicate that theMMSE-GGMM method competes with other state of the art methods.  
### Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
- Authors : Yin Dai, an Xu, Fayu Liu, Siqi Li, Sheng Liu, Lifu Shi, Jun Fu
- Link : [http://arxiv.org/abs/2206.03336](http://arxiv.org/abs/2206.03336)
> ABSTRACT  :  Parotid gland tumors account for approximately 2% to 10% of head and neck tumors. Preoperative tumor localization, differential diagnosis, and subsequent selection of appropriate treatment for parotid gland tumors is critical. However, the relative rarity of these tumors and the highly dispersed tissue types have left an unmet need for a subtle differential diagnosis of such neoplastic lesions based on preoperative radiomics. Recently, deep learning methods have developed rapidly, especially Transformer beats the traditional convolutional neural network in computer vision. Many new Transformer-based networks have been proposed for computer vision tasks. In this study, multicenter multimodal parotid gland MRI images were collected. The **Swin**-Unet which was based on Transformer was used. MRI images of STIR, T1 and T2 modalities were combined into a three-channel data to train the network. We achieved segmentation of the region of interest for parotid gland and tumor. The DSC of the model on the test set was 88.63%, MPA was 99.31%, MIoU was 83.99%, and HD was 3.04. Then a series of comparison experiments were designed in this paper to further validate the segmentation performance of the algorithm.  
## cs.LG
---
### Forecasting COVID- 19 cases using Statistical Models and Ontology-based Semantic Modelling: A **real time** data analytics approach. (arXiv:2206.02795v1 [q-bio.PE])
- Authors : Sadhana Tiwari, Ritesh Chandra, Sonali Agarwal
- Link : [http://arxiv.org/abs/2206.02795](http://arxiv.org/abs/2206.02795)
> ABSTRACT  :  SARS-COV-19 is the most prominent issue which many countries face today. The frequent changes in infections, recovered and deaths represents the dynamic nature of this pandemic. It is very crucial to predict the spreading rate of this virus for accurate decision making against fighting with the situation of getting infected through the virus, tracking and controlling the virus transmission in the community. We develop a prediction model using statistical time series models such as SARIMA and FBProphet to monitor the daily active, recovered and death cases of COVID-19 accurately. Then with the help of various details across each individual patient (like height, weight, gender etc.), we designed a set of rules using Semantic Web Rule Language and some mathematical models for dealing with COVID19 infected cases on an individual basis. After combining all the models, a COVID-19 Ontology is developed and performs various queries using SPARQL query on designed Ontology which accumulate the risk factors, provide appropriate diagnosis, precautions and preventive suggestions for COVID Patients. After comparing the performance of SARIMA and FBProphet, it is observed that the SARIMA model performs better in forecasting of COVID cases. On individual basis COVID case prediction, approx. 497 individual samples have been tested and classified into five different levels of COVID classes such as Having COVID, No COVID, High Risk COVID case, Medium to High Risk case, and Control needed case.  
### Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
- Authors : Siyuan Dong, Lin Zhao, Xiao Chen, Yikang Liu, Terrence Chen, Shanhui Sun
- Link : [http://arxiv.org/abs/2206.02838](http://arxiv.org/abs/2206.02838)
> ABSTRACT  :  High-quality MRI reconstruction plays a critical role in clinical applications. Deep learning-based methods have achieved promising results on MRI reconstruction. However, most state-of-the-art methods were designed to optimize the evaluation metrics commonly used for natural images, such as PSNR and SSIM, whereas the visual quality is not primarily pursued. Compared to the fully-sampled images, the reconstructed images are often blurry, where high-frequency features might not be sharp enough for confident clinical diagnosis. To this end, we propose an invertible sharpening network (InvSharpNet) to improve the visual quality of MRI reconstructions. During training, unlike the traditional methods that learn to map the input data to the ground truth, InvSharpNet adapts a backward training strategy that learns a blurring transform from the ground truth (fully-sampled image) to the input data (blurry reconstruction). During inference, the learned blurring transform can be inverted to a sharpening transform leveraging the network's invertibility. The experiments on various MRI datasets demonstrate that InvSharpNet can improve reconstruction sharpness with few artifacts. The results were also evaluated by radiologists, indicating better visual quality and diagnostic confidence of our proposed method.  
### Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v1 [cs.SD])
- Authors : Joan Serr, Santiago Pascual, Jordi Pons, Oguz Araz, Davide Scaini
- Link : [http://arxiv.org/abs/2206.03065](http://arxiv.org/abs/2206.03065)
> ABSTRACT  :  Removing background noise from speech audio has been the subject of considerable research and effort, especially in recent years due to the rise of virtual communication and amateur sound recording. Yet background noise is not the only unpleasant disturbance that can prevent intelligibility: reverb, clipping, codec artifacts, problematic equalization, limited bandwidth, or inconsistent loudness are equally disturbing and ubiquitous. In this work, we propose to consider the task of speech **enhancement** as a holistic endeavor, and present a universal speech **enhancement** system that tackles 55 different distortions at the same time. Our approach consists of a generative model that employs score-based diffusion, together with a multi-resolution conditioning network that performs **enhancement** with mixture density networks. We show that this approach significantly outperforms the state of the art in a subjective test performed by expert listeners. We also show that it achieves competitive objective scores with just 4-8 diffusion steps, despite not considering any particular strategy for fast sampling. We hope that both our methodology and technical contributions encourage researchers and practitioners to adopt a universal approach to speech **enhancement**, possibly framing it as a generative task.  
### Patch-based image Super Resolution using generalized Gaussian mixture model. (arXiv:2206.03069v1 [eess.IV])
- Authors : Lan Nguyen, ois Aujol, Yannick Berthoumieu
- Link : [http://arxiv.org/abs/2206.03069](http://arxiv.org/abs/2206.03069)
> ABSTRACT  :  Single Image Super Resolution (SISR) methods aim to recover the clean images in high resolution from low resolution observations.A family of patch-based approaches have received considerable attention and development. The minimum mean square error (MMSE) methodis a powerful image **restoration** method that uses a probability model on the patches of images. This paper proposes an algorithm to learn a jointgeneralized Gaussian mixture model (GGMM) from a pair of the low resolution patches and the corresponding high resolution patches fromthe reference data. We then reconstruct the high resolution image based on the MMSE method. Our numerical evaluations indicate that theMMSE-GGMM method competes with other state of the art methods.  
### Collaborative Intelligence Orchestration: Inconsistency-Based Fusion of Semi-Supervised Learning and Active Learning. (arXiv:2206.03288v1 [cs.LG])
- Authors : Jiannan Guo, Yangyang Kang, Yu Duan, Xiaozhong Liu, Siliang Tang, Wenqiao Zhang, Kun Kuang, Changlong Sun, Fei Wu
- Link : [http://arxiv.org/abs/2206.03288](http://arxiv.org/abs/2206.03288)
> ABSTRACT  :  While annotating decent amounts of data to satisfy sophisticated learning models can be cost-prohibitive for many real-world applications. Active learning (AL) and semi-supervised learning (SSL) are two effective, but often isolated, means to alleviate the data-hungry problem. Some recent studies explored the potential of combining AL and SSL to better probe the unlabeled data. However, almost all these contemporary SSL-AL works use a simple combination strategy, ignoring SSL and AL's inherent relation. Further, other methods suffer from high computational costs when dealing with large-scale, high-dimensional datasets. Motivated by the industry practice of labeling data, we propose an innovative Inconsistency-based virtual aDvErsarial Active Learning (IDEAL) algorithm to further investigate SSL-AL's potential superiority and achieve mutual **enhancement** of AL and SSL, i.e., SSL propagates label information to unlabeled samples and provides smoothed embeddings for AL, while AL excludes samples with inconsistent predictions and considerable uncertainty for SSL. We estimate unlabeled samples' inconsistency by augmentation strategies of different granularities, including fine-grained continuous perturbation exploration and coarse-grained data transformations. Extensive experiments, in both text and image domains, validate the effectiveness of the proposed algorithm, comparing it against state-of-the-art baselines. Two real-world case studies visualize the practical industrial value of applying and deploying the proposed data sampling algorithm.  
### Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
- Authors : Yin Dai, an Xu, Fayu Liu, Siqi Li, Sheng Liu, Lifu Shi, Jun Fu
- Link : [http://arxiv.org/abs/2206.03336](http://arxiv.org/abs/2206.03336)
> ABSTRACT  :  Parotid gland tumors account for approximately 2% to 10% of head and neck tumors. Preoperative tumor localization, differential diagnosis, and subsequent selection of appropriate treatment for parotid gland tumors is critical. However, the relative rarity of these tumors and the highly dispersed tissue types have left an unmet need for a subtle differential diagnosis of such neoplastic lesions based on preoperative radiomics. Recently, deep learning methods have developed rapidly, especially Transformer beats the traditional convolutional neural network in computer vision. Many new Transformer-based networks have been proposed for computer vision tasks. In this study, multicenter multimodal parotid gland MRI images were collected. The **Swin**-Unet which was based on Transformer was used. MRI images of STIR, T1 and T2 modalities were combined into a three-channel data to train the network. We achieved segmentation of the region of interest for parotid gland and tumor. The DSC of the model on the test set was 88.63%, MPA was 99.31%, MIoU was 83.99%, and HD was 3.04. Then a series of comparison experiments were designed in this paper to further validate the segmentation performance of the algorithm.  
### CANShield: Signal-based Intrusion Detection for Controller Area Networks. (arXiv:2205.01306v3 [cs.CR] UPDATED)
- Authors : Md Hasan, Yang Xiao, Pablo Moriano, Wenjing Lou, Thomas Hou
- Link : [http://arxiv.org/abs/2205.01306](http://arxiv.org/abs/2205.01306)
> ABSTRACT  :  Modern vehicles rely on a fleet of electronic control units (ECUs) connected through controller area network (CAN) buses for critical vehicular control. However, with the expansion of advanced connectivity features in automobiles and the elevated risks of internal system **exposure**, the CAN bus is increasingly prone to intrusions and injection attacks. The ordinary injection attacks disrupt the typical timing properties of the CAN data stream, and the rule-based intrusion detection systems (IDS) can easily detect them. However, advanced attackers can inject false data to the time series sensory data (signal), while looking innocuous by the pattern/frequency of the CAN messages. Such attacks can bypass the rule-based IDS or any anomaly-based IDS built on binary payload data. To make the vehicles robust against such intelligent attacks, we propose CANShield, a signal-based intrusion detection framework for the CAN bus. CANShield consists of three modules: a data preprocessing module that handles the high-dimensional CAN data stream at the signal level and makes them suitable for a deep learning model; a data analyzer module consisting of multiple deep autoencoder (AE) networks, each analyzing the time-series data from a different temporal perspective; and finally an attack detection module that uses an ensemble method to make the final decision. Evaluation results on two high-fidelity signal-based CAN attack datasets show the high accuracy and responsiveness of CANShield in detecting wide-range of advanced intrusion attacks.  
## cs.AI
---
### Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v1 [cs.SD])
- Authors : Joan Serr, Santiago Pascual, Jordi Pons, Oguz Araz, Davide Scaini
- Link : [http://arxiv.org/abs/2206.03065](http://arxiv.org/abs/2206.03065)
> ABSTRACT  :  Removing background noise from speech audio has been the subject of considerable research and effort, especially in recent years due to the rise of virtual communication and amateur sound recording. Yet background noise is not the only unpleasant disturbance that can prevent intelligibility: reverb, clipping, codec artifacts, problematic equalization, limited bandwidth, or inconsistent loudness are equally disturbing and ubiquitous. In this work, we propose to consider the task of speech **enhancement** as a holistic endeavor, and present a universal speech **enhancement** system that tackles 55 different distortions at the same time. Our approach consists of a generative model that employs score-based diffusion, together with a multi-resolution conditioning network that performs **enhancement** with mixture density networks. We show that this approach significantly outperforms the state of the art in a subjective test performed by expert listeners. We also show that it achieves competitive objective scores with just 4-8 diffusion steps, despite not considering any particular strategy for fast sampling. We hope that both our methodology and technical contributions encourage researchers and practitioners to adopt a universal approach to speech **enhancement**, possibly framing it as a generative task.  
# Paper List
---
## cs.CV
---
**110** new papers in cs.CV:-) 
1. FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data. (arXiv:2206.02792v1 [cs.LG])
2. FedNST: Federated Noisy Student Training for Automatic Speech Recognition. (arXiv:2206.02797v1 [eess.AS])
3. EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain Extraction. (arXiv:2206.02837v1 [eess.IV])
4. Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
5. Spatial Acoustic Projection for 3D Imaging Sonar Reconstruction. (arXiv:2206.02840v1 [cs.RO])
6. A Deeper Dive Into What Deep Spatiotemporal Networks Encode: Quantifying Static vs. Dynamic Information. (arXiv:2206.02846v1 [cs.CV])
7. Exploring the Potential of SAR Data for Cloud Removal in Optical Satellite Imagery. (arXiv:2206.02850v1 [cs.CV])
8. SpikiLi: A Spiking Simulation of LiDAR based **Real-time** Object Detection for Autonomous Driving. (arXiv:2206.02876v1 [cs.CV])
9. Mesh-based Dynamics with Occlusion Reasoning for Cloth Manipulation. (arXiv:2206.02881v1 [cs.RO])
10. Polymorphic-GAN: Generating Aligned Samples across Multiple Domains with Learned Morph Maps. (arXiv:2206.02903v1 [cs.CV])
11. Learning Treatment Plan Representations for Content Based Image Retrieval. (arXiv:2206.02912v1 [cs.CV])
12. Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks. (arXiv:2206.02916v1 [cs.LG])
13. HMRNet: High and Multi-Resolution Network with Bidirectional Feature Calibration for Brain Structure Segmentation in Radiotherapy. (arXiv:2206.02959v1 [eess.IV])
14. Masked Unsupervised Self-training for Zero-shot Image Classification. (arXiv:2206.02967v1 [cs.CV])
15. DETR++: Taming Your Multi-Scale Detection Transformer. (arXiv:2206.02977v1 [cs.CV])
16. Structured Context Transformer for Generic Event Boundary Detection. (arXiv:2206.02985v1 [cs.CV])
17. TadML: A fast temporal action detection with Mechanics-MLP. (arXiv:2206.02997v1 [cs.CV])
18. PP-OCRv3: More Attempts for the Improvement of Ultra Lightweight OCR System. (arXiv:2206.03001v1 [cs.CV])
19. Transformer-based Personalized Attention Mechanism (PersAM) for Medical Images with Clinical Records. (arXiv:2206.03003v1 [eess.IV])
20. Self-Knowledge Distillation based Self-Supervised Learning for Covid-19 Detection from Chest X-Ray Images. (arXiv:2206.03009v1 [eess.IV])
21. MS-RNN: A Flexible Multi-Scale Framework for Spatiotemporal Predictive Learning. (arXiv:2206.03010v1 [cs.CV])
22. TriBYOL: Triplet BYOL for Self-Supervised Representation Learning. (arXiv:2206.03012v1 [cs.CV])
23. The Devil is in the Labels: Noisy Label Correction for Robust Scene Graph Generation. (arXiv:2206.03014v1 [cs.CV])
24. Development of Automatic Endotracheal Tube and Carina Detection on Portable Supine Chest Radiographs using Artificial Intelligence. (arXiv:2206.03017v1 [cs.CV])
25. Deep Learning Techniques for Visual Counting. (arXiv:2206.03033v1 [cs.CV])
26. COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset for Computer-aided COVID-19 Screening from Chest CT Images. (arXiv:2206.03043v1 [eess.IV])
27. Layered Depth Refinement with Mask Guidance. (arXiv:2206.03048v1 [cs.CV])
28. Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans. (arXiv:2206.03049v1 [eess.IV])
29. Spatial Parsing and Dynamic Temporal Pooling networks for Human-Object Interaction detection. (arXiv:2206.03061v1 [cs.CV])
30. Object Scan Context: Object-centric Spatial Descriptor for Place Recognition within 3D Point Cloud Map. (arXiv:2206.03062v1 [cs.CV])
31. Minimum Efforts to Build an End-to-End Spatial-Temporal Action Detector. (arXiv:2206.03064v1 [cs.CV])
32. Recent Advances for Quantum Neural Networks in Generative Learning. (arXiv:2206.03066v1 [quant-ph])
33. Pushing the Limits of Learning-based Traversability Analysis for Autonomous Driving on CPU. (arXiv:2206.03083v1 [cs.RO])
34. Online Deep Clustering with Video Track Consistency. (arXiv:2206.03086v1 [cs.CV])
35. Critical Regularizations for Neural Surface Reconstruction in the Wild. (arXiv:2206.03087v1 [cs.CV])
36. Dual **Swin**-Transformer based Mutual Interactive Network for RGB-D Salient Object Detection. (arXiv:2206.03105v1 [cs.CV])
37. MIRNF: Medical Image Registration via Neural Fields. (arXiv:2206.03111v1 [cs.CV])
38. Wavelet Prior Attention Learning in Axial Inpainting Network. (arXiv:2206.03113v1 [cs.CV])
39. Self-Training of Handwritten Word Recognition for Synthetic-to-Real Adaptation. (arXiv:2206.03149v1 [cs.CV])
40. Utility of Equivariant Message Passing in Cortical Mesh Segmentation. (arXiv:2206.03164v1 [cs.CV])
41. Improving Image Captioning with Control Signal of Sentence Quality. (arXiv:2206.03196v1 [cs.CV])
42. Omnivision forecasting: combining satellite observations with sky images for improved intra-hour solar energy predictions. (arXiv:2206.03207v1 [cs.CV])
43. Deep Neural Patchworks: Coping with Large Segmentation Tasks. (arXiv:2206.03210v1 [cs.CV])
44. Towards better Interpretable and Generalizable AD detection using Collective Artificial Intelligence. (arXiv:2206.03247v1 [eess.IV])
45. On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning. (arXiv:2206.03271v1 [cs.LG])
46. NeMF: Neural Motion Fields for Kinematic Animation. (arXiv:2206.03287v1 [cs.CV])
47. Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
48. cViL: Cross-Lingual Training of Vision-Language Models using Knowledge Distillation. (arXiv:2206.03354v1 [cs.CL])
49. An efficient semi-supervised quality control system trained using physics-based MRI-artefact generators and adversarial training. (arXiv:2206.03359v1 [eess.IV])
50. Hierarchical Similarity Learning for Aliasing Suppression Image Super-Resolution. (arXiv:2206.03361v1 [cs.CV])
51. Localizing Semantic Patches for Accelerating Image Classification. (arXiv:2206.03367v1 [cs.CV])
52. IL-MCAM: An interactive learning and multi-channel attention mechanism-based weakly supervised colorectal histopathology image classification approach. (arXiv:2206.03368v1 [cs.CV])
53. Garment Avatars: Realistic Cloth Driving using Pattern Registration. (arXiv:2206.03373v1 [cs.CV])
54. Shape, Light & Material Decomposition from Images using Monte Carlo Rendering and Denoising. (arXiv:2206.03380v1 [cs.GR])
55. Tutel: Adaptive Mixture-of-Experts at Scale. (arXiv:2206.03382v1 [cs.DC])
56. Towards a General Purpose CNN for Long Range Dependencies in $\mathrm{N}$D. (arXiv:2206.03398v1 [cs.LG])
57. Fast and Robust Non-Rigid Registration Using Accelerated Majorization-Minimization. (arXiv:2206.03410v1 [cs.CV])
58. Exploring the combination of deep-learning based direct segmentation and deformable image registration for cone-beam CT based auto-segmentation for adaptive radiotherapy. (arXiv:2206.03413v1 [physics.med-ph])
59. Revealing Single Frame Bias for Video-and-Language Learning. (arXiv:2206.03428v1 [cs.CV])
60. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v1 [cs.CV])
61. Robot Self-Calibration Using Actuated 3D Sensors. (arXiv:2206.03430v1 [cs.RO])
62. Self-supervised Domain Adaptation in Crowd Counting. (arXiv:2206.03431v1 [cs.CV])
63. Can CNNs Be More Robust Than Transformers?. (arXiv:2206.03452v1 [cs.CV])
64. Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models. (arXiv:2206.03461v1 [cs.CV])
65. SHRED: 3D Shape Region Decomposition with Learned Local Operations. (arXiv:2206.03480v1 [cs.CV])
66. Detection Hub: Unifying Object Detection Datasets via Query Adaptation on Language Embedding. (arXiv:2206.03484v1 [cs.CV])
67. Attending Category Disentangled Global Context for Image Classification. (arXiv:1812.06663v5 [cs.CV] UPDATED)
68. Stratified Rule-Aware Network for Abstract Visual Reasoning. (arXiv:2002.06838v3 [cs.CV] UPDATED)
69. Learning to Segment Human Body Parts with Synthetically Trained Deep Convolutional Networks. (arXiv:2102.01460v3 [cs.CV] UPDATED)
70. Look, Cast and Mold: Learning 3D Shape Manifold from Single-view Synthetic Data. (arXiv:2103.04789v3 [cs.CV] UPDATED)
71. Deformable Capsules for Object Detection. (arXiv:2104.05031v2 [cs.CV] UPDATED)
72. Common Limitations of Image Processing Metrics: A Picture Story. (arXiv:2104.05642v5 [eess.IV] UPDATED)
73. Consistency Regularization for Variational Auto-Encoders. (arXiv:2105.14859v2 [cs.LG] UPDATED)
74. Tikhonov Regularization of Circle-Valued Signals. (arXiv:2108.02602v3 [math.OC] UPDATED)
75. DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT. (arXiv:2109.07711v2 [eess.IV] UPDATED)
76. Learn to Ignore: Domain Adaptation for Multi-Site MRI Analysis. (arXiv:2110.06803v3 [cs.CV] UPDATED)
77. Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention. (arXiv:2110.12372v4 [eess.IV] UPDATED)
78. Automated skin lesion segmentation using multi-scale feature extraction scheme and dual-attention mechanism. (arXiv:2111.08708v3 [eess.IV] UPDATED)
79. Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion. (arXiv:2111.12602v4 [cs.CV] UPDATED)
80. MAE-DET: Revisiting Maximum Entropy Principle in Zero-Shot NAS for Efficient Object Detection. (arXiv:2111.13336v3 [cs.CV] UPDATED)
81. Neural Point Light Fields. (arXiv:2112.01473v3 [cs.CV] UPDATED)
82. Hybrid Instance-aware Temporal Fusion for Online Video Instance Segmentation. (arXiv:2112.01695v2 [cs.CV] UPDATED)
83. GradMax: Growing Neural Networks using Gradient Information. (arXiv:2201.05125v3 [cs.LG] UPDATED)
84. Vertical Federated Edge Learning with Distributed Integrated Sensing and Communication. (arXiv:2201.08512v2 [eess.SP] UPDATED)
85. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v3 [cs.LG] UPDATED)
86. Debiased Self-Training for Semi-Supervised Learning. (arXiv:2202.07136v3 [cs.LG] UPDATED)
87. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v2 [cs.LG] UPDATED)
88. Syntax-Aware Network for Handwritten Mathematical Expression Recognition. (arXiv:2203.01601v4 [cs.CV] UPDATED)
89. Revisiting Click-based Interactive Video Object Segmentation. (arXiv:2203.01784v2 [cs.CV] UPDATED)
90. TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers. (arXiv:2203.10726v2 [eess.IV] UPDATED)
91. Cell segmentation from telecentric bright-field transmitted light microscopy images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v2 [q-bio.QM] UPDATED)
92. Eventor: An Efficient Event-Based Monocular Multi-View Stereo Accelerator on FPGA Platform. (arXiv:2203.15439v2 [cs.AR] UPDATED)
93. Deep Vehicle Detection in Satellite Video. (arXiv:2204.06828v2 [cs.CV] UPDATED)
94. Differentiable Zooming for Multiple Instance Learning on Whole-Slide Images. (arXiv:2204.12454v3 [cs.CV] UPDATED)
95. Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework. (arXiv:2205.03860v3 [cs.CV] UPDATED)
96. An Effective Transformer-based Solution for RSNA Intracranial Hemorrhage Detection Competition. (arXiv:2205.07556v3 [cs.CV] UPDATED)
97. ColonFormer: An Efficient Transformer based Method for Colon Polyp Segmentation. (arXiv:2205.08473v3 [cs.CV] UPDATED)
98. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v2 [eess.IV] UPDATED)
99. SelfReformer: Self-Refined Network with Transformer for Salient Object Detection. (arXiv:2205.11283v2 [cs.CV] UPDATED)
100. DeepRM: Deep Recurrent Matching for 6D Pose Refinement. (arXiv:2205.14474v3 [cs.CV] UPDATED)
101. Harnessing spectral representations for subgraph alignment. (arXiv:2205.14938v2 [cs.LG] UPDATED)
102. Self-Supervised Pre-training of Vision Transformers for Dense Prediction Tasks. (arXiv:2205.15173v2 [cs.CV] UPDATED)
103. Is Mapping Necessary for Realistic PointGoal Navigation?. (arXiv:2206.00997v2 [cs.CV] UPDATED)
104. The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural Network for Online Gesture Recognition. (arXiv:2206.01910v2 [cs.CV] UPDATED)
105. CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks. (arXiv:2206.01992v2 [cs.CV] UPDATED)
106. Efficient Annotation and Learning for 3D Hand Pose Estimation: A Survey. (arXiv:2206.02257v2 [cs.CV] UPDATED)
107. SealID: Saimaa ringed seal re-identification dataset. (arXiv:2206.02260v2 [cs.CV] UPDATED)
108. NORPPA: NOvel Ringed seal re-identification by Pelage Pattern Aggregation. (arXiv:2206.02498v2 [cs.CV] UPDATED)
109. Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images. (arXiv:2206.02761v2 [cs.CV] UPDATED)
110. Low Power Neuromorphic EMG Gesture Classification. (arXiv:2206.02061v1 [eess.SP] CROSS LISTED)
## eess.IV
---
**27** new papers in eess.IV:-) 
1. Can autism be diagnosed with AI?. (arXiv:2206.02787v1 [eess.IV])
2. EVC-Net: Multi-scale V-Net with Conditional Random Fields for Brain Extraction. (arXiv:2206.02837v1 [eess.IV])
3. Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
4. Exploring the Potential of SAR Data for Cloud Removal in Optical Satellite Imagery. (arXiv:2206.02850v1 [cs.CV])
5. HMRNet: High and Multi-Resolution Network with Bidirectional Feature Calibration for Brain Structure Segmentation in Radiotherapy. (arXiv:2206.02959v1 [eess.IV])
6. Transformer-based Personalized Attention Mechanism (PersAM) for Medical Images with Clinical Records. (arXiv:2206.03003v1 [eess.IV])
7. Self-Knowledge Distillation based Self-Supervised Learning for Covid-19 Detection from Chest X-Ray Images. (arXiv:2206.03009v1 [eess.IV])
8. COVIDx CT-3: A Large-scale, Multinational, Open-Source Benchmark Dataset for Computer-aided COVID-19 Screening from Chest CT Images. (arXiv:2206.03043v1 [eess.IV])
9. Siamese Encoder-based Spatial-Temporal Mixer for Growth Trend Prediction of Lung Nodules on CT Scans. (arXiv:2206.03049v1 [eess.IV])
10. Patch-based image Super Resolution using generalized Gaussian mixture model. (arXiv:2206.03069v1 [eess.IV])
11. Pancreatic Cancer ROSE Image Classification Based on Multiple Instance Learning with Shuffle Instances. (arXiv:2206.03080v1 [eess.IV])
12. FlexLip: A Controllable Text-to-Lip System. (arXiv:2206.03206v1 [eess.AS])
13. Towards better Interpretable and Generalizable AD detection using Collective Artificial Intelligence. (arXiv:2206.03247v1 [eess.IV])
14. Future Artificial Intelligence tools and perspectives in medicine. (arXiv:2206.03289v1 [cs.LG])
15. Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
16. An efficient semi-supervised quality control system trained using physics-based MRI-artefact generators and adversarial training. (arXiv:2206.03359v1 [eess.IV])
17. Hierarchical Similarity Learning for Aliasing Suppression Image Super-Resolution. (arXiv:2206.03361v1 [cs.CV])
18. Fast Unsupervised Brain Anomaly Detection and Segmentation with Diffusion Models. (arXiv:2206.03461v1 [cs.CV])
19. Common Limitations of Image Processing Metrics: A Picture Story. (arXiv:2104.05642v5 [eess.IV] UPDATED)
20. DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT. (arXiv:2109.07711v2 [eess.IV] UPDATED)
21. Uncertainty-Guided Lung Nodule Segmentation with Feature-Aware Attention. (arXiv:2110.12372v4 [eess.IV] UPDATED)
22. Automated skin lesion segmentation using multi-scale feature extraction scheme and dual-attention mechanism. (arXiv:2111.08708v3 [eess.IV] UPDATED)
23. Time-series image denoising of pressure-sensitive paint data by projected multivariate singular spectrum analysis. (arXiv:2203.07574v2 [eess.IV] UPDATED)
24. TransFusion: Multi-view Divergent Fusion for Medical Image Segmentation with Transformers. (arXiv:2203.10726v2 [eess.IV] UPDATED)
25. Cell segmentation from telecentric bright-field transmitted light microscopy images using a Residual Attention U-Net: a case study on HeLa line. (arXiv:2203.12290v2 [q-bio.QM] UPDATED)
26. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v2 [eess.IV] UPDATED)
27. A framework for self-supervised MR image reconstruction using sub-sampling via Noisier2Noise. (arXiv:2205.10278v2 [eess.IV] UPDATED)
## cs.LG
---
**228** new papers in cs.LG:-) 
1. Towards Job-Transition-Tag Graph for a Better Job Title Representation Learning. (arXiv:2206.02782v1 [cs.LG])
2. Zeroth-Order SciML: Non-intrusive Integration of Scientific Software with Deep Learning. (arXiv:2206.02785v1 [cs.LG])
3. Impossibility of Collective Intelligence. (arXiv:2206.02786v1 [cs.LG])
4. Accurate Virus Identification with Interpretable Raman Signatures by Machine Learning. (arXiv:2206.02788v1 [q-bio.QM])
5. Efficient and Accurate Physics-aware Multiplex Graph Neural Networks for 3D Small Molecules and Macromolecule Complexes. (arXiv:2206.02789v1 [q-bio.BM])
6. Improving Model Understanding and Trust with Counterfactual Explanations of Model Confidence. (arXiv:2206.02790v1 [cs.LG])
7. Instance-Dependent Label-Noise Learning with Manifold-Regularized Transition Matrix Estimation. (arXiv:2206.02791v1 [cs.LG])
8. FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data. (arXiv:2206.02792v1 [cs.LG])
9. Machine learning models for determination of weldbead shape parameters for gas metal arc welded T-joints -- A comparative study. (arXiv:2206.02794v1 [cs.LG])
10. Forecasting COVID- 19 cases using Statistical Models and Ontology-based Semantic Modelling: A **real time** data analytics approach. (arXiv:2206.02795v1 [q-bio.PE])
11. Interpolation-based Correlation Reduction Network for Semi-Supervised Graph Learning. (arXiv:2206.02796v1 [cs.LG])
12. FedNST: Federated Noisy Student Training for Automatic Speech Recognition. (arXiv:2206.02797v1 [eess.AS])
13. Quantum Neural Network Classifiers: A Tutorial. (arXiv:2206.02806v1 [quant-ph])
14. Deep Learning Models of the Discrete Component of the Galactic Interstellar Gamma-Ray Emission. (arXiv:2206.02819v1 [astro-ph.HE])
15. RORL: Robust Offline Reinforcement Learning via Conservative Smoothing. (arXiv:2206.02829v1 [cs.LG])
16. Collaborative Linear Bandits with Adversarial Agents: Near-Optimal Regret Bounds. (arXiv:2206.02834v1 [cs.LG])
17. Invertible Sharpening Network for MRI Reconstruction **Enhancement**. (arXiv:2206.02838v1 [eess.IV])
18. On Efficient Approximate Queries over Machine Learning Models. (arXiv:2206.02845v1 [cs.DB])
19. A Bird's-Eye Tutorial of Graph Attention Architectures. (arXiv:2206.02849v1 [cs.LG])
20. Efficient entity-based reinforcement learning. (arXiv:2206.02855v1 [cs.LG])
21. A Human-Centric Take on Model Monitoring. (arXiv:2206.02868v1 [cs.LG])
22. Graph Rationalization with Environment-based Augmentations. (arXiv:2206.02886v1 [cs.LG])
23. Sample Complexity of Nonparametric Off-Policy Evaluation on Low-Dimensional Manifolds using Deep Networks. (arXiv:2206.02887v1 [cs.LG])
24. Conditional Seq2Seq model for the time-dependent two-level system. (arXiv:2206.02889v1 [quant-ph])
25. A Justice-Based Framework for the Analysis of Algorithmic Fairness-Utility Trade-Offs. (arXiv:2206.02891v1 [cs.CY])
26. Distributive Justice as the Foundational Premise of Fair ML: Unification, Extension, and Interpretation of Group Fairness Metrics. (arXiv:2206.02897v1 [cs.CY])
27. Goal-Space Planning with Subgoal Models. (arXiv:2206.02902v1 [cs.LG])
28. Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data. (arXiv:2206.02909v1 [eess.SP])
29. Boundary informed inverse PDE problems on discrete Riemann surfaces. (arXiv:2206.02911v1 [math.NA])
30. Training Subset Selection for Weak Supervision. (arXiv:2206.02914v1 [stat.ML])
31. 8-bit Numerical Formats for Deep Neural Networks. (arXiv:2206.02915v1 [cs.LG])
32. Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks. (arXiv:2206.02916v1 [cs.LG])
33. Schema-Guided Event Graph Completion. (arXiv:2206.02921v1 [cs.LG])
34. Tight basis cycle representatives for persistent homology of large data sets. (arXiv:2206.02925v1 [cs.LG])
35. Spectral Bias Outside the Training Set for Deep Networks in the Kernel Regime. (arXiv:2206.02927v1 [stat.ML])
36. Neuro-Symbolic Causal Language Planning with Commonsense Prompting. (arXiv:2206.02928v1 [cs.CL])
37. Predicting Electricity Infrastructure Induced Wildfire Risk in California. (arXiv:2206.02930v1 [eess.SY])
38. On the Convergence of Optimizing Persistent-Homology-Based Losses. (arXiv:2206.02946v1 [cs.LG])
39. Sampling without Replacement Leads to Faster Rates in Finite-Sum Minimax Optimization. (arXiv:2206.02953v1 [math.OC])
40. Robust Time Series Dissimilarity Measure for Outlier Detection and Periodicity Detection. (arXiv:2206.02956v1 [cs.LG])
41. GRETEL: A unified framework for Graph Counterfactual Explanation Evaluation. (arXiv:2206.02957v1 [cs.LG])
42. Beyond Faithfulness: A Framework to Characterize and Compare Saliency Methods. (arXiv:2206.02958v1 [cs.LG])
43. Confounder Analysis in Measuring Representation in Product Funnels. (arXiv:2206.02962v1 [stat.ML])
44. Improving Knowledge Graph Embedding via Iterative Self-Semantic Knowledge Distillation. (arXiv:2206.02963v1 [cs.LG])
45. A Simple and Optimal Policy Design for Online Learning with Safety against Heavy-tailed Risk. (arXiv:2206.02969v1 [stat.ML])
46. Decomposed Linear Dynamical Systems (dLDS) for learning the latent components of neural dynamics. (arXiv:2206.02972v1 [stat.ML])
47. Recall Distortion in Neural Network Pruning and the Undecayed Pruning Algorithm. (arXiv:2206.02976v1 [cs.LG])
48. DETR++: Taming Your Multi-Scale Detection Transformer. (arXiv:2206.02977v1 [cs.CV])
49. DynaMaR: Dynamic Prompt with Mask Token Representation. (arXiv:2206.02982v1 [cs.CL])
50. Distributionally Invariant Learning: Rationalization and Practical Algorithms. (arXiv:2206.02990v1 [cs.LG])
51. Driving in Real Life with Inverse Reinforcement Learning. (arXiv:2206.03004v1 [cs.RO])
52. Histogram Estimation under User-level Privacy with Heterogeneous Data. (arXiv:2206.03008v1 [cs.LG])
53. Self-Knowledge Distillation based Self-Supervised Learning for Covid-19 Detection from Chest X-Ray Images. (arXiv:2206.03009v1 [eess.IV])
54. The Survival Bandit Problem. (arXiv:2206.03019v1 [cs.LG])
55. Adaptive Weighted Nonnegative Matrix Factorization for Robust Feature Representation. (arXiv:2206.03020v1 [cs.LG])
56. How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via $f$-Advantage Regression. (arXiv:2206.03023v1 [cs.LG])
57. Intelligent Circuit Design and Implementation with Machine Learning. (arXiv:2206.03032v1 [cs.LG])
58. Learning Backward Compatible Embeddings. (arXiv:2206.03040v1 [stat.ML])
59. Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v1 [cs.SD])
60. Recent Advances for Quantum Neural Networks in Generative Learning. (arXiv:2206.03066v1 [quant-ph])
61. Patch-based image Super Resolution using generalized Gaussian mixture model. (arXiv:2206.03069v1 [eess.IV])
62. SubStrat: A Subset-Based Strategy for Faster AutoML. (arXiv:2206.03070v1 [cs.LG])
63. An Empirical Study of IoT Security Aspects at Sentence-Level in Developer Textual Discussions. (arXiv:2206.03079v1 [cs.CR])
64. Beyond spectral gap: The role of the topology in decentralized learning. (arXiv:2206.03093v1 [cs.LG])
65. Better Best of Both Worlds Bounds for Bandits with Switching Costs. (arXiv:2206.03098v1 [cs.LG])
66. Singapore Soundscape Site Selection Survey (S5): Identification of Characteristic Soundscapes of Singapore via Weighted k-means Clustering. (arXiv:2206.03112v1 [cs.LG])
67. Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse. (arXiv:2206.03126v1 [cs.LG])
68. Spatial-Temporal Adaptive Graph Convolution with Attention Network for Traffic Forecasting. (arXiv:2206.03128v1 [cs.LG])
69. Towards Meta-learned Algorithm Selection using Implicit Fidelity Information. (arXiv:2206.03130v1 [cs.LG])
70. CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities. (arXiv:2206.03132v1 [cs.AI])
71. Intra-agent speech permits zero-shot task acquisition. (arXiv:2206.03139v1 [cs.LG])
72. Group Meritocratic Fairness in Linear Contextual Bandits. (arXiv:2206.03150v1 [stat.ML])
73. Shuffled Check-in: Privacy Amplification towards Practical Distributed Learning. (arXiv:2206.03151v1 [cs.LG])
74. Utility of Equivariant Message Passing in Cortical Mesh Segmentation. (arXiv:2206.03164v1 [cs.CV])
75. Decentralized Low-Latency Collaborative Inference via Ensembles on the Edge. (arXiv:2206.03165v1 [cs.LG])
76. Look Back When Surprised: Stabilizing Reverse Experience Replay for Neural Approximation. (arXiv:2206.03171v1 [cs.LG])
77. Fooling Explanations in Text Classifiers. (arXiv:2206.03178v1 [cs.LG])
78. Risk Measures and Upper Probabilities: Coherence and Stratification. (arXiv:2206.03183v1 [cs.LG])
79. A new Hyper-heuristic based on Adaptive Simulated Annealing and Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem. (arXiv:2206.03185v1 [cs.AI])
80. Generalized Data Distribution Iteration. (arXiv:2206.03192v1 [cs.LG])
81. Explaining the physics of transfer learning a data-driven subgrid-scale closure to a different turbulent flow. (arXiv:2206.03198v1 [physics.flu-dyn])
82. FairVFL: A Fair Vertical Federated Learning Framework with Contrastive Adversarial Learning. (arXiv:2206.03200v1 [cs.LG])
83. From "Where" to "What": Towards Human-Understandable Explanations through Concept Relevance Propagation. (arXiv:2206.03208v1 [cs.LG])
84. Deep Neural Patchworks: Coping with Large Segmentation Tasks. (arXiv:2206.03210v1 [cs.CV])
85. Improved Cardiac Arrhythmia Prediction Based on Heart Rate Variability Analysis. (arXiv:2206.03222v1 [cs.LG])
86. Does Crypto Kill? Relationship between Electricity Consumption Carbon Footprints and Bitcoin Transactions. (arXiv:2206.03227v1 [cs.CY])
87. Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances. (arXiv:2206.03230v1 [stat.ML])
88. Inferring Unfairness and Error from Population Statistics in Binary and Multiclass Classification. (arXiv:2206.03234v1 [cs.LG])
89. Analyzing the impact of feature selection on the accuracy of heart disease prediction. (arXiv:2206.03239v1 [cs.LG])
90. Rites de Passage: Elucidating Displacement to Emplacement of Refugees. (arXiv:2206.03248v1 [cs.CY])
91. Demystifying the Global Convergence Puzzle of Learning Over-parameterized ReLU Nets in Very High Dimensions. (arXiv:2206.03254v1 [cs.LG])
92. Flexible Group Fairness Metrics for Survival Analysis. (arXiv:2206.03256v1 [cs.CY])
93. Marvolo: Programmatic Data Augmentation for Practical ML-Driven Malware Detection. (arXiv:2206.03265v1 [cs.CR])
94. Machine Learning Sensors. (arXiv:2206.03266v1 [cs.LG])
95. On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning. (arXiv:2206.03271v1 [cs.LG])
96. Collaborative Intelligence Orchestration: Inconsistency-Based Fusion of Semi-Supervised Learning and Active Learning. (arXiv:2206.03288v1 [cs.LG])
97. Future Artificial Intelligence tools and perspectives in medicine. (arXiv:2206.03289v1 [cs.LG])
98. GAAF: Searching Activation Functions for Binary Neural Networks through Genetic Algorithm. (arXiv:2206.03291v1 [cs.NE])
99. Joint Manifold Learning and Density Estimation Using Normalizing Flows. (arXiv:2206.03293v1 [cs.LG])
100. Generalization Error Bounds for Deep Neural Networks Trained by SGD. (arXiv:2206.03299v1 [cs.LG])
101. Recent Advances in Bayesian Optimization. (arXiv:2206.03301v1 [cs.LG])
102. On the balance between the training time and interpretability of neural ODE for time series modelling. (arXiv:2206.03304v1 [cs.LG])
103. Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate Model Predictive Trajectory Tracking. (arXiv:2206.03305v1 [cs.RO])
104. PyTSK: A Python Toolbox for TSK Fuzzy Systems. (arXiv:2206.03310v1 [cs.LG])
105. Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning. (arXiv:2206.03312v1 [cs.NE])
106. Integrating Random Effects in Deep Neural Networks. (arXiv:2206.03314v1 [stat.ML])
107. Neural Network Decoders for Permutation Codes Correcting Different Errors. (arXiv:2206.03315v1 [cs.IT])
108. Subject Membership Inference Attacks in Federated Learning. (arXiv:2206.03317v1 [cs.LG])
109. Early Abnormal Detection of Sewage Pipe Network: Bagging of Various Abnormal Detection Algorithms. (arXiv:2206.03321v1 [cs.LG])
110. Deep Learning-based FEA surrogate for sub-sea pressure vessel. (arXiv:2206.03322v1 [cs.LG])
111. Efficient decentralized multi-agent learning in asymmetric queuing systems. (arXiv:2206.03324v1 [cs.LG])
112. Searching Similarity Measure for Binarized Neural Networks. (arXiv:2206.03325v1 [cs.LG])
113. Efficient Machine Learning, Compilers, and Optimizations for Embedded Systems. (arXiv:2206.03326v1 [cs.LG])
114. Concentration bounds for SSP Q-learning for average cost MDPs. (arXiv:2206.03328v1 [cs.LG])
115. Improving the Diagnosis of Psychiatric Disorders with Self-Supervised Graph State Space Models. (arXiv:2206.03331v1 [cs.LG])
116. Assessing Project-Level Fine-Tuning of ML4SE Models. (arXiv:2206.03333v1 [cs.SE])
117. Parotid Gland MRI Segmentation Based on **Swin**-Unet and Multimodal Images. (arXiv:2206.03336v1 [eess.IV])
118. Preconditioned Gradient Descent for Overparameterized Nonconvex Burer--Monteiro Factorization with Global Optimality Certification. (arXiv:2206.03345v1 [math.OC])
119. Specification-Guided Learning of Nash Equilibria with High Social Welfare. (arXiv:2206.03348v1 [cs.GT])
120. AS2T: Arbitrary Source-To-Target Adversarial Attack on Speaker Recognition Systems. (arXiv:2206.03351v1 [cs.SD])
121. Adaptive Regularization for Adversarial Training. (arXiv:2206.03353v1 [stat.ML])
122. An efficient semi-supervised quality control system trained using physics-based MRI-artefact generators and adversarial training. (arXiv:2206.03359v1 [eess.IV])
123. Building Robust Ensembles via Margin Boosting. (arXiv:2206.03362v1 [cs.LG])
124. KPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular Property Prediction. (arXiv:2206.03364v1 [q-bio.BM])
125. DeepOPF-AL: Augmented Learning for Solving AC-OPF Problems with Multiple Load-Solution Mappings. (arXiv:2206.03365v1 [cs.LG])
126. Computational Doob's $h$-transforms for Online Filtering of Discretely Observed Diffusions. (arXiv:2206.03369v1 [stat.ML])
127. On Outer Bi-Lipschitz Extensions of Linear Johnson-Lindenstrauss Embeddings of Low-Dimensional Submanifolds of $\mathbb{R}^N$. (arXiv:2206.03376v1 [math.NA])
128. Imitating Past Successes can be Very Suboptimal. (arXiv:2206.03378v1 [cs.LG])
129. On the Role of Discount Factor in Offline Reinforcement Learning. (arXiv:2206.03383v1 [cs.LG])
130. Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics. (arXiv:2206.03390v1 [cs.CY])
131. Data Stealing Attack on Medical Images: Is it Safe to Export Networks from Data Lakes?. (arXiv:2206.03391v1 [cs.CR])
132. Towards Understanding and Mitigating Audio Adversarial Examples for Speaker Recognition. (arXiv:2206.03393v1 [cs.SD])
133. Group privacy for personalized federated learning. (arXiv:2206.03396v1 [cs.LG])
134. Towards a General Purpose CNN for Long Range Dependencies in $\mathrm{N}$D. (arXiv:2206.03398v1 [cs.LG])
135. FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v1 [cs.LG])
136. Improving Fairness in Graph Neural Networks via Mitigating Sensitive Attribute Leakage. (arXiv:2206.03426v1 [cs.LG])
137. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v1 [cs.CV])
138. Federated Hetero-Task Learning. (arXiv:2206.03436v1 [cs.LG])
139. Robust Sparse Mean Estimation via Sum of Squares. (arXiv:2206.03441v1 [cs.DS])
140. Learning in Observable POMDPs, without Computationally Intractable Oracles. (arXiv:2206.03446v1 [cs.LG])
141. Combining physics-based and data-driven techniques for reliable hybrid analysis and modeling using the corrective source term approach. (arXiv:2206.03451v1 [cs.LG])
142. Adversarial Reprogramming Revisited. (arXiv:2206.03466v1 [cs.LG])
143. Discrete State-Action Abstraction via the Successor Representation. (arXiv:2206.03467v1 [cs.AI])
144. FDGNN: Fully Dynamic Graph Neural Network. (arXiv:2206.03469v1 [cs.LG])
145. Short Blocklength Wiretap Channel Codes via Deep Learning: Design and Performance Evaluation. (arXiv:2206.03477v1 [cs.IT])
146. SHRED: 3D Shape Region Decomposition with Learned Local Operations. (arXiv:2206.03480v1 [cs.CV])
147. Parametric Chordal Sparsity for SDP-based Neural Network Verification. (arXiv:2206.03482v1 [cs.LG])
148. Few-Shot Learning by Dimensionality Reduction in Gradient Space. (arXiv:2206.03483v1 [cs.LG])
149. Unbiased estimators for random design regression. (arXiv:1907.03411v2 [stat.ML] UPDATED)
150. Stratified Rule-Aware Network for Abstract Visual Reasoning. (arXiv:2002.06838v3 [cs.CV] UPDATED)
151. Machine learning fairness notions: Bridging the gap with real-world applications. (arXiv:2006.16745v5 [cs.LG] UPDATED)
152. Survey on Causal-based Machine Learning Fairness Notions. (arXiv:2010.09553v7 [cs.LG] UPDATED)
153. Yet Another Representation of Binary Decision Trees: A Mathematical Demonstration. (arXiv:2101.07077v5 [cs.LG] UPDATED)
154. On Transportation of Mini-batches: A Hierarchical Approach. (arXiv:2102.05912v5 [stat.ML] UPDATED)
155. Bump Hunting in Latent Space. (arXiv:2103.06595v2 [hep-ph] UPDATED)
156. Consistency Regularization for Variational Auto-Encoders. (arXiv:2105.14859v2 [cs.LG] UPDATED)
157. A Robust Classification-autoencoder to Defend Outliers and Adversaries. (arXiv:2106.15927v2 [cs.LG] UPDATED)
158. An Embedding of ReLU Networks and an Analysis of their Identifiability. (arXiv:2107.09370v5 [cs.LG] UPDATED)
159. Unstructured Handwashing Recognition using Smartwatch to Reduce Contact Transmission of Pathogens. (arXiv:2107.13405v4 [cs.LG] UPDATED)
160. Improving Mini-batch Optimal Transport via Partial Transportation. (arXiv:2108.09645v4 [stat.ML] UPDATED)
161. Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v3 [cs.CL] UPDATED)
162. Computing Graph Descriptors on Edge Streams. (arXiv:2109.01494v4 [cs.LG] UPDATED)
163. DeepMTS: Deep Multi-task Learning for Survival Prediction in Patients with Advanced Nasopharyngeal Carcinoma using Pretreatment PET/CT. (arXiv:2109.07711v2 [eess.IV] UPDATED)
164. The Fragility of Optimized Bandit Algorithms. (arXiv:2109.13595v2 [cs.LG] UPDATED)
165. Cycle-Consistent World Models for Domain Independent Latent Imagination. (arXiv:2110.00808v2 [cs.LG] UPDATED)
166. Task-aware Privacy Preservation for Multi-dimensional Data. (arXiv:2110.02329v2 [cs.CR] UPDATED)
167. Lottery Tickets with Nonzero Biases. (arXiv:2110.11150v2 [cs.LG] UPDATED)
168. TUNet: A Block-online Bandwidth Extension Model based on Transformers and Self-supervised Pretraining. (arXiv:2110.13492v5 [cs.LG] UPDATED)
169. Towards Fairness-Aware Federated Learning. (arXiv:2111.01872v2 [cs.LG] UPDATED)
170. On the Use and Misuse of Absorbing States in Multi-agent Reinforcement Learning. (arXiv:2111.05992v2 [cs.LG] UPDATED)
171. Learning in High-Dimensional Feature Spaces Using ANOVA-Based Fast Matrix-Vector Multiplication. (arXiv:2111.10140v2 [cs.LG] UPDATED)
172. Plant 'n' Seek: Can You Find the Winning Ticket?. (arXiv:2111.11153v2 [cs.LG] UPDATED)
173. Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion. (arXiv:2111.12602v4 [cs.CV] UPDATED)
174. Survey Descent: A Multipoint Generalization of Gradient Descent for Nonsmooth Optimization. (arXiv:2111.15645v4 [math.OC] UPDATED)
175. Optimal Best Arm Identification in Two-Armed Bandits with a Fixed Budget under a Small Gap. (arXiv:2201.04469v7 [stat.ML] UPDATED)
176. GradMax: Growing Neural Networks using Gradient Information. (arXiv:2201.05125v3 [cs.LG] UPDATED)
177. Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next. (arXiv:2201.05624v4 [cs.LG] UPDATED)
178. DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for Layer Fusion in DNN Accelerators. (arXiv:2201.11218v2 [cs.LG] UPDATED)
179. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v3 [cs.LG] UPDATED)
180. On Recoverability of Graph Neural Network Representations. (arXiv:2201.12843v2 [cs.LG] UPDATED)
181. Progressive Distillation for Fast Sampling of Diffusion Models. (arXiv:2202.00512v2 [cs.LG] UPDATED)
182. Molecular Representation Learning via Heterogeneous Motif Graph Neural Networks. (arXiv:2202.00529v2 [cs.LG] UPDATED)
183. Selection in the Presence of Implicit Bias: The Advantage of Intersectional Constraints. (arXiv:2202.01661v2 [cs.CY] UPDATED)
184. Reweighing auxiliary losses in supervised learning. (arXiv:2202.03250v2 [cs.LG] UPDATED)
185. On the Convergence of Clustered Federated Learning. (arXiv:2202.06187v2 [cs.LG] UPDATED)
186. Debiased Self-Training for Semi-Supervised Learning. (arXiv:2202.07136v3 [cs.LG] UPDATED)
187. The Pareto Frontier of Instance-Dependent Guarantees in Multi-Player Multi-Armed Bandits with no Communication. (arXiv:2202.09653v2 [cs.LG] UPDATED)
188. Truncated Diffusion Probabilistic Models. (arXiv:2202.09671v2 [stat.ML] UPDATED)
189. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v2 [cs.LG] UPDATED)
190. Generative modeling via tensor train sketching. (arXiv:2202.11788v2 [math.NA] UPDATED)
191. First is Better Than Last for Training Data Influence. (arXiv:2202.11844v2 [cs.LG] UPDATED)
192. Benign Underfitting of Stochastic Gradient Descent. (arXiv:2202.13361v3 [cs.LG] UPDATED)
193. Label-Free Explainability for Unsupervised Models. (arXiv:2203.01928v2 [cs.LG] UPDATED)
194. Unsupervised Domain Adaptation across FMCW Radar Configurations Using Margin Disparity Discrepancy. (arXiv:2203.04588v2 [eess.SP] UPDATED)
195. A Contribution-based Device Selection Scheme in Federated Learning. (arXiv:2203.05369v2 [cs.LG] UPDATED)
196. Identifiability of Causal-based Fairness Notions: A State of the Art. (arXiv:2203.05900v2 [cs.LG] UPDATED)
197. Time-series image denoising of pressure-sensitive paint data by projected multivariate singular spectrum analysis. (arXiv:2203.07574v2 [eess.IV] UPDATED)
198. Reachability In Simple Neural Networks. (arXiv:2203.07941v2 [cs.CC] UPDATED)
199. Few-Shot Learning on Graphs. (arXiv:2203.09308v2 [cs.LG] UPDATED)
200. Federated Spatial Reuse Optimization in Next-Generation Decentralized IEEE 802.11 WLANs. (arXiv:2203.10472v2 [cs.NI] UPDATED)
201. Neural Lagrangian Schr\"odinger Bridge. (arXiv:2204.04853v3 [cs.LG] UPDATED)
202. A Machine Learning Tutorial for Operational Meteorology, Part I: Traditional Machine Learning. (arXiv:2204.07492v2 [physics.ao-ph] UPDATED)
203. Beyond Lipschitz: Sharp Generalization and Excess Risk Bounds for Full-Batch GD. (arXiv:2204.12446v3 [stat.ML] UPDATED)
204. CANShield: Signal-based Intrusion Detection for Controller Area Networks. (arXiv:2205.01306v3 [cs.CR] UPDATED)
205. Reachability Constrained Reinforcement Learning. (arXiv:2205.07536v2 [cs.LG] UPDATED)
206. Simple Contrastive Graph Clustering. (arXiv:2205.07865v2 [cs.LG] UPDATED)
207. BabyNet: Residual Transformer Module for Birth Weight Prediction on Fetal Ultrasound Video. (arXiv:2205.09382v2 [eess.IV] UPDATED)
208. SelfReformer: Self-Refined Network with Transformer for Salient Object Detection. (arXiv:2205.11283v2 [cs.CV] UPDATED)
209. AsyncFedED: Asynchronous Federated Learning with Euclidean Distance based Adaptive Weight Aggregation. (arXiv:2205.13797v2 [cs.LG] UPDATED)
210. ByteComp: Revisiting Gradient Compression in Distributed Training. (arXiv:2205.14465v2 [cs.LG] UPDATED)
211. Adversarial Bandits Robust to $S$-Switch Regret. (arXiv:2205.14839v2 [cs.LG] UPDATED)
212. Harnessing spectral representations for subgraph alignment. (arXiv:2205.14938v2 [cs.LG] UPDATED)
213. Mitigating Dataset Bias by Using Per-sample Gradient. (arXiv:2205.15704v2 [cs.LG] UPDATED)
214. Evolving Domain Generalization. (arXiv:2206.00047v2 [cs.LG] UPDATED)
215. Collaborative Learning of Distributions under Heterogeneity and Communication Constraints. (arXiv:2206.00707v2 [stat.ML] UPDATED)
216. Applied Federated Learning: Architectural Design for Robust and Efficient Learning in Privacy Aware Settings. (arXiv:2206.00807v2 [cs.LG] UPDATED)
217. Federated Learning with a Sampling Algorithm under Isoperimetry. (arXiv:2206.00920v2 [cs.LG] UPDATED)
218. Approximate Network Motif Mining Via Graph Learning. (arXiv:2206.01008v2 [cs.LG] UPDATED)
219. Algorithmic Stability of Heavy-Tailed Stochastic Gradient Descent on Least Squares. (arXiv:2206.01274v2 [stat.ML] UPDATED)
220. Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v2 [stat.ML] UPDATED)
221. Deep Learning Prediction of Severe Health Risks for Pediatric COVID-19 Patients with a Large Feature Set in 2021 BARDA Data Challenge. (arXiv:2206.01696v2 [cs.LG] UPDATED)
222. Variable-rate hierarchical CPC leads to acoustic unit discovery in speech. (arXiv:2206.02211v2 [cs.SD] UPDATED)
223. Adaptive Rollout Length for Model-Based RL Using Model-Free Deep RL. (arXiv:2206.02380v2 [cs.LG] UPDATED)
224. Mean Estimation in High-Dimensional Binary Markov Gaussian Mixture Models. (arXiv:2206.02455v2 [math.ST] UPDATED)
225. UTTS: Unsupervised TTS with Conditional Disentangled Sequential Variational Auto-encoder. (arXiv:2206.02512v2 [eess.AS] UPDATED)
226. Per-Instance Privacy Accounting for Differentially Private Stochastic Gradient Descent. (arXiv:2206.02617v2 [cs.LG] UPDATED)
227. Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning. (arXiv:2206.02670v2 [cs.LG] UPDATED)
228. Dual Decomposition of Convex Optimization Layers for Consistent Attention in Medical Images. (arXiv:2206.02761v2 [cs.CV] UPDATED)
## cs.AI
---
**105** new papers in cs.AI:-) 
1. Towards Job-Transition-Tag Graph for a Better Job Title Representation Learning. (arXiv:2206.02782v1 [cs.LG])
2. Intake Monitoring in Free-Living Conditions: Overview and Lessons we Have Learned. (arXiv:2206.02784v1 [cs.HC])
3. Zeroth-Order SciML: Non-intrusive Integration of Scientific Software with Deep Learning. (arXiv:2206.02785v1 [cs.LG])
4. Improving Model Understanding and Trust with Counterfactual Explanations of Model Confidence. (arXiv:2206.02790v1 [cs.LG])
5. FIFA: Making Fairness More Generalizable in Classifiers Trained on Imbalanced Data. (arXiv:2206.02792v1 [cs.LG])
6. FedNST: Federated Noisy Student Training for Automatic Speech Recognition. (arXiv:2206.02797v1 [eess.AS])
7. Quantum Neural Network Classifiers: A Tutorial. (arXiv:2206.02806v1 [quant-ph])
8. RORL: Robust Offline Reinforcement Learning via Conservative Smoothing. (arXiv:2206.02829v1 [cs.LG])
9. Researching Alignment Research: Unsupervised Analysis. (arXiv:2206.02841v1 [cs.CY])
10. A Bird's-Eye Tutorial of Graph Attention Architectures. (arXiv:2206.02849v1 [cs.LG])
11. Efficient entity-based reinforcement learning. (arXiv:2206.02855v1 [cs.LG])
12. Physics and semantic informed multi-sensor calibration via optimization theory and self-supervised learning. (arXiv:2206.02856v1 [cs.RO])
13. Self-supervised Learning for Human Activity Recognition Using 700,000 Person-days of Wearable Data. (arXiv:2206.02909v1 [eess.SP])
14. Training Subset Selection for Weak Supervision. (arXiv:2206.02914v1 [stat.ML])
15. Remember the Past: Distilling Datasets into Addressable Memories for Neural Networks. (arXiv:2206.02916v1 [cs.LG])
16. Schema-Guided Event Graph Completion. (arXiv:2206.02921v1 [cs.LG])
17. Understanding Machine Learning Practitioners' Data Documentation Perceptions, Needs, Challenges, and Desiderata. (arXiv:2206.02923v1 [cs.HC])
18. Neuro-Symbolic Causal Language Planning with Commonsense Prompting. (arXiv:2206.02928v1 [cs.CL])
19. GRETEL: A unified framework for Graph Counterfactual Explanation Evaluation. (arXiv:2206.02957v1 [cs.LG])
20. Improving Knowledge Graph Embedding via Iterative Self-Semantic Knowledge Distillation. (arXiv:2206.02963v1 [cs.LG])
21. Masked Unsupervised Self-training for Zero-shot Image Classification. (arXiv:2206.02967v1 [cs.CV])
22. Enhancing Dual-Encoders with Question and Answer Cross-Embeddings for Answer Retrieval. (arXiv:2206.02978v1 [cs.CL])
23. Driving in Real Life with Inverse Reinforcement Learning. (arXiv:2206.03004v1 [cs.RO])
24. TriBYOL: Triplet BYOL for Self-Supervised Representation Learning. (arXiv:2206.03012v1 [cs.CV])
25. Development of Automatic Endotracheal Tube and Carina Detection on Portable Supine Chest Radiographs using Artificial Intelligence. (arXiv:2206.03017v1 [cs.CV])
26. How Far I'll Go: Offline Goal-Conditioned Reinforcement Learning via $f$-Advantage Regression. (arXiv:2206.03023v1 [cs.LG])
27. Learning Symbolic Operators: A Neurosymbolic Solution for Autonomous Disassembly of Electric Vehicle Battery. (arXiv:2206.03027v1 [cs.RO])
28. CAISAR: A platform for Characterizing Artificial Intelligence Safety and Robustness. (arXiv:2206.03044v1 [cs.AI])
29. Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v1 [cs.SD])
30. Normalisations of Existential Rules: Not so Innocuous!. (arXiv:2206.03124v1 [cs.AI])
31. CitySpec: An Intelligent Assistant System for Requirement Specification in Smart Cities. (arXiv:2206.03132v1 [cs.AI])
32. Intra-agent speech permits zero-shot task acquisition. (arXiv:2206.03139v1 [cs.LG])
33. Representational Systems Theory: A Unified Approach to Encoding, Analysing and Transforming Representations. (arXiv:2206.03172v1 [cs.AI])
34. TSFEDL: A Python Library for Time Series Spatio-Temporal Feature Extraction and Prediction using Deep Learning (with Appendices on Detailed Network Architectures and Experimental Cases of Study). (arXiv:2206.03179v1 [cs.NE])
35. A new Hyper-heuristic based on Adaptive Simulated Annealing and Reinforcement Learning for the Capacitated Electric Vehicle Routing Problem. (arXiv:2206.03185v1 [cs.AI])
36. Generalized Data Distribution Iteration. (arXiv:2206.03192v1 [cs.LG])
37. FlexLip: A Controllable Text-to-Lip System. (arXiv:2206.03206v1 [eess.AS])
38. Omnivision forecasting: combining satellite observations with sky images for improved intra-hour solar energy predictions. (arXiv:2206.03207v1 [cs.CV])
39. From "Where" to "What": Towards Human-Understandable Explanations through Concept Relevance Propagation. (arXiv:2206.03208v1 [cs.LG])
40. Variational Meta Reinforcement Learning for Social Robotics. (arXiv:2206.03211v1 [cs.RO])
41. Improving Students' Academic Performance with AI and Semantic Technologies. (arXiv:2206.03213v1 [cs.CY])
42. Data Governance in the Age of Large-Scale Data-Driven Language Technology. (arXiv:2206.03216v1 [cs.CY])
43. A Perspective on K-12 AI Education. (arXiv:2206.03217v1 [cs.CY])
44. A Transparency Index Framework for AI in Education. (arXiv:2206.03220v1 [cs.CY])
45. The Beyond the Fence Musical and Computer Says Show Documentary. (arXiv:2206.03224v1 [cs.CY])
46. The Different Faces of AI Ethics Across the World: A Principle-Implementation Gap Analysis. (arXiv:2206.03225v1 [cs.CY])
47. Fairness and Explainability in Automatic Decision-Making Systems. A challenge for computer science and law. (arXiv:2206.03226v1 [cs.CY])
48. The risk ethics of autonomous vehicles: a continuous trolley problem in regular road traffic. (arXiv:2206.03258v1 [cs.CY])
49. Optimists at Heart: Why Do We Research Game AI? (Extended Version). (arXiv:2206.03261v1 [cs.CY])
50. On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning. (arXiv:2206.03271v1 [cs.LG])
51. The Algorithmic Imprint. (arXiv:2206.03275v1 [cs.CY])
52. Physics-Inspired Temporal Learning of Quadrotor Dynamics for Accurate Model Predictive Trajectory Tracking. (arXiv:2206.03305v1 [cs.RO])
53. Neuro-Nav: A Library for Neurally-Plausible Reinforcement Learning. (arXiv:2206.03312v1 [cs.NE])
54. Subject Membership Inference Attacks in Federated Learning. (arXiv:2206.03317v1 [cs.LG])
55. Deep Learning-based FEA surrogate for sub-sea pressure vessel. (arXiv:2206.03322v1 [cs.LG])
56. Specification-Guided Learning of Nash Equilibria with High Social Welfare. (arXiv:2206.03348v1 [cs.GT])
57. Searching for Optimal Subword Tokenization in Cross-domain NER. (arXiv:2206.03352v1 [cs.CL])
58. Position Paper: Online Modeling for Offline Planning. (arXiv:2206.03356v1 [cs.AI])
59. Towards Explainable Social Agent Authoring tools: A case study on FAtiMA-Toolkit. (arXiv:2206.03360v1 [cs.MA])
60. Building Robust Ensembles via Margin Boosting. (arXiv:2206.03362v1 [cs.LG])
61. KPGT: Knowledge-Guided Pre-training of Graph Transformer for Molecular Property Prediction. (arXiv:2206.03364v1 [q-bio.BM])
62. Imitating Past Successes can be Very Suboptimal. (arXiv:2206.03378v1 [cs.LG])
63. Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics. (arXiv:2206.03390v1 [cs.CY])
64. Towards Understanding and Mitigating Audio Adversarial Examples for Speaker Recognition. (arXiv:2206.03393v1 [cs.SD])
65. Group privacy for personalized federated learning. (arXiv:2206.03396v1 [cs.LG])
66. MIX-MAB: Reinforcement Learning-based Resource Allocation Algorithm for LoRaWAN. (arXiv:2206.03401v1 [cs.NI])
67. FedRel: An Adaptive Federated Relevance Framework for Spatial Temporal Graph Learning. (arXiv:2206.03420v1 [cs.LG])
68. Revealing Single Frame Bias for Video-and-Language Learning. (arXiv:2206.03428v1 [cs.CV])
69. Generating Long Videos of Dynamic Scenes. (arXiv:2206.03429v1 [cs.CV])
70. Learning in Observable POMDPs, without Computationally Intractable Oracles. (arXiv:2206.03446v1 [cs.LG])
71. Discrete State-Action Abstraction via the Successor Representation. (arXiv:2206.03467v1 [cs.AI])
72. Stratified Rule-Aware Network for Abstract Visual Reasoning. (arXiv:2002.06838v3 [cs.CV] UPDATED)
73. Machine learning fairness notions: Bridging the gap with real-world applications. (arXiv:2006.16745v5 [cs.LG] UPDATED)
74. SAS: Self-Augmentation Strategy for Language Model Pre-training. (arXiv:2106.07176v4 [cs.CL] UPDATED)
75. Boosting Search Engines with Interactive Agents. (arXiv:2109.00527v3 [cs.CL] UPDATED)
76. Computing Graph Descriptors on Edge Streams. (arXiv:2109.01494v4 [cs.LG] UPDATED)
77. Low-Resource Named Entity Recognition Based on Multi-hop Dependency Trigger. (arXiv:2109.07118v2 [cs.CL] UPDATED)
78. Lottery Tickets with Nonzero Biases. (arXiv:2110.11150v2 [cs.LG] UPDATED)
79. Towards Fairness-Aware Federated Learning. (arXiv:2111.01872v2 [cs.LG] UPDATED)
80. On the Use and Misuse of Absorbing States in Multi-agent Reinforcement Learning. (arXiv:2111.05992v2 [cs.LG] UPDATED)
81. Plant 'n' Seek: Can You Find the Winning Ticket?. (arXiv:2111.11153v2 [cs.LG] UPDATED)
82. Hierarchical Graph-Convolutional Variational AutoEncoding for Generative Modelling of Human Motion. (arXiv:2111.12602v4 [cs.CV] UPDATED)
83. Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next. (arXiv:2201.05624v4 [cs.LG] UPDATED)
84. DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for Layer Fusion in DNN Accelerators. (arXiv:2201.11218v2 [cs.LG] UPDATED)
85. Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks. (arXiv:2201.12179v3 [cs.LG] UPDATED)
86. Progressive Distillation for Fast Sampling of Diffusion Models. (arXiv:2202.00512v2 [cs.LG] UPDATED)
87. Selection in the Presence of Implicit Bias: The Advantage of Intersectional Constraints. (arXiv:2202.01661v2 [cs.CY] UPDATED)
88. Deconstructing Distributions: A Pointwise Framework of Learning. (arXiv:2202.09931v2 [cs.LG] UPDATED)
89. Label-Free Explainability for Unsupervised Models. (arXiv:2203.01928v2 [cs.LG] UPDATED)
90. Federated Spatial Reuse Optimization in Next-Generation Decentralized IEEE 802.11 WLANs. (arXiv:2203.10472v2 [cs.NI] UPDATED)
91. Iterative Depth-First Search for FOND Planning. (arXiv:2204.04322v2 [cs.AI] UPDATED)
92. Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and A Vision-Language Framework. (arXiv:2205.03860v3 [cs.CV] UPDATED)
93. Reachability Constrained Reinforcement Learning. (arXiv:2205.07536v2 [cs.LG] UPDATED)
94. Simple Contrastive Graph Clustering. (arXiv:2205.07865v2 [cs.LG] UPDATED)
95. A framework for self-supervised MR image reconstruction using sub-sampling via Noisier2Noise. (arXiv:2205.10278v2 [eess.IV] UPDATED)
96. Enhancing Sequential Recommendation with Graph Contrastive Learning. (arXiv:2205.14837v2 [cs.IR] UPDATED)
97. Leveraging Pre-Trained Language Models to Streamline Natural Language Interaction for Self-Tracking. (arXiv:2205.15503v3 [cs.CL] UPDATED)
98. Optimal Activation Functions for the Random Features Regression Model. (arXiv:2206.01332v2 [stat.ML] UPDATED)
99. The Spike Gating Flow: A Hierarchical Structure Based Spiking Neural Network for Online Gesture Recognition. (arXiv:2206.01910v2 [cs.CV] UPDATED)
100. CAINNFlow: Convolutional block Attention modules and Invertible Neural Networks Flow for anomaly detection and localization tasks. (arXiv:2206.01992v2 [cs.CV] UPDATED)
101. Variable-rate hierarchical CPC leads to acoustic unit discovery in speech. (arXiv:2206.02211v2 [cs.SD] UPDATED)
102. On the Advance of Making Language Models Better Reasoners. (arXiv:2206.02336v2 [cs.CL] UPDATED)
103. Adaptive Rollout Length for Model-Based RL Using Model-Free Deep RL. (arXiv:2206.02380v2 [cs.LG] UPDATED)
104. UTTS: Unsupervised TTS with Conditional Disentangled Sequential Variational Auto-encoder. (arXiv:2206.02512v2 [eess.AS] UPDATED)
105. Robust Adversarial Attacks Detection based on Explainable Deep Reinforcement Learning For UAV Guidance and Planning. (arXiv:2206.02670v2 [cs.LG] UPDATED)

