# Your interest papers
---
## cs.CV
---
### Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
- Authors : Masud An, Nur Islam, Nazmus Saqib, Shafkat Khan, Ho Yub
- Link : [http://arxiv.org/abs/2207.05176](http://arxiv.org/abs/2207.05176)
> ABSTRACT  :  Image denoising is still a challenging issue in many computer vision sub-domains. Recent studies show that significant improvements are made possible in a supervised setting. However, few challenges, such as spatial fidelity and cartoon-like smoothing remain unresolved or decisively overlooked. Our study proposes a simple yet efficient architecture for the denoising problem that addresses the aforementioned issues. The proposed architecture revisits the concept of modular concatenation instead of long and deeper cascaded connections, to recover a cleaner approximation of the given image. We find that different modules can capture versatile representations, and concatenated representation creates a richer subspace for low-level image **restoration**. The proposed architecture's number of parameters remains smaller than the number for most of the previous networks and still achieves significant improvements over the current state-of-the-art networks.  
### Revisiting Inlier and Outlier Specification for Improved Out-of-Distribution Detection. (arXiv:2207.05286v1 [cs.CV])
- Authors : Vivek Narayanaswamy, Yamen Mubarka, Rushil Anirudh, Deepta Rajan, Andreas Spanias
- Link : [http://arxiv.org/abs/2207.05286](http://arxiv.org/abs/2207.05286)
> ABSTRACT  :  Accurately detecting out-of-distribution (OOD) data with varying levels of semantic and covariate shifts with respect to the in-distribution (ID) data is critical for deployment of safe and reliable models. This is particularly the case when dealing with highly consequential applications (e.g. medical imaging, self-driving cars, etc). The goal is to design a detector that can accept meaningful variations of the ID data, while also rejecting examples from OOD regimes. In practice, this dual objective can be realized by enforcing consistency using an appropriate scoring function (e.g., energy) and calibrating the detector to reject a curated set of OOD data (referred to as outlier **exposure** or shortly OE). While OE methods are widely adopted, assembling representative OOD datasets is both costly and challenging due to the unpredictability of real-world scenarios, hence the recent trend of designing OE-free detectors. In this paper, we make a surprising finding that controlled generalization to ID variations and **exposure** to diverse (synthetic) outlier examples are essential to simultaneously improving semantic and modality shift detection. In contrast to existing methods, our approach samples inliers in the latent space, and constructs outlier examples via negative data augmentation. Through a rigorous empirical study on medical imaging benchmarks (MedMNIST, ISIC2019 and NCT), we demonstrate significant performance gains ($15\% - 35\%$ in AUROC) over existing OE-free, OOD detection approaches under both semantic and modality shifts.  
### UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v1 [cs.CV])
- Authors : Jihao Liu, Xin Huang, Guanglu Song, Yu Liu, Hongsheng Li
- Link : [http://arxiv.org/abs/2207.05420](http://arxiv.org/abs/2207.05420)
> ABSTRACT  :  Recently, transformer and multi-layer perceptron (MLP) architectures have achieved impressive results on various vision tasks. However, how to effectively combine those operators to form high-performance hybrid visual architectures still remains a challenge. In this work, we study the learnable combination of convolution, transformer, and MLP by proposing a novel unified architecture search approach. Our approach contains two key designs to achieve the search for high-performance networks. First, we model the very different searchable operators in a unified form, and thus enable the operators to be characterized with the same set of configuration parameters. In this way, the overall search space size is significantly reduced, and the total search cost becomes affordable. Second, we propose context-aware downsampling modules (DSMs) to mitigate the gap between the different types of operators. Our proposed DSMs are able to better adapt features from different types of operators, which is important for identifying high-performance hybrid architectures. Finally, we integrate configurable operators and DSMs into a unified search space and search with a Reinforcement Learning-based search algorithm to fully explore the optimal combination of the operators. To this end, we search a baseline network and scale it up to obtain a family of models, named UniNets, which achieve much better accuracy and efficiency than previous ConvNets and Transformers. In particular, our UniNet-B5 achieves 84.9% top-1 accuracy on ImageNet, outperforming EfficientNet-B7 and BoTNet-T7 with 44% and 55% fewer FLOPs respectively. By pretraining on the ImageNet-21K, our UniNet-B6 achieves 87.4%, outperforming **Swin**-L with 51% fewer FLOPs and 41% fewer parameters. Code is available at https://github.com/Sense-X/UniNet.  
### On the limits of perceptual quality measures for enhanced underwater images. (arXiv:2207.05470v1 [cs.CV])
- Authors : Chau Yi, Andrea Cavallaro
- Link : [http://arxiv.org/abs/2207.05470](http://arxiv.org/abs/2207.05470)
> ABSTRACT  :  The appearance of objects in underwater images is degraded by the selective attenuation of light, which reduces contrast and causes a colour cast. This degradation depends on the water environment, and increases with depth and with the distance of the object from the camera. Despite an increasing volume of works in underwater image **enhancement** and **restoration**, the lack of a commonly accepted evaluation measure is hindering the progress as it is difficult to compare methods. In this paper, we review commonly used colour accuracy measures, such as colour reproduction error and CIEDE2000, and no-reference image quality measures, such as UIQM, UCIQE and CCF, which have not yet been systematically validated. We show that none of the no-reference quality measures satisfactorily rates the quality of enhanced underwater images and discuss their main shortcomings. Images and results are available at https://puiqe.eecs.qmul.ac.uk.  
### Ego-motion Estimation Based on Fusion of Images and Events. (arXiv:2207.05588v1 [cs.CV])
- Authors : Liren Yang
- Link : [http://arxiv.org/abs/2207.05588](http://arxiv.org/abs/2207.05588)
> ABSTRACT  :  Event camera is a novel bio-inspired vision sensor that outputs event stream. In this paper, we propose a novel data fusion algorithm called EAS to fuse conventional intensity images with the event stream. The fusion result is applied to some ego-motion estimation frameworks, and is evaluated on a public dataset acquired in dim scenes. In our 3-DoF rotation estimation framework, EAS achieves the highest estimation accuracy among intensity images and representations of events including event slice, TS and SITS. Compared with original images, EAS reduces the average APE by 69%, benefiting from the inclusion of more features for tracking. The result shows that our algorithm effectively leverages the **high dynamic range** of event cameras to improve the performance of the ego-motion estimation framework based on optical flow tracking in difficult illumination conditions.  
### Towards **Real-time** High-Definition Image Snow Removal: Efficient Pyramid Network with Asymmetrical Encoder-decoder Architecture. (arXiv:2207.05605v1 [cs.CV])
- Authors : Tian Ye, Sixiang Chen, Yun Liu, Yi Ye, Erkang Chen
- Link : [http://arxiv.org/abs/2207.05605](http://arxiv.org/abs/2207.05605)
> ABSTRACT  :  In winter scenes, the degradation of images taken under snow can be pretty complex, where the spatial distribution of snowy degradation is varied from image to image. Recent methods adopt deep neural networks to directly recover clean scenes from snowy images. However, due to the paradox caused by the variation of complex snowy degradation, achieving reliable High-Definition image desnowing performance in **real time** is a considerable challenge. We develop a novel Efficient Pyramid Network with asymmetrical encoder-decoder architecture for real-time HD image desnowing. The general idea of our proposed network is to utilize the multi-scale feature flow fully and implicitly mine clean cues from features. Compared with previous state-of-the-art desnowing methods, our approach achieves a better complexity-performance trade-off and effectively handles the processing difficulties of HD and Ultra-HD images.    The extensive experiments on three large-scale image desnowing datasets demonstrate that our method surpasses all state-of-the-art approaches by a large margin both quantitatively and qualitatively, boosting the PSNR metric from 31.76 dB to 34.10 dB on the CSD test dataset and from 28.29 dB to 30.87 dB on the SRRS test dataset.  
### MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing. (arXiv:2207.05621v1 [cs.CV])
- Authors : Sixiang Chen, Tian Ye, Yun Liu, Taodong Liao, Yi Ye, Erkang Chen
- Link : [http://arxiv.org/abs/2207.05621](http://arxiv.org/abs/2207.05621)
> ABSTRACT  :  Image **restoration** of snow scenes in severe weather is a difficult task. Snow images have complex degradations and are cluttered over clean images, changing the distribution of clean images. The previous methods based on CNNs are challenging to remove perfectly in restoring snow scenes due to their local inductive biases' lack of a specific global modeling ability. In this paper, we apply the vision transformer to the task of snow removal from a single image. Specifically, we propose a parallel network architecture split along the channel, performing local feature refinement and global information modeling separately. We utilize a channel shuffle operation to combine their respective strengths to enhance network performance. Second, we propose the MSP module, which utilizes multi-scale avgpool to aggregate information of different sizes and simultaneously performs multi-scale projection self-attention on multi-head self-attention to improve the representation ability of the model under different scale degradations. Finally, we design a lightweight and simple local capture module, which can refine the local capture capability of the model.    In the experimental part, we conduct extensive experiments to demonstrate the superiority of our method. We compared the previous snow removal methods on three snow scene datasets. The experimental results show that our method surpasses the state-of-the-art methods with fewer parameters and computation. We achieve substantial growth by 1.99dB and SSIM 0.03 on the CSD test dataset. On the SRRS and Snow100K datasets, we also increased PSNR by 2.47dB and 1.62dB compared with the Transweather approach and improved by 0.03 in SSIM. In the visual comparison section, our MSP-Former also achieves better visual effects than existing methods, proving the usability of our method.  
### Vision Transformer for **NeRF**-Based View Synthesis from a Single Input Image. (arXiv:2207.05736v1 [cs.CV])
- Authors : En Lin, Lin Yen, Sheng Lai, Yi Lin, Chang Shih, Ravi Ramamoorthi
- Link : [http://arxiv.org/abs/2207.05736](http://arxiv.org/abs/2207.05736)
> ABSTRACT  :  Although neural radiance fields (**NeRF**) have shown impressive advances for novel view synthesis, most methods typically require multiple input images of the same scene with accurate camera poses. In this work, we seek to substantially reduce the inputs to a single unposed image. Existing approaches condition on local image features to reconstruct a 3D object, but often render blurry predictions at viewpoints that are far away from the source view. To address this issue, we propose to leverage both the global and local features to form an expressive 3D representation. The global features are learned from a vision transformer, while the local features are extracted from a 2D convolutional network. To synthesize a novel view, we train a multilayer perceptron (MLP) network conditioned on the learned 3D representation to perform volume rendering. This novel 3D representation allows the network to reconstruct unseen regions without enforcing constraints like symmetry or canonical coordinate systems. Our method can render novel views from only a single input image and generalize across multiple object categories using a single model. Quantitative and qualitative evaluations demonstrate that the proposed method achieves state-of-the-art performance and renders richer details than existing approaches.  
### Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v3 [eess.IV] UPDATED)
- Authors : Xiaojie Chu, Liangyu Chen, Chengpeng Chen, Xin Lu
- Link : [http://arxiv.org/abs/2112.04491](http://arxiv.org/abs/2112.04491)
> ABSTRACT  :  Global operations, such as global average pooling, are widely used in top-performance image restorers. They aggregate global information from input features along entire spatial dimensions but behave differently during training and inference in image **restoration** tasks: they are based on different regions, namely the cropped patches (from images) and the full-resolution images. This paper revisits global information aggregation and finds that the image-based features during inference have a different distribution than the patch-based features during training. This train-test inconsistency negatively impacts the performance of models, which is severely overlooked by previous works. To reduce the inconsistency and improve test-time performance, we propose a simple method called Test-time Local Converter (TLC). Our TLC converts global operations to local ones only during inference so that they aggregate features within local spatial regions rather than the entire large images. The proposed method can be applied to various global modules (e.g., normalization, channel and spatial attention) with negligible costs. Without the need for any fine-tuning, TLC improves state-of-the-art results on several image **restoration** tasks, including single-image motion deblurring, video deblurring, defocus deblurring, and image denoising. In particular, with TLC, our Restormer-Local improves the state-of-the-art result in single image deblurring from 32.92 dB to 33.57 dB on GoPro dataset. The code is available at https://github.com/megvii-research/tlc.  
### Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v2 [eess.IV] UPDATED)
- Authors : Xiang Chen, Zhentao Fan, Pengpeng Li, Longgang Dai, Caihua Kong, Zhuoran Zheng, Yufeng Huang, Yufeng Li
- Link : [http://arxiv.org/abs/2203.07677](http://arxiv.org/abs/2203.07677)
> ABSTRACT  :  We offer a practical unpaired learning based image dehazing network from an unpaired set of clear and hazy images. This paper provides a new perspective to treat image dehazing as a two-class separated factor disentanglement task, i.e, the task-relevant factor of clear image reconstruction and the task-irrelevant factor of haze-relevant distribution. To achieve the disentanglement of these two-class factors in deep feature space, contrastive learning is introduced into a CycleGAN framework to learn disentangled representations by guiding the generated images to be associated with latent factors. With such formulation, the proposed contrastive disentangled dehazing method (CDD-GAN) employs negative generators to cooperate with the encoder network to update alternately, so as to produce a queue of challenging negative adversaries. Then these negative adversaries are trained end-to-end together with the backbone representation network to enhance the discriminative information and promote factor disentanglement performance by maximizing the adversarial contrastive loss. During the training, we further show that hard negative examples can suppress the task-irrelevant factors and unpaired clear exemples can enhance the task-relevant factors, in order to better facilitate haze removal and help image **restoration**. Extensive experiments on both synthetic and real-world datasets demonstrate that our method performs favorably against existing unpaired dehazing baselines.  
### Eye**NeRF**: A Hybrid Representation for Photorealistic Synthesis, Animation and Relighting of Human Eyes. (arXiv:2206.08428v2 [cs.CV] UPDATED)
- Authors : Gengyan Li, Abhimitra Meka, Otmar Hilliges, Thabo Beeler, Google Inc
- Link : [http://arxiv.org/abs/2206.08428](http://arxiv.org/abs/2206.08428)
> ABSTRACT  :  A unique challenge in creating high-quality animatable and relightable 3D avatars of people is modeling human eyes. The challenge of synthesizing eyes is multifold as it requires 1) appropriate representations for the various components of the eye and the periocular region for coherent viewpoint synthesis, capable of representing diffuse, refractive and highly reflective surfaces, 2) disentangling skin and eye appearance from environmental illumination such that it may be rendered under novel lighting conditions, and 3) capturing eyeball motion and the deformation of the surrounding skin to enable re-gazing. These challenges have traditionally necessitated the use of expensive and cumbersome capture setups to obtain high-quality results, and even then, modeling of the eye region holistically has remained elusive. We present a novel geometry and appearance representation that enables high-fidelity capture and photorealistic animation, view synthesis and relighting of the eye region using only a sparse set of lights and cameras. Our hybrid representation combines an explicit parametric surface model for the eyeball with implicit deformable volumetric representations for the periocular region and the interior of the eye. This novel hybrid model has been designed to address the various parts of that challenging facial area - the explicit eyeball surface allows modeling refraction and high-frequency specular reflection at the cornea, whereas the implicit representation is well suited to model lower-frequency skin reflection via spherical harmonics and can represent non-surface structures such as hair or diffuse volumetric bodies, both of which are a challenge for explicit surface models. We show that for high-resolution close-ups of the eye, our model can synthesize high-fidelity animated gaze from novel views under unseen illumination conditions.  
## eess.IV
---
### Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
- Authors : Masud An, Nur Islam, Nazmus Saqib, Shafkat Khan, Ho Yub
- Link : [http://arxiv.org/abs/2207.05176](http://arxiv.org/abs/2207.05176)
> ABSTRACT  :  Image denoising is still a challenging issue in many computer vision sub-domains. Recent studies show that significant improvements are made possible in a supervised setting. However, few challenges, such as spatial fidelity and cartoon-like smoothing remain unresolved or decisively overlooked. Our study proposes a simple yet efficient architecture for the denoising problem that addresses the aforementioned issues. The proposed architecture revisits the concept of modular concatenation instead of long and deeper cascaded connections, to recover a cleaner approximation of the given image. We find that different modules can capture versatile representations, and concatenated representation creates a richer subspace for low-level image **restoration**. The proposed architecture's number of parameters remains smaller than the number for most of the previous networks and still achieves significant improvements over the current state-of-the-art networks.  
### On the limits of perceptual quality measures for enhanced underwater images. (arXiv:2207.05470v1 [cs.CV])
- Authors : Chau Yi, Andrea Cavallaro
- Link : [http://arxiv.org/abs/2207.05470](http://arxiv.org/abs/2207.05470)
> ABSTRACT  :  The appearance of objects in underwater images is degraded by the selective attenuation of light, which reduces contrast and causes a colour cast. This degradation depends on the water environment, and increases with depth and with the distance of the object from the camera. Despite an increasing volume of works in underwater image **enhancement** and **restoration**, the lack of a commonly accepted evaluation measure is hindering the progress as it is difficult to compare methods. In this paper, we review commonly used colour accuracy measures, such as colour reproduction error and CIEDE2000, and no-reference image quality measures, such as UIQM, UCIQE and CCF, which have not yet been systematically validated. We show that none of the no-reference quality measures satisfactorily rates the quality of enhanced underwater images and discuss their main shortcomings. Images and results are available at https://puiqe.eecs.qmul.ac.uk.  
### Ego-motion Estimation Based on Fusion of Images and Events. (arXiv:2207.05588v1 [cs.CV])
- Authors : Liren Yang
- Link : [http://arxiv.org/abs/2207.05588](http://arxiv.org/abs/2207.05588)
> ABSTRACT  :  Event camera is a novel bio-inspired vision sensor that outputs event stream. In this paper, we propose a novel data fusion algorithm called EAS to fuse conventional intensity images with the event stream. The fusion result is applied to some ego-motion estimation frameworks, and is evaluated on a public dataset acquired in dim scenes. In our 3-DoF rotation estimation framework, EAS achieves the highest estimation accuracy among intensity images and representations of events including event slice, TS and SITS. Compared with original images, EAS reduces the average APE by 69%, benefiting from the inclusion of more features for tracking. The result shows that our algorithm effectively leverages the **high dynamic range** of event cameras to improve the performance of the ego-motion estimation framework based on optical flow tracking in difficult illumination conditions.  
### Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v3 [eess.IV] UPDATED)
- Authors : Xiaojie Chu, Liangyu Chen, Chengpeng Chen, Xin Lu
- Link : [http://arxiv.org/abs/2112.04491](http://arxiv.org/abs/2112.04491)
> ABSTRACT  :  Global operations, such as global average pooling, are widely used in top-performance image restorers. They aggregate global information from input features along entire spatial dimensions but behave differently during training and inference in image **restoration** tasks: they are based on different regions, namely the cropped patches (from images) and the full-resolution images. This paper revisits global information aggregation and finds that the image-based features during inference have a different distribution than the patch-based features during training. This train-test inconsistency negatively impacts the performance of models, which is severely overlooked by previous works. To reduce the inconsistency and improve test-time performance, we propose a simple method called Test-time Local Converter (TLC). Our TLC converts global operations to local ones only during inference so that they aggregate features within local spatial regions rather than the entire large images. The proposed method can be applied to various global modules (e.g., normalization, channel and spatial attention) with negligible costs. Without the need for any fine-tuning, TLC improves state-of-the-art results on several image **restoration** tasks, including single-image motion deblurring, video deblurring, defocus deblurring, and image denoising. In particular, with TLC, our Restormer-Local improves the state-of-the-art result in single image deblurring from 32.92 dB to 33.57 dB on GoPro dataset. The code is available at https://github.com/megvii-research/tlc.  
### Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v2 [eess.IV] UPDATED)
- Authors : Xiang Chen, Zhentao Fan, Pengpeng Li, Longgang Dai, Caihua Kong, Zhuoran Zheng, Yufeng Huang, Yufeng Li
- Link : [http://arxiv.org/abs/2203.07677](http://arxiv.org/abs/2203.07677)
> ABSTRACT  :  We offer a practical unpaired learning based image dehazing network from an unpaired set of clear and hazy images. This paper provides a new perspective to treat image dehazing as a two-class separated factor disentanglement task, i.e, the task-relevant factor of clear image reconstruction and the task-irrelevant factor of haze-relevant distribution. To achieve the disentanglement of these two-class factors in deep feature space, contrastive learning is introduced into a CycleGAN framework to learn disentangled representations by guiding the generated images to be associated with latent factors. With such formulation, the proposed contrastive disentangled dehazing method (CDD-GAN) employs negative generators to cooperate with the encoder network to update alternately, so as to produce a queue of challenging negative adversaries. Then these negative adversaries are trained end-to-end together with the backbone representation network to enhance the discriminative information and promote factor disentanglement performance by maximizing the adversarial contrastive loss. During the training, we further show that hard negative examples can suppress the task-irrelevant factors and unpaired clear exemples can enhance the task-relevant factors, in order to better facilitate haze removal and help image **restoration**. Extensive experiments on both synthetic and real-world datasets demonstrate that our method performs favorably against existing unpaired dehazing baselines.  
## cs.LG
---
### "Why do so?" -- A Practical Perspective on Machine Learning Security. (arXiv:2207.05164v1 [cs.LG])
- Authors : Kathrin Grosse, Lukas Bieringer, Tarek Richard, Battista Biggio, Katharina Krombholz
- Link : [http://arxiv.org/abs/2207.05164](http://arxiv.org/abs/2207.05164)
> ABSTRACT  :  Despite the large body of academic work on machine learning security, little is known about the occurrence of attacks on machine learning systems in the wild. In this paper, we report on a quantitative study with 139 industrial practitioners. We analyze attack occurrence and concern and evaluate statistical hypotheses on factors influencing threat perception and **exposure**. Our results shed light on real-world attacks on deployed machine learning. On the organizational level, while we find no predictors for threat **exposure** in our sample, the amount of implement defenses depends on **exposure** to threats or expected likelihood to become a target. We also provide a detailed analysis of practitioners' replies on the relevance of individual machine learning attacks, unveiling complex concerns like unreliable decision making, business information leakage, and bias introduction into models. Finally, we find that on the individual level, prior knowledge about machine learning security influences threat perception. Our work paves the way for more research about adversarial machine learning in practice, but yields also insights for regulation and auditing.  
### Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
- Authors : Masud An, Nur Islam, Nazmus Saqib, Shafkat Khan, Ho Yub
- Link : [http://arxiv.org/abs/2207.05176](http://arxiv.org/abs/2207.05176)
> ABSTRACT  :  Image denoising is still a challenging issue in many computer vision sub-domains. Recent studies show that significant improvements are made possible in a supervised setting. However, few challenges, such as spatial fidelity and cartoon-like smoothing remain unresolved or decisively overlooked. Our study proposes a simple yet efficient architecture for the denoising problem that addresses the aforementioned issues. The proposed architecture revisits the concept of modular concatenation instead of long and deeper cascaded connections, to recover a cleaner approximation of the given image. We find that different modules can capture versatile representations, and concatenated representation creates a richer subspace for low-level image **restoration**. The proposed architecture's number of parameters remains smaller than the number for most of the previous networks and still achieves significant improvements over the current state-of-the-art networks.  
### Revisiting Inlier and Outlier Specification for Improved Out-of-Distribution Detection. (arXiv:2207.05286v1 [cs.CV])
- Authors : Vivek Narayanaswamy, Yamen Mubarka, Rushil Anirudh, Deepta Rajan, Andreas Spanias
- Link : [http://arxiv.org/abs/2207.05286](http://arxiv.org/abs/2207.05286)
> ABSTRACT  :  Accurately detecting out-of-distribution (OOD) data with varying levels of semantic and covariate shifts with respect to the in-distribution (ID) data is critical for deployment of safe and reliable models. This is particularly the case when dealing with highly consequential applications (e.g. medical imaging, self-driving cars, etc). The goal is to design a detector that can accept meaningful variations of the ID data, while also rejecting examples from OOD regimes. In practice, this dual objective can be realized by enforcing consistency using an appropriate scoring function (e.g., energy) and calibrating the detector to reject a curated set of OOD data (referred to as outlier **exposure** or shortly OE). While OE methods are widely adopted, assembling representative OOD datasets is both costly and challenging due to the unpredictability of real-world scenarios, hence the recent trend of designing OE-free detectors. In this paper, we make a surprising finding that controlled generalization to ID variations and **exposure** to diverse (synthetic) outlier examples are essential to simultaneously improving semantic and modality shift detection. In contrast to existing methods, our approach samples inliers in the latent space, and constructs outlier examples via negative data augmentation. Through a rigorous empirical study on medical imaging benchmarks (MedMNIST, ISIC2019 and NCT), we demonstrate significant performance gains ($15\% - 35\%$ in AUROC) over existing OE-free, OOD detection approaches under both semantic and modality shifts.  
### Using Machine Learning to Reduce Observational Biases When Detecting New Impacts on Mars. (arXiv:2207.05679v1 [cs.LG])
- Authors : Gary Doran, Annabelle Gao, Joe Pate, Daniel Wexler, Jet Propulsion, California Institute, of Technology, Brown University, ETH Zurich
- Link : [http://arxiv.org/abs/2207.05679](http://arxiv.org/abs/2207.05679)
> ABSTRACT  :  The current inventory of recent (fresh) impacts on Mars shows a strong bias towards areas of low thermal inertia. These areas are generally visually bright, and impacts create **dark** scours and rays that make them easier to detect. It is expected that impacts occur at a similar rate in areas of higher thermal inertia, but those impacts are under-detected. This study investigates the use of a trained machine learning classifier to increase the detection of fresh impacts on Mars using CTX data. This approach discovered 69 new fresh impacts that have been confirmed with follow-up HiRISE images. We found that examining candidates partitioned by thermal inertia (TI) values, which is only possible due to the large number of machine learning candidates, helps reduce the observational bias and increase the number of known high-TI impacts.  
### Insights into Deep Non-linear Filters for Improved Multi-channel Speech **Enhancement**. (arXiv:2206.13310v2 [eess.AS] UPDATED)
- Authors : Kristina Tesch, Timo Gerkmann
- Link : [http://arxiv.org/abs/2206.13310](http://arxiv.org/abs/2206.13310)
> ABSTRACT  :  The key advantage of using multiple microphones for speech **enhancement** is that spatial filtering can be used to complement the tempo-spectral processing. In a traditional setting, linear spatial filtering (beamforming) and single-channel post-filtering are commonly performed separately. In contrast, there is a trend towards employing deep neural networks (DNNs) to learn a joint spatial and tempo-spectral non-linear filter, which means that the restriction of a linear processing model and that of a separate processing of spatial and tempo-spectral information can potentially be overcome. However, the internal mechanisms that lead to good performance of such data-driven filters for multi-channel speech **enhancement** are not well understood. Therefore, in this work, we analyse the properties of a non-linear spatial filter realized by a DNN as well as its interdependency with temporal and spectral processing by carefully controlling the information sources (spatial, spectral, and temporal) available to the network. We confirm the superiority of a non-linear spatial processing model, which outperforms an oracle linear spatial filter in a challenging speaker extraction scenario for a low number of microphones by 0.24 POLQA score. Our analyses reveal that in particular spectral information should be processed jointly with spatial information as this increases the spatial selectivity of the filter. Our systematic evaluation then leads to a simple network architecture, that outperforms state-of-the-art network architectures on a speaker extraction task by 0.22 POLQA score and by 0.32 POLQA score on the CHiME3 data.  
## cs.AI
---
### UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v1 [cs.CV])
- Authors : Jihao Liu, Xin Huang, Guanglu Song, Yu Liu, Hongsheng Li
- Link : [http://arxiv.org/abs/2207.05420](http://arxiv.org/abs/2207.05420)
> ABSTRACT  :  Recently, transformer and multi-layer perceptron (MLP) architectures have achieved impressive results on various vision tasks. However, how to effectively combine those operators to form high-performance hybrid visual architectures still remains a challenge. In this work, we study the learnable combination of convolution, transformer, and MLP by proposing a novel unified architecture search approach. Our approach contains two key designs to achieve the search for high-performance networks. First, we model the very different searchable operators in a unified form, and thus enable the operators to be characterized with the same set of configuration parameters. In this way, the overall search space size is significantly reduced, and the total search cost becomes affordable. Second, we propose context-aware downsampling modules (DSMs) to mitigate the gap between the different types of operators. Our proposed DSMs are able to better adapt features from different types of operators, which is important for identifying high-performance hybrid architectures. Finally, we integrate configurable operators and DSMs into a unified search space and search with a Reinforcement Learning-based search algorithm to fully explore the optimal combination of the operators. To this end, we search a baseline network and scale it up to obtain a family of models, named UniNets, which achieve much better accuracy and efficiency than previous ConvNets and Transformers. In particular, our UniNet-B5 achieves 84.9% top-1 accuracy on ImageNet, outperforming EfficientNet-B7 and BoTNet-T7 with 44% and 55% fewer FLOPs respectively. By pretraining on the ImageNet-21K, our UniNet-B6 achieves 87.4%, outperforming **Swin**-L with 51% fewer FLOPs and 41% fewer parameters. Code is available at https://github.com/Sense-X/UniNet.  
# Paper List
---
## cs.CV
---
**167** new papers in cs.CV:-) 
1. Learning to segment prostate cancer by aggressiveness from scribbles in bi-parametric MRI. (arXiv:2207.05056v1 [eess.IV])
2. Histopathological Imaging Classification of Breast Tissue for Cancer Diagnosis Support Using Deep Learning Models. (arXiv:2207.05057v1 [eess.IV])
3. Discovering Domain Disentanglement for Generalized Multi-source Domain Adaptation. (arXiv:2207.05070v1 [cs.LG])
4. RUSH: Robust Contrastive Learning via Randomized Smoothing. (arXiv:2207.05127v1 [cs.LG])
5. FreeREA: Training-Free Evolution-based Architecture Search. (arXiv:2207.05135v1 [cs.NE])
6. Towards Effective Multi-Label Recognition Attacks via Knowledge Graph Consistency. (arXiv:2207.05137v1 [cs.CV])
7. Accelerated Deep Lossless Image Coding with Unified Paralleleized GPU Coding Architecture. (arXiv:2207.05152v1 [eess.IV])
8. Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
9. Fine-grained Activities of People Worldwide. (arXiv:2207.05182v1 [cs.CV])
10. Patch-level instance-group discrimination with pretext-invariant learning for colitis scoring. (arXiv:2207.05192v1 [cs.CV])
11. Collaborative Uncertainty Benefits Multi-Agent Multi-Modal Trajectory Forecasting. (arXiv:2207.05195v1 [cs.CV])
12. Real-Time And Robust 3D Object Detection with Roadside LiDARs. (arXiv:2207.05200v1 [cs.CV])
13. Scaling Novel Object Detection with Weakly Supervised Detection Transformers. (arXiv:2207.05205v1 [cs.CV])
14. Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v1 [cs.LG])
15. Regression Metric Loss: Learning a Semantic Representation Space for Medical Images. (arXiv:2207.05231v1 [eess.IV])
16. Efficient Human Vision Inspired Action Recognition using Adaptive Spatiotemporal Sampling. (arXiv:2207.05249v1 [cs.CV])
17. Dynamic Proposals for Efficient Object Detection. (arXiv:2207.05252v1 [cs.CV])
18. Hunting Group Clues with Transformers for Social Group Activity Recognition. (arXiv:2207.05254v1 [cs.CV])
19. Normalized Feature Distillation for Semantic Segmentation. (arXiv:2207.05256v1 [cs.CV])
20. Accelerating Certifiable Estimation with Preconditioned Eigensolvers. (arXiv:2207.05257v1 [cs.RO])
21. Cross-Architecture Knowledge Distillation. (arXiv:2207.05273v1 [cs.CV])
22. Photonic Reconfigurable Accelerators for Efficient Inference of CNNs with Mixed-Sized Tensors. (arXiv:2207.05278v1 [cs.AR])
23. PseudoClick: Interactive Image Segmentation with Click Imitation. (arXiv:2207.05282v1 [cs.CV])
24. Revisiting Inlier and Outlier Specification for Improved Out-of-Distribution Detection. (arXiv:2207.05286v1 [cs.CV])
25. MetaAge: Meta-Learning Personalized Age Estimators. (arXiv:2207.05288v1 [cs.CV])
26. Trusted Multi-Scale Classification Framework for Whole Slide Image. (arXiv:2207.05290v1 [cs.CV])
27. Towards Hard-Positive Query Mining for DETR-based Human-Object Interaction Detection. (arXiv:2207.05293v1 [cs.CV])
28. SD-GAN: Semantic Decomposition for Face Image Synthesis with Discrete Attribute. (arXiv:2207.05300v1 [cs.CV])
29. Contrastive Deep Supervision. (arXiv:2207.05306v1 [cs.CV])
30. Outpainting by Queries. (arXiv:2207.05312v1 [cs.CV])
31. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v1 [cs.CV])
32. Twin identification over viewpoint change: A deep convolutional neural network surpasses humans. (arXiv:2207.05316v1 [cs.CV])
33. CPO: Change Robust Panorama to Point Cloud Localization. (arXiv:2207.05317v1 [cs.CV])
34. Certified Adversarial Robustness via Anisotropic Randomized Smoothing. (arXiv:2207.05327v1 [cs.CV])
35. Robotic Detection of a Human-Comprehensible Gestural Language for Underwater Multi-Human-Robot Collaboration. (arXiv:2207.05331v1 [cs.RO])
36. IDEA: Increasing Text Diversity via Online Multi-Label Recognition for Vision-Language Pre-training. (arXiv:2207.05333v1 [cs.CV])
37. Cycle Self-Training for Semi-Supervised Object Detection with Distribution Consistency Reweighting. (arXiv:2207.05334v1 [cs.CV])
38. Dual Contrastive Learning for Spatio-temporal Representation. (arXiv:2207.05340v1 [cs.CV])
39. Video Graph Transformer for Video Question Answering. (arXiv:2207.05342v1 [cs.CV])
40. HEAD: HEtero-Assists Distillation for Heterogeneous Object Detectors. (arXiv:2207.05345v1 [cs.CV])
41. eX-ViT: A Novel eXplainable Vision Transformer for Weakly Supervised Semantic Segmentation. (arXiv:2207.05358v1 [cs.CV])
42. CP3: Unifying Point Cloud Completion by Pretrain-Prompt-Predict Paradigm. (arXiv:2207.05359v1 [cs.CV])
43. Image and Model Transformation with Secret Key for Vision Transformer. (arXiv:2207.05366v1 [cs.CV])
44. Rethinking gradient weights' influence over saliency map estimation. (arXiv:2207.05374v1 [cs.CV])
45. Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion Prior. (arXiv:2207.05375v1 [cs.CV])
46. Collaborative Neural Rendering using Anime Character Sheets. (arXiv:2207.05378v1 [cs.CV])
47. Frequency Domain Model Augmentation for Adversarial Attack. (arXiv:2207.05382v1 [cs.CV])
48. Controllable Shadow Generation Using Pixel Height Maps. (arXiv:2207.05385v1 [cs.CV])
49. Wound Segmentation with Dynamic Illumination Correction and Dual-view Semantic Fusion. (arXiv:2207.05388v1 [eess.IV])
50. Knowledge Condensation Distillation. (arXiv:2207.05409v1 [cs.CV])
51. A Baseline for Detecting Out-of-Distribution Examples in Image Captioning. (arXiv:2207.05418v1 [cs.CV])
52. UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v1 [cs.CV])
53. Improving Domain Generalization by Learning without Forgetting: Application in Retail Checkout. (arXiv:2207.05422v1 [cs.CV])
54. Learning Diverse Tone Styles for Image Retouching. (arXiv:2207.05430v1 [cs.CV])
55. Synergistic Self-supervised and Quantization Learning. (arXiv:2207.05432v1 [cs.CV])
56. Category-Level 6D Object Pose and Size Estimation using Self-Supervised Deep Prior Deformation Networks. (arXiv:2207.05444v1 [cs.CV])
57. On the Effects of Image Quality Degradation on Minutiae- and Ridge-Based Automatic Fingerprint Recognition. (arXiv:2207.05447v1 [cs.CV])
58. A review of schemes for fingerprint image quality computation. (arXiv:2207.05449v1 [cs.CV])
59. TransFA: Transformer-based Representation for Face Attribute Evaluation. (arXiv:2207.05456v1 [cs.CV])
60. On the limits of perceptual quality measures for enhanced underwater images. (arXiv:2207.05470v1 [cs.CV])
61. A novel conservative chaos driven dynamic DNA coding for image encryption. (arXiv:2207.05475v1 [cs.CR])
62. VertXNet: Automatic Segmentation and Identification of Lumbar and Cervical Vertebrae from Spinal X-ray Images. (arXiv:2207.05476v1 [eess.IV])
63. CorrI2P: Deep Image-to-Point Cloud Registration via Dense Correspondence. (arXiv:2207.05483v1 [cs.CV])
64. Skeletal Human Action Recognition using Hybrid Attention based Graph Convolutional Network. (arXiv:2207.05493v1 [cs.CV])
65. Paint and Distill: Boosting 3D Object Detection with Semantic Passing Network. (arXiv:2207.05497v1 [cs.CV])
66. Modality-Aware Contrastive Instance Learning with Self-Distillation for Weakly-Supervised Audio-Visual Violence Detection. (arXiv:2207.05500v1 [cs.CV])
67. Next-ViT: Next Generation Vision Transformer for Efficient Deployment in Realistic Industrial Scenarios. (arXiv:2207.05501v1 [cs.CV])
68. Transferability-Guided Cross-Domain Cross-Task Transfer Learning. (arXiv:2207.05510v1 [cs.CV])
69. Compound Prototype Matching for Few-shot Action Recognition. (arXiv:2207.05515v1 [cs.CV])
70. Tracking Objects as Pixel-wise Distributions. (arXiv:2207.05518v1 [cs.CV])
71. Long-term Leap Attention, Short-term Periodic Shift for Video Classification. (arXiv:2207.05526v1 [cs.CV])
72. Camera Pose Auto-Encoders for Improving Pose Regression. (arXiv:2207.05530v1 [cs.CV])
73. Utilizing Excess Resources in Training Neural Networks. (arXiv:2207.05532v1 [cs.LG])
74. DTG-SSOD: Dense Teacher Guidance for Semi-Supervised Object Detection. (arXiv:2207.05536v1 [cs.CV])
75. Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v1 [cs.LG])
76. LightViT: Towards Light-Weight Convolution-Free Vision Transformers. (arXiv:2207.05557v1 [cs.CV])
77. Learning from Label Relationships in Human Affect. (arXiv:2207.05577v1 [cs.CV])
78. Online Video Instance Segmentation via Robust Context Fusion. (arXiv:2207.05580v1 [cs.CV])
79. Ego-motion Estimation Based on Fusion of Images and Events. (arXiv:2207.05588v1 [cs.CV])
80. Towards **Real-time** High-Definition Image Snow Removal: Efficient Pyramid Network with Asymmetrical Encoder-decoder Architecture. (arXiv:2207.05605v1 [cs.CV])
81. Inner Monologue: Embodied Reasoning through Planning with Language Models. (arXiv:2207.05608v1 [cs.RO])
82. Contrastive Learning for Online Semi-Supervised General Continual Learning. (arXiv:2207.05615v1 [cs.LG])
83. LudVision -- Remote Detection of Exotic Invasive Aquatic Floral Species using Drone-Mounted Multispectral Data. (arXiv:2207.05620v1 [cs.CV])
84. MSP-Former: Multi-Scale Projection Transformer for Single Image Desnowing. (arXiv:2207.05621v1 [cs.CV])
85. GANzzle: Reframing jigsaw puzzle solving as a retrieval task using a generative mental image. (arXiv:2207.05634v1 [cs.CV])
86. Backdoor Attacks on Crowd Counting. (arXiv:2207.05641v1 [cs.CV])
87. Docent: A content-based recommendation system to discover contemporary art. (arXiv:2207.05648v1 [cs.LG])
88. Dynamic Gradient Reactivation for Backward Compatible Person Re-identification. (arXiv:2207.05658v1 [cs.CV])
89. RE-Tagger: A light-weight Real-Estate Image Classifier. (arXiv:2207.05696v1 [cs.CV])
90. Tell Me the Evidence? Dual Visual-Linguistic Interaction for Answer Grounding. (arXiv:2207.05703v1 [cs.CV])
91. M-FUSE: Multi-frame Fusion for Scene Flow Estimation. (arXiv:2207.05704v1 [cs.CV])
92. Bayesian Experimental Design for Computed Tomography with the Linearised Deep Image Prior. (arXiv:2207.05714v1 [cs.CV])
93. Enhancing Fairness of Visual Attribute Predictors. (arXiv:2207.05727v1 [cs.CV])
94. Physical Passive Patch Adversarial Attacks on Visual Odometry Systems. (arXiv:2207.05729v1 [cs.CV])
95. 1st Place Solution to the EPIC-Kitchens Action Anticipation Challenge 2022. (arXiv:2207.05730v1 [cs.CV])
96. A Skeleton-aware Graph Convolutional Network for Human-Object Interaction Detection. (arXiv:2207.05733v1 [cs.CV])
97. Vision Transformer for **NeRF**-Based View Synthesis from a Single Input Image. (arXiv:2207.05736v1 [cs.CV])
98. Multi-structure bone segmentation in pediatric MR images with combined regularization from shape priors and adversarial network. (arXiv:2009.07092v5 [eess.IV] UPDATED)
99. Biometrics in the Era of COVID-19: Challenges and Opportunities. (arXiv:2102.09258v2 [cs.CY] UPDATED)
100. Self-Supervised Classification Network. (arXiv:2103.10994v3 [cs.CV] UPDATED)
101. Weakly-supervised Part-Attention and Mentored Networks for Vehicle Re-Identification. (arXiv:2107.08228v2 [cs.CV] UPDATED)
102. Neural Video Compression using GANs for Detail Synthesis and Propagation. (arXiv:2107.12038v3 [eess.IV] UPDATED)
103. RigNet: Repetitive Image Guided Network for Depth Completion. (arXiv:2107.13802v4 [cs.CV] UPDATED)
104. Diverse Similarity Encoder for Deep GAN Inversion. (arXiv:2108.10201v2 [cs.CV] UPDATED)
105. Cell Multi-Bernoulli (Cell-MB) Sensor Control for Multi-object Search-While-Tracking (SWT). (arXiv:2108.11236v2 [eess.SP] UPDATED)
106. PC$^2$-PU: Patch Correlation and Point Correlation for Effective Point Cloud Upsampling. (arXiv:2109.09337v3 [cs.CV] UPDATED)
107. Propagating State Uncertainty Through Trajectory Forecasting. (arXiv:2110.03267v4 [cs.RO] UPDATED)
108. MM-Pyramid: Multimodal Pyramid Attentional Network for Audio-Visual Event Localization and Video Parsing. (arXiv:2111.12374v2 [cs.CV] UPDATED)
109. diffConv: Analyzing Irregular Point Clouds with an Irregular View. (arXiv:2111.14658v3 [cs.CV] UPDATED)
110. EAGAN: Efficient Two-stage Evolutionary Architecture Search for GANs. (arXiv:2111.15097v2 [cs.CV] UPDATED)
111. Adaptive Channel Encoding Transformer for Point Cloud Analysis. (arXiv:2112.02507v3 [cs.CV] UPDATED)
112. Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v3 [eess.IV] UPDATED)
113. PeopleSansPeople: A Synthetic Data Generator for Human-Centric Computer Vision. (arXiv:2112.09290v2 [cs.CV] UPDATED)
114. Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis. (arXiv:2112.10325v4 [eess.IV] UPDATED)
115. Facial-Sketch Synthesis: A New Challenge. (arXiv:2112.15439v6 [cs.CV] UPDATED)
116. Persistent Homology for Breast Tumor Classification using Mammogram Scans. (arXiv:2201.02295v2 [eess.IV] UPDATED)
117. Dynamic Label Assignment for Object Detection by Combining Predicted IoUs and Anchor IoUs. (arXiv:2201.09396v2 [cs.CV] UPDATED)
118. Generalized Global Ranking-Aware Neural Architecture Ranker for Efficient Image Classifier Search. (arXiv:2201.12725v2 [cs.CV] UPDATED)
119. CGiS-Net: Aggregating Colour, Geometry and Implicit Semantic Features for Indoor Place Recognition. (arXiv:2202.02070v2 [cs.CV] UPDATED)
120. Equivariance versus Augmentation for Spherical Images. (arXiv:2202.03990v2 [cs.LG] UPDATED)
121. Deep Metric Learning-Based Semi-Supervised Regression With Alternate Learning. (arXiv:2202.11388v2 [cs.CV] UPDATED)
122. A Novel Self-Supervised Cross-Modal Image Retrieval Method In Remote Sensing. (arXiv:2202.11429v2 [cs.CV] UPDATED)
123. SWIS: Self-Supervised Representation Learning For Writer Independent Offline Signature Verification. (arXiv:2202.13078v2 [cs.CV] UPDATED)
124. Improved Hard Example Mining Approach for Single Shot Object Detectors. (arXiv:2202.13080v2 [cs.CV] UPDATED)
125. Constrained unsupervised anomaly segmentation. (arXiv:2203.01671v2 [eess.IV] UPDATED)
126. Highly Accurate Dichotomous Image Segmentation. (arXiv:2203.03041v3 [cs.CV] UPDATED)
127. CF-ViT: A General Coarse-to-Fine Method for Vision Transformer. (arXiv:2203.03821v3 [cs.CV] UPDATED)
128. PaCC-Net: Position Aware Circular Convolution with Merits from ConvNets and Transformer. (arXiv:2203.03952v4 [cs.CV] UPDATED)
129. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v2 [eess.IV] UPDATED)
130. Decoupled Knowledge Distillation. (arXiv:2203.08679v2 [cs.CV] UPDATED)
131. PanoFormer: Panorama Transformer for Indoor 360 Depth Estimation. (arXiv:2203.09283v2 [cs.CV] UPDATED)
132. Multi-Modal Masked Pre-Training for Monocular Panoramic Depth Completion. (arXiv:2203.09855v5 [cs.CV] UPDATED)
133. Transform your Smartphone into a DSLR Camera: Learning the ISP in the Wild. (arXiv:2203.10636v4 [cs.CV] UPDATED)
134. Weakly-Supervised Salient Object Detection Using Point Supervision. (arXiv:2203.11652v2 [cs.CV] UPDATED)
135. Transformer Compressed Sensing via Global Image Tokens. (arXiv:2203.12861v3 [cs.CV] UPDATED)
136. Cross-Modality High-Frequency Transformer for MR Image Super-Resolution. (arXiv:2203.15314v2 [cs.CV] UPDATED)
137. CycDA: Unsupervised Cycle Domain Adaptation from Image to Video. (arXiv:2203.16244v2 [cs.CV] UPDATED)
138. Saliency in Augmented Reality. (arXiv:2204.08308v2 [cs.CV] UPDATED)
139. MMRotate: A Rotated Object Detection Benchmark using Pytorch. (arXiv:2204.13317v2 [cs.CV] UPDATED)
140. Uncertainty estimation for Cross-dataset performance in Trajectory prediction. (arXiv:2205.07310v2 [cs.CV] UPDATED)
141. MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes. (arXiv:2205.09248v2 [cs.SD] UPDATED)
142. TRT-ViT: TensorRT-oriented Vision Transformer. (arXiv:2205.09579v3 [cs.CV] UPDATED)
143. Temporally Precise Action Spotting in Soccer Videos Using Dense Detection Anchors. (arXiv:2205.10450v2 [cs.CV] UPDATED)
144. SHREC 2022: pothole and crack detection in the road pavement using images and RGB-D data. (arXiv:2205.13326v5 [cs.CV] UPDATED)
145. Improving the Robustness and Generalization of Deep Neural Network with Confidence Threshold Reduction. (arXiv:2206.00913v2 [cs.LG] UPDATED)
146. Learning Ego 3D Representation as Ray Tracing. (arXiv:2206.04042v2 [cs.CV] UPDATED)
147. Quantitative Imaging Principles Improves Medical Image Learning. (arXiv:2206.06663v3 [q-bio.QM] UPDATED)
148. Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v2 [cs.LG] UPDATED)
149. Eye**NeRF**: A Hybrid Representation for Photorealistic Synthesis, Animation and Relighting of Human Eyes. (arXiv:2206.08428v2 [cs.CV] UPDATED)
150. GNN-PMB: A Simple but Effective Online 3D Multi-Object Tracker without Bells and Whistles. (arXiv:2206.10255v2 [eess.SY] UPDATED)
151. UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior. (arXiv:2206.13389v2 [cs.CV] UPDATED)
152. C2FTrans: Coarse-to-Fine Transformers for Medical Image Segmentation. (arXiv:2206.14409v2 [cs.CV] UPDATED)
153. The Lighter The Better: Rethinking Transformers in Medical Image Segmentation Through Adaptive Pruning. (arXiv:2206.14413v2 [cs.CV] UPDATED)
154. PolarFormer: Multi-camera 3D Object Detection with Polar Transformers. (arXiv:2206.15398v4 [cs.CV] UPDATED)
155. Boosting Single-Frame 3D Object Detection by Simulating Multi-Frame Point Clouds. (arXiv:2207.01030v2 [cs.CV] UPDATED)
156. Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models. (arXiv:2207.01056v2 [cs.CV] UPDATED)
157. Detection of ADHD based on Eye Movements during Natural Viewing. (arXiv:2207.01377v4 [cs.CV] UPDATED)
158. AvatarCap: Animatable Avatar Conditioned Monocular Human Volumetric Capture. (arXiv:2207.02031v2 [cs.CV] UPDATED)
159. Towards Counterfactual Image Manipulation via CLIP. (arXiv:2207.02812v3 [cs.CV] UPDATED)
160. Network Binarization via Contrastive Learning. (arXiv:2207.02970v2 [cs.CV] UPDATED)
161. What Makes for Automatic Reconstruction of Pulmonary Segments. (arXiv:2207.03078v2 [eess.IV] UPDATED)
162. Complementing Brightness Constancy with Deep Networks for Optical Flow Prediction. (arXiv:2207.03790v2 [cs.CV] UPDATED)
163. Radiomics-Guided Global-Local Transformer for Weakly Supervised Pathology Localization in Chest X-Rays. (arXiv:2207.04394v2 [cs.CV] UPDATED)
164. Depthformer : Multiscale Vision Transformer For Monocular Depth Estimation With Local Global Information Fusion. (arXiv:2207.04535v2 [cs.CV] UPDATED)
165. Geometry-aware Single-image Full-body Human Relighting. (arXiv:2207.04750v2 [cs.CV] UPDATED)
166. Dual Vision Transformer. (arXiv:2207.04976v2 [cs.CV] UPDATED)
167. Learning Continuous Grasping Function with a Dexterous Hand from Human Demonstrations. (arXiv:2207.05053v2 [cs.RO] UPDATED)
## eess.IV
---
**27** new papers in eess.IV:-) 
1. Learning to segment prostate cancer by aggressiveness from scribbles in bi-parametric MRI. (arXiv:2207.05056v1 [eess.IV])
2. Histopathological Imaging Classification of Breast Tissue for Cancer Diagnosis Support Using Deep Learning Models. (arXiv:2207.05057v1 [eess.IV])
3. Revisiting the Sample Adaptive Offset post-filter of VVC with Neural-Networks. (arXiv:2207.05134v1 [eess.IV])
4. Accelerated Deep Lossless Image Coding with Unified Paralleleized GPU Coding Architecture. (arXiv:2207.05152v1 [eess.IV])
5. Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
6. Regression Metric Loss: Learning a Semantic Representation Space for Medical Images. (arXiv:2207.05231v1 [eess.IV])
7. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v1 [cs.CV])
8. Wound Segmentation with Dynamic Illumination Correction and Dual-view Semantic Fusion. (arXiv:2207.05388v1 [eess.IV])
9. On the Effects of Image Quality Degradation on Minutiae- and Ridge-Based Automatic Fingerprint Recognition. (arXiv:2207.05447v1 [cs.CV])
10. A review of schemes for fingerprint image quality computation. (arXiv:2207.05449v1 [cs.CV])
11. On the limits of perceptual quality measures for enhanced underwater images. (arXiv:2207.05470v1 [cs.CV])
12. VertXNet: Automatic Segmentation and Identification of Lumbar and Cervical Vertebrae from Spinal X-ray Images. (arXiv:2207.05476v1 [eess.IV])
13. Towards Hybrid-Optimization Video Coding. (arXiv:2207.05565v1 [eess.IV])
14. Ego-motion Estimation Based on Fusion of Images and Events. (arXiv:2207.05588v1 [cs.CV])
15. Multi-structure bone segmentation in pediatric MR images with combined regularization from shape priors and adversarial network. (arXiv:2009.07092v5 [eess.IV] UPDATED)
16. COL0RME: COvariance-based $\ell_0$ super-Resolution Microscopy with intensity Estimation. (arXiv:2010.13477v2 [math.OC] UPDATED)
17. Neural Video Compression using GANs for Detail Synthesis and Propagation. (arXiv:2107.12038v3 [eess.IV] UPDATED)
18. Diverse Similarity Encoder for Deep GAN Inversion. (arXiv:2108.10201v2 [cs.CV] UPDATED)
19. Improving Image **Restoration** by Revisiting Global Information Aggregation. (arXiv:2112.04491v3 [eess.IV] UPDATED)
20. Incremental Cross-view Mutual Distillation for Self-supervised Medical CT Synthesis. (arXiv:2112.10325v4 [eess.IV] UPDATED)
21. Persistent Homology for Breast Tumor Classification using Mammogram Scans. (arXiv:2201.02295v2 [eess.IV] UPDATED)
22. SWIS: Self-Supervised Representation Learning For Writer Independent Offline Signature Verification. (arXiv:2202.13078v2 [cs.CV] UPDATED)
23. Constrained unsupervised anomaly segmentation. (arXiv:2203.01671v2 [eess.IV] UPDATED)
24. Unpaired Deep Image Dehazing Using Contrastive Disentanglement Learning. (arXiv:2203.07677v2 [eess.IV] UPDATED)
25. Transformer Compressed Sensing via Global Image Tokens. (arXiv:2203.12861v3 [cs.CV] UPDATED)
26. Quantitative Imaging Principles Improves Medical Image Learning. (arXiv:2206.06663v3 [q-bio.QM] UPDATED)
27. What Makes for Automatic Reconstruction of Pulmonary Segments. (arXiv:2207.03078v2 [eess.IV] UPDATED)
## cs.LG
---
**174** new papers in cs.LG:-) 
1. WeShort: Out-of-distribution Detection With Weak Shortcut structure. (arXiv:2207.05055v1 [cs.LG])
2. Learning to segment prostate cancer by aggressiveness from scribbles in bi-parametric MRI. (arXiv:2207.05056v1 [eess.IV])
3. Histopathological Imaging Classification of Breast Tissue for Cancer Diagnosis Support Using Deep Learning Models. (arXiv:2207.05057v1 [eess.IV])
4. Differentiable Physics Simulations with Contacts: Do They Have Correct Gradients w.r.t. Position, Velocity and Control?. (arXiv:2207.05060v1 [cs.LG])
5. Adaptive Graph Spatial-Temporal Transformer Network for Traffic Flow Forecasting. (arXiv:2207.05064v1 [cs.LG])
6. On the Representation of Causal Background Knowledge and its Applications in Causal Inference. (arXiv:2207.05067v1 [cs.AI])
7. Few-Shot Semantic Relation Prediction across Heterogeneous Graphs. (arXiv:2207.05068v1 [cs.LG])
8. Discovering Domain Disentanglement for Generalized Multi-source Domain Adaptation. (arXiv:2207.05070v1 [cs.LG])
9. Online Continual Learning of End-to-End Speech Recognition Models. (arXiv:2207.05071v1 [cs.LG])
10. Keep your Distance: Determining Sampling and Distance Thresholds in Machine Learning Monitoring. (arXiv:2207.05078v1 [cs.LG])
11. Horizontal Federated Learning and Secure Distributed Training for Recommendation System with Intel SGX. (arXiv:2207.05079v1 [cs.LG])
12. Learning an evolved mixture model for task-free continual learning. (arXiv:2207.05080v1 [cs.LG])
13. A Macrocolumn Architecture Implemented with Temporal (Spiking) Neurons. (arXiv:2207.05081v1 [cs.NE])
14. Joint NMF for Identification of Shared Features in Datasets and a Dataset Distance Measure. (arXiv:2207.05112v1 [cs.LG])
15. RUSH: Robust Contrastive Learning via Randomized Smoothing. (arXiv:2207.05127v1 [cs.LG])
16. Dev2vec: Representing Domain Expertise of Developers in an Embedding Space. (arXiv:2207.05132v1 [cs.SE])
17. FreeREA: Training-Free Evolution-based Architecture Search. (arXiv:2207.05135v1 [cs.NE])
18. Accelerated Deep Lossless Image Coding with Unified Paralleleized GPU Coding Architecture. (arXiv:2207.05152v1 [eess.IV])
19. Can Language Models perform Abductive Commonsense Reasoning?. (arXiv:2207.05155v1 [cs.AI])
20. DAUX: a Density-based Approach for Uncertainty eXplanations. (arXiv:2207.05161v1 [cs.LG])
21. "Why do so?" -- A Practical Perspective on Machine Learning Security. (arXiv:2207.05164v1 [cs.LG])
22. Denoising single images by feature ensemble revisited. (arXiv:2207.05176v1 [cs.CV])
23. Scaling Novel Object Detection with Weakly Supervised Detection Transformers. (arXiv:2207.05205v1 [cs.CV])
24. Fourier Neural Operator with Learned Deformations for PDEs on General Geometries. (arXiv:2207.05209v1 [cs.LG])
25. Shapley Computations Using Surrogate Model-Based Trees. (arXiv:2207.05214v1 [stat.ML])
26. Grounding Aleatoric Uncertainty in Unsupervised Environment Design. (arXiv:2207.05219v1 [cs.LG])
27. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v1 [cs.CL])
28. Bootstrapping a User-Centered Task-Oriented Dialogue System. (arXiv:2207.05223v1 [cs.CL])
29. Susceptibility of Continual Learning Against Adversarial Attacks. (arXiv:2207.05225v1 [cs.LG])
30. Recent Developments in AI and USPTO Open Data. (arXiv:2207.05239v1 [cs.LG])
31. Accelerating Large-Scale Graph-based Nearest Neighbor Search on a Computational Storage Platform. (arXiv:2207.05241v1 [cs.AR])
32. Unsupervised learning of observation functions in state-space models by nonparametric moment methods. (arXiv:2207.05242v1 [stat.ML])
33. FedPseudo: Pseudo value-based Deep Learning Models for Federated Survival Analysis. (arXiv:2207.05247v1 [cs.LG])
34. Efficient Real-world Testing of Causal Decision Making via Bayesian Experimental Design for Contextual Optimisation. (arXiv:2207.05250v1 [stat.ML])
35. Building Korean Sign Language Augmentation (KoSLA) Corpus with Data Augmentation Technique. (arXiv:2207.05261v1 [cs.CL])
36. Size and depth of monotone neural networks: interpolation and approximation. (arXiv:2207.05275v1 [cs.LG])
37. Photonic Reconfigurable Accelerators for Efficient Inference of CNNs with Mixed-Sized Tensors. (arXiv:2207.05278v1 [cs.AR])
38. Offline Equilibrium Finding. (arXiv:2207.05285v1 [cs.AI])
39. Revisiting Inlier and Outlier Specification for Improved Out-of-Distribution Detection. (arXiv:2207.05286v1 [cs.CV])
40. Pseudo value-based Deep Neural Networks for Multi-state Survival Analysis. (arXiv:2207.05291v1 [cs.LG])
41. TabSynDex: A Universal Metric for Robust Evaluation of Synthetic Tabular Data. (arXiv:2207.05295v1 [cs.LG])
42. Efficient and Privacy Preserving Group Signature for Federated Learning. (arXiv:2207.05297v1 [cs.CR])
43. Causal Conceptions of Fairness and their Consequences. (arXiv:2207.05302v1 [cs.LG])
44. CANF-VC: Conditional Augmented Normalizing Flows for Video Compression. (arXiv:2207.05315v1 [cs.CV])
45. Bi-fidelity Evolutionary Multiobjective Search for Adversarially Robust Deep Neural Architectures. (arXiv:2207.05321v1 [cs.LG])
46. Using Interpretable Machine Learning to Predict Maternal and Fetal Outcomes. (arXiv:2207.05322v1 [cs.LG])
47. CompoundE: Knowledge Graph Embedding with Translation, Rotation and Scaling Compound Operations. (arXiv:2207.05324v1 [cs.AI])
48. IDEA: Increasing Text Diversity via Online Multi-Label Recognition for Vision-Language Pre-training. (arXiv:2207.05333v1 [cs.CV])
49. A Bipartite Graph Neural Network Approach for Scalable Beamforming Optimization. (arXiv:2207.05364v1 [eess.SP])
50. Optimal Clustering with Noisy Queries via Multi-Armed Bandit. (arXiv:2207.05376v1 [cs.LG])
51. An Information-Theoretic Analysis for Transfer Learning: Error Bounds and Applications. (arXiv:2207.05377v1 [cs.IT])
52. Split Time Series into Patches: Rethinking Long-term Series Forecasting with Dateformer. (arXiv:2207.05397v1 [cs.LG])
53. A Baseline for Detecting Out-of-Distribution Examples in Image Captioning. (arXiv:2207.05418v1 [cs.CV])
54. Synergistic Self-supervised and Quantization Learning. (arXiv:2207.05432v1 [cs.CV])
55. Simultaneously Learning Stochastic and Adversarial Bandits under the Position-Based Model. (arXiv:2207.05437v1 [cs.LG])
56. Wasserstein multivariate auto-regressive models for modeling distributional time series and its application in graph learning. (arXiv:2207.05442v1 [stat.ML])
57. Adversarial Robustness Assessment of NeuroEvolution Approaches. (arXiv:2207.05451v1 [cs.NE])
58. IMG-NILM: A Deep learning NILM approach using energy heatmaps. (arXiv:2207.05463v1 [cs.LG])
59. A Benchmark dataset for predictive maintenance. (arXiv:2207.05466v1 [cs.LG])
60. Sliced-Wasserstein normalizing flows: beyond maximum likelihood training. (arXiv:2207.05468v1 [stat.ML])
61. End-to-end speech recognition modeling from de-identified data. (arXiv:2207.05469v1 [eess.AS])
62. Uncertainty-Aware Learning Against Label Noise on Imbalanced Datasets. (arXiv:2207.05471v1 [stat.ML])
63. A developmental approach for training deep belief networks. (arXiv:2207.05473v1 [cs.LG])
64. HelixFold: An Efficient Implementation of AlphaFold2 using PaddlePaddle. (arXiv:2207.05477v1 [cs.DC])
65. Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning. (arXiv:2207.05480v1 [cs.LG])
66. Label-Efficient Self-Supervised Speaker Verification With Information Maximization and Contrastive Learning. (arXiv:2207.05506v1 [eess.AS])
67. EfficientLEAF: A Faster LEarnable Audio Frontend of Questionable Use. (arXiv:2207.05508v1 [cs.SD])
68. Hybrid Physical-Neural ODEs for Fast N-body Simulations. (arXiv:2207.05509v1 [astro-ph.CO])
69. Transferability-Guided Cross-Domain Cross-Task Transfer Learning. (arXiv:2207.05510v1 [cs.CV])
70. A semi-supervised geometric-driven methodology for supervised fishing activity detection on multi-source AIS tracking messages. (arXiv:2207.05514v1 [cs.LG])
71. Tracking Objects as Pixel-wise Distributions. (arXiv:2207.05518v1 [cs.CV])
72. Federated Unlearning: How to Efficiently Erase a Client in FL?. (arXiv:2207.05521v1 [cs.LG])
73. Utilizing Excess Resources in Training Neural Networks. (arXiv:2207.05532v1 [cs.LG])
74. Markovian Gaussian Process Variational Autoencoders. (arXiv:2207.05543v1 [cs.LG])
75. Practical Attacks on Machine Learning: A Case Study on Adversarial Windows Malware. (arXiv:2207.05548v1 [cs.CR])
76. PoeticTTS -- Controllable Poetry Reading for Literary Studies. (arXiv:2207.05549v1 [eess.AS])
77. LightViT: Towards Light-Weight Convolution-Free Vision Transformers. (arXiv:2207.05557v1 [cs.CV])
78. Brain-inspired Graph Spiking Neural Networks for Commonsense Knowledge Representation and Reasoning. (arXiv:2207.05561v1 [cs.NE])
79. BASED-XAI: Breaking Ablation Studies Down for Explainable Artificial Intelligence. (arXiv:2207.05566v1 [cs.LG])
80. Investigating the Impact of Independent Rule Fitnesses in a Learning Classifier System. (arXiv:2207.05582v1 [cs.LG])
81. Inner Monologue: Embodied Reasoning through Planning with Language Models. (arXiv:2207.05608v1 [cs.RO])
82. Contrastive Learning for Online Semi-Supervised General Continual Learning. (arXiv:2207.05615v1 [cs.LG])
83. DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization. (arXiv:2207.05631v1 [cs.LG])
84. Docent: A content-based recommendation system to discover contemporary art. (arXiv:2207.05648v1 [cs.LG])
85. A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained Optimization. (arXiv:2207.05650v1 [math.OC])
86. A Computational Model for Logical Analysis of Data. (arXiv:2207.05664v1 [cs.LG])
87. From Spectral Graph Convolutions to Large Scale Graph Convolutional Networks. (arXiv:2207.05669v1 [cs.LG])
88. DDI Prediction via Heterogeneous Graph Attention Networks. (arXiv:2207.05672v1 [cs.LG])
89. Using Machine Learning to Reduce Observational Biases When Detecting New Impacts on Mars. (arXiv:2207.05679v1 [cs.LG])
90. Long Short-Term Memory to predict 3D Amino acids Positions in GPCR Molecular Dynamics. (arXiv:2207.05682v1 [q-bio.BM])
91. Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL. (arXiv:2207.05683v1 [cs.MA])
92. Machine Learning model for gas-liquid interface reconstruction in CFD numerical simulations. (arXiv:2207.05684v1 [physics.flu-dyn])
93. PAC-Bayesian Domain Adaptation Bounds for Multiclass Learners. (arXiv:2207.05685v1 [cs.LG])
94. The MuSe 2022 Multimodal Sentiment Analysis Challenge: Humor, Emotional Reactions, and Stress. (arXiv:2207.05691v1 [cs.LG])
95. A machine-learning-based tool for last closed magnetic flux surface reconstruction on tokamak. (arXiv:2207.05695v1 [physics.plasm-ph])
96. RE-Tagger: A light-weight Real-Estate Image Classifier. (arXiv:2207.05696v1 [cs.CV])
97. A Newton-CG based barrier method for finding a second-order stationary point of nonconvex conic optimization with complexity guarantees. (arXiv:2207.05697v1 [math.OC])
98. Autoencoding Conditional GAN for Portfolio Allocation Diversification. (arXiv:2207.05701v1 [q-fin.PM])
99. Conservative SPDEs as fluctuating mean field limits of stochastic gradient descent. (arXiv:2207.05705v1 [math.PR])
100. Improved Batching Strategy For Irregular Time-Series ODE. (arXiv:2207.05708v1 [cs.LG])
101. The Untold Impact of Learning Approaches on Software Fault-Proneness Predictions. (arXiv:2207.05710v1 [cs.SE])
102. Bayesian Experimental Design for Computed Tomography with the Linearised Deep Image Prior. (arXiv:2207.05714v1 [cs.CV])
103. Latent Variable Models for Bayesian Causal Discovery. (arXiv:2207.05723v1 [cs.LG])
104. AGBoost: Attention-based Modification of Gradient Boosting Machine. (arXiv:2207.05724v1 [cs.LG])
105. Physical Passive Patch Adversarial Attacks on Visual Odometry Systems. (arXiv:2207.05729v1 [cs.CV])
106. PAC Reinforcement Learning for Predictive State Representations. (arXiv:2207.05738v1 [cs.LG])
107. A Data-Based Perspective on Transfer Learning. (arXiv:2207.05739v1 [cs.LG])
108. Reactive Exploration to Cope with Non-Stationarity in Lifelong Reinforcement Learning. (arXiv:2207.05742v1 [cs.LG])
109. Cognition in Dynamical Systems, Second Edition. (arXiv:1805.00787v2 [cs.MA] UPDATED)
110. Capturing Evolution Genes for Time Series Data. (arXiv:1905.05004v2 [cs.LG] UPDATED)
111. Robustness and Personalization in Federated Learning: A Unified Approach via Regularization. (arXiv:2009.06303v3 [cs.LG] UPDATED)
112. Autotelic Agents with Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey. (arXiv:2012.09830v7 [cs.LG] UPDATED)
113. Truly Sparse Neural Networks at Scale. (arXiv:2102.01732v2 [cs.LG] UPDATED)
114. Benchmarking of eight recurrent neural network variants for breath phase and adventitious sound detection on a self-developed open-access lung sound database-HF_Lung_V1. (arXiv:2102.03049v3 [cs.SD] UPDATED)
115. WheaCha: A Method for Explaining the Predictions of Models of Code. (arXiv:2102.04625v3 [cs.LG] UPDATED)
116. Coupling streaming AI and HPC ensembles to achieve 100-1000x faster biomolecular simulations. (arXiv:2104.04797v5 [cs.DC] UPDATED)
117. Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data. (arXiv:2106.01336v5 [cs.LG] UPDATED)
118. Remote sensing and AI for building climate adaptation applications. (arXiv:2107.02693v2 [cs.LG] UPDATED)
119. Structure-Enhanced Pop Music Generation via Harmony-Aware Learning. (arXiv:2109.06441v2 [cs.SD] UPDATED)
120. Propagating State Uncertainty Through Trajectory Forecasting. (arXiv:2110.03267v4 [cs.RO] UPDATED)
121. High-dimensional Inference for Dynamic Treatment Effects. (arXiv:2110.04924v3 [stat.ME] UPDATED)
122. Large Language Models Can Be Strong Differentially Private Learners. (arXiv:2110.05679v3 [cs.LG] UPDATED)
123. A Dataset Perspective on Offline Reinforcement Learning. (arXiv:2111.04714v2 [cs.LG] UPDATED)
124. Fast Yet Effective Machine Unlearning. (arXiv:2111.08947v4 [cs.LG] UPDATED)
125. Asteroid Flyby Cycler Trajectory Design Using Deep Neural Networks. (arXiv:2111.11858v3 [astro-ph.IM] UPDATED)
126. Learning with Noisy Labels by Efficient Transition Matrix Estimation to Combat Label Miscorrection. (arXiv:2111.14932v2 [cs.LG] UPDATED)
127. EAGAN: Efficient Two-stage Evolutionary Architecture Search for GANs. (arXiv:2111.15097v2 [cs.CV] UPDATED)
128. PeopleSansPeople: A Synthetic Data Generator for Human-Centric Computer Vision. (arXiv:2112.09290v2 [cs.CV] UPDATED)
129. On robust risk-based active-learning algorithms for enhanced decision support. (arXiv:2201.02555v2 [cs.LG] UPDATED)
130. Zero-Shot Machine Unlearning. (arXiv:2201.05629v2 [cs.LG] UPDATED)
131. "That's so cute!": The CARE Dataset for Affective Response Detection. (arXiv:2201.11895v2 [cs.LG] UPDATED)
132. A Robust and Flexible EM Algorithm for Mixtures of Elliptical Distributions with Missing Data. (arXiv:2201.12020v3 [stat.ML] UPDATED)
133. Solving a directed percolation inverse problem. (arXiv:2201.12222v3 [cond-mat.dis-nn] UPDATED)
134. Log-Euclidean Signatures for Intrinsic Distances Between Unaligned Datasets. (arXiv:2202.01671v2 [stat.ML] UPDATED)
135. Equivariance versus Augmentation for Spherical Images. (arXiv:2202.03990v2 [cs.LG] UPDATED)
136. DeepTx: Deep Learning Beamforming with Channel Prediction. (arXiv:2202.07998v3 [eess.SP] UPDATED)
137. Deep Metric Learning-Based Semi-Supervised Regression With Alternate Learning. (arXiv:2202.11388v2 [cs.CV] UPDATED)
138. Integrated multimodal artificial intelligence framework for healthcare applications. (arXiv:2202.12998v2 [cs.LG] UPDATED)
139. SWIS: Self-Supervised Representation Learning For Writer Independent Offline Signature Verification. (arXiv:2202.13078v2 [cs.CV] UPDATED)
140. Root-aligned SMILES: A Tight Representation for Chemical Reaction Prediction. (arXiv:2203.11444v4 [cs.LG] UPDATED)
141. Accelerating Bayesian Optimization for Biological Sequence Design with Denoising Autoencoders. (arXiv:2203.12742v2 [cs.LG] UPDATED)
142. Transformer Compressed Sensing via Global Image Tokens. (arXiv:2203.12861v3 [cs.CV] UPDATED)
143. Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness and Intelligibility Assessment. (arXiv:2203.15937v3 [eess.AS] UPDATED)
144. Modern Views of Machine Learning for Precision Psychiatry. (arXiv:2204.01607v2 [cs.LG] UPDATED)
145. Exploring the Role of Task Transferability in Large-Scale Multi-Task Learning. (arXiv:2204.11117v2 [cs.CL] UPDATED)
146. Uniform Manifold Approximation with Two-phase Optimization. (arXiv:2205.00420v2 [cs.LG] UPDATED)
147. The ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts. (arXiv:2205.01780v3 [eess.AS] UPDATED)
148. Accelerated Reinforcement Learning for Temporal Logic Control Objectives. (arXiv:2205.04424v3 [cs.RO] UPDATED)
149. Representation learning with function call graph transformations for malware open set recognition. (arXiv:2205.06918v3 [cs.CR] UPDATED)
150. MESH2IR: Neural Acoustic Impulse Response Generator for Complex 3D Scenes. (arXiv:2205.09248v2 [cs.SD] UPDATED)
151. MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent Reinforcement Learning. (arXiv:2205.12449v2 [cs.LG] UPDATED)
152. CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning. (arXiv:2205.15083v2 [cs.LG] UPDATED)
153. Online Meta-Learning in Adversarial Multi-Armed Bandits. (arXiv:2205.15921v2 [cs.LG] UPDATED)
154. A Cross-City Federated Transfer Learning Framework: A Case Study on Urban Region Profiling. (arXiv:2206.00007v3 [cs.LG] UPDATED)
155. Improving the Robustness and Generalization of Deep Neural Network with Confidence Threshold Reduction. (arXiv:2206.00913v2 [cs.LG] UPDATED)
156. Quantum Neural Network Classifiers: A Tutorial. (arXiv:2206.02806v2 [quant-ph] UPDATED)
157. Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v2 [cs.LG] UPDATED)
158. A Machine Learning Data Fusion Model for Soil Moisture Retrieval. (arXiv:2206.09649v2 [physics.ao-ph] UPDATED)
159. Interpretable Deep Causal Learning for Moderation Effects. (arXiv:2206.10261v3 [cs.LG] UPDATED)
160. Prediction of Maneuvering Status for Aerial Vehicles using Supervised Learning Methods. (arXiv:2206.10303v2 [cs.RO] UPDATED)
161. Insights into Deep Non-linear Filters for Improved Multi-channel Speech **Enhancement**. (arXiv:2206.13310v2 [eess.AS] UPDATED)
162. The Neural-Prediction based Acceleration Algorithm of Column Generation for Graph-Based Set Covering Problems. (arXiv:2207.01411v2 [cs.LG] UPDATED)
163. Network Binarization via Contrastive Learning. (arXiv:2207.02970v2 [cs.CV] UPDATED)
164. Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v2 [cs.LG] UPDATED)
165. Revisiting Pretraining Objectives for Tabular Deep Learning. (arXiv:2207.03208v2 [cs.LG] UPDATED)
166. Guiding the retraining of convolutional neural networks against adversarial inputs. (arXiv:2207.03689v2 [cs.SE] UPDATED)
167. Multi-Model Federated Learning with Provable Guarantees. (arXiv:2207.04330v2 [cs.LG] UPDATED)
168. An Introduction to Lifelong Supervised Learning. (arXiv:2207.04354v2 [cs.LG] UPDATED)
169. How Robust is your Fair Model? Exploring the Robustness of Diverse Fairness Strategies. (arXiv:2207.04581v2 [cs.LG] UPDATED)
170. Dynamic Budget Throttling in Repeated Second-Price Auctions. (arXiv:2207.04690v2 [cs.GT] UPDATED)
171. Efficient NLP Inference at the Edge via Elastic Pipelining. (arXiv:2207.05022v2 [cs.LG] UPDATED)
172. Learning Continuous Grasping Function with a Dexterous Hand from Human Demonstrations. (arXiv:2207.05053v2 [cs.RO] UPDATED)
173. Distributed Online System Identification for LTI Systems Using Reverse Experience Replay. (arXiv:2207.01062v1 [cs.LG] CROSS LISTED)
174. voxel2vec: A Natural Language Processing Approach to Learning Distributed Representations for Scientific Data. (arXiv:2207.02565v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**95** new papers in cs.AI:-) 
1. Inferring and Conveying Intentionality: Beyond Numerical Rewards to Logical Intentions. (arXiv:2207.05058v1 [cs.AI])
2. Differentiable Physics Simulations with Contacts: Do They Have Correct Gradients w.r.t. Position, Velocity and Control?. (arXiv:2207.05060v1 [cs.LG])
3. Adaptive Graph Spatial-Temporal Transformer Network for Traffic Flow Forecasting. (arXiv:2207.05064v1 [cs.LG])
4. On the Representation of Causal Background Knowledge and its Applications in Causal Inference. (arXiv:2207.05067v1 [cs.AI])
5. Few-Shot Semantic Relation Prediction across Heterogeneous Graphs. (arXiv:2207.05068v1 [cs.LG])
6. Discovering Domain Disentanglement for Generalized Multi-source Domain Adaptation. (arXiv:2207.05070v1 [cs.LG])
7. Online Continual Learning of End-to-End Speech Recognition Models. (arXiv:2207.05071v1 [cs.LG])
8. Keep your Distance: Determining Sampling and Distance Thresholds in Machine Learning Monitoring. (arXiv:2207.05078v1 [cs.LG])
9. Horizontal Federated Learning and Secure Distributed Training for Recommendation System with Intel SGX. (arXiv:2207.05079v1 [cs.LG])
10. Learning an evolved mixture model for task-free continual learning. (arXiv:2207.05080v1 [cs.LG])
11. Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2021. (arXiv:2207.05133v1 [cs.CL])
12. FreeREA: Training-Free Evolution-based Architecture Search. (arXiv:2207.05135v1 [cs.NE])
13. Towards Personalized Healthcare in Cardiac Population: The Development of a Wearable ECG Monitoring System, an ECG Lossy Compression Schema, and a ResNet-Based AF Detector. (arXiv:2207.05138v1 [eess.SY])
14. Can Language Models perform Abductive Commonsense Reasoning?. (arXiv:2207.05155v1 [cs.AI])
15. DAUX: a Density-based Approach for Uncertainty eXplanations. (arXiv:2207.05161v1 [cs.LG])
16. Knowledge Graph Induction enabling Recommending and Trend Analysis: A Corporate Research Community Use Case. (arXiv:2207.05188v1 [cs.AI])
17. Patch-level instance-group discrimination with pretext-invariant learning for colitis scoring. (arXiv:2207.05192v1 [cs.CV])
18. Grounding Aleatoric Uncertainty in Unsupervised Environment Design. (arXiv:2207.05219v1 [cs.LG])
19. Language Models (Mostly) Know What They Know. (arXiv:2207.05221v1 [cs.CL])
20. Bootstrapping a User-Centered Task-Oriented Dialogue System. (arXiv:2207.05223v1 [cs.CL])
21. Efficient Real-world Testing of Causal Decision Making via Bayesian Experimental Design for Contextual Optimisation. (arXiv:2207.05250v1 [stat.ML])
22. Accelerating Certifiable Estimation with Preconditioned Eigensolvers. (arXiv:2207.05257v1 [cs.RO])
23. Language-Based Causal Representation Learning. (arXiv:2207.05259v1 [cs.AI])
24. Building Korean Sign Language Augmentation (KoSLA) Corpus with Data Augmentation Technique. (arXiv:2207.05261v1 [cs.CL])
25. A Survey on Table Question Answering: Recent Advances. (arXiv:2207.05270v1 [cs.CL])
26. Online Game Level Generation from Music. (arXiv:2207.05271v1 [cs.AI])
27. Photonic Reconfigurable Accelerators for Efficient Inference of CNNs with Mixed-Sized Tensors. (arXiv:2207.05278v1 [cs.AR])
28. Offline Equilibrium Finding. (arXiv:2207.05285v1 [cs.AI])
29. PLM-ICD: Automatic ICD Coding with Pretrained Language Models. (arXiv:2207.05289v1 [cs.CL])
30. Causal Conceptions of Fairness and their Consequences. (arXiv:2207.05302v1 [cs.LG])
31. Contrastive Deep Supervision. (arXiv:2207.05306v1 [cs.CV])
32. CompoundE: Knowledge Graph Embedding with Translation, Rotation and Scaling Compound Operations. (arXiv:2207.05324v1 [cs.AI])
33. Diversity-aware social robots meet people: beyond context-aware embodied AI. (arXiv:2207.05372v1 [cs.RO])
34. Western Mediterranean wetlands bird species classification: evaluating small-footprint deep learning approaches on a new annotated dataset. (arXiv:2207.05393v1 [cs.SD])
35. Split Time Series into Patches: Rethinking Long-term Series Forecasting with Dateformer. (arXiv:2207.05397v1 [cs.LG])
36. UniNet: Unified Architecture Search with Convolution, Transformer, and MLP. (arXiv:2207.05420v1 [cs.CV])
37. Adversarial Robustness Assessment of NeuroEvolution Approaches. (arXiv:2207.05451v1 [cs.NE])
38. A Benchmark dataset for predictive maintenance. (arXiv:2207.05466v1 [cs.LG])
39. Sliced-Wasserstein normalizing flows: beyond maximum likelihood training. (arXiv:2207.05468v1 [stat.ML])
40. Transferability-Guided Cross-Domain Cross-Task Transfer Learning. (arXiv:2207.05510v1 [cs.CV])
41. Tracking Objects as Pixel-wise Distributions. (arXiv:2207.05518v1 [cs.CV])
42. Camera Pose Auto-Encoders for Improving Pose Regression. (arXiv:2207.05530v1 [cs.CV])
43. DTG-SSOD: Dense Teacher Guidance for Semi-Supervised Object Detection. (arXiv:2207.05536v1 [cs.CV])
44. LightViT: Towards Light-Weight Convolution-Free Vision Transformers. (arXiv:2207.05557v1 [cs.CV])
45. Brain-inspired Graph Spiking Neural Networks for Commonsense Knowledge Representation and Reasoning. (arXiv:2207.05561v1 [cs.NE])
46. BASED-XAI: Breaking Ablation Studies Down for Explainable Artificial Intelligence. (arXiv:2207.05566v1 [cs.LG])
47. Multi-Behavior Hypergraph-Enhanced Transformer for Sequential Recommendation. (arXiv:2207.05584v1 [cs.IR])
48. Inner Monologue: Embodied Reasoning through Planning with Language Models. (arXiv:2207.05608v1 [cs.RO])
49. Contrastive Learning for Online Semi-Supervised General Continual Learning. (arXiv:2207.05615v1 [cs.LG])
50. LudVision -- Remote Detection of Exotic Invasive Aquatic Floral Species using Drone-Mounted Multispectral Data. (arXiv:2207.05620v1 [cs.CV])
51. DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization. (arXiv:2207.05631v1 [cs.LG])
52. Backdoor Attacks on Crowd Counting. (arXiv:2207.05641v1 [cs.CV])
53. Docent: A content-based recommendation system to discover contemporary art. (arXiv:2207.05648v1 [cs.LG])
54. A Single-Loop Gradient Descent and Perturbed Ascent Algorithm for Nonconvex Functional Constrained Optimization. (arXiv:2207.05650v1 [math.OC])
55. DDI Prediction via Heterogeneous Graph Attention Networks. (arXiv:2207.05672v1 [cs.LG])
56. The Contribution of Lyrics and Acoustics to Collaborative Understanding of Mood. (arXiv:2207.05680v1 [cs.MM])
57. Long Short-Term Memory to predict 3D Amino acids Positions in GPCR Molecular Dynamics. (arXiv:2207.05682v1 [q-bio.BM])
58. Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL. (arXiv:2207.05683v1 [cs.MA])
59. The MuSe 2022 Multimodal Sentiment Analysis Challenge: Humor, Emotional Reactions, and Stress. (arXiv:2207.05691v1 [cs.LG])
60. Latent Variable Models for Bayesian Causal Discovery. (arXiv:2207.05723v1 [cs.LG])
61. A Skeleton-aware Graph Convolutional Network for Human-Object Interaction Detection. (arXiv:2207.05733v1 [cs.CV])
62. Reactive Exploration to Cope with Non-Stationarity in Lifelong Reinforcement Learning. (arXiv:2207.05742v1 [cs.LG])
63. Cognition in Dynamical Systems, Second Edition. (arXiv:1805.00787v2 [cs.MA] UPDATED)
64. Reward Maximisation through Discrete Active Inference. (arXiv:2009.08111v4 [cs.AI] UPDATED)
65. Autotelic Agents with Intrinsically Motivated Goal-Conditioned Reinforcement Learning: a Short Survey. (arXiv:2012.09830v7 [cs.LG] UPDATED)
66. Benchmarking of eight recurrent neural network variants for breath phase and adventitious sound detection on a self-developed open-access lung sound database-HF_Lung_V1. (arXiv:2102.03049v3 [cs.SD] UPDATED)
67. Risk-averse autonomous systems: A brief history and recent developments from the perspective of optimal control. (arXiv:2109.08947v3 [cs.AI] UPDATED)
68. A Dataset Perspective on Offline Reinforcement Learning. (arXiv:2111.04714v2 [cs.LG] UPDATED)
69. Learning with Noisy Labels by Efficient Transition Matrix Estimation to Combat Label Miscorrection. (arXiv:2111.14932v2 [cs.LG] UPDATED)
70. PeopleSansPeople: A Synthetic Data Generator for Human-Centric Computer Vision. (arXiv:2112.09290v2 [cs.CV] UPDATED)
71. Zero-Shot Machine Unlearning. (arXiv:2201.05629v2 [cs.LG] UPDATED)
72. Integrated multimodal artificial intelligence framework for healthcare applications. (arXiv:2202.12998v2 [cs.LG] UPDATED)
73. ParaNames: A Massively Multilingual Entity Name Corpus. (arXiv:2202.14035v3 [cs.CL] UPDATED)
74. Decoupled Knowledge Distillation. (arXiv:2203.08679v2 [cs.CV] UPDATED)
75. Weakly-Supervised Salient Object Detection Using Point Supervision. (arXiv:2203.11652v2 [cs.CV] UPDATED)
76. Modern Views of Machine Learning for Precision Psychiatry. (arXiv:2204.01607v2 [cs.LG] UPDATED)
77. MMRotate: A Rotated Object Detection Benchmark using Pytorch. (arXiv:2204.13317v2 [cs.CV] UPDATED)
78. CGMN: A Contrastive Graph Matching Network for Self-Supervised Graph Similarity Learning. (arXiv:2205.15083v2 [cs.LG] UPDATED)
79. A Cross-City Federated Transfer Learning Framework: A Case Study on Urban Region Profiling. (arXiv:2206.00007v3 [cs.LG] UPDATED)
80. Quantum Neural Network Classifiers: A Tutorial. (arXiv:2206.02806v2 [quant-ph] UPDATED)
81. Interpretable Deep Causal Learning for Moderation Effects. (arXiv:2206.10261v3 [cs.LG] UPDATED)
82. UI Layers Merger: Merging UI layers via Visual Learning and Boundary Prior. (arXiv:2206.13389v2 [cs.CV] UPDATED)
83. Knowledge Distillation of Transformer-based Language Models Revisited. (arXiv:2206.14366v3 [cs.CL] UPDATED)
84. C2FTrans: Coarse-to-Fine Transformers for Medical Image Segmentation. (arXiv:2206.14409v2 [cs.CV] UPDATED)
85. The Lighter The Better: Rethinking Transformers in Medical Image Segmentation Through Adaptive Pruning. (arXiv:2206.14413v2 [cs.CV] UPDATED)
86. PolarFormer: Multi-camera 3D Object Detection with Polar Transformers. (arXiv:2206.15398v4 [cs.CV] UPDATED)
87. Counterfactually Measuring and Eliminating Social Bias in Vision-Language Pre-training Models. (arXiv:2207.01056v2 [cs.CV] UPDATED)
88. Towards the Practical Utility of Federated Learning in the Medical Domain. (arXiv:2207.03075v2 [cs.LG] UPDATED)
89. DGraph: A Large-Scale Financial Dataset for Graph Anomaly Detection. (arXiv:2207.03579v2 [cs.SI] UPDATED)
90. Guiding the retraining of convolutional neural networks against adversarial inputs. (arXiv:2207.03689v2 [cs.SE] UPDATED)
91. An Introduction to Lifelong Supervised Learning. (arXiv:2207.04354v2 [cs.LG] UPDATED)
92. Planning Sequential Tasks on Contact Graph. (arXiv:2207.04364v2 [cs.RO] UPDATED)
93. Dual Vision Transformer. (arXiv:2207.04976v2 [cs.CV] UPDATED)
94. Efficient Task Planning for Mobile Manipulation: a Virtual Kinematic Chain Perspective. (arXiv:2108.01259v1 [cs.RO] CROSS LISTED)
95. Consolidating Kinematic Models to Promote Coordinated Mobile Manipulations. (arXiv:2108.01264v3 [cs.RO] CROSS LISTED)

