# Your interest papers
---
## cs.CV
---
### Dynamic Rectification Knowledge Distillation. (arXiv:2201.11319v1 [cs.CV])
- Authors : Fahad Rahman, Ahnaf Ismat, Silvia Ahmed, Lutfe Elahi, Nabeel Mohammed
- Link : [http://arxiv.org/abs/2201.11319](http://arxiv.org/abs/2201.11319)
> ABSTRACT  :  Knowledge Distillation is a technique which aims to utilize **dark** knowledge to compress and transfer information from a vast, well-trained neural network (teacher model) to a smaller, less capable neural network (student model) with improved inference efficiency. This approach of distilling knowledge has gained popularity as a result of the prohibitively complicated nature of such cumbersome models for deployment on edge computing devices. Generally, the teacher models used to teach smaller student models are cumbersome in nature and expensive to train. To eliminate the necessity for a cumbersome teacher model completely, we propose a simple yet effective knowledge distillation framework that we termed Dynamic Rectification Knowledge Distillation (DR-KD). Our method transforms the student into its own teacher, and if the self-teacher makes wrong predictions while distilling information, the error is rectified prior to the knowledge being distilled. Specifically, the teacher targets are dynamically tweaked by the agency of ground-truth while distilling the knowledge gained from traditional training. Our proposed DR-KD performs remarkably well in the absence of a sophisticated cumbersome teacher model and achieves comparable performance to existing state-of-the-art teacher-free knowledge distillation frameworks when implemented by a low-cost dynamic mannered teacher. Our approach is all-encompassing and can be utilized for any deep neural network training that requires categorization or object recognition. DR-KD enhances the test accuracy on Tiny ImageNet by 2.65% over prominent baseline models, which is significantly better than any other knowledge distillation approach while requiring no additional training costs.  
### Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
- Authors : Dionne Takudzwa, Mkhuseli Ngxande
- Link : [http://arxiv.org/abs/2201.11389](http://arxiv.org/abs/2201.11389)
> ABSTRACT  :  In the age of streaming and surveillance compressed video **enhancement** has become a problem in need of constant improvement. Here, we investigate a way of improving the Multi-Frame Quality **Enhancement** approach. This approach consists of making use of the frames that have the peak quality in the region to improve those that have a lower quality in that region. This approach consists of obtaining quantized data from the videos using a deep belief network. The quantized data is then fed into the MF-CNN architecture to improve the compressed video. We further investigate the impact of using a Bi-LSTM for detecting the peak quality frames. Our approach obtains better results than the first approach of the MFQE which uses an SVM for PQF detection. On the other hand, our MFQE approach does not outperform the latest version of the MQFE approach that uses a Bi-LSTM for PQF detection.  
### Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v1 [cs.CV])
- Authors : Penglei Gao, Xi Yang, Rui Zhang, Kaizhu Huang, Yujie Geng
- Link : [http://arxiv.org/abs/2201.11403](http://arxiv.org/abs/2201.11403)
> ABSTRACT  :  While most present image outpainting conducts horizontal extrapolation, we study the generalised image outpainting problem that extrapolates visual context all-side around a given image. To this end, we develop a novel transformer-based generative adversarial network called U-Transformer able to extend image borders with plausible structure and details even for complicated scenery images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular **Swin** Transformer blocks. As such, our novel framework can better cope with image long-range dependencies which are crucially important for generalised image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor network to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.  
### In Defense of Kalman Filtering for Polyp Tracking from Colonoscopy Videos. (arXiv:2201.11450v1 [cs.CV])
- Authors : David Butler, Yuan Zhang, Tim Chen, Seon Ho, Rajvinder Singh, Gustavo Carneiro
- Link : [http://arxiv.org/abs/2201.11450](http://arxiv.org/abs/2201.11450)
> ABSTRACT  :  **Real-time** and robust automatic detection of polyps from colonoscopy videos are essential tasks to help improve the performance of doctors during this exam. The current focus of the field is on the development of accurate but inefficient detectors that will not enable a real-time application. We advocate that the field should instead focus on the development of simple and efficient detectors that an be combined with effective trackers to allow the implementation of real-time polyp detectors. In this paper, we propose a Kalman filtering tracker that can work together with powerful, but efficient detectors, enabling the implementation of real-time polyp detectors. In particular, we show that the combination of our Kalman filtering with the detector PP-YOLO shows state-of-the-art (SOTA) detection accuracy and real-time processing. More specifically, our approach has SOTA results on the CVC-ClinicDB dataset, with a recall of 0.740, precision of 0.869, $F_1$ score of 0.799, an average precision (AP) of 0.837, and can run in **real time** (i.e., 30 frames per second). We also evaluate our method on a subset of the Hyper-Kvasir annotated by our clinical collaborators, resulting in SOTA results, with a recall of 0.956, precision of 0.875, $F_1$ score of 0.914, AP of 0.952, and can run in **real time**.  
### Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
- Authors : Saeed Anwar, Muhammad Tahir, **Chongyi Li**, Ajmal Mian, Fahad Shahbaz, Abdul Wahab
- Link : [http://arxiv.org/abs/2008.10774](http://arxiv.org/abs/2008.10774)
> ABSTRACT  :  Image colorization is the process of estimating RGB colors for grayscale images or video frames to improve their aesthetic and perceptual quality. Deep learning techniques for image colorization have progressed notably over the last decade, calling the need for a systematic survey and benchmarking of these techniques. This article presents a comprehensive survey of recent state-of-the-art deep learning-based image colorization techniques, describing their fundamental block architectures, inputs, optimizers, loss functions, training protocols, and training data \textit{etc.} It categorizes the existing colorization techniques into seven classes and discusses important factors governing their performance, such as benchmark datasets and evaluation metrics. We highlight the limitations of existing datasets and introduce a new dataset specific to colorization. Using the existing datasets and our new one, we perform an extensive experimental evaluation of existing image colorization methods. Finally, we discuss the limitations of existing methods and recommend possible solutions as well as future research directions for this rapidly evolving topic of deep image colorization. Dataset and codes for evaluation are publicly available at https://github.com/saeed-anwar/ColorSurvey  
### FOD-A: A Dataset for Foreign Object Debris in Airports. (arXiv:2110.03072v2 [cs.CV] UPDATED)
- Authors : Travis Munyer, Chi Huang, Chenyu Huang, Xin Zhong
- Link : [http://arxiv.org/abs/2110.03072](http://arxiv.org/abs/2110.03072)
> ABSTRACT  :  Foreign Object Debris (FOD) detection has attracted increased attention in the area of machine learning and computer vision. However, a robust and publicly available image dataset for FOD has not been initialized. To this end, this paper introduces an image dataset of FOD, named FOD in Airports (FOD-A). FOD-A object categories have been selected based on guidance from prior documentation and related research by the Federal Aviation Administration (FAA). In addition to the primary annotations of bounding boxes for object detection, FOD-A provides labeled environmental conditions. As such, each annotation instance is further categorized into three light level categories (bright, dim, and **dark**) and two weather categories (dry and wet). Currently, FOD-A has released 31 object categories and over 30,000 annotation instances. This paper presents the creation methodology, discusses the publicly available dataset extension process, and demonstrates the practicality of FOD-A with widely used machine learning models for object detection.  
### 3D High-Quality Magnetic Resonance Image **Restoration** in Clinics Using Deep Learning. (arXiv:2111.14259v3 [eess.IV] UPDATED)
- Authors : Hao Li, Jianan Liu
- Link : [http://arxiv.org/abs/2111.14259](http://arxiv.org/abs/2111.14259)
> ABSTRACT  :  Shortening acquisition time and reducing the motion artifacts are two of the most essential concerns in magnetic resonance imaging. As a promising solution, deep learning-based high-quality MR image **restoration** has been investigated to generate higher resolution and motion artifact-free MR images from lower resolution images acquired with shortened acquisition time, without costing additional acquisition time or modifying the pulse sequences. However, numerous problems still exist to prevent deep learning approaches from becoming practical in the clinic environment. Specifically, most of the prior works focus solely on the network model but ignore the impact of various downsampling strategies on the acquisition time. Besides, the long inference time and high GPU consumption are also the bottlenecks to deploy most of the prior works in clinics. Furthermore, prior studies employ random movement in retrospective motion artifact generation, resulting in uncontrollable severity of motion artifact. More importantly, doctors are unsure whether the generated MR images are trustworthy, making diagnosis difficult. To overcome all these problems, we employed a unified 2D deep learning neural network for both 3D MRI super resolution and motion artifact reduction, demonstrating such a framework can achieve better performance in 3D MRI **restoration** tasks compared to other states of the art methods and remains the GPU consumption and inference time significantly low, thus easier to deploy. We also analyzed several downsampling strategies based on the acceleration factor, including multiple combinations of in-plane and through-plane downsampling, and developed a controllable and quantifiable motion artifact generation method. At last, the pixel-wise uncertainty was calculated and used to estimate the accuracy of the generated image, providing additional information for reliable diagnosis.  
## eess.IV
---
### Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
- Authors : Dionne Takudzwa, Mkhuseli Ngxande
- Link : [http://arxiv.org/abs/2201.11389](http://arxiv.org/abs/2201.11389)
> ABSTRACT  :  In the age of streaming and surveillance compressed video **enhancement** has become a problem in need of constant improvement. Here, we investigate a way of improving the Multi-Frame Quality **Enhancement** approach. This approach consists of making use of the frames that have the peak quality in the region to improve those that have a lower quality in that region. This approach consists of obtaining quantized data from the videos using a deep belief network. The quantized data is then fed into the MF-CNN architecture to improve the compressed video. We further investigate the impact of using a Bi-LSTM for detecting the peak quality frames. Our approach obtains better results than the first approach of the MFQE which uses an SVM for PQF detection. On the other hand, our MFQE approach does not outperform the latest version of the MQFE approach that uses a Bi-LSTM for PQF detection.  
### Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
- Authors : Saeed Anwar, Muhammad Tahir, **Chongyi Li**, Ajmal Mian, Fahad Shahbaz, Abdul Wahab
- Link : [http://arxiv.org/abs/2008.10774](http://arxiv.org/abs/2008.10774)
> ABSTRACT  :  Image colorization is the process of estimating RGB colors for grayscale images or video frames to improve their aesthetic and perceptual quality. Deep learning techniques for image colorization have progressed notably over the last decade, calling the need for a systematic survey and benchmarking of these techniques. This article presents a comprehensive survey of recent state-of-the-art deep learning-based image colorization techniques, describing their fundamental block architectures, inputs, optimizers, loss functions, training protocols, and training data \textit{etc.} It categorizes the existing colorization techniques into seven classes and discusses important factors governing their performance, such as benchmark datasets and evaluation metrics. We highlight the limitations of existing datasets and introduce a new dataset specific to colorization. Using the existing datasets and our new one, we perform an extensive experimental evaluation of existing image colorization methods. Finally, we discuss the limitations of existing methods and recommend possible solutions as well as future research directions for this rapidly evolving topic of deep image colorization. Dataset and codes for evaluation are publicly available at https://github.com/saeed-anwar/ColorSurvey  
### 3D High-Quality Magnetic Resonance Image **Restoration** in Clinics Using Deep Learning. (arXiv:2111.14259v3 [eess.IV] UPDATED)
- Authors : Hao Li, Jianan Liu
- Link : [http://arxiv.org/abs/2111.14259](http://arxiv.org/abs/2111.14259)
> ABSTRACT  :  Shortening acquisition time and reducing the motion artifacts are two of the most essential concerns in magnetic resonance imaging. As a promising solution, deep learning-based high-quality MR image **restoration** has been investigated to generate higher resolution and motion artifact-free MR images from lower resolution images acquired with shortened acquisition time, without costing additional acquisition time or modifying the pulse sequences. However, numerous problems still exist to prevent deep learning approaches from becoming practical in the clinic environment. Specifically, most of the prior works focus solely on the network model but ignore the impact of various downsampling strategies on the acquisition time. Besides, the long inference time and high GPU consumption are also the bottlenecks to deploy most of the prior works in clinics. Furthermore, prior studies employ random movement in retrospective motion artifact generation, resulting in uncontrollable severity of motion artifact. More importantly, doctors are unsure whether the generated MR images are trustworthy, making diagnosis difficult. To overcome all these problems, we employed a unified 2D deep learning neural network for both 3D MRI super resolution and motion artifact reduction, demonstrating such a framework can achieve better performance in 3D MRI **restoration** tasks compared to other states of the art methods and remains the GPU consumption and inference time significantly low, thus easier to deploy. We also analyzed several downsampling strategies based on the acceleration factor, including multiple combinations of in-plane and through-plane downsampling, and developed a controllable and quantifiable motion artifact generation method. At last, the pixel-wise uncertainty was calculated and used to estimate the accuracy of the generated image, providing additional information for reliable diagnosis.  
## cs.LG
---
### Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
- Authors : Dionne Takudzwa, Mkhuseli Ngxande
- Link : [http://arxiv.org/abs/2201.11389](http://arxiv.org/abs/2201.11389)
> ABSTRACT  :  In the age of streaming and surveillance compressed video **enhancement** has become a problem in need of constant improvement. Here, we investigate a way of improving the Multi-Frame Quality **Enhancement** approach. This approach consists of making use of the frames that have the peak quality in the region to improve those that have a lower quality in that region. This approach consists of obtaining quantized data from the videos using a deep belief network. The quantized data is then fed into the MF-CNN architecture to improve the compressed video. We further investigate the impact of using a Bi-LSTM for detecting the peak quality frames. Our approach obtains better results than the first approach of the MFQE which uses an SVM for PQF detection. On the other hand, our MFQE approach does not outperform the latest version of the MQFE approach that uses a Bi-LSTM for PQF detection.  
### FinGAN: Generative Adversarial Network for Analytical Customer Relationship Management in Banking and Insurance. (arXiv:2201.11486v1 [cs.CE])
- Authors : Prateek Kate, Vadlamani Ravi, Akhilesh Gangwar
- Link : [http://arxiv.org/abs/2201.11486](http://arxiv.org/abs/2201.11486)
> ABSTRACT  :  Churn prediction in credit cards, fraud detection in insurance, and loan default prediction are important analytical customer relationship management (ACRM) problems. Since frauds, churns and defaults happen less frequently, the datasets for these problems turn out to be naturally highly unbalanced. Consequently, all supervised machine learning classifiers tend to yield substantial false-positive rates when trained on such unbalanced datasets. We propose two ways of data balancing. In the first, we propose an oversampling method to generate synthetic samples of minority class using Generative Adversarial Network (GAN). We employ Vanilla GAN [1], Wasserstein GAN [2] and CTGAN [3] separately to oversample the minority class samples. In order to assess the efficacy of our proposed approach, we use a host of machine learning classifiers, including Random Forest, Decision Tree, support vector machine (SVM), and Logistic Regression on the data balanced by GANs. In the second method, we introduce a hybrid method to handle data imbalance. In this second way, we utilize the power of undersampling and over-sampling together by augmenting the synthetic minority class data oversampled by GAN with the undersampled majority class data obtained by one-class support vigor machine (OCSVM) [4]. We combine both over-sampled data generated by GAN and the data under-sampled by OCSVM [4] and pass the resultant data to classifiers. When we compared our results to those of Farquad et al. [5], Sun**dark**umar, Ravi, and Siddeshwar [6], our proposed methods outperform the previous results in terms of the area under the ROC curve (AUC) on all datasets.  
### Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
- Authors : Saeed Anwar, Muhammad Tahir, **Chongyi Li**, Ajmal Mian, Fahad Shahbaz, Abdul Wahab
- Link : [http://arxiv.org/abs/2008.10774](http://arxiv.org/abs/2008.10774)
> ABSTRACT  :  Image colorization is the process of estimating RGB colors for grayscale images or video frames to improve their aesthetic and perceptual quality. Deep learning techniques for image colorization have progressed notably over the last decade, calling the need for a systematic survey and benchmarking of these techniques. This article presents a comprehensive survey of recent state-of-the-art deep learning-based image colorization techniques, describing their fundamental block architectures, inputs, optimizers, loss functions, training protocols, and training data \textit{etc.} It categorizes the existing colorization techniques into seven classes and discusses important factors governing their performance, such as benchmark datasets and evaluation metrics. We highlight the limitations of existing datasets and introduce a new dataset specific to colorization. Using the existing datasets and our new one, we perform an extensive experimental evaluation of existing image colorization methods. Finally, we discuss the limitations of existing methods and recommend possible solutions as well as future research directions for this rapidly evolving topic of deep image colorization. Dataset and codes for evaluation are publicly available at https://github.com/saeed-anwar/ColorSurvey  
### FOD-A: A Dataset for Foreign Object Debris in Airports. (arXiv:2110.03072v2 [cs.CV] UPDATED)
- Authors : Travis Munyer, Chi Huang, Chenyu Huang, Xin Zhong
- Link : [http://arxiv.org/abs/2110.03072](http://arxiv.org/abs/2110.03072)
> ABSTRACT  :  Foreign Object Debris (FOD) detection has attracted increased attention in the area of machine learning and computer vision. However, a robust and publicly available image dataset for FOD has not been initialized. To this end, this paper introduces an image dataset of FOD, named FOD in Airports (FOD-A). FOD-A object categories have been selected based on guidance from prior documentation and related research by the Federal Aviation Administration (FAA). In addition to the primary annotations of bounding boxes for object detection, FOD-A provides labeled environmental conditions. As such, each annotation instance is further categorized into three light level categories (bright, dim, and **dark**) and two weather categories (dry and wet). Currently, FOD-A has released 31 object categories and over 30,000 annotation instances. This paper presents the creation methodology, discusses the publicly available dataset extension process, and demonstrates the practicality of FOD-A with widely used machine learning models for object detection.  
## cs.AI
---
### Dynamic Rectification Knowledge Distillation. (arXiv:2201.11319v1 [cs.CV])
- Authors : Fahad Rahman, Ahnaf Ismat, Silvia Ahmed, Lutfe Elahi, Nabeel Mohammed
- Link : [http://arxiv.org/abs/2201.11319](http://arxiv.org/abs/2201.11319)
> ABSTRACT  :  Knowledge Distillation is a technique which aims to utilize **dark** knowledge to compress and transfer information from a vast, well-trained neural network (teacher model) to a smaller, less capable neural network (student model) with improved inference efficiency. This approach of distilling knowledge has gained popularity as a result of the prohibitively complicated nature of such cumbersome models for deployment on edge computing devices. Generally, the teacher models used to teach smaller student models are cumbersome in nature and expensive to train. To eliminate the necessity for a cumbersome teacher model completely, we propose a simple yet effective knowledge distillation framework that we termed Dynamic Rectification Knowledge Distillation (DR-KD). Our method transforms the student into its own teacher, and if the self-teacher makes wrong predictions while distilling information, the error is rectified prior to the knowledge being distilled. Specifically, the teacher targets are dynamically tweaked by the agency of ground-truth while distilling the knowledge gained from traditional training. Our proposed DR-KD performs remarkably well in the absence of a sophisticated cumbersome teacher model and achieves comparable performance to existing state-of-the-art teacher-free knowledge distillation frameworks when implemented by a low-cost dynamic mannered teacher. Our approach is all-encompassing and can be utilized for any deep neural network training that requires categorization or object recognition. DR-KD enhances the test accuracy on Tiny ImageNet by 2.65% over prominent baseline models, which is significantly better than any other knowledge distillation approach while requiring no additional training costs.  
### Reasoning Like Program Executors. (arXiv:2201.11473v1 [cs.CL])
- Authors : Xinyu Pi, Qian Liu, Bei Chen, Morteza Ziyadi, Zeqi Lin, Yan Gao, Qiang Fu, Guang Lou, Weizhu Chen
- Link : [http://arxiv.org/abs/2201.11473](http://arxiv.org/abs/2201.11473)
> ABSTRACT  :  Reasoning over natural language is a long-standing goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a new pre-training paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed in program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of programs. In this paper, we show three empirically powerful instances, i.e., POET-Math, POET-Logic, and POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance on natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. Taking the DROP benchmark as a representative example, POET improves the F1 metric of BART from 69.2% to 80.6%. Furthermore, POET shines in giant language models, pushing the F1 metric of T5-11B to 87.6% and achieving a new state-of-the-art performance on DROP. POET opens a new gate on reasoning-**enhancement** pre-training and we hope our analysis would shed light on the future research of reasoning like program executors.  
### Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
- Authors : Saeed Anwar, Muhammad Tahir, **Chongyi Li**, Ajmal Mian, Fahad Shahbaz, Abdul Wahab
- Link : [http://arxiv.org/abs/2008.10774](http://arxiv.org/abs/2008.10774)
> ABSTRACT  :  Image colorization is the process of estimating RGB colors for grayscale images or video frames to improve their aesthetic and perceptual quality. Deep learning techniques for image colorization have progressed notably over the last decade, calling the need for a systematic survey and benchmarking of these techniques. This article presents a comprehensive survey of recent state-of-the-art deep learning-based image colorization techniques, describing their fundamental block architectures, inputs, optimizers, loss functions, training protocols, and training data \textit{etc.} It categorizes the existing colorization techniques into seven classes and discusses important factors governing their performance, such as benchmark datasets and evaluation metrics. We highlight the limitations of existing datasets and introduce a new dataset specific to colorization. Using the existing datasets and our new one, we perform an extensive experimental evaluation of existing image colorization methods. Finally, we discuss the limitations of existing methods and recommend possible solutions as well as future research directions for this rapidly evolving topic of deep image colorization. Dataset and codes for evaluation are publicly available at https://github.com/saeed-anwar/ColorSurvey  
### Few-shot Multi-hop Question Answering over Knowledge Base. (arXiv:2112.11909v2 [cs.CL] UPDATED)
- Authors : Meihao Fan, **Lei Zhang**, Siyao Xiao, Yuru Liang
- Link : [http://arxiv.org/abs/2112.11909](http://arxiv.org/abs/2112.11909)
> ABSTRACT  :  KBQA is a task that requires to answer questions by using semantic structured information in knowledge base. Previous work in this area has been restricted due to the lack of large semantic parsing dataset and the exponential growth of searching space with the increasing hops of relation paths. In this paper, we propose an efficient pipeline method equipped with a pre-trained language model. By adopting Beam Search algorithm, the searching space will not be restricted in subgraph of 3 hops. Besides, we propose a data generation strategy, which enables our model to generalize well from few training samples. We evaluate our model on an open-domain complex Chinese Question Answering task CCKS2019 and achieve F1-score of 62.55% on the test dataset. In addition, in order to test the few-shot learning capability of our model, we ramdomly select 10% of the primary data to train our model, the result shows that our model can still achieves F1-score of 58.54%, which verifies the capability of our model to process KBQA task and the advantage in few-shot Learning.  
# Paper List
---
## cs.CV
---
**78** new papers in cs.CV:-) 
1. DIREG3D: DIrectly REGress 3D Hands from Multiple Cameras. (arXiv:2201.11187v1 [cs.CV])
2. ReforesTree: A Dataset for Estimating Tropical Forest Carbon Stock with Deep Learning and Aerial Imagery. (arXiv:2201.11192v1 [cs.CV])
3. Challenges and Opportunities for Machine Learning Classification of Behavior and Mental State from Images. (arXiv:2201.11197v1 [cs.CV])
4. Continuous Examination by Automatic Quiz Assessment Using Spiral Codes and Image Processing. (arXiv:2201.11228v1 [cs.CV])
5. HistoKT: Cross Knowledge Transfer in Computational Pathology. (arXiv:2201.11246v1 [eess.IV])
6. Controlling Directions Orthogonal to a Classifier. (arXiv:2201.11259v1 [cs.LG])
7. Revisiting RCAN: Improved Training for Image Super-Resolution. (arXiv:2201.11279v1 [cs.CV])
8. Interactive 3D Character Modeling from 2D Orthogonal Drawings with Annotations. (arXiv:2201.11284v1 [cs.CV])
9. Efficient divide-and-conquer registration of UAV and ground LiDAR point clouds through canopy shape context. (arXiv:2201.11296v1 [cs.CV])
10. Dissecting the impact of different loss functions with gradient surgery. (arXiv:2201.11307v1 [cs.CV])
11. Transformer Module Networks for Systematic Generalization in Visual Question Answering. (arXiv:2201.11316v1 [cs.CV])
12. Dynamic Rectification Knowledge Distillation. (arXiv:2201.11319v1 [cs.CV])
13. Few-shot Transfer Learning for Holographic Image Reconstruction using a Recurrent Neural Network. (arXiv:2201.11333v1 [eess.IV])
14. Exploring Global Diversity and Local Context for Video Summarization. (arXiv:2201.11345v1 [cs.CV])
15. Effective Shortcut Technique for GAN. (arXiv:2201.11351v1 [cs.CV])
16. Deep Confidence Guided Distance for 3D Partial Shape Registration. (arXiv:2201.11379v1 [cs.CV])
17. Contrastive Embedding Distribution Refinement and Entropy-Aware Attention for 3D Point Cloud Classification. (arXiv:2201.11388v1 [cs.CV])
18. Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
19. Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v1 [cs.CV])
20. Non-linear Motion Estimation for Video Frame Interpolation using Space-time Convolutions. (arXiv:2201.11407v1 [cs.CV])
21. DocSegTr: An Instance-Level End-to-End Document Image Segmentation Transformer. (arXiv:2201.11438v1 [cs.CV])
22. An Analysis on Ensemble Learning optimized Medical Image Classification with Deep Convolutional Neural Networks. (arXiv:2201.11440v1 [cs.CV])
23. Pan-Tumor CAnine cuTaneous Cancer Histology (CATCH) Dataset. (arXiv:2201.11446v1 [eess.IV])
24. In Defense of Kalman Filtering for Polyp Tracking from Colonoscopy Videos. (arXiv:2201.11450v1 [cs.CV])
25. RelTR: Relation Transformer for Scene Graph Generation. (arXiv:2201.11460v1 [cs.CV])
26. Eye-focused Detection of Bell's Palsy in Videos. (arXiv:2201.11479v1 [cs.CV])
27. Head and eye egocentric gesture recognition for human-robot interaction using eyewear cameras. (arXiv:2201.11500v1 [cs.CV])
28. Anomaly Detection in Retinal Images using Multi-Scale Deep Feature Sparse Coding. (arXiv:2201.11506v1 [cs.CV])
29. Density-Aware Hyper-Graph Neural Networks for Graph-based Semi-supervised Node Classification. (arXiv:2201.11511v1 [cs.LG])
30. ResiDualGAN: Resize-Residual DualGAN for Cross-Domain Remote Sensing Images Semantic Segmentation. (arXiv:2201.11523v1 [cs.CV])
31. Beyond ImageNet Attack: Towards Crafting Adversarial Examples for Black-box Domains. (arXiv:2201.11528v1 [cs.CV])
32. ASOC: Adaptive Self-aware Object Co-localization. (arXiv:2201.11547v1 [cs.CV])
33. A Probabilistic Framework for Dynamic Object Recognition in 3D Environment With A Novel Continuous Ground Estimation Method. (arXiv:2201.11608v1 [cs.CV])
34. Domain generalization in deep learning-based mass detection in mammography: A large-scale multi-center study. (arXiv:2201.11620v1 [cs.CV])
35. Automatic Classification of Neuromuscular Diseases in Children Using Photoacoustic Imaging. (arXiv:2201.11630v1 [eess.IV])
36. Deep Video Prior for Video Consistency and Propagation. (arXiv:2201.11632v1 [cs.CV])
37. Team Yao at Factify 2022: Utilizing Pre-trained Models and Co-attention Networks for Multi-Modal Fact Verification. (arXiv:2201.11664v1 [cs.CV])
38. Vision Checklist: Towards Testable Error Analysis of Image Models to Help System Designers Interrogate Model Capabilities. (arXiv:2201.11674v1 [cs.CV])
39. Unsupervised Change Detection using DRE-CUSUM. (arXiv:2201.11678v1 [cs.LG])
40. DropNAS: Grouped Operation Dropout for Differentiable Architecture Search. (arXiv:2201.11679v1 [cs.LG])
41. Constrained Structure Learning for Scene Graph Generation. (arXiv:2201.11697v1 [cs.CV])
42. Matched Illumination. (arXiv:2201.11700v1 [eess.IV])
43. A Systematic Study of Bias Amplification. (arXiv:2201.11706v1 [cs.LG])
44. IGLUE: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages. (arXiv:2201.11732v1 [cs.CL])
45. Ranking Info Noise Contrastive Estimation: Boosting Contrastive Learning via Ranked Positives. (arXiv:2201.11736v1 [cs.CV])
46. PRNU Based Source Camera Identification for Webcam and Smartphone Videos. (arXiv:2201.11737v1 [eess.IV])
47. Latent Agents in Networks: Estimation and Targeting. (arXiv:1808.04878v3 [cs.SI] UPDATED)
48. Analysis and algorithms for $\ell_p$-based semi-supervised learning on graphs. (arXiv:1901.05031v4 [math.NA] UPDATED)
49. Generating Adjacency Matrix for Video Relocalization. (arXiv:2008.08977v2 [cs.CV] UPDATED)
50. Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
51. Can we Generalize and Distribute Private Representation Learning?. (arXiv:2010.01792v4 [cs.LG] UPDATED)
52. MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v3 [cs.LG] UPDATED)
53. MODNet: Real-Time Trimap-Free Portrait Matting via Objective Decomposition. (arXiv:2011.11961v3 [cs.CV] UPDATED)
54. SPAA: Stealthy Projector-based Adversarial Attacks on Deep Image Classifiers. (arXiv:2012.05858v2 [cs.CV] UPDATED)
55. Learning Non-linear Wavelet Transformation via Normalizing Flow. (arXiv:2101.11306v2 [cs.LG] UPDATED)
56. Looking Beyond Two Frames: End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers. (arXiv:2103.14829v3 [cs.CV] UPDATED)
57. Self-Supervised Learning from Semantically Imprecise Data. (arXiv:2104.10901v2 [cs.CV] UPDATED)
58. Temporal Prediction and Evaluation of Brassica Growth in the Field using Conditional Generative Adversarial Networks. (arXiv:2105.07789v2 [cs.CV] UPDATED)
59. YOLO5Face: Why Reinventing a Face Detector. (arXiv:2105.12931v3 [cs.CV] UPDATED)
60. The effectiveness of feature attribution methods and its correlation with automatic evaluation scores. (arXiv:2105.14944v4 [cs.CV] UPDATED)
61. Mutual Distillation of Confident Knowledge. (arXiv:2106.01489v2 [cs.LG] UPDATED)
62. Relation-Based Associative Joint Location for Human Pose Estimation in Videos. (arXiv:2107.03591v2 [cs.CV] UPDATED)
63. Modality specific U-Net variants for biomedical image segmentation: A survey. (arXiv:2107.04537v4 [eess.IV] UPDATED)
64. Convolutional Neural Network (CNN) vs Vision Transformer (ViT) for Digital Holography. (arXiv:2108.09147v4 [cs.CV] UPDATED)
65. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v4 [cs.CV] UPDATED)
66. Learning to Aggregate and Refine Noisy Labels for Visual Sentiment Analysis. (arXiv:2109.07509v2 [cs.CV] UPDATED)
67. Towards Protecting Face Embeddings in Mobile Face Verification Scenarios. (arXiv:2110.00434v3 [cs.CV] UPDATED)
68. FOD-A: A Dataset for Foreign Object Debris in Airports. (arXiv:2110.03072v2 [cs.CV] UPDATED)
69. Biometric Template Protection for Neural-Network-based Face Recognition Systems: A Survey of Methods and Evaluation Techniques. (arXiv:2110.05044v2 [cs.CV] UPDATED)
70. CVAD: A generic medical anomaly detector based on Cascade VAE. (arXiv:2110.15811v2 [eess.IV] UPDATED)
71. Generalized Radiograph Representation Learning via Cross-supervision between Images and Free-text Radiology Reports. (arXiv:2111.03452v2 [eess.IV] UPDATED)
72. iBOT: Image BERT Pre-Training with Online Tokenizer. (arXiv:2111.07832v3 [cs.CV] UPDATED)
73. Efficient deep learning models for land cover image classification. (arXiv:2111.09451v2 [cs.CV] UPDATED)
74. 3D High-Quality Magnetic Resonance Image **Restoration** in Clinics Using Deep Learning. (arXiv:2111.14259v3 [eess.IV] UPDATED)
75. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v2 [eess.IV] UPDATED)
76. How Robust are Discriminatively Trained Zero-Shot Learning Models?. (arXiv:2201.10972v2 [cs.CV] UPDATED)
77. Multi-Attribute Balanced Sampling for Disentangled GAN Controls. (arXiv:2111.00909v2 [cs.LG] CROSS LISTED)
78. Jacobian Computation for Cumulative B-splines on SE(3) and Application to Continuous-Time Object Tracking. (arXiv:2201.10602v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. DIREG3D: DIrectly REGress 3D Hands from Multiple Cameras. (arXiv:2201.11187v1 [cs.CV])
2. On The Energy Statistics of Feature Maps in Pruning of Neural Networks with Skip-Connections. (arXiv:2201.11209v1 [cs.LG])
3. HistoKT: Cross Knowledge Transfer in Computational Pathology. (arXiv:2201.11246v1 [eess.IV])
4. Unmixing based PAN guided fusion network for hyperspectral imagery. (arXiv:2201.11318v1 [eess.IV])
5. Few-shot Transfer Learning for Holographic Image Reconstruction using a Recurrent Neural Network. (arXiv:2201.11333v1 [eess.IV])
6. Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
7. Pan-Tumor CAnine cuTaneous Cancer Histology (CATCH) Dataset. (arXiv:2201.11446v1 [eess.IV])
8. Eye-focused Detection of Bell's Palsy in Videos. (arXiv:2201.11479v1 [cs.CV])
9. ASOC: Adaptive Self-aware Object Co-localization. (arXiv:2201.11547v1 [cs.CV])
10. Total variation-based phase retrieval for diffraction tomography. (arXiv:2201.11579v1 [math.NA])
11. Automatic Classification of Neuromuscular Diseases in Children Using Photoacoustic Imaging. (arXiv:2201.11630v1 [eess.IV])
12. Matched Illumination. (arXiv:2201.11700v1 [eess.IV])
13. PRNU Based Source Camera Identification for Webcam and Smartphone Videos. (arXiv:2201.11737v1 [eess.IV])
14. Generating Adjacency Matrix for Video Relocalization. (arXiv:2008.08977v2 [cs.CV] UPDATED)
15. Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
16. Modality specific U-Net variants for biomedical image segmentation: A survey. (arXiv:2107.04537v4 [eess.IV] UPDATED)
17. Convolutional Neural Network (CNN) vs Vision Transformer (ViT) for Digital Holography. (arXiv:2108.09147v4 [cs.CV] UPDATED)
18. CVAD: A generic medical anomaly detector based on Cascade VAE. (arXiv:2110.15811v2 [eess.IV] UPDATED)
19. Generalized Radiograph Representation Learning via Cross-supervision between Images and Free-text Radiology Reports. (arXiv:2111.03452v2 [eess.IV] UPDATED)
20. 3D High-Quality Magnetic Resonance Image **Restoration** in Clinics Using Deep Learning. (arXiv:2111.14259v3 [eess.IV] UPDATED)
21. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v2 [eess.IV] UPDATED)
## cs.LG
---
**151** new papers in cs.LG:-) 
1. Inference-optimized AI and high performance computing for gravitational wave detection at scale. (arXiv:2201.11133v1 [gr-qc])
2. Born-Infeld (BI) for AI: Energy-Conserving Descent (ECD) for Optimization. (arXiv:2201.11137v1 [cs.LG])
3. OntoProtein: Protein Pretraining With Gene Ontology Embedding. (arXiv:2201.11147v1 [q-bio.BM])
4. Self-Certifying Classification by Linearized Deep Assignment. (arXiv:2201.11162v1 [stat.ML])
5. Hyperparameter Tuning for Deep Reinforcement Learning Applications. (arXiv:2201.11182v1 [cs.LG])
6. A dual approach for federated learning. (arXiv:2201.11183v1 [cs.LG])
7. Crystal structure prediction with machine learning-based element substitution. (arXiv:2201.11188v1 [cond-mat.mtrl-sci])
8. Attention cannot be an Explanation. (arXiv:2201.11194v1 [cs.HC])
9. IMACS: Image Model Attribution Comparison Summaries. (arXiv:2201.11196v1 [cs.LG])
10. Challenges and Opportunities for Machine Learning Classification of Behavior and Mental State from Images. (arXiv:2201.11197v1 [cs.CV])
11. On the Convergence of mSGD and AdaGrad for Stochastic Optimization. (arXiv:2201.11204v1 [cs.LG])
12. Generative Trees: Adversarial and Copycat. (arXiv:2201.11205v1 [cs.LG])
13. Reward-Free RL is No Harder Than Reward-Aware RL in Linear Markov Decision Processes. (arXiv:2201.11206v1 [cs.LG])
14. On The Energy Statistics of Feature Maps in Pruning of Neural Networks with Skip-Connections. (arXiv:2201.11209v1 [cs.LG])
15. Learning Mixtures of Linear Dynamical Systems. (arXiv:2201.11211v1 [stat.ML])
16. Predicting Succinylation Sites in Proteins with Improved Deep Learning Architecture. (arXiv:2201.11215v1 [q-bio.BM])
17. DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for Layer Fusion in DNN Accelerators. (arXiv:2201.11218v1 [cs.LG])
18. Online Change Point Detection for Weighted and Directed Random Dot Product Graphs. (arXiv:2201.11222v1 [cs.LG])
19. Synchromesh: Reliable code generation from pre-trained language models. (arXiv:2201.11227v1 [cs.LG])
20. Objective Prediction of Tomorrow's Affect Using Multi-Modal Physiological Data and Personal Chronicles: A Study of Monitoring College Student Well-being in 2020. (arXiv:2201.11230v1 [cs.HC])
21. Gap Minimization for Knowledge Sharing and Transfer. (arXiv:2201.11231v1 [cs.LG])
22. Heterogeneous Peer Effects in the Linear Threshold Model. (arXiv:2201.11242v1 [cs.SI])
23. Jointly Learning Knowledge Embedding and Neighborhood Consensus with Relational Knowledge Distillation for Entity Alignment. (arXiv:2201.11249v1 [cs.LG])
24. Neuro-Symbolic Entropy Regularization. (arXiv:2201.11250v1 [cs.LG])
25. Reinforcement Learning Based Query Vertex Ordering Model for Subgraph Matching. (arXiv:2201.11251v1 [cs.LG])
26. Semantic Code Classification for Automated Machine Learning. (arXiv:2201.11252v1 [cs.LG])
27. Mapping the Buried Cable by Ground Penetrating Radar and Gaussian-Process Regression. (arXiv:2201.11253v1 [cs.LG])
28. Controlling Directions Orthogonal to a Classifier. (arXiv:2201.11259v1 [cs.LG])
29. To what extent should we trust AI models when they extrapolate?. (arXiv:2201.11260v1 [cs.LG])
30. Stock2Vec: An Embedding to Improve Predictive Models for Companies. (arXiv:2201.11290v1 [cs.LG])
31. Multi-view learning with privileged weighted twin support vector machine. (arXiv:2201.11306v1 [stat.ML])
32. Dissecting the impact of different loss functions with gradient surgery. (arXiv:2201.11307v1 [cs.CV])
33. Towards a Secure and Reliable Federated Learning using Blockchain. (arXiv:2201.11311v1 [cs.CR])
34. Transformer Module Networks for Systematic Generalization in Visual Question Answering. (arXiv:2201.11316v1 [cs.CV])
35. Deep Recurrent Learning for Heart Sounds Segmentation based on Instantaneous Frequency Features. (arXiv:2201.11320v1 [eess.AS])
36. Few-shot Transfer Learning for Holographic Image Reconstruction using a Recurrent Neural Network. (arXiv:2201.11333v1 [eess.IV])
37. Towards Agnostic Feature-based Dynamic Pricing: Linear Policies vs Linear Valuation with Unknown Noise. (arXiv:2201.11341v1 [cs.LG])
38. Distributed gradient-based optimization in the presence of dependent aperiodic communication. (arXiv:2201.11343v1 [math.OC])
39. Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift. (arXiv:2201.11349v1 [cs.LG])
40. Benchmarking learned non-Cartesian k-space trajectories and reconstruction networks. (arXiv:2201.11356v1 [cs.LG])
41. Fairness implications of encoding protected categorical attributes. (arXiv:2201.11358v1 [cs.LG])
42. HYPERLOCK: In-Memory Hyperdimensional Encryption in Memristor Crossbar Array. (arXiv:2201.11362v1 [cs.CR])
43. Achieving Personalized Federated Learning with Sparse Local Models. (arXiv:2201.11380v1 [cs.LG])
44. Multi-Frame Quality **Enhancement** On Compressed Video Using Quantised Data of Deep Belief Networks. (arXiv:2201.11389v1 [eess.IV])
45. Restarted Nonconvex Accelerated Gradient Descent: No More Polylogarithmic Factor in the $O(\epsilon^{-7/4})$ Complexity. (arXiv:2201.11411v1 [math.OC])
46. Fast Moving Natural Evolution Strategy for High-Dimensional Problems. (arXiv:2201.11422v1 [cs.NE])
47. An Analysis on Ensemble Learning optimized Medical Image Classification with Deep Convolutional Neural Networks. (arXiv:2201.11440v1 [cs.CV])
48. Setting AI in context: A case study on defining the context and operational design domain for automated driving. (arXiv:2201.11451v1 [cs.SE])
49. Alleviating the Transit Timing Variations bias in transit surveys. II. RIVERS: Twin resonant Earth-sized planets around Kepler-1972 recovered from Kepler's false positive. (arXiv:2201.11459v1 [astro-ph.EP])
50. Quantile-Based Policy Optimization for Reinforcement Learning. (arXiv:2201.11463v1 [cs.LG])
51. FinGAN: Generative Adversarial Network for Analytical Customer Relationship Management in Banking and Insurance. (arXiv:2201.11486v1 [cs.CE])
52. The Implicit Bias of Benign Overfitting. (arXiv:2201.11489v1 [cs.LG])
53. GraphTune: A Learning-based Graph Generative Model with Tunable Structural Features. (arXiv:2201.11494v1 [cs.LG])
54. From Motion to Muscle. (arXiv:2201.11501v1 [cs.LG])
55. Density-Aware Hyper-Graph Neural Networks for Graph-based Semi-supervised Node Classification. (arXiv:2201.11511v1 [cs.LG])
56. Multimodal neural networks better explain multivoxel patterns in the hippocampus. (arXiv:2201.11517v1 [q-bio.NC])
57. Transfer Portal: Accurately Forecasting the Impact of a Player Transfer in Soccer. (arXiv:2201.11533v1 [cs.LG])
58. Capacity and Achievable Rates of Fading Few-mode MIMO IM/DD Optical Fiber Channels. (arXiv:2201.11538v1 [cs.IT])
59. Human Interpretation of Saliency-based Explanation Over Text. (arXiv:2201.11569v1 [cs.CL])
60. FairMod: Fair Link Prediction and Recommendation via Graph Modification. (arXiv:2201.11596v1 [cs.LG])
61. Domain-Invariant Representation Learning from EEG with Private Encoders. (arXiv:2201.11613v1 [cs.LG])
62. On the Role of Multi-Objective Optimization to the Transit Network Design Problem. (arXiv:2201.11616v1 [cs.LG])
63. Domain generalization in deep learning-based mass detection in mammography: A large-scale multi-center study. (arXiv:2201.11620v1 [cs.CV])
64. LiteLSTM Architecture for Deep Recurrent Neural Networks. (arXiv:2201.11624v1 [cs.LG])
65. Early Detection of Network Attacks Using Deep Learning. (arXiv:2201.11628v1 [cs.CR])
66. Towards Data-driven LQR with KoopmanizingFlows. (arXiv:2201.11640v1 [eess.SY])
67. Bit-serial Weight Pools: Compression and Arbitrary Precision Execution of Neural Networks on Resource Constrained Processors. (arXiv:2201.11651v1 [cs.LG])
68. Representation learnt by SGD and Adaptive learning rules -- Conditions that Vary Sparsity and Selectivity in Neural Network. (arXiv:2201.11653v1 [cs.LG])
69. Model Generalization in Arrival Runway Occupancy Time Prediction by Feature Equivalences. (arXiv:2201.11654v1 [cs.LG])
70. LAGOON: An Analysis Tool for Open Source Communities. (arXiv:2201.11657v1 [cs.SI])
71. TrustAL: Trustworthy Active Learning using Knowledge Distillation. (arXiv:2201.11661v1 [cs.LG])
72. MeltpoolNet: Melt pool Characteristic Prediction in Metal Additive Manufacturing Using Machine Learning. (arXiv:2201.11662v1 [cs.LG])
73. A Machine Learning-based Characterization Framework for Parametric Representation of Nonlinear Sloshing. (arXiv:2201.11663v1 [cs.LG])
74. Team Yao at Factify 2022: Utilizing Pre-trained Models and Co-attention Networks for Multi-Modal Fact Verification. (arXiv:2201.11664v1 [cs.CV])
75. Capture Agent Free Biosensing using Porous Silicon Arrays and Machine Learning. (arXiv:2201.11671v1 [physics.med-ph])
76. Vision Checklist: Towards Testable Error Analysis of Image Models to Help System Designers Interrogate Model Capabilities. (arXiv:2201.11674v1 [cs.CV])
77. Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap. (arXiv:2201.11676v1 [cs.LG])
78. Unsupervised Change Detection using DRE-CUSUM. (arXiv:2201.11678v1 [cs.LG])
79. DropNAS: Grouped Operation Dropout for Differentiable Architecture Search. (arXiv:2201.11679v1 [cs.LG])
80. Generative Adversarial Exploration for Reinforcement Learning. (arXiv:2201.11685v1 [cs.LG])
81. SSLGuard: A Watermarking Scheme for Self-supervised Learning Pre-trained Encoders. (arXiv:2201.11692v1 [cs.CR])
82. Model Agnostic Interpretability for Multiple Instance Learning. (arXiv:2201.11701v1 [cs.LG])
83. A Systematic Study of Bias Amplification. (arXiv:2201.11706v1 [cs.LG])
84. Simplicial Convolutional Filters. (arXiv:2201.11720v1 [eess.SP])
85. Reinforced Cooperative Load Balancing in Data Center. (arXiv:2201.11727v1 [cs.DC])
86. Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks. (arXiv:2201.11729v1 [cs.LG])
87. Robust Augmentation for Multivariate Time Series Classification. (arXiv:2201.11739v1 [cs.LG])
88. Time Limits in Reinforcement Learning. (arXiv:1712.00378v4 [cs.LG] UPDATED)
89. Analysis and algorithms for $\ell_p$-based semi-supervised learning on graphs. (arXiv:1901.05031v4 [math.NA] UPDATED)
90. Scalable Spike Source Localization in Extracellular Recordings using Amortized Variational Inference. (arXiv:1905.12375v4 [q-bio.NC] UPDATED)
91. Likelihood Contribution based Multi-scale Architecture for Generative Flows. (arXiv:1908.01686v3 [cs.LG] UPDATED)
92. Stochastic First-order Methods for Convex and Nonconvex Functional Constrained Optimization. (arXiv:1908.02734v4 [math.OC] UPDATED)
93. Learning Constrained Adaptive Differentiable Predictive Control Policies With Guarantees. (arXiv:2004.11184v6 [eess.SY] UPDATED)
94. Improved Complexities for Stochastic Conditional Gradient Methods under Interpolation-like Conditions. (arXiv:2006.08167v2 [math.OC] UPDATED)
95. Logic of Machine Learning. (arXiv:2006.09500v4 [cs.LG] UPDATED)
96. Generating Adjacency Matrix for Video Relocalization. (arXiv:2008.08977v2 [cs.CV] UPDATED)
97. Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
98. MQTransformer: Multi-Horizon Forecasts with Context Dependent and Feedback-Aware Attention. (arXiv:2009.14799v4 [cs.LG] UPDATED)
99. Distributed Proximal Splitting Algorithms with Rates and Acceleration. (arXiv:2010.00952v3 [math.OC] UPDATED)
100. Can we Generalize and Distribute Private Representation Learning?. (arXiv:2010.01792v4 [cs.LG] UPDATED)
101. Generalized Matrix Factorization: efficient algorithms for fitting generalized linear latent variable models to large data arrays. (arXiv:2010.02469v3 [cs.LG] UPDATED)
102. MixMix: All You Need for Data-Free Compression Are Feature and Data Mixing. (arXiv:2011.09899v3 [cs.LG] UPDATED)
103. Spectral Analysis and Fixed Point Stability of Deep Neural Dynamics. (arXiv:2011.13492v2 [cs.LG] UPDATED)
104. Learning Non-linear Wavelet Transformation via Normalizing Flow. (arXiv:2101.11306v2 [cs.LG] UPDATED)
105. Exploring the Geometry and Topology of Neural Network Loss Landscapes. (arXiv:2102.00485v2 [cs.LG] UPDATED)
106. Advanced Stationary and Non-Stationary Kernel Designs for Domain-Aware Gaussian Processes. (arXiv:2102.03432v3 [stat.ML] UPDATED)
107. Emojis predict dropouts of remote workers: An empirical study of emoji usage on GitHub. (arXiv:2102.05737v2 [cs.LG] UPDATED)
108. COMBO: Conservative Offline Model-Based Policy Optimization. (arXiv:2102.08363v2 [cs.LG] UPDATED)
109. Data-Aware Device Scheduling for Federated Edge Learning. (arXiv:2102.09491v2 [cs.DC] UPDATED)
110. PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains. (arXiv:2102.12206v4 [cs.CL] UPDATED)
111. Monotonic Alpha-divergence Minimisation for Variational Inference. (arXiv:2103.05684v2 [stat.CO] UPDATED)
112. Graph Attention Networks for Channel Estimation in RIS-assisted Satellite IoT Communications. (arXiv:2104.00735v2 [cs.NI] UPDATED)
113. Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx. (arXiv:2104.05522v5 [cs.LG] UPDATED)
114. Temporal Prediction and Evaluation of Brassica Growth in the Field using Conditional Generative Adversarial Networks. (arXiv:2105.07789v2 [cs.CV] UPDATED)
115. Mutual Distillation of Confident Knowledge. (arXiv:2106.01489v2 [cs.LG] UPDATED)
116. As easy as APC: overcoming missing data and class imbalance in time series with self-supervised learning. (arXiv:2106.15577v5 [cs.LG] UPDATED)
117. Greedy structure learning from data that contains systematic missing values. (arXiv:2107.04184v2 [cs.LG] UPDATED)
118. Implicit Regularization of Bregman Proximal Point Algorithm and Mirror Descent on Separable Data. (arXiv:2108.06808v3 [cs.LG] UPDATED)
119. Construction Cost Index Forecasting: A Multi-feature Fusion Approach. (arXiv:2108.10155v4 [cs.LG] UPDATED)
120. Consistent Relative Confidence and Label-Free Model Selection for Convolutional Neural Networks. (arXiv:2108.11845v4 [cs.CV] UPDATED)
121. Optimal transport weights for causal inference. (arXiv:2109.01991v3 [stat.ME] UPDATED)
122. Exploration in Deep Reinforcement Learning: A Comprehensive Survey. (arXiv:2109.06668v3 [cs.AI] UPDATED)
123. Learning to Aggregate and Refine Noisy Labels for Visual Sentiment Analysis. (arXiv:2109.07509v2 [cs.CV] UPDATED)
124. Information-Theoretic Characterization of the Generalization Error for Iterative Semi-Supervised Learning. (arXiv:2110.00926v3 [cs.LG] UPDATED)
125. FOD-A: A Dataset for Foreign Object Debris in Airports. (arXiv:2110.03072v2 [cs.CV] UPDATED)
126. Multi-View Self-Attention Based Transformer for Speaker Recognition. (arXiv:2110.05036v2 [eess.AS] UPDATED)
127. OneFlow: Redesign the Distributed Deep Learning Framework from Scratch. (arXiv:2110.15032v3 [cs.DC] UPDATED)
128. Generalized Radiograph Representation Learning via Cross-supervision between Images and Free-text Radiology Reports. (arXiv:2111.03452v2 [eess.IV] UPDATED)
129. Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods. (arXiv:2111.03941v6 [cs.LG] UPDATED)
130. CSI Clustering with Variational Autoencoding. (arXiv:2111.09758v2 [eess.SP] UPDATED)
131. Scalable Learning for Optimal Load Shedding Under Power Grid Emergency Operations. (arXiv:2111.11980v2 [cs.LG] UPDATED)
132. Critical Initialization of Wide and Deep Neural Networks through Partial Jacobians: General Theory and Applications. (arXiv:2111.12143v3 [cs.LG] UPDATED)
133. A Quantum-like Model for Predicting Human Decisions in the Entangled Social Systems. (arXiv:2111.13902v2 [physics.soc-ph] UPDATED)
134. First-Order Regret in Reinforcement Learning with Linear Function Approximation: A Robust Estimation Approach. (arXiv:2112.03432v2 [cs.LG] UPDATED)
135. ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling. (arXiv:2201.01337v2 [cs.CL] UPDATED)
136. Mirror Learning: A Unifying Framework of Policy Optimisation. (arXiv:2201.02373v4 [cs.LG] UPDATED)
137. Optimizing Prediction of MGMT Promoter Methylation from MRI Scans using Adversarial Learning. (arXiv:2201.04416v2 [eess.IV] UPDATED)
138. The Recurrent Reinforcement Learning Crypto Agent. (arXiv:2201.04699v2 [cs.LG] UPDATED)
139. Using Computational Intelligence for solving the Ornstein-Zernike equation. (arXiv:2201.05089v2 [cond-mat.soft] UPDATED)
140. Unsupervised Graph Poisoning Attack via Contrastive Loss Back-propagation. (arXiv:2201.07986v3 [cs.LG] UPDATED)
141. Deep Learning-Accelerated 3D Carbon Storage Reservoir Pressure Forecasting Based on Data Assimilation Using Surface Displacement from InSAR. (arXiv:2201.08543v2 [stat.ML] UPDATED)
142. Multi-Agent Adversarial Attacks for Multi-Channel Communications. (arXiv:2201.09149v2 [cs.MA] UPDATED)
143. Differential Geometry in Neural Implicits. (arXiv:2201.09263v2 [cs.GR] UPDATED)
144. Investigating Expressiveness of Transformer in Spectral Domain for Graphs. (arXiv:2201.09332v2 [cs.LG] UPDATED)
145. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v3 [cs.LG] UPDATED)
146. Neural Implicit Surfaces in Higher Dimension. (arXiv:2201.09636v2 [cs.LG] UPDATED)
147. Sparsity Regularization For Cold-Start Recommendation. (arXiv:2201.10711v2 [cs.IR] UPDATED)
148. Exploiting Semantic Epsilon Greedy Exploration Strategy in Multi-Agent Reinforcement Learning. (arXiv:2201.10803v2 [cs.LG] UPDATED)
149. Combining optimal path search with task-dependent learning in a neural network. (arXiv:2201.11104v2 [cs.LG] UPDATED)
150. MALTS: Matching After Learning to Stretch. (arXiv:1811.07415v6 [stat.ME] CROSS LISTED)
151. Multi-Attribute Balanced Sampling for Disentangled GAN Controls. (arXiv:2111.00909v2 [cs.LG] CROSS LISTED)
## cs.AI
---
**80** new papers in cs.AI:-) 
1. Inference-optimized AI and high performance computing for gravitational wave detection at scale. (arXiv:2201.11133v1 [gr-qc])
2. Explainable Patterns for Distinction and Prediction of Moral Judgement on Reddit. (arXiv:2201.11155v1 [cs.CL])
3. First-Order Context-Specific Likelihood Weighting in Hybrid Probabilistic Logic Programs. (arXiv:2201.11165v1 [cs.AI])
4. DNNFuser: Generative Pre-Trained Transformer as a Generalized Mapper for Layer Fusion in DNN Accelerators. (arXiv:2201.11218v1 [cs.LG])
5. DiGamma: Domain-aware Genetic Algorithm for HW-Mapping Co-optimization for DNN Accelerators. (arXiv:2201.11220v1 [cs.NE])
6. Gap Minimization for Knowledge Sharing and Transfer. (arXiv:2201.11231v1 [cs.LG])
7. Diagnosing AI Explanation Methods with Folk Concepts of Behavior. (arXiv:2201.11239v1 [cs.AI])
8. Jointly Learning Knowledge Embedding and Neighborhood Consensus with Relational Knowledge Distillation for Entity Alignment. (arXiv:2201.11249v1 [cs.LG])
9. Neuro-Symbolic Entropy Regularization. (arXiv:2201.11250v1 [cs.LG])
10. Reinforcement Learning Based Query Vertex Ordering Model for Subgraph Matching. (arXiv:2201.11251v1 [cs.LG])
11. Semantic Code Classification for Automated Machine Learning. (arXiv:2201.11252v1 [cs.LG])
12. Mapping the Buried Cable by Ground Penetrating Radar and Gaussian-Process Regression. (arXiv:2201.11253v1 [cs.LG])
13. To what extent should we trust AI models when they extrapolate?. (arXiv:2201.11260v1 [cs.LG])
14. Dissecting the impact of different loss functions with gradient surgery. (arXiv:2201.11307v1 [cs.CV])
15. Towards a Secure and Reliable Federated Learning using Blockchain. (arXiv:2201.11311v1 [cs.CR])
16. Dynamic Rectification Knowledge Distillation. (arXiv:2201.11319v1 [cs.CV])
17. Epistemic AI platform accelerates innovation by connecting biomedical knowledge. (arXiv:2201.11331v1 [cs.AI])
18. Smart City Defense Game: Strategic Resource Management during Socio-Cyber-Physical Attacks. (arXiv:2201.11342v1 [cs.GT])
19. Exploring Global Diversity and Local Context for Video Summarization. (arXiv:2201.11345v1 [cs.CV])
20. Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift. (arXiv:2201.11349v1 [cs.LG])
21. Effective Shortcut Technique for GAN. (arXiv:2201.11351v1 [cs.CV])
22. Achieving Personalized Federated Learning with Sparse Local Models. (arXiv:2201.11380v1 [cs.LG])
23. Contrastive Embedding Distribution Refinement and Entropy-Aware Attention for 3D Point Cloud Classification. (arXiv:2201.11388v1 [cs.CV])
24. The MSXF TTS System for ICASSP 2022 ADD Challenge. (arXiv:2201.11400v1 [cs.SD])
25. Online Planning in POMDPs with Self-Improving Simulators. (arXiv:2201.11404v1 [cs.AI])
26. Non-linear Motion Estimation for Video Frame Interpolation using Space-time Convolutions. (arXiv:2201.11407v1 [cs.CV])
27. Reinforcement Learning-Empowered Mobile Edge Computing for 6G Edge Intelligence. (arXiv:2201.11410v1 [cs.IT])
28. An Analysis on Ensemble Learning optimized Medical Image Classification with Deep Convolutional Neural Networks. (arXiv:2201.11440v1 [cs.CV])
29. Human-centered mechanism design with Democratic AI. (arXiv:2201.11441v1 [cs.AI])
30. Quantile-Based Policy Optimization for Reinforcement Learning. (arXiv:2201.11463v1 [cs.LG])
31. Reasoning Like Program Executors. (arXiv:2201.11473v1 [cs.CL])
32. Eye-focused Detection of Bell's Palsy in Videos. (arXiv:2201.11479v1 [cs.CV])
33. Human Interpretation of Saliency-based Explanation Over Text. (arXiv:2201.11569v1 [cs.CL])
34. Grad2Task: Improved Few-shot Text Classification Using Gradients for Task Representation. (arXiv:2201.11576v1 [cs.CL])
35. DecisionHoldem: Safe Depth-Limited Solving With Diverse Opponents for Imperfect-Information Games. (arXiv:2201.11580v1 [cs.AI])
36. A Probabilistic Framework for Dynamic Object Recognition in 3D Environment With A Novel Continuous Ground Estimation Method. (arXiv:2201.11608v1 [cs.CV])
37. On the Role of Multi-Objective Optimization to the Transit Network Design Problem. (arXiv:2201.11616v1 [cs.LG])
38. Domain generalization in deep learning-based mass detection in mammography: A large-scale multi-center study. (arXiv:2201.11620v1 [cs.CV])
39. LiteLSTM Architecture for Deep Recurrent Neural Networks. (arXiv:2201.11624v1 [cs.LG])
40. Internal language model estimation through explicit context vector learning for attention-based encoder-decoder ASR. (arXiv:2201.11627v1 [eess.AS])
41. Deep Video Prior for Video Consistency and Propagation. (arXiv:2201.11632v1 [cs.CV])
42. Incremental Mining of Frequent Serial Episodes Considering Multiple Occurrence. (arXiv:2201.11650v1 [cs.DB])
43. Model Generalization in Arrival Runway Occupancy Time Prediction by Feature Equivalences. (arXiv:2201.11654v1 [cs.LG])
44. TrustAL: Trustworthy Active Learning using Knowledge Distillation. (arXiv:2201.11661v1 [cs.LG])
45. MeltpoolNet: Melt pool Characteristic Prediction in Metal Additive Manufacturing Using Machine Learning. (arXiv:2201.11662v1 [cs.LG])
46. Team Yao at Factify 2022: Utilizing Pre-trained Models and Co-attention Networks for Multi-Modal Fact Verification. (arXiv:2201.11664v1 [cs.CV])
47. Learning Stance Embeddings from Signed Social Graphs. (arXiv:2201.11675v1 [cs.SI])
48. Generative Adversarial Exploration for Reinforcement Learning. (arXiv:2201.11685v1 [cs.LG])
49. Recursive Binding for Similarity-Preserving Hypervector Representations of Sequences. (arXiv:2201.11691v1 [cs.AI])
50. Constrained Structure Learning for Scene Graph Generation. (arXiv:2201.11697v1 [cs.CV])
51. Model Agnostic Interpretability for Multiple Instance Learning. (arXiv:2201.11701v1 [cs.LG])
52. Search Trajectories Networks of Multiobjective Evolutionary Algorithms. (arXiv:2201.11726v1 [cs.NE])
53. Implicit Regularization in Hierarchical Tensor Factorization and Deep Convolutional Neural Networks. (arXiv:2201.11729v1 [cs.LG])
54. Image Colorization: A Survey and Dataset. (arXiv:2008.10774v3 [cs.CV] UPDATED)
55. Federated Edge Learning : Design Issues and Challenges. (arXiv:2009.00081v2 [cs.DC] UPDATED)
56. Learning Non-linear Wavelet Transformation via Normalizing Flow. (arXiv:2101.11306v2 [cs.LG] UPDATED)
57. COMBO: Conservative Offline Model-Based Policy Optimization. (arXiv:2102.08363v2 [cs.LG] UPDATED)
58. PADA: Example-based Prompt Learning for on-the-fly Adaptation to Unseen Domains. (arXiv:2102.12206v4 [cs.CL] UPDATED)
59. Show Me What You Can Do: Capability Calibration on Reachable Workspace for Human-Robot Collaboration. (arXiv:2103.04077v3 [cs.RO] UPDATED)
60. Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx. (arXiv:2104.05522v5 [cs.LG] UPDATED)
61. MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple Accelerator Cores. (arXiv:2104.13997v3 [cs.AR] UPDATED)
62. The effectiveness of feature attribution methods and its correlation with automatic evaluation scores. (arXiv:2105.14944v4 [cs.CV] UPDATED)
63. Mutual Distillation of Confident Knowledge. (arXiv:2106.01489v2 [cs.LG] UPDATED)
64. As easy as APC: overcoming missing data and class imbalance in time series with self-supervised learning. (arXiv:2106.15577v5 [cs.LG] UPDATED)
65. Exploration in Deep Reinforcement Learning: A Comprehensive Survey. (arXiv:2109.06668v3 [cs.AI] UPDATED)
66. MPC-Friendly Commitments for Publicly Verifiable Covert Security. (arXiv:2109.07461v2 [cs.CR] UPDATED)
67. Multi-View Self-Attention Based Transformer for Speaker Recognition. (arXiv:2110.05036v2 [eess.AS] UPDATED)
68. Representing Matrices Using Algebraic ZX-calculus. (arXiv:2110.06898v2 [quant-ph] UPDATED)
69. Effects of Different Optimization Formulations in Evolutionary Reinforcement Learning on Diverse Behavior Generation. (arXiv:2110.08122v3 [cs.NE] UPDATED)
70. OneFlow: Redesign the Distributed Deep Learning Framework from Scratch. (arXiv:2110.15032v3 [cs.DC] UPDATED)
71. Automating Public Announcement Logic with Relativized Common Knowledge as a Fragment of HOL in LogiKEy. (arXiv:2111.01654v3 [cs.AI] UPDATED)
72. Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods. (arXiv:2111.03941v6 [cs.LG] UPDATED)
73. Few-shot Multi-hop Question Answering over Knowledge Base. (arXiv:2112.11909v2 [cs.CL] UPDATED)
74. ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling. (arXiv:2201.01337v2 [cs.CL] UPDATED)
75. Mirror Learning: A Unifying Framework of Policy Optimisation. (arXiv:2201.02373v4 [cs.LG] UPDATED)
76. Homotopic Policy Mirror Descent: Policy Convergence, Implicit Regularization, and Improved Sample Complexity. (arXiv:2201.09457v3 [cs.LG] UPDATED)
77. Exploiting Semantic Epsilon Greedy Exploration Strategy in Multi-Agent Reinforcement Learning. (arXiv:2201.10803v2 [cs.LG] UPDATED)
78. How Robust are Discriminatively Trained Zero-Shot Learning Models?. (arXiv:2201.10972v2 [cs.CV] UPDATED)
79. Combining optimal path search with task-dependent learning in a neural network. (arXiv:2201.11104v2 [cs.LG] UPDATED)
80. Multi-Attribute Balanced Sampling for Disentangled GAN Controls. (arXiv:2111.00909v2 [cs.LG] CROSS LISTED)

