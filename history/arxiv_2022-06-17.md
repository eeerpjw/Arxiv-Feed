# Your interest papers
---
## cs.CV
---
### PeQuENet: Perceptual Quality **Enhancement** of Compressed Video with Adaptation- and Attention-based Network. (arXiv:2206.07893v1 [cs.CV])
- Authors : Saiping Zhang, Luis Herranz, Marta Mrak, Marc Gorriz, Shuai Wan, Fuzheng Yang
- Link : [http://arxiv.org/abs/2206.07893](http://arxiv.org/abs/2206.07893)
> ABSTRACT  :  In this paper we propose a generative adversarial network (GAN) framework to enhance the perceptual quality of compressed videos. Our framework includes attention and adaptation to different quantization parameters (QPs) in a single model. The attention module exploits global receptive fields that can capture and align long-range correlations between consecutive frames, which can be beneficial for enhancing perceptual quality of videos. The frame to be enhanced is fed into the deep network together with its neighboring frames, and in the first stage features at different depths are extracted. Then extracted features are fed into attention blocks to explore global temporal correlations, followed by a series of upsampling and convolution layers. Finally, the resulting features are processed by the QP-conditional adaptation module which leverages the corresponding QP information. In this way, a single model can be used to enhance adaptively to various QPs without requiring multiple models specific for every QP value, while having similar performance. Experimental results demonstrate the superior performance of the proposed PeQuENet compared with the state-of-the-art compressed video quality **enhancement** algorithms.  
### Longitudinal detection of new MS lesions using Deep Learning. (arXiv:2206.08272v1 [eess.IV])
- Authors : Reda Abdellah, Boris Mansencal, Pierrick Coup
- Link : [http://arxiv.org/abs/2206.08272](http://arxiv.org/abs/2206.08272)
> ABSTRACT  :  The detection of new multiple sclerosis (MS) lesions is an important marker of the evolution of the disease. The applicability of learning-based methods could automate this task efficiently. However, the lack of annotated longitudinal data with new-appearing lesions is a limiting factor for the training of robust and generalizing models. In this work, we describe a deep-learning-based pipeline addressing the challenging task of detecting and segmenting new MS lesions. First, we propose to use transfer-learning from a model trained on a segmentation task using single time-points. Therefore, we exploit knowledge from an easier task and for which more annotated datasets are available. Second, we propose a data synthesis strategy to generate realistic longitudinal time-points with new lesions using single time-point scans. In this way, we pretrain our detection model on large synthetic annotated datasets. Finally, we use a data-augmentation technique designed to simulate data diversity in MRI. By doing that, we increase the size of the available small annotated longitudinal datasets. Our ablation study showed that each contribution lead to an **enhancement** of the segmentation accuracy. Using the proposed pipeline, we obtained the best score for the segmentation and the detection of new MS lesions in the MSSEG2 MICCAI challenge.  
### Boosting the Adversarial Transferability of Surrogate Model with **Dark** Knowledge. (arXiv:2206.08316v1 [cs.LG])
- Authors : Dingcheng Yang, Zihao Xiao, Wenjian Yu
- Link : [http://arxiv.org/abs/2206.08316](http://arxiv.org/abs/2206.08316)
> ABSTRACT  :  Deep neural networks (DNNs) for image classification are known to be vulnerable to adversarial examples. And, the adversarial examples have transferability, which means an adversarial example for a DNN model can fool another black-box model with a non-trivial probability. This gave birth of the transfer-based adversarial attack where the adversarial examples generated by a pretrained or known model (called surrogate model) are used to conduct black-box attack. There are some work on how to generate the adversarial examples from a given surrogate model to achieve better transferability. However, training a special surrogate model to generate adversarial examples with better transferability is relatively under-explored. In this paper, we propose a method of training a surrogate model with abundant **dark** knowledge to boost the adversarial transferability of the adversarial examples generated by the surrogate model. This trained surrogate model is named **dark** surrogate model (DSM), and the proposed method to train DSM consists of two key components: a teacher model extracting **dark** knowledge and providing soft labels, and the mixing augmentation skill which enhances the **dark** knowledge of training data. Extensive experiments have been conducted to show that the proposed method can substantially improve the adversarial transferability of surrogate model across different architectures of surrogate model and optimizers for generating adversarial examples. We also show that the proposed method can be applied to other scenarios of transfer-based attack that contain **dark** knowledge, like face verification.  
### FWD: **Real-time** Novel View Synthesis with Forward Warping and Depth. (arXiv:2206.08355v1 [cs.CV])
- Authors : Ang Cao, Chris Rockwell, Justin Johnson
- Link : [http://arxiv.org/abs/2206.08355](http://arxiv.org/abs/2206.08355)
> ABSTRACT  :  Novel view synthesis (NVS) is a challenging task requiring systems to generate photorealistic images of scenes from new viewpoints, where both quality and speed are important for applications. Previous image-based rendering (IBR) methods are fast, but have poor quality when input views are sparse. Recent Neural Radiance Fields (**NeRF**) and generalizable variants give impressive results but are not real-time. In our paper, we propose a generalizable NVS method with sparse inputs, called FWD, which gives high-quality synthesis in real-time. With explicit depth and differentiable rendering, it achieves competitive results to the SOTA methods with 130-1000x speedup and better perceptual quality. If available, we can seamlessly integrate sensor depth during either training or inference to improve image quality while retaining real-time speed. With the growing prevalence of depths sensors, we hope that methods making use of depth will become increasingly useful.  
### Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields. (arXiv:2206.08361v1 [cs.CV])
- Authors : Keqiang Sun, Shangzhe Wu, Zhaoyang Huang, Ning Zhang, Quan Wang, HongSheng Li
- Link : [http://arxiv.org/abs/2206.08361](http://arxiv.org/abs/2206.08361)
> ABSTRACT  :  Capitalizing on the recent advances in image generation models, existing controllable face image synthesis methods are able to generate high-fidelity images with some levels of controllability, e.g., controlling the shapes, expressions, textures, and poses of the generated face images. However, these methods focus on 2D image generative models, which are prone to producing inconsistent face images under large expression and pose changes. In this paper, we propose a new **NeRF**-based conditional 3D face synthesis framework, which enables 3D controllability over the generated face images by imposing explicit 3D conditions from 3D face priors. At its core is a conditional Generative Occupancy Field (cGOF) that effectively enforces the shape of the generated face to commit to a given 3D Morphable Model (3DMM) mesh. To achieve accurate control over fine-grained 3D face shapes of the synthesized image, we additionally incorporate a 3D landmark loss as well as a volume warping loss into our synthesis algorithm. Experiments validate the effectiveness of the proposed method, which is able to generate high-fidelity face images and shows more precise 3D controllability than state-of-the-art 2D-based controllable face synthesis methods. Find code and demo at https://keqiangsun.github.io/projects/cgof.  
### Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model. (arXiv:2206.08368v1 [cs.CV])
- Authors : Marc Habermann, Soshi Shimada, Vladislav Golyanik, Christian Theobalt
- Link : [http://arxiv.org/abs/2206.08368](http://arxiv.org/abs/2206.08368)
> ABSTRACT  :  Capturing general deforming scenes is crucial for many computer graphics and vision applications, and it is especially challenging when only a monocular RGB video of the scene is available. Competing methods assume dense point tracks, 3D templates, large-scale training datasets, or only capture small-scale deformations. In contrast to those, our method, Ub4D, makes none of these assumptions while outperforming the previous state of the art in challenging scenarios. Our technique includes two new, in the context of non-rigid 3D reconstruction, components, i.e., 1) A coordinate-based and **implicit neural representation** for non-rigid scenes, which enables an unbiased reconstruction of dynamic scenes, and 2) A novel dynamic scene flow loss, which enables the reconstruction of larger deformations. Results on our new dataset, which will be made publicly available, demonstrate the clear improvement over the state of the art in terms of surface reconstruction accuracy and robustness to large deformations. Visit the project page https://4dqv.mpi-inf.mpg.de/Ub4D/.  
### Mutual Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.09960v3 [cs.CV] UPDATED)
- Authors : Yicheng Wu, Zongyuan Ge, Donghao Zhang, Minfeng Xu, **Lei Zhang**, Yong Xia, Jianfei Cai
- Link : [http://arxiv.org/abs/2109.09960](http://arxiv.org/abs/2109.09960)
> ABSTRACT  :  In this paper, we propose a novel mutual consistency network (MC-Net+) to effectively exploit the unlabeled data for semi-supervised medical image segmentation. The MC-Net+ model is motivated by the observation that deep models trained with limited annotations are prone to output highly uncertain and easily mis-classified predictions in the ambiguous regions (e.g., adhesive edges or thin branches) for medical image segmentation. Leveraging these challenging samples can make the semi-supervised segmentation model training more effective. Therefore, our proposed MC-Net+ model consists of two new designs. First, the model contains one shared encoder and multiple slightly different decoders (i.e., using different up-sampling strategies). The statistical discrepancy of multiple decoders' outputs is computed to denote the model's uncertainty, which indicates the unlabeled hard regions. Second, we apply a novel mutual consistency constraint between one decoder's probability output and other decoders' soft pseudo labels. In this way, we minimize the discrepancy of multiple outputs (i.e., the model uncertainty) during training and force the model to generate invariant results in such challenging regions, aiming at regularizing the model training. We compared the segmentation results of our MC-Net+ model with five state-of-the-art semi-supervised approaches on three public medical datasets. Extension experiments with two standard semi-supervised settings demonstrate the superior performance of our model over other methods, which sets a new state of the art for semi-supervised medical image segmentation. Our code is released publicly at https://github.com/ycwu1997/MC-Net.  
### Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion **Enhancement**. (arXiv:2205.03569v3 [cs.CV] UPDATED)
- Authors : Bing Li, Jiaxin Chen, Dongming Zhang, Xiuguo Bao, Di Huang
- Link : [http://arxiv.org/abs/2205.03569](http://arxiv.org/abs/2205.03569)
> ABSTRACT  :  Compressed video action recognition has recently drawn growing attention, since it remarkably reduces the storage and computational cost via replacing raw videos by sparsely sampled RGB frames and compressed motion cues (e.g., motion vectors and residuals). However, this task severely suffers from the coarse and noisy dynamics and the insufficient fusion of the heterogeneous RGB and motion modalities. To address the two issues above, this paper proposes a novel framework, namely Attentive Cross-modal Interaction Network with Motion **Enhancement** (MEACI-Net). It follows the two-stream architecture, i.e. one for the RGB modality and the other for the motion modality. Particularly, the motion stream employs a multi-scale block embedded with a denoising module to enhance representation learning. The interaction between the two streams is then strengthened by introducing the Selective Motion Complement (SMC) and Cross-Modality Augment (CMA) modules, where SMC complements the RGB modality with spatio-temporally attentive local motion features and CMA further combines the two modalities with selective feature augmentation. Extensive experiments on the UCF-101, HMDB-51 and Kinetics-400 benchmarks demonstrate the effectiveness and efficiency of MEACI-Net.  
### Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video **Restoration**. (arXiv:2205.10195v2 [cs.CV] UPDATED)
- Authors : Jing Lin, Xiaowan Hu, Yuanhao Cai, Haoqian Wang, Youliang Yan, Xueyi Zou, Yulun Zhang, Luc Van
- Link : [http://arxiv.org/abs/2205.10195](http://arxiv.org/abs/2205.10195)
> ABSTRACT  :  How to properly model the inter-frame relation within the video sequence is an important but unsolved challenge for video **restoration** (VR). In this work, we propose an unsupervised flow-aligned sequence-to-sequence model (S2SVR) to address this problem. On the one hand, the sequence-to-sequence model, which has proven capable of sequence modeling in the field of natural language processing, is explored for the first time in VR. Optimized serialization modeling shows potential in capturing long-range dependencies among frames. On the other hand, we equip the sequence-to-sequence model with an unsupervised optical flow estimator to maximize its potential. The flow estimator is trained with our proposed unsupervised distillation loss, which can alleviate the data discrepancy and inaccurate degraded optical flow issues of previous flow-based methods. With reliable optical flow, we can establish accurate correspondence among multiple frames, narrowing the domain difference between 1D language and 2D misaligned frames and improving the potential of the sequence-to-sequence model. S2SVR shows superior performance in multiple VR tasks, including video deblurring, video super-resolution, and compressed video quality **enhancement**. Code and models are publicly available at https://github.com/linjing7/VR-Baseline  
### S$^2$-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v2 [cs.CV] UPDATED)
- Authors : Chenhui Yang, Chenxi Huang, Tewodros Legesse, Xin Hong
- Link : [http://arxiv.org/abs/2206.07298](http://arxiv.org/abs/2206.07298)
> ABSTRACT  :  Modern high-performance semantic segmentation methods employ a heavy backbone and dilated convolution to extract the relevant feature. Although extracting features with both contextual and semantic information is critical for the segmentation tasks, it brings a memory footprint and high computation cost for real-time applications. This paper presents a new model to achieve a trade-off between accuracy/speed for real-time road scene semantic segmentation. Specifically, we proposed a lightweight model named Scale-aware Strip Attention Guided Feature Pyramid Network (S$^2$-FPN). Our network consists of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts an attention mechanisms to learn discriminative multi-scale features and help close the semantic gap between different levels. APF uses the scale-aware attention to encode global context with vertical stripping operation and models the long-range dependencies, which helps relate pixels with similar semantic label. In addition, APF employs channel-wise reweighting block (CRB) to emphasize the channel features. Finally, the decoder of S$^2$-FPN then adopts GFU, which is used to fuse features from APF and the encoder. Extensive experiments have been conducted on two challenging semantic segmentation benchmarks, which demonstrate that our approach achieves better accuracy/speed trade-off with different model settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS, 77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and 69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this work will be made available at \url{https://github.com/mohamedac29/S2-FPN  
## eess.IV
---
### PeQuENet: Perceptual Quality **Enhancement** of Compressed Video with Adaptation- and Attention-based Network. (arXiv:2206.07893v1 [cs.CV])
- Authors : Saiping Zhang, Luis Herranz, Marta Mrak, Marc Gorriz, Shuai Wan, Fuzheng Yang
- Link : [http://arxiv.org/abs/2206.07893](http://arxiv.org/abs/2206.07893)
> ABSTRACT  :  In this paper we propose a generative adversarial network (GAN) framework to enhance the perceptual quality of compressed videos. Our framework includes attention and adaptation to different quantization parameters (QPs) in a single model. The attention module exploits global receptive fields that can capture and align long-range correlations between consecutive frames, which can be beneficial for enhancing perceptual quality of videos. The frame to be enhanced is fed into the deep network together with its neighboring frames, and in the first stage features at different depths are extracted. Then extracted features are fed into attention blocks to explore global temporal correlations, followed by a series of upsampling and convolution layers. Finally, the resulting features are processed by the QP-conditional adaptation module which leverages the corresponding QP information. In this way, a single model can be used to enhance adaptively to various QPs without requiring multiple models specific for every QP value, while having similar performance. Experimental results demonstrate the superior performance of the proposed PeQuENet compared with the state-of-the-art compressed video quality **enhancement** algorithms.  
### Longitudinal detection of new MS lesions using Deep Learning. (arXiv:2206.08272v1 [eess.IV])
- Authors : Reda Abdellah, Boris Mansencal, Pierrick Coup
- Link : [http://arxiv.org/abs/2206.08272](http://arxiv.org/abs/2206.08272)
> ABSTRACT  :  The detection of new multiple sclerosis (MS) lesions is an important marker of the evolution of the disease. The applicability of learning-based methods could automate this task efficiently. However, the lack of annotated longitudinal data with new-appearing lesions is a limiting factor for the training of robust and generalizing models. In this work, we describe a deep-learning-based pipeline addressing the challenging task of detecting and segmenting new MS lesions. First, we propose to use transfer-learning from a model trained on a segmentation task using single time-points. Therefore, we exploit knowledge from an easier task and for which more annotated datasets are available. Second, we propose a data synthesis strategy to generate realistic longitudinal time-points with new lesions using single time-point scans. In this way, we pretrain our detection model on large synthetic annotated datasets. Finally, we use a data-augmentation technique designed to simulate data diversity in MRI. By doing that, we increase the size of the available small annotated longitudinal datasets. Our ablation study showed that each contribution lead to an **enhancement** of the segmentation accuracy. Using the proposed pipeline, we obtained the best score for the segmentation and the detection of new MS lesions in the MSSEG2 MICCAI challenge.  
## cs.LG
---
### EPG2S: Speech Generation and Speech **Enhancement** based on Electropalatography and Audio Signals using Multimodal Learning. (arXiv:2206.07860v1 [cs.SD])
- Authors : Chin Chen, Hsun Chen, Richard Tzong, Han Tsai, Yu Tsao
- Link : [http://arxiv.org/abs/2206.07860](http://arxiv.org/abs/2206.07860)
> ABSTRACT  :  Speech generation and **enhancement** based on articulatory movements facilitate communication when the scope of verbal communication is absent, e.g., in patients who have lost the ability to speak. Although various techniques have been proposed to this end, electropalatography (EPG), which is a monitoring technique that records contact between the tongue and hard palate during speech, has not been adequately explored. Herein, we propose a novel multimodal EPG-to-speech (EPG2S) system that utilizes EPG and speech signals for speech generation and **enhancement**. Different fusion strategies based on multiple combinations of EPG and noisy speech signals are examined, and the viability of the proposed method is investigated. Experimental results indicate that EPG2S achieves desirable speech generation outcomes based solely on EPG signals. Further, the addition of noisy speech signals is observed to improve quality and intelligibility. Additionally, EPG2S is observed to achieve high-quality speech **enhancement** based solely on audio signals, with the addition of EPG signals further improving the performance. The late fusion strategy is deemed to be the most effective approach for simultaneous speech generation and **enhancement**.  
### Challenges and Opportunities in Deep Reinforcement Learning with Graph Neural Networks: A Comprehensive review of Algorithms and Applications. (arXiv:2206.07922v1 [cs.LG])
- Authors : Sai Munikoti, Deepesh Agarwal, Laya Das, Mahantesh Halappanavar, Balasubramaniam Natarajan
- Link : [http://arxiv.org/abs/2206.07922](http://arxiv.org/abs/2206.07922)
> ABSTRACT  :  Deep reinforcement learning (DRL) has empowered a variety of artificial intelligence fields, including pattern recognition, robotics, recommendation-systems, and gaming. Similarly, graph neural networks (GNN) have also demonstrated their superior performance in supervised learning for graph-structured data. In recent times, the fusion of GNN with DRL for graph-structured environments has attracted a lot of attention. This paper provides a comprehensive review of these hybrid works. These works can be classified into two categories: (1) algorithmic **enhancement**, where DRL and GNN complement each other for better utility; (2) application-specific **enhancement**, where DRL and GNN support each other. This fusion effectively addresses various complex problems in engineering and life sciences. Based on the review, we further analyze the applicability and benefits of fusing these two domains, especially in terms of increasing generalizability and reducing computational complexity. Finally, the key challenges in integrating DRL and GNN, and potential future research directions are highlighted, which will be of interest to the broader machine learning community.  
### Adversarial Privacy Protection on Speech **Enhancement**. (arXiv:2206.08170v1 [cs.SD])
- Authors : Mingyu Dong, Diqun Yan, Rangding Wang
- Link : [http://arxiv.org/abs/2206.08170](http://arxiv.org/abs/2206.08170)
> ABSTRACT  :  Speech is easily leaked imperceptibly, such as being recorded by mobile phones in different situations. Private content in speech may be maliciously extracted through speech **enhancement** technology. Speech **enhancement** technology has developed rapidly along with deep neural networks (DNNs), but adversarial examples can cause DNNs to fail. In this work, we propose an adversarial method to degrade speech **enhancement** systems. Experimental results show that generated adversarial examples can erase most content information in original examples or replace it with target speech content through speech **enhancement**. The word error rate (WER) between an enhanced original example and enhanced adversarial example recognition result can reach 89.0%. WER of target attack between enhanced adversarial example and target example is low to 33.75% . Adversarial perturbation can bring the rate of change to the original example to more than 1.4430. This work can prevent the malicious extraction of speech.  
### A machine-generated catalogue of Charon's craters and implications for the Kuiper belt. (arXiv:2206.08277v1 [astro-ph.EP])
- Authors : Mohamad Ali
- Link : [http://arxiv.org/abs/2206.08277](http://arxiv.org/abs/2206.08277)
> ABSTRACT  :  In this paper we investigate Charon's craters size distribution using a deep learning model. This is motivated by the recent results of Singer et al. (2019) who, using manual cataloging, found a change in the size distribution slope of craters smaller than 12 km in diameter, translating into a paucity of small Kuiper Belt objects. These results were corroborated by Robbins and Singer (2021), but opposed by Morbidelli et al. (2021), necessitating an independent review. Our MaskRCNN-based ensemble of models was trained on Lunar, Mercurian, and Martian crater catalogues and both optical and digital elevation images. We use a robust image augmentation scheme to force the model to generalize and transfer-learn into icy objects. With no prior bias or **exposure** to Charon, our model find best fit slopes of q =-1.47+-0.33 for craters smaller than 10 km, and q =-2.91+-0.51 for craters larger than 15 km. These values indicate a clear change in slope around 15 km as suggested by Singer et al. (2019) and thus independently confirm their conclusions. Our slopes however are both slightly flatter than those found more recently by Robbins and Singer (2021). Our trained models and relevant codes are available online on github.com/malidib/ACID .  
### Boosting the Adversarial Transferability of Surrogate Model with **Dark** Knowledge. (arXiv:2206.08316v1 [cs.LG])
- Authors : Dingcheng Yang, Zihao Xiao, Wenjian Yu
- Link : [http://arxiv.org/abs/2206.08316](http://arxiv.org/abs/2206.08316)
> ABSTRACT  :  Deep neural networks (DNNs) for image classification are known to be vulnerable to adversarial examples. And, the adversarial examples have transferability, which means an adversarial example for a DNN model can fool another black-box model with a non-trivial probability. This gave birth of the transfer-based adversarial attack where the adversarial examples generated by a pretrained or known model (called surrogate model) are used to conduct black-box attack. There are some work on how to generate the adversarial examples from a given surrogate model to achieve better transferability. However, training a special surrogate model to generate adversarial examples with better transferability is relatively under-explored. In this paper, we propose a method of training a surrogate model with abundant **dark** knowledge to boost the adversarial transferability of the adversarial examples generated by the surrogate model. This trained surrogate model is named **dark** surrogate model (DSM), and the proposed method to train DSM consists of two key components: a teacher model extracting **dark** knowledge and providing soft labels, and the mixing augmentation skill which enhances the **dark** knowledge of training data. Extensive experiments have been conducted to show that the proposed method can substantially improve the adversarial transferability of surrogate model across different architectures of surrogate model and optimizers for generating adversarial examples. We also show that the proposed method can be applied to other scenarios of transfer-based attack that contain **dark** knowledge, like face verification.  
### Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features. (arXiv:2111.02363v3 [eess.AS] UPDATED)
- Authors : Wei Fu, Fei Chen, Shann Fuh, Min Wang, Yu Tsao
- Link : [http://arxiv.org/abs/2111.02363](http://arxiv.org/abs/2111.02363)
> ABSTRACT  :  In this study, we propose a cross-domain multi-objective speech assessment model called MOSA-Net, which can estimate multiple speech assessment metrics simultaneously. Experimental results show that MOSA-Net can improve the linear correlation coefficient (LCC) by 0.026 (0.990 vs 0.964 in seen noise environments) and 0.012 (0.969 vs 0.957 in unseen noise environments) in PESQ prediction, compared to Quality-Net, an existing single-task model for PESQ prediction, and improve LCC by 0.021 (0.985 vs 0.964 in seen noise environments) and 0.047 (0.836 vs 0.789 in unseen noise environments) in STOI prediction, compared to STOI-Net (based on CRNN), an existing single-task model for STOI prediction. Moreover, MOSA-Net, originally trained to assess objective scores, can be used as a pre-trained model to be effectively adapted to an assessment model for predicting subjective quality and intelligibility scores with a limited amount of training data. Experimental results show that MOSA-Net can improve LCC by 0.018 (0.805 vs 0.787) in MOS prediction, compared to MOS-SSL, a strong single-task model for MOS prediction. In light of the confirmed prediction capability, we further adopt the latent representations of MOSA-Net to guide the speech **enhancement** (SE) process and derive a quality-intelligibility (QI)-aware SE (QIA-SE) approach accordingly. Experimental results show that QIA-SE provides superior **enhancement** performance compared with the baseline SE system in terms of objective evaluation metrics and qualitative evaluation test. For example, QIA-SE can improve PESQ by 0.301 (2.953 vs 2.652 in seen noise environments) and 0.18 (2.658 vs 2.478 in unseen noise environments) over a CNN-based baseline SE model.  
## cs.AI
---
### Mutual Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.09960v3 [cs.CV] UPDATED)
- Authors : Yicheng Wu, Zongyuan Ge, Donghao Zhang, Minfeng Xu, **Lei Zhang**, Yong Xia, Jianfei Cai
- Link : [http://arxiv.org/abs/2109.09960](http://arxiv.org/abs/2109.09960)
> ABSTRACT  :  In this paper, we propose a novel mutual consistency network (MC-Net+) to effectively exploit the unlabeled data for semi-supervised medical image segmentation. The MC-Net+ model is motivated by the observation that deep models trained with limited annotations are prone to output highly uncertain and easily mis-classified predictions in the ambiguous regions (e.g., adhesive edges or thin branches) for medical image segmentation. Leveraging these challenging samples can make the semi-supervised segmentation model training more effective. Therefore, our proposed MC-Net+ model consists of two new designs. First, the model contains one shared encoder and multiple slightly different decoders (i.e., using different up-sampling strategies). The statistical discrepancy of multiple decoders' outputs is computed to denote the model's uncertainty, which indicates the unlabeled hard regions. Second, we apply a novel mutual consistency constraint between one decoder's probability output and other decoders' soft pseudo labels. In this way, we minimize the discrepancy of multiple outputs (i.e., the model uncertainty) during training and force the model to generate invariant results in such challenging regions, aiming at regularizing the model training. We compared the segmentation results of our MC-Net+ model with five state-of-the-art semi-supervised approaches on three public medical datasets. Extension experiments with two standard semi-supervised settings demonstrate the superior performance of our model over other methods, which sets a new state of the art for semi-supervised medical image segmentation. Our code is released publicly at https://github.com/ycwu1997/MC-Net.  
### S$^2$-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v2 [cs.CV] UPDATED)
- Authors : Chenhui Yang, Chenxi Huang, Tewodros Legesse, Xin Hong
- Link : [http://arxiv.org/abs/2206.07298](http://arxiv.org/abs/2206.07298)
> ABSTRACT  :  Modern high-performance semantic segmentation methods employ a heavy backbone and dilated convolution to extract the relevant feature. Although extracting features with both contextual and semantic information is critical for the segmentation tasks, it brings a memory footprint and high computation cost for real-time applications. This paper presents a new model to achieve a trade-off between accuracy/speed for real-time road scene semantic segmentation. Specifically, we proposed a lightweight model named Scale-aware Strip Attention Guided Feature Pyramid Network (S$^2$-FPN). Our network consists of three main modules: Attention Pyramid Fusion (APF) module, Scale-aware Strip Attention Module (SSAM), and Global Feature Upsample (GFU) module. APF adopts an attention mechanisms to learn discriminative multi-scale features and help close the semantic gap between different levels. APF uses the scale-aware attention to encode global context with vertical stripping operation and models the long-range dependencies, which helps relate pixels with similar semantic label. In addition, APF employs channel-wise reweighting block (CRB) to emphasize the channel features. Finally, the decoder of S$^2$-FPN then adopts GFU, which is used to fuse features from APF and the encoder. Extensive experiments have been conducted on two challenging semantic segmentation benchmarks, which demonstrate that our approach achieves better accuracy/speed trade-off with different model settings. The proposed models have achieved a results of 76.2\%mIoU/87.3FPS, 77.4\%mIoU/67FPS, and 77.8\%mIoU/30.5FPS on Cityscapes dataset, and 69.6\%mIoU,71.0\% mIoU, and 74.2\% mIoU on Camvid dataset. The code for this work will be made available at \url{https://github.com/mohamedac29/S2-FPN  
# Paper List
---
## cs.CV
---
**116** new papers in cs.CV:-) 
1. Improving Diversity with Adversarially Learned Transformations for Domain Generalization. (arXiv:2206.07736v1 [cs.LG])
2. Edge Inference with Fully Differentiable Quantized Mixed Precision Neural Networks. (arXiv:2206.07741v1 [cs.LG])
3. Reconstructing Training Data from Trained Neural Networks. (arXiv:2206.07758v1 [cs.LG])
4. SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos. (arXiv:2206.07764v1 [cs.CV])
5. Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation. (arXiv:2206.07771v1 [cs.CV])
6. On Calibrated Model Uncertainty in Deep Learning. (arXiv:2206.07795v1 [cs.LG])
7. What makes domain generalization hard?. (arXiv:2206.07802v1 [cs.CV])
8. Disentangling visual and written concepts in CLIP. (arXiv:2206.07835v1 [cs.CV])
9. Action Spotting using Dense Detection Anchors Revisited: Submission to the SoccerNet Challenge 2022. (arXiv:2206.07846v1 [cs.CV])
10. Improved surface reconstruction using high-frequency details. (arXiv:2206.07850v1 [cs.CV])
11. PeQuENet: Perceptual Quality **Enhancement** of Compressed Video with Adaptation- and Attention-based Network. (arXiv:2206.07893v1 [cs.CV])
12. Dual Contrastive Attributed Graph Clustering Network. (arXiv:2206.07897v1 [cs.CV])
13. Multimodal Dialogue State Tracking. (arXiv:2206.07898v1 [cs.AI])
14. Lifelong Wandering: A realistic few-shot online continual learning setting. (arXiv:2206.07932v1 [cs.CV])
15. Technical Report for Argoverse2 Challenge 2022 -- Motion Forecasting Task. (arXiv:2206.07934v1 [cs.CV])
16. Analysis and Extensions of Adversarial Training for Video Classification. (arXiv:2206.07953v1 [cs.CV])
17. A Simple Baseline for BEV Perception Without LiDAR. (arXiv:2206.07959v1 [cs.CV])
18. DreamNet: A Deep Riemannian Network based on SPD Manifold Learning for Visual Classification. (arXiv:2206.07967v1 [cs.CV])
19. Multi-scale Cooperative Multimodal Transformers for Multimodal Sentiment Analysis in Videos. (arXiv:2206.07981v1 [cs.CV])
20. Image Captioning based on Feature Refinement and Reflective Decoding. (arXiv:2206.07986v1 [cs.CV])
21. Patch-level Representation Learning for Self-supervised Vision Transformers. (arXiv:2206.07990v1 [cs.CV])
22. Joint Class-Affinity Loss Correction for Robust Medical Image Segmentation with Noisy Labels. (arXiv:2206.07994v1 [cs.CV])
23. Balancing Discriminability and Transferability for Source-Free Domain Adaptation. (arXiv:2206.08009v1 [cs.CV])
24. MoDi: Unconditional Motion Synthesis from Diverse Data. (arXiv:2206.08010v1 [cs.GR])
25. Backbones-Review: Feature Extraction Networks for Deep Learning and Deep Reinforcement Learning Approaches. (arXiv:2206.08016v1 [cs.CV])
26. Multi-View Imputation and Cross-Attention Network Based on Incomplete Longitudinal and Multi-Modal Data for Alzheimer's Disease Prediction. (arXiv:2206.08019v1 [eess.IV])
27. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v1 [eess.IV])
28. DeepFormableTag: End-to-end Generation and Recognition of Deformable Fiducial Markers. (arXiv:2206.08026v1 [cs.CV])
29. Learning Effect of Lay People in Gesture-Based Locomotion in Virtual Reality. (arXiv:2206.08076v1 [cs.HC])
30. Neural Scene Representation for Locomotion on Structured Terrain. (arXiv:2206.08077v1 [cs.RO])
31. U-PET: MRI-based Dementia Detection with Joint Generation of Synthetic FDG-PET Images. (arXiv:2206.08078v1 [eess.IV])
32. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v1 [cs.CV])
33. An Improved Normed-Deformable Convolution for Crowd Counting. (arXiv:2206.08084v1 [cs.CV])
34. A Simple Baseline for Adversarial Domain Adaptation-based Unsupervised Flood Forecasting. (arXiv:2206.08105v1 [cs.CV])
35. Channel Importance Matters in Few-Shot Image Classification. (arXiv:2206.08126v1 [cs.CV])
36. Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline. (arXiv:2206.08129v1 [cs.CV])
37. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v1 [cs.LG])
38. Self-Adaptive Label Augmentation for Semi-supervised Few-shot Classification. (arXiv:2206.08150v1 [cs.CV])
39. Zero-Shot Video Question Answering via Frozen Bidirectional Language Models. (arXiv:2206.08155v1 [cs.CV])
40. Volumetric Supervised Contrastive Learning for Seismic Semantic Segmentation. (arXiv:2206.08158v1 [cs.CV])
41. K-Radar: 4D Radar Object Detection Dataset and Benchmark for Autonomous Driving in Various Weather Conditions. (arXiv:2206.08171v1 [cs.CV])
42. RefCrowd: Grounding the Target in Crowd with Referring Expressions. (arXiv:2206.08172v1 [cs.CV])
43. Level 2 Autonomous Driving on a Single Device: Diving into the Devils of Openpilot. (arXiv:2206.08176v1 [cs.CV])
44. Nucleus Segmentation and Analysis in Breast Cancer with the MIScnn Framework. (arXiv:2206.08182v1 [cs.CV])
45. Asymptotic Soft Cluster Pruning for Deep Neural Networks. (arXiv:2206.08186v1 [cs.CV])
46. Online Segmentation of LiDAR Sequences: Dataset and Algorithm. (arXiv:2206.08194v1 [cs.CV])
47. Selective Multi-Scale Learning for Object Detection. (arXiv:2206.08206v1 [cs.CV])
48. A Closer Look at Smoothness in Domain Adversarial Training. (arXiv:2206.08213v1 [cs.LG])
49. HaGRID - HAnd Gesture Recognition Image Dataset. (arXiv:2206.08219v1 [cs.CV])
50. Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency. (arXiv:2206.08222v1 [cs.CV])
51. Multi scale Feature Extraction and Fusion for Online Knowledge Distillation. (arXiv:2206.08224v1 [cs.CV])
52. Delving into the Scale Variance Problem in Object Detection. (arXiv:2206.08227v1 [cs.CV])
53. Open-Set Recognition with Gradient-Based Representations. (arXiv:2206.08229v1 [cs.CV])
54. Simple and Efficient Architectures for Semantic Segmentation. (arXiv:2206.08236v1 [cs.CV])
55. Catastrophic overfitting is a bug but also a feature. (arXiv:2206.08242v1 [cs.LG])
56. Gradient-Based Adversarial and Out-of-Distribution Detection. (arXiv:2206.08255v1 [cs.LG])
57. Longitudinal detection of new MS lesions using Deep Learning. (arXiv:2206.08272v1 [eess.IV])
58. Rank the triplets: A ranking-based multiple instance learning framework for detecting HPV infection in head and neck cancers using routine H&E images. (arXiv:2206.08275v1 [cs.CV])
59. Video Capsule Endoscopy Classification using Focal Modulation Guided Convolutional Neural Network. (arXiv:2206.08298v1 [eess.IV])
60. Adversarial Patch Attacks and Defences in Vision-Based Tasks: A Survey. (arXiv:2206.08304v1 [cs.CV])
61. Deepfake histological images for enhancing digital pathology. (arXiv:2206.08308v1 [eess.IV])
62. SoundSpaces 2.0: A Simulation Platform for Visual-Acoustic Learning. (arXiv:2206.08312v1 [cs.SD])
63. Boosting the Adversarial Transferability of Surrogate Model with **Dark** Knowledge. (arXiv:2206.08316v1 [cs.LG])
64. iBoot: Image-bootstrapped Self-Supervised Video Representation Learning. (arXiv:2206.08339v1 [cs.CV])
65. Realistic One-shot Mesh-based Head Avatars. (arXiv:2206.08343v1 [cs.CV])
66. Real-World Single Image Super-Resolution Under Rainy Condition. (arXiv:2206.08345v1 [cs.CV])
67. Beyond Supervised vs. Unsupervised: Representative Benchmarking and Analysis of Image Representation Learning. (arXiv:2206.08347v1 [cs.CV])
68. FWD: **Real-time** Novel View Synthesis with Forward Warping and Depth. (arXiv:2206.08355v1 [cs.CV])
69. OmniMAE: Single Model Masked Pretraining on Images and Videos. (arXiv:2206.08356v1 [cs.CV])
70. Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing. (arXiv:2206.08357v1 [cs.CV])
71. MixGen: A New Multi-Modal Data Augmentation. (arXiv:2206.08358v1 [cs.CV])
72. Controllable 3D Face Synthesis with Conditional Generative Occupancy Fields. (arXiv:2206.08361v1 [cs.CV])
73. Unified Fourier-based Kernel and Nonlinearity Design for Equivariant Networks on Homogeneous Spaces. (arXiv:2206.08362v1 [cs.CV])
74. Virtual Correspondence: Humans as a Cue for Extreme-View Geometry. (arXiv:2206.08365v1 [cs.CV])
75. SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation. (arXiv:2206.08367v1 [cs.CV])
76. Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model. (arXiv:2206.08368v1 [cs.CV])
77. Towards Robust and Reproducible Active Learning Using Neural Networks. (arXiv:2002.09564v3 [cs.LG] UPDATED)
78. Face Anti-Spoofing by Learning Polarization Cues in a Real-World Scenario. (arXiv:2003.08024v3 [cs.CV] UPDATED)
79. Pointly-Supervised Instance Segmentation. (arXiv:2104.06404v2 [cs.CV] UPDATED)
80. DEEMD: Drug Efficacy Estimation against SARS-CoV-2 based on cell Morphology with Deep multiple instance learning. (arXiv:2105.05758v2 [cs.LG] UPDATED)
81. OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data. (arXiv:2107.08943v2 [cs.CV] UPDATED)
82. Out-of-Domain Generalization from a Single Source: An Uncertainty Quantification Approach. (arXiv:2108.02888v2 [cs.CV] UPDATED)
83. Skin Deep Unlearning: Artefact and Instrument Debiasing in the Context of Melanoma Classification. (arXiv:2109.09818v5 [cs.CV] UPDATED)
84. Mutual Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.09960v3 [cs.CV] UPDATED)
85. CausalAF: Causal Autoregressive Flow for Safety-Critical Driving Scenario Generation. (arXiv:2110.13939v2 [cs.CV] UPDATED)
86. Solving Inverse Problems in Medical Imaging with Score-Based Generative Models. (arXiv:2111.08005v2 [eess.IV] UPDATED)
87. SeCGAN: Parallel Conditional Generative Adversarial Networks for Face Editing via Semantic Consistency. (arXiv:2111.09298v4 [cs.CV] UPDATED)
88. Masked-attention Mask Transformer for Universal Image Segmentation. (arXiv:2112.01527v3 [cs.CV] UPDATED)
89. Wild ToFu: Improving Range and Quality of Indirect Time-of-Flight Depth with RGB Fusion in Challenging Environments. (arXiv:2112.03750v2 [cs.CV] UPDATED)
90. BEVDet: High-performance Multi-camera 3D Object Detection in Bird-Eye-View. (arXiv:2112.11790v3 [cs.CV] UPDATED)
91. Learning from Synthetic InSAR with Vision Transformers: The case of volcanic unrest detection. (arXiv:2201.03016v2 [eess.IV] UPDATED)
92. Can We Find Neurons that Cause Unrealistic Images in Deep Generative Networks?. (arXiv:2201.06346v4 [cs.CV] UPDATED)
93. Dataset Condensation with Contrastive Signals. (arXiv:2202.02916v3 [cs.CV] UPDATED)
94. General Cyclical Training of Neural Networks. (arXiv:2202.08835v2 [cs.LG] UPDATED)
95. Cyclical Focal Loss. (arXiv:2202.08978v2 [cs.CV] UPDATED)
96. Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation. (arXiv:2203.01324v2 [eess.IV] UPDATED)
97. HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging. (arXiv:2203.02149v2 [eess.IV] UPDATED)
98. A Large-scale Comprehensive Dataset and Copy-overlap Aware Evaluation Protocol for Segment-level Video Copy Detection. (arXiv:2203.02654v2 [cs.CV] UPDATED)
99. Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction. (arXiv:2203.04845v2 [cs.CV] UPDATED)
100. Neural Enhanced Belief Propagation for Data Association in Multiobject Tracking. (arXiv:2203.09948v3 [cs.CV] UPDATED)
101. Evaluation of April Tag and WhyCode Fiducial Systems for Autonomous Precision Drone Landing with a Gimbal-Mounted Camera. (arXiv:2203.10180v2 [cs.CV] UPDATED)
102. End-to-end Document Recognition and Understanding with Dessurt. (arXiv:2203.16618v3 [cs.CV] UPDATED)
103. BEVDet4D: Exploit Temporal Cues in Multi-camera 3D Object Detection. (arXiv:2203.17054v3 [cs.CV] UPDATED)
104. Faculty Distillation with Optimal Transport. (arXiv:2204.11526v2 [cs.LG] UPDATED)
105. Unlocking High-Accuracy Differentially Private Image Classification through Scale. (arXiv:2204.13650v2 [cs.LG] UPDATED)
106. Representation Learning for Compressed Video Action Recognition via Attentive Cross-modal Interaction with Motion **Enhancement**. (arXiv:2205.03569v3 [cs.CV] UPDATED)
107. Multi-level Consistency Learning for Semi-supervised Domain Adaptation. (arXiv:2205.04066v2 [cs.CV] UPDATED)
108. Adaptive Convolutional Dictionary Network for CT Metal Artifact Reduction. (arXiv:2205.07471v2 [eess.IV] UPDATED)
109. Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging. (arXiv:2205.10102v2 [cs.CV] UPDATED)
110. Unsupervised Flow-Aligned Sequence-to-Sequence Learning for Video **Restoration**. (arXiv:2205.10195v2 [cs.CV] UPDATED)
111. BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation. (arXiv:2205.13542v2 [cs.CV] UPDATED)
112. Virtual embeddings and self-consistency for self-supervised learning. (arXiv:2206.06023v2 [cs.CV] UPDATED)
113. Efficient Decoder-free Object Detection with Transformers. (arXiv:2206.06829v3 [cs.CV] UPDATED)
114. S$^2$-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v2 [cs.CV] UPDATED)
115. Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction. (arXiv:2206.07364v2 [eess.IV] UPDATED)
116. A Survey of Detection Methods for Die Attachment and Wire Bonding Defects in Integrated Circuit Manufacturing. (arXiv:2206.07481v2 [eess.SP] UPDATED)
## eess.IV
---
**23** new papers in eess.IV:-) 
1. On Calibrated Model Uncertainty in Deep Learning. (arXiv:2206.07795v1 [cs.LG])
2. PeQuENet: Perceptual Quality **Enhancement** of Compressed Video with Adaptation- and Attention-based Network. (arXiv:2206.07893v1 [cs.CV])
3. Inverse Problem of Ultrasound Beamforming with Denoising-Based Regularized Solutions. (arXiv:2206.07926v1 [eess.IV])
4. Multi-View Imputation and Cross-Attention Network Based on Incomplete Longitudinal and Multi-Modal Data for Alzheimer's Disease Prediction. (arXiv:2206.08019v1 [eess.IV])
5. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v1 [eess.IV])
6. Three-Dimensional Alignment of Density Maps in Cryo-Electron Microscopy. (arXiv:2206.08027v1 [eess.IV])
7. U-PET: MRI-based Dementia Detection with Joint Generation of Synthetic FDG-PET Images. (arXiv:2206.08078v1 [eess.IV])
8. DeepJSCC-Q: Constellation Constrained Deep Joint Source-Channel Coding. (arXiv:2206.08100v1 [eess.IV])
9. Large-scale, multi-centre, multi-disease validation of an AI clinical tool for cine CMR analysis. (arXiv:2206.08137v1 [eess.IV])
10. Simple and Efficient Architectures for Semantic Segmentation. (arXiv:2206.08236v1 [cs.CV])
11. Longitudinal detection of new MS lesions using Deep Learning. (arXiv:2206.08272v1 [eess.IV])
12. Video Capsule Endoscopy Classification using Focal Modulation Guided Convolutional Neural Network. (arXiv:2206.08298v1 [eess.IV])
13. Adversarial Patch Attacks and Defences in Vision-Based Tasks: A Survey. (arXiv:2206.08304v1 [cs.CV])
14. Deepfake histological images for enhancing digital pathology. (arXiv:2206.08308v1 [eess.IV])
15. Real-World Single Image Super-Resolution Under Rainy Condition. (arXiv:2206.08345v1 [cs.CV])
16. Face Anti-Spoofing by Learning Polarization Cues in a Real-World Scenario. (arXiv:2003.08024v3 [cs.CV] UPDATED)
17. Solving Inverse Problems in Medical Imaging with Score-Based Generative Models. (arXiv:2111.08005v2 [eess.IV] UPDATED)
18. Learning from Synthetic InSAR with Vision Transformers: The case of volcanic unrest detection. (arXiv:2201.03016v2 [eess.IV] UPDATED)
19. Exploring Smoothness and Class-Separation for Semi-supervised Medical Image Segmentation. (arXiv:2203.01324v2 [eess.IV] UPDATED)
20. HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging. (arXiv:2203.02149v2 [eess.IV] UPDATED)
21. Adaptive Convolutional Dictionary Network for CT Metal Artifact Reduction. (arXiv:2205.07471v2 [eess.IV] UPDATED)
22. Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral Compressive Imaging. (arXiv:2205.10102v2 [cs.CV] UPDATED)
23. Seeking Common Ground While Reserving Differences: Multiple Anatomy Collaborative Framework for Undersampled MRI Reconstruction. (arXiv:2206.07364v2 [eess.IV] UPDATED)
## cs.LG
---
**251** new papers in cs.LG:-) 
1. Taxonomy of Benchmarks in Graph Representation Learning. (arXiv:2206.07729v1 [cs.LG])
2. Improving Diversity with Adversarially Learned Transformations for Domain Generalization. (arXiv:2206.07736v1 [cs.LG])
3. Disparate Impact in Differential Privacy from Gradient Misalignment. (arXiv:2206.07737v1 [cs.LG])
4. Edge Inference with Fully Differentiable Quantized Mixed Precision Neural Networks. (arXiv:2206.07741v1 [cs.LG])
5. Feature Overcorrelation in Deep Graph Neural Networks: A New Perspective. (arXiv:2206.07743v1 [cs.LG])
6. When to intervene? Prescriptive Process Monitoring Under Uncertainty and Resource Constraints. (arXiv:2206.07745v1 [cs.AI])
7. Condensing Graphs via One-Step Gradient Matching. (arXiv:2206.07746v1 [cs.LG])
8. On the Identifiability of Nonlinear ICA: Sparsity and Beyond. (arXiv:2206.07751v1 [cs.LG])
9. Hybrid full-field thermal characterization of additive manufacturing processes using physics-informed neural networks with data. (arXiv:2206.07756v1 [cs.LG])
10. Reconstructing Training Data from Trained Neural Networks. (arXiv:2206.07758v1 [cs.LG])
11. SAVi++: Towards End-to-End Object-Centric Learning from Real-World Videos. (arXiv:2206.07764v1 [cs.CV])
12. Pareto Invariant Risk Minimization. (arXiv:2206.07766v1 [cs.LG])
13. Kantorovich Strikes Back! Wasserstein GANs are not Optimal Transport?. (arXiv:2206.07767v1 [cs.LG])
14. HyperImpute: Generalized Iterative Imputation with Automatic Model Selection. (arXiv:2206.07769v1 [stat.ML])
15. Robust Attack Graph Generation. (arXiv:2206.07776v1 [cs.LG])
16. A machine learning approach to predicting pore pressure response in liquefiable sands under cyclic loading. (arXiv:2206.07780v1 [physics.geo-ph])
17. Evaluating Short-Term Forecasting of Multiple Time Series in IoT Environments. (arXiv:2206.07784v1 [cs.LG])
18. Participation and Data Valuation in IoT Data Markets through Distributed Coalitions. (arXiv:2206.07785v1 [cs.NI])
19. Federated Data Analytics: A Study on Linear Models. (arXiv:2206.07786v1 [stat.AP])
20. On Calibrated Model Uncertainty in Deep Learning. (arXiv:2206.07795v1 [cs.LG])
21. FixEval: Execution-based Evaluation of Program Fixes for Competitive Programming Problems. (arXiv:2206.07796v1 [cs.SE])
22. Gaussian Blue Noise. (arXiv:2206.07798v1 [cs.GR])
23. Beyond Adult and COMPAS: Fairness in Multi-Class Prediction. (arXiv:2206.07801v1 [cs.LG])
24. Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems. (arXiv:2206.07808v1 [cs.CL])
25. Search-Based Testing Approach for Deep Reinforcement Learning Agents. (arXiv:2206.07813v1 [cs.SE])
26. Large-Scale Differentiable Causal Discovery of Factor Graphs. (arXiv:2206.07824v1 [stat.ML])
27. Metric-Fair Classifier Derandomization. (arXiv:2206.07826v1 [cs.LG])
28. Adaptive Expert Models for Personalization in Federated Learning. (arXiv:2206.07832v1 [cs.LG])
29. Efficient Approximation of Expected Hypervolume Improvement using Gauss-Hermite Quadrature. (arXiv:2206.07834v1 [cs.LG])
30. Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization. (arXiv:2206.07837v1 [cs.LG])
31. Linearity Grafting: Relaxed Neuron Pruning Helps Certifiable Robustness. (arXiv:2206.07839v1 [cs.LG])
32. Architectural Backdoors in Neural Networks. (arXiv:2206.07840v1 [cs.LG])
33. Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning. (arXiv:2206.07842v1 [cs.LG])
34. Conformal prediction set for time-series. (arXiv:2206.07851v1 [stat.ML])
35. Performance analysis of coreset selection for quantum implementation of K-Means clustering algorithm. (arXiv:2206.07852v1 [quant-ph])
36. The Scattering Transform Network with Generalized Morse Wavelets and Its Application to Music Genre Classification. (arXiv:2206.07857v1 [eess.AS])
37. EPG2S: Speech Generation and Speech **Enhancement** based on Electropalatography and Audio Signals using Multimodal Learning. (arXiv:2206.07860v1 [cs.SD])
38. Let Invariant Rationale Discovery Inspire Graph Contrastive Learning. (arXiv:2206.07869v1 [cs.LG])
39. Optimization-Derived Learning with Essential Convergence Analysis of Training and Hyper-training. (arXiv:2206.07875v1 [cs.LG])
40. Domain Generalization via Selective Consistency Regularization for Time Series Classification. (arXiv:2206.07876v1 [cs.LG])
41. Accelerating Inference and Language Model Fusion of Recurrent Neural Network Transducers via End-to-End 4-bit Quantization. (arXiv:2206.07882v1 [cs.CL])
42. Pure Exploration of Causal Bandits. (arXiv:2206.07883v1 [cs.LG])
43. Generalization Bounds for Data-Driven Numerical Linear Algebra. (arXiv:2206.07886v1 [cs.LG])
44. Max-Margin Works while Large Margin Fails: Generalization without Uniform Convergence. (arXiv:2206.07892v1 [cs.LG])
45. Multimodal Dialogue State Tracking. (arXiv:2206.07898v1 [cs.AI])
46. On Privacy and Personalization in Cross-Silo Federated Learning. (arXiv:2206.07902v1 [cs.LG])
47. Explainable Models via Compression of Tree Ensembles. (arXiv:2206.07904v1 [cs.LG])
48. Simultaneously Learning Stochastic and Adversarial Bandits with General Graph Feedback. (arXiv:2206.07908v1 [cs.LG])
49. Introducing the Huber mechanism for differentially private low-rank matrix completion. (arXiv:2206.07910v1 [cs.CR])
50. Double Sampling Randomized Smoothing. (arXiv:2206.07912v1 [cs.LG])
51. Barrier Certified Safety Learning Control: When Sum-of-Square Programming Meets Reinforcement Learning. (arXiv:2206.07915v1 [eess.SY])
52. "Understanding Robustness Lottery": A Comparative Visual Analysis of Neural Network Pruning Approaches. (arXiv:2206.07918v1 [cs.HC])
53. Challenges and Opportunities in Deep Reinforcement Learning with Graph Neural Networks: A Comprehensive review of Algorithms and Applications. (arXiv:2206.07922v1 [cs.LG])
54. Lifelong Wandering: A realistic few-shot online continual learning setting. (arXiv:2206.07932v1 [cs.CV])
55. PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series. (arXiv:2206.07940v1 [cs.LG])
56. Distributed Online Learning Algorithm With Differential Privacy Strategy for Convex Nondecomposable Global Objectives. (arXiv:2206.07944v1 [math.OC])
57. Forming Effective Human-AI Teams: Building Machine Learning Models that Complement the Capabilities of Multiple Experts. (arXiv:2206.07948v1 [cs.AI])
58. Analysis and Extensions of Adversarial Training for Video Classification. (arXiv:2206.07953v1 [cs.CV])
59. BlindFL: Vertical Federated Machine Learning without Peeking into Your Data. (arXiv:2206.07975v1 [cs.LG])
60. Cyclocopula Technique to Study the Relationship Between Two Cyclostationary Time Series with Fractional Brownian Motion Errors. (arXiv:2206.07976v1 [stat.ME])
61. Personalized Federated Learning via Variational Bayesian Inference. (arXiv:2206.07977v1 [cs.LG])
62. Research Topic Flows in Co-Authorship Networks. (arXiv:2206.07980v1 [cs.SI])
63. Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination. (arXiv:2206.07989v1 [cs.LG])
64. Patch-level Representation Learning for Self-supervised Vision Transformers. (arXiv:2206.07990v1 [cs.CV])
65. Continual Learning with Guarantees via Weight Interval Constraints. (arXiv:2206.07996v1 [cs.LG])
66. Differentially Private Multi-Party Data Release for Linear Regression. (arXiv:2206.07998v1 [cs.CR])
67. The convergent Indian buffet process. (arXiv:2206.08002v1 [stat.ML])
68. When a RF Beats a CNN and GRU, Together -- A Comparison of Deep Learning and Classical Machine Learning Approaches for Encrypted Malware Traffic Classification. (arXiv:2206.08004v1 [cs.CR])
69. Evaluating Self-Supervised Learning for Molecular Graph Embeddings. (arXiv:2206.08005v1 [cs.LG])
70. DCASE 2022: Comparative Analysis Of CNNs For Acoustic Scene Classification Under Low-Complexity Considerations. (arXiv:2206.08007v1 [cs.SD])
71. Balancing Discriminability and Transferability for Source-Free Domain Adaptation. (arXiv:2206.08009v1 [cs.CV])
72. MoDi: Unconditional Motion Synthesis from Diverse Data. (arXiv:2206.08010v1 [cs.GR])
73. Hardness prediction of age-hardening aluminum alloy based on ensemble learning. (arXiv:2206.08011v1 [cond-mat.mtrl-sci])
74. On Error and Compression Rates for Prototype Rules. (arXiv:2206.08014v1 [cs.LG])
75. Partial Identifiability for Nonnegative Matrix Factorization. (arXiv:2206.08022v1 [math.NA])
76. AMOS: A Large-Scale Abdominal Multi-Organ Benchmark for Versatile Medical Image Segmentation. (arXiv:2206.08023v1 [eess.IV])
77. Acoustic Modeling for End-to-End Empathetic Dialogue Speech Synthesis Using Linguistic and Prosodic Contexts of Dialogue History. (arXiv:2206.08039v1 [cs.SD])
78. Automated analysis of continuum fields from atomistic simulations using statistical machine learning. (arXiv:2206.08048v1 [cond-mat.mtrl-sci])
79. Time Interval-enhanced Graph Neural Network for Shared-account Cross-domain Sequential Recommendation. (arXiv:2206.08050v1 [cs.IR])
80. Generalized Leverage Scores: Geometric Interpretation and Applications. (arXiv:2206.08054v1 [cs.LG])
81. Active Nearest Neighbor Regression Through Delaunay Refinement. (arXiv:2206.08061v1 [cs.LG])
82. Neural tangent kernel analysis of shallow $\alpha$-Stable ReLU neural networks. (arXiv:2206.08065v1 [cs.LG])
83. Neural Scene Representation for Locomotion on Structured Terrain. (arXiv:2206.08077v1 [cs.RO])
84. U-PET: MRI-based Dementia Detection with Joint Generation of Synthetic FDG-PET Images. (arXiv:2206.08078v1 [eess.IV])
85. A Machine Learning-based Digital Twin for Electric Vehicle Battery Modeling. (arXiv:2206.08080v1 [cs.LG])
86. TransDrift: Modeling Word-Embedding Drift using Transformer. (arXiv:2206.08081v1 [cs.CL])
87. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v1 [cs.CV])
88. Reinforcement Learning-enhanced Shared-account Cross-domain Sequential Recommendation. (arXiv:2206.08088v1 [cs.IR])
89. Unsupervised Space Partitioning for Nearest Neighbor Search. (arXiv:2206.08091v1 [cs.LG])
90. On the well-spread property and its relation to linear regression. (arXiv:2206.08092v1 [cs.LG])
91. Applications of Machine Learning to the Identification of Anomalous ER Claims. (arXiv:2206.08093v1 [cs.LG])
92. Deep Neural Imputation: A Framework for Recovering Incomplete Brain Recordings. (arXiv:2206.08094v1 [cs.LG])
93. DeepJSCC-Q: Constellation Constrained Deep Joint Source-Channel Coding. (arXiv:2206.08100v1 [eess.IV])
94. Is Continual Learning Truly Learning Representations Continually?. (arXiv:2206.08101v1 [cs.LG])
95. Closed-Form Diffeomorphic Transformations for Time Series Alignment. (arXiv:2206.08107v1 [cs.LG])
96. On Private Online Convex Optimization: Optimal Algorithms in $\ell_p$-Geometry and High Dimensional Contextual Bandits. (arXiv:2206.08111v1 [cs.LG])
97. Learning to Infer Structures of Network Games. (arXiv:2206.08119v1 [cs.LG])
98. Using adversarial images to improve outcomes of federated learning for non-IID data. (arXiv:2206.08124v1 [cs.LG])
99. Large-scale, multi-centre, multi-disease validation of an AI clinical tool for cine CMR analysis. (arXiv:2206.08137v1 [eess.IV])
100. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v1 [cs.LG])
101. A Contextual Combinatorial Semi-Bandit Approach to Network Bottleneck Identification. (arXiv:2206.08144v1 [cs.LG])
102. A Truthful Owner-Assisted Scoring Mechanism. (arXiv:2206.08149v1 [cs.LG])
103. Fault-Tolerant Collaborative Inference through the Edge-PRUNE Framework. (arXiv:2206.08152v1 [cs.LG])
104. Zero-Shot Video Question Answering via Frozen Bidirectional Language Models. (arXiv:2206.08155v1 [cs.CV])
105. Long Range Graph Benchmark. (arXiv:2206.08164v1 [cs.LG])
106. Adversarial Privacy Protection on Speech **Enhancement**. (arXiv:2206.08170v1 [cs.SD])
107. Not All Lotteries Are Made Equal. (arXiv:2206.08175v1 [cs.LG])
108. User Engagement and Churn in Mobile Health Applications. (arXiv:2206.08178v1 [stat.ML])
109. ResNorm: Tackling Long-tailed Degree Distribution Issue in Graph Neural Networks via Normalization. (arXiv:2206.08181v1 [cs.LG])
110. MAGIC: Microlensing Analysis Guided by Intelligent Computation. (arXiv:2206.08199v1 [astro-ph.IM])
111. Learning Physics between Digital Twins with Low-Fidelity Models and Physics-Informed Gaussian Processes. (arXiv:2206.08201v1 [stat.ML])
112. Inherent Inconsistencies of Feature Importance. (arXiv:2206.08204v1 [cs.LG])
113. A Closer Look at Smoothness in Domain Adversarial Training. (arXiv:2206.08213v1 [cs.LG])
114. Functional Output Regression with Infimal Convolution: Exploring the Huber and $\epsilon$-insensitive Losses. (arXiv:2206.08220v1 [stat.ML])
115. Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency. (arXiv:2206.08222v1 [cs.CV])
116. All the World's a (Hyper)Graph: A Data Drama. (arXiv:2206.08225v1 [cs.LG])
117. Simple and Efficient Architectures for Semantic Segmentation. (arXiv:2206.08236v1 [cs.CV])
118. Noisy Learning for Neural ODEs Acts as a Robustness Locus Widening. (arXiv:2206.08237v1 [cs.LG])
119. Catastrophic overfitting is a bug but also a feature. (arXiv:2206.08242v1 [cs.LG])
120. On the Surprising Behaviour of node2vec. (arXiv:2206.08252v1 [cs.LG])
121. Gradient-Based Adversarial and Out-of-Distribution Detection. (arXiv:2206.08255v1 [cs.LG])
122. Gradient Descent for Low-Rank Functions. (arXiv:2206.08257v1 [cs.LG])
123. ProGNNosis: A Data-driven Model to Predict GNN Computation Time Using Graph Metrics. (arXiv:2206.08258v1 [cs.LG])
124. Attention-wise masked graph contrastive learning for predicting molecular property. (arXiv:2206.08262v1 [q-bio.BM])
125. Maximum Likelihood Training for Score-Based Diffusion ODEs by High-Order Denoising Score Matching. (arXiv:2206.08265v1 [stat.ML])
126. Learning with little mixing. (arXiv:2206.08269v1 [cs.LG])
127. Concentration of Data Encoding in Parameterized Quantum Circuits. (arXiv:2206.08273v1 [quant-ph])
128. Rank the triplets: A ranking-based multiple instance learning framework for detecting HPV infection in head and neck cancers using routine H&E images. (arXiv:2206.08275v1 [cs.CV])
129. A machine-generated catalogue of Charon's craters and implications for the Kuiper belt. (arXiv:2206.08277v1 [astro-ph.EP])
130. Switchable Representation Learning Framework with Self-compatibility. (arXiv:2206.08289v1 [cs.AI])
131. GoodBye WaveNet -- A Language Model for Raw Audio with Context of 1/2 Million Samples. (arXiv:2206.08297v1 [cs.SD])
132. On Scaled Methods for Saddle Point Problems. (arXiv:2206.08303v1 [cs.LG])
133. Adversarial Patch Attacks and Defences in Vision-Based Tasks: A Survey. (arXiv:2206.08304v1 [cs.CV])
134. Sharper Convergence Guarantees for Asynchronous SGD for Distributed and Federated Learning. (arXiv:2206.08307v1 [cs.LG])
135. Deepfake histological images for enhancing digital pathology. (arXiv:2206.08308v1 [eess.IV])
136. Pythae: Unifying Generative Autoencoders in Python -- A Benchmarking Use Case. (arXiv:2206.08309v1 [cs.LG])
137. Continuous-Time Modeling of Counterfactual Outcomes Using Neural Controlled Differential Equations. (arXiv:2206.08311v1 [cs.LG])
138. Boosting the Adversarial Transferability of Surrogate Model with **Dark** Knowledge. (arXiv:2206.08316v1 [cs.LG])
139. Compressed-VFL: Communication-Efficient Learning with Vertically Partitioned Data. (arXiv:2206.08330v1 [cs.LG])
140. BYOL-Explore: Exploration by Bootstrapped Prediction. (arXiv:2206.08332v1 [cs.LG])
141. Constrained Submodular Optimization for Vaccine Design. (arXiv:2206.08336v1 [q-bio.QM])
142. iBoot: Image-bootstrapped Self-Supervised Video Representation Learning. (arXiv:2206.08339v1 [cs.CV])
143. Know your audience: specializing grounded language models with the game of Dixit. (arXiv:2206.08349v1 [cs.LG])
144. Towards Understanding How Machines Can Learn Causal Overhypotheses. (arXiv:2206.08353v1 [cs.LG])
145. OmniMAE: Single Model Masked Pretraining on Images and Videos. (arXiv:2206.08356v1 [cs.CV])
146. Spatially-Adaptive Multilayer Selection for GAN Inversion and Editing. (arXiv:2206.08357v1 [cs.CV])
147. MixGen: A New Multi-Modal Data Augmentation. (arXiv:2206.08358v1 [cs.CV])
148. Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability. (arXiv:2206.08363v1 [cs.LG])
149. Interaction-Grounded Learning with Action-inclusive Feedback. (arXiv:2206.08364v1 [cs.LG])
150. Scalable First-Order Bayesian Optimization via Structured Automatic Differentiation. (arXiv:2206.08366v1 [cs.LG])
151. SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation. (arXiv:2206.08367v1 [cs.CV])
152. Towards Robust and Reproducible Active Learning Using Neural Networks. (arXiv:2002.09564v3 [cs.LG] UPDATED)
153. Face Anti-Spoofing by Learning Polarization Cues in a Real-World Scenario. (arXiv:2003.08024v3 [cs.CV] UPDATED)
154. Deep Learning for Time Series Forecasting: Tutorial and Literature Survey. (arXiv:2004.10240v2 [cs.LG] UPDATED)
155. Learning to Denoise Historical Music. (arXiv:2008.02027v2 [eess.AS] UPDATED)
156. Learning Models of Individual Behavior in Chess. (arXiv:2008.10086v3 [cs.AI] UPDATED)
157. Finite-Time Convergence Rates of Decentralized Stochastic Approximation with Applications in Multi-Agent and Multi-Task Learning. (arXiv:2010.15088v2 [cs.LG] UPDATED)
158. Applying Machine Learning to Crowd-sourced Data from Earthquake Detective. (arXiv:2011.04740v2 [physics.geo-ph] UPDATED)
159. NCGNN: Node-Level Capsule Graph Neural Network for Semisupervised Classification. (arXiv:2012.03476v2 [cs.LG] UPDATED)
160. Federated Learning on the Road: Autonomous Controller Design for Connected and Autonomous Vehicles. (arXiv:2102.03401v2 [eess.SY] UPDATED)
161. Meta-Learning Dynamics Forecasting Using Task Inference. (arXiv:2102.10271v4 [cs.LG] UPDATED)
162. Preserved central model for faster bidirectional compression in distributed settings. (arXiv:2102.12528v2 [cs.LG] UPDATED)
163. A Tree-based Model Averaging Approach for Personalized Treatment Effect Estimation from Heterogeneous Data Sources. (arXiv:2103.06261v3 [stat.ML] UPDATED)
164. mlf-core: a framework for deterministic machine learning. (arXiv:2104.07651v2 [cs.MS] UPDATED)
165. DEEMD: Drug Efficacy Estimation against SARS-CoV-2 based on cell Morphology with Deep multiple instance learning. (arXiv:2105.05758v2 [cs.LG] UPDATED)
166. An accelerated expectation-maximization algorithm for multi-reference alignment. (arXiv:2105.07372v2 [eess.SP] UPDATED)
167. Model Zoo: A Growing "Brain" That Learns Continually. (arXiv:2106.03027v3 [cs.LG] UPDATED)
168. Benchmarking Differential Privacy and Federated Learning for BERT Models. (arXiv:2106.13973v2 [cs.CL] UPDATED)
169. Classical Planning in Deep Latent Space. (arXiv:2107.00110v3 [cs.AI] UPDATED)
170. Approximate Frank-Wolfe Algorithms over Graph-structured Support Sets. (arXiv:2107.00472v2 [math.OC] UPDATED)
171. OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data. (arXiv:2107.08943v2 [cs.CV] UPDATED)
172. Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them. (arXiv:2107.11630v2 [cs.LG] UPDATED)
173. The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation. (arXiv:2107.13473v3 [eess.SP] UPDATED)
174. Fuzzy Logic Based Logical Query Answering on Knowledge Graphs. (arXiv:2108.02390v2 [cs.LG] UPDATED)
175. Estimating Categorical Counterfactuals via Deep Twin Networks. (arXiv:2109.01904v4 [cs.LG] UPDATED)
176. Learning Interpretable Representations of Entanglement in Quantum Optics Experiments using Deep Generative Models. (arXiv:2109.02490v2 [cs.LG] UPDATED)
177. LSB: Local Self-Balancing MCMC in Discrete Spaces. (arXiv:2109.03867v3 [cs.AI] UPDATED)
178. New Versions of Gradient Temporal Difference Learning. (arXiv:2109.04033v2 [cs.LG] UPDATED)
179. Multi-Objective Bayesian Optimization over High-Dimensional Search Spaces. (arXiv:2109.10964v4 [cs.LG] UPDATED)
180. CENN: Conservative energy method based on neural networks with subdomains for solving variational problems involving heterogeneous and complex geometries. (arXiv:2110.01359v3 [math.NA] UPDATED)
181. Universality of Winning Tickets: A Renormalization Group Perspective. (arXiv:2110.03210v3 [cs.LG] UPDATED)
182. TAG: Toward Accurate Social Media Content Tagging with a Concept Graph. (arXiv:2110.06892v4 [cs.LG] UPDATED)
183. Adversarial Attacks on Gaussian Process Bandits. (arXiv:2110.08449v3 [stat.ML] UPDATED)
184. CausalAF: Causal Autoregressive Flow for Safety-Critical Driving Scenario Generation. (arXiv:2110.13939v2 [cs.CV] UPDATED)
185. An Asymptotic Test for Conditional Independence using Analytic Kernel Embeddings. (arXiv:2110.14868v2 [stat.ML] UPDATED)
186. Deep Learning-based Non-Intrusive Multi-Objective Speech Assessment Model with Cross-Domain Features. (arXiv:2111.02363v3 [eess.AS] UPDATED)
187. OpenFWI: Large-Scale Multi-Structural Benchmark Datasets for Seismic Full Waveform Inversion. (arXiv:2111.02926v3 [cs.LG] UPDATED)
188. Multi-Agent Learning for Iterative Dominance Elimination: Formal Barriers and New Algorithms. (arXiv:2111.05486v2 [cs.GT] UPDATED)
189. A Minimax Learning Approach to Off-Policy Evaluation in Confounded Partially Observable Markov Decision Processes. (arXiv:2111.06784v4 [cs.LG] UPDATED)
190. Solving Inverse Problems in Medical Imaging with Score-Based Generative Models. (arXiv:2111.08005v2 [eess.IV] UPDATED)
191. Masked-attention Mask Transformer for Universal Image Segmentation. (arXiv:2112.01527v3 [cs.CV] UPDATED)
192. Phase transitions in nonparametric regressions: a curse of exploiting higher degree smoothness assumptions in finite samples. (arXiv:2112.03626v3 [math.ST] UPDATED)
193. Wild ToFu: Improving Range and Quality of Indirect Time-of-Flight Depth with RGB Fusion in Challenging Environments. (arXiv:2112.03750v2 [cs.CV] UPDATED)
194. Scheduling Servers with Stochastic Bilinear Rewards. (arXiv:2112.06362v2 [cs.LG] UPDATED)
195. SCORE: Approximating Curvature Information under Self-Concordant Regularization. (arXiv:2112.07344v2 [cs.LG] UPDATED)
196. Multimeasurement Generative Models. (arXiv:2112.09822v2 [stat.ML] UPDATED)
197. Computationally Efficient Approximations for Matrix-based Renyi's Entropy. (arXiv:2112.13720v3 [stat.ML] UPDATED)
198. Tracking Most Significant Arm Switches in Bandits. (arXiv:2112.13838v6 [cs.LG] UPDATED)
199. Graph Signal Reconstruction Techniques for IoT Air Pollution Monitoring Platforms. (arXiv:2201.00378v2 [eess.SP] UPDATED)
200. The dynamics of representation learning in shallow, non-linear autoencoders. (arXiv:2201.02115v2 [stat.ML] UPDATED)
201. Deep Reinforcement Learning, a textbook. (arXiv:2201.02135v3 [cs.AI] UPDATED)
202. Black-box Safety Analysis and Retraining of DNNs based on Feature Extraction and Clustering. (arXiv:2201.05077v3 [cs.SE] UPDATED)
203. Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime. (arXiv:2201.07296v2 [math.OC] UPDATED)
204. Approximately Equivariant Networks for Imperfectly Symmetric Dynamics. (arXiv:2201.11969v4 [cs.LG] UPDATED)
205. Transfer Learning In Differential Privacy's Hybrid-Model. (arXiv:2201.12018v2 [cs.LG] UPDATED)
206. FEDformer: Frequency Enhanced Decomposed Transformer for Long-term Series Forecasting. (arXiv:2201.12740v3 [cs.LG] UPDATED)
207. Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism. (arXiv:2201.12987v2 [cs.LG] UPDATED)
208. Continual Repeated Annealed Flow Transport Monte Carlo. (arXiv:2201.13117v2 [stat.ML] UPDATED)
209. Deep Reference Priors: What is the best way to pretrain a model?. (arXiv:2202.00187v2 [stat.ML] UPDATED)
210. Active Learning on a Budget: Opposite Strategies Suit High and Low Budgets. (arXiv:2202.02794v4 [cs.LG] UPDATED)
211. Dataset Condensation with Contrastive Signals. (arXiv:2202.02916v3 [cs.CV] UPDATED)
212. Generalization Bounds via Convex Analysis. (arXiv:2202.04985v2 [stat.ML] UPDATED)
213. Flowformer: Linearizing Transformers with Conservation Flows. (arXiv:2202.06258v2 [cs.LG] UPDATED)
214. Off-Policy Evaluation for Large Action Spaces via Embeddings. (arXiv:2202.06317v2 [cs.LG] UPDATED)
215. General Cyclical Training of Neural Networks. (arXiv:2202.08835v2 [cs.LG] UPDATED)
216. Cyclical Focal Loss. (arXiv:2202.08978v2 [cs.CV] UPDATED)
217. Memorize to Generalize: on the Necessity of Interpolation in High Dimensional Linear Regression. (arXiv:2202.09889v2 [stat.ML] UPDATED)
218. Robustness and Accuracy Could Be Reconcilable by (Proper) Definition. (arXiv:2202.10103v2 [cs.LG] UPDATED)
219. Sample Efficiency of Data Augmentation Consistency Regularization. (arXiv:2202.12230v2 [cs.LG] UPDATED)
220. Learning Multi-Task Gaussian Process Over Heterogeneous Input Domains. (arXiv:2202.12636v2 [stat.ML] UPDATED)
221. Optimal-er Auctions through Attention. (arXiv:2202.13110v3 [cs.LG] UPDATED)
222. Contrasting random and learned features in deep Bayesian linear regression. (arXiv:2203.00573v2 [cs.LG] UPDATED)
223. Low-Degree Multicalibration. (arXiv:2203.01255v2 [cs.LG] UPDATED)
224. Risk-Averse No-Regret Learning in Online Convex Games. (arXiv:2203.08957v2 [cs.LG] UPDATED)
225. Neural Enhanced Belief Propagation for Data Association in Multiobject Tracking. (arXiv:2203.09948v3 [cs.CV] UPDATED)
226. Horizon-Free Reinforcement Learning in Polynomial Time: the Power of Stationary Policies. (arXiv:2203.12922v2 [cs.LG] UPDATED)
227. STUDIES: Corpus of Japanese Empathetic Dialogue Speech Towards Friendly Voice Agent. (arXiv:2203.14757v2 [cs.SD] UPDATED)
228. Equivariant Diffusion for Molecule Generation in 3D. (arXiv:2203.17003v2 [cs.LG] UPDATED)
229. Faculty Distillation with Optimal Transport. (arXiv:2204.11526v2 [cs.LG] UPDATED)
230. Unlocking High-Accuracy Differentially Private Image Classification through Scale. (arXiv:2204.13650v2 [cs.LG] UPDATED)
231. An Intriguing Property of Geophysics Inversion. (arXiv:2204.13731v2 [cs.LG] UPDATED)
232. Data-Free Adversarial Knowledge Distillation for Graph Neural Networks. (arXiv:2205.03811v2 [cs.LG] UPDATED)
233. Process, Bias and Temperature Scalable CMOS Analog Computing Circuits for Machine Learning. (arXiv:2205.05664v2 [cs.AR] UPDATED)
234. Integrating User and Item Reviews in Deep Cooperative Neural Networks for Movie Ranking Prediction. (arXiv:2205.06296v4 [cs.IR] UPDATED)
235. Generalizing to Evolving Domains with Latent Structure-Aware Sequential Autoencoder. (arXiv:2205.07649v2 [cs.LG] UPDATED)
236. DDXPlus: A New Dataset For Automatic Medical Diagnosis. (arXiv:2205.09148v2 [cs.CL] UPDATED)
237. $O(N^2)$ Universal Antisymmetry in Fermionic Neural Networks. (arXiv:2205.13205v2 [cs.LG] UPDATED)
238. Pruning has a disparate impact on model accuracy. (arXiv:2205.13574v2 [cs.LG] UPDATED)
239. Mixed Graph Contrastive Network for Semi-Supervised Node Classification. (arXiv:2206.02796v2 [cs.LG] UPDATED)
240. Generalized Data Distribution Iteration. (arXiv:2206.03192v2 [cs.LG] UPDATED)
241. Two Ways of Understanding Social Dynamics: Analyzing the Predictability of Emergence of Objects in Reddit r/place Dependent on Locality in Space and Time. (arXiv:2206.03563v2 [physics.soc-ph] UPDATED)
242. On gradient descent training under data augmentation with on-line noisy copies. (arXiv:2206.03734v2 [stat.ML] UPDATED)
243. Diffeomorphic Counterfactuals with Generative Models. (arXiv:2206.05075v2 [cs.LG] UPDATED)
244. Feature Selection using e-values. (arXiv:2206.05391v2 [stat.ML] UPDATED)
245. Squeeze All: Novel Estimator and Self-Normalized Bound for Linear Contextual Bandits. (arXiv:2206.05404v2 [stat.ML] UPDATED)
246. Discovery and density estimation of latent confounders in Bayesian networks with evidence lower bound. (arXiv:2206.05490v2 [cs.LG] UPDATED)
247. The Dynamics of Riemannian Robbins-Monro Algorithms. (arXiv:2206.06795v2 [math.OC] UPDATED)
248. On Provably Robust Meta-Bayesian Optimization. (arXiv:2206.06872v2 [cs.LG] UPDATED)
249. Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. (arXiv:2206.07137v2 [cs.LG] UPDATED)
250. A Survey of Detection Methods for Die Attachment and Wire Bonding Defects in Integrated Circuit Manufacturing. (arXiv:2206.07481v2 [eess.SP] UPDATED)
251. Preliminary study on the impact of EEG density on TMS-EEG classification in Alzheimer's disease. (arXiv:2206.07492v2 [eess.SP] UPDATED)
## cs.AI
---
**94** new papers in cs.AI:-) 
1. Disparate Impact in Differential Privacy from Gradient Misalignment. (arXiv:2206.07737v1 [cs.LG])
2. Feature Overcorrelation in Deep Graph Neural Networks: A New Perspective. (arXiv:2206.07743v1 [cs.LG])
3. When to intervene? Prescriptive Process Monitoring Under Uncertainty and Resource Constraints. (arXiv:2206.07745v1 [cs.AI])
4. Condensing Graphs via One-Step Gradient Matching. (arXiv:2206.07746v1 [cs.LG])
5. On the Identifiability of Nonlinear ICA: Sparsity and Beyond. (arXiv:2206.07751v1 [cs.LG])
6. Physics-Infused Fuzzy Generative Adversarial Network for Robust Failure Prognosis. (arXiv:2206.07762v1 [cs.AI])
7. Deep Learning and Handheld Augmented Reality Based System for Optimal Data Collection in Fault Diagnostics Domain. (arXiv:2206.07772v1 [cs.AI])
8. What makes domain generalization hard?. (arXiv:2206.07802v1 [cs.CV])
9. Alexa Teacher Model: Pretraining and Distilling Multi-Billion-Parameter Encoders for Natural Language Understanding Systems. (arXiv:2206.07808v1 [cs.CL])
10. High-Resolution Bathymetric Reconstruction From Sidescan Sonar With Deep Neural Networks. (arXiv:2206.07810v1 [cs.RO])
11. Search-Based Testing Approach for Deep Reinforcement Learning Agents. (arXiv:2206.07813v1 [cs.SE])
12. Neural Network Normal Estimation and Bathymetry Reconstruction from Sidescan Sonar. (arXiv:2206.07819v1 [cs.RO])
13. Efficient Approximation of Expected Hypervolume Improvement using Gauss-Hermite Quadrature. (arXiv:2206.07834v1 [cs.LG])
14. Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization. (arXiv:2206.07837v1 [cs.LG])
15. Linearity Grafting: Relaxed Neuron Pruning Helps Certifiable Robustness. (arXiv:2206.07839v1 [cs.LG])
16. Queried Unlabeled Data Improves and Robustifies Class-Incremental Learning. (arXiv:2206.07842v1 [cs.LG])
17. Unifying Framework for Optimizations in non-boolean Formalisms. (arXiv:2206.07862v1 [cs.AI])
18. How to talk so your robot will learn: Instructions, descriptions, and pragmatics. (arXiv:2206.07870v1 [cs.AI])
19. Pure Exploration of Causal Bandits. (arXiv:2206.07883v1 [cs.LG])
20. Multimodal Dialogue State Tracking. (arXiv:2206.07898v1 [cs.AI])
21. PROFHIT: Probabilistic Robust Forecasting for Hierarchical Time-series. (arXiv:2206.07940v1 [cs.LG])
22. Forming Effective Human-AI Teams: Building Machine Learning Models that Complement the Capabilities of Multiple Experts. (arXiv:2206.07948v1 [cs.AI])
23. Analysis and Extensions of Adversarial Training for Video Classification. (arXiv:2206.07953v1 [cs.CV])
24. PreCogIIITH at HinglishEval : Leveraging Code-Mixing Metrics & Language Model Embeddings To Estimate Code-Mix Quality. (arXiv:2206.07988v1 [cs.AI])
25. Double Check Your State Before Trusting It: Confidence-Aware Bidirectional Offline Model-Based Imagination. (arXiv:2206.07989v1 [cs.LG])
26. Patch-level Representation Learning for Self-supervised Vision Transformers. (arXiv:2206.07990v1 [cs.CV])
27. MoDi: Unconditional Motion Synthesis from Diverse Data. (arXiv:2206.08010v1 [cs.GR])
28. Exploiting Global Semantic Similarities in Knowledge Graphs by Relational Prototype Entities. (arXiv:2206.08021v1 [cs.CL])
29. Time Interval-enhanced Graph Neural Network for Shared-account Cross-domain Sequential Recommendation. (arXiv:2206.08050v1 [cs.IR])
30. Neural Scene Representation for Locomotion on Structured Terrain. (arXiv:2206.08077v1 [cs.RO])
31. A Machine Learning-based Digital Twin for Electric Vehicle Battery Modeling. (arXiv:2206.08080v1 [cs.LG])
32. CARLANE: A Lane Detection Benchmark for Unsupervised Domain Adaptation from Simulation to multiple Real-World Domains. (arXiv:2206.08083v1 [cs.CV])
33. Reinforcement Learning-enhanced Shared-account Cross-domain Sequential Recommendation. (arXiv:2206.08088v1 [cs.IR])
34. Closed-Form Diffeomorphic Transformations for Time Series Alignment. (arXiv:2206.08107v1 [cs.LG])
35. Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline. (arXiv:2206.08129v1 [cs.CV])
36. Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification. (arXiv:2206.08138v1 [cs.LG])
37. K-Radar: 4D Radar Object Detection Dataset and Benchmark for Autonomous Driving in Various Weather Conditions. (arXiv:2206.08171v1 [cs.CV])
38. Nucleus Segmentation and Analysis in Breast Cancer with the MIScnn Framework. (arXiv:2206.08182v1 [cs.CV])
39. UAVs Beneath the Surface: Cooperative Autonomy for Subterranean Search and Rescue in DARPA SubT. (arXiv:2206.08185v1 [cs.RO])
40. Asymptotic Soft Cluster Pruning for Deep Neural Networks. (arXiv:2206.08186v1 [cs.CV])
41. Inherent Inconsistencies of Feature Importance. (arXiv:2206.08204v1 [cs.LG])
42. Deep Learning Architecture for Automatic Essay Scoring. (arXiv:2206.08232v1 [cs.CL])
43. Catastrophic overfitting is a bug but also a feature. (arXiv:2206.08242v1 [cs.LG])
44. 'John ate 5 apples' != 'John ate some apples': Self-Supervised Paraphrase Quality Detection for Algebraic Word Problems. (arXiv:2206.08263v1 [cs.CL])
45. Towards the Generation of Musical Explanations with GPT-3. (arXiv:2206.08264v1 [cs.CL])
46. ANGLEr: A Next-Generation Natural Language Exploratory Framework. (arXiv:2206.08266v1 [cs.CL])
47. The Road to a Successful HRI: AI, Trust and ethicS-TRAITS. (arXiv:2206.08270v1 [cs.RO])
48. Alternative models: Critical examination of disability definitions in the development of artificial intelligence technologies. (arXiv:2206.08287v1 [cs.AI])
49. Switchable Representation Learning Framework with Self-compatibility. (arXiv:2206.08289v1 [cs.AI])
50. Equivariant Descriptor Fields: SE(3)-Equivariant Energy-Based Models for End-to-End Visual Robotic Manipulation Learning. (arXiv:2206.08321v1 [cs.RO])
51. Characteristics of Harmful Text: Towards Rigorous Benchmarking of Language Models. (arXiv:2206.08325v1 [cs.CL])
52. BYOL-Explore: Exploration by Bootstrapped Prediction. (arXiv:2206.08332v1 [cs.LG])
53. Know your audience: specializing grounded language models with the game of Dixit. (arXiv:2206.08349v1 [cs.LG])
54. OmniMAE: Single Model Masked Pretraining on Images and Videos. (arXiv:2206.08356v1 [cs.CV])
55. MixGen: A New Multi-Modal Data Augmentation. (arXiv:2206.08358v1 [cs.CV])
56. Benchmarking Heterogeneous Treatment Effect Models through the Lens of Interpretability. (arXiv:2206.08363v1 [cs.LG])
57. Interaction-Grounded Learning with Action-inclusive Feedback. (arXiv:2206.08364v1 [cs.LG])
58. Scalable First-Order Bayesian Optimization via Structured Automatic Differentiation. (arXiv:2206.08366v1 [cs.LG])
59. Learning Models of Individual Behavior in Chess. (arXiv:2008.10086v3 [cs.AI] UPDATED)
60. Federated Learning on the Road: Autonomous Controller Design for Connected and Autonomous Vehicles. (arXiv:2102.03401v2 [eess.SY] UPDATED)
61. Topos and Stacks of Deep Neural Networks. (arXiv:2106.14587v3 [math.AT] UPDATED)
62. Classical Planning in Deep Latent Space. (arXiv:2107.00110v3 [cs.AI] UPDATED)
63. Estimating Categorical Counterfactuals via Deep Twin Networks. (arXiv:2109.01904v4 [cs.LG] UPDATED)
64. LSB: Local Self-Balancing MCMC in Discrete Spaces. (arXiv:2109.03867v3 [cs.AI] UPDATED)
65. Mutual Consistency Learning for Semi-supervised Medical Image Segmentation. (arXiv:2109.09960v3 [cs.CV] UPDATED)
66. Multi-Objective Bayesian Optimization over High-Dimensional Search Spaces. (arXiv:2109.10964v4 [cs.LG] UPDATED)
67. TAG: Toward Accurate Social Media Content Tagging with a Concept Graph. (arXiv:2110.06892v4 [cs.LG] UPDATED)
68. Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks. (arXiv:2110.06904v2 [cs.CR] UPDATED)
69. CausalAF: Causal Autoregressive Flow for Safety-Critical Driving Scenario Generation. (arXiv:2110.13939v2 [cs.CV] UPDATED)
70. Masked-attention Mask Transformer for Universal Image Segmentation. (arXiv:2112.01527v3 [cs.CV] UPDATED)
71. Wild ToFu: Improving Range and Quality of Indirect Time-of-Flight Depth with RGB Fusion in Challenging Environments. (arXiv:2112.03750v2 [cs.CV] UPDATED)
72. A Review for Deep Reinforcement Learning in Atari:Benchmarks, Challenges, and Solutions. (arXiv:2112.04145v4 [cs.AI] UPDATED)
73. Deep Reinforcement Learning, a textbook. (arXiv:2201.02135v3 [cs.AI] UPDATED)
74. BandMaxSAT: A Local Search MaxSAT Solver with Multi-armed Bandit. (arXiv:2201.05544v2 [cs.AI] UPDATED)
75. Convergence of Policy Gradient for Entropy Regularized MDPs with Neural Network Approximation in the Mean-Field Regime. (arXiv:2201.07296v2 [math.OC] UPDATED)
76. Flowformer: Linearizing Transformers with Conservation Flows. (arXiv:2202.06258v2 [cs.LG] UPDATED)
77. Off-Policy Evaluation for Large Action Spaces via Embeddings. (arXiv:2202.06317v2 [cs.LG] UPDATED)
78. General Cyclical Training of Neural Networks. (arXiv:2202.08835v2 [cs.LG] UPDATED)
79. Cyclical Focal Loss. (arXiv:2202.08978v2 [cs.CV] UPDATED)
80. Hierarchical Interpretation of Neural Text Classification. (arXiv:2202.09792v2 [cs.CL] UPDATED)
81. Knowledge Graph-Enabled Text-Based Automatic Personality Prediction. (arXiv:2203.09103v2 [cs.CL] UPDATED)
82. Data Smells: Categories, Causes and Consequences, and Detection of Suspicious Data in AI-based Systems. (arXiv:2203.10384v3 [cs.SE] UPDATED)
83. STUDIES: Corpus of Japanese Empathetic Dialogue Speech Towards Friendly Voice Agent. (arXiv:2203.14757v2 [cs.SD] UPDATED)
84. Handling sign language transcription system with the computer-friendly numerical multilabels. (arXiv:2204.06924v3 [cs.CL] UPDATED)
85. Causal discovery under a confounder blanket. (arXiv:2205.05715v2 [stat.ME] UPDATED)
86. Generalizing to Evolving Domains with Latent Structure-Aware Sequential Autoencoder. (arXiv:2205.07649v2 [cs.LG] UPDATED)
87. DDXPlus: A New Dataset For Automatic Medical Diagnosis. (arXiv:2205.09148v2 [cs.CL] UPDATED)
88. Fast and Accurate Error Simulation for CNNs against Soft Errors. (arXiv:2206.02051v2 [cs.AR] UPDATED)
89. Generalized Data Distribution Iteration. (arXiv:2206.03192v2 [cs.LG] UPDATED)
90. Diffeomorphic Counterfactuals with Generative Models. (arXiv:2206.05075v2 [cs.LG] UPDATED)
91. Virtual embeddings and self-consistency for self-supervised learning. (arXiv:2206.06023v2 [cs.CV] UPDATED)
92. On Provably Robust Meta-Bayesian Optimization. (arXiv:2206.06872v2 [cs.LG] UPDATED)
93. S$^2$-FPN: Scale-ware Strip Attention Guided Feature Pyramid Network for **Real-time** Semantic Segmentation. (arXiv:2206.07298v2 [cs.CV] UPDATED)
94. The Emotion is Not One-hot Encoding: Learning with Grayscale Label for Emotion Recognition in Conversation. (arXiv:2206.07359v2 [cs.CL] UPDATED)

