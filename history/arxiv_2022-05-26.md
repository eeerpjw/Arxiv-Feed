# Your interest papers
---
## cs.CV
---
### A Lightweight NMS-free Framework for **Real-time** Visual Fault Detection System of Freight Trains. (arXiv:2205.12458v1 [cs.CV])
- Authors : Guodong Sun, Yang Zhou, Huilin Pan, Bo Wu, Ye Hu, Yang Zhang
- Link : [http://arxiv.org/abs/2205.12458](http://arxiv.org/abs/2205.12458)
> ABSTRACT  :  **Real-time** vision-based system of fault detection (RVBS-FD) for freight trains is an essential part of ensuring railway transportation safety. Most existing vision-based methods still have high computational costs based on convolutional neural networks. The computational cost is mainly reflected in the backbone, neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper, we propose a lightweight NMS-free framework to achieve real-time detection and high accuracy simultaneously. First, we use a lightweight backbone for feature extraction and design a fault detection pyramid to process features. This fault detection pyramid includes three novel individual modules using attention mechanism, bottleneck, and dilated convolution for feature **enhancement** and computation reduction. Instead of using NMS, we calculate different loss functions, including classification and location costs in the detection head, to further reduce computation. Experimental results show that our framework achieves over 83 frames per second speed with a smaller model size and higher accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource requirements of our method are low during the training and testing process.  
### Efficient Textured Mesh Recovery from Multiple Views with Differentiable Rendering. (arXiv:2205.12468v1 [cs.CV])
- Authors : Lixiang Lin, Yisu Zhang, Jianke Zhu
- Link : [http://arxiv.org/abs/2205.12468](http://arxiv.org/abs/2205.12468)
> ABSTRACT  :  Despite of the promising results on shape and color recovery using self-supervision, the multi-layer perceptrons-based methods usually costs hours to train the deep neural network due to the implicit surface representation. Moreover, it is quite computational intensive to render a single image, since a forward network inference is required for each pixel. To tackle these challenges, in this paper, we propose an efficient coarse-to-fine approach to recover the textured mesh from multi-view images. Specifically, we take advantage of a differentiable Poisson Solver to represent the shape, which is able to produce topology-agnostic and watertight surfaces. To account for the depth information, we optimize the shape geometry by minimizing the difference between the rendered mesh with the depth predicted by the learning-based multi-view stereo algorithm. In contrast to the **implicit neural representation** on shape and color, we introduce a physically based inverse rendering scheme to jointly estimate the lighting and reflectance of the objects, which is able to render the high resolution image at real-time. Additionally, we fine-tune the extracted mesh by inverse rendering to obtain the mesh with fine details and high fidelity image. We have conducted the extensive experiments on several multi-view stereo datasets, whose promising results demonstrate the efficacy of our proposed approach. We will make our full implementation publicly available.  
### Guiding Visual Question Answering with Attention Priors. (arXiv:2205.12616v1 [cs.CV])
- Authors : Thao Minh, Vuong Le, Sunil Gupta, Svetha Venkatesh, Truyen Tran
- Link : [http://arxiv.org/abs/2205.12616](http://arxiv.org/abs/2205.12616)
> ABSTRACT  :  The current success of modern visual reasoning systems is arguably attributed to cross-modality attention mechanisms. However, in deliberative reasoning such as in VQA, attention is unconstrained at each step, and thus may serve as a statistical pooling mechanism rather than a semantic operation intended to select information relevant to inference. This is because at training time, attention is only guided by a very sparse signal (i.e. the answer label) at the end of the inference chain. This causes the cross-modality attention weights to deviate from the desired visual-language bindings. To rectify this deviation, we propose to guide the attention mechanism using explicit linguistic-visual grounding. This grounding is derived by connecting structured linguistic concepts in the query to their referents among the visual objects. Here we learn the grounding from the pairing of questions and images alone, without the need for answer annotation or external grounding supervision. This grounding guides the attention mechanism inside VQA models through a duality of mechanisms: pre-training attention weight calculation and directly guiding the weights at inference time on a case-by-case basis. The resultant algorithm is capable of probing attention-based reasoning models, injecting relevant associative knowledge, and regulating the core reasoning process. This scalable **enhancement** improves the performance of VQA models, fortifies their robustness to limited access to supervised data, and increases interpretability.  
### NTIRE 2022 Challenge on **High Dynamic Range** Imaging: Methods and Results. (arXiv:2205.12633v1 [cs.CV])
- Authors : Sibi Catley, Richard Shaw, Radu Timofte, Zexin Zhang, Cen Liu, Yunbo Peng, Yue Lin, Gaocheng Yu, Jin Zhang, Zhe Ma, Hongbin Wang, Xiangyu Chen, Xintao Wang, Haiwei Wu, Lin Liu, Chao Dong, Jiantao Zhou, Qingsen Yan, Song Zhang, Weiye Chen, Yuhang Liu, Zhen Zhang, Yanning Zhang, Javen Qinfeng, Dong Gong, Dan Zhu, Mengdi Sun, Guannan Chen, Yang Hu, Haowei Li, Baozhu Zou, Zhen Liu, Wenjie Lin, Ting Jiang, Chengzhi Jiang, Xinpeng Li, Mingyan Han, Haoqiang Fan, Jian Sun, Shuaicheng Liu, Juan Mar, Michael Sloth, Peter Schneider, Chunyang Li, Long Bao, Gang He, Ziyao Xu, Li Xu, Gen Zhan, Ming Sun, Xing Wen, Junlin Li, Jinjing Li, Chenghua Li, Ruipeng Gang, Fangya Li, Chenming Liu, Shuang Feng, Fei Lei, et al, additional authors, not shown
- Link : [http://arxiv.org/abs/2205.12633](http://arxiv.org/abs/2205.12633)
> ABSTRACT  :  This paper reviews the challenge on constrained **high dynamic range** (**HDR**) imaging that was part of the New Trends in Image **Restoration** and **Enhancement** (NTIRE) workshop, held in conjunction with CVPR 2022. This manuscript focuses on the competition set-up, datasets, the proposed methods and their results. The challenge aims at estimating an **HDR** image from multiple respective low dynamic range (LDR) observations, which might suffer from under- or over-exposed regions and different sources of noise. The challenge is composed of two tracks with an emphasis on fidelity and complexity constraints: In Track 1, participants are asked to optimize objective fidelity scores while imposing a low-complexity constraint (i.e. solutions can not exceed a given number of operations). In Track 2, participants are asked to minimize the complexity of their solutions while imposing a constraint on fidelity scores (i.e. solutions are required to obtain a higher fidelity score than the prescribed baseline). Both tracks use the same data and metrics: Fidelity is measured by means of PSNR with respect to a ground-truth **HDR** image (computed both directly and with a canonical tonemapping operation), while complexity metrics include the number of Multiply-Accumulate (MAC) operations and runtime (in seconds).  
### TreEnhance: An Automatic Tree-Search Based Method for Low-Light Image **Enhancement**. (arXiv:2205.12639v1 [cs.CV])
- Authors : Marco Cotogni, Claudio Cusano
- Link : [http://arxiv.org/abs/2205.12639](http://arxiv.org/abs/2205.12639)
> ABSTRACT  :  In this paper we present TreEnhance, an automatic method for **low-light** image **enhancement** capable of improving the quality of digital images. The method combines tree search theory, and in particular the Monte Carlo Tree Search (MCTS) algorithm, with deep reinforcement learning. Given as input a **low-light** image, TreEnhance produces as output its enhanced version together with the sequence of image editing operations used to obtain it. The method repeatedly alternates two main phases. In the generation phase a modified version of MCTS explores the space of image editing operations and selects the most promising sequence. In the optimization phase the parameters of a neural network, implementing the **enhancement** policy, are updated. After training, two different inference solutions are proposed for the **enhancement** of new images: one is based on MCTS and is more accurate but more time and memory consuming; the other directly applies the learned policy and is faster but slightly less precise. Unlike other methods from the state of the art, TreEnhance does not pose any constraint on the image resolution and can be used in a variety of scenarios with minimal tuning. We tested the method on two datasets: the Low-Light dataset and the Adobe Five-K dataset obtaining good results from both a qualitative and a quantitative point of view.  
### Context-Aware Video Reconstruction for Rolling Shutter Cameras. (arXiv:2205.12912v1 [cs.CV])
- Authors : Bin Fan, Yuchao Dai, Zhiyuan Zhang, Qi Liu, Mingyi He
- Link : [http://arxiv.org/abs/2205.12912](http://arxiv.org/abs/2205.12912)
> ABSTRACT  :  With the ubiquity of rolling shutter (RS) cameras, it is becoming increasingly attractive to recover the latent global shutter (GS) video from two consecutive RS frames, which also places a higher demand on realism. Existing solutions, using deep neural networks or optimization, achieve promising performance. However, these methods generate intermediate GS frames through image warping based on the RS model, which inevitably result in black holes and noticeable motion artifacts. In this paper, we alleviate these issues by proposing a context-aware GS video reconstruction architecture. It facilitates the advantages such as occlusion reasoning, motion compensation, and temporal abstraction. Specifically, we first estimate the **bilateral** motion field so that the pixels of the two RS frames are warped to a common GS frame accordingly. Then, a refinement scheme is proposed to guide the GS frame synthesis along with **bilateral** occlusion masks to produce high-fidelity GS video frames at arbitrary times. Furthermore, we derive an approximated **bilateral** motion field model, which can serve as an alternative to provide a simple but effective GS frame initialization for related tasks. Experiments on synthetic and real data show that our approach achieves superior performance over state-of-the-art methods in terms of objective metrics and subjective visual quality. Code is available at \url{https://github.com/GitCVfb/CVR}.  
### Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
- Authors : Chenyang Si, Weihao Yu, Pan Zhou, Yichen Zhou, Xinchao Wang, Shuicheng Yan
- Link : [http://arxiv.org/abs/2205.12956](http://arxiv.org/abs/2205.12956)
> ABSTRACT  :  Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to Transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e. gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model **Swin**-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at https://github.com/sail-sg/iFormer.  
### Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction. (arXiv:2111.15119v3 [cs.CV] UPDATED)
- Authors : Lingbo Liu, Zewei Yang, Guanbin Li, Kuo Wang, Tianshui Chen, Liang Lin
- Link : [http://arxiv.org/abs/2111.15119](http://arxiv.org/abs/2111.15119)
> ABSTRACT  :  Land remote sensing analysis is a crucial research in earth science. In this work, we focus on a challenging task of land analysis, i.e., automatic extraction of traffic roads from remote sensing data, which has widespread applications in urban development and expansion estimation. Nevertheless, conventional methods either only utilized the limited information of aerial images, or simply fused multimodal information (e.g., vehicle trajectories), thus cannot well recognize unconstrained roads. To facilitate this problem, we introduce a novel neural network framework termed Cross-Modal Message Propagation Network (CMMPNet), which fully benefits the complementary different modal data (i.e., aerial images and crowdsourced trajectories). Specifically, CMMPNet is composed of two deep Auto-Encoders for modality-specific representation learning and a tailor-designed Dual **Enhancement** Module for cross-modal representation refinement. In particular, the complementary information of each modality is comprehensively extracted and dynamically propagated to enhance the representation of another modality. Extensive experiments on three real-world benchmarks demonstrate the effectiveness of our CMMPNet for robust road extraction benefiting from blending different modal data, either using image and trajectory data or image and Lidar data. From the experimental results, we observe that the proposed approach outperforms current state-of-the-art methods by large margins.Our source code is resealed on the project page <a href="http://lingboliu.com/multimodal_road_extraction.html.">this http URL</a>  
### Active Domain Adaptation with Multi-level Contrastive Units for Semantic Segmentation. (arXiv:2205.11192v2 [cs.CV] UPDATED)
- Authors : Hao Zhang, Ruimao Zhang, Zhanglin Peng, Junle Wang, Yanqing Jing
- Link : [http://arxiv.org/abs/2205.11192](http://arxiv.org/abs/2205.11192)
> ABSTRACT  :  To further reduce the cost of semi-supervised domain adaptation (SSDA) labeling, a more effective way is to use active learning (AL) to annotate a selected subset with specific properties. However, domain adaptation tasks are always addressed in two interactive aspects: domain transfer and the **enhancement** of discrimination, which requires the selected data to be both uncertain under the model and diverse in feature space. Contrary to active learning in classification tasks, it is usually challenging to select pixels that contain both the above properties in segmentation tasks, leading to the complex design of pixel selection strategy. To address such an issue, we propose a novel Active Domain Adaptation scheme with Multi-level Contrastive Units (ADA-MCU) for semantic image segmentation. A simple pixel selection strategy followed with the construction of multi-level contrastive units is introduced to optimize the model for both domain adaptation and active supervised learning. In practice, MCUs are constructed from intra-image, cross-image, and cross-domain levels by using both labeled and unlabeled pixels. At each level, we define contrastive losses from center-to-center and pixel-to-pixel manners, with the aim of jointly aligning the category centers and reducing outliers near the decision boundaries. In addition, we also introduce a categories correlation matrix to implicitly describe the relationship between categories, which are used to adjust the weights of the losses for MCUs. Extensive experimental results on standard benchmarks show that the proposed method achieves competitive performance against state-of-the-art SSDA methods with 50% fewer labeled pixels and significantly outperforms state-of-the-art with a large margin by using the same level of annotation cost.  
### Stylized**NeRF**: Consistent 3D Scene Stylization as Stylized **NeRF** via 2D-3D Mutual Learning. (arXiv:2205.12183v2 [cs.GR] UPDATED)
- Authors : Hua Huang, Yue He, Jie Yuan, Kun Lai, Lin Gao
- Link : [http://arxiv.org/abs/2205.12183](http://arxiv.org/abs/2205.12183)
> ABSTRACT  :  3D scene stylization aims at generating stylized images of the scene from arbitrary novel views following a given set of style examples, while ensuring consistency when rendered from different views. Directly applying methods for image or video stylization to 3D scenes cannot achieve such consistency. Thanks to recently proposed neural radiance fields (**NeRF**), we are able to represent a 3D scene in a consistent way. Consistent 3D scene stylization can be effectively achieved by stylizing the corresponding **NeRF**. However, there is a significant domain gap between style examples which are 2D images and **NeRF** which is an implicit volumetric representation. To address this problem, we propose a novel mutual learning framework for 3D scene stylization that combines a 2D image stylization network and **NeRF** to fuse the stylization ability of 2D stylization network with the 3D consistency of **NeRF**. We first pre-train a standard **NeRF** of the 3D scene to be stylized and replace its color prediction module with a style network to obtain a stylized **NeRF**. It is followed by distilling the prior knowledge of spatial consistency from **NeRF** to the 2D stylization network through an introduced consistency loss. We also introduce a mimic loss to supervise the mutual learning of the **NeRF** style module and fine-tune the 2D stylization decoder. In order to further make our model handle ambiguities of 2D stylization results, we introduce learnable latent codes that obey the probability distributions conditioned on the style. They are attached to training samples as conditional inputs to better learn the style module in our novel stylized **NeRF**. Experimental results demonstrate that our method is superior to existing approaches in both visual quality and long-range consistency.  
## eess.IV
---
### A Lightweight NMS-free Framework for **Real-time** Visual Fault Detection System of Freight Trains. (arXiv:2205.12458v1 [cs.CV])
- Authors : Guodong Sun, Yang Zhou, Huilin Pan, Bo Wu, Ye Hu, Yang Zhang
- Link : [http://arxiv.org/abs/2205.12458](http://arxiv.org/abs/2205.12458)
> ABSTRACT  :  **Real-time** vision-based system of fault detection (RVBS-FD) for freight trains is an essential part of ensuring railway transportation safety. Most existing vision-based methods still have high computational costs based on convolutional neural networks. The computational cost is mainly reflected in the backbone, neck, and post-processing, i.e., non-maximum suppression (NMS). In this paper, we propose a lightweight NMS-free framework to achieve real-time detection and high accuracy simultaneously. First, we use a lightweight backbone for feature extraction and design a fault detection pyramid to process features. This fault detection pyramid includes three novel individual modules using attention mechanism, bottleneck, and dilated convolution for feature **enhancement** and computation reduction. Instead of using NMS, we calculate different loss functions, including classification and location costs in the detection head, to further reduce computation. Experimental results show that our framework achieves over 83 frames per second speed with a smaller model size and higher accuracy than the state-of-the-art detectors. Meanwhile, the hardware resource requirements of our method are low during the training and testing process.  
### NTIRE 2022 Challenge on **High Dynamic Range** Imaging: Methods and Results. (arXiv:2205.12633v1 [cs.CV])
- Authors : Sibi Catley, Richard Shaw, Radu Timofte, Zexin Zhang, Cen Liu, Yunbo Peng, Yue Lin, Gaocheng Yu, Jin Zhang, Zhe Ma, Hongbin Wang, Xiangyu Chen, Xintao Wang, Haiwei Wu, Lin Liu, Chao Dong, Jiantao Zhou, Qingsen Yan, Song Zhang, Weiye Chen, Yuhang Liu, Zhen Zhang, Yanning Zhang, Javen Qinfeng, Dong Gong, Dan Zhu, Mengdi Sun, Guannan Chen, Yang Hu, Haowei Li, Baozhu Zou, Zhen Liu, Wenjie Lin, Ting Jiang, Chengzhi Jiang, Xinpeng Li, Mingyan Han, Haoqiang Fan, Jian Sun, Shuaicheng Liu, Juan Mar, Michael Sloth, Peter Schneider, Chunyang Li, Long Bao, Gang He, Ziyao Xu, Li Xu, Gen Zhan, Ming Sun, Xing Wen, Junlin Li, Jinjing Li, Chenghua Li, Ruipeng Gang, Fangya Li, Chenming Liu, Shuang Feng, Fei Lei, et al, additional authors, not shown
- Link : [http://arxiv.org/abs/2205.12633](http://arxiv.org/abs/2205.12633)
> ABSTRACT  :  This paper reviews the challenge on constrained **high dynamic range** (**HDR**) imaging that was part of the New Trends in Image **Restoration** and **Enhancement** (NTIRE) workshop, held in conjunction with CVPR 2022. This manuscript focuses on the competition set-up, datasets, the proposed methods and their results. The challenge aims at estimating an **HDR** image from multiple respective low dynamic range (LDR) observations, which might suffer from under- or over-exposed regions and different sources of noise. The challenge is composed of two tracks with an emphasis on fidelity and complexity constraints: In Track 1, participants are asked to optimize objective fidelity scores while imposing a low-complexity constraint (i.e. solutions can not exceed a given number of operations). In Track 2, participants are asked to minimize the complexity of their solutions while imposing a constraint on fidelity scores (i.e. solutions are required to obtain a higher fidelity score than the prescribed baseline). Both tracks use the same data and metrics: Fidelity is measured by means of PSNR with respect to a ground-truth **HDR** image (computed both directly and with a canonical tonemapping operation), while complexity metrics include the number of Multiply-Accumulate (MAC) operations and runtime (in seconds).  
### These Maps Are Made For Walking: Real-Time Terrain Property Estimation for Mobile Robots. (arXiv:2205.12925v1 [cs.RO])
- Authors : Parker Ewen, Adam Li, Yuxin Chen, Steven Hong, Ram Vasudevan
- Link : [http://arxiv.org/abs/2205.12925](http://arxiv.org/abs/2205.12925)
> ABSTRACT  :  The equations of motion governing mobile robots are dependent on terrain properties such as the coefficient of friction, and contact model parameters. Estimating these properties is thus essential for robotic navigation. Ideally any map estimating terrain properties should run in **real time**, mitigate sensor noise, and provide probability distributions of the aforementioned properties, thus enabling risk-mitigating navigation and planning. This paper addresses these needs and proposes a Bayesian inference framework for semantic mapping which recursively estimates both the terrain surface profile and a probability distribution for terrain properties using data from a single RGB-D camera. The proposed framework is evaluated in simulation against other semantic mapping methods and is shown to outperform these state-of-the-art methods in terms of correctly estimating simulated ground-truth terrain properties when evaluated using a precision-recall curve and the Kullback-Leibler divergence test. Additionally, the proposed method is deployed on a physical legged robotic platform in both indoor and outdoor environments, and we show our method correctly predicts terrain properties in both cases. The proposed framework runs in real-time and includes a ROS interface for easy integration.  
## cs.LG
---
### Removing the fat from your posterior samples with margarine. (arXiv:2205.12841v1 [astro-ph.IM])
- Authors : Pablo Lemos, Eloy de, Lera Acedo, Anastasia Fialkov, Justin Alsing
- Link : [http://arxiv.org/abs/2205.12841](http://arxiv.org/abs/2205.12841)
> ABSTRACT  :  Bayesian workflows often require the introduction of nuisance parameters, yet for core science modelling one needs access to a marginal posterior density. In this work we use masked autoregressive flows and kernel density estimators to encapsulate the marginal posterior, allowing us to compute marginal Kullback-Leibler divergences and marginal Bayesian model dimensionalities in addition to generating samples and computing marginal log probabilities. We demonstrate this in application to topical cosmological examples of the **Dark** Energy Survey, and global 21cm signal experiments. In addition to the computation of marginal Bayesian statistics, this work is important for further applications in Bayesian experimental design, complex prior modelling and likelihood emulation. This technique is made publicly available in the pip-installable code margarine.  
### Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
- Authors : Chenyang Si, Weihao Yu, Pan Zhou, Yichen Zhou, Xinchao Wang, Shuicheng Yan
- Link : [http://arxiv.org/abs/2205.12956](http://arxiv.org/abs/2205.12956)
> ABSTRACT  :  Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to Transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e. gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model **Swin**-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at https://github.com/sail-sg/iFormer.  
### Training Heterogeneous Features in Sequence to Sequence Tasks: Latent Enhanced Multi-filter Seq2Seq Model. (arXiv:2105.08840v3 [cs.CL] UPDATED)
- Authors : Yunhao Yang, Zhaokun Xue
- Link : [http://arxiv.org/abs/2105.08840](http://arxiv.org/abs/2105.08840)
> ABSTRACT  :  In language processing, training data with extremely large variance may lead to difficulty in the language model's convergence. It is difficult for the network parameters to adapt sentences with largely varied semantics or grammatical structures. To resolve this problem, we introduce a model that concentrates the each of the heterogeneous features in the input sentences. Building upon the encoder-decoder architecture, we design a latent-enhanced multi-filter seq2seq model (LEMS) that analyzes the input representations by introducing a latent space transformation and clustering. The representations are extracted from the final hidden state of the encoder and lie in the latent space. A latent space transformation is applied for enhancing the quality of the representations. Thus the clustering algorithm can easily separate samples based on the features of these representations. Multiple filters are trained by the features from their corresponding clusters, and the heterogeneity of the training data can be resolved accordingly. We conduct two sets of comparative experiments on semantic parsing and machine translation, using the Geo-query dataset and Multi30k English-French to demonstrate the **enhancement** our model has made respectively.  
### What killed the Convex Booster ?. (arXiv:2205.09628v2 [cs.LG] UPDATED)
- Authors : Yishay Mansour, Richard Nock
- Link : [http://arxiv.org/abs/2205.09628](http://arxiv.org/abs/2205.09628)
> ABSTRACT  :  A landmark negative result of Long and Servedio established a worst-case spectacular failure of a supervised learning trio (loss, algorithm, model) otherwise praised for its high precision machinery. Hundreds of papers followed up on the two suspected culprits: the loss (for being convex) and/or the algorithm (for fitting a classical boosting blueprint). Here, we call to the half-century+ founding theory of losses for class probability estimation (properness), an extension of Long and Servedio's results and a new general boosting algorithm to demonstrate that the real culprit in their specific context was in fact the (linear) model class. We advocate for a more general stanpoint on the problem as we argue that the source of the negative result lies in the **dark** side of a pervasive -- and otherwise prized -- aspect of ML: \textit{parameterisation}.  
## cs.AI
---
### Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
- Authors : Chenyang Si, Weihao Yu, Pan Zhou, Yichen Zhou, Xinchao Wang, Shuicheng Yan
- Link : [http://arxiv.org/abs/2205.12956](http://arxiv.org/abs/2205.12956)
> ABSTRACT  :  Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high- and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of convolution and max-pooling for capturing the high-frequency information to Transformers. Different from recent hybrid frameworks, the Inception mixer brings greater efficiency through a channel splitting mechanism to adopt parallel convolution/max-pooling path and self-attention path as high- and low-frequency mixers, while having the flexibility to model discriminative information scattered within a wide frequency range. Considering that bottom layers play more roles in capturing high-frequency details while top layers more in modeling low-frequency global information, we further introduce a frequency ramp structure, i.e. gradually decreasing the dimensions fed to the high-frequency mixer and increasing those to the low-frequency mixer, which can effectively trade-off high- and low-frequency components across different layers. We benchmark the iFormer on a series of vision tasks, and showcase that it achieves impressive performance on image classification, COCO detection and ADE20K segmentation. For example, our iFormer-S hits the top-1 accuracy of 83.4% on ImageNet-1K, much higher than DeiT-S by 3.6%, and even slightly better than much bigger model **Swin**-B (83.3%) with only 1/4 parameters and 1/3 FLOPs. Code and models will be released at https://github.com/sail-sg/iFormer.  
### Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction. (arXiv:2111.15119v3 [cs.CV] UPDATED)
- Authors : Lingbo Liu, Zewei Yang, Guanbin Li, Kuo Wang, Tianshui Chen, Liang Lin
- Link : [http://arxiv.org/abs/2111.15119](http://arxiv.org/abs/2111.15119)
> ABSTRACT  :  Land remote sensing analysis is a crucial research in earth science. In this work, we focus on a challenging task of land analysis, i.e., automatic extraction of traffic roads from remote sensing data, which has widespread applications in urban development and expansion estimation. Nevertheless, conventional methods either only utilized the limited information of aerial images, or simply fused multimodal information (e.g., vehicle trajectories), thus cannot well recognize unconstrained roads. To facilitate this problem, we introduce a novel neural network framework termed Cross-Modal Message Propagation Network (CMMPNet), which fully benefits the complementary different modal data (i.e., aerial images and crowdsourced trajectories). Specifically, CMMPNet is composed of two deep Auto-Encoders for modality-specific representation learning and a tailor-designed Dual **Enhancement** Module for cross-modal representation refinement. In particular, the complementary information of each modality is comprehensively extracted and dynamically propagated to enhance the representation of another modality. Extensive experiments on three real-world benchmarks demonstrate the effectiveness of our CMMPNet for robust road extraction benefiting from blending different modal data, either using image and trajectory data or image and Lidar data. From the experimental results, we observe that the proposed approach outperforms current state-of-the-art methods by large margins.Our source code is resealed on the project page <a href="http://lingboliu.com/multimodal_road_extraction.html.">this http URL</a>  
# Paper List
---
## cs.CV
---
**100** new papers in cs.CV:-) 
1. Action Recognition for American Sign Language. (arXiv:2205.12261v1 [cs.CV])
2. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v1 [cs.CV])
3. Trajectory Optimization for Physics-Based Reconstruction of 3d Human Pose from Monocular Video. (arXiv:2205.12292v1 [cs.CV])
4. Face2Text revisited: Improved data set and baseline results. (arXiv:2205.12342v1 [cs.CV])
5. A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection. (arXiv:2205.12358v1 [cs.CV])
6. Jointly Optimizing Color Rendition and In-Camera Backgrounds in an RGB Virtual Production Stage. (arXiv:2205.12403v1 [cs.CV])
7. Convolutional Neural Processes for Inpainting Satellite Images. (arXiv:2205.12407v1 [cs.CV])
8. Interaction of a priori Anatomic Knowledge with Self-Supervised Contrastive Learning in Cardiac Magnetic Resonance Imaging. (arXiv:2205.12429v1 [eess.IV])
9. Skin Cancer Diagnostics with an All-Inclusive Smartphone Application. (arXiv:2205.12438v1 [eess.IV])
10. Cross-Domain Style Mixing for Face Cartoonization. (arXiv:2205.12450v1 [cs.CV])
11. Region-aware Knowledge Distillation for Efficient Image-to-Image Translation. (arXiv:2205.12451v1 [cs.CV])
12. A Lightweight NMS-free Framework for **Real-time** Visual Fault Detection System of Freight Trains. (arXiv:2205.12458v1 [cs.CV])
13. A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral Image Classification. (arXiv:2205.12459v1 [cs.CV])
14. sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite Images. (arXiv:2205.12464v1 [cs.CV])
15. Eye-gaze-guided Vision Transformer for Rectifying Shortcut Learning. (arXiv:2205.12466v1 [cs.CV])
16. Efficient Textured Mesh Recovery from Multiple Views with Differentiable Rendering. (arXiv:2205.12468v1 [cs.CV])
17. The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training. (arXiv:2205.12502v1 [cs.CV])
18. Text-to-Face Generation with StyleGAN2. (arXiv:2205.12512v1 [cs.CV])
19. Structure Aware and Class Balanced 3D Object Detection on nuScenes Dataset. (arXiv:2205.12519v1 [cs.CV])
20. Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset. (arXiv:2205.12522v1 [cs.CV])
21. Accelerating Diffusion Models via Early Stop of the Diffusion Process. (arXiv:2205.12524v1 [cs.CV])
22. Structured Uncertainty in the Observation Space of Variational Autoencoders. (arXiv:2205.12533v1 [cs.LG])
23. Misleading Deep-Fake Detection with GAN Fingerprints. (arXiv:2205.12543v1 [cs.CV])
24. Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual Localization. (arXiv:2205.12544v1 [cs.CV])
25. Some equivalence relation between persistent homology and morphological dynamics. (arXiv:2205.12546v1 [cs.CV])
26. Breaking the Chain of Gradient Leakage in Vision Transformers. (arXiv:2205.12551v1 [cs.CV])
27. Spotlights: Probing Shapes from Spherical Viewpoints. (arXiv:2205.12564v1 [cs.CV])
28. From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets. (arXiv:2205.12579v1 [cs.CV])
29. MUG: Multi-human Graph Network for 3D Mesh Reconstruction from 2D Pose. (arXiv:2205.12583v1 [cs.CV])
30. Deniable Steganography. (arXiv:2205.12587v1 [cs.CR])
31. VTP: Volumetric Transformer for Multi-view Multi-person 3D Pose Estimation. (arXiv:2205.12602v1 [cs.CV])
32. ReSmooth: Detecting and Utilizing OOD Samples when Training with Data Augmentation. (arXiv:2205.12606v1 [cs.CV])
33. Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment Outcomes. (arXiv:2205.12611v1 [cs.CV])
34. Guiding Visual Question Answering with Attention Priors. (arXiv:2205.12616v1 [cs.CV])
35. DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation. (arXiv:2205.12617v1 [cs.CL])
36. Location-free Human Pose Estimation. (arXiv:2205.12619v1 [cs.CV])
37. Primitive3D: 3D Object Dataset Synthesis from Randomly Assembled Primitives. (arXiv:2205.12627v1 [cs.CV])
38. Multimodal Knowledge Alignment with Reinforcement Learning. (arXiv:2205.12630v1 [cs.CL])
39. NTIRE 2022 Challenge on **High Dynamic Range** Imaging: Methods and Results. (arXiv:2205.12633v1 [cs.CV])
40. Real-Time Video Deblurring via Lightweight Motion Compensation. (arXiv:2205.12634v1 [cs.CV])
41. MoCoViT: Mobile Convolutional Vision Transformer. (arXiv:2205.12635v1 [cs.CV])
42. TreEnhance: An Automatic Tree-Search Based Method for Low-Light Image **Enhancement**. (arXiv:2205.12639v1 [cs.CV])
43. UniInst: Unique Representation for End-to-End Instance Segmentation. (arXiv:2205.12646v1 [cs.CV])
44. Contrastive Learning with Boosted Memorization. (arXiv:2205.12693v1 [cs.CV])
45. COVID-19 Severity Classification on Chest X-ray Images. (arXiv:2205.12705v1 [eess.IV])
46. SIoU Loss: More Powerful Learning for Bounding Box Regression. (arXiv:2205.12740v1 [cs.CV])
47. An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation. (arXiv:2205.12753v1 [cs.CV])
48. An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems. (arXiv:2205.12755v1 [cs.LG])
49. AO2-DETR: Arbitrary-Oriented Object Detection Transformer. (arXiv:2205.12785v1 [cs.CV])
50. Non-rigid Point Cloud Registration with Neural Deformation Pyramid. (arXiv:2205.12796v1 [cs.CV])
51. DistillAdapt: Source-Free Active Visual Domain Adaptation. (arXiv:2205.12840v1 [cs.CV])
52. A Comparative Study of Gastric Histopathology Sub-size Image Classification: from Linear Regression to Visual Transformer. (arXiv:2205.12843v1 [eess.IV])
53. Deep Gradient Learning for Efficient Camouflaged Object Detection. (arXiv:2205.12853v1 [cs.CV])
54. Structure Unbiased Adversarial Model for Medical Image Segmentation. (arXiv:2205.12857v1 [eess.IV])
55. Image Colorization using U-Net with Skip Connections and Fusion Layer on Landscape Images. (arXiv:2205.12867v1 [cs.CV])
56. Open-Domain Sign Language Translation Learned from Online Video. (arXiv:2205.12870v1 [cs.CV])
57. You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos. (arXiv:2205.12886v1 [cs.CV])
58. RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v1 [eess.IV])
59. Context-Aware Video Reconstruction for Rolling Shutter Cameras. (arXiv:2205.12912v1 [cs.CV])
60. A Low Memory Footprint Quantized Neural Network for Depth Completion of Very Sparse Time-of-Flight Depth Maps. (arXiv:2205.12918v1 [cs.CV])
61. DH-GAN: A Physics-driven Untrained Generative Adversarial Network for 3D Microscopic Imaging using Digital Holography. (arXiv:2205.12920v1 [cs.IR])
62. Domain Adaptation for Object Detection using SE Adaptors and Center Loss. (arXiv:2205.12923v1 [cs.CV])
63. Pretraining is All You Need for Image-to-Image Translation. (arXiv:2205.12952v1 [cs.CV])
64. Neural 3D Reconstruction in the Wild. (arXiv:2205.12955v1 [cs.CV])
65. Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
66. LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation Function for Neural Networks. (arXiv:1901.05894v3 [cs.CV] UPDATED)
67. Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v6 [cs.CV] UPDATED)
68. RELLIS-3D Dataset: Data, Benchmarks and Analysis. (arXiv:2011.12954v4 [cs.CV] UPDATED)
69. 3D Object Detection for Autonomous Driving: A Survey. (arXiv:2106.10823v3 [cs.CV] UPDATED)
70. Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v4 [cs.LG] UPDATED)
71. Temporal Action Localization Using Gated Recurrent Units. (arXiv:2108.03375v2 [cs.CV] UPDATED)
72. Learning Foveated Reconstruction to Preserve Perceived Image Statistics. (arXiv:2108.03499v2 [cs.GR] UPDATED)
73. PVT: Point-Voxel Transformer for Point Cloud Learning. (arXiv:2108.06076v4 [cs.CV] UPDATED)
74. Learning JPEG Compression Artifacts for Image Manipulation Detection and Localization. (arXiv:2108.12947v2 [eess.IV] UPDATED)
75. Deep Kernel Representation for Image Reconstruction in PET. (arXiv:2110.01174v4 [eess.IV] UPDATED)
76. Do we still need ImageNet pre-training in remote sensing scene classification?. (arXiv:2111.03690v3 [cs.CV] UPDATED)
77. Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction. (arXiv:2111.15119v3 [cs.CV] UPDATED)
78. Temporally Resolution Decrement: Utilizing the Shape Consistency for Higher Computational Efficiency. (arXiv:2112.00954v2 [cs.CV] UPDATED)
79. Investigating the usefulness of Quantum Blur. (arXiv:2112.01646v2 [cs.CV] UPDATED)
80. Self-Paced Deep Regression Forests with Consideration on Ranking Fairness. (arXiv:2112.06455v7 [cs.CV] UPDATED)
81. Attention-based Proposals Refinement for 3D Object Detection. (arXiv:2201.07070v3 [cs.CV] UPDATED)
82. Self-Supervised Scene Flow Estimation with 4D Automotive Radar. (arXiv:2203.01137v2 [cs.CV] UPDATED)
83. A Tree-Structured Multi-Task Model Recommender. (arXiv:2203.05092v2 [cs.LG] UPDATED)
84. Text2LIVE: Text-Driven Layered Image and Video Editing. (arXiv:2204.02491v2 [cs.CV] UPDATED)
85. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v3 [eess.IV] UPDATED)
86. Controllable Image Captioning. (arXiv:2204.13324v4 [cs.CV] UPDATED)
87. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v2 [q-bio.GN] UPDATED)
88. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v2 [cs.CV] UPDATED)
89. From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model. (arXiv:2205.00690v2 [cs.LG] UPDATED)
90. FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning. (arXiv:2205.07246v2 [cs.LG] UPDATED)
91. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v3 [cs.LG] UPDATED)
92. VNT-Net: Rotational Invariant Vector Neuron Transformers. (arXiv:2205.09690v2 [cs.CV] UPDATED)
93. People Tracking and Re-Identifying in Distributed Contexts: Extension Study of PoseTReID. (arXiv:2205.10086v2 [cs.CV] UPDATED)
94. muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems. (arXiv:2205.10937v2 [cs.LG] UPDATED)
95. NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images. (arXiv:2205.11191v2 [cs.CV] UPDATED)
96. Active Domain Adaptation with Multi-level Contrastive Units for Semantic Segmentation. (arXiv:2205.11192v2 [cs.CV] UPDATED)
97. Discriminative Feature Learning through Feature Distance Loss. (arXiv:2205.11606v2 [cs.CV] UPDATED)
98. Diffuse Map Guiding Unsupervised Generative Adversarial Network for SVBRDF Estimation. (arXiv:2205.11951v2 [cs.CV] UPDATED)
99. mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections. (arXiv:2205.12005v2 [cs.CL] UPDATED)
100. Stylized**NeRF**: Consistent 3D Scene Stylization as Stylized **NeRF** via 2D-3D Mutual Learning. (arXiv:2205.12183v2 [cs.GR] UPDATED)
## eess.IV
---
**19** new papers in eess.IV:-) 
1. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v1 [cs.CV])
2. Interaction of a priori Anatomic Knowledge with Self-Supervised Contrastive Learning in Cardiac Magnetic Resonance Imaging. (arXiv:2205.12429v1 [eess.IV])
3. Skin Cancer Diagnostics with an All-Inclusive Smartphone Application. (arXiv:2205.12438v1 [eess.IV])
4. A Lightweight NMS-free Framework for **Real-time** Visual Fault Detection System of Freight Trains. (arXiv:2205.12458v1 [cs.CV])
5. A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral Image Classification. (arXiv:2205.12459v1 [cs.CV])
6. FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation. (arXiv:2205.12465v1 [cs.LG])
7. Misleading Deep-Fake Detection with GAN Fingerprints. (arXiv:2205.12543v1 [cs.CV])
8. Some equivalence relation between persistent homology and morphological dynamics. (arXiv:2205.12546v1 [cs.CV])
9. NTIRE 2022 Challenge on **High Dynamic Range** Imaging: Methods and Results. (arXiv:2205.12633v1 [cs.CV])
10. COVID-19 Severity Classification on Chest X-ray Images. (arXiv:2205.12705v1 [eess.IV])
11. A Comparative Study of Gastric Histopathology Sub-size Image Classification: from Linear Regression to Visual Transformer. (arXiv:2205.12843v1 [eess.IV])
12. Structure Unbiased Adversarial Model for Medical Image Segmentation. (arXiv:2205.12857v1 [eess.IV])
13. Image Colorization using U-Net with Skip Connections and Fusion Layer on Landscape Images. (arXiv:2205.12867v1 [cs.CV])
14. RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v1 [eess.IV])
15. These Maps Are Made For Walking: Real-Time Terrain Property Estimation for Mobile Robots. (arXiv:2205.12925v1 [cs.RO])
16. Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v6 [cs.CV] UPDATED)
17. Learning JPEG Compression Artifacts for Image Manipulation Detection and Localization. (arXiv:2108.12947v2 [eess.IV] UPDATED)
18. Deep Kernel Representation for Image Reconstruction in PET. (arXiv:2110.01174v4 [eess.IV] UPDATED)
19. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v3 [eess.IV] UPDATED)
## cs.LG
---
**184** new papers in cs.LG:-) 
1. Action Recognition for American Sign Language. (arXiv:2205.12261v1 [cs.CV])
2. Wavelet Feature Maps Compression for Image-to-Image CNNs. (arXiv:2205.12268v1 [cs.CV])
3. lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Continual Learning on Autonomous Agents. (arXiv:2205.12295v1 [cs.NE])
4. FreDo: Frequency Domain-based Long-Term Time Series Forecasting. (arXiv:2205.12301v1 [cs.LG])
5. Fast & Furious: Modelling Malware Detection as Evolving Data Streams. (arXiv:2205.12311v1 [cs.CR])
6. ColdGuess: A General and Effective Relational Graph Convolutional Network to Tackle Cold Start Cases. (arXiv:2205.12318v1 [cs.LG])
7. Beyond Impossibility: Balancing Sufficiency, Separation and Accuracy. (arXiv:2205.12327v1 [cs.LG])
8. Certified Robustness Against Natural Language Attacks by Causal Intervention. (arXiv:2205.12331v1 [cs.LG])
9. K-12BERT: BERT for K-12 education. (arXiv:2205.12335v1 [cs.CL])
10. Women, artificial intelligence, and key positions in collaboration networks: Towards a more equal scientific ecosystem. (arXiv:2205.12339v1 [cs.SI])
11. Low-rank Optimal Transport: Approximation, Statistics and Debiasing. (arXiv:2205.12365v1 [stat.ML])
12. TorchNTK: A Library for Calculation of Neural Tangent Kernels of PyTorch Models. (arXiv:2205.12372v1 [cs.LG])
13. Learning to Model Editing Processes. (arXiv:2205.12374v1 [cs.CL])
14. Hardness of Maximum Likelihood Learning of DPPs. (arXiv:2205.12377v1 [cs.CC])
15. Imposing Gaussian Pre-Activations in a Neural Network. (arXiv:2205.12379v1 [cs.LG])
16. First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization. (arXiv:2205.12381v1 [cs.LG])
17. PLAtE: A Large-scale Dataset for List Page Web Extraction. (arXiv:2205.12386v1 [cs.CL])
18. Recipe2Vec: Multi-modal Recipe Representation Learning with Graph Neural Networks. (arXiv:2205.12396v1 [cs.LG])
19. Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT. (arXiv:2205.12399v1 [cs.LG])
20. Reward Uncertainty for Exploration in Preference-based Reinforcement Learning. (arXiv:2205.12401v1 [cs.LG])
21. Multi-Head Online Learning for Delayed Feedback Modeling. (arXiv:2205.12406v1 [cs.LG])
22. Convolutional Neural Processes for Inpainting Satellite Images. (arXiv:2205.12407v1 [cs.CV])
23. AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large Language Models. (arXiv:2205.12410v1 [cs.CL])
24. Linear Connectivity Reveals Generalization Strategies. (arXiv:2205.12411v1 [cs.LG])
25. Differentially Private AUC Computation in Vertical Federated Learning. (arXiv:2205.12412v1 [cs.LG])
26. Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret. (arXiv:2205.12418v1 [cs.LG])
27. Physics Guided Machine Learning for Variational Multiscale Reduced Order Modeling. (arXiv:2205.12419v1 [physics.flu-dyn])
28. Deletion and Insertion Tests in Regression Models. (arXiv:2205.12423v1 [cs.LG])
29. VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection. (arXiv:2205.12424v1 [cs.CR])
30. Non-stationary Bandits with Knapsacks. (arXiv:2205.12427v1 [cs.LG])
31. Towards Understanding Label Regularization for Fine-tuning Pre-trained Language Models. (arXiv:2205.12428v1 [cs.LG])
32. Additive Logistic Mechanism for Privacy-Preserving Self-Supervised Learning. (arXiv:2205.12430v1 [cs.LG])
33. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v1 [math.OC])
34. Generating Natural Language Proofs with Verifier-Guided Search. (arXiv:2205.12443v1 [cs.CL])
35. Over-the-Air Design of GAN Training for mmWave MIMO Channel Estimation. (arXiv:2205.12445v1 [eess.SP])
36. FLEURS: Few-shot Learning Evaluation of Universal Representations of Speech. (arXiv:2205.12446v1 [cs.CL])
37. Transportation-Inequalities, Lyapunov Stability and Sampling for Dynamical Systems on Continuous State Space. (arXiv:2205.12448v1 [stat.ML])
38. MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent Reinforcement Learning. (arXiv:2205.12449v1 [cs.LG])
39. Recipe for a General, Powerful, Scalable Graph Transformer. (arXiv:2205.12454v1 [cs.LG])
40. Investigating Information Inconsistency in Multilingual Open-Domain Question Answering. (arXiv:2205.12456v1 [cs.CL])
41. Linear Algorithms for Nonparametric Multiclass Probability Estimation. (arXiv:2205.12460v1 [stat.ME])
42. Augmentation-induced Consistency Regularization for Classification. (arXiv:2205.12461v1 [cs.LG])
43. sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite Images. (arXiv:2205.12464v1 [cs.CV])
44. FBNETGEN: Task-aware GNN-based fMRI Analysis via Functional Brain Network Generation. (arXiv:2205.12465v1 [cs.LG])
45. A Convergence Theory for Over-parameterized Variational Quantum Eigensolvers. (arXiv:2205.12481v1 [quant-ph])
46. Federated Self-supervised Learning for Heterogeneous Clients. (arXiv:2205.12493v1 [cs.LG])
47. The Dialog Must Go On: Improving Visual Dialog via Generative Self-Training. (arXiv:2205.12502v1 [cs.CV])
48. Memorization in NLP Fine-tuning Methods. (arXiv:2205.12506v1 [cs.CL])
49. Exact Phase Transitions in Deep Learning. (arXiv:2205.12510v1 [cs.LG])
50. Toward Discovering Options that Achieve Faster Planning. (arXiv:2205.12515v1 [cs.LG])
51. Skill Machines: Temporal Logic Composition in Reinforcement Learning. (arXiv:2205.12532v1 [cs.LG])
52. Structured Uncertainty in the Observation Space of Variational Autoencoders. (arXiv:2205.12533v1 [cs.LG])
53. Is a Question Decomposition Unit All We Need?. (arXiv:2205.12538v1 [cs.CL])
54. Misleading Deep-Fake Detection with GAN Fingerprints. (arXiv:2205.12543v1 [cs.CV])
55. RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning. (arXiv:2205.12548v1 [cs.CL])
56. Learning from time-dependent streaming data with online stochastic algorithms. (arXiv:2205.12549v1 [cs.LG])
57. Learning dynamics from partial observations with structured neural ODEs. (arXiv:2205.12550v1 [eess.SY])
58. Towards a Fair Comparison and Realistic Design and Evaluation Framework of Android Malware Detectors. (arXiv:2205.12569v1 [cs.CR])
59. Heterogeneous Reservoir Computing Models for Persian Speech Recognition. (arXiv:2205.12594v1 [cs.SD])
60. RobustLR: Evaluating Robustness to Logical Perturbation in Deductive Reasoning. (arXiv:2205.12598v1 [cs.CL])
61. ORCA: Interpreting Prompted Language Models via Locating Supporting Data Evidence in the Ocean of Pretraining Data. (arXiv:2205.12600v1 [cs.CL])
62. Learning Distributions by Generative Adversarial Networks: Approximation and Generalization. (arXiv:2205.12601v1 [cs.LG])
63. Deep Aesthetic Assessment and Retrieval of Breast Cancer Treatment Outcomes. (arXiv:2205.12611v1 [cs.CV])
64. Autoformalization with Large Language Models. (arXiv:2205.12615v1 [cs.LG])
65. On the Interpretability of Regularisation for Neural Networks Through Model Gradient Similarity. (arXiv:2205.12642v1 [stat.ML])
66. Fast Inference and Transfer of Compositional Task Structures for Few-shot Task Generalization. (arXiv:2205.12648v1 [cs.LG])
67. MAPLE-X: Latency Prediction with Explicit Microprocessor Prior Knowledge. (arXiv:2205.12660v1 [cs.LG])
68. Training Language Models with Memory Augmentation. (arXiv:2205.12674v1 [cs.CL])
69. Rethinking Fano's Inequality in Ensemble Learning. (arXiv:2205.12683v1 [cs.LG])
70. Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations. (arXiv:2205.12685v1 [cs.CL])
71. Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models. (arXiv:2205.12694v1 [cs.CL])
72. Surprises in adversarially-trained linear regression. (arXiv:2205.12695v1 [stat.ML])
73. Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts. (arXiv:2205.12701v1 [cs.CL])
74. Scalable Online Change Detection for High-dimensional Data Streams. (arXiv:2205.12706v1 [cs.LG])
75. VeriFi: Towards Verifiable Federated Unlearning. (arXiv:2205.12709v1 [cs.CR])
76. Service Discovery in Social Internet of Things using Graph Neural Networks. (arXiv:2205.12711v1 [cs.LG])
77. DPSNN: A Differentially Private Spiking Neural Network. (arXiv:2205.12718v1 [cs.NE])
78. Mathematical Models of Human Drivers Using Artificial Risk Fields. (arXiv:2205.12722v1 [cs.LG])
79. Interpretable Feature Engineering for Time Series Predictors using Attention Networks. (arXiv:2205.12723v1 [cs.LG])
80. Deep interpretable ensembles. (arXiv:2205.12729v1 [stat.ML])
81. Uncertainty Quantification for Transport in Porous media using Parameterized Physics Informed neural Networks. (arXiv:2205.12730v1 [cs.CE])
82. Machine learning methods for Schlieren imaging of a plasma channel in tenuous atomic vapor. (arXiv:2205.12731v1 [physics.plasm-ph])
83. Global geomagnetic perturbation forecasting using Deep Learning. (arXiv:2205.12734v1 [physics.space-ph])
84. Machine learning method for return direction forecasting of Exchange Traded Funds using classification and regression models. (arXiv:2205.12746v1 [q-fin.CP])
85. Fast Stochastic Composite Minimization and an Accelerated Frank-Wolfe Algorithm under Parallelization. (arXiv:2205.12751v1 [math.OC])
86. NECA: Network-Embedded Deep Representation Learning for Categorical Data. (arXiv:2205.12752v1 [cs.LG])
87. An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation. (arXiv:2205.12753v1 [cs.CV])
88. An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems. (arXiv:2205.12755v1 [cs.LG])
89. An Experimental Comparison Between Temporal Difference and Residual Gradient with Neural Network Approximation. (arXiv:2205.12770v1 [cs.LG])
90. Residual-Concatenate Neural Network with Deep Regularization Layers for Binary Classification. (arXiv:2205.12775v1 [cs.LG])
91. Ultra-compact Binary Neural Networks for Human Activity Recognition on RISC-V Processors. (arXiv:2205.12781v1 [cs.LG])
92. TrustGNN: Graph Neural Network based Trust Evaluation via Learnable Propagative and Composable Nature. (arXiv:2205.12784v1 [cs.LG])
93. Impartial Games: A Challenge for Reinforcement Learning. (arXiv:2205.12787v1 [cs.LG])
94. Gradient-based explanations for Gaussian Process regression and classification models. (arXiv:2205.12797v1 [cs.LG])
95. Mirror Descent Maximizes Generalized Margin and Can Be Implemented Efficiently. (arXiv:2205.12808v1 [cs.LG])
96. Removing the fat from your posterior samples with margarine. (arXiv:2205.12841v1 [astro-ph.IM])
97. A Universal Error Measure for Input Predictions Applied to Online Graph Problems. (arXiv:2205.12850v1 [cs.DS])
98. Stochastic Second-Order Methods Provably Beat SGD For Gradient-Dominated Functions. (arXiv:2205.12856v1 [cs.LG])
99. Image Colorization using U-Net with Skip Connections and Fusion Layer on Landscape Images. (arXiv:2205.12867v1 [cs.CV])
100. Understanding Programmatic Weak Supervision via Source-aware Influence Function. (arXiv:2205.12879v1 [cs.LG])
101. Trust-based Consensus in Multi-Agent Reinforcement Learning Systems. (arXiv:2205.12880v1 [cs.MA])
102. Robust Reinforcement Learning on Graphs for Logistics optimization. (arXiv:2205.12888v1 [cs.LG])
103. Differentially Private Data Generation Needs Better Features. (arXiv:2205.12900v1 [stat.ML])
104. RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v1 [eess.IV])
105. A Neural Tangent Kernel Formula for Ensembles of Soft Trees with Arbitrary Architectures. (arXiv:2205.12904v1 [cs.LG])
106. Analytics of Business Time Series Using Machine Learning and Bayesian Inference. (arXiv:2205.12905v1 [cs.LG])
107. Boosting Tail Neural Network for Realtime Custom Keyword Spotting. (arXiv:2205.12933v1 [eess.AS])
108. Amortized Inference for Causal Structure Learning. (arXiv:2205.12934v1 [cs.LG])
109. Mitigating multiple descents: A model-agnostic framework for risk monotonization. (arXiv:2205.12937v1 [math.ST])
110. Conformal Prediction Intervals with Temporal Dependence. (arXiv:2205.12940v1 [stat.ML])
111. Learning Mean Field Games: A Survey. (arXiv:2205.12944v1 [cs.LG])
112. Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
113. Exact Convergence Rates of the Neural Tangent Kernel in the Large Depth Limit. (arXiv:1905.13654v11 [stat.ML] UPDATED)
114. A Kernel Stein Test for Comparing Latent Variable Models. (arXiv:1907.00586v4 [stat.ML] UPDATED)
115. Multimodal active speaker detection and virtual cinematography for video conferencing. (arXiv:2002.03977v3 [eess.AS] UPDATED)
116. MGX: Near-Zero Overhead Memory Protection for Data-Intensive Accelerators. (arXiv:2004.09679v2 [cs.CR] UPDATED)
117. Learning the Travelling Salesperson Problem Requires Rethinking Generalization. (arXiv:2006.07054v6 [cs.LG] UPDATED)
118. Multi-Agent Low-Dimensional Linear Bandits. (arXiv:2007.01442v4 [cs.LG] UPDATED)
119. GuardNN: Secure Accelerator Architecture for Privacy-Preserving Deep Learning. (arXiv:2008.11632v2 [cs.CR] UPDATED)
120. Learning to Maximize Speech Quality Directly Using MOS Prediction for Neural Text-to-Speech. (arXiv:2011.01174v5 [eess.AS] UPDATED)
121. xFraud: Explainable Fraud Transaction Detection. (arXiv:2011.12193v3 [cs.LG] UPDATED)
122. HEBO Pushing The Limits of Sample-Efficient Hyperparameter Optimisation. (arXiv:2012.03826v6 [cs.LG] UPDATED)
123. Label Leakage and Protection in Two-party Split Learning. (arXiv:2102.08504v3 [cs.LG] UPDATED)
124. Meta-Learning-Based Robust Adaptive Flight Control Under Uncertain Wind Conditions. (arXiv:2103.01932v3 [cs.RO] UPDATED)
125. FastAdaBelief: Improving Convergence Rate for Belief-based Adaptive Optimizers by Exploiting Strong Convexity. (arXiv:2104.13790v3 [cs.LG] UPDATED)
126. Principal Components Bias in Over-parameterized Linear Models, and its Manifestation in Deep Neural Networks. (arXiv:2105.05553v7 [cs.LG] UPDATED)
127. Training Heterogeneous Features in Sequence to Sequence Tasks: Latent Enhanced Multi-filter Seq2Seq Model. (arXiv:2105.08840v3 [cs.CL] UPDATED)
128. Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v4 [cs.LG] UPDATED)
129. Online Metro Origin-Destination Prediction via Heterogeneous Information Aggregation. (arXiv:2107.00946v5 [cs.LG] UPDATED)
130. Learning JPEG Compression Artifacts for Image Manipulation Detection and Localization. (arXiv:2108.12947v2 [eess.IV] UPDATED)
131. So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v4 [cs.CL] UPDATED)
132. Learn2Agree: Fitting with Multiple Annotators without Objective Ground Truth. (arXiv:2109.03596v2 [cs.LG] UPDATED)
133. Detecting Multi-Sensor Fusion Errors in Advanced Driver-Assistance Systems. (arXiv:2109.06404v3 [cs.RO] UPDATED)
134. Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation. (arXiv:2109.06604v2 [cs.CL] UPDATED)
135. Physics-guided Deep Markov Models for Learning Nonlinear Dynamical Systems with Uncertainty. (arXiv:2110.08607v3 [cs.LG] UPDATED)
136. Domain Adaptation via Maximizing Surrogate Mutual Information. (arXiv:2110.12184v2 [cs.LG] UPDATED)
137. On Representation Knowledge Distillation for Graph Neural Networks. (arXiv:2111.04964v2 [cs.LG] UPDATED)
138. NeuralPDE: Modelling Dynamical Systems from Data. (arXiv:2111.07671v2 [cs.LG] UPDATED)
139. CGX: Adaptive System Support for Communication-Efficient Deep Learning. (arXiv:2111.08617v4 [cs.DC] UPDATED)
140. Graph-Based Similarity of Neural Network Representations. (arXiv:2111.11165v2 [cs.LG] UPDATED)
141. MAPLE: Microprocessor A Priori for Latency Estimation. (arXiv:2111.15106v2 [cs.LG] UPDATED)
142. Black box tests for algorithmic stability. (arXiv:2111.15546v2 [cs.LG] UPDATED)
143. Tell me why! Explanations support learning relational and causal structure. (arXiv:2112.03753v3 [cs.LG] UPDATED)
144. A Review of Indoor Millimeter Wave Device-based Localization and Device-free Sensing Technologies and Applications. (arXiv:2112.05593v3 [cs.NI] UPDATED)
145. Sharpness-Aware Minimization with Dynamic Reweighting. (arXiv:2112.08772v3 [cs.LG] UPDATED)
146. The Web Is Your Oyster -- Knowledge-Intensive NLP against a Very Large Web Corpus. (arXiv:2112.09924v2 [cs.CL] UPDATED)
147. A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning. (arXiv:2201.01221v2 [cs.LG] UPDATED)
148. Learning Mixtures of Linear Dynamical Systems. (arXiv:2201.11211v2 [stat.ML] UPDATED)
149. Giga-scale Kernel Matrix Vector Multiplication on GPU. (arXiv:2202.01085v2 [math.NA] UPDATED)
150. To Impute or not to Impute? Missing Data in Treatment Effect Estimation. (arXiv:2202.02096v3 [stat.ML] UPDATED)
151. Conditional Gradients for the Approximately Vanishing Ideal. (arXiv:2202.03349v8 [cs.LG] UPDATED)
152. Optimizing Warfarin Dosing using Deep Reinforcement Learning. (arXiv:2202.03486v2 [cs.LG] UPDATED)
153. VAEL: Bridging Variational Autoencoders and Probabilistic Logic Programming. (arXiv:2202.04178v2 [cs.PL] UPDATED)
154. Neural Sheaf Diffusion: A Topological Perspective on Heterophily and Oversmoothing in GNNs. (arXiv:2202.04579v2 [cs.LG] UPDATED)
155. Adaptively Exploiting d-Separators with Causal Bandits. (arXiv:2202.05100v2 [stat.ML] UPDATED)
156. Cross Domain Few-Shot Learning via Meta Adversarial Training. (arXiv:2202.05713v3 [cs.LG] UPDATED)
157. Should You Mask 15% in Masked Language Modeling?. (arXiv:2202.08005v2 [cs.CL] UPDATED)
158. Label Leakage and Protection from Forward Embedding in Vertical Federated Learning. (arXiv:2203.01451v3 [cs.LG] UPDATED)
159. A Tree-Structured Multi-Task Model Recommender. (arXiv:2203.05092v2 [cs.LG] UPDATED)
160. A comparative study of non-deep learning, deep learning, and ensemble learning methods for sunspot number prediction. (arXiv:2203.05757v2 [astro-ph.SR] UPDATED)
161. The worst of both worlds: A comparative analysis of errors in learning from data in psychology and machine learning. (arXiv:2203.06498v7 [cs.LG] UPDATED)
162. Deep Reinforcement Learning Guided Graph Neural Networks for Brain Network Analysis. (arXiv:2203.10093v2 [cs.LG] UPDATED)
163. Sub-Task Decomposition Enables Learning in Sequence to Sequence Tasks. (arXiv:2204.02892v2 [cs.CL] UPDATED)
164. Graph Neural Networks Designed for Different Graph Types: A Survey. (arXiv:2204.03080v2 [cs.LG] UPDATED)
165. Sketch guided and progressive growing GAN for realistic and editable ultrasound image synthesis. (arXiv:2204.06929v3 [eess.IV] UPDATED)
166. When Is Partially Observable Reinforcement Learning Not Scary?. (arXiv:2204.08967v2 [cs.LG] UPDATED)
167. MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering. (arXiv:2204.10629v2 [cs.CL] UPDATED)
168. RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning. (arXiv:2204.12581v2 [cs.LG] UPDATED)
169. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v2 [q-bio.GN] UPDATED)
170. Depth Estimation with Simplified Transformer. (arXiv:2204.13791v2 [cs.CV] UPDATED)
171. From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model. (arXiv:2205.00690v2 [cs.LG] UPDATED)
172. Growing Isotropic Neural Cellular Automata. (arXiv:2205.01681v2 [cs.NE] UPDATED)
173. What is Proxy Discrimination?. (arXiv:2205.05265v2 [cs.LG] UPDATED)
174. FreeMatch: Self-adaptive Thresholding for Semi-supervised Learning. (arXiv:2205.07246v2 [cs.LG] UPDATED)
175. Bayesian Physics-Informed Neural Networks for real-world nonlinear dynamical systems. (arXiv:2205.08304v2 [cs.LG] UPDATED)
176. A Regression Approach to Learning-Augmented Online Algorithms. (arXiv:2205.08717v2 [cs.LG] UPDATED)
177. How catastrophic can catastrophic forgetting be in linear regression?. (arXiv:2205.09588v2 [cs.LG] UPDATED)
178. CLCNet: Rethinking of Ensemble Modeling with Classification Confidence Network. (arXiv:2205.09612v3 [cs.LG] UPDATED)
179. What killed the Convex Booster ?. (arXiv:2205.09628v2 [cs.LG] UPDATED)
180. DEMAND: Deep Matrix Approximately Nonlinear Decomposition to Identify Meta, Canonical, and Sub-Spatial Pattern of functional Magnetic Resonance Imaging in the Human Brain. (arXiv:2205.10264v2 [cs.LG] UPDATED)
181. EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex Structures. (arXiv:2205.10390v2 [cs.LG] UPDATED)
182. muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems. (arXiv:2205.10937v2 [cs.LG] UPDATED)
183. SepIt: Approaching a Single Channel Speech Separation Bound. (arXiv:2205.11801v2 [eess.AS] UPDATED)
184. Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy, Challenges and Vision. (arXiv:2205.11913v2 [cs.DC] UPDATED)
## cs.AI
---
**102** new papers in cs.AI:-) 
1. lpSpikeCon: Enabling Low-Precision Spiking Neural Network Processing for Efficient Unsupervised Continual Learning on Autonomous Agents. (arXiv:2205.12295v1 [cs.NE])
2. FreDo: Frequency Domain-based Long-Term Time Series Forecasting. (arXiv:2205.12301v1 [cs.LG])
3. ColdGuess: A General and Effective Relational Graph Convolutional Network to Tackle Cold Start Cases. (arXiv:2205.12318v1 [cs.LG])
4. Multilevel sentiment analysis in arabic. (arXiv:2205.12328v1 [cs.CL])
5. Women, artificial intelligence, and key positions in collaboration networks: Towards a more equal scientific ecosystem. (arXiv:2205.12339v1 [cs.SI])
6. Toxicity Detection with Generative Prompt-based Inference. (arXiv:2205.12390v1 [cs.CL])
7. Toward Understanding Bias Correlations for Mitigation in NLP. (arXiv:2205.12391v1 [cs.CL])
8. Emergent Communication through Metropolis-Hastings Naming Game with Deep Generative Models. (arXiv:2205.12392v1 [cs.AI])
9. Reward Uncertainty for Exploration in Preference-based Reinforcement Learning. (arXiv:2205.12401v1 [cs.LG])
10. Multi-Head Online Learning for Delayed Feedback Modeling. (arXiv:2205.12406v1 [cs.LG])
11. AdaMix: Mixture-of-Adapter for Parameter-efficient Tuning of Large Language Models. (arXiv:2205.12410v1 [cs.CL])
12. Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret. (arXiv:2205.12418v1 [cs.LG])
13. Active Programming by Example with a Natural Language Prior. (arXiv:2205.12422v1 [cs.CL])
14. Deletion and Insertion Tests in Regression Models. (arXiv:2205.12423v1 [cs.LG])
15. VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection. (arXiv:2205.12424v1 [cs.CR])
16. Lyapunov function approach for approximation algorithm design and analysis: with applications in submodular maximization. (arXiv:2205.12442v1 [math.OC])
17. Sparse*BERT: Sparse Models are Robust. (arXiv:2205.12452v1 [cs.CL])
18. Investigating Information Inconsistency in Multilingual Open-Domain Question Answering. (arXiv:2205.12456v1 [cs.CL])
19. Augmentation-induced Consistency Regularization for Classification. (arXiv:2205.12461v1 [cs.LG])
20. sat2pc: Estimating Point Cloud of Building Roofs from 2D Satellite Images. (arXiv:2205.12464v1 [cs.CV])
21. Low Resource Style Transfer via Domain Adaptive Meta Learning. (arXiv:2205.12475v1 [cs.CL])
22. GisPy: A Tool for Measuring Gist Inference Score in Text. (arXiv:2205.12484v1 [cs.CL])
23. Conditional set generation using Seq2seq models. (arXiv:2205.12485v1 [cs.CL])
24. Improve Event Extraction via Self-Training with Gradient Guidance. (arXiv:2205.12490v1 [cs.CL])
25. Teaching Broad Reasoning Skills via Decomposition-Guided Contexts. (arXiv:2205.12496v1 [cs.CL])
26. Deadlock-Free Method for Multi-Agent Pickup and Delivery Problem Using Priority Inheritance with Temporary Priority. (arXiv:2205.12504v1 [cs.MA])
27. Toward Discovering Options that Achieve Faster Planning. (arXiv:2205.12515v1 [cs.LG])
28. Is a Question Decomposition Unit All We Need?. (arXiv:2205.12538v1 [cs.CL])
29. Apport des ontologies pour le calcul de la similarit\'e s\'emantique au sein d'un syst\`eme de recommandation. (arXiv:2205.12539v1 [cs.IR])
30. Deep Dense Local Feature Matching and Vehicle Removal for Indoor Visual Localization. (arXiv:2205.12544v1 [cs.CV])
31. Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v1 [cs.CL])
32. Spotlights: Probing Shapes from Spherical Viewpoints. (arXiv:2205.12564v1 [cs.CV])
33. From Pedestrian Detection to Crosswalk Estimation: An EM Algorithm and Analysis on Diverse Datasets. (arXiv:2205.12579v1 [cs.CV])
34. A Simple and Unified Tagging Model with Priming for Relational Structure Predictions. (arXiv:2205.12585v1 [cs.CL])
35. Perturbation Augmentation for Fairer NLP. (arXiv:2205.12586v1 [cs.CL])
36. Autoformalization with Large Language Models. (arXiv:2205.12615v1 [cs.LG])
37. DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation. (arXiv:2205.12617v1 [cs.CL])
38. Are Large Pre-Trained Language Models Leaking Your Personal Information?. (arXiv:2205.12628v1 [cs.CL])
39. UniInst: Unique Representation for End-to-End Instance Segmentation. (arXiv:2205.12646v1 [cs.CV])
40. Fast Inference and Transfer of Compositional Task Structures for Few-shot Task Generalization. (arXiv:2205.12648v1 [cs.LG])
41. MAPLE-X: Latency Prediction with Explicit Microprocessor Prior Knowledge. (arXiv:2205.12660v1 [cs.LG])
42. Rethinking Fano's Inequality in Ensemble Learning. (arXiv:2205.12683v1 [cs.LG])
43. Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations. (arXiv:2205.12685v1 [cs.CL])
44. Large Language Models are Zero-Shot Clinical Information Extractors. (arXiv:2205.12689v1 [cs.CL])
45. Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models. (arXiv:2205.12694v1 [cs.CL])
46. DPSNN: A Differentially Private Spiking Neural Network. (arXiv:2205.12718v1 [cs.NE])
47. Inductive Learning of Complex Knowledge from Raw Data. (arXiv:2205.12735v1 [cs.AI])
48. SIoU Loss: More Powerful Learning for Bounding Box Regression. (arXiv:2205.12740v1 [cs.CV])
49. A Human-Centric Assessment Framework for AI. (arXiv:2205.12749v1 [cs.AI])
50. NECA: Network-Embedded Deep Representation Learning for Categorical Data. (arXiv:2205.12752v1 [cs.LG])
51. An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems. (arXiv:2205.12755v1 [cs.LG])
52. An Experimental Comparison Between Temporal Difference and Residual Gradient with Neural Network Approximation. (arXiv:2205.12770v1 [cs.LG])
53. Impartial Games: A Challenge for Reinforcement Learning. (arXiv:2205.12787v1 [cs.LG])
54. Automatic question generation based on sentence structure analysis using machine learning approach. (arXiv:2205.12811v1 [cs.CL])
55. On Building Spoken Language Understanding Systems for Low Resourced Languages. (arXiv:2205.12818v1 [cs.CL])
56. Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors. (arXiv:2205.12854v1 [cs.CL])
57. Trust-based Consensus in Multi-Agent Reinforcement Learning Systems. (arXiv:2205.12880v1 [cs.MA])
58. You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos. (arXiv:2205.12886v1 [cs.CV])
59. Robust Reinforcement Learning on Graphs for Logistics optimization. (arXiv:2205.12888v1 [cs.LG])
60. Reasoning over Logically Interacted Conditions for Question Answering. (arXiv:2205.12898v1 [cs.CL])
61. RADNet: Ensemble Model for Robust Glaucoma Classification in Color Fundus Images. (arXiv:2205.12902v1 [eess.IV])
62. NaturalProver: Grounded Mathematical Proof Generation with Language Models. (arXiv:2205.12910v1 [cs.CL])
63. SoK: Cross-border Criminal Investigations and Digital Evidence. (arXiv:2205.12911v1 [cs.CR])
64. Learning Mean Field Games: A Survey. (arXiv:2205.12944v1 [cs.LG])
65. Inception Transformer. (arXiv:2205.12956v1 [cs.CV])
66. xFraud: Explainable Fraud Transaction Detection. (arXiv:2011.12193v3 [cs.LG] UPDATED)
67. Finding Good Proofs for Description Logic Entailments Using Recursive Quality Measures (Extended Technical Report). (arXiv:2104.13138v2 [cs.AI] UPDATED)
68. Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v4 [cs.LG] UPDATED)
69. PVT: Point-Voxel Transformer for Point Cloud Learning. (arXiv:2108.06076v4 [cs.CV] UPDATED)
70. So Cloze yet so Far: N400 Amplitude is Better Predicted by Distributional Information than Human Predictability Judgements. (arXiv:2109.01226v4 [cs.CL] UPDATED)
71. Detecting Multi-Sensor Fusion Errors in Advanced Driver-Assistance Systems. (arXiv:2109.06404v3 [cs.RO] UPDATED)
72. Non-Parametric Unsupervised Domain Adaptation for Neural Machine Translation. (arXiv:2109.06604v2 [cs.CL] UPDATED)
73. Semi-Autonomous Teleoperation via Learning Non-Prehensile Manipulation Skills. (arXiv:2109.13081v2 [cs.RO] UPDATED)
74. MAPLE: Microprocessor A Priori for Latency Estimation. (arXiv:2111.15106v2 [cs.LG] UPDATED)
75. Aerial Images Meet Crowdsourced Trajectories: A New Approach to Robust Road Extraction. (arXiv:2111.15119v3 [cs.CV] UPDATED)
76. Frequency Fitness Assignment: Optimization without Bias for Good Solutions can be Efficient. (arXiv:2112.00229v4 [cs.NE] UPDATED)
77. Investigating the usefulness of Quantum Blur. (arXiv:2112.01646v2 [cs.CV] UPDATED)
78. Tell me why! Explanations support learning relational and causal structure. (arXiv:2112.03753v3 [cs.LG] UPDATED)
79. The Web Is Your Oyster -- Knowledge-Intensive NLP against a Very Large Web Corpus. (arXiv:2112.09924v2 [cs.CL] UPDATED)
80. Surprise-Guided Search for Learning Task Specifications from Demonstrations. (arXiv:2112.10807v3 [cs.AI] UPDATED)
81. A Deeper Understanding of State-Based Critics in Multi-Agent Reinforcement Learning. (arXiv:2201.01221v2 [cs.LG] UPDATED)
82. Cross Domain Few-Shot Learning via Meta Adversarial Training. (arXiv:2202.05713v3 [cs.LG] UPDATED)
83. A comparative study of non-deep learning, deep learning, and ensemble learning methods for sunspot number prediction. (arXiv:2203.05757v2 [astro-ph.SR] UPDATED)
84. Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v2 [cs.CL] UPDATED)
85. Deep Reinforcement Learning Guided Graph Neural Networks for Brain Network Analysis. (arXiv:2203.10093v2 [cs.LG] UPDATED)
86. Synthesis of Stabilizing Recurrent Equilibrium Network Controllers. (arXiv:2204.00122v2 [eess.SY] UPDATED)
87. When Is Partially Observable Reinforcement Learning Not Scary?. (arXiv:2204.08967v2 [cs.LG] UPDATED)
88. What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment. (arXiv:2204.09148v2 [cs.CL] UPDATED)
89. MEKER: Memory Efficient Knowledge Embedding Representation for Link Prediction and Question Answering. (arXiv:2204.10629v2 [cs.CL] UPDATED)
90. RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning. (arXiv:2204.12581v2 [cs.LG] UPDATED)
91. Coupling Deep Imputation with Multitask Learning for Downstream Tasks on Genomics Data. (arXiv:2204.13705v2 [q-bio.GN] UPDATED)
92. From Noisy Prediction to True Label: Noisy Prediction Calibration via Generative Model. (arXiv:2205.00690v2 [cs.LG] UPDATED)
93. MAS2HP: A Multi Agent System to predict protein structure in 2D HP model. (arXiv:2205.08451v3 [q-bio.BM] UPDATED)
94. EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex Structures. (arXiv:2205.10390v2 [cs.LG] UPDATED)
95. Coordinating Policies Among Multiple Agents via an Intelligent Communication Channel. (arXiv:2205.10607v2 [cs.AI] UPDATED)
96. muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems. (arXiv:2205.10937v2 [cs.LG] UPDATED)
97. A Survey of Research on Fair Recommender Systems. (arXiv:2205.11127v2 [cs.IR] UPDATED)
98. NPU-BOLT: A Dataset for Bolt Object Detection in Natural Scene Images. (arXiv:2205.11191v2 [cs.CV] UPDATED)
99. Non-Parametric Domain Adaptation for End-to-End Speech Translation. (arXiv:2205.11211v2 [cs.CL] UPDATED)
100. On the Paradox of Learning to Reason from Data. (arXiv:2205.11502v2 [cs.CL] UPDATED)
101. Effectively Incorporating Weighted Cost-to-go Heuristic in Suboptimal CBS. (arXiv:2205.11624v2 [cs.AI] UPDATED)
102. Deep Learning Workload Scheduling in GPU Datacenters: Taxonomy, Challenges and Vision. (arXiv:2205.11913v2 [cs.DC] UPDATED)

