# Your interest papers
---
## cs.CV
---
### Gravitationally Lensed Black Hole Emission Tomography. (arXiv:2204.03715v1 [cs.CV])
- Authors : Aviad Levis, Ren Ng
- Link : [http://arxiv.org/abs/2204.03715](http://arxiv.org/abs/2204.03715)
> ABSTRACT  :  Measurements from the Event Horizon Telescope enabled the visualization of light emission around a black hole for the first time. So far, these measurements have been used to recover a 2D image under the assumption that the emission field is static over the period of acquisition. In this work, we propose BH-**NeRF**, a novel tomography approach that leverages gravitational lensing to recover the continuous 3D emission field near a black hole. Compared to other 3D reconstruction or tomography settings, this task poses two significant challenges: first, rays near black holes follow curved paths dictated by general relativity, and second, we only observe measurements from a single viewpoint. Our method captures the unknown emission field using a continuous volumetric function parameterized by a coordinate-based neural network, and uses knowledge of Keplerian orbital dynamics to establish correspondence between 3D points over time. Together, these enable BH-**NeRF** to recover accurate 3D emission fields, even in challenging situations with sparse measurements and uncertain orbital dynamics. This work takes the first steps in showing how future measurements from the Event Horizon Telescope could be used to recover evolving 3D emission around the supermassive black hole in our Galactic center.  
### Vision Transformers for Single Image Dehazing. (arXiv:2204.03883v1 [cs.CV])
- Authors : Yuda Song, Zhuqing He, Hui Qian, Xin Du
- Link : [http://arxiv.org/abs/2204.03883](http://arxiv.org/abs/2204.03883)
> ABSTRACT  :  Image dehazing is a representative low-level vision task that estimates latent haze-free images from hazy images. In recent years, convolutional neural network-based methods have dominated image dehazing. However, vision Transformers, which has recently made a breakthrough in high-level vision tasks, has not brought new dimensions to image dehazing. We start with the popular **Swin** Transformer and find that several of its key designs are unsuitable for image dehazing. To this end, we propose DehazeFormer, which consists of various improvements, such as the modified normalization layer, activation function, and spatial information aggregation scheme. We train multiple variants of DehazeFormer on various datasets to demonstrate its effectiveness. Specifically, on the most frequently used SOTS indoor set, our small model outperforms FFA-Net with only 25% #Param and 5% computational cost. To the best of our knowledge, our large model is the first method with the PSNR over 40 dB on the SOTS indoor set, dramatically outperforming the previous state-of-the-art methods. We also collect a large-scale realistic remote sensing dehazing dataset for evaluating the method's capability to remove highly non-homogeneous haze.  
### Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])
- Authors : Yutaro Yamada, Mayu Otani
- Link : [http://arxiv.org/abs/2204.03934](http://arxiv.org/abs/2204.03934)
> ABSTRACT  :  As clean ImageNet accuracy nears its ceiling, the research community is increasingly more concerned about robust accuracy under distributional shifts. While a variety of methods have been proposed to robustify neural networks, these techniques often target models trained on ImageNet classification. At the same time, it is a common practice to use ImageNet pretrained backbones for downstream tasks such as object detection, semantic segmentation, and image classification from different domains. This raises a question: Can these robust image classifiers transfer robustness to downstream tasks? For object detection and semantic segmentation, we find that a vanilla **Swin** Transformer, a variant of Vision Transformer tailored for dense prediction tasks, transfers robustness better than Convolutional Neural Networks that are trained to be robust to the corrupted version of ImageNet. For CIFAR10 classification, we find that models that are robustified for ImageNet do not retain robustness when fully fine-tuned. These findings suggest that current robustification techniques tend to emphasize ImageNet evaluations. Moreover, network architecture is a strong source of robustness when we consider transfer learning.  
### Underwater Image **Enhancement** Using Pre-trained Transformer. (arXiv:2204.04199v1 [eess.IV])
- Authors : Abderrahmene Boudiaf, Yuhang Guo, Adarsh Ghimire, Naoufel Werghi, Giulia De, Sajid Javed, Jorge Dias
- Link : [http://arxiv.org/abs/2204.04199](http://arxiv.org/abs/2204.04199)
> ABSTRACT  :  The goal of this work is to apply a denoising image transformer to remove the distortion from underwater images and compare it with other similar approaches. Automatic **restoration** of underwater images plays an important role since it allows to increase the quality of the images, without the need for more expensive equipment. This is a critical example of the important role of the machine learning algorithms to support marine exploration and monitoring, reducing the need for human intervention like the manual processing of the images, thus saving time, effort, and cost. This paper is the first application of the image transformer-based approach called "Pre-Trained Image Processing Transformer" to underwater images. This approach is tested on the UFO-120 dataset, containing 1500 images with the corresponding clean images.  
### Dancing under the stars: video denoising in starlight. (arXiv:2204.04210v1 [cs.CV])
- Authors : Kristina Monakhova, Laura Waller, Vladlen Koltun
- Link : [http://arxiv.org/abs/2204.04210](http://arxiv.org/abs/2204.04210)
> ABSTRACT  :  Imaging in **low light** is extremely challenging due to low photon counts. Using sensitive CMOS cameras, it is currently possible to take videos at **night** under moonlight (0.05-0.3 lux illumination). In this paper, we demonstrate photorealistic video under starlight (no moon present, $&lt;$0.001 lux) for the first time. To enable this, we develop a GAN-tuned physics-based noise model to more accurately represent camera noise at the lowest light levels. Using this noise model, we train a video denoiser using a combination of simulated noisy video clips and real noisy still images. We capture a 5-10 fps video dataset with significant motion at approximately 0.6-0.7 millilux with no active illumination. Comparing against alternative methods, we achieve improved video quality at the lowest light levels, demonstrating photorealistic video denoising in starlight for the first time.  
### A Voxel Graph CNN for Object Classification with Event Cameras. (arXiv:2106.00216v3 [cs.CV] UPDATED)
- Authors : Yongjian Deng, Hao Chen, Hai Liu, Youfu Li
- Link : [http://arxiv.org/abs/2106.00216](http://arxiv.org/abs/2106.00216)
> ABSTRACT  :  Event cameras attract researchers' attention due to their low power consumption, **high dynamic range**, and extremely high temporal resolution. Learning models on event-based object classification have recently achieved massive success by accumulating sparse events into dense frames to apply traditional 2D learning methods. Yet, these approaches necessitate heavy-weight models and are with high computational complexity due to the redundant information introduced by the sparse-to-dense conversion, limiting the potential of event cameras on real-life applications. This study aims to address the core problem of balancing accuracy and model complexity for event-based classification models. To this end, we introduce a novel graph representation for event data to exploit their sparsity better and customize a lightweight voxel graph convolutional neural network (\textit{EV-VGCNN}) for event-based classification. Specifically, (1) using voxel-wise vertices rather than previous point-wise inputs to explicitly exploit regional 2D semantics of event streams while keeping the sparsity;(2) proposing a multi-scale feature relational layer (\textit{MFRL}) to extract spatial and motion cues from each vertex discriminatively concerning its distances to neighbors. Comprehensive experiments show that our model can advance state-of-the-art classification accuracy with extremely low model complexity (merely 0.84M parameters).  
### Provident Vehicle Detection at **Night** for Advanced Driver Assistance Systems. (arXiv:2107.11302v3 [cs.CV] UPDATED)
- Authors : Lukas Ewecker, Ebubekir Asan, Lars Ohnemus, Sascha Saralajew
- Link : [http://arxiv.org/abs/2107.11302](http://arxiv.org/abs/2107.11302)
> ABSTRACT  :  In recent years, computer vision algorithms have become more powerful. However, current algorithms mainly share one limitation: They rely on directly visible objects. This is a significant drawback compared to human behavior, where visual cues caused by objects (e.g., shadows) are already used intuitively to retrieve information or anticipate occurring objects. While driving at **night**, this performance deficit becomes even more obvious: Humans already process the light artifacts caused by the headlamps of oncoming vehicles to estimate where they appear, whereas current object detection systems require that the oncoming vehicle is directly visible before it can be detected. Based on previous work on this subject, in this paper, we present a complete system that can detect light artifacts caused by the headlights of oncoming vehicles so that it detects that a vehicle is approaching providently. For that, an entire algorithm architecture is investigated, including the detection in the image space, the three-dimensional localization, and the tracking of light artifacts. To demonstrate the usefulness of such an algorithm, the proposed algorithm is deployed in a test vehicle to use the detected light artifacts to control the glare-free high beam system proactively. Using this experimental setting, the provident vehicle detection system's time benefit compared to an in-production computer vision system is quantified. Additionally, the glare-free high beam use case provides a real-time and real-world visualization interface of the detection results by considering the adaptive headlamps as projectors. With this investigation of provident vehicle detection, we want to put awareness on the unconventional sensing task of detecting objects providently and further close the performance gap between human behavior and computer vision algorithms to bring autonomous and automated driving a step forward.  
### Event-Based Fusion for Motion Deblurring with Cross-modal Attention. (arXiv:2112.00167v2 [cs.CV] UPDATED)
- Authors : Lei Sun, Christos Sakaridis, Jingyun Liang, Qi Jiang, Kailun Yang, Peng Sun, Yaozu Ye, Kaiwei Wang, Luc Van
- Link : [http://arxiv.org/abs/2112.00167](http://arxiv.org/abs/2112.00167)
> ABSTRACT  :  Traditional frame-based cameras inevitably suffer from motion blur due to long **exposure** times. As a kind of bio-inspired camera, the event camera records the intensity changes in an asynchronous way with high temporal resolution, providing valid image degradation information within the **exposure** time. In this paper, we rethink the eventbased image deblurring problem and unfold it into an end-to-end two-stage image **restoration** network. To effectively fuse event and image features, we design an event-image cross-modal attention module applied at multiple levels of our network, which allows to focus on relevant features from the event branch and filter out noise. We also introduce a novel symmetric cumulative event representation specifically for image deblurring as well as an event mask gated connection between the two stages of our network which helps avoid information loss. At the dataset level, to foster event-based motion deblurring and to facilitate evaluation on challenging real-world images, we introduce the Real Event Blur (REBlur) dataset, captured with an event camera in an illumination controlled optical laboratory. Our Event Fusion Network (EFNet) sets the new state of the art in motion deblurring, surpassing both the prior best-performing image-based method and all event-based methods with public implementations on the GoPro dataset (by up to 2.47dB) and on our REBlur dataset, even in extreme blurry conditions. The code and our REBlur dataset will be made publicly available.  
### Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v3 [cs.CV] UPDATED)
- Authors : Penglei Gao, Xi Yang, Rui Zhang, Kaizhu Huang, Yujie Geng, Yuyao Yan
- Link : [http://arxiv.org/abs/2201.11403](http://arxiv.org/abs/2201.11403)
> ABSTRACT  :  While most present image outpainting conducts horizontal extrapolation, we study the generalised image outpainting problem that extrapolates visual context all-side around a given image. To this end, we develop a novel transformer-based generative adversarial network called U-Transformer able to extend image borders with plausible structure and details even for complicated scenery images. Specifically, we design a generator as an encoder-to-decoder structure embedded with the popular **Swin** Transformer blocks. As such, our novel framework can better cope with image long-range dependencies which are crucially important for generalised image outpainting. We propose additionally a U-shaped structure and multi-view Temporal Spatial Predictor network to reinforce image self-reconstruction as well as unknown-part prediction smoothly and realistically. We experimentally demonstrate that our proposed method could produce visually appealing results for generalized image outpainting against the state-of-the-art image outpainting approaches.  
### Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v3 [eess.IV] UPDATED)
- Authors : Abril Corona, Jonathan Frawley, Sam Bond, Sarath Bethapudi
- Link : [http://arxiv.org/abs/2202.01020](http://arxiv.org/abs/2202.01020)
> ABSTRACT  :  Computed tomography (CT) is an effective medical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multiplanar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qualitative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets are available at https://github.com/abrilcf/mednerf  
### Beyond Fixation: Dynamic Window Visual Transformer. (arXiv:2203.12856v2 [cs.CV] UPDATED)
- Authors : Pengzhen Ren, Changlin Li, Guangrun Wang, Yun Xiao, Qing Du, Xiaodan Liang, Xiaojun Chang
- Link : [http://arxiv.org/abs/2203.12856](http://arxiv.org/abs/2203.12856)
> ABSTRACT  :  Recently, a surge of interest in visual transformers is to reduce the computational cost by limiting the calculation of self-attention to a local window. Most current work uses a fixed single-scale window for modeling by default, ignoring the impact of window size on model performance. However, this may limit the modeling potential of these window-based models for multi-scale information. In this paper, we propose a novel method, named Dynamic Window Vision Transformer (DW-ViT). The dynamic window strategy proposed by DW-ViT goes beyond the model that employs a fixed single window setting. To the best of our knowledge, we are the first to use dynamic multi-scale windows to explore the upper limit of the effect of window settings on model performance. In DW-ViT, multi-scale information is obtained by assigning windows of different sizes to different head groups of window multi-head self-attention. Then, the information is dynamically fused by assigning different weights to the multi-scale window branches. We conducted a detailed performance evaluation on three datasets, ImageNet-1K, ADE20K, and COCO. Compared with related state-of-the-art (SoTA) methods, DW-ViT obtains the best performance. Specifically, compared with the current SoTA **Swin** Transformers \cite{liu2021swin}, DW-ViT has achieved consistent and substantial improvements on all three datasets with similar parameters and computational costs. In addition, DW-ViT exhibits good scalability and can be easily inserted into any window-based visual transformers.  
### Audio-visual multi-channel speech separation, dereverberation and recognition. (arXiv:2204.01977v2 [cs.SD] UPDATED)
- Authors : Guinan Li, Jianwei Yu, Jiajun Deng, Xunying Liu, Helen Meng
- Link : [http://arxiv.org/abs/2204.01977](http://arxiv.org/abs/2204.01977)
> ABSTRACT  :  Despite the rapid advance of automatic speech recognition (ASR) technologies, accurate recognition of cocktail party speech characterised by the interference from overlapping speakers, background noise and room reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, audio-visual speech **enhancement** techniques have been developed, although predominantly targeting overlapping speech separation and recognition tasks. In this paper, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all three stages of the system is proposed. The advantage of the additional visual modality over using audio only is demonstrated on two neural dereverberation approaches based on DNN-WPE and spectral mapping respectively. The learning cost function mismatch between the separation and dereverberation models and their integration with the back-end recognition system is minimised using fine-tuning on the MSE and LF-MMI criteria. Experiments conducted on the LRS2 dataset suggest that the proposed audio-visual multi-channel speech separation, dereverberation and recognition system outperforms the baseline audio-visual multi-channel speech separation and recognition system containing no dereverberation module by a statistically significant word error rate (WER) reduction of 2.06% absolute (8.77% relative).  
## eess.IV
---
### Underwater Image **Enhancement** Using Pre-trained Transformer. (arXiv:2204.04199v1 [eess.IV])
- Authors : Abderrahmene Boudiaf, Yuhang Guo, Adarsh Ghimire, Naoufel Werghi, Giulia De, Sajid Javed, Jorge Dias
- Link : [http://arxiv.org/abs/2204.04199](http://arxiv.org/abs/2204.04199)
> ABSTRACT  :  The goal of this work is to apply a denoising image transformer to remove the distortion from underwater images and compare it with other similar approaches. Automatic **restoration** of underwater images plays an important role since it allows to increase the quality of the images, without the need for more expensive equipment. This is a critical example of the important role of the machine learning algorithms to support marine exploration and monitoring, reducing the need for human intervention like the manual processing of the images, thus saving time, effort, and cost. This paper is the first application of the image transformer-based approach called "Pre-Trained Image Processing Transformer" to underwater images. This approach is tested on the UFO-120 dataset, containing 1500 images with the corresponding clean images.  
### Dancing under the stars: video denoising in starlight. (arXiv:2204.04210v1 [cs.CV])
- Authors : Kristina Monakhova, Laura Waller, Vladlen Koltun
- Link : [http://arxiv.org/abs/2204.04210](http://arxiv.org/abs/2204.04210)
> ABSTRACT  :  Imaging in **low light** is extremely challenging due to low photon counts. Using sensitive CMOS cameras, it is currently possible to take videos at **night** under moonlight (0.05-0.3 lux illumination). In this paper, we demonstrate photorealistic video under starlight (no moon present, $&lt;$0.001 lux) for the first time. To enable this, we develop a GAN-tuned physics-based noise model to more accurately represent camera noise at the lowest light levels. Using this noise model, we train a video denoiser using a combination of simulated noisy video clips and real noisy still images. We capture a 5-10 fps video dataset with significant motion at approximately 0.6-0.7 millilux with no active illumination. Comparing against alternative methods, we achieve improved video quality at the lowest light levels, demonstrating photorealistic video denoising in starlight for the first time.  
### Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v3 [eess.IV] UPDATED)
- Authors : Abril Corona, Jonathan Frawley, Sam Bond, Sarath Bethapudi
- Link : [http://arxiv.org/abs/2202.01020](http://arxiv.org/abs/2202.01020)
> ABSTRACT  :  Computed tomography (CT) is an effective medical imaging modality, widely used in the field of clinical medicine for the diagnosis of various pathologies. Advances in Multidetector CT imaging technology have enabled additional functionalities, including generation of thin slice multiplanar cross-sectional body imaging and 3D reconstructions. However, this involves patients being exposed to a considerable dose of ionising radiation. Excessive ionising radiation can lead to deterministic and harmful effects on the body. This paper proposes a Deep Learning model that learns to reconstruct CT projections from a few or even a single-view X-ray. This is based on a novel architecture that builds from neural radiance fields, which learns a continuous representation of CT scans by disentangling the shape and volumetric depth of surface and internal anatomical structures from 2D images. Our model is trained on chest and knee datasets, and we demonstrate qualitative and quantitative high-fidelity renderings and compare our approach to other recent radiance field-based methods. Our code and link to our datasets are available at https://github.com/abrilcf/mednerf  
## cs.LG
---
### Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])
- Authors : Yutaro Yamada, Mayu Otani
- Link : [http://arxiv.org/abs/2204.03934](http://arxiv.org/abs/2204.03934)
> ABSTRACT  :  As clean ImageNet accuracy nears its ceiling, the research community is increasingly more concerned about robust accuracy under distributional shifts. While a variety of methods have been proposed to robustify neural networks, these techniques often target models trained on ImageNet classification. At the same time, it is a common practice to use ImageNet pretrained backbones for downstream tasks such as object detection, semantic segmentation, and image classification from different domains. This raises a question: Can these robust image classifiers transfer robustness to downstream tasks? For object detection and semantic segmentation, we find that a vanilla **Swin** Transformer, a variant of Vision Transformer tailored for dense prediction tasks, transfers robustness better than Convolutional Neural Networks that are trained to be robust to the corrupted version of ImageNet. For CIFAR10 classification, we find that models that are robustified for ImageNet do not retain robustness when fully fine-tuned. These findings suggest that current robustification techniques tend to emphasize ImageNet evaluations. Moreover, network architecture is a strong source of robustness when we consider transfer learning.  
### Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])
- Authors : Deqing Zhai, Xiuju Fu, Xiao Feng, Haiyan Xu, Wanbing Zhang
- Link : [http://arxiv.org/abs/2204.04085](http://arxiv.org/abs/2204.04085)
> ABSTRACT  :  Given the trend of digitization and increasing number of maritime transport, prediction of vessel berth stay has been triggered for requirements of operation research and scheduling optimization problem in the era of maritime big data, which takes a significant part in port efficiency and maritime logistics **enhancement**. This study proposes a systematic and dynamic approach of predicting berth stay for tanker terminals. The approach covers three innovative aspects: 1) Data source employed is multi-faceted, including cargo operation data from tanker terminals, time-series data from automatic identification system (AIS), etc. 2) The process of berth stay is decomposed into multiple blocks according to data analysis and information extraction innovatively, and practical operation scenarios are also developed accordingly. 3) The predictive models of berth stay are developed on the basis of prior data analysis and information extraction under two methods, including regression and decomposed distribution. The models are evaluated under four dynamic scenarios with certain designated cargoes among two different terminals. The evaluation results show that the proposed approach can predict berth stay with the accuracy up to 98.81% validated by historical baselines, and also demonstrate the proposed approach has dynamic capability of predicting berth stay among the scenarios. The model may be potentially applied for short-term pilot-booking or scheduling optimizations within a reasonable time frame for advancement of port intelligence and logistics efficiency.  
### Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition. (arXiv:2110.05267v2 [eess.AS] UPDATED)
- Authors : Yuchen Hu, Nana Hou, Chen Chen, Eng Siong
- Link : [http://arxiv.org/abs/2110.05267](http://arxiv.org/abs/2110.05267)
> ABSTRACT  :  Speech **enhancement** (SE) aims to suppress the additive noise from a noisy speech signal to improve the speech's perceptual quality and intelligibility. However, the over-suppression phenomenon in the enhanced speech might degrade the performance of downstream automatic speech recognition (ASR) task due to the missing latent information. To alleviate such problem, we propose an interactive feature fusion network (IFF-Net) for noise-robust speech recognition to learn complementary information from the enhanced feature and original noisy feature. Experimental results show that the proposed method achieves absolute word error rate (WER) reduction of 4.1% over the best baseline on RATS Channel-A corpus. Our further analysis indicates that the proposed IFF-Net can complement some missing information in the over-suppressed enhanced feature.  
### Beyond Fixation: Dynamic Window Visual Transformer. (arXiv:2203.12856v2 [cs.CV] UPDATED)
- Authors : Pengzhen Ren, Changlin Li, Guangrun Wang, Yun Xiao, Qing Du, Xiaodan Liang, Xiaojun Chang
- Link : [http://arxiv.org/abs/2203.12856](http://arxiv.org/abs/2203.12856)
> ABSTRACT  :  Recently, a surge of interest in visual transformers is to reduce the computational cost by limiting the calculation of self-attention to a local window. Most current work uses a fixed single-scale window for modeling by default, ignoring the impact of window size on model performance. However, this may limit the modeling potential of these window-based models for multi-scale information. In this paper, we propose a novel method, named Dynamic Window Vision Transformer (DW-ViT). The dynamic window strategy proposed by DW-ViT goes beyond the model that employs a fixed single window setting. To the best of our knowledge, we are the first to use dynamic multi-scale windows to explore the upper limit of the effect of window settings on model performance. In DW-ViT, multi-scale information is obtained by assigning windows of different sizes to different head groups of window multi-head self-attention. Then, the information is dynamically fused by assigning different weights to the multi-scale window branches. We conducted a detailed performance evaluation on three datasets, ImageNet-1K, ADE20K, and COCO. Compared with related state-of-the-art (SoTA) methods, DW-ViT obtains the best performance. Specifically, compared with the current SoTA **Swin** Transformers \cite{liu2021swin}, DW-ViT has achieved consistent and substantial improvements on all three datasets with similar parameters and computational costs. In addition, DW-ViT exhibits good scalability and can be easily inserted into any window-based visual transformers.  
## cs.AI
---
### IA-GCN: Interactive Graph Convolutional Network for Recommendation. (arXiv:2204.03827v1 [cs.IR])
- Authors : Yinan Zhang, Pei Wang, Xiwei Zhao, Hao Qi, Jie He, Junsheng Jin, Changping Peng, Zhangang Lin, Jingping Shao
- Link : [http://arxiv.org/abs/2204.03827](http://arxiv.org/abs/2204.03827)
> ABSTRACT  :  Recently, Graph Convolutional Network (GCN) has become a novel state-of-art for Collaborative Filtering (CF) based Recommender Systems (RS). It is a common practice to learn informative user and item representations by performing embedding propagation on a user-item bipartite graph, and then provide the users with personalized item suggestions based on the representations. Despite effectiveness, existing algorithms neglect precious interactive features between user-item pairs in the embedding process. When predicting a user's preference for different items, they still aggregate the user tree in the same way, without emphasizing target-related information in the user neighborhood. Such a uniform aggregation scheme easily leads to suboptimal user and item representations, limiting the model expressiveness to some extent.    In this work, we address this problem by building **bilateral** interactive guidance between each user-item pair and proposing a new model named IA-GCN (short for InterActive GCN). Specifically, when learning the user representation from its neighborhood, we assign higher attention weights to those neighbors similar to the target item. Correspondingly, when learning the item representation, we pay more attention to those neighbors resembling the target user. This leads to interactive and interpretable features, effectively distilling target-specific information through each graph convolutional operation. Our model is built on top of LightGCN, a state-of-the-art GCN model for CF, and can be combined with various GCN-based CF architectures in an end-to-end fashion. Extensive experiments on three benchmark datasets demonstrate the effectiveness and robustness of IA-GCN.  
### Enhance Incomplete Utterance **Restoration** by Joint Learning Token Extraction and Text Generation. (arXiv:2204.03958v1 [cs.CL])
- Authors : Shumpei Inoue, Tsungwei Liu, Nguyen Hong, Tien Nguyen
- Link : [http://arxiv.org/abs/2204.03958](http://arxiv.org/abs/2204.03958)
> ABSTRACT  :  This paper introduces a model for incomplete utterance **restoration** (IUR). Different from prior studies that only work on extraction or abstraction datasets, we design a simple but effective model, working for both scenarios of IUR. Our design simulates the nature of IUR, where omitted tokens from the context contribute to **restoration**. From this, we construct a Picker that identifies the omitted tokens. To support the picker, we design two label creation methods (soft and hard labels), which can work in cases of no annotation of the omitted tokens. The **restoration** is done by using a Generator with the help of the Picker on joint learning. Promising results on four benchmark datasets in extraction and abstraction scenarios show that our model is better than the pretrained T5 and non-generative language model methods in both rich and limited training data settings. The code will be also available.  
### Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])
- Authors : Deqing Zhai, Xiuju Fu, Xiao Feng, Haiyan Xu, Wanbing Zhang
- Link : [http://arxiv.org/abs/2204.04085](http://arxiv.org/abs/2204.04085)
> ABSTRACT  :  Given the trend of digitization and increasing number of maritime transport, prediction of vessel berth stay has been triggered for requirements of operation research and scheduling optimization problem in the era of maritime big data, which takes a significant part in port efficiency and maritime logistics **enhancement**. This study proposes a systematic and dynamic approach of predicting berth stay for tanker terminals. The approach covers three innovative aspects: 1) Data source employed is multi-faceted, including cargo operation data from tanker terminals, time-series data from automatic identification system (AIS), etc. 2) The process of berth stay is decomposed into multiple blocks according to data analysis and information extraction innovatively, and practical operation scenarios are also developed accordingly. 3) The predictive models of berth stay are developed on the basis of prior data analysis and information extraction under two methods, including regression and decomposed distribution. The models are evaluated under four dynamic scenarios with certain designated cargoes among two different terminals. The evaluation results show that the proposed approach can predict berth stay with the accuracy up to 98.81% validated by historical baselines, and also demonstrate the proposed approach has dynamic capability of predicting berth stay among the scenarios. The model may be potentially applied for short-term pilot-booking or scheduling optimizations within a reasonable time frame for advancement of port intelligence and logistics efficiency.  
### The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation. (arXiv:2202.13307v2 [cs.IR] UPDATED)
- Authors : Yashar Deldjoo, Ali Tourani, Mohammadmehdi Naghiaei
- Link : [http://arxiv.org/abs/2202.13307](http://arxiv.org/abs/2202.13307)
> ABSTRACT  :  Point-of-Interest (POI) recommender systems provide personalized recommendations to users and help businesses attract potential customers. Despite their success, recent studies suggest that highly data-driven recommendations could be impacted by data biases, resulting in unfair outcomes for different stakeholders, mainly consumers (users) and providers (items). Most existing fairness-related research works in recommender systems treat user fairness and item fairness issues individually, disregarding that RS work in a two-sided marketplace. This paper studies the interplay between (i) the unfairness of active users, (ii) the unfairness of popular items, and (iii) the accuracy (personalization) of recommendation as three angles of our study triangle. We group users into advantaged and disadvantaged levels to measure user fairness based on their activity level. For item fairness, we divide items into short-head, mid-tail, and long-tail groups and study the **exposure** of these item groups into the top-k recommendation list of users. Experimental validation of eight different recommendation models commonly used for POI recommendation (e.g., contextual, CF) on two publicly available POI recommendation datasets, Gowalla and Yelp, indicate that most well-performing models suffer seriously from the unfairness of popularity bias (provider unfairness). Furthermore, our study shows that most recommendation models cannot satisfy both consumer and producer fairness, indicating a trade-off between these variables possibly due to natural biases in data. We choose the POI recommendation as our test scenario; however, the insights should be trivially extendable on other domains.  
# Paper List
---
## cs.CV
---
**101** new papers in cs.CV:-) 
1. PlutoNet: An Efficient Polyp Segmentation Network. (arXiv:2204.03652v1 [eess.IV])
2. Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder. (arXiv:2204.03654v1 [eess.IV])
3. TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates. (arXiv:2204.03671v1 [cs.CV])
4. DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image. (arXiv:2204.03688v1 [cs.CV])
5. Adaptive-Gravity: A Defense Against Adversarial Samples. (arXiv:2204.03694v1 [cs.LG])
6. Predicting Solar Flares Using CNN and LSTM on Two Solar Cycles of Active Region Data. (arXiv:2204.03710v1 [astro-ph.SR])
7. Using Multiple Self-Supervised Tasks Improves Model Robustness. (arXiv:2204.03714v1 [cs.CV])
8. Gravitationally Lensed Black Hole Emission Tomography. (arXiv:2204.03715v1 [cs.CV])
9. Automated Design of Salient Object Detection Algorithms with Brain Programming. (arXiv:2204.03722v1 [cs.CV])
10. MHMS: Multimodal Hierarchical Multimedia Summarization. (arXiv:2204.03734v1 [cs.CV])
11. BankNote-Net: Open dataset for assistive universal currency recognition. (arXiv:2204.03738v1 [cs.CV])
12. Drivers' attention detection: a systematic literature review. (arXiv:2204.03741v1 [cs.CV])
13. Mitosis domain generalization in histopathology images -- The MIDOG challenge. (arXiv:2204.03742v1 [eess.IV])
14. Powering Finetuning in Few-shot Learning: Domain-Agnostic Feature Adaptation with Rectified Class Prototypes. (arXiv:2204.03749v1 [cs.CV])
15. Multi-objective optimization determines when, which and how to fuse deep networks: an application to predict COVID-19 outcomes. (arXiv:2204.03772v1 [eess.IV])
16. TorMentor: Deterministic dynamic-path, data augmentations with fractals. (arXiv:2204.03776v1 [cs.CV])
17. Semantic Representation and Dependency Learning for Multi-Label Image Recognition. (arXiv:2204.03795v1 [cs.CV])
18. A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis. (arXiv:2204.03804v1 [eess.IV])
19. Canonical Mean Filter for Almost Zero-Shot Multi-Task classification. (arXiv:2204.03815v1 [cs.CV])
20. Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation. (arXiv:2204.03838v1 [cs.CV])
21. From 2D Images to 3D Model:Weakly Supervised Multi-View Face Reconstruction with Deep Fusion. (arXiv:2204.03842v1 [cs.CV])
22. Prediction of COVID-19 using chest X-ray images. (arXiv:2204.03849v1 [eess.IV])
23. Multi-scale temporal network for continuous sign language recognition. (arXiv:2204.03864v1 [cs.CV])
24. Spatiotemporal Augmentation on Selective Frequencies for Video Representation Learning. (arXiv:2204.03865v1 [cs.CV])
25. Controllable Missingness from Uncontrollable Missingness: Joint Learning Measurement Policy and Imputation. (arXiv:2204.03872v1 [cs.LG])
26. Spatial Transformer Network on Skeleton-based Gait Recognition. (arXiv:2204.03873v1 [cs.CV])
27. CD$^2$-pFed: Cyclic Distillation-guided Channel Decoupling for Model Personalization in Federated Learning. (arXiv:2204.03880v1 [cs.CV])
28. Vision Transformers for Single Image Dehazing. (arXiv:2204.03883v1 [cs.CV])
29. SuperNet in Neural Architecture Search: A Taxonomic Survey. (arXiv:2204.03916v1 [cs.CV])
30. Biometric identification by means of hand geometry and a neural net classifier. (arXiv:2204.03925v1 [cs.CV])
31. Deep Hyperspectral-Depth Reconstruction Using Single Color-Dot Projection. (arXiv:2204.03929v1 [cs.CV])
32. Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])
33. Study of a committee of neural networks for biometric hand-geometry recognition. (arXiv:2204.03935v1 [cs.CV])
34. On Distinctive Image Captioning via Comparing and Reweighting. (arXiv:2204.03938v1 [cs.CV])
35. Probabilistic Representations for Video Contrastive Learning. (arXiv:2204.03946v1 [cs.CV])
36. Points to Patches: Enabling the Use of Self-Attention for 3D Shape Recognition. (arXiv:2204.03957v1 [cs.CV])
37. SnapMode: An Intelligent and Distributed Large-Scale Fashion Image Retrieval Platform Based On Big Data and Deep Generative Adversarial Network Technologies. (arXiv:2204.03998v1 [cs.IR])
38. Multimodal Quasi-AutoRegression: Forecasting the visual popularity of new fashion products. (arXiv:2204.04014v1 [cs.CV])
39. Engagement Detection with Multi-Task Training in E-Learning Environments. (arXiv:2204.04020v1 [cs.CV])
40. A Generic Image Retrieval Method for Date Estimation of Historical Document Collections. (arXiv:2204.04028v1 [cs.CV])
41. Confidence Score for Unsupervised Foreground Background Separation of Document Images. (arXiv:2204.04044v1 [cs.CV])
42. Efficient tracking of team sport players with few game-specific annotations. (arXiv:2204.04049v1 [cs.CV])
43. Identifying Ambiguous Similarity Conditions via Semantic Matching. (arXiv:2204.04053v1 [cs.CV])
44. Deep Learning-Based Intra Mode Derivation for Versatile Video Coding. (arXiv:2204.04059v1 [eess.IV])
45. Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. (arXiv:2204.04063v1 [cs.CV])
46. Invariant Descriptors for Intrinsic Reflectance Optimization. (arXiv:2204.04076v1 [cs.CV])
47. General Incremental Learning with Domain-aware Categorical Representations. (arXiv:2204.04078v1 [cs.CV])
48. POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition. (arXiv:2204.04083v1 [cs.CV])
49. Dynamic super-resolution in particle tracking problems. (arXiv:2204.04092v1 [eess.SP])
50. Visible-Thermal UAV Tracking: A Large-Scale Benchmark and New Baseline. (arXiv:2204.04120v1 [cs.CV])
51. Sat2lod2: A Software For Automated Lod-2 Modeling From Satellite-Derived Orthophoto And Digital Surface Model. (arXiv:2204.04139v1 [cs.CV])
52. Investigating Spherical Epipolar Rectification for Multi-View Stereo 3D Reconstruction. (arXiv:2204.04141v1 [cs.CV])
53. A Novel Intrinsic Image Decomposition Method to Recover Albedo for Aerial Images in Photogrammetry Processing. (arXiv:2204.04142v1 [cs.CV])
54. Optical tracking in team sports. (arXiv:2204.04143v1 [cs.CV])
55. Constrained Bundle Adjustment for Structure From Motion Using Uncalibrated Multi-Camera Systems. (arXiv:2204.04145v1 [cs.CV])
56. A Video Anomaly Detection Framework based on Appearance-Motion Semantics Representation Consistency. (arXiv:2204.04151v1 [cs.CV])
57. Particle Videos Revisited: Tracking Through Occlusions Using Point Trajectories. (arXiv:2204.04153v1 [cs.CV])
58. Underwater Image **Enhancement** Using Pre-trained Transformer. (arXiv:2204.04199v1 [eess.IV])
59. Dancing under the stars: video denoising in starlight. (arXiv:2204.04210v1 [cs.CV])
60. Searching for Apparel Products from Images in the Wild. (arXiv:1907.02244v2 [cs.CV] UPDATED)
61. Gaining Scale Invariance in UAV Bird's Eye View Object Detection by Adaptive Resizing. (arXiv:2101.12694v2 [cs.CV] UPDATED)
62. Generalizing to Unseen Domains: A Survey on Domain Generalization. (arXiv:2103.03097v6 [cs.LG] UPDATED)
63. Learning Graph Embeddings for Open World Compositional Zero-Shot Learning. (arXiv:2105.01017v3 [cs.CV] UPDATED)
64. A Voxel Graph CNN for Object Classification with Event Cameras. (arXiv:2106.00216v3 [cs.CV] UPDATED)
65. Provident Vehicle Detection at **Night** for Advanced Driver Assistance Systems. (arXiv:2107.11302v3 [cs.CV] UPDATED)
66. CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v2 [cs.CV] UPDATED)
67. Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v4 [cs.CV] UPDATED)
68. Rethinking the Misalignment Problem in Dense Object Detection. (arXiv:2108.12176v3 [cs.CV] UPDATED)
69. CardiSort: a convolutional neural network for cross vendor automated sorting of cardiac MR images. (arXiv:2109.08479v2 [eess.IV] UPDATED)
70. Consistent Explanations by Contrastive Learning. (arXiv:2110.00527v2 [cs.CV] UPDATED)
71. Image prediction of disease progression by style-based manifold extrapolation. (arXiv:2111.11439v2 [eess.IV] UPDATED)
72. A War Beyond Deepfake: Benchmarking Facial Counterfeits and Countermeasures. (arXiv:2111.12912v2 [cs.CV] UPDATED)
73. SPIN: Simplifying Polar Invariance for Neural networks Application to vision-based irradiance forecasting. (arXiv:2111.14507v3 [cs.CV] UPDATED)
74. Robust Partial-to-Partial Point Cloud Registration in a Full Range. (arXiv:2111.15606v2 [cs.CV] UPDATED)
75. Event-Based Fusion for Motion Deblurring with Cross-modal Attention. (arXiv:2112.00167v2 [cs.CV] UPDATED)
76. Federated Learning with Adaptive Batchnorm for Personalized Healthcare. (arXiv:2112.00734v2 [cs.LG] UPDATED)
77. Putting 3D Spatially Sparse Networks on a Diet. (arXiv:2112.01316v2 [cs.CV] UPDATED)
78. GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v3 [cs.CV] UPDATED)
79. Human Hands as Probes for Interactive Object Understanding. (arXiv:2112.09120v2 [cs.CV] UPDATED)
80. An effective coaxiality measurement for twist drill based on line structured light sensor. (arXiv:2112.09873v3 [cs.CV] UPDATED)
81. An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v2 [cs.LG] UPDATED)
82. Generalised Image Outpainting with U-Transformer. (arXiv:2201.11403v3 [cs.CV] UPDATED)
83. Should I take a walk? Estimating Energy Expenditure from Video Data. (arXiv:2202.00712v2 [cs.CV] UPDATED)
84. Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v3 [eess.IV] UPDATED)
85. Cyber Mobility Mirror: A Deep Learning-based Real-World Object Perception Platform Using Roadside LiDAR. (arXiv:2202.13505v2 [cs.CV] UPDATED)
86. Improving Point Cloud Based Place Recognition with Ranking-based Loss and Large Batch Training. (arXiv:2203.00972v2 [cs.CV] UPDATED)
87. OVE6D: Object Viewpoint Encoding for Depth-based 6D Object Pose Estimation. (arXiv:2203.01072v3 [cs.CV] UPDATED)
88. HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction. (arXiv:2203.01577v3 [cs.CV] UPDATED)
89. PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence. (arXiv:2203.01754v2 [cs.CV] UPDATED)
90. Voice-Face Homogeneity Tells Deepfake. (arXiv:2203.02195v2 [cs.CV] UPDATED)
91. HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR. (arXiv:2203.09215v2 [cs.CV] UPDATED)
92. Beyond Fixation: Dynamic Window Visual Transformer. (arXiv:2203.12856v2 [cs.CV] UPDATED)
93. Facial Expression Classification using Fusion of Deep Neural Network in Video for the 3rd ABAW3 Competition. (arXiv:2203.12899v3 [cs.CV] UPDATED)
94. MGRR-Net: Multi-level Graph Relational Reasoning Network for Facial Action Units Detection. (arXiv:2204.01349v2 [cs.CV] UPDATED)
95. DAD: Data-free Adversarial Defense at Test Time. (arXiv:2204.01568v2 [cs.LG] UPDATED)
96. Audio-visual multi-channel speech separation, dereverberation and recognition. (arXiv:2204.01977v2 [cs.SD] UPDATED)
97. Fine-Grained Predicates Learning for Scene Graph Generation. (arXiv:2204.02597v2 [cs.CV] UPDATED)
98. MDA GAN: Adversarial-Learning-based 3-D Seismic Data Interpolation and Reconstruction for Complex Missing. (arXiv:2204.03197v2 [physics.geo-ph] UPDATED)
99. Context-Sensitive Temporal Feature Learning for Gait Recognition. (arXiv:2204.03270v2 [cs.CV] UPDATED)
100. Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale. (arXiv:2204.03514v2 [cs.AI] UPDATED)
101. A Comprehensive Review of Sign Language Recognition: Different Types, Modalities, and Datasets. (arXiv:2204.03328v1 [cs.CV] CROSS LISTED)
## eess.IV
---
**21** new papers in eess.IV:-) 
1. PlutoNet: An Efficient Polyp Segmentation Network. (arXiv:2204.03652v1 [eess.IV])
2. Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder. (arXiv:2204.03654v1 [eess.IV])
3. Physics-assisted Generative Adversarial Network for X-Ray Tomography. (arXiv:2204.03703v1 [eess.IV])
4. Mitosis domain generalization in histopathology images -- The MIDOG challenge. (arXiv:2204.03742v1 [eess.IV])
5. Multi-objective optimization determines when, which and how to fuse deep networks: an application to predict COVID-19 outcomes. (arXiv:2204.03772v1 [eess.IV])
6. A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis. (arXiv:2204.03804v1 [eess.IV])
7. Prediction of COVID-19 using chest X-ray images. (arXiv:2204.03849v1 [eess.IV])
8. Lensless coherent diffraction imaging based on spatial light modulator with unknown modulation curve. (arXiv:2204.03947v1 [physics.optics])
9. Deep Learning-Based Intra Mode Derivation for Versatile Video Coding. (arXiv:2204.04059v1 [eess.IV])
10. Reconstruction of Videos Taken by a Non-Regular Sampling Sensor. (arXiv:2204.04064v1 [eess.IV])
11. Reducing Randomness of Non-Regular Sampling Masks for Image Reconstruction. (arXiv:2204.04065v1 [eess.IV])
12. Reconstruction of images taken by a pair of non-regular sampling sensors using correlation based matching. (arXiv:2204.04067v1 [eess.IV])
13. Automatic Census of Mussel Platforms Using Sentinel 2 Images. (arXiv:2204.04112v1 [eess.IV])
14. Underwater Image **Enhancement** Using Pre-trained Transformer. (arXiv:2204.04199v1 [eess.IV])
15. Dancing under the stars: video denoising in starlight. (arXiv:2204.04210v1 [cs.CV])
16. Searching for Apparel Products from Images in the Wild. (arXiv:1907.02244v2 [cs.CV] UPDATED)
17. CardiSort: a convolutional neural network for cross vendor automated sorting of cardiac MR images. (arXiv:2109.08479v2 [eess.IV] UPDATED)
18. Image prediction of disease progression by style-based manifold extrapolation. (arXiv:2111.11439v2 [eess.IV] UPDATED)
19. Artifacts in optical projection tomography due to refractive index mismatch: model and correction. (arXiv:2112.12602v3 [physics.optics] UPDATED)
20. Med**NeRF**: Medical Neural Radiance Fields for Reconstructing 3D-aware CT-Projections from a Single X-ray. (arXiv:2202.01020v3 [eess.IV] UPDATED)
21. Facial Expression Classification using Fusion of Deep Neural Network in Video for the 3rd ABAW3 Competition. (arXiv:2203.12899v3 [cs.CV] UPDATED)
## cs.LG
---
**114** new papers in cs.LG:-) 
1. Identification of Autism spectrum disorder based on a novel feature selection method and Variational Autoencoder. (arXiv:2204.03654v1 [eess.IV])
2. Learning to Walk Autonomously via Reset-Free Quality-Diversity. (arXiv:2204.03655v1 [cs.LG])
3. Qade: Solving Differential Equations on Quantum Annealers. (arXiv:2204.03657v1 [quant-ph])
4. TemporalUV: Capturing Loose Clothing with Temporally Coherent UV Coordinates. (arXiv:2204.03671v1 [cs.CV])
5. Adaptive-Gravity: A Defense Against Adversarial Samples. (arXiv:2204.03694v1 [cs.LG])
6. Physics-assisted Generative Adversarial Network for X-Ray Tomography. (arXiv:2204.03703v1 [eess.IV])
7. Introducing a Framework and a Decision Protocol to Calibrate Recommender Systems. (arXiv:2204.03706v1 [cs.IR])
8. Using Multiple Self-Supervised Tasks Improves Model Robustness. (arXiv:2204.03714v1 [cs.CV])
9. A survey on learning from imbalanced data streams: taxonomy, challenges, empirical study, and reproducible experimental framework. (arXiv:2204.03719v1 [cs.LG])
10. Automated Design of Salient Object Detection Algorithms with Brain Programming. (arXiv:2204.03722v1 [cs.CV])
11. A Kernel Method to Nonlinear Location Estimation with RSS-based Fingerprint. (arXiv:2204.03724v1 [cs.NI])
12. T4PdM: a Deep Neural Network based on the Transformer Architecture for Fault Diagnosis of Rotating Machinery. (arXiv:2204.03725v1 [cs.AI])
13. Decentralized Event-Triggered Federated Learning with Heterogeneous Communication Thresholds. (arXiv:2204.03726v1 [cs.LG])
14. GreaseVision: Rewriting the Rules of the Interface. (arXiv:2204.03731v1 [cs.HC])
15. Mixing Signals: Data Augmentation Approach for Deep Learning Based Modulation Recognition. (arXiv:2204.03737v1 [eess.SP])
16. BankNote-Net: Open dataset for assistive universal currency recognition. (arXiv:2204.03738v1 [cs.CV])
17. Brain-Inspired Hyperdimensional Computing: How Thermal-Friendly for Edge Computing?. (arXiv:2204.03739v1 [cs.ET])
18. Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG])
19. Quantum version of the k-NN classifier based on a quantum sorting algorithm. (arXiv:2204.03761v1 [quant-ph])
20. Global ECG Classification by Self-Operational Neural Networks with Feature Injection. (arXiv:2204.03768v1 [cs.LG])
21. Q-learning with online random forests. (arXiv:2204.03771v1 [stat.ML])
22. Free Energy Evaluation Using Marginalized Annealed Importance Sampling. (arXiv:2204.03784v1 [stat.ML])
23. Personal VAD 2.0: Optimizing Personal Voice Activity Detection for On-Device Speech Recognition. (arXiv:2204.03793v1 [eess.AS])
24. A Learnable Variational Model for Joint Multimodal MRI Reconstruction and Synthesis. (arXiv:2204.03804v1 [eess.IV])
25. Federated Learning with Partial Model Personalization. (arXiv:2204.03809v1 [cs.LG])
26. Exploring the Universality of Hadronic Jet Classification. (arXiv:2204.03812v1 [hep-ph])
27. DiversiTree: Computing Diverse Sets of Near-Optimal Solutions to Mixed-Integer Optimization Problems. (arXiv:2204.03822v1 [cs.DM])
28. Does the Market of Citations Reward Reproducible Work?. (arXiv:2204.03829v1 [cs.DL])
29. Data-Driven Evaluation of Training Action Space for Reinforcement Learning. (arXiv:2204.03840v1 [cs.LG])
30. Decomposition-based Generation Process for Instance-Dependent Partial Label Learning. (arXiv:2204.03845v1 [cs.LG])
31. Controllable Missingness from Uncontrollable Missingness: Joint Learning Measurement Policy and Imputation. (arXiv:2204.03872v1 [cs.LG])
32. CD$^2$-pFed: Cyclic Distillation-guided Channel Decoupling for Model Personalization in Federated Learning. (arXiv:2204.03880v1 [cs.CV])
33. Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 1. (arXiv:2204.03899v1 [cs.CE])
34. A posteriori learning for quasi-geostrophic turbulence parametrization. (arXiv:2204.03911v1 [physics.flu-dyn])
35. SuperNet in Neural Architecture Search: A Taxonomic Survey. (arXiv:2204.03916v1 [cs.CV])
36. Network Shuffling: Privacy Amplification via Random Walks. (arXiv:2204.03919v1 [cs.CR])
37. Global Update Guided Federated Learning. (arXiv:2204.03920v1 [cs.LG])
38. Does Robustness on ImageNet Transfer to Downstream Tasks?. (arXiv:2204.03934v1 [cs.CV])
39. Study of a committee of neural networks for biometric hand-geometry recognition. (arXiv:2204.03935v1 [cs.CV])
40. Channel model for end-to-end learning of communications systems: A survey. (arXiv:2204.03944v1 [cs.LG])
41. Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 2. (arXiv:2204.03955v1 [cs.CE])
42. Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v1 [cs.AI])
43. Disability prediction in multiple sclerosis using performance outcome measures and demographic data. (arXiv:2204.03969v1 [cs.LG])
44. KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v1 [cs.CL])
45. The Complexity of Markov Equilibrium in Stochastic Games. (arXiv:2204.03991v1 [cs.LG])
46. ECG Biometric Recognition: Review, System Proposal, and Benchmark Evaluation. (arXiv:2204.03992v1 [cs.LG])
47. Labeling-Free Comparison Testing of Deep Learning Models. (arXiv:2204.03994v1 [cs.LG])
48. SnapMode: An Intelligent and Distributed Large-Scale Fashion Image Retrieval Platform Based On Big Data and Deep Generative Adversarial Network Technologies. (arXiv:2204.03998v1 [cs.IR])
49. Mel-spectrogram features for acoustic vehicle detection and speed estimation. (arXiv:2204.04013v1 [cs.LG])
50. Disentangled Latent Speech Representation for Automatic Pathological Intelligibility Assessment. (arXiv:2204.04016v1 [eess.AS])
51. Quantum Machine Learning Framework for Virtual Screening in Drug Discovery: a Prospective Quantum Advantage. (arXiv:2204.04017v1 [quant-ph])
52. Engagement Detection with Multi-Task Training in E-Learning Environments. (arXiv:2204.04020v1 [cs.CV])
53. Ontology Matching Through Absolute Orientation of Embedding Spaces. (arXiv:2204.04040v1 [cs.AI])
54. Checking HateCheck: a cross-functional analysis of behaviour-aware learning for hate speech detection. (arXiv:2204.04042v1 [cs.CL])
55. C-NMT: A Collaborative Inference Framework for Neural Machine Translation. (arXiv:2204.04043v1 [cs.LG])
56. KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media. (arXiv:2204.04046v1 [cs.LG])
57. GPSAF: A Generalized Probabilistic Surrogate-Assisted Framework for Constrained Single- and Multi-objective Optimization. (arXiv:2204.04054v1 [math.OC])
58. Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. (arXiv:2204.04063v1 [cs.CV])
59. Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])
60. Generative Adversarial Method Based On Neural Tangent Kernels. (arXiv:2204.04090v1 [cs.LG])
61. Karaoker: Alignment-free singing voice synthesis with speech training data. (arXiv:2204.04127v1 [eess.AS])
62. EPASAD: Ellipsoid decision boundary based Process-Aware Stealthy Attack Detector. (arXiv:2204.04154v1 [cs.CR])
63. Self-supervised Speaker Diarization. (arXiv:2204.04166v1 [cs.SD])
64. Ranking with submodular functions on a budget. (arXiv:2204.04168v1 [cs.DS])
65. Automatic Data Augmentation Selection and Parametrization in Contrastive Self-Supervised Speech Representation Learning. (arXiv:2204.04170v1 [eess.AS])
66. A Low-Cost Robot Science Kit for Education with Symbolic Regression for Hypothesis Discovery and Validation. (arXiv:2204.04187v1 [cond-mat.mtrl-sci])
67. Learning Polynomial Transformations. (arXiv:2204.04209v1 [cs.LG])
68. Measuring AI Systems Beyond Accuracy. (arXiv:2204.04211v1 [cs.SE])
69. Adaptive dynamic programming for nonaffine nonlinear optimal control problem with state constraints. (arXiv:1911.11397v3 [eess.SY] UPDATED)
70. TF-Coder: Program Synthesis for Tensor Manipulations. (arXiv:2003.09040v4 [cs.PL] UPDATED)
71. Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v3 [cs.LG] UPDATED)
72. Two-stage Training of Graph Neural Networks for Graph Classification. (arXiv:2011.05097v4 [cs.LG] UPDATED)
73. Neural graph embeddings via matrix factorization for link prediction: smoothing or truncating negatives?. (arXiv:2011.09907v2 [cs.SI] UPDATED)
74. Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v4 [cs.LG] UPDATED)
75. Generalizing to Unseen Domains: A Survey on Domain Generalization. (arXiv:2103.03097v6 [cs.LG] UPDATED)
76. Learning-Based Vulnerability Analysis of Cyber-Physical Systems. (arXiv:2103.06271v3 [cs.CR] UPDATED)
77. How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v3 [cs.LG] UPDATED)
78. Covariance-Free Sparse Bayesian Learning. (arXiv:2105.10439v2 [eess.SP] UPDATED)
79. MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v3 [cs.LG] UPDATED)
80. On the Convergence of Stochastic Extragradient for Bilinear Games using Restarted Iteration Averaging. (arXiv:2107.00464v4 [math.OC] UPDATED)
81. Pretext Tasks selection for multitask self-supervised speech representation learning. (arXiv:2107.00594v4 [eess.AS] UPDATED)
82. Constraints Penalized Q-learning for Safe Offline Reinforcement Learning. (arXiv:2107.09003v3 [cs.LG] UPDATED)
83. Federated Causal Inference in Heterogeneous Observational Data. (arXiv:2107.11732v3 [cs.LG] UPDATED)
84. Low-Resource Adaptation of Open-Domain Generative Chatbots. (arXiv:2108.06329v2 [cs.CL] UPDATED)
85. CONet: Channel Optimization for Convolutional Neural Networks. (arXiv:2108.06822v2 [cs.CV] UPDATED)
86. Group-based Distinctive Image Captioning with Memory Attention. (arXiv:2108.09151v4 [cs.CV] UPDATED)
87. Interactive Feature Fusion for End-to-End Noise-Robust Speech Recognition. (arXiv:2110.05267v2 [eess.AS] UPDATED)
88. Omni-Training for Data-Efficient Deep Learning. (arXiv:2110.07510v2 [cs.LG] UPDATED)
89. AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning. (arXiv:2110.13005v4 [cs.LG] UPDATED)
90. Active Linear Regression for $\ell_p$ Norms and Beyond. (arXiv:2111.04888v3 [cs.LG] UPDATED)
91. Image prediction of disease progression by style-based manifold extrapolation. (arXiv:2111.11439v2 [eess.IV] UPDATED)
92. Federated Learning with Adaptive Batchnorm for Personalized Healthcare. (arXiv:2112.00734v2 [cs.LG] UPDATED)
93. GCA-Net : Utilizing Gated Context Attention for Improving Image Forgery Localization and Detection. (arXiv:2112.04298v3 [cs.CV] UPDATED)
94. Spinning Language Models: Risks of Propaganda-As-A-Service and Countermeasures. (arXiv:2112.05224v2 [cs.CR] UPDATED)
95. Human Hands as Probes for Interactive Object Understanding. (arXiv:2112.09120v2 [cs.CV] UPDATED)
96. An analysis of over-sampling labeled data in semi-supervised learning with FixMatch. (arXiv:2201.00604v2 [cs.LG] UPDATED)
97. Neural network training under semidefinite constraints. (arXiv:2201.00632v2 [cs.LG] UPDATED)
98. Neural Network Optimization for Reinforcement Learning Tasks Using Sparse Computations. (arXiv:2201.02571v2 [cs.LG] UPDATED)
99. Identifiability of Label Noise Transition Matrix. (arXiv:2202.02016v2 [cs.LG] UPDATED)
100. Measuring disentangled generative spatio-temporal representation. (arXiv:2202.04821v2 [cs.LG] UPDATED)
101. Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)
102. A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v2 [cs.LG] UPDATED)
103. Beyond Fixation: Dynamic Window Visual Transformer. (arXiv:2203.12856v2 [cs.CV] UPDATED)
104. A Manifold View of Adversarial Risk. (arXiv:2203.13277v2 [cs.LG] UPDATED)
105. Combining Evolution and Deep Reinforcement Learning for Policy Search: a Survey. (arXiv:2203.14009v3 [cs.LG] UPDATED)
106. Training strategy for a lightweight countermeasure model for automatic speaker verification. (arXiv:2203.17031v3 [cs.SD] UPDATED)
107. DAD: Data-free Adversarial Defense at Test Time. (arXiv:2204.01568v2 [cs.LG] UPDATED)
108. VNIbCReg: VICReg with Neighboring-Invariance and better-Covariance Evaluated on Non-stationary Seismic Signal Time Series. (arXiv:2204.02697v3 [cs.LG] UPDATED)
109. Accelerating Attention through Gradient-Based Learned Runtime Pruning. (arXiv:2204.03227v2 [cs.CL] UPDATED)
110. Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation. (arXiv:2204.03293v2 [cs.SE] UPDATED)
111. Generalised Latent Assimilation in Heterogeneous Reduced Spaces with Machine Learning Surrogate Models. (arXiv:2204.03497v2 [cs.LG] UPDATED)
112. Interval Bound Propagation$\unicode{x2013}$aided Few$\unicode{x002d}$shot Learning. (arXiv:2204.03511v2 [cs.LG] UPDATED)
113. FedADMM: A Robust Federated Deep Learning Framework with Adaptivity to System Heterogeneity. (arXiv:2204.03529v2 [cs.LG] UPDATED)
114. Text-Aware Predictive Monitoring of Business Processes. (arXiv:2104.09962v2 [cs.AI] CROSS LISTED)
## cs.AI
---
**70** new papers in cs.AI:-) 
1. Learning to Walk Autonomously via Reset-Free Quality-Diversity. (arXiv:2204.03655v1 [cs.LG])
2. DAD-3DHeads: A Large-scale Dense, Accurate and Diverse Dataset for 3D Head Alignment from a Single Image. (arXiv:2204.03688v1 [cs.CV])
3. Predicting Solar Flares Using CNN and LSTM on Two Solar Cycles of Active Region Data. (arXiv:2204.03710v1 [astro-ph.SR])
4. T4PdM: a Deep Neural Network based on the Transformer Architecture for Fault Diagnosis of Rotating Machinery. (arXiv:2204.03725v1 [cs.AI])
5. Successes and critical failures of neural networks in capturing human-like speech recognition. (arXiv:2204.03740v1 [cs.SD])
6. Automated Isovist Computation for Minecraft. (arXiv:2204.03752v1 [cs.AI])
7. TorMentor: Deterministic dynamic-path, data augmentations with fractals. (arXiv:2204.03776v1 [cs.CV])
8. End-of-Life of Software How is it Defined and Managed?. (arXiv:2204.03800v1 [cs.SE])
9. IA-GCN: Interactive Graph Convolutional Network for Recommendation. (arXiv:2204.03827v1 [cs.IR])
10. Does the Market of Citations Reward Reproducible Work?. (arXiv:2204.03829v1 [cs.DL])
11. PharmMT: A Neural Machine Translation Approach to Simplify Prescription Directions. (arXiv:2204.03830v1 [cs.CL])
12. Picture Fuzzy Interactional Aggregation Operators via Strict Triangular Norms and Applications to Multi-Criteria Decision Making. (arXiv:2204.03878v1 [cs.AI])
13. Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 1. (arXiv:2204.03899v1 [cs.CE])
14. HINNPerf: Hierarchical Interaction Neural Network for Performance Prediction of Configurable Systems. (arXiv:2204.03931v1 [cs.SE])
15. On Distinctive Image Captioning via Comparing and Reweighting. (arXiv:2204.03938v1 [cs.CV])
16. RuBioRoBERTa: a pre-trained biomedical language model for Russian language biomedical text mining. (arXiv:2204.03951v1 [cs.CL])
17. Optimizing Coordinative Schedules for Tanker Terminals: An Intelligent Large Spatial-Temporal Data-Driven Approach -- Part 2. (arXiv:2204.03955v1 [cs.CE])
18. Enhance Incomplete Utterance **Restoration** by Joint Learning Token Extraction and Text Generation. (arXiv:2204.03958v1 [cs.CL])
19. Blockchain as an Enabler for Transfer Learning in Smart Environments. (arXiv:2204.03959v1 [cs.AI])
20. KGI: An Integrated Framework for Knowledge Intensive Language Tasks. (arXiv:2204.03985v1 [cs.CL])
21. ECG Biometric Recognition: Review, System Proposal, and Benchmark Evaluation. (arXiv:2204.03992v1 [cs.LG])
22. Labeling-Free Comparison Testing of Deep Learning Models. (arXiv:2204.03994v1 [cs.LG])
23. SnapMode: An Intelligent and Distributed Large-Scale Fashion Image Retrieval Platform Based On Big Data and Deep Generative Adversarial Network Technologies. (arXiv:2204.03998v1 [cs.IR])
24. On Projectivity in Markov Logic Networks. (arXiv:2204.04009v1 [cs.AI])
25. Ontology Matching Through Absolute Orientation of Embedding Spaces. (arXiv:2204.04040v1 [cs.AI])
26. C-NMT: A Collaborative Inference Framework for Neural Machine Translation. (arXiv:2204.04043v1 [cs.LG])
27. KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media. (arXiv:2204.04046v1 [cs.LG])
28. Transfer Attacks Revisited: A Large-Scale Empirical Study in Real Computer Vision Settings. (arXiv:2204.04063v1 [cs.CV])
29. Utility Functions for Human/Robot Interaction. (arXiv:2204.04071v1 [cs.AI])
30. Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese. (arXiv:2204.04080v1 [cs.CL])
31. POSTER: A Pyramid Cross-Fusion Transformer Network for Facial Expression Recognition. (arXiv:2204.04083v1 [cs.CV])
32. Predicting Berth Stay for Tanker Terminals: A Systematic and Dynamic Approach. (arXiv:2204.04085v1 [cs.CE])
33. EfficientFi: Towards Large-Scale Lightweight WiFi Sensing via CSI Compression. (arXiv:2204.04138v1 [cs.NI])
34. Optical tracking in team sports. (arXiv:2204.04143v1 [cs.CV])
35. Process Mining on Uncertain Event Data. (arXiv:2204.04148v1 [cs.AI])
36. Uncertain Case Identifiers in Process Mining: A User Study of the Event-Case Correlation Problem on Click Data. (arXiv:2204.04164v1 [cs.DB])
37. GRAM: Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering. (arXiv:2204.04179v1 [cs.CL])
38. Efficient Partial Credit Grading of Proof Blocks Problems. (arXiv:2204.04196v1 [cs.AI])
39. Measuring AI Systems Beyond Accuracy. (arXiv:2204.04211v1 [cs.SE])
40. Mining Uncertain Event Data in Process Mining. (arXiv:1910.00089v4 [cs.AI] UPDATED)
41. Conformance Checking over Uncertain Event Data. (arXiv:2009.14452v3 [cs.AI] UPDATED)
42. Neural graph embeddings via matrix factorization for link prediction: smoothing or truncating negatives?. (arXiv:2011.09907v2 [cs.SI] UPDATED)
43. Benchmarks, Algorithms, and Metrics for Hierarchical Disentanglement. (arXiv:2102.05185v4 [cs.LG] UPDATED)
44. Generalizing to Unseen Domains: A Survey on Domain Generalization. (arXiv:2103.03097v6 [cs.LG] UPDATED)
45. PROVED: A Tool for Graph Representation and Analysis of Uncertain Event Data. (arXiv:2103.05564v3 [cs.AI] UPDATED)
46. Analyzing Semantics of Aggregate Answer Set Programming Using Approximation Fixpoint Theory. (arXiv:2104.14789v2 [cs.AI] UPDATED)
47. Investigating Math Word Problems using Pretrained Multilingual Language Models. (arXiv:2105.08928v2 [cs.CL] UPDATED)
48. Lightweight Cross-Lingual Sentence Representation Learning. (arXiv:2105.13856v3 [cs.CL] UPDATED)
49. Don't Take It Literally: An Edit-Invariant Sequence Loss for Text Generation. (arXiv:2106.15078v5 [cs.CL] UPDATED)
50. Constraints Penalized Q-learning for Safe Offline Reinforcement Learning. (arXiv:2107.09003v3 [cs.LG] UPDATED)
51. AxoNN: An asynchronous, message-driven parallel framework for extreme-scale deep learning. (arXiv:2110.13005v4 [cs.LG] UPDATED)
52. CoCo Games: Graphical Game-Theoretic Swarm Control for Communication-Aware Coverage. (arXiv:2111.04576v2 [cs.RO] UPDATED)
53. Human Hands as Probes for Interactive Object Understanding. (arXiv:2112.09120v2 [cs.CV] UPDATED)
54. Online Grounding of Symbolic Planning Domains in Unknown Environments. (arXiv:2112.10007v2 [cs.AI] UPDATED)
55. Homepage2Vec: Language-Agnostic Website Embedding and Classification. (arXiv:2201.03677v3 [cs.CL] UPDATED)
56. The Quest for a Common Model of the Intelligent Decision Maker. (arXiv:2202.13252v2 [cs.AI] UPDATED)
57. The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation. (arXiv:2202.13307v2 [cs.IR] UPDATED)
58. Sample Complexity versus Depth: An Information Theoretic Analysis. (arXiv:2203.00246v3 [cs.LG] UPDATED)
59. Reasoning about Counterfactuals to Improve Human Inverse Reinforcement Learning. (arXiv:2203.01855v2 [cs.RO] UPDATED)
60. Voice-Face Homogeneity Tells Deepfake. (arXiv:2203.02195v2 [cs.CV] UPDATED)
61. HSC4D: Human-centered 4D Scene Capture in Large-scale Indoor-outdoor Space Using Wearable IMUs and LiDAR. (arXiv:2203.09215v2 [cs.CV] UPDATED)
62. A Spatial-Temporal Attention Multi-Graph Convolution Network for Ride-Hailing Demand Prediction Based on Periodicity with Offset. (arXiv:2203.12505v2 [cs.LG] UPDATED)
63. Deep Neural Convolutive Matrix Factorization for Articulatory Representation Decomposition. (arXiv:2204.00465v2 [eess.AS] UPDATED)
64. AutoOpt: A Methodological Framework of Automatically Designing Metaheuristics for Optimization Problems. (arXiv:2204.00998v3 [cs.NE] UPDATED)
65. ELECRec: Training Sequential Recommenders as Discriminators. (arXiv:2204.02011v2 [cs.AI] UPDATED)
66. Enhancing Semantic Code Search with Multimodal Contrastive Learning and Soft Data Augmentation. (arXiv:2204.03293v2 [cs.SE] UPDATED)
67. Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale. (arXiv:2204.03514v2 [cs.AI] UPDATED)
68. Text-Aware Predictive Monitoring of Business Processes. (arXiv:2104.09962v2 [cs.AI] CROSS LISTED)
69. Analyzing Medical Data with Process Mining: a COVID-19 Case Study. (arXiv:2202.04625v2 [cs.DB] CROSS LISTED)
70. A Comprehensive Review of Sign Language Recognition: Different Types, Modalities, and Datasets. (arXiv:2204.03328v1 [cs.CV] CROSS LISTED)

