# Your interest papers
---
## cs.CV
---
### AccMPEG: Optimizing Video Encoding for Video Analytics. (arXiv:2204.12534v1 [cs.NI])
- Authors : Kuntai Du, Qizheng Zhang, Anton Arapin, Haodong Wang, Zhengxu Xia, Junchen Jiang
- Link : [http://arxiv.org/abs/2204.12534](http://arxiv.org/abs/2204.12534)
> ABSTRACT  :  With more videos being recorded by edge sensors (cameras) and analyzed by computer-vision deep neural nets (DNNs), a new breed of video streaming systems has emerged, with the goal to compress and stream videos to remote servers in **real time** while preserving enough information to allow highly accurate inference by the server-side DNNs. An ideal design of the video streaming system should simultaneously meet three key requirements: (1) low latency of encoding and streaming, (2) high accuracy of server-side DNNs, and (3) low compute overheads on the camera. Unfortunately, despite many recent efforts, such video streaming system has hitherto been elusive, especially when serving advanced vision tasks such as object detection or semantic segmentation. This paper presents AccMPEG, a new video encoding and streaming system that meets all the three requirements. The key is to learn how much the encoding quality at each (16x16) macroblock can influence the server-side DNN accuracy, which we call accuracy gradient. Our insight is that these macroblock-level accuracy gradient can be inferred with sufficient precision by feeding the video frames through a cheap model. AccMPEG provides a suite of techniques that, given a new server-side DNN, can quickly create a cheap model to infer the accuracy gradient on any new frame in near realtime. Our extensive evaluation of AccMPEG on two types of edge devices (one Intel Xeon Silver 4100 CPU or NVIDIA Jetson Nano) and three vision tasks (six recent pre-trained DNNs) shows that AccMPEG (with the same camera-side compute resources) can reduce the end-to-end inference delay by 10-43% without hurting accuracy compared to the state-of-the-art baselines  
### Dataset for Robust and Accurate Leading Vehicle Velocity Recognition. (arXiv:2204.12717v1 [cs.CV])
- Authors : Genya Ogawa, Toru Saito, Noriyuki Aoi, Subaru Corporation, Signate Inc
- Link : [http://arxiv.org/abs/2204.12717](http://arxiv.org/abs/2204.12717)
> ABSTRACT  :  Recognition of the surrounding environment using a camera is an important technology in Advanced Driver-Assistance Systems and Autonomous Driving, and recognition technology is often solved by machine learning approaches such as deep learning in recent years. Machine learning requires datasets for learning and evaluation. To develop robust recognition technology in the real world, in addition to normal driving environment, data in environments that are difficult for cameras such as rainy weather or **night**time are essential. We have constructed a dataset that one can benchmark the technology, targeting the velocity recognition of the leading vehicle. This task is an important one for the Advanced Driver-Assistance Systems and Autonomous Driving. The dataset is available at https://signate.jp/competitions/657  
### Conformer and Blind Noisy Students for Improved Image Quality Assessment. (arXiv:2204.12819v1 [eess.IV])
- Authors : Maxime Burchi, Radu Timofte
- Link : [http://arxiv.org/abs/2204.12819](http://arxiv.org/abs/2204.12819)
> ABSTRACT  :  Generative models for image **restoration**, **enhancement**, and generation have significantly improved the quality of the generated images. Surprisingly, these models produce more pleasant images to the human eye than other methods, yet, they may get a lower perceptual quality score using traditional perceptual quality metrics such as PSNR or SSIM. Therefore, it is necessary to develop a quantitative metric to reflect the performance of new algorithms, which should be well-aligned with the person's mean opinion score (MOS). Learning-based approaches for perceptual image quality assessment (IQA) usually require both the distorted and reference image for measuring the perceptual quality accurately. However, commonly only the distorted or generated image is available. In this work, we explore the performance of transformer-based full-reference IQA models. We also propose a method for IQA based on semi-supervised knowledge distillation from full-reference teacher models into blind student models using noisy pseudo-labeled data. Our approaches achieved competitive results on the NTIRE 2022 Perceptual Image Quality Assessment Challenge: our full-reference model was ranked 4th, and our blind noisy student was ranked 3rd among 70 participants, each in their respective track.  
### LAI Estimation of Cucumber Crop Based on Improved Fully Convolutional Network. (arXiv:2104.07955v2 [cs.CV] UPDATED)
- Authors : Weiqi Shu, Ling Wang, Bolong Liu, Jie Liu
- Link : [http://arxiv.org/abs/2104.07955](http://arxiv.org/abs/2104.07955)
> ABSTRACT  :  LAI (Leaf Area Index) is of great importance for crop yield estimation in agronomy. It is directly related to plant growth status, net assimilation rate, plant photosynthesis, and carbon dioxide in the environment. How to measure LAI accurately and efficiently is the key to the crop yield estimation problem. Manual measurement consumes a lot of human resources and material resources. Remote sensing technology is not suitable for near-Earth LAI measurement. Besides, methods based on traditional digital image processing are greatly affected by environmental noise and image **exposure**. Nowadays, deep learning is widely used in many fields. The improved FCN (Fully Convolutional Network) is proposed in our study for LAI measure task. Eighty-two cucumber images collected from our greenhouse are labeled to fine-tuning the pre-trained model. The result shows that the improved FCN model performs well on our dataset. Our method's mean IoU can reach 0.908, which is 11% better than conventional methods and 4.7% better than the basic FCN model.  
### Residual Contrastive Learning for Image Reconstruction: Learning Transferable Representations from Noisy Images. (arXiv:2106.10070v2 [cs.CV] UPDATED)
- Authors : Nanqing Dong, Matteo Maggioni, Yongxin Yang, Ales Leonardis, Steven McDonagh
- Link : [http://arxiv.org/abs/2106.10070](http://arxiv.org/abs/2106.10070)
> ABSTRACT  :  This paper is concerned with contrastive learning (CL) for low-level image **restoration** and **enhancement** tasks. We propose a new label-efficient learning paradigm based on residuals, residual contrastive learning (RCL), and derive an unsupervised visual representation learning framework, suitable for low-level vision tasks with noisy inputs. While supervised image reconstruction aims to minimize residual terms directly, RCL alternatively builds a connection between residuals and CL by defining a novel instance discrimination pretext task, using residuals as the discriminative feature. Our formulation mitigates the severe task misalignment between instance discrimination pretext tasks and downstream image reconstruction tasks, present in existing CL frameworks. Experimentally, we find that RCL can learn robust and transferable representations that improve the performance of various downstream tasks, such as denoising and super resolution, in comparison with recent self-supervised methods designed specifically for noisy inputs. Additionally, our unsupervised pre-training can significantly reduce annotation costs whilst maintaining performance competitive with fully-supervised image reconstruction.  
### OSSID: Online Self-Supervised Instance Detection by (and for) Pose Estimation. (arXiv:2201.07309v2 [cs.CV] UPDATED)
- Authors : Qiao Gu, Brian Okorn, David Held
- Link : [http://arxiv.org/abs/2201.07309](http://arxiv.org/abs/2201.07309)
> ABSTRACT  :  **Real-time** object pose estimation is necessary for many robot manipulation algorithms. However, state-of-the-art methods for object pose estimation are trained for a specific set of objects; these methods thus need to be retrained to estimate the pose of each new object, often requiring tens of GPU-days of training for optimal performance. In this paper, we propose the OSSID framework, leveraging a slow zero-shot pose estimator to self-supervise the training of a fast detection algorithm. This fast detector can then be used to filter the input to the pose estimator, drastically improving its inference speed. We show that this self-supervised training exceeds the performance of existing zero-shot detection methods on two widely used object pose estimation and detection datasets, without requiring any human annotations. Further, we show that the resulting method for pose estimation has a significantly faster inference speed, due to the ability to filter out large parts of the image. Thus, our method for self-supervised online learning of a detector (trained using pseudo-labels from a slow pose estimator) leads to accurate pose estimation at real-time speeds, without requiring human annotations. Supplementary materials and code can be found at https://georgegu1997.github.io/OSSID/  
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
### A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v2 [cs.CV] UPDATED)
- Authors : Ziyin Ma, Changjae Oh
- Link : [http://arxiv.org/abs/2202.08758](http://arxiv.org/abs/2202.08758)
> ABSTRACT  :  We present a wavelet-based dual-stream network that addresses color cast and blurry details in underwater images. We handle these artifacts separately by decomposing an input image into multiple frequency bands using discrete wavelet transform, which generates the downsampled structure image and detail images. These sub-band images are used as input to our dual-stream network that incorporates two sub-networks: the multi-color space fusion network and the detail **enhancement** network. The multi-color space fusion network takes the decomposed structure image as input and estimates the color corrected output by employing the feature representations from diverse color spaces of the input. The detail **enhancement** network addresses the blurriness of the original underwater image by improving the image details from high-frequency sub-bands. We validate the proposed method on both real-world and synthetic underwater datasets and show the effectiveness of our model in color correction and blur removal with low computational complexity.  
### **NeRF**-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields. (arXiv:2203.01913v2 [cs.RO] UPDATED)
- Authors : Lin Yen, Pete Florence, Yi Lin, Alberto Rodriguez, Phillip Isola
- Link : [http://arxiv.org/abs/2203.01913](http://arxiv.org/abs/2203.01913)
> ABSTRACT  :  Thin, reflective objects such as forks and whisks are common in our daily lives, but they are particularly challenging for robot perception because it is hard to reconstruct them using commodity RGB-D cameras or multi-view stereo techniques. While traditional pipelines struggle with objects like these, Neural Radiance Fields (**NeRF**s) have recently been shown to be remarkably effective for performing view synthesis on objects with thin structures or reflective materials. In this paper we explore the use of **NeRF** as a new source of supervision for robust robot vision systems. In particular, we demonstrate that a **NeRF** representation of a scene can be used to train dense object descriptors. We use an optimized **NeRF** to extract dense correspondences between multiple views of an object, and then use these correspondences as training data for learning a view-invariant representation of the object. **NeRF**'s usage of a density field allows us to reformulate the correspondence problem with a novel distribution-of-depths formulation, as opposed to the conventional approach of using a depth map. Dense correspondence models supervised with our method significantly outperform off-the-shelf learned descriptors by 106% (PCK@3px metric, more than doubling performance) and outperform our baseline supervised with multi-view stereo by 29%. Furthermore, we demonstrate the learned dense descriptors enable robots to perform accurate 6-degree of freedom (6-DoF) pick and place of thin and reflective objects.  
### CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation. (arXiv:2204.09914v2 [cs.CV] UPDATED)
- Authors : Xiaoyan Li, Gang Zhang, Hongyu Pan, Zhenhua Wang
- Link : [http://arxiv.org/abs/2204.09914](http://arxiv.org/abs/2204.09914)
> ABSTRACT  :  LiDAR semantic segmentation essential for advanced autonomous driving is required to be accurate, fast, and easy-deployed on mobile platforms. Previous point-based or sparse voxel-based methods are far away from real-time applications since time-consuming neighbor searching or sparse 3D convolution are employed. Recent 2D projection-based methods, including range view and multi-view fusion, can run in **real time**, but suffer from lower accuracy due to information loss during the 2D projection. Besides, to improve the performance, previous methods usually adopt test time augmentation (TTA), which further slows down the inference process. To achieve a better speed-accuracy trade-off, we propose Cascade Point-Grid Fusion Network (CPGNet), which ensures both effectiveness and efficiency mainly by the following two techniques: 1) the novel Point-Grid (PG) fusion block extracts semantic features mainly on the 2D projected grid for efficiency, while summarizes both 2D and 3D features on 3D point for minimal information loss; 2) the proposed transformation consistency loss narrows the gap between the single-time model inference and TTA. The experiments on the SemanticKITTI and nuScenes benchmarks demonstrate that the CPGNet without ensemble models or TTA is comparable with the state-of-the-art RPVNet, while it runs 4.7 times faster.  
### Assessing the ability of generative adversarial networks to learn canonical medical image statistics. (arXiv:2204.12007v2 [eess.IV] UPDATED)
- Authors : Prabhat KC, Rongping Zeng
- Link : [http://arxiv.org/abs/2204.12007](http://arxiv.org/abs/2204.12007)
> ABSTRACT  :  In recent years, generative adversarial networks (GANs) have gained tremendous popularity for potential applications in medical imaging, such as medical image synthesis, **restoration**, reconstruction, translation, as well as objective image quality assessment. Despite the impressive progress in generating high-resolution, perceptually realistic images, it is not clear if modern GANs reliably learn the statistics that are meaningful to a downstream medical imaging application. In this work, the ability of a state-of-the-art GAN to learn the statistics of canonical stochastic image models (SIMs) that are relevant to objective assessment of image quality is investigated. It is shown that although the employed GAN successfully learned several basic first- and second-order statistics of the specific medical SIMs under consideration and generated images with high perceptual quality, it failed to correctly learn several per-image statistics pertinent to the these SIMs, highlighting the urgent need to assess medical image GANs in terms of objective measures of image quality.  
## eess.IV
---
### Conformer and Blind Noisy Students for Improved Image Quality Assessment. (arXiv:2204.12819v1 [eess.IV])
- Authors : Maxime Burchi, Radu Timofte
- Link : [http://arxiv.org/abs/2204.12819](http://arxiv.org/abs/2204.12819)
> ABSTRACT  :  Generative models for image **restoration**, **enhancement**, and generation have significantly improved the quality of the generated images. Surprisingly, these models produce more pleasant images to the human eye than other methods, yet, they may get a lower perceptual quality score using traditional perceptual quality metrics such as PSNR or SSIM. Therefore, it is necessary to develop a quantitative metric to reflect the performance of new algorithms, which should be well-aligned with the person's mean opinion score (MOS). Learning-based approaches for perceptual image quality assessment (IQA) usually require both the distorted and reference image for measuring the perceptual quality accurately. However, commonly only the distorted or generated image is available. In this work, we explore the performance of transformer-based full-reference IQA models. We also propose a method for IQA based on semi-supervised knowledge distillation from full-reference teacher models into blind student models using noisy pseudo-labeled data. Our approaches achieved competitive results on the NTIRE 2022 Perceptual Image Quality Assessment Challenge: our full-reference model was ranked 4th, and our blind noisy student was ranked 3rd among 70 participants, each in their respective track.  
### Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in Dynamic Tomography. (arXiv:2110.15424v2 [eess.IV] UPDATED)
- Authors : Zhishen Huang, Marc Klasky, Trevor Wilcox, Saiprasad Ravishankar
- Link : [http://arxiv.org/abs/2110.15424](http://arxiv.org/abs/2110.15424)
> ABSTRACT  :  Object density reconstruction from projections containing scattered radiation and noise is of critical importance in many applications. Existing scatter correction and density reconstruction methods may not provide the high accuracy needed in many applications and can break down in the presence of unmodeled or anomalous scatter and other experimental artifacts. Incorporating machine-learned models could prove beneficial for accurate density reconstruction particularly in dynamic imaging, where the time-evolution of the density fields could be captured by partial differential equations or by learning from hydrodynamics simulations. In this work, we demonstrate the ability of learned deep neural networks to perform artifact removal in noisy density reconstructions, where the noise is imperfectly characterized. We use a Wasserstein generative adversarial network (WGAN), where the generator serves as a denoiser that removes artifacts in densities obtained from traditional reconstruction algorithms. We train the networks from large density time-series datasets, with noise simulated according to parametric random distributions that may mimic noise in experiments. The WGAN is trained with noisy density frames as generator inputs, to match the generator outputs to the distribution of clean densities (time-series) from simulations. A supervised loss is also included in the training, which leads to improved density **restoration** performance. In addition, we employ physics-based constraints such as mass conservation during network training and application to further enable highly accurate density reconstructions. Our preliminary numerical results show that the models trained in our frameworks can remove significant portions of unknown noise in density time-series data.  
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
### A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v2 [cs.CV] UPDATED)
- Authors : Ziyin Ma, Changjae Oh
- Link : [http://arxiv.org/abs/2202.08758](http://arxiv.org/abs/2202.08758)
> ABSTRACT  :  We present a wavelet-based dual-stream network that addresses color cast and blurry details in underwater images. We handle these artifacts separately by decomposing an input image into multiple frequency bands using discrete wavelet transform, which generates the downsampled structure image and detail images. These sub-band images are used as input to our dual-stream network that incorporates two sub-networks: the multi-color space fusion network and the detail **enhancement** network. The multi-color space fusion network takes the decomposed structure image as input and estimates the color corrected output by employing the feature representations from diverse color spaces of the input. The detail **enhancement** network addresses the blurriness of the original underwater image by improving the image details from high-frequency sub-bands. We validate the proposed method on both real-world and synthetic underwater datasets and show the effectiveness of our model in color correction and blur removal with low computational complexity.  
### Assessing the ability of generative adversarial networks to learn canonical medical image statistics. (arXiv:2204.12007v2 [eess.IV] UPDATED)
- Authors : Prabhat KC, Rongping Zeng
- Link : [http://arxiv.org/abs/2204.12007](http://arxiv.org/abs/2204.12007)
> ABSTRACT  :  In recent years, generative adversarial networks (GANs) have gained tremendous popularity for potential applications in medical imaging, such as medical image synthesis, **restoration**, reconstruction, translation, as well as objective image quality assessment. Despite the impressive progress in generating high-resolution, perceptually realistic images, it is not clear if modern GANs reliably learn the statistics that are meaningful to a downstream medical imaging application. In this work, the ability of a state-of-the-art GAN to learn the statistics of canonical stochastic image models (SIMs) that are relevant to objective assessment of image quality is investigated. It is shown that although the employed GAN successfully learned several basic first- and second-order statistics of the specific medical SIMs under consideration and generated images with high perceptual quality, it failed to correctly learn several per-image statistics pertinent to the these SIMs, highlighting the urgent need to assess medical image GANs in terms of objective measures of image quality.  
## cs.LG
---
### Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages. (arXiv:2204.12543v1 [cs.CL])
- Authors : Mithun Das, Somnath Banerjee, Animesh Mukherjee
- Link : [http://arxiv.org/abs/2204.12543](http://arxiv.org/abs/2204.12543)
> ABSTRACT  :  Abusive language is a growing concern in many social media platforms. Repeated **exposure** to abusive speech has created physiological effects on the target users. Thus, the problem of abusive language should be addressed in all forms for online peace and safety. While extensive research exists in abusive speech detection, most studies focus on English. Recently, many smearing incidents have occurred in India, which provoked diverse forms of abusive speech in online space in various languages based on the geographic location. Therefore it is essential to deal with such malicious content. In this paper, to bridge the gap, we demonstrate a large-scale analysis of multilingual abusive speech in Indic languages. We examine different interlingual transfer mechanisms and observe the performance of various multilingual models for abusive speech detection for eight different Indic languages. We also experiment to show how robust these models are on adversarial attacks. Finally, we conduct an in-depth error analysis by looking into the models' misclassified posts across various settings. We have made our code and models public for other researchers.  
### Surrogate Assisted Evolutionary Multi-objective Optimisation applied to a Pressure **Swin**g Adsorption system. (arXiv:2204.12585v1 [cs.NE])
- Authors : Liezl Stander, Matthew Woolway, Van Zyl
- Link : [http://arxiv.org/abs/2204.12585](http://arxiv.org/abs/2204.12585)
> ABSTRACT  :  Chemical plant design and optimisation have proven challenging due to the complexity of these real-world systems. The resulting complexity translates into high computational costs for these systems' mathematical formulations and simulation models. Research has illustrated the benefits of using machine learning surrogate models as substitutes for computationally expensive models during optimisation. This paper extends recent research into optimising chemical plant design and operation. The study further explores Surrogate Assisted Genetic Algorithms (SA-GA) in more complex variants of the original plant design and optimisation problems, such as the inclusion of parallel and feedback components. The novel extension to the original algorithm proposed in this study, Surrogate Assisted NSGA-\Romannum{2} (SA-NSGA), was tested on a popular literature case, the Pressure **Swin**g Adsorption (PSA) system. We further provide extensive experimentation, comparing various meta-heuristic optimisation techniques and numerous machine learning models as surrogates. The results for both sets of systems illustrate the benefits of using Genetic Algorithms as an optimisation framework for complex chemical plant system design and optimisation for both single and multi-objective scenarios. We confirm that Random Forest surrogate assisted Evolutionary Algorithms can be scaled to increasingly complex chemical systems with parallel and feedback components. We further find that combining a Genetic Algorithm framework with Machine Learning Surrogate models as a substitute for long-running simulation models yields significant computational efficiency improvements, 1.7 - 1.84 times speedup for the increased complexity examples and a 2.7 times speedup for the Pressure **Swin**g Adsorption system.  
### Zero-Touch Network on Industrial IoT: An End-to-End Machine Learning Approach. (arXiv:2204.12605v1 [cs.LG])
- Authors : Chun Lin, Hung Lin, Chi Chen
- Link : [http://arxiv.org/abs/2204.12605](http://arxiv.org/abs/2204.12605)
> ABSTRACT  :  Industry 4.0-enabled smart factory is expected to realize the next revolution for manufacturers. Although artificial intelligence (AI) technologies have improved productivity, current use cases belong to small-scale and single-task operations. To unbound the potential of smart factory, this paper develops zero-touch network systems for intelligent manufacturing and facilitates distributed AI applications in both training and inferring stages in a large-scale manner. The open radio access network (O-RAN) architecture is first introduced for the zero-touch platform to enable globally controlling communications and computation infrastructure capability in the field. The designed serverless framework allows intelligent and efficient learning assignments and resource allocations. Hence, requested learning tasks can be assigned to appropriate robots, and the underlying infrastructure can be used to support the learning tasks without expert knowledge. Moreover, due to the proposed network system's flexibility, powerful AI-enabled networking algorithms can be utilized to ensure service-level agreements and superior performances for factory workloads. Finally, three open research directions of backward compatibility, end-to-end **enhancement**s, and cybersecurity are discussed for zero-touch smart factory.  
### SVD Perspectives for Augmenting DeepONet Flexibility and Interpretability. (arXiv:2204.12670v1 [cs.LG])
- Authors : Simone Venturi, Tiernan Casey
- Link : [http://arxiv.org/abs/2204.12670](http://arxiv.org/abs/2204.12670)
> ABSTRACT  :  Deep operator networks (DeepONets) are powerful architectures for fast and accurate emulation of complex dynamics. As their remarkable generalization capabilities are primarily enabled by their projection-based attribute, we investigate connections with low-rank techniques derived from the singular value decomposition (SVD). We demonstrate that some of the concepts behind proper orthogonal decomposition (POD)-neural networks can improve DeepONet's design and training phases. These ideas lead us to a methodology extension that we name SVD-DeepONet. Moreover, through multiple SVD analyses, we find that DeepONet inherits from its projection-based attribute strong inefficiencies in representing dynamics characterized by symmetries. Inspired by the work on shifted-POD, we develop flexDeepONet, an architecture **enhancement** that relies on a pre-transformation network for generating a moving reference frame and isolating the rigid components of the dynamics. In this way, the physics can be represented on a latent space free from rotations, translations, and stretches, and an accurate projection can be performed to a low-dimensional basis. In addition to flexibility and interpretability, the proposed perspectives increase DeepONet's generalization capabilities and computational efficiencies. For instance, we show flexDeepONet can accurately surrogate the dynamics of 19 variables in a combustion chemistry application by relying on 95% less trainable parameters than the ones of the vanilla architecture. We argue that DeepONet and SVD-based methods can reciprocally benefit from each other. In particular, the flexibility of the former in leveraging multiple data sources and multifidelity knowledge in the form of both unstructured data and physics-informed constraints has the potential to greatly extend the applicability of methodologies such as POD and PCA.  
### Can deep learning match the efficiency of human visual long-term memory to store object details?. (arXiv:2204.13061v1 [cs.LG])
- Authors : Emin Orhan
- Link : [http://arxiv.org/abs/2204.13061](http://arxiv.org/abs/2204.13061)
> ABSTRACT  :  Humans have a remarkably large capacity to store detailed visual information in long-term memory even after a single **exposure**, as demonstrated by classic experiments in psychology. For example, Standing (1973) showed that humans could recognize with high accuracy thousands of pictures that they had seen only once a few days prior to a recognition test. In deep learning, the primary mode of incorporating new information into a model is through gradient descent in the model's parameter space. This paper asks whether deep learning via gradient descent can match the efficiency of human visual long-term memory to incorporate new information in a rigorous, head-to-head, quantitative comparison. We answer this in the negative: even in the best case, models learning via gradient descent appear to require approximately 10 **exposure**s to the same visual materials in order to reach a recognition memory performance humans achieve after only a single **exposure**. Prior knowledge induced via pretraining and bigger model sizes improve performance, but these improvements are not very visible after a single **exposure** (it takes a few **exposure**s for the improvements to become apparent), suggesting that simply scaling up the pretraining data size or model size might not be enough for the model to reach human-level memory efficiency.  
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v8 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
### Residual Contrastive Learning for Image Reconstruction: Learning Transferable Representations from Noisy Images. (arXiv:2106.10070v2 [cs.CV] UPDATED)
- Authors : Nanqing Dong, Matteo Maggioni, Yongxin Yang, Ales Leonardis, Steven McDonagh
- Link : [http://arxiv.org/abs/2106.10070](http://arxiv.org/abs/2106.10070)
> ABSTRACT  :  This paper is concerned with contrastive learning (CL) for low-level image **restoration** and **enhancement** tasks. We propose a new label-efficient learning paradigm based on residuals, residual contrastive learning (RCL), and derive an unsupervised visual representation learning framework, suitable for low-level vision tasks with noisy inputs. While supervised image reconstruction aims to minimize residual terms directly, RCL alternatively builds a connection between residuals and CL by defining a novel instance discrimination pretext task, using residuals as the discriminative feature. Our formulation mitigates the severe task misalignment between instance discrimination pretext tasks and downstream image reconstruction tasks, present in existing CL frameworks. Experimentally, we find that RCL can learn robust and transferable representations that improve the performance of various downstream tasks, such as denoising and super resolution, in comparison with recent self-supervised methods designed specifically for noisy inputs. Additionally, our unsupervised pre-training can significantly reduce annotation costs whilst maintaining performance competitive with fully-supervised image reconstruction.  
### Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v2 [cs.LG] UPDATED)
- Authors : Baihan Lin, Djallel Bouneffouf
- Link : [http://arxiv.org/abs/2106.15808](http://arxiv.org/abs/2106.15808)
> ABSTRACT  :  In light of the COVID-19 pandemic, it is an open challenge and critical practical problem to find a optimal way to dynamically prescribe the best policies that balance both the governmental resources and epidemic control in different countries and regions. To solve this multi-dimensional tradeoff of exploitation and exploration, we formulate this technical challenge as a contextual combinatorial bandit problem that jointly optimizes a multi-criteria reward function. Given the historical daily cases in a region and the past intervention plans in place, the agent should generate useful intervention plans that policy makers can implement in **real time** to minimizing both the number of daily COVID-19 cases and the stringency of the recommended interventions. We prove this concept with simulations of multiple realistic policy making scenarios and demonstrate a clear advantage in providing a pareto optimal solution in the epidemic intervention problem.  
### Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in Dynamic Tomography. (arXiv:2110.15424v2 [eess.IV] UPDATED)
- Authors : Zhishen Huang, Marc Klasky, Trevor Wilcox, Saiprasad Ravishankar
- Link : [http://arxiv.org/abs/2110.15424](http://arxiv.org/abs/2110.15424)
> ABSTRACT  :  Object density reconstruction from projections containing scattered radiation and noise is of critical importance in many applications. Existing scatter correction and density reconstruction methods may not provide the high accuracy needed in many applications and can break down in the presence of unmodeled or anomalous scatter and other experimental artifacts. Incorporating machine-learned models could prove beneficial for accurate density reconstruction particularly in dynamic imaging, where the time-evolution of the density fields could be captured by partial differential equations or by learning from hydrodynamics simulations. In this work, we demonstrate the ability of learned deep neural networks to perform artifact removal in noisy density reconstructions, where the noise is imperfectly characterized. We use a Wasserstein generative adversarial network (WGAN), where the generator serves as a denoiser that removes artifacts in densities obtained from traditional reconstruction algorithms. We train the networks from large density time-series datasets, with noise simulated according to parametric random distributions that may mimic noise in experiments. The WGAN is trained with noisy density frames as generator inputs, to match the generator outputs to the distribution of clean densities (time-series) from simulations. A supervised loss is also included in the training, which leads to improved density **restoration** performance. In addition, we employ physics-based constraints such as mass conservation during network training and application to further enable highly accurate density reconstructions. Our preliminary numerical results show that the models trained in our frameworks can remove significant portions of unknown noise in density time-series data.  
### ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
- Authors : Runsheng Xu, Zhengzhong Tu, Yuanqi Du, Xiaoyu Dong, Jinlong Li, Zibo Meng, Jiaqi Ma, Hongkai YU
- Link : [http://arxiv.org/abs/2202.02606](http://arxiv.org/abs/2202.02606)
> ABSTRACT  :  Renovating the memories in old photos is an intriguing research topic in computer vision fields. These legacy images often suffer from severe and commingled degradations such as cracks, noise, and color-fading, while lack of large-scale paired old photo datasets makes this **restoration** task very challenging. In this work, we present a novel reference-based end-to-end learning framework that can jointly repair and colorize the degraded legacy pictures. Specifically, the proposed framework consists of three modules: a **restoration** sub-network for degradation **restoration**, a similarity sub-network for color histogram matching and transfer, and a colorization subnet that learns to predict the chroma elements of the images conditioned on chromatic reference signals. The whole system takes advantage of the color histogram priors in a given reference image, which vastly reduces the dependency on large-scale training data. Apart from the proposed method, we also create, to our knowledge, the first public and real-world old photo dataset with paired ground truth for evaluating old photo **restoration** models, wherein each old photo is paired with a manually restored pristine image by PhotoShop experts. Our extensive experiments conducted on both synthetic and real-world datasets demonstrate that our method significantly outperforms state-of-the-arts both quantitatively and qualitatively.  
## cs.AI
---
### LAI Estimation of Cucumber Crop Based on Improved Fully Convolutional Network. (arXiv:2104.07955v2 [cs.CV] UPDATED)
- Authors : Weiqi Shu, Ling Wang, Bolong Liu, Jie Liu
- Link : [http://arxiv.org/abs/2104.07955](http://arxiv.org/abs/2104.07955)
> ABSTRACT  :  LAI (Leaf Area Index) is of great importance for crop yield estimation in agronomy. It is directly related to plant growth status, net assimilation rate, plant photosynthesis, and carbon dioxide in the environment. How to measure LAI accurately and efficiently is the key to the crop yield estimation problem. Manual measurement consumes a lot of human resources and material resources. Remote sensing technology is not suitable for near-Earth LAI measurement. Besides, methods based on traditional digital image processing are greatly affected by environmental noise and image **exposure**. Nowadays, deep learning is widely used in many fields. The improved FCN (Fully Convolutional Network) is proposed in our study for LAI measure task. Eighty-two cucumber images collected from our greenhouse are labeled to fine-tuning the pre-trained model. The result shows that the improved FCN model performs well on our dataset. Our method's mean IoU can reach 0.908, which is 11% better than conventional methods and 4.7% better than the basic FCN model.  
### Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v8 [cs.LG] UPDATED)
- Authors : Harshavardhan Kamarthi, Alexander Rodr, Aditya Prakash
- Link : [http://arxiv.org/abs/2106.04420](http://arxiv.org/abs/2106.04420)
> ABSTRACT  :  In real-time forecasting in public health, data collection is a non-trivial and demanding task. Often after initially released, it undergoes several revisions later (maybe due to human or technical constraints) - as a result, it may take weeks until the data reaches to a stable value. This so-called 'backfill' phenomenon and its effect on model performance has been barely studied in the prior literature. In this paper, we introduce the multi-variate backfill problem using COVID-19 as the motivating example. We construct a detailed dataset composed of relevant signals over the past year of the pandemic. We then systematically characterize several patterns in backfill dynamics and leverage our observations for formulating a novel problem and neural framework Back2Future that aims to refines a given model's predictions in real-time. Our extensive experiments demonstrate that our method refines the performance of top models for COVID-19 forecasting, in contrast to non-trivial baselines, yielding 18% improvement over baselines, enabling us obtain a new SOTA performance. In addition, we show that our model improves model evaluation too; hence policy-makers can better understand the true accuracy of forecasting models in real-time.  
### Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v2 [cs.LG] UPDATED)
- Authors : Baihan Lin, Djallel Bouneffouf
- Link : [http://arxiv.org/abs/2106.15808](http://arxiv.org/abs/2106.15808)
> ABSTRACT  :  In light of the COVID-19 pandemic, it is an open challenge and critical practical problem to find a optimal way to dynamically prescribe the best policies that balance both the governmental resources and epidemic control in different countries and regions. To solve this multi-dimensional tradeoff of exploitation and exploration, we formulate this technical challenge as a contextual combinatorial bandit problem that jointly optimizes a multi-criteria reward function. Given the historical daily cases in a region and the past intervention plans in place, the agent should generate useful intervention plans that policy makers can implement in **real time** to minimizing both the number of daily COVID-19 cases and the stringency of the recommended interventions. We prove this concept with simulations of multiple realistic policy making scenarios and demonstrate a clear advantage in providing a pareto optimal solution in the epidemic intervention problem.  
### OSSID: Online Self-Supervised Instance Detection by (and for) Pose Estimation. (arXiv:2201.07309v2 [cs.CV] UPDATED)
- Authors : Qiao Gu, Brian Okorn, David Held
- Link : [http://arxiv.org/abs/2201.07309](http://arxiv.org/abs/2201.07309)
> ABSTRACT  :  **Real-time** object pose estimation is necessary for many robot manipulation algorithms. However, state-of-the-art methods for object pose estimation are trained for a specific set of objects; these methods thus need to be retrained to estimate the pose of each new object, often requiring tens of GPU-days of training for optimal performance. In this paper, we propose the OSSID framework, leveraging a slow zero-shot pose estimator to self-supervise the training of a fast detection algorithm. This fast detector can then be used to filter the input to the pose estimator, drastically improving its inference speed. We show that this self-supervised training exceeds the performance of existing zero-shot detection methods on two widely used object pose estimation and detection datasets, without requiring any human annotations. Further, we show that the resulting method for pose estimation has a significantly faster inference speed, due to the ability to filter out large parts of the image. Thus, our method for self-supervised online learning of a detector (trained using pseudo-labels from a slow pose estimator) leads to accurate pose estimation at real-time speeds, without requiring human annotations. Supplementary materials and code can be found at https://georgegu1997.github.io/OSSID/  
### Embracing AWKWARD! **Real-time** Adjustment of Reactive Plans Using Social Norms. (arXiv:2204.10740v2 [cs.MA] UPDATED)
- Authors : Leila Methnani, Andreas Antoniades, Andreas Theodorou
- Link : [http://arxiv.org/abs/2204.10740](http://arxiv.org/abs/2204.10740)
> ABSTRACT  :  This paper presents the AWKWARD agent architecture for the development of agents in Multi-Agent Systems. AWKWARD agents can have their plans re-configured in **real time** to align with social role requirements under changing environmental and social circumstances. The proposed hybrid architecture makes use of Behaviour Oriented Design (BOD) to develop agents with reactive planning and of the well-established OperA framework to provide organisational, social, and interaction definitions in order to validate and adjust agents' behaviours. Together, OperA and BOD can achieve real-time adjustment of agent plans for evolving social roles, while providing the additional benefit of transparency into the interactions that drive this behavioural change in individual agents. We present this architecture to motivate the bridging between traditional symbolic- and behaviour-based AI communities, where such combined solutions can help MAS researchers in their pursuit of building stronger, more robust intelligent agent teams. We use DOTA2, a game where success is heavily dependent on social interactions, as a medium to demonstrate a sample implementation of our proposed hybrid architecture.  
# Paper List
---
## cs.CV
---
**95** new papers in cs.CV:-) 
1. PolyLoss: A Polynomial Expansion Perspective of Classification Loss Functions. (arXiv:2204.12511v1 [cs.CV])
2. Coupled Iterative Refinement for 6D Multi-Object Pose Estimation. (arXiv:2204.12516v1 [cs.CV])
3. Leveraging Unlabeled Data for Sketch-based Understanding. (arXiv:2204.12522v1 [cs.CV])
4. Expanding the Latent Space of StyleGAN for Real Face Editing. (arXiv:2204.12530v1 [cs.CV])
5. AccMPEG: Optimizing Video Encoding for Video Analytics. (arXiv:2204.12534v1 [cs.NI])
6. Building Change Detection using Multi-Temporal Airborne LiDAR Data. (arXiv:2204.12535v1 [cs.CV])
7. Multi stain graph fusion for multimodal integration in pathology. (arXiv:2204.12541v1 [eess.IV])
8. hate-alert@DravidianLangTech-ACL2022: Ensembling Multi-Modalities for Tamil TrollMeme Classification. (arXiv:2204.12587v1 [cs.MM])
9. The Influence of the Other-Race Effect on Susceptibility to Face Morphing Attacks. (arXiv:2204.12591v1 [cs.CV])
10. Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition. (arXiv:2204.12624v1 [cs.CV])
11. SCGC : Self-Supervised Contrastive Graph Clustering. (arXiv:2204.12656v1 [cs.LG])
12. MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation. (arXiv:2204.12667v1 [cs.CV])
13. Optimized latent-code selection for explainable conditional text-to-image GANs. (arXiv:2204.12678v1 [cs.CV])
14. Improving the Transferability of Adversarial Examples with Restructure Embedded Patches. (arXiv:2204.12680v1 [cs.CV])
15. Density-preserving Deep Point Cloud Compression. (arXiv:2204.12684v1 [cs.CV])
16. Robust Face Anti-Spoofing with Dual Probabilistic Modeling. (arXiv:2204.12685v1 [cs.CV])
17. Grasping the Arrow of Time from the Singularity: Decoding Micromotion in Low-dimensional Latent Spaces from StyleGAN. (arXiv:2204.12696v1 [cs.CV])
18. Mapping suburban bicycle lanes using street scene images and deep learning. (arXiv:2204.12701v1 [cs.CV])
19. Dataset for Robust and Accurate Leading Vehicle Velocity Recognition. (arXiv:2204.12717v1 [cs.CV])
20. PRE-NAS: Predictor-assisted Evolutionary Neural Architecture Search. (arXiv:2204.12726v1 [cs.CV])
21. Human-Centered Prior-Guided and Task-Dependent Multi-Task Representation Learning for Action Recognition Pre-Training. (arXiv:2204.12729v1 [cs.CV])
22. A Multi-Head Convolutional Neural Network With Multi-path Attention improves Image Denoising. (arXiv:2204.12736v1 [cs.CV])
23. Self-Supervised Text Erasing with Controllable Image Synthesis. (arXiv:2204.12743v1 [cs.CV])
24. Self-Driving Car Steering Angle Prediction: Let Transformer Be a Car Again. (arXiv:2204.12748v1 [cs.CV])
25. Talking Head Generation Driven by Speech-Related Facial Action Units and Audio- Based on Multimodal Representation Fusion. (arXiv:2204.12756v1 [cs.CV])
26. A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching. (arXiv:2204.12805v1 [cs.CV])
27. The MeVer DeepFake Detection Service: Lessons Learnt from Developing and Deploying in the Wild. (arXiv:2204.12816v1 [cs.CV])
28. CATrans: Context and Affinity Transformer for Few-Shot Segmentation. (arXiv:2204.12817v1 [cs.CV])
29. Conformer and Blind Noisy Students for Improved Image Quality Assessment. (arXiv:2204.12819v1 [eess.IV])
30. Power Bundle Adjustment for Large-Scale 3D Reconstruction. (arXiv:2204.12834v1 [cs.CV])
31. BBBD: Bounding Box Based Detector for Occlusion Detection and Order Recovery. (arXiv:2204.12841v1 [cs.CV])
32. Forecasting Urban Development from Satellite Images. (arXiv:2204.12875v1 [cs.CV])
33. Low-rank Meets Sparseness: An Integrated Spatial-Spectral Total Variation Approach to Hyperspectral Denoising. (arXiv:2204.12879v1 [cs.CV])
34. Gleo-Det: Deep Convolution Feature-Guided Detector with Local Entropy Optimization for Salient Points. (arXiv:2204.12884v1 [cs.CV])
35. Global Trajectory Helps Person Retrieval in a Camera Network. (arXiv:2204.12900v1 [cs.CV])
36. Epicardial Adipose Tissue Segmentation from CT Images with A Semi-3D Neural Network. (arXiv:2204.12904v1 [eess.IV])
37. An Iterative Labeling Method for Annotating Fisheries Imagery. (arXiv:2204.12934v1 [cs.LG])
38. Unsupervised Learning of Unbiased Visual Representations. (arXiv:2204.12941v1 [cs.LG])
39. MAPLE-Edge: A Runtime Latency Predictor for Edge Devices. (arXiv:2204.12950v1 [cs.LG])
40. Towards assessing agricultural land suitability with causal machine learning. (arXiv:2204.12956v1 [cs.LG])
41. CapOnImage: Context-driven Dense-Captioning on Image. (arXiv:2204.12974v1 [cs.CV])
42. DearKD: Data-Efficient Early Knowledge Distillation for Vision Transformers. (arXiv:2204.12997v1 [cs.CV])
43. Relevance-based Margin for Contrastively-trained Video Retrieval Models. (arXiv:2204.13001v1 [cs.CV])
44. Defending Against Person Hiding Adversarial Patch Attack with a Universal White Frame. (arXiv:2204.13004v1 [cs.CV])
45. Ollivier-Ricci Curvature For Head Pose Estimation From a Single Image. (arXiv:2204.13006v1 [cs.CV])
46. Dropout Inference with Non-Uniform Weight Scaling. (arXiv:2204.13047v1 [cs.LG])
47. Collaborative Learning for Hand and Object Reconstruction with Attention-guided Graph Convolution. (arXiv:2204.13062v1 [cs.CV])
48. Attention Consistency on Visual Corruptions for Single-Source Domain Generalization. (arXiv:2204.13091v1 [cs.CV])
49. 3D Magic Mirror: Clothing Reconstruction from a Single Image via a Causal Perspective. (arXiv:2204.13096v1 [cs.CV])
50. Few-Shot Head Swapping in the Wild. (arXiv:2204.13100v1 [cs.CV])
51. Self-Supervised Learning of Object Parts for Semantic Segmentation. (arXiv:2204.13101v1 [cs.CV])
52. The Chiral Domain of a Camera Arrangement. (arXiv:2003.09265v4 [math.AG] UPDATED)
53. A closed-form solution to estimate uncertainty in non-rigid structure from motion. (arXiv:2005.04810v4 [cs.CV] UPDATED)
54. SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space. (arXiv:2008.00397v2 [cs.CV] UPDATED)
55. HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation. (arXiv:2011.14672v4 [cs.CV] UPDATED)
56. Hyperspectral Image Classification-Traditional to Deep Models: A Survey for Future Prospects. (arXiv:2101.06116v3 [eess.IV] UPDATED)
57. LAI Estimation of Cucumber Crop Based on Improved Fully Convolutional Network. (arXiv:2104.07955v2 [cs.CV] UPDATED)
58. Augmenting Anchors by the Detector Itself. (arXiv:2105.14086v2 [cs.CV] UPDATED)
59. Residual Contrastive Learning for Image Reconstruction: Learning Transferable Representations from Noisy Images. (arXiv:2106.10070v2 [cs.CV] UPDATED)
60. Task-Aware Sampling Layer for Point-Wise Analysis. (arXiv:2107.04291v3 [cs.CV] UPDATED)
61. Continual Learning for Image-Based Camera Localization. (arXiv:2108.09112v2 [cs.CV] UPDATED)
62. Bio-Inspired Audio-Visual Cues Integration for Visual Attention Prediction. (arXiv:2109.08371v2 [cs.CV] UPDATED)
63. BINAS: Bilinear Interpretable Neural Architecture Search. (arXiv:2110.12399v3 [cs.LG] UPDATED)
64. Learning to Detect Open Carry and Concealed Object with 77GHz Radar. (arXiv:2111.00551v2 [eess.SP] UPDATED)
65. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v2 [eess.IV] UPDATED)
66. Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis. (arXiv:2111.15186v2 [cs.LG] UPDATED)
67. Self-Supervised Keypoint Discovery in Behavioral Videos. (arXiv:2112.05121v2 [cs.CV] UPDATED)
68. OSSID: Online Self-Supervised Instance Detection by (and for) Pose Estimation. (arXiv:2201.07309v2 [cs.CV] UPDATED)
69. Learning-by-Novel-View-Synthesis for Full-Face Appearance-Based 3D Gaze Estimation. (arXiv:2201.07927v3 [cs.CV] UPDATED)
70. A Real-Time Rendering Method for Light Field Display. (arXiv:2201.08266v4 [cs.GR] UPDATED)
71. On scale-invariant properties in natural images and their simulations. (arXiv:2201.13312v2 [cs.CV] UPDATED)
72. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v3 [eess.IV] UPDATED)
73. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
74. Learning Perspective Deformation in X-Ray Transmission Imaging. (arXiv:2202.06366v2 [eess.IV] UPDATED)
75. A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v2 [cs.CV] UPDATED)
76. **NeRF**-Supervision: Learning Dense Object Descriptors from Neural Radiance Fields. (arXiv:2203.01913v2 [cs.RO] UPDATED)
77. Things not Written in Text: Exploring Spatial Commonsense from Visual Signals. (arXiv:2203.08075v2 [cs.CL] UPDATED)
78. Generating natural images with direct Patch Distributions Matching. (arXiv:2203.11862v2 [cs.CV] UPDATED)
79. UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v4 [cs.CV] UPDATED)
80. Integrative Few-Shot Learning for Classification and Segmentation. (arXiv:2203.15712v2 [cs.CV] UPDATED)
81. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v5 [cs.CV] UPDATED)
82. Vision-and-Language Pretrained Models: A Survey. (arXiv:2204.07356v3 [cs.CV] UPDATED)
83. MultiEarth 2022 -- Multimodal Learning for Earth and Environment Workshop and Challenge. (arXiv:2204.07649v2 [cs.CV] UPDATED)
84. Learning 3D Semantics from Pose-Noisy 2D Images with Hierarchical Full Attention Network. (arXiv:2204.08084v3 [cs.CV] UPDATED)
85. CPGNet: Cascade Point-Grid Fusion Network for Real-Time LiDAR Semantic Segmentation. (arXiv:2204.09914v2 [cs.CV] UPDATED)
86. Leveraging Deepfakes to Close the Domain Gap between Real and Synthetic Images in Facial Capture Pipelines. (arXiv:2204.10746v2 [cs.CV] UPDATED)
87. Identity Preserving Loss for Learned Image Compression. (arXiv:2204.10869v3 [cs.CV] UPDATED)
88. End-to-End Audio Strikes Back: Boosting Augmentations Towards An Efficient Audio Classification Network. (arXiv:2204.11479v2 [cs.SD] UPDATED)
89. Unsupervised Domain Adaptation for Monocular 3D Object Detection via Self-Training. (arXiv:2204.11590v2 [cs.CV] UPDATED)
90. Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection. (arXiv:2204.11795v2 [eess.SP] UPDATED)
91. Contrastive learning-based computational histopathology predict differential expression of cancer driver genes. (arXiv:2204.11994v2 [cs.CV] UPDATED)
92. Assessing the ability of generative adversarial networks to learn canonical medical image statistics. (arXiv:2204.12007v2 [eess.IV] UPDATED)
93. A Novel Framework for Characterization of Tumor-Immune Spatial Relationships in Tumor Microenvironment. (arXiv:2204.12283v2 [q-bio.QM] UPDATED)
94. Evaluating the Quality of a Synthesized Motion with the Fr\'echet Motion Distance. (arXiv:2204.12318v2 [cs.CV] UPDATED)
95. Understanding The Robustness in Vision Transformers. (arXiv:2204.12451v2 [cs.CV] UPDATED)
## eess.IV
---
**23** new papers in eess.IV:-) 
1. Building Change Detection using Multi-Temporal Airborne LiDAR Data. (arXiv:2204.12535v1 [cs.CV])
2. Multi stain graph fusion for multimodal integration in pathology. (arXiv:2204.12541v1 [eess.IV])
3. Online multi-resolution fusion of space-borne multispectral images. (arXiv:2204.12566v1 [eess.IV])
4. Density-preserving Deep Point Cloud Compression. (arXiv:2204.12684v1 [cs.CV])
5. A Multi-Head Convolutional Neural Network With Multi-path Attention improves Image Denoising. (arXiv:2204.12736v1 [cs.CV])
6. Conformer and Blind Noisy Students for Improved Image Quality Assessment. (arXiv:2204.12819v1 [eess.IV])
7. Increasing Imaging Resolution by Non-Regular Sampling and Joint Sparse Deconvolution and Extrapolation. (arXiv:2204.12867v1 [eess.IV])
8. Resampling Images to a Regular Grid from a Non-Regular Subset of Pixel Positions Using Frequency Selective Reconstruction. (arXiv:2204.12873v1 [eess.IV])
9. Low-rank Meets Sparseness: An Integrated Spatial-Spectral Total Variation Approach to Hyperspectral Denoising. (arXiv:2204.12879v1 [cs.CV])
10. Motion Compensated Three-Dimensional Frequency Selective Extrapolation for Improved Error Concealment in Video Communication. (arXiv:2204.12882v1 [eess.IV])
11. Epicardial Adipose Tissue Segmentation from CT Images with A Semi-3D Neural Network. (arXiv:2204.12904v1 [eess.IV])
12. Edge effect removal in Fourier ptychographic microscopy via perfect Fourier transformation (PFT). (arXiv:2009.03138v2 [eess.IV] UPDATED)
13. Hyperspectral Image Classification-Traditional to Deep Models: A Survey for Future Prospects. (arXiv:2101.06116v3 [eess.IV] UPDATED)
14. Cascading Neural Network Methodology for Artificial Intelligence-Assisted Radiographic Detection and Classification of Lead-Less Implanted Electronic Devices within the Chest. (arXiv:2108.11954v2 [eess.IV] UPDATED)
15. Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in Dynamic Tomography. (arXiv:2110.15424v2 [eess.IV] UPDATED)
16. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v2 [eess.IV] UPDATED)
17. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v3 [eess.IV] UPDATED)
18. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
19. Learning Perspective Deformation in X-Ray Transmission Imaging. (arXiv:2202.06366v2 [eess.IV] UPDATED)
20. A Wavelet-based Dual-stream Network for Underwater Image **Enhancement**. (arXiv:2202.08758v2 [cs.CV] UPDATED)
21. Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection. (arXiv:2204.11795v2 [eess.SP] UPDATED)
22. Assessing the ability of generative adversarial networks to learn canonical medical image statistics. (arXiv:2204.12007v2 [eess.IV] UPDATED)
23. A Novel Framework for Characterization of Tumor-Immune Spatial Relationships in Tumor Microenvironment. (arXiv:2204.12283v2 [q-bio.QM] UPDATED)
## cs.LG
---
**142** new papers in cs.LG:-) 
1. AI-Assisted Authentication: State of the Art, Taxonomy and Future Roadmap. (arXiv:2204.12492v1 [cs.CR])
2. One-shot Federated Learning without Server-side Training. (arXiv:2204.12493v1 [cs.LG])
3. Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies. (arXiv:2204.12495v1 [cs.LG])
4. Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering. (arXiv:2204.12496v1 [cs.LG])
5. Identification of feasible pathway information for c-di-GMP binding proteins in cellulose production. (arXiv:2204.12526v1 [q-bio.QM])
6. Application of WGAN-GP in recommendation and Questioning the relevance of GAN-based approaches. (arXiv:2204.12527v1 [cs.IR])
7. Double Diffusion Maps and their Latent Harmonics for Scientific Computations in Latent Space. (arXiv:2204.12536v1 [stat.ML])
8. Multi stain graph fusion for multimodal integration in pathology. (arXiv:2204.12541v1 [eess.IV])
9. Data Bootstrapping Approaches to Improve Low Resource Abusive Language Detection for Indic Languages. (arXiv:2204.12543v1 [cs.CL])
10. An Empirical Study of the Occurrence of Heavy-Tails in Training a ReLU Gate. (arXiv:2204.12554v1 [cs.LG])
11. SoFaiR: Single Shot Fair Representation Learning. (arXiv:2204.12556v1 [cs.LG])
12. Process Knowledge-infused Learning for Suicidality Assessment on Social Media. (arXiv:2204.12560v1 [cs.AI])
13. Learning Eco-Driving Strategies at Signalized Intersections. (arXiv:2204.12561v1 [eess.SY])
14. Toward Policy Explanations for Multi-Agent Reinforcement Learning. (arXiv:2204.12568v1 [cs.AI])
15. Novel Applications for VAE-based Anomaly Detection Systems. (arXiv:2204.12577v1 [cs.LG])
16. RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning. (arXiv:2204.12581v1 [cs.LG])
17. Fast Aquatic Swimmer Optimization with Differentiable Projective Dynamics and Neural Network Hydrodynamic Models. (arXiv:2204.12584v1 [cs.RO])
18. Surrogate Assisted Evolutionary Multi-objective Optimisation applied to a Pressure **Swin**g Adsorption system. (arXiv:2204.12585v1 [cs.NE])
19. Protein 3D structure-based neural networks highly improve the accuracy in compound-protein binding affinity prediction. (arXiv:2204.12586v1 [q-bio.BM])
20. hate-alert@DravidianLangTech-ACL2022: Ensembling Multi-Modalities for Tamil TrollMeme Classification. (arXiv:2204.12587v1 [cs.MM])
21. Self-scalable Tanh (Stan): Faster Convergence and Better Generalization in Physics-informed Neural Networks. (arXiv:2204.12589v1 [cs.LG])
22. Zero-Touch Network on Industrial IoT: An End-to-End Machine Learning Approach. (arXiv:2204.12605v1 [cs.LG])
23. Rate-Constrained Remote Contextual Bandits. (arXiv:2204.12620v1 [cs.LG])
24. Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition. (arXiv:2204.12624v1 [cs.CV])
25. Gaussian Kernel Variance For an Adaptive Learning Method on Signals Over Graphs. (arXiv:2204.12629v1 [eess.SP])
26. Meta-Learning Based Early Fault Detection for Rolling Bearings via Few-Shot Anomaly Detection. (arXiv:2204.12637v1 [cs.LG])
27. Generating Examples From CLI Usage: Can Transformers Help?. (arXiv:2204.12648v1 [cs.SE])
28. Generating Self-Serendipity Preference in Recommender Systems for Addressing Cold Start Problems. (arXiv:2204.12651v1 [cs.IR])
29. SCGC : Self-Supervised Contrastive Graph Clustering. (arXiv:2204.12656v1 [cs.LG])
30. Understanding A Class of Decentralized and Federated Optimization Algorithms: A Multi-Rate Feedback Control Perspective. (arXiv:2204.12663v1 [cs.LG])
31. Relational Abstractions for Generalized Reinforcement Learning on Symbolic Problems. (arXiv:2204.12665v1 [cs.LG])
32. Adaptable Text Matching via Meta-Weight Regulator. (arXiv:2204.12668v1 [cs.IR])
33. SVD Perspectives for Augmenting DeepONet Flexibility and Interpretability. (arXiv:2204.12670v1 [cs.LG])
34. The Multimarginal Optimal Transport Formulation of Adversarial Multiclass Classification. (arXiv:2204.12676v1 [cs.LG])
35. Heterogeneous Ensemble Knowledge Transfer for Training Large Models in Federated Learning. (arXiv:2204.12703v1 [cs.LG])
36. Accelerated Continuous-Time Approximate Dynamic Programming via Data-Assisted Hybrid Control. (arXiv:2204.12707v1 [math.OC])
37. Data-based price discrimination: information theoretic limitations and a minimax optimal strategy. (arXiv:2204.12723v1 [cs.GT])
38. Human-Centered Prior-Guided and Task-Dependent Multi-Task Representation Learning for Action Recognition Pre-Training. (arXiv:2204.12729v1 [cs.CV])
39. A Multi-Head Convolutional Neural Network With Multi-path Attention improves Image Denoising. (arXiv:2204.12736v1 [cs.CV])
40. DraftRec: Personalized Draft Recommendation for Winning in Multi-Player Online Battle Arena Games. (arXiv:2204.12750v1 [cs.AI])
41. Bounded Memory Adversarial Bandits with Composite Anonymous Delayed Feedback. (arXiv:2204.12764v1 [cs.LG])
42. An Empirical Evaluation of Flow Based Programming in the Machine Learning Deployment Context. (arXiv:2204.12781v1 [cs.SE])
43. Machines of finite depth: towards a formalization of neural networks. (arXiv:2204.12786v1 [cs.LG])
44. Learning Green's functions associated with parabolic partial differential equations. (arXiv:2204.12789v1 [math.NA])
45. Supervised Contrastive CSI Representation Learning for Massive MIMO Positioning. (arXiv:2204.12796v1 [cs.IT])
46. GTNet: A Tree-Based Deep Graph Learning Architecture. (arXiv:2204.12802v1 [cs.LG])
47. When Performance is not Enough -- A Multidisciplinary View on Clinical Decision Support. (arXiv:2204.12810v1 [cs.LG])
48. Uncertainty-Aware Prediction of Battery Energy Consumption for Hybrid Electric Vehicles. (arXiv:2204.12825v1 [cs.LG])
49. Transfer Learning with Pre-trained Conditional Generative Models. (arXiv:2204.12833v1 [cs.LG])
50. Learning to Parallelize in a Shared-Memory Environment with Transformers. (arXiv:2204.12835v1 [cs.DC])
51. Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study. (arXiv:2204.12844v1 [cs.RO])
52. Detecting Backdoor Poisoning Attacks on Deep Neural Networks by Heatmap Clustering. (arXiv:2204.12848v1 [cs.LG])
53. Performance and Interpretability Comparisons of Supervised Machine Learning Algorithms: An Empirical Study. (arXiv:2204.12868v1 [stat.ML])
54. LiftPool: Lifting-based Graph Pooling for Hierarchical Graph Representation Learning. (arXiv:2204.12881v1 [cs.LG])
55. Spending Privacy Budget Fairly and Wisely. (arXiv:2204.12903v1 [cs.LG])
56. Epicardial Adipose Tissue Segmentation from CT Images with A Semi-3D Neural Network. (arXiv:2204.12904v1 [eess.IV])
57. Forecasting Foreign Exchange Rates With Parameter-Free Regression Networks Tuned By Bayesian Optimization. (arXiv:2204.12914v1 [q-fin.ST])
58. Improving Feature Generalizability with Multitask Learning in Class Incremental Learning. (arXiv:2204.12915v1 [cs.LG])
59. GypSum: Learning Hybrid Representations for Code Summarization. (arXiv:2204.12916v1 [cs.SE])
60. Topological Data Analysis for Anomaly Detection in Host-Based Logs. (arXiv:2204.12919v1 [cs.LG])
61. Trainable Compound Activation Functions for Machine Learning. (arXiv:2204.12920v1 [cs.LG])
62. Using the Projected Belief Network at High Dimensions. (arXiv:2204.12922v1 [cs.LG])
63. A Bayesian Approach To Graph Partitioning. (arXiv:2204.12927v1 [cs.LG])
64. Sequence-Based Target Coin Prediction for Cryptocurrency Pump-and-Dump. (arXiv:2204.12929v1 [q-fin.ST])
65. NFT Appraisal Prediction: Utilizing Search Trends, Public Market Data, Linear Regression and Recurrent Neural Networks. (arXiv:2204.12932v1 [q-fin.ST])
66. An Iterative Labeling Method for Annotating Fisheries Imagery. (arXiv:2204.12934v1 [cs.LG])
67. Learning to Transfer Role Assignment Across Team Sizes. (arXiv:2204.12937v1 [cs.LG])
68. On the Dynamics of Inference and Learning. (arXiv:2204.12939v1 [cond-mat.dis-nn])
69. Meshless method stencil evaluation with machine learning. (arXiv:2204.12940v1 [cs.LG])
70. Unsupervised Learning of Unbiased Visual Representations. (arXiv:2204.12941v1 [cs.LG])
71. Domain Knowledge-Infused Deep Learning for Automated Analog/Radio-Frequency Circuit Parameter Optimization. (arXiv:2204.12948v1 [cs.LG])
72. MAPLE-Edge: A Runtime Latency Predictor for Edge Devices. (arXiv:2204.12950v1 [cs.LG])
73. Towards assessing agricultural land suitability with causal machine learning. (arXiv:2204.12956v1 [cs.LG])
74. Scalable particle-based alternatives to EM. (arXiv:2204.12965v1 [stat.CO])
75. Multi-Objective Physics-Guided Recurrent Neural Networks for Identifying Non-Autonomous Dynamical Systems. (arXiv:2204.12972v1 [eess.SY])
76. First do no harm: counterfactual objective functions for safe & ethical AI. (arXiv:2204.12993v1 [cs.AI])
77. Ollivier-Ricci Curvature For Head Pose Estimation From a Single Image. (arXiv:2204.13006v1 [cs.CV])
78. NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue. (arXiv:2204.13021v1 [cs.CL])
79. Binding Actions to Objects in World Models. (arXiv:2204.13022v1 [cs.LG])
80. Dropout Inference with Non-Uniform Weight Scaling. (arXiv:2204.13047v1 [cs.LG])
81. TERMinator: A Neural Framework for Structure-Based Protein Design using Tertiary Repeating Motifs. (arXiv:2204.13048v1 [q-bio.BM])
82. Bisimulation Makes Analogies in Goal-Conditioned Reinforcement Learning. (arXiv:2204.13060v1 [cs.LG])
83. Can deep learning match the efficiency of human visual long-term memory to store object details?. (arXiv:2204.13061v1 [cs.LG])
84. Treating Crowdsourcing as Examination: How to Score Tasks and Online Workers?. (arXiv:2204.13065v1 [cs.HC])
85. Faster online calibration without randomization: interval forecasts and the power of two choices. (arXiv:2204.13087v1 [cs.LG])
86. Variational Kalman Filtering with Hinf-Based Correction for Robust Bayesian Learning in High Dimensions. (arXiv:2204.13089v1 [stat.ML])
87. FlowGNN: A Dataflow Architecture for Universal Graph Neural Network Inference via Multi-Queue Streaming. (arXiv:2204.13103v1 [cs.DC])
88. Network Classification Based Structural Analysis of Real Networks and their Model-Generated Counterparts. (arXiv:1810.08498v4 [cs.SI] UPDATED)
89. Accurate inference of crowdsourcing properties when using efficient allocation strategies. (arXiv:1903.03104v2 [cs.LG] UPDATED)
90. Differentially Quantized Gradient Methods. (arXiv:2002.02508v4 [cs.LG] UPDATED)
91. SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space. (arXiv:2008.00397v2 [cs.CV] UPDATED)
92. Unify Local and Global Information for Top-$N$ Recommendation. (arXiv:2012.01635v2 [cs.IR] UPDATED)
93. Rethinking the Promotion Brought by Contrastive Learning to Semi-Supervised Node Classification. (arXiv:2012.07437v2 [cs.LG] UPDATED)
94. Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v6 [cs.LG] UPDATED)
95. IH-GAN: A Conditional Generative Model for Implicit Surface-Based Inverse Design of Cellular Structures. (arXiv:2103.02588v4 [cs.CE] UPDATED)
96. Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models. (arXiv:2104.05158v6 [cs.DC] UPDATED)
97. Neural String Edit Distance. (arXiv:2104.08388v2 [cs.CL] UPDATED)
98. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v8 [cs.LG] UPDATED)
99. Residual Contrastive Learning for Image Reconstruction: Learning Transferable Representations from Noisy Images. (arXiv:2106.10070v2 [cs.CV] UPDATED)
100. Exoskeleton-Based Multimodal Action and Movement Recognition: Identifying and Developing the Optimal Boosted Learning Approach. (arXiv:2106.10331v2 [cs.RO] UPDATED)
101. Generalization Bounds with Minimal Dependency on Hypothesis Class via Distributionally Robust Optimization. (arXiv:2106.11180v2 [math.OC] UPDATED)
102. Encoding Involutory Invariances in Neural Networks. (arXiv:2106.12891v2 [cs.LG] UPDATED)
103. GNMR: A provable one-line algorithm for low rank matrix recovery. (arXiv:2106.12933v3 [math.OC] UPDATED)
104. Certified Robustness via Randomized Smoothing over Multiplicative Parameters. (arXiv:2106.14432v2 [cs.LG] UPDATED)
105. Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v2 [cs.LG] UPDATED)
106. Maximum Entropy Dueling Network Architecture in Atari Domain. (arXiv:2107.14457v2 [cs.LG] UPDATED)
107. SALIENCE: An Unsupervised User Adaptation Model for Multiple Wearable Sensors Based Human Activity Recognition. (arXiv:2108.10213v2 [eess.SP] UPDATED)
108. A Study of Fake News Reading and Annotating in Social Media Context. (arXiv:2109.12523v2 [cs.HC] UPDATED)
109. Leveraging power grid topology in machine learning assisted optimal power flow. (arXiv:2110.00306v3 [cs.LG] UPDATED)
110. BINAS: Bilinear Interpretable Neural Architecture Search. (arXiv:2110.12399v3 [cs.LG] UPDATED)
111. Physics-Driven Learning of Wasserstein GAN for Density Reconstruction in Dynamic Tomography. (arXiv:2110.15424v2 [eess.IV] UPDATED)
112. Efficient Learning of the Parameters of Non-Linear Models using Differentiable Resampling in Particle Filters. (arXiv:2111.01409v2 [stat.ML] UPDATED)
113. Explainable k-means. Don't be greedy, plant bigger trees!. (arXiv:2111.03193v2 [cs.LG] UPDATED)
114. Single-pass Object-adaptive Data Undersampling and Reconstruction for MRI. (arXiv:2111.09212v2 [eess.IV] UPDATED)
115. Automatic Synthesis of Diverse Weak Supervision Sources for Behavior Analysis. (arXiv:2111.15186v2 [cs.LG] UPDATED)
116. Variational Learning for Unsupervised Knowledge Grounded Dialogs. (arXiv:2112.00653v3 [cs.CL] UPDATED)
117. Regularized Newton Method with Global $O(1/k^2)$ Convergence. (arXiv:2112.02089v2 [math.OC] UPDATED)
118. Building separable approximations for quantum states via neural networks. (arXiv:2112.08055v4 [quant-ph] UPDATED)
119. Sublinear Time Approximation of Text Similarity Matrices. (arXiv:2112.09631v3 [cs.LG] UPDATED)
120. Accelerated Proximal Alternating Gradient-Descent-Ascent for Nonconvex Minimax Machine Learning. (arXiv:2112.11663v6 [cs.LG] UPDATED)
121. AI-Bind: Improving Binding Predictions for Novel Protein Targets and Ligands. (arXiv:2112.13168v4 [q-bio.QM] UPDATED)
122. Variance-Reduced Heterogeneous Federated Learning via Stratified Client Selection. (arXiv:2201.05762v2 [cs.LG] UPDATED)
123. AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees. (arXiv:2201.07984v2 [cs.AI] UPDATED)
124. Differentially Private SGDA for Minimax Problems. (arXiv:2201.09046v3 [cs.LG] UPDATED)
125. ISNet: Costless and Implicit Image Segmentation for Deep Classifiers, with Application in COVID-19 Detection. (arXiv:2202.00232v3 [eess.IV] UPDATED)
126. ROMNet: Renovate the Old Memories. (arXiv:2202.02606v2 [eess.IV] UPDATED)
127. Discovering Quantum Phase Transitions with Fermionic Neural Networks. (arXiv:2202.05183v2 [physics.comp-ph] UPDATED)
128. A Survey on Machine Learning Approaches for Modelling Intuitive Physics. (arXiv:2202.06481v2 [cs.LG] UPDATED)
129. Closing the Gap between Single-User and Multi-User VoiceFilter-Lite. (arXiv:2202.12169v2 [eess.AS] UPDATED)
130. Data-driven detector signal characterization with constrained bottleneck autoencoders. (arXiv:2203.04604v4 [physics.ins-det] UPDATED)
131. LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval. (arXiv:2203.06169v2 [cs.CL] UPDATED)
132. UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning. (arXiv:2203.14542v4 [cs.CV] UPDATED)
133. Reinforcement learning on graphs: A survey. (arXiv:2204.06127v2 [cs.LG] UPDATED)
134. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v5 [cs.CV] UPDATED)
135. Neural Collapse Inspired Attraction-Repulsion-Balanced Loss for Imbalanced Learning. (arXiv:2204.08735v2 [cs.LG] UPDATED)
136. Long-term Spatio-temporal Forecasting via Dynamic Multiple-Graph Attention. (arXiv:2204.11008v2 [cs.LG] UPDATED)
137. Reinforced Causal Explainer for Graph Neural Networks. (arXiv:2204.11028v2 [cs.LG] UPDATED)
138. Data Debugging with Shapley Importance over End-to-End Machine Learning Pipelines. (arXiv:2204.11131v2 [cs.LG] UPDATED)
139. An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models. (arXiv:2204.11351v2 [cs.LG] UPDATED)
140. Trusted Multi-View Classification with Dynamic Evidential Fusion. (arXiv:2204.11423v2 [cs.LG] UPDATED)
141. Online Deep Learning from Doubly-Streaming Data. (arXiv:2204.11793v2 [cs.LG] UPDATED)
142. Performer: A Novel PPG to ECG Reconstruction Transformer For a Digital Biomarker of Cardiovascular Disease Detection. (arXiv:2204.11795v2 [eess.SP] UPDATED)
## cs.AI
---
**75** new papers in cs.AI:-) 
1. AI-Assisted Authentication: State of the Art, Taxonomy and Future Roadmap. (arXiv:2204.12492v1 [cs.CR])
2. Enhancing Privacy against Inversion Attacks in Federated Learning by using Mixing Gradients Strategies. (arXiv:2204.12495v1 [cs.LG])
3. Self-Supervised Information Bottleneck for Deep Multi-View Subspace Clustering. (arXiv:2204.12496v1 [cs.LG])
4. Automation of Radiation Treatment Planning for Rectal Cancer. (arXiv:2204.12539v1 [physics.med-ph])
5. Parkinson's disease diagnostics using AI and natural language knowledge transfer. (arXiv:2204.12559v1 [cs.CL])
6. Process Knowledge-infused Learning for Suicidality Assessment on Social Media. (arXiv:2204.12560v1 [cs.AI])
7. Learning Eco-Driving Strategies at Signalized Intersections. (arXiv:2204.12561v1 [eess.SY])
8. On the Verification of Belief Programs. (arXiv:2204.12562v1 [cs.AI])
9. Toward Policy Explanations for Multi-Agent Reinforcement Learning. (arXiv:2204.12568v1 [cs.AI])
10. RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning. (arXiv:2204.12581v1 [cs.LG])
11. Testing the Ability of Language Models to Interpret Figurative Language. (arXiv:2204.12632v1 [cs.CL])
12. Generating Examples From CLI Usage: Can Transformers Help?. (arXiv:2204.12648v1 [cs.SE])
13. Investigating the Emergence of Online Learning in Different Countries using the 5 W's and 1 H Approach. (arXiv:2204.12650v1 [cs.CY])
14. Trends in Remote Learning-based Google Shopping in the United States due to COVID-19. (arXiv:2204.12654v1 [cs.CY])
15. Relational Abstractions for Generalized Reinforcement Learning on Symbolic Problems. (arXiv:2204.12665v1 [cs.LG])
16. Span-level Bidirectional Cross-attention Framework for Aspect Sentiment Triplet Extraction. (arXiv:2204.12674v1 [cs.CL])
17. Discovering Representative Attribute-stars via Minimum Description Length. (arXiv:2204.12704v1 [cs.AI])
18. UBERT: A Novel Language Model for Synonymy Prediction at Scale in the UMLS Metathesaurus. (arXiv:2204.12716v1 [cs.CL])
19. Minimum Displacement Motion Planning for Movable Obstacles. (arXiv:2204.12740v1 [cs.RO])
20. Self-Supervised Text Erasing with Controllable Image Synthesis. (arXiv:2204.12743v1 [cs.CV])
21. DraftRec: Personalized Draft Recommendation for Winning in Multi-Player Online Battle Arena Games. (arXiv:2204.12750v1 [cs.AI])
22. Learn from Structural Scope: Improving Aspect-Level Sentiment Analysis with Hybrid Graph Convolutional Networks. (arXiv:2204.12784v1 [cs.CL])
23. GTNet: A Tree-Based Deep Graph Learning Architecture. (arXiv:2204.12802v1 [cs.LG])
24. Probing Simile Knowledge from Pre-trained Language Models. (arXiv:2204.12807v1 [cs.CL])
25. A Survey on XAI for Beyond 5G Security: Technical Aspects, Use Cases, Challenges and Research Directions. (arXiv:2204.12822v1 [cs.NI])
26. Transfer Learning with Pre-trained Conditional Generative Models. (arXiv:2204.12833v1 [cs.LG])
27. Accelerating Robot Learning of Contact-Rich Manipulations: A Curriculum Learning Study. (arXiv:2204.12844v1 [cs.RO])
28. Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming. (arXiv:2204.12846v1 [math.NA])
29. Beyond Duplicates: Towards Understanding and Predicting Link Types in Issue Tracking Systems. (arXiv:2204.12893v1 [cs.SE])
30. Global Trajectory Helps Person Retrieval in a Camera Network. (arXiv:2204.12900v1 [cs.CV])
31. Capabilities and Skills in Manufacturing: A Survey Over the Last Decade of ETFA. (arXiv:2204.12908v1 [cs.AI])
32. Topological Data Analysis for Anomaly Detection in Host-Based Logs. (arXiv:2204.12919v1 [cs.LG])
33. Causal Analysis of Generic Time Series Data Applied for Market Prediction. (arXiv:2204.12928v1 [q-fin.ST])
34. AdaCoach: A Virtual Coach for Training Customer Service Agents. (arXiv:2204.12935v1 [cs.CL])
35. Learning to Transfer Role Assignment Across Team Sizes. (arXiv:2204.12937v1 [cs.LG])
36. MAPLE-Edge: A Runtime Latency Predictor for Edge Devices. (arXiv:2204.12950v1 [cs.LG])
37. Towards assessing agricultural land suitability with causal machine learning. (arXiv:2204.12956v1 [cs.LG])
38. First do no harm: counterfactual objective functions for safe & ethical AI. (arXiv:2204.12993v1 [cs.AI])
39. Towards Teachable Reasoning Systems. (arXiv:2204.13074v1 [cs.CL])
40. SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space. (arXiv:2008.00397v2 [cs.CV] UPDATED)
41. SAT-based Circuit Local Improvement. (arXiv:2102.12579v3 [cs.AI] UPDATED)
42. Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models. (arXiv:2104.05158v6 [cs.DC] UPDATED)
43. LAI Estimation of Cucumber Crop Based on Improved Fully Convolutional Network. (arXiv:2104.07955v2 [cs.CV] UPDATED)
44. Augmenting Anchors by the Detector Itself. (arXiv:2105.14086v2 [cs.CV] UPDATED)
45. Back2Future: Leveraging Backfill Dynamics for Improving **Real-time** Predictions in Future. (arXiv:2106.04420v8 [cs.LG] UPDATED)
46. Encoding Involutory Invariances in Neural Networks. (arXiv:2106.12891v2 [cs.LG] UPDATED)
47. Optimal Epidemic Control as a Contextual Combinatorial Bandit with Budget. (arXiv:2106.15808v2 [cs.LG] UPDATED)
48. Maximum Entropy Dueling Network Architecture in Atari Domain. (arXiv:2107.14457v2 [cs.LG] UPDATED)
49. ICAF: Iterative Contrastive Alignment Framework for Multimodal Abstractive Summarization. (arXiv:2108.05123v2 [cs.AI] UPDATED)
50. Cascading Neural Network Methodology for Artificial Intelligence-Assisted Radiographic Detection and Classification of Lead-Less Implanted Electronic Devices within the Chest. (arXiv:2108.11954v2 [eess.IV] UPDATED)
51. Enabling risk-aware Reinforcement Learning for medical interventions through uncertainty decomposition. (arXiv:2109.07827v2 [cs.AI] UPDATED)
52. Favoring Eagerness for Remaining Items: Designing Efficient, Fair, and Strategyproof Mechanisms. (arXiv:2109.08856v2 [cs.GT] UPDATED)
53. BINAS: Bilinear Interpretable Neural Architecture Search. (arXiv:2110.12399v3 [cs.LG] UPDATED)
54. Automated scholarly paper review: Technologies and challenges. (arXiv:2111.07533v2 [cs.AI] UPDATED)
55. Triggerless Backdoor Attack for NLP Tasks with Clean Labels. (arXiv:2111.07970v2 [cs.CL] UPDATED)
56. Literature-Augmented Clinical Outcome Prediction. (arXiv:2111.08374v2 [cs.CL] UPDATED)
57. Weakly Supervised Text-to-SQL Parsing through Question Decomposition. (arXiv:2112.06311v3 [cs.CL] UPDATED)
58. Explainable artificial intelligence for autonomous driving: An overview and guide for future research directions. (arXiv:2112.11561v2 [cs.AI] UPDATED)
59. OSSID: Online Self-Supervised Instance Detection by (and for) Pose Estimation. (arXiv:2201.07309v2 [cs.CV] UPDATED)
60. AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees. (arXiv:2201.07984v2 [cs.AI] UPDATED)
61. A Survey on Machine Learning Approaches for Modelling Intuitive Physics. (arXiv:2202.06481v2 [cs.LG] UPDATED)
62. LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval. (arXiv:2203.06169v2 [cs.CL] UPDATED)
63. HyperBox: A Supervised Approach for Hypernym Discovery using Box Embeddings. (arXiv:2204.02058v2 [cs.CL] UPDATED)
64. A Weakly Supervised Propagation Model for Rumor Verification and Stance Detection with Multiple Instance Learning. (arXiv:2204.02626v2 [cs.CL] UPDATED)
65. Learning Convolutional Neural Networks in the Frequency Domain. (arXiv:2204.06718v5 [cs.CV] UPDATED)
66. Embracing AWKWARD! **Real-time** Adjustment of Reactive Plans Using Social Norms. (arXiv:2204.10740v2 [cs.MA] UPDATED)
67. A New Lagrangian Problem Crossover: A Systematic Review and Meta-Analysis of Crossover Standards. (arXiv:2204.10890v2 [cs.NE] UPDATED)
68. Long-term Spatio-temporal Forecasting via Dynamic Multiple-Graph Attention. (arXiv:2204.11008v2 [cs.LG] UPDATED)
69. Reinforced Causal Explainer for Graph Neural Networks. (arXiv:2204.11028v2 [cs.LG] UPDATED)
70. Data Debugging with Shapley Importance over End-to-End Machine Learning Pipelines. (arXiv:2204.11131v2 [cs.LG] UPDATED)
71. An empirical study of the effect of background data size on the stability of SHapley Additive exPlanations (SHAP) for deep learning models. (arXiv:2204.11351v2 [cs.LG] UPDATED)
72. Robust Self-Augmentation for Named Entity Recognition with Meta Reweighting. (arXiv:2204.11406v2 [cs.CL] UPDATED)
73. Learning First-Order Symbolic Planning Representations That Are Grounded. (arXiv:2204.11902v2 [cs.AI] UPDATED)
74. Spontaneous Emergence of Computation in Network Cascades. (arXiv:2204.11956v2 [physics.soc-ph] UPDATED)
75. Collaborative Target Search with a Visual Drone Swarm: An Adaptive Curriculum Embedded Multi-stage Reinforcement Learning Approach. (arXiv:2204.12181v2 [cs.RO] UPDATED)

