# Your interest papers
---
## cs.CV
---
### MIPI 2022 Challenge on RGBW Sensor Fusion: Dataset and Report. (arXiv:2209.07530v1 [eess.IV])
- Authors : Qingyu Yang, Guang Yang, Jun Jiang, **Chongyi Li**, Ruicheng Feng, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07530](http://arxiv.org/abs/2209.07530)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge, including five tracks focusing on novel image sensors and imaging algorithms. In this paper, RGBW Joint Fusion and Denoise, one of the five tracks, working on the fusion of binning-mode RGBW to Bayer, is introduced. The participants were provided with a new dataset including 70 (training) and 15 (validation) scenes of high-quality RGBW and Bayer pairs. In addition, for each scene, RGBW of different noise levels was provided at 24dB and 42dB. All the data were captured using an RGBW sensor in both outdoor and indoor conditions. The final results are evaluated using objective metrics, including PSNR, SSIM}, LPIPS, and KLD. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### Self-Attentive Pooling for Efficient Deep Learning. (arXiv:2209.07659v1 [cs.CV])
- Authors : Fang Chen, Gourav Datta, Souvikk Kundu, Peter Beerel
- Link : [http://arxiv.org/abs/2209.07659](http://arxiv.org/abs/2209.07659)
> ABSTRACT  :  Efficient custom pooling techniques that can aggressively trim the dimensions of a feature map and thereby reduce inference compute and memory footprint for resource-constrained computer vision applications have recently gained significant traction. However, prior pooling works extract only the local context of the activation maps, limiting their effectiveness. In contrast, we propose a novel non-local self-attentive pooling method that can be used as a drop-in replacement to the standard pooling layers, such as max/average pooling or strided convolution. The proposed self-attention module uses patch embedding, multi-head self-attention, and spatial-channel **restoration**, followed by sigmoid activation and exponential soft-max. This self-attention mechanism efficiently aggregates dependencies between non-local activation patches during down-sampling. Extensive experiments on standard object classification and detection tasks with various convolutional neural network (CNN) architectures demonstrate the superiority of our proposed mechanism over the state-of-the-art (SOTA) pooling techniques. In particular, we surpass the test accuracy of existing pooling techniques on different variants of MobileNet-V2 on ImageNet by an average of 1.2%. With the aggressive down-sampling of the activation maps in the initial layers (providing up to 22x reduction in memory consumption), our approach achieves 1.43% higher test accuracy compared to SOTA techniques with iso-memory footprints. This enables the deployment of our models in memory-constrained devices, such as micro-controllers (without losing significant accuracy), because the initial activation maps consume a significant amount of on-chip memory for high-resolution images required for complex vision tasks. Our proposed pooling method also leverages the idea of channel pruning to further reduce memory footprints.  
### SQ-**Swin**: a Pretrained Siamese Quadratic **Swin** Transformer for Lettuce Browning Prediction. (arXiv:2209.07683v1 [cs.CV])
- Authors : Dayang Wang, Boce Zhang, Yongshun Xu, Yaguang Luo, Hengyong Yu
- Link : [http://arxiv.org/abs/2209.07683](http://arxiv.org/abs/2209.07683)
> ABSTRACT  :  Packaged fresh-cut lettuce is widely consumed as a major component of vegetable salad owing to its high nutrition, freshness, and convenience. However, enzymatic browning discoloration on lettuce cut edges significantly reduces product quality and shelf life. While there are many research and breeding efforts underway to minimize browning, the progress is hindered by the lack of a rapid and reliable methodology to evaluate browning. Current methods to identify and quantify browning are either too subjective, labor intensive, or inaccurate. In this paper, we report a deep learning model for lettuce browning prediction. To the best of our knowledge, it is the first-of-its-kind on deep learning for lettuce browning prediction using a pretrained Siamese Quadratic **Swin** (SQ-**Swin**) transformer with several highlights. First, our model includes quadratic features in the transformer model which is more powerful to incorporate real-world representations than the linear transformer. Second, a multi-scale training strategy is proposed to augment the data and explore more of the inherent self-similarity of the lettuce images. Third, the proposed model uses a siamese architecture which learns the inter-relations among the limited training samples. Fourth, the model is pretrained on the ImageNet and then trained with the reptile meta-learning algorithm to learn higher-order gradients than a regular one. Experiment results on the fresh-cut lettuce datasets show that the proposed SQ-**Swin** outperforms the traditional methods and other deep learning-based backbones.  
### ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV])
- Authors : Zimian Wei, Hengyue Pan, Xin Niu, Dongsheng Li
- Link : [http://arxiv.org/abs/2209.07738](http://arxiv.org/abs/2209.07738)
> ABSTRACT  :  Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more efficient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer outperforms similar size vision transformers(ViTs) and convolutional neural networks (CNNs) in various tasks. For example, ConvFormer-S, ConvFormer-L achieve state-of-the-art performance of 82.8%, 83.6% top-1 accuracy on ImageNet dataset. Moreover, ConvFormer-S outperforms **Swin**-T by 1.5 mIoU on ADE20K, and 0.9 bounding box AP on COCO with a smaller model size. Code and models will be available.  
### Estimation of Optical Aberrations in 3D Microscopic Bioimages. (arXiv:2209.07911v1 [eess.IV])
- Authors : Kira Vinogradova
- Link : [http://arxiv.org/abs/2209.07911](http://arxiv.org/abs/2209.07911)
> ABSTRACT  :  The quality of microscopy images often suffers from optical aberrations. These aberrations and their associated point spread functions have to be quantitatively estimated to restore aberrated images. The recent state-of-the-art method PhaseNet, based on a convolutional neural network, can quantify aberrations accurately but is limited to images of point light sources, e.g. fluorescent beads. In this research, we describe an extension of PhaseNet enabling its use on 3D images of biological samples. To this end, our method incorporates object-specific information into the simulated images used for training the network. Further, we add a Python-based **restoration** of images via Richardson-Lucy deconvolution. We demonstrate that the deconvolution with the predicted PSF can not only remove the simulated aberrations but also improve the quality of the real raw microscopic images with unknown residual PSF. We provide code for fast and convenient prediction and correction of aberrations.  
### DPFNet: A Dual-branch Dilated Network with Phase-aware Fourier Convolution for **Low-light** Image **Enhancement**. (arXiv:2209.07937v1 [cs.CV])
- Authors : Yunliang Zhuang, Zhuoran Zheng, Chen Lyu
- Link : [http://arxiv.org/abs/2209.07937](http://arxiv.org/abs/2209.07937)
> ABSTRACT  :  **Low-light** image **enhancement** is a classical computer vision problem aiming to recover normal-**exposure** images from **low-light** images. However, convolutional neural networks commonly used in this field are good at sampling low-frequency local structural features in the spatial domain, which leads to unclear texture details of the reconstructed images. To alleviate this problem, we propose a novel module using the Fourier coefficients, which can recover high-quality texture details under the constraint of semantics in the frequency phase and supplement the spatial domain. In addition, we design a simple and efficient module for the image spatial domain using dilated convolutions with different receptive fields to alleviate the loss of detail caused by frequent downsampling. We integrate the above parts into an end-to-end dual branch network and design a novel loss committee and an adaptive fusion module to guide the network to flexibly combine spatial and frequency domain features to generate more pleasing visual effects. Finally, we evaluate the proposed network on public benchmarks. Extensive experimental results show that our method outperforms many existing state-of-the-art ones, showing outstanding performance and potential.  
### Enhancing Video Analytics Accuracy via **Real-time** Automated Camera Parameter Tuning. (arXiv:2107.03964v4 [cs.LG] UPDATED)
- Authors : Sibendu Paul, Kunal Rao, Giuseppe Coviello, Murugan Sankaradas, Oliver Po, Charlie Hu
- Link : [http://arxiv.org/abs/2107.03964](http://arxiv.org/abs/2107.03964)
> ABSTRACT  :  In Video Analytics Pipelines (VAP), Analytics Units (AUs) such as object detection and face recognition running on remote servers critically rely on surveillance cameras to capture high-quality video streams in order to achieve high accuracy. Modern IP cameras come with a large number of camera parameters that directly affect the quality of the video stream capture. While a few of such parameters, e.g., **exposure**, focus, white balance are automatically adjusted by the camera internally, the remaining ones are not. We denote such camera parameters as non-automated (NAUTO) parameters. In this paper, we first show that environmental condition changes can have significant adverse effect on the accuracy of insights from the AUs, but such adverse impact can potentially be mitigated by dynamically adjusting NAUTO camera parameters in response to changes in environmental conditions. We then present CamTuner, to our knowledge, the first framework that dynamically adapts NAUTO camera parameters to optimize the accuracy of AUs in a VAP in response to adverse changes in environmental conditions. CamTuner is based on SARSA reinforcement learning and it incorporates two novel components: a light-weight analytics quality estimator and a virtual camera that drastically speed up offline RL training. Our controlled experiments and real-world VAP deployment show that compared to a VAP using the default camera setting, CamTuner enhances VAP accuracy by detecting 15.9% additional persons and 2.6%-4.2% additional cars (without any false positives) in a large enterprise parking lot and 9.7% additional cars in a 5G smart traffic intersection scenario, which enables a new usecase of accurate and reliable automatic vehicle collision prediction (AVCP). CamTuner opens doors for new ways to significantly enhance video analytics accuracy beyond incremental improvements from refining deep-learning models.  
## eess.IV
---
### MIPI 2022 Challenge on RGBW Sensor Fusion: Dataset and Report. (arXiv:2209.07530v1 [eess.IV])
- Authors : Qingyu Yang, Guang Yang, Jun Jiang, **Chongyi Li**, Ruicheng Feng, Shangchen Zhou, Wenxiu Sun, Qingpeng Zhu, Chen Change, **Jinwei Gu**
- Link : [http://arxiv.org/abs/2209.07530](http://arxiv.org/abs/2209.07530)
> ABSTRACT  :  Developing and integrating advanced image sensors with novel algorithms in camera systems are prevalent with the increasing demand for computational photography and imaging on mobile platforms. However, the lack of high-quality data for research and the rare opportunity for in-depth exchange of views from industry and academia constrain the development of mobile intelligent photography and imaging (MIPI). To bridge the gap, we introduce the first MIPI challenge, including five tracks focusing on novel image sensors and imaging algorithms. In this paper, RGBW Joint Fusion and Denoise, one of the five tracks, working on the fusion of binning-mode RGBW to Bayer, is introduced. The participants were provided with a new dataset including 70 (training) and 15 (validation) scenes of high-quality RGBW and Bayer pairs. In addition, for each scene, RGBW of different noise levels was provided at 24dB and 42dB. All the data were captured using an RGBW sensor in both outdoor and indoor conditions. The final results are evaluated using objective metrics, including PSNR, SSIM}, LPIPS, and KLD. A detailed description of all models developed in this challenge is provided in this paper. More details of this challenge and the link to the dataset can be found at https://github.com/mipi-challenge/MIPI2022.  
### Structure-Preserving Spectral Reflectance Estimation using Guided Filtering. (arXiv:2209.07889v1 [eess.IV])
- Authors : Frank Sippel, rgen Seiler, Nils Genser
- Link : [http://arxiv.org/abs/2209.07889](http://arxiv.org/abs/2209.07889)
> ABSTRACT  :  Light spectra are a very important source of information for diverse classification problems, e.g., for discrimination of materials. To lower the cost for acquiring this information, multispectral cameras are used. Several techniques exist for estimating light spectra out of multispectral images by exploiting properties about the spectrum. Unfortunately, especially when capturing multispectral videos, the images are heavily affected by noise due to the nature of limited **exposure** times in videos. Therefore, models that explicitly try to lower the influence of noise on the reconstructed spectrum are highly desirable. Hence, a novel reconstruction algorithm is presented. This novel estimation method is based on the guided filtering technique which preserves basic structures, while using spatial information to reduce the influence of noise. The evaluation based on spectra of natural images reveals that this new technique yields better quantitative and subjective results in noisy scenarios than other state-of-the-art spatial reconstruction methods. Specifically, the proposed algorithm lowers the mean squared error and the spectral angle up to 46% and 35% in noisy scenarios, respectively. Furthermore, it is shown that the proposed reconstruction technique works out-of-the-box and does not need any calibration or training by reconstructing spectra from a real-world multispectral camera with nine channels.  
### Estimation of Optical Aberrations in 3D Microscopic Bioimages. (arXiv:2209.07911v1 [eess.IV])
- Authors : Kira Vinogradova
- Link : [http://arxiv.org/abs/2209.07911](http://arxiv.org/abs/2209.07911)
> ABSTRACT  :  The quality of microscopy images often suffers from optical aberrations. These aberrations and their associated point spread functions have to be quantitatively estimated to restore aberrated images. The recent state-of-the-art method PhaseNet, based on a convolutional neural network, can quantify aberrations accurately but is limited to images of point light sources, e.g. fluorescent beads. In this research, we describe an extension of PhaseNet enabling its use on 3D images of biological samples. To this end, our method incorporates object-specific information into the simulated images used for training the network. Further, we add a Python-based **restoration** of images via Richardson-Lucy deconvolution. We demonstrate that the deconvolution with the predicted PSF can not only remove the simulated aberrations but also improve the quality of the real raw microscopic images with unknown residual PSF. We provide code for fast and convenient prediction and correction of aberrations.  
### Single-shot pop-out 3D metrology of thin specimens with TEM. (arXiv:2209.07930v1 [physics.ins-det])
- Authors : Deepan Balakrishnan, See Wee, Zhaslan Baraissov, Michel Bosman, Utkur Mirsaidov, Duane Loh
- Link : [http://arxiv.org/abs/2209.07930](http://arxiv.org/abs/2209.07930)
> ABSTRACT  :  Three-dimensional (3D) imaging of thin, extended specimens at nanometer resolution is critical for applications in biology, materials science, advanced synthesis, and manufacturing. Many 3D imaging techniques are limited to surface features, or available only for selective cross-sections, or require a tilt series of a local region, hence making them unsuitable for rapid, non-sacrificial screening of extended objects, or investigating fast dynamics. Here we describe a coherent imaging technique that recovers the 3D volume of a thin specimen with only a single, non-tomographic, energy-filtered, bright-field transmission electron microscopy (TEM) image. This technique does not require physically fracturing or sectioning thin specimens, only needs a single brief **exposure**s to electron doses of ~100 e {\AA}-2, and can be readily calibrated for many existing TEMs; thus it can be widely deployed for rapid 3D metrology that complements existing forms of metrology.  
### DPFNet: A Dual-branch Dilated Network with Phase-aware Fourier Convolution for **Low-light** Image **Enhancement**. (arXiv:2209.07937v1 [cs.CV])
- Authors : Yunliang Zhuang, Zhuoran Zheng, Chen Lyu
- Link : [http://arxiv.org/abs/2209.07937](http://arxiv.org/abs/2209.07937)
> ABSTRACT  :  **Low-light** image **enhancement** is a classical computer vision problem aiming to recover normal-**exposure** images from **low-light** images. However, convolutional neural networks commonly used in this field are good at sampling low-frequency local structural features in the spatial domain, which leads to unclear texture details of the reconstructed images. To alleviate this problem, we propose a novel module using the Fourier coefficients, which can recover high-quality texture details under the constraint of semantics in the frequency phase and supplement the spatial domain. In addition, we design a simple and efficient module for the image spatial domain using dilated convolutions with different receptive fields to alleviate the loss of detail caused by frequent downsampling. We integrate the above parts into an end-to-end dual branch network and design a novel loss committee and an adaptive fusion module to guide the network to flexibly combine spatial and frequency domain features to generate more pleasing visual effects. Finally, we evaluate the proposed network on public benchmarks. Extensive experimental results show that our method outperforms many existing state-of-the-art ones, showing outstanding performance and potential.  
## cs.LG
---
### Statistical Properties of the Entropy from Ordinal Patterns. (arXiv:2209.07650v1 [cs.IT])
- Authors : Juliana Gambini
- Link : [http://arxiv.org/abs/2209.07650](http://arxiv.org/abs/2209.07650)
> ABSTRACT  :  The ultimate purpose of the statistical analysis of ordinal patterns is to characterize the distribution of the features they induce. In particular, knowing the joint distribution of the pair Entropy-Statistical Complexity for a large class of time series models would allow statistical tests that are unavailable to date. Working in this direction, we characterize the asymptotic distribution of the empirical Shannon's Entropy for any model under which the true normalized Entropy is neither zero nor one. We obtain the asymptotic distribution from the Central Limit Theorem (assuming large time series), the Multivariate Delta Method, and a third-order correction of its mean value. We discuss the applicability of other results (exact, first-, and second-order corrections) regarding their accuracy and numerical stability. Within a general framework for building test statistics about Shannon's Entropy, we present a **bilateral** test that verifies if there is enough evidence to reject the hypothesis that two signals produce ordinal patterns with the same Shannon's Entropy. We applied this **bilateral** test to the daily maximum temperature time series from three cities (Dublin, Edinburgh, and Miami) and obtained sensible results.  
### Self-Attentive Pooling for Efficient Deep Learning. (arXiv:2209.07659v1 [cs.CV])
- Authors : Fang Chen, Gourav Datta, Souvikk Kundu, Peter Beerel
- Link : [http://arxiv.org/abs/2209.07659](http://arxiv.org/abs/2209.07659)
> ABSTRACT  :  Efficient custom pooling techniques that can aggressively trim the dimensions of a feature map and thereby reduce inference compute and memory footprint for resource-constrained computer vision applications have recently gained significant traction. However, prior pooling works extract only the local context of the activation maps, limiting their effectiveness. In contrast, we propose a novel non-local self-attentive pooling method that can be used as a drop-in replacement to the standard pooling layers, such as max/average pooling or strided convolution. The proposed self-attention module uses patch embedding, multi-head self-attention, and spatial-channel **restoration**, followed by sigmoid activation and exponential soft-max. This self-attention mechanism efficiently aggregates dependencies between non-local activation patches during down-sampling. Extensive experiments on standard object classification and detection tasks with various convolutional neural network (CNN) architectures demonstrate the superiority of our proposed mechanism over the state-of-the-art (SOTA) pooling techniques. In particular, we surpass the test accuracy of existing pooling techniques on different variants of MobileNet-V2 on ImageNet by an average of 1.2%. With the aggressive down-sampling of the activation maps in the initial layers (providing up to 22x reduction in memory consumption), our approach achieves 1.43% higher test accuracy compared to SOTA techniques with iso-memory footprints. This enables the deployment of our models in memory-constrained devices, such as micro-controllers (without losing significant accuracy), because the initial activation maps consume a significant amount of on-chip memory for high-resolution images required for complex vision tasks. Our proposed pooling method also leverages the idea of channel pruning to further reduce memory footprints.  
### A Biologically-Inspired Dual Stream World Model. (arXiv:2209.08035v1 [cs.LG])
- Authors : Arthur Juliani, Margaret Sereno
- Link : [http://arxiv.org/abs/2209.08035](http://arxiv.org/abs/2209.08035)
> ABSTRACT  :  The medial temporal lobe (MTL), a brain region containing the hippocampus and nearby areas, is hypothesized to be an experience-construction system in mammals, supporting both recall and imagination of temporally-extended sequences of events. Such capabilities are also core to many recently proposed ``world models" in the field of AI research. Taking inspiration from this connection, we propose a novel variant, the Dual Stream World Model (DSWM), which learns from high-dimensional observations and dissociates them into context and content streams. DSWM can reliably generate imagined trajectories in novel 2D environments after only a single **exposure**, outperforming a standard world model. DSWM also learns latent representations which bear a strong resemblance to place cells found in the hippocampus. We show that this representation is useful as a reinforcement learning basis function, and that the generative model can be used to aid the policy learning process using Dyna-like updates.  
### Optimal binning: mathematical programming formulation. (arXiv:2001.08025v2 [cs.LG] UPDATED)
- Authors : Guillermo Navas
- Link : [http://arxiv.org/abs/2001.08025](http://arxiv.org/abs/2001.08025)
> ABSTRACT  :  The optimal binning is the optimal discretization of a variable into bins given a discrete or continuous numeric target. We present a rigorous and extensible mathematical programming formulation for solving the optimal binning problem for a binary, continuous and multi-class target type, incorporating constraints not previously addressed. For all three target types, we introduce a convex mixed-integer programming formulation. Several algorithmic **enhancement**s, such as automatic determination of the most suitable monotonic trend via a Machine-Learning-based classifier and implementation aspects are thoughtfully discussed. The new mathematical programming formulations are carefully implemented in the open-source python library OptBinning.  
### Enhancing Video Analytics Accuracy via **Real-time** Automated Camera Parameter Tuning. (arXiv:2107.03964v4 [cs.LG] UPDATED)
- Authors : Sibendu Paul, Kunal Rao, Giuseppe Coviello, Murugan Sankaradas, Oliver Po, Charlie Hu
- Link : [http://arxiv.org/abs/2107.03964](http://arxiv.org/abs/2107.03964)
> ABSTRACT  :  In Video Analytics Pipelines (VAP), Analytics Units (AUs) such as object detection and face recognition running on remote servers critically rely on surveillance cameras to capture high-quality video streams in order to achieve high accuracy. Modern IP cameras come with a large number of camera parameters that directly affect the quality of the video stream capture. While a few of such parameters, e.g., **exposure**, focus, white balance are automatically adjusted by the camera internally, the remaining ones are not. We denote such camera parameters as non-automated (NAUTO) parameters. In this paper, we first show that environmental condition changes can have significant adverse effect on the accuracy of insights from the AUs, but such adverse impact can potentially be mitigated by dynamically adjusting NAUTO camera parameters in response to changes in environmental conditions. We then present CamTuner, to our knowledge, the first framework that dynamically adapts NAUTO camera parameters to optimize the accuracy of AUs in a VAP in response to adverse changes in environmental conditions. CamTuner is based on SARSA reinforcement learning and it incorporates two novel components: a light-weight analytics quality estimator and a virtual camera that drastically speed up offline RL training. Our controlled experiments and real-world VAP deployment show that compared to a VAP using the default camera setting, CamTuner enhances VAP accuracy by detecting 15.9% additional persons and 2.6%-4.2% additional cars (without any false positives) in a large enterprise parking lot and 9.7% additional cars in a 5G smart traffic intersection scenario, which enables a new usecase of accurate and reliable automatic vehicle collision prediction (AVCP). CamTuner opens doors for new ways to significantly enhance video analytics accuracy beyond incremental improvements from refining deep-learning models.  
### Satellite galaxy abundance dependency on cosmology in Magneticum simulations. (arXiv:2110.05498v2 [astro-ph.CO] UPDATED)
- Authors : Antonio Ragagnin, Alessandra Fumagalli, Tiago Castro, Klaus Dolag, Alexandro Saro, Matteo Costanzi, Sebastian Bocquet
- Link : [http://arxiv.org/abs/2110.05498](http://arxiv.org/abs/2110.05498)
> ABSTRACT  :  Context: Modelling satellite galaxy abundance $N_s$ in Galaxy Clusters (GCs) is a key element in modelling the Halo Occupation Distribution (HOD), which itself is a powerful tool to connect observational studies with numerical simulations. Aims: To study the impact of cosmological parameters on satellite abundance both in cosmological simulations and in mock observations. Methods: We build an emulator (HODEmu, \url{https://github.com/aragagnin/HODEmu/}) of satellite abundance based on cosmological parameters $\Omega_m, \Omega_b, \sigma_8, h_0$ and redshift $z.$ We train our emulator using \magneticum hydrodynamic simulations that span 15 different cosmologies, each over $4$ redshift slices between $0&lt;z&lt;0.5,$ and for each setup we fit normalisation $A$, log-slope $\beta$ and Gaussian fractional-scatter $\sigma$ of the $N_s-M$ relation. The emulator is based on multi-variate output Gaussian Process Regression (GPR). Results: We find that $A$ and $\beta$ depend on cosmological parameters, even if weakly, especially on $\Omega_m,$ $\Omega_b.$ This dependency can explain some discrepancies found in literature between satellite HOD of different cosmological simulations (Magneticum, Illustris, BAHAMAS). We also show that satellite abundance cosmology dependency differs between full-physics (FP) simulations, **dark**-matter only (DMO), and non-radiative simulations. Conclusions: This work provides a preliminary calibration of the cosmological dependency of the satellite abundance of high mass halos, and we showed that modelling HOD with cosmological parameters is necessary to interpret satellite abundance, and we showed the importance of using FP simulations in modelling this dependency.  
### Multimodal Audio-Visual Information Fusion using Canonical-Correlated Graph Neural Network for Energy-Efficient Speech **Enhancement**. (arXiv:2202.04528v3 [cs.SD] UPDATED)
- Authors : Leandro Aparecido, Paulo Papa, Javier Del, Amir Hussain, Ahsan Adeel
- Link : [http://arxiv.org/abs/2202.04528](http://arxiv.org/abs/2202.04528)
> ABSTRACT  :  This paper proposes a novel multimodal self-supervised architecture for energy-efficient audio-visual (AV) speech **enhancement** that integrates Graph Neural Networks with canonical correlation analysis (CCA-GNN). The proposed approach lays its foundations on a state-of-the-art CCA-GNN that learns representative embeddings by maximizing the correlation between pairs of augmented views of the same input while decorrelating disconnected features. The key idea of the conventional CCA-GNN involves discarding augmentation-variant information and preserving augmentation-invariant information while preventing capturing of redundant information. Our proposed AV CCA-GNN model deals with multimodal representation learning context. Specifically, our model improves contextual AV speech processing by maximizing canonical correlation from augmented views of the same channel and canonical correlation from audio and visual embeddings. In addition, it proposes a positional node encoding that considers a prior-frame sequence distance instead of a feature-space representation when computing the node's nearest neighbors, introducing temporal information in the embeddings through the neighborhood's connectivity. Experiments conducted on the benchmark ChiME3 dataset show that our proposed prior frame-based AV CCA-GNN ensures better feature learning in the temporal context, leading to more energy-efficient speech reconstruction than state-of-the-art CCA-GNN and multilayer perceptron.  
### Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v2 [cs.SD] UPDATED)
- Authors : Joan Serr, Santiago Pascual, Jordi Pons, Oguz Araz, Davide Scaini
- Link : [http://arxiv.org/abs/2206.03065](http://arxiv.org/abs/2206.03065)
> ABSTRACT  :  Removing background noise from speech audio has been the subject of considerable effort, especially in recent years due to the rise of virtual communication and amateur recordings. Yet background noise is not the only unpleasant disturbance that can prevent intelligibility: reverb, clipping, codec artifacts, problematic equalization, limited bandwidth, or inconsistent loudness are equally disturbing and ubiquitous. In this work, we propose to consider the task of speech **enhancement** as a holistic endeavor, and present a universal speech **enhancement** system that tackles 55 different distortions at the same time. Our approach consists of a generative model that employs score-based diffusion, together with a multi-resolution conditioning network that performs **enhancement** with mixture density networks. We show that this approach significantly outperforms the state of the art in a subjective test performed by expert listeners. We also show that it achieves competitive objective scores with just 4-8 diffusion steps, despite not considering any particular strategy for fast sampling. We hope that both our methodology and technical contributions encourage researchers and practitioners to adopt a universal approach to speech **enhancement**, possibly framing it as a generative task.  
### Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v2 [q-bio.NC] UPDATED)
- Authors : Chandramouli Rajagopalan, David Rawlinson, Elkhonon Goldberg, Gideon Kowadlo
- Link : [http://arxiv.org/abs/2209.06862](http://arxiv.org/abs/2209.06862)
> ABSTRACT  :  The brains of all **bilateral**ly symmetric animals on Earth are are divided into left and right hemispheres. The anatomy and functionality of the hemispheres have a large degree of overlap, but they specialize to possess different attributes. The left hemisphere is believed to specialize in specificity and routine, the right in generalities and novelty. In this study, we propose an artificial neural network that imitates that **bilateral** architecture using two convolutional neural networks with different training objectives and test it on an image classification task. The **bilateral** architecture outperforms architectures of similar representational capacity that don't exploit differential specialization. It demonstrates the efficacy of **bilateral**ism and constitutes a new principle that could be incorporated into other computational neuroscientific models and used as an inductive bias when designing new ML systems. An analysis of the model can help us to understand the human brain.  
## cs.AI
---
### ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV])
- Authors : Zimian Wei, Hengyue Pan, Xin Niu, Dongsheng Li
- Link : [http://arxiv.org/abs/2209.07738](http://arxiv.org/abs/2209.07738)
> ABSTRACT  :  Vision transformers have shown excellent performance in computer vision tasks. However, the computation cost of their (local) self-attention mechanism is expensive. Comparatively, CNN is more efficient with built-in inductive bias. Recent works show that CNN is promising to compete with vision transformers by learning their architecture design and training protocols. Nevertheless, existing methods either ignore multi-level features or lack dynamic prosperity, leading to sub-optimal performance. In this paper, we propose a novel attention mechanism named MCA, which captures different patterns of input images by multiple kernel sizes and enables input-adaptive weights with a gating mechanism. Based on MCA, we present a neural network named ConvFormer. ConvFormer adopts the general architecture of vision transformers, while replacing the (local) self-attention mechanism with our proposed MCA. Extensive experimental results demonstrated that ConvFormer outperforms similar size vision transformers(ViTs) and convolutional neural networks (CNNs) in various tasks. For example, ConvFormer-S, ConvFormer-L achieve state-of-the-art performance of 82.8%, 83.6% top-1 accuracy on ImageNet dataset. Moreover, ConvFormer-S outperforms **Swin**-T by 1.5 mIoU on ADE20K, and 0.9 bounding box AP on COCO with a smaller model size. Code and models will be available.  
### Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v2 [q-bio.NC] UPDATED)
- Authors : Chandramouli Rajagopalan, David Rawlinson, Elkhonon Goldberg, Gideon Kowadlo
- Link : [http://arxiv.org/abs/2209.06862](http://arxiv.org/abs/2209.06862)
> ABSTRACT  :  The brains of all **bilateral**ly symmetric animals on Earth are are divided into left and right hemispheres. The anatomy and functionality of the hemispheres have a large degree of overlap, but they specialize to possess different attributes. The left hemisphere is believed to specialize in specificity and routine, the right in generalities and novelty. In this study, we propose an artificial neural network that imitates that **bilateral** architecture using two convolutional neural networks with different training objectives and test it on an image classification task. The **bilateral** architecture outperforms architectures of similar representational capacity that don't exploit differential specialization. It demonstrates the efficacy of **bilateral**ism and constitutes a new principle that could be incorporated into other computational neuroscientific models and used as an inductive bias when designing new ML systems. An analysis of the model can help us to understand the human brain.  
# Paper List
---
## cs.CV
---
**88** new papers in cs.CV:-) 
1. MIPI 2022 Challenge on RGBW Sensor Fusion: Dataset and Report. (arXiv:2209.07530v1 [eess.IV])
2. One-Shot Synthesis of Images and Segmentation Masks. (arXiv:2209.07547v1 [cs.CV])
3. PIZZA: A Powerful Image-only Zero-Shot Zero-CAD Approach to 6 DoF Tracking. (arXiv:2209.07589v1 [cs.CV])
4. Prediction of Gender from Longitudinal MRI data via Deep Learning on Adolescent Data Reveals Unique Patterns Associated with Brain Structure and Change over a Two-year Period. (arXiv:2209.07590v1 [eess.IV])
5. Explicit Tradeoffs between Adversarial and Natural Distributional Robustness. (arXiv:2209.07592v1 [cs.LG])
6. Towards Improving Calibration in Object Detection Under Domain Shift. (arXiv:2209.07601v1 [cs.CV])
7. CES-KD: Curriculum-based Expert Selection for Guided Knowledge Distillation. (arXiv:2209.07606v1 [cs.CV])
8. Hierarchical Superquadric Decomposition with Implicit Space Separation. (arXiv:2209.07619v1 [cs.CV])
9. Self-Attentive Pooling for Efficient Deep Learning. (arXiv:2209.07659v1 [cs.CV])
10. SQ-**Swin**: a Pretrained Siamese Quadratic **Swin** Transformer for Lettuce Browning Prediction. (arXiv:2209.07683v1 [cs.CV])
11. Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation. (arXiv:2209.07695v1 [cs.CV])
12. Hybrid Window Attention Based Transformer Architecture for Brain Tumor Segmentation. (arXiv:2209.07704v1 [eess.IV])
13. Automatic Tumor Segmentation via False Positive Reduction Network for Whole-Body Multi-Modal PET/CT Images. (arXiv:2209.07705v1 [eess.IV])
14. LO-Det: Lightweight Oriented Object Detection in Remote Sensing Images. (arXiv:2209.07709v1 [cs.CV])
15. Continual Learning with Dependency Preserving Hypernetworks. (arXiv:2209.07712v1 [cs.LG])
16. A Mosquito is Worth 16x16 Larvae: Evaluation of Deep Learning Architectures for Mosquito Larvae Classification. (arXiv:2209.07718v1 [cs.CV])
17. VINet: Visual and Inertial-based Terrain Classification and Adaptive Navigation over Unknown Terrain. (arXiv:2209.07725v1 [cs.RO])
18. CenterLineDet: Road Lane CenterLine Graph Detection With Vehicle-Mounted Sensors by Transformer for High-definition Map Creation. (arXiv:2209.07734v1 [cs.CV])
19. Enhance the Visual Representation via Discrete Adversarial Training. (arXiv:2209.07735v1 [cs.CV])
20. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV])
21. Expansion and Shrinkage of Localization for Weakly-Supervised Semantic Segmentation. (arXiv:2209.07761v1 [cs.CV])
22. Image Understands Point Cloud: Weakly Supervised 3D Semantic Segmentation via Association Learning. (arXiv:2209.07774v1 [cs.CV])
23. Spatial-then-Temporal Self-Supervised Learning for Video Correspondence. (arXiv:2209.07778v1 [cs.CV])
24. PointCAT: Contrastive Adversarial Training for Robust Point Cloud Recognition. (arXiv:2209.07788v1 [cs.CV])
25. A Large-scale Multiple-objective Method for Black-box Attack against Object Detection. (arXiv:2209.07790v1 [cs.CV])
26. KaliCalib: A Framework for Basketball Court Registration. (arXiv:2209.07795v1 [cs.CV])
27. Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series. (arXiv:2209.07802v1 [cs.LG])
28. SRFeat: Learning Locally Accurate and Globally Consistent Non-Rigid Shape Correspondence. (arXiv:2209.07806v1 [cs.CV])
29. Single Image Deraining via Rain-Steaks Aware Deep Convolutional Neural Network. (arXiv:2209.07808v1 [cs.CV])
30. Modeling Multiple Views via Implicitly Preserving Global Consistency and Local Complementarity. (arXiv:2209.07811v1 [cs.CV])
31. Self-Supervised Learning of Phenotypic Representations from Cell Images with Weak Labels. (arXiv:2209.07819v1 [cs.CV])
32. Weakly Supervised Semantic Segmentation via Progressive Patch Learning. (arXiv:2209.07828v1 [cs.CV])
33. Topological Structure Learning for Weakly-Supervised Out-of-Distribution Detection. (arXiv:2209.07837v1 [cs.CV])
34. 3D Matting: A Soft Segmentation Method Applied in Computed Tomography. (arXiv:2209.07843v1 [eess.IV])
35. Whole-Body Lesion Segmentation in 18F-FDG PET/CT. (arXiv:2209.07851v1 [eess.IV])
36. GATraj: A Graph- and Attention-based Multi-Agent Trajectory Prediction Model. (arXiv:2209.07857v1 [cs.RO])
37. TwistSLAM++: Fusing multiple modalities for accurate dynamic semantic SLAM. (arXiv:2209.07888v1 [cs.CV])
38. 3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable Scene Graphs. (arXiv:2209.07896v1 [cs.RO])
39. MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning. (arXiv:2209.07902v1 [cs.LG])
40. Memory Consistent Unsupervised Off-the-Shelf Model Adaptation for Source-Relaxed Medical Image Segmentation. (arXiv:2209.07910v1 [cs.CV])
41. Estimation of Optical Aberrations in 3D Microscopic Bioimages. (arXiv:2209.07911v1 [eess.IV])
42. On Developing Facial Stress Analysis and Expression Recognition Platform. (arXiv:2209.07916v1 [cs.CV])
43. iDF-SLAM: End-to-End RGB-D SLAM with Neural Implicit Mapping and Deep Feature Tracking. (arXiv:2209.07919v1 [cs.RO])
44. An Attention-guided Multistream Feature Fusion Network for Localization of Risky Objects in Driving Videos. (arXiv:2209.07922v1 [cs.CV])
45. A Deep Moving-camera Background Model. (arXiv:2209.07923v1 [cs.CV])
46. DPFNet: A Dual-branch Dilated Network with Phase-aware Fourier Convolution for **Low-light** Image **Enhancement**. (arXiv:2209.07937v1 [cs.CV])
47. Traffic Congestion Prediction using Deep Convolutional Neural Networks: A Color-coding Approach. (arXiv:2209.07943v1 [cs.CV])
48. Omni-Dimensional Dynamic Convolution. (arXiv:2209.07947v1 [cs.CV])
49. SeqOT: A Spatial-Temporal Transformer Network for Place Recognition Using Sequential LiDAR Data. (arXiv:2209.07951v1 [cs.CV])
50. StyleGAN Encoder-Based Attack for Block Scrambled Face Images. (arXiv:2209.07953v1 [cs.CV])
51. Towards Bridging the Performance Gaps of Joint Energy-based Models. (arXiv:2209.07959v1 [cs.CV])
52. Imitrob: Imitation Learning Dataset for Training and Evaluating 6D Object Pose Estimators. (arXiv:2209.07976v1 [cs.RO])
53. CurveFormer: 3D Lane Detection by Curve Propagation with Curve Queries and Attention. (arXiv:2209.07989v1 [cs.CV])
54. Self-Supervised Learning with an Information Maximization Criterion. (arXiv:2209.07999v1 [cs.LG])
55. Causes of Catastrophic Forgetting in Class-Incremental Semantic Segmentation. (arXiv:2209.08010v1 [cs.CV])
56. Continual Learning for Class- and Domain-Incremental Semantic Segmentation. (arXiv:2209.08023v1 [cs.CV])
57. Stylized Adversarial Defense. (arXiv:2007.14672v2 [cs.CV] UPDATED)
58. Adversarial Driving: Attacking End-to-End Autonomous Driving. (arXiv:2103.09151v4 [cs.CV] UPDATED)
59. Bayesian dense inverse searching algorithm for real-time stereo matching in minimally invasive surgery. (arXiv:2106.07136v2 [cs.CV] UPDATED)
60. Enhancing Video Analytics Accuracy via **Real-time** Automated Camera Parameter Tuning. (arXiv:2107.03964v4 [cs.LG] UPDATED)
61. Fairness Properties of Face Recognition and Obfuscation Systems. (arXiv:2108.02707v3 [cs.CV] UPDATED)
62. AutoMTL: A Programming Framework for Automating Efficient Multi-Task Learning. (arXiv:2110.13076v2 [cs.LG] UPDATED)
63. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v5 [eess.IV] UPDATED)
64. Video-driven Neural Physically-based Facial Asset for Production. (arXiv:2202.05592v4 [cs.CV] UPDATED)
65. Holistic Attention-Fusion Adversarial Network for Single Image Defogging. (arXiv:2202.09553v2 [cs.CV] UPDATED)
66. InCloud: Incremental Learning for Point Cloud Place Recognition. (arXiv:2203.00807v2 [cs.CV] UPDATED)
67. Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction. (arXiv:2203.01703v3 [cs.CV] UPDATED)
68. Robust Table Detection and Structure Recognition from Heterogeneous Document Images. (arXiv:2203.09056v2 [cs.CV] UPDATED)
69. End-to-end Dense Video Captioning as Sequence Generation. (arXiv:2204.08121v2 [cs.CV] UPDATED)
70. DSCA: A Dual-Stream Network with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v3 [eess.IV] UPDATED)
71. AFT-VO: Asynchronous Fusion Transformers for Multi-View Visual Odometry Estimation. (arXiv:2206.12946v2 [cs.CV] UPDATED)
72. Boosting R-CNN: Reweighting R-CNN Samples by RPN's Error for Underwater Object Detection. (arXiv:2206.13728v2 [cs.CV] UPDATED)
73. Improving saliency models' predictions of the next fixation with humans' intrinsic cost of gaze shifts. (arXiv:2207.04250v2 [cs.CV] UPDATED)
74. 2DPASS: 2D Priors Assisted Semantic Segmentation on LiDAR Point Clouds. (arXiv:2207.04397v2 [cs.CV] UPDATED)
75. iColoriT: Towards Propagating Local Hint to the Right Region in Interactive Colorization by Leveraging Vision Transformer. (arXiv:2207.06831v4 [cs.CV] UPDATED)
76. Going Off-Grid: Continuous Implicit Neural Representations for 3D Vascular Modeling. (arXiv:2207.14663v2 [eess.IV] UPDATED)
77. Forensic License Plate Recognition with Compression-Informed Transformers. (arXiv:2207.14686v2 [cs.CV] UPDATED)
78. Lethal Dose Conjecture on Data Poisoning. (arXiv:2208.03309v2 [cs.LG] UPDATED)
79. A Man-in-the-Middle Attack against Object Detection Systems. (arXiv:2208.07174v2 [cs.RO] UPDATED)
80. AiM: Taking Answers in Mind to Correct Chinese Cloze Tests in Educational Applications. (arXiv:2208.12505v2 [cs.CL] UPDATED)
81. Why is the video analytics accuracy fluctuating, and what can we do about it?. (arXiv:2208.12644v2 [cs.CV] UPDATED)
82. Self-Supervised Face Presentation Attack Detection with Dynamic Grayscale Snippets. (arXiv:2208.13070v2 [cs.CV] UPDATED)
83. Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion. (arXiv:2209.01205v3 [cs.LG] UPDATED)
84. Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v2 [cs.AI] UPDATED)
85. TrackletMapper: Ground Surface Segmentation and Mapping from Traffic Participant Trajectories. (arXiv:2209.05247v2 [cs.RO] UPDATED)
86. PaLI: A Jointly-Scaled Multilingual Language-Image Model. (arXiv:2209.06794v2 [cs.CV] UPDATED)
87. One-Shot Transfer of Affordance Regions? AffCorrs!. (arXiv:2209.07147v2 [cs.CV] UPDATED)
88. A Robotic Visual Grasping Design: Rethinking Convolution Neural Network with High-Resolutions. (arXiv:2209.07459v2 [cs.RO] UPDATED)
## eess.IV
---
**24** new papers in eess.IV:-) 
1. MIPI 2022 Challenge on RGBW Sensor Fusion: Dataset and Report. (arXiv:2209.07530v1 [eess.IV])
2. Multi-Pose Fusion for Sparse-View CT Reconstruction Using Consensus Equilibrium. (arXiv:2209.07561v1 [eess.IV])
3. Prediction of Gender from Longitudinal MRI data via Deep Learning on Adolescent Data Reveals Unique Patterns Associated with Brain Structure and Change over a Two-year Period. (arXiv:2209.07590v1 [eess.IV])
4. Parallel faceted imaging in radio interferometry via proximal splitting (Faceted HyperSARA): II. Code and real data proof of concept. (arXiv:2209.07604v1 [astro-ph.IM])
5. Hybrid Window Attention Based Transformer Architecture for Brain Tumor Segmentation. (arXiv:2209.07704v1 [eess.IV])
6. Automatic Tumor Segmentation via False Positive Reduction Network for Whole-Body Multi-Modal PET/CT Images. (arXiv:2209.07705v1 [eess.IV])
7. 3D Matting: A Soft Segmentation Method Applied in Computed Tomography. (arXiv:2209.07843v1 [eess.IV])
8. Whole-Body Lesion Segmentation in 18F-FDG PET/CT. (arXiv:2209.07851v1 [eess.IV])
9. Structure-Preserving Spectral Reflectance Estimation using Guided Filtering. (arXiv:2209.07889v1 [eess.IV])
10. Spatio-spectral Image Reconstruction Using Non-local Filtering. (arXiv:2209.07890v1 [eess.IV])
11. Hyperspectral Image Reconstruction from Multispectral Images Using Non-Local Filtering. (arXiv:2209.07891v1 [eess.IV])
12. Optimal Filter Selection for Multispectral Object Classification Using Fast Binary Search. (arXiv:2209.07894v1 [eess.IV])
13. Memory Consistent Unsupervised Off-the-Shelf Model Adaptation for Source-Relaxed Medical Image Segmentation. (arXiv:2209.07910v1 [cs.CV])
14. Estimation of Optical Aberrations in 3D Microscopic Bioimages. (arXiv:2209.07911v1 [eess.IV])
15. Single-shot pop-out 3D metrology of thin specimens with TEM. (arXiv:2209.07930v1 [physics.ins-det])
16. DPFNet: A Dual-branch Dilated Network with Phase-aware Fourier Convolution for **Low-light** Image **Enhancement**. (arXiv:2209.07937v1 [cs.CV])
17. Self-Supervised Learning with an Information Maximization Criterion. (arXiv:2209.07999v1 [cs.LG])
18. Plug-and-Play Regularization using Linear Solvers. (arXiv:2209.08003v1 [eess.IV])
19. Motion Detection in Diffraction Tomography by Common Circle Methods. (arXiv:2209.08086v1 [math.NA])
20. Parallel faceted imaging in radio interferometry via proximal splitting (Faceted HyperSARA): I. Algorithm and simulations. (arXiv:2003.07358v2 [astro-ph.IM] UPDATED)
21. Deep learning for brain metastasis detection and segmentation in longitudinal MRI data. (arXiv:2112.11833v5 [eess.IV] UPDATED)
22. Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction. (arXiv:2203.01703v3 [cs.CV] UPDATED)
23. DSCA: A Dual-Stream Network with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v3 [eess.IV] UPDATED)
24. Going Off-Grid: Continuous Implicit Neural Representations for 3D Vascular Modeling. (arXiv:2207.14663v2 [eess.IV] UPDATED)
## cs.LG
---
**159** new papers in cs.LG:-) 
1. Improved proteasomal cleavage prediction with positive-unlabeled learning. (arXiv:2209.07527v1 [q-bio.QM])
2. A Survey on the application of Data Science And Analytics in the field of Organised Sports. (arXiv:2209.07528v1 [cs.LG])
3. On the Soft-Subnetwork for Few-shot Class Incremental Learning. (arXiv:2209.07529v1 [cs.LG])
4. Improving Robust Fairness via Balance Adversarial Training. (arXiv:2209.07534v1 [cs.LG])
5. Toward an understanding of the properties of neural network approaches for supernovae light curve approximation. (arXiv:2209.07542v1 [astro-ph.IM])
6. One-Shot Synthesis of Images and Segmentation Masks. (arXiv:2209.07547v1 [cs.CV])
7. Human-level Atari 200x faster. (arXiv:2209.07550v1 [cs.LG])
8. ZeroEGGS: Zero-shot Example-based Gesture Generation from Speech. (arXiv:2209.07556v1 [cs.GR])
9. Prediction of $\textrm{CO}_2$ Adsorption in Nano-Pores with Graph Neural Networks. (arXiv:2209.07567v1 [cond-mat.mtrl-sci])
10. Physically Constrained Generative Adversarial Networks for Improving Precipitation Fields from Earth System Models. (arXiv:2209.07568v1 [physics.ao-ph])
11. Towards a Better Microcredit Decision. (arXiv:2209.07574v1 [q-fin.RM])
12. A Nested Genetic Algorithm for Explaining Classification Data Sets with Decision Rules. (arXiv:2209.07575v1 [cs.NE])
13. Experimental verification of the quantum nature of a neural network. (arXiv:2209.07577v1 [cs.NE])
14. Pixel-wise classification in graphene-detection with tree-based machine learning algorithms. (arXiv:2209.07578v1 [cond-mat.mtrl-sci])
15. The Development of Spatial Attention U-Net for The Recovery of Ionospheric Measurements and The Extraction of Ionospheric Parameters. (arXiv:2209.07581v1 [physics.space-ph])
16. Context-Aware Query Rewriting for Improving Users' Search Experience on E-commerce Websites. (arXiv:2209.07584v1 [cs.IR])
17. Theroretical Insight into Batch Normalization: Data Dependant Auto-Tuning of Regularization Rate. (arXiv:2209.07587v1 [stat.ML])
18. Prediction of Gender from Longitudinal MRI data via Deep Learning on Adolescent Data Reveals Unique Patterns Associated with Brain Structure and Change over a Two-year Period. (arXiv:2209.07590v1 [eess.IV])
19. Explicit Tradeoffs between Adversarial and Natural Distributional Robustness. (arXiv:2209.07592v1 [cs.LG])
20. STPOTR: Simultaneous Human Trajectory and Pose Prediction Using a Non-Autoregressive Transformer for Robot Following Ahead. (arXiv:2209.07600v1 [cs.RO])
21. Hub-aware Random Walk Graph Embedding Methods for Classification. (arXiv:2209.07603v1 [cs.LG])
22. CES-KD: Curriculum-based Expert Selection for Guided Knowledge Distillation. (arXiv:2209.07606v1 [cs.CV])
23. Training Recipe for N:M Structured Sparsity with Decaying Pruning Mask. (arXiv:2209.07617v1 [cs.LG])
24. Studying the explanations for the automated prediction of bug and non-bug issues using LIME and SHAP. (arXiv:2209.07623v1 [cs.SE])
25. Self-Relation Attention and Temporal Awareness for Emotion Recognition via Vocal Burst. (arXiv:2209.07629v1 [cs.SD])
26. Improving Language Model Prompting in Support of Semi-autonomous Task Learning. (arXiv:2209.07636v1 [cs.LG])
27. Library transfer between distinct Laser-Induced Breakdown Spectroscopy systems with shared standards. (arXiv:2209.07637v1 [physics.data-an])
28. Bayesian Identification of Nonseparable Hamiltonian Systems Using Stochastic Dynamic Models. (arXiv:2209.07646v1 [math.DS])
29. Statistical Properties of the Entropy from Ordinal Patterns. (arXiv:2209.07650v1 [cs.IT])
30. Self-Attentive Pooling for Efficient Deep Learning. (arXiv:2209.07659v1 [cs.CV])
31. On the Relation between Sensitivity and Accuracy in In-context Learning. (arXiv:2209.07661v1 [cs.CL])
32. Can There be Art Without an Artist?. (arXiv:2209.07667v1 [cs.AI])
33. Reducing Variance in Temporal-Difference Value Estimation via Ensemble of Deep Networks. (arXiv:2209.07670v1 [cs.LG])
34. Conservative Dual Policy Optimization for Efficient Model-Based Reinforcement Learning. (arXiv:2209.07676v1 [cs.LG])
35. Learning Pair Potentials using Differentiable Simulations. (arXiv:2209.07679v1 [physics.chem-ph])
36. Masked Imitation Learning: Discovering Environment-Invariant Modalities in Multimodal Demonstrations. (arXiv:2209.07682v1 [cs.LG])
37. Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango. (arXiv:2209.07686v1 [cs.CL])
38. Towards A Unified Policy Abstraction Theory and Representation Learning Approach in Markov Decision Processes. (arXiv:2209.07696v1 [cs.LG])
39. Adversarial Cross-View Disentangled Graph Contrastive Learning. (arXiv:2209.07699v1 [cs.LG])
40. Federated Coordinate Descent for Privacy-Preserving Multiparty Linear Regression. (arXiv:2209.07702v1 [cs.LG])
41. Automatic Tumor Segmentation via False Positive Reduction Network for Whole-Body Multi-Modal PET/CT Images. (arXiv:2209.07705v1 [eess.IV])
42. Continual Learning with Dependency Preserving Hypernetworks. (arXiv:2209.07712v1 [cs.LG])
43. Renyi Differential Privacy of Propose-Test-Release and Applications to Private and Robust Machine Learning. (arXiv:2209.07716v1 [cs.CR])
44. A Mosquito is Worth 16x16 Larvae: Evaluation of Deep Learning Architectures for Mosquito Larvae Classification. (arXiv:2209.07718v1 [cs.CV])
45. Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study. (arXiv:2209.07736v1 [cs.LG])
46. Computing Abductive Explanations for Boosted Trees. (arXiv:2209.07740v1 [cs.AI])
47. Reinforcement Learning Based Cooperative P2P Energy Trading between DC Nanogrid Clusters with Wind and PV Energy Resources. (arXiv:2209.07744v1 [cs.LG])
48. Sales Channel Optimization via Simulations Based on Observational Data with Delayed Rewards: A Case Study at LinkedIn. (arXiv:2209.07749v1 [cs.LG])
49. PINEAPPLE: Personifying INanimate Entities by Acquiring Parallel Personification data for Learning Enhanced generation. (arXiv:2209.07752v1 [cs.CL])
50. On the Robustness of Graph Neural Diffusion to Topology Perturbations. (arXiv:2209.07754v1 [cs.LG])
51. Joint estimation of posterior probability and propensity score function for positive and unlabelled data. (arXiv:2209.07787v1 [stat.ML])
52. DBT-DMAE: An Effective Multivariate Time Series Pre-Train Model under Missing Data. (arXiv:2209.07798v1 [cs.LG])
53. Dynamics-informed deconvolutional neural networks for super-resolution identification of regime changes in epidemiological time series. (arXiv:2209.07802v1 [cs.LG])
54. A Comprehensive Benchmark for COVID-19 Predictive Modeling Using Electronic Health Records in Intensive Care: Choosing the Best Model for COVID-19 Prognosis. (arXiv:2209.07805v1 [cs.LG])
55. Model Inversion Attacks against Graph Neural Networks. (arXiv:2209.07807v1 [cs.LG])
56. M$^2$DQN: A Robust Method for Accelerating Deep Q-learning Network. (arXiv:2209.07809v1 [cs.LG])
57. Serialized Interacting Mixed Membership Stochastic Block Model. (arXiv:2209.07813v1 [cs.LG])
58. Truthful Generalized Linear Models. (arXiv:2209.07815v1 [cs.LG])
59. Properties of Reddit News Topical Interactions. (arXiv:2209.07816v1 [cs.SI])
60. SPGP: Structure Prototype Guided Graph Pooling. (arXiv:2209.07817v1 [cs.LG])
61. Quantization for decentralized learning under subspace constraints. (arXiv:2209.07821v1 [math.OC])
62. Privacy-Preserving Distributed Expectation Maximization for Gaussian Mixture Model using Subspace Perturbation. (arXiv:2209.07833v1 [cs.LG])
63. Topological Structure Learning for Weakly-Supervised Out-of-Distribution Detection. (arXiv:2209.07837v1 [cs.CV])
64. Neuromuscular Reinforcement Learning to Actuate Human Limbs through FES. (arXiv:2209.07849v1 [cs.LG])
65. FairGBM: Gradient Boosting with Fairness Constraints. (arXiv:2209.07850v1 [cs.LG])
66. Extracting Biomedical Factual Knowledge Using Pretrained Language Model and Electronic Health Record Context. (arXiv:2209.07859v1 [cs.IR])
67. Machine Learning Decoder for 5G NR PUCCH Format 0. (arXiv:2209.07861v1 [cs.NI])
68. Continual Few Shot Learning with Hippocampal-Inspired Replay. (arXiv:2209.07863v1 [cs.NE])
69. LogGD:Detecting Anomalies from System Logs by Graph Neural Networks. (arXiv:2209.07869v1 [cs.SE])
70. Less is Better: Recovering Intended-Feature Subspace to Robustify NLU Models. (arXiv:2209.07879v1 [cs.CL])
71. Model Predictive Robustness of Signal Temporal Logic Predicates. (arXiv:2209.07881v1 [cs.RO])
72. Minibatch Stochastic Three Points Method for Unconstrained Smooth Minimization. (arXiv:2209.07883v1 [math.OC])
73. Versatile Skill Control via Self-supervised Adversarial Imitation of Unlabeled Mixed Motions. (arXiv:2209.07899v1 [cs.RO])
74. MetaMask: Revisiting Dimensional Confounder for Self-Supervised Learning. (arXiv:2209.07902v1 [cs.LG])
75. Memory Consistent Unsupervised Off-the-Shelf Model Adaptation for Source-Relaxed Medical Image Segmentation. (arXiv:2209.07910v1 [cs.CV])
76. A benchmark study on methods to ensure fair algorithmic decisions for credit scoring. (arXiv:2209.07912v1 [cs.LG])
77. ImDrug: A Benchmark for Deep Imbalanced Learning in AI-aided Drug Discovery. (arXiv:2209.07921v1 [cs.LG])
78. GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks. (arXiv:2209.07924v1 [cs.LG])
79. Explainability in subgraphs-enhanced Graph Neural Networks. (arXiv:2209.07926v1 [cs.LG])
80. Mining SoC Message Flows with Attention Model. (arXiv:2209.07929v1 [cs.AI])
81. Fine-tuning or top-tuning? Transfer learning with pretrained features and fast kernel methods. (arXiv:2209.07932v1 [cs.LG])
82. Omni-Dimensional Dynamic Convolution. (arXiv:2209.07947v1 [cs.CV])
83. Malicious Source Code Detection Using Transformer. (arXiv:2209.07957v1 [cs.CR])
84. Causal Fourier Analysis on Directed Acyclic Graphs and Posets. (arXiv:2209.07970v1 [eess.SP])
85. Examining spatial heterogeneity of ridesourcing demand determinants with explainable machine learning. (arXiv:2209.07980v1 [cs.LG])
86. Self-Supervised Learning with an Information Maximization Criterion. (arXiv:2209.07999v1 [cs.LG])
87. Robust Inference of Manifold Density and Geometry by Doubly Stochastic Scaling. (arXiv:2209.08004v1 [math.ST])
88. Stability and Generalization for Markov Chain Stochastic Gradient Methods. (arXiv:2209.08005v1 [stat.ML])
89. IoT Data Analytics in Dynamic Environments: From An Automated Machine Learning Perspective. (arXiv:2209.08018v1 [cs.LG])
90. Trustworthy Reinforcement Learning Against Intrinsic Vulnerabilities: Robustness, Safety, and Generalizability. (arXiv:2209.08025v1 [cs.LG])
91. Interactions in Information Spread. (arXiv:2209.08026v1 [cs.SI])
92. Detection of Interacting Variables for Generalized Linear Models via Neural Networks. (arXiv:2209.08030v1 [stat.ML])
93. Learning Policies for Continuous Control via Transition Models. (arXiv:2209.08033v1 [cs.RO])
94. A Biologically-Inspired Dual Stream World Model. (arXiv:2209.08035v1 [cs.LG])
95. DAGMA: Learning DAGs via M-matrices and a Log-Determinant Acyclicity Characterization. (arXiv:2209.08037v1 [cs.LG])
96. Exploring the Whole Rashomon Set of Sparse Decision Trees. (arXiv:2209.08040v1 [cs.LG])
97. Self-Optimizing Feature Transformation. (arXiv:2209.08044v1 [cs.LG])
98. PTab: Using the Pre-trained Language Model for Modeling Tabular Data. (arXiv:2209.08060v1 [cs.LG])
99. A Systematic Evaluation of Node Embedding Robustness. (arXiv:2209.08064v1 [cs.LG])
100. Mitigating the Effects of Non-Identifiability on Inference for Bayesian Neural Networks with Latent Variables. (arXiv:1911.00569v4 [cs.LG] UPDATED)
101. D-GCCA: Decomposition-based Generalized Canonical Correlation Analysis for Multi-view High-dimensional Data. (arXiv:2001.02856v3 [stat.ML] UPDATED)
102. Optimal binning: mathematical programming formulation. (arXiv:2001.08025v2 [cs.LG] UPDATED)
103. Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model. (arXiv:2005.12900v6 [cs.LG] UPDATED)
104. Support vector machines and Radon's theorem. (arXiv:2011.00617v4 [cs.LG] UPDATED)
105. BayesBeat: Reliable Atrial Fibrillation Detection from Noisy Photoplethysmography Data. (arXiv:2011.00753v2 [cs.LG] UPDATED)
106. Sub-GMN: The Neural Subgraph Matching Network Model. (arXiv:2104.00186v5 [cs.LG] UPDATED)
107. Neurons on Amoebae. (arXiv:2106.03695v2 [math.AG] UPDATED)
108. Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations. (arXiv:2106.13876v4 [cs.CL] UPDATED)
109. Enhancing Video Analytics Accuracy via **Real-time** Automated Camera Parameter Tuning. (arXiv:2107.03964v4 [cs.LG] UPDATED)
110. UnSplit: Data-Oblivious Model Inversion, Model Stealing, and Label Inference Attacks Against Split Learning. (arXiv:2108.09033v2 [cs.CR] UPDATED)
111. SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split Learning. (arXiv:2108.09052v3 [cs.CR] UPDATED)
112. CrypTen: Secure Multi-Party Computation Meets Machine Learning. (arXiv:2109.00984v2 [cs.LG] UPDATED)
113. Satellite galaxy abundance dependency on cosmology in Magneticum simulations. (arXiv:2110.05498v2 [astro-ph.CO] UPDATED)
114. Multi-Modal Pre-Training for Automated Speech Recognition. (arXiv:2110.09890v2 [eess.AS] UPDATED)
115. AutoMTL: A Programming Framework for Automating Efficient Multi-Task Learning. (arXiv:2110.13076v2 [cs.LG] UPDATED)
116. How to See Hidden Patterns in Metamaterials with Interpretable Machine Learning. (arXiv:2111.05949v3 [cs.LG] UPDATED)
117. Privacy-preserving Federated Learning for Residential Short Term Load Forecasting. (arXiv:2111.09248v3 [cs.LG] UPDATED)
118. Modeling and estimating mixed memberships in weighted networks. (arXiv:2112.04389v2 [cs.SI] UPDATED)
119. Two-view Graph Neural Networks for Knowledge Graph Completion. (arXiv:2112.09231v2 [cs.CL] UPDATED)
120. A Spectral Method for Joint Community Detection and Orthogonal Group Synchronization. (arXiv:2112.13199v2 [stat.ML] UPDATED)
121. Evolutionary Action Selection for Gradient-based Policy Learning. (arXiv:2201.04286v4 [cs.NE] UPDATED)
122. Overcoming Exploration: Deep Reinforcement Learning in Complex Environments from Temporal Logic Specifications. (arXiv:2201.12231v3 [cs.RO] UPDATED)
123. Smoothed Embeddings for Certified Few-Shot Learning. (arXiv:2202.01186v2 [cs.LG] UPDATED)
124. Systematically and efficiently improving existing $k$-means initialization algorithms by pairwise-nearest-neighbor smoothing. (arXiv:2202.03949v3 [cs.LG] UPDATED)
125. Multimodal Audio-Visual Information Fusion using Canonical-Correlated Graph Neural Network for Energy-Efficient Speech **Enhancement**. (arXiv:2202.04528v3 [cs.SD] UPDATED)
126. Missing Data Imputation and Acquisition with Deep Hierarchical Models and Hamiltonian Monte Carlo. (arXiv:2202.04599v3 [cs.LG] UPDATED)
127. Non-stationary Bandits and Meta-Learning with a Small Set of Optimal Arms. (arXiv:2202.13001v5 [cs.LG] UPDATED)
128. Capturing Shape Information with Multi-Scale Topological Loss Terms for 3D Reconstruction. (arXiv:2203.01703v3 [cs.CV] UPDATED)
129. Algorithmic Regularization in Model-free Overparametrized Asymmetric Matrix Factorization. (arXiv:2203.02839v2 [cs.LG] UPDATED)
130. Properties and Performance of the ABCDe Random Graph Model with Community Structure. (arXiv:2203.14899v2 [cs.SI] UPDATED)
131. Active Learning for Computationally Efficient Distribution of Binary Evolution Simulations. (arXiv:2203.16683v3 [astro-ph.SR] UPDATED)
132. Learning to Constrain Policy Optimization with Virtual Trust Region. (arXiv:2204.09315v2 [cs.LG] UPDATED)
133. Broad Recommender System: An Efficient Nonlinear Collaborative Filtering Approach. (arXiv:2204.11602v2 [cs.IR] UPDATED)
134. Symphony Generation with Permutation Invariant Language Model. (arXiv:2205.05448v2 [cs.SD] UPDATED)
135. Mondrian Forest for Data Stream Classification Under Memory Constraints. (arXiv:2205.07871v2 [cs.LG] UPDATED)
136. FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting. (arXiv:2205.08897v4 [cs.LG] UPDATED)
137. TransTab: Learning Transferable Tabular Transformers Across Tables. (arXiv:2205.09328v2 [cs.LG] UPDATED)
138. The Selectively Adaptive Lasso. (arXiv:2205.10697v3 [stat.ML] UPDATED)
139. Maximum Likelihood Training of Implicit Nonlinear Diffusion Models. (arXiv:2205.13699v2 [cs.LG] UPDATED)
140. Universal Speech **Enhancement** with Score-based Diffusion. (arXiv:2206.03065v2 [cs.SD] UPDATED)
141. DSCA: A Dual-Stream Network with Cross-Attention on Whole-Slide Image Pyramids for Cancer Prognosis. (arXiv:2206.05782v3 [eess.IV] UPDATED)
142. Learning the Quality of Machine Permutations in Job Shop Scheduling. (arXiv:2207.03244v2 [cs.LG] UPDATED)
143. FairDistillation: Mitigating Stereotyping in Language Models. (arXiv:2207.04546v2 [cs.CL] UPDATED)
144. Optimization of the Shape of a Hydrokinetic Turbine's Draft Tube and Hub Assembly Using Design-by-Morphing with Bayesian Optimization. (arXiv:2207.11451v4 [cs.CG] UPDATED)
145. Factorizable Joint Shift in Multinomial Classification. (arXiv:2207.14514v2 [stat.ML] UPDATED)
146. What can be learnt with wide convolutional networkds?. (arXiv:2208.01003v2 [stat.ML] UPDATED)
147. Lethal Dose Conjecture on Data Poisoning. (arXiv:2208.03309v2 [cs.LG] UPDATED)
148. More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference. (arXiv:2208.04580v3 [cs.LG] UPDATED)
149. Learning with Local Gradients at the Edge. (arXiv:2208.08503v2 [cs.LG] UPDATED)
150. Why is the video analytics accuracy fluctuating, and what can we do about it?. (arXiv:2208.12644v2 [cs.CV] UPDATED)
151. Listen to your heart: A self-supervised approach for detecting murmur in heart-beat sounds. (arXiv:2208.14845v3 [cs.LG] UPDATED)
152. Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion. (arXiv:2209.01205v3 [cs.LG] UPDATED)
153. MRF-PINN: A Multi-Receptive-Field convolutional physics-informed neural network for solving partial differential equations. (arXiv:2209.03151v2 [cs.LG] UPDATED)
154. Fairness in Forecasting of Observations of Linear Dynamical Systems. (arXiv:2209.05274v2 [cs.LG] UPDATED)
155. The Mori-Zwanzig formulation of deep learning. (arXiv:2209.05544v2 [cs.LG] UPDATED)
156. Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v2 [q-bio.NC] UPDATED)
157. Efficient learning of nonlinear prediction models with time-series privileged information. (arXiv:2209.07067v2 [cs.LG] UPDATED)
158. Decentralized Learning with Separable Data: Generalization and Fast Algorithms. (arXiv:2209.07116v2 [cs.LG] UPDATED)
159. A Robotic Visual Grasping Design: Rethinking Convolution Neural Network with High-Resolutions. (arXiv:2209.07459v2 [cs.RO] UPDATED)
## cs.AI
---
**75** new papers in cs.AI:-) 
1. On the Soft-Subnetwork for Few-shot Class Incremental Learning. (arXiv:2209.07529v1 [cs.LG])
2. Improving Robust Fairness via Balance Adversarial Training. (arXiv:2209.07534v1 [cs.LG])
3. Snowmass 2021 Computational Frontier CompF03 Topical Group Report: Machine Learning. (arXiv:2209.07559v1 [physics.comp-ph])
4. A Nested Genetic Algorithm for Explaining Classification Data Sets with Decision Rules. (arXiv:2209.07575v1 [cs.NE])
5. Corpus-Guided Contrast Sets for Morphosyntactic Feature Detection in Low-Resource English Varieties. (arXiv:2209.07611v1 [cs.CL])
6. Training Recipe for N:M Structured Sparsity with Decaying Pruning Mask. (arXiv:2209.07617v1 [cs.LG])
7. Differentiable Bilevel Programming for Stackelberg Congestion Games. (arXiv:2209.07618v1 [cs.GT])
8. Improving Language Model Prompting in Support of Semi-autonomous Task Learning. (arXiv:2209.07636v1 [cs.LG])
9. Application of Liquid Rank Reputation System for Content Recommendation. (arXiv:2209.07641v1 [cs.IR])
10. Computing the optimal distributionally-robust strategy to commit to. (arXiv:2209.07647v1 [cs.GT])
11. Multiscale Adaptive Scheduling and Path-Planning for Power-Constrained UAV-Relays via SMDPs. (arXiv:2209.07655v1 [eess.SY])
12. Sequential Bayesian Optimization for Adaptive Informative Path Planning with Multimodal Sensing. (arXiv:2209.07660v1 [cs.AI])
13. On the Relation between Sensitivity and Accuracy in In-context Learning. (arXiv:2209.07661v1 [cs.CL])
14. Can There be Art Without an Artist?. (arXiv:2209.07667v1 [cs.AI])
15. ConFiguRe: Exploring Discourse-level Chinese Figures of Speech. (arXiv:2209.07678v1 [cs.CL])
16. Text and Patterns: For Effective Chain of Thought, It Takes Two to Tango. (arXiv:2209.07686v1 [cs.CL])
17. Selecting Stickers in Open-Domain Dialogue through Multitask Learning. (arXiv:2209.07697v1 [cs.CL])
18. Comments on "Iteratively Re-weighted Algorithm for Fuzzy c-Means". (arXiv:2209.07715v1 [cs.AI])
19. A Mosquito is Worth 16x16 Larvae: Evaluation of Deep Learning Architectures for Mosquito Larvae Classification. (arXiv:2209.07718v1 [cs.CV])
20. Extrapolation and Spectral Bias of Neural Nets with Hadamard Product: a Polynomial Net Study. (arXiv:2209.07736v1 [cs.LG])
21. ConvFormer: Closing the Gap Between CNN and Vision Transformers. (arXiv:2209.07738v1 [cs.CV])
22. Computing Abductive Explanations for Boosted Trees. (arXiv:2209.07740v1 [cs.AI])
23. PINEAPPLE: Personifying INanimate Entities by Acquiring Parallel Personification data for Learning Enhanced generation. (arXiv:2209.07752v1 [cs.CL])
24. Game-theoretic Objective Space Planning. (arXiv:2209.07758v1 [cs.RO])
25. Possible Stories: Evaluating Situated Commonsense Reasoning under Multiple Possible Scenarios. (arXiv:2209.07760v1 [cs.CL])
26. DBT-DMAE: An Effective Multivariate Time Series Pre-Train Model under Missing Data. (arXiv:2209.07798v1 [cs.LG])
27. Model Inversion Attacks against Graph Neural Networks. (arXiv:2209.07807v1 [cs.LG])
28. M$^2$DQN: A Robust Method for Accelerating Deep Q-learning Network. (arXiv:2209.07809v1 [cs.LG])
29. Negation, Coordination, and Quantifiers in Contextualized Language Models. (arXiv:2209.07836v1 [cs.CL])
30. FairGBM: Gradient Boosting with Fairness Constraints. (arXiv:2209.07850v1 [cs.LG])
31. Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned. (arXiv:2209.07858v1 [cs.CL])
32. Extracting Biomedical Factual Knowledge Using Pretrained Language Model and Electronic Health Record Context. (arXiv:2209.07859v1 [cs.IR])
33. Adaptive Natural Language Generation for Task-oriented Dialogue via Reinforcement Learning. (arXiv:2209.07873v1 [cs.CL])
34. Less is Better: Recovering Intended-Feature Subspace to Robustify NLU Models. (arXiv:2209.07879v1 [cs.CL])
35. Model Predictive Robustness of Signal Temporal Logic Predicates. (arXiv:2209.07881v1 [cs.RO])
36. Versatile Skill Control via Self-supervised Adversarial Imitation of Unlabeled Mixed Motions. (arXiv:2209.07899v1 [cs.RO])
37. Memory Consistent Unsupervised Off-the-Shelf Model Adaptation for Source-Relaxed Medical Image Segmentation. (arXiv:2209.07910v1 [cs.CV])
38. A benchmark study on methods to ensure fair algorithmic decisions for credit scoring. (arXiv:2209.07912v1 [cs.LG])
39. ImDrug: A Benchmark for Deep Imbalanced Learning in AI-aided Drug Discovery. (arXiv:2209.07921v1 [cs.LG])
40. GNNInterpreter: A Probabilistic Generative Model-Level Explanation for Graph Neural Networks. (arXiv:2209.07924v1 [cs.LG])
41. The BLue Amazon Brain (BLAB): A Modular Architecture of Services about the Brazilian Maritime Territory. (arXiv:2209.07928v1 [cs.AI])
42. Mining SoC Message Flows with Attention Model. (arXiv:2209.07929v1 [cs.AI])
43. Traffic Congestion Prediction using Deep Convolutional Neural Networks: A Color-coding Approach. (arXiv:2209.07943v1 [cs.CV])
44. Omni-Dimensional Dynamic Convolution. (arXiv:2209.07947v1 [cs.CV])
45. User Guided Abductive Proof Generation for Answer Set Programming Queries (Extended Version). (arXiv:2209.07948v1 [cs.AI])
46. A Multi-turn Machine Reading Comprehension Framework with Rethink Mechanism for Emotion-Cause Pair Extraction. (arXiv:2209.07972v1 [cs.CL])
47. SoLo T-DIRL: Socially-Aware Dynamic Local Planner based on Trajectory-Ranked Deep Inverse Reinforcement Learning. (arXiv:2209.07996v1 [cs.RO])
48. Self-Supervised Learning with an Information Maximization Criterion. (arXiv:2209.07999v1 [cs.LG])
49. Learning Policies for Continuous Control via Transition Models. (arXiv:2209.08033v1 [cs.RO])
50. Exploring the Whole Rashomon Set of Sparse Decision Trees. (arXiv:2209.08040v1 [cs.LG])
51. Self-Optimizing Feature Transformation. (arXiv:2209.08044v1 [cs.LG])
52. PTab: Using the Pre-trained Language Model for Modeling Tabular Data. (arXiv:2209.08060v1 [cs.LG])
53. Case Studies for Computing Density of Reachable States for Safe Autonomous Motion Planning. (arXiv:2209.08073v1 [cs.RO])
54. Knowledge-Grounded Self-Rationalization via Extractive and Natural Language Explanations. (arXiv:2106.13876v4 [cs.CL] UPDATED)
55. Fairness Properties of Face Recognition and Obfuscation Systems. (arXiv:2108.02707v3 [cs.CV] UPDATED)
56. Privacy-preserving Federated Learning for Residential Short Term Load Forecasting. (arXiv:2111.09248v3 [cs.LG] UPDATED)
57. Two-view Graph Neural Networks for Knowledge Graph Completion. (arXiv:2112.09231v2 [cs.CL] UPDATED)
58. Scaling Up Knowledge Graph Creation to Large and Heterogeneous Data Sources. (arXiv:2201.09694v2 [cs.AI] UPDATED)
59. Smoothed Embeddings for Certified Few-Shot Learning. (arXiv:2202.01186v2 [cs.LG] UPDATED)
60. Uncovering Instabilities in Variational-Quantum Deep Q-Networks. (arXiv:2202.05195v2 [quant-ph] UPDATED)
61. InCloud: Incremental Learning for Point Cloud Place Recognition. (arXiv:2203.00807v2 [cs.CV] UPDATED)
62. Scalable Verification of GNN-based Job Schedulers. (arXiv:2203.03153v4 [cs.AI] UPDATED)
63. Incremental Prompting: Episodic Memory Prompt for Lifelong Event Detection. (arXiv:2204.07275v2 [cs.CL] UPDATED)
64. Symphony Generation with Permutation Invariant Language Model. (arXiv:2205.05448v2 [cs.SD] UPDATED)
65. Mondrian Forest for Data Stream Classification Under Memory Constraints. (arXiv:2205.07871v2 [cs.LG] UPDATED)
66. TransTab: Learning Transferable Tabular Transformers Across Tables. (arXiv:2205.09328v2 [cs.LG] UPDATED)
67. Forensic License Plate Recognition with Compression-Informed Transformers. (arXiv:2207.14686v2 [cs.CV] UPDATED)
68. Lethal Dose Conjecture on Data Poisoning. (arXiv:2208.03309v2 [cs.LG] UPDATED)
69. More Interpretable Graph Similarity Computation via Maximum Common Subgraph Inference. (arXiv:2208.04580v3 [cs.LG] UPDATED)
70. Learning with Local Gradients at the Edge. (arXiv:2208.08503v2 [cs.LG] UPDATED)
71. Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v2 [cs.AI] UPDATED)
72. ProjB: An Improved Bilinear Biased ProjE model for Knowledge Graph Completion. (arXiv:2209.02390v2 [cs.AI] UPDATED)
73. SANCL: Multimodal Review Helpfulness Prediction with Selective Attention and Natural Contrastive Learning. (arXiv:2209.05040v4 [cs.CL] UPDATED)
74. Deep learning in a **bilateral** brain with hemispheric specialization. (arXiv:2209.06862v2 [q-bio.NC] UPDATED)
75. Gollum: A Gold Standard for Large Scale Multi Source Knowledge Graph Matching. (arXiv:2209.07479v2 [cs.AI] UPDATED)

